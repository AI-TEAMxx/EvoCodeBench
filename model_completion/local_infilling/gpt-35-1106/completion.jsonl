{"namespace": "iris.io.validators.are_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shapes of field1 and field2 are equal.\"\"\"\n        shape_field_1 = values[field1].shape\n        shape_field_2 = values[field2].shape\n\n        if shape_field_1 != shape_field_2:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, resp. {shape_field_1} and {shape_field_2}.\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shapes of field1 and field2 are equal.\"\"\"\n        shape_field_1 = values[field1].shape\n        shape_field_2 = values[field2].shape\n\n        if shape_field_1 != shape_field_2:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, resp. {shape_field_1} and {shape_field_2}.\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shapes of field1 and field2 are equal.\"\"\"\n        shape_field_1 = values[field1].shape\n        shape_field_2 = values[field2].shape\n\n        if shape_field_1 != shape_field_2:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, resp. {shape_field_1} and {shape_field_2}.\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1 and field2 have the same shape.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, resp. {values[field1].shape} and {values[field2].shape}.\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if len(field1) equals len(field2) and if every element have the same shape.\"\"\"\n        shape_field_1 = values[field1].shape\n        shape_field_2 = values[field2].shape\n\n        if shape_field_1 != shape_field_2:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, resp. {shape_field_1} and {shape_field_2}.\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shapes of field1 and field2 are equal.\"\"\"\n        shape_field_1 = values[field1].shape\n        shape_field_2 = values[field2].shape\n\n        if shape_field_1 != shape_field_2:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, resp. {shape_field_1} and {shape_field_2}.\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1 and field2 have the same shape.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, resp. {values[field1].shape} and {values[field2].shape}.\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shapes of field1 and field2 are equal.\"\"\"\n        shape_field_1 = values[field1].shape\n        shape_field_2 = values[field2].shape\n\n        if shape_field_1 != shape_field_2:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, resp. {shape_field_1} and {shape_field_2}.\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1 and field2 have the same shape.\"\"\"\n        shape_field_1 = values[field1].shape\n        shape_field_2 = values[field2].shape\n\n        if shape_field_1 != shape_field_2:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, resp. {shape_field_1} and {shape_field_2}.\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1 and field2 have the same shape.\"\"\"\n        shape_field_1 = values[field1].shape\n        shape_field_2 = values[field2].shape\n\n        if shape_field_1 != shape_field_2:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, resp. {shape_field_1} and {shape_field_2}.\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shapes of field1 and field2 are equal.\"\"\"\n        shape_field_1 = values[field1].shape\n        shape_field_2 = values[field2].shape\n\n        if shape_field_1 != shape_field_2:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, resp. {shape_field_1} and {shape_field_2}.\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shapes of field1 and field2 match.\"\"\"\n        shape_field_1 = values[field1].shape\n        shape_field_2 = values[field2].shape\n\n        if shape_field_1 != shape_field_2:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, resp. {shape_field_1} and {shape_field_2}.\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shapes of field1 and field2 are equal.\"\"\"\n        shape_field_1 = values[field1].shape\n        shape_field_2 = values[field2].shape\n\n        if shape_field_1 != shape_field_2:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, resp. {shape_field_1} and {shape_field_2}.\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if len(field1) equals len(field2) and if every element have the same shape.\"\"\"\n        shapes_field_1 = [element.shape for element in values[field1]]\n        shapes_field_2 = [element.shape for element in values[field2]]\n\n        if len(values[field1]) != len(values[field2]) or shapes_field_1 != shapes_field_2:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, resp. {shapes_field_1} and {shapes_field_2}.\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shapes of field1 and field2 are equal.\"\"\"\n        shape_field_1 = values[field1].shape\n        shape_field_2 = values[field2].shape\n\n        if shape_field_1 != shape_field_2:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, resp. {shape_field_1} and {shape_field_2}.\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1 and field2 have the same shape.\"\"\"\n        shape_field_1 = values[field1].shape\n        shape_field_2 = values[field2].shape\n\n        if shape_field_1 != shape_field_2:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, resp. {shape_field_1} and {shape_field_2}.\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1 and field2 have the same shape.\"\"\"\n        shape_field_1 = values[field1].shape\n        shape_field_2 = values[field2].shape\n\n        if shape_field_1 != shape_field_2:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, resp. {shape_field_1} and {shape_field_2}.\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if len(field1) equals len(field2) and if every element have the same shape.\"\"\"\n        shapes_field_1 = [element.shape for element in values[field1]]\n        shapes_field_2 = [element.shape for element in values[field2]]\n\n        if len(values[field1]) != len(values[field2]) or shapes_field_1 != shapes_field_2:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, resp. {shapes_field_1} and {shapes_field_2}.\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if len(field1) equals len(field2) and if every element have the same shape.\"\"\"\n        shapes_field_1 = [element.shape for element in values[field1]]\n        shapes_field_2 = [element.shape for element in values[field2]]\n\n        if len(values[field1]) != len(values[field2]) or shapes_field_1 != shapes_field_2:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, resp. {shapes_field_1} and {shapes_field_2}.\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shapes of field1 and field2 are equal.\"\"\"\n        shape_field_1 = values[field1].shape\n        shape_field_2 = values[field2].shape\n\n        if shape_field_1 != shape_field_2:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, resp. {shape_field_1} and {shape_field_2}.\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(*args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_execute(result)\n\n        return result"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(*args, **kwargs)\n        result = self.run(*args, **kwargs)\n        for callback in self._callbacks:\n            callback.post_execute(result)\n        return result"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        # Add the implementation of the execute method here\n        pass"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(self, *args, **kwargs)\n        \n        result = self.run(*args, **kwargs)\n        \n        for callback in self._callbacks:\n            callback.post_execute(self, *args, **kwargs)\n        \n        return result"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(*args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_execute(result)\n\n        return result"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(*args, **kwargs)\n        \n        result = self.run(*args, **kwargs)\n        \n        for callback in self._callbacks:\n            callback.post_execute(result, *args, **kwargs)\n        \n        return result"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(*args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_execute(result, *args, **kwargs)\n\n        return result"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        # Add the implementation of the execute method here\n        pass  # Placeholder for the implementation"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        # Add the implementation of the main algorithm here\n        pass"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(*args, **kwargs)\n        \n        result = self.run(*args, **kwargs)\n        \n        for callback in self._callbacks:\n            callback.post_execute(result, *args, **kwargs)\n        \n        return result"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(*args, **kwargs)\n        \n        result = self.run(*args, **kwargs)\n        \n        for callback in self._callbacks:\n            callback.post_execute(result, *args, **kwargs)\n        \n        return result"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(*args, **kwargs)  # Pre-execution hook\n\n        result = self.run(*args, **kwargs)  # Main algorithm run method\n\n        for callback in self._callbacks:\n            callback.post_execute(result, *args, **kwargs)  # Post-execution hook\n\n        return result"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(*args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_execute(result)\n\n        return result"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(*args, **kwargs)\n        result = self.run(*args, **kwargs)\n        for callback in self._callbacks:\n            callback.post_execute(result, *args, **kwargs)\n        return result"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        # Add the implementation of the main algorithm here\n        pass"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(*args, **kwargs)  # Pre-execution hook\n\n        result = self.run(*args, **kwargs)  # Main algorithm run method\n\n        for callback in self._callbacks:\n            callback.post_execute(result, *args, **kwargs)  # Post-execution hook\n\n        return result"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        # Add the implementation of the execute method here\n        # This is where the main algorithm logic should be executed\n        pass"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(*args, **kwargs)\n        \n        result = self.run(*args, **kwargs)\n        \n        for callback in self._callbacks:\n            callback.post_execute(result, *args, **kwargs)\n        \n        return result"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(*args, **kwargs)\n        \n        result = self.run(*args, **kwargs)\n        \n        for callback in self._callbacks:\n            callback.post_execute(result, *args, **kwargs)\n        \n        return result"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        # Add the implementation of the execute method here\n        pass"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n            return self.check_type(deserialized_output, type_definition)\n        except (json.JSONDecodeError, TypeError):\n            return False"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "\n        try:\n            deserialized_output = json.loads(output)\n            return self.check_type(deserialized_output, type_definition)\n        except (json.JSONDecodeError, TypeError):\n            return False"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n            return self.check_type(deserialized_output, type_definition)\n        except json.JSONDecodeError:\n            return False"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n            return self.check_type(deserialized_output, type_definition)\n        except (json.JSONDecodeError, TypeError):\n            return False"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n            return self.check_type(deserialized_output, type_definition)\n        except (json.JSONDecodeError, TypeError):\n            return False"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "\n        try:\n            deserialized_output = json.loads(output)\n            return self.check_type(deserialized_output, type_definition)\n        except (json.JSONDecodeError, TypeError):\n            return False"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n            return self.check_type(deserialized_output, type_definition)\n        except (json.JSONDecodeError, TypeError):\n            return False"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "\n        try:\n            deserialized_output = json.loads(output)\n            return self.check_type(deserialized_output, type_definition)\n        except json.JSONDecodeError:\n            return False"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "\n        try:\n            deserialized_output = json.loads(output)\n            return self.check_type(deserialized_output, type_definition)\n        except (json.JSONDecodeError, TypeError):\n            return False"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "\n        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "\n        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n            return self.check_type(deserialized_output, type_definition)\n        except (json.JSONDecodeError, TypeError):\n            return False"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n            return self.check_type(deserialized_output, type_definition)\n        except (json.JSONDecodeError, TypeError):\n            return False"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n            return self.check_type(deserialized_output, type_definition)\n        except (json.JSONDecodeError, TypeError):\n            return False"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n            return self.check_type(deserialized_output, type_definition)\n        except (json.JSONDecodeError, TypeError):\n            return False"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n            return self.check_type(deserialized_output, type_definition)\n        except json.JSONDecodeError:\n            return False"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "\n        try:\n            deserialized_output = json.loads(output)\n            return self.check_type(deserialized_output, type_definition)\n        except (json.JSONDecodeError, TypeError):\n            return False"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n            return self.check_type(deserialized_output, type_definition)\n        except json.JSONDecodeError:\n            return False"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)"}
{"namespace": "tanuki.utils.encode_int", "completion": "    charset = string.ascii_lowercase + string.digits + \"_\"\n\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\"\n\n    return charset[n]"}
{"namespace": "tanuki.utils.encode_int", "completion": "    charset = string.ascii_lowercase + string.digits + \"_\"\n\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\"\n    return charset[n]"}
{"namespace": "tanuki.utils.encode_int", "completion": "    charset = string.ascii_lowercase + string.digits + \"_\"\n\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\"\n    return charset[n]"}
{"namespace": "tanuki.utils.encode_int", "completion": "    charset = string.ascii_lowercase + string.digits + \"_\"\n\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\"\n\n    return charset[n]"}
{"namespace": "tanuki.utils.encode_int", "completion": "    charset = string.ascii_lowercase + string.digits + \"_\"\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\"\n    return charset[n]"}
{"namespace": "tanuki.utils.encode_int", "completion": "    charset = string.ascii_lowercase + string.digits + \"_\"\n\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\"\n\n    return charset[n]"}
{"namespace": "tanuki.utils.encode_int", "completion": "    charset = string.ascii_lowercase + string.digits + \"_\"\n\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\"\n    return charset[n]"}
{"namespace": "tanuki.utils.encode_int", "completion": "    charset = string.ascii_lowercase + string.digits + \"_\"\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\"\n    return charset[n]"}
{"namespace": "tanuki.utils.encode_int", "completion": "    charset = string.ascii_lowercase + string.digits + \"_\"\n\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\"\n    return charset[n]"}
{"namespace": "tanuki.utils.encode_int", "completion": "    charset = string.ascii_lowercase + string.digits + \"_\"\n\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\"\n\n    return charset[n]"}
{"namespace": "tanuki.utils.encode_int", "completion": "    charset = string.ascii_lowercase + string.digits + \"_\"\n\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\"\n    return charset[n]"}
{"namespace": "tanuki.utils.encode_int", "completion": "    charset = string.ascii_lowercase + string.digits + \"_\"\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\"\n    return charset[n]"}
{"namespace": "tanuki.utils.encode_int", "completion": "    charset = string.ascii_lowercase + string.digits + \"_\"\n\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\"\n\n    return charset[n]"}
{"namespace": "tanuki.utils.encode_int", "completion": "    charset = string.ascii_lowercase + string.digits + \"_\"\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\"\n    return charset[n]"}
{"namespace": "tanuki.utils.encode_int", "completion": "    charset = string.ascii_lowercase + string.digits + \"_\"\n\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\"\n    return charset[n]"}
{"namespace": "tanuki.utils.encode_int", "completion": "    charset = string.ascii_lowercase + string.digits + \"_\"\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\"\n    return charset[n]"}
{"namespace": "tanuki.utils.encode_int", "completion": "    charset = string.ascii_lowercase + string.digits + \"_\"\n\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\"\n\n    return charset[n]"}
{"namespace": "tanuki.utils.encode_int", "completion": "    charset = string.ascii_lowercase + string.digits + \"_\"\n\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\"\n\n    return charset[n]"}
{"namespace": "tanuki.utils.encode_int", "completion": "    charset = string.ascii_lowercase + string.digits + \"_\"\n\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\"\n\n    return charset[n]"}
{"namespace": "tanuki.utils.encode_int", "completion": "    charset = string.ascii_lowercase + string.digits + \"_\"\n\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\"\n\n    return charset[n]"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        name = func_object.__name__\n        docstring = func_object.__doc__\n\n        parameters = signature.parameters\n        input_type_hints = [type_hints[param.annotation] if param.annotation != inspect.Parameter.empty else None for param in parameters.values()]\n\n        output_type_hint = type_hints.get('return')\n        output_class_definition = get_class_definition(output_type_hint)\n\n        function_type = FunctionType.SYMBOLIC if output_class_definition == Embedding else FunctionType.EMBEDDABLE\n\n        return FunctionDescription(name, docstring, input_type_hints, output_class_definition, function_type)"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "\n        signature = inspect.signature(func_object)\n        hints = get_type_hints(func_object)\n        name = func_object.__name__\n        docstring = inspect.getdoc(func_object)\n\n        input_type_hints = []\n        output_type_hints = None\n\n        for param in signature.parameters.values():\n            if param.annotation != inspect.Parameter.empty:\n                input_type_hints.append(get_class_definition(param.annotation))\n\n        if signature.return_annotation != inspect.Parameter.empty:\n            output_type_hints = get_class_definition(signature.return_annotation)\n\n        function_type = FunctionType.SYMBOLIC if output_type_hints is None else FunctionType.EMBEDDABLE\n\n        return FunctionDescription(name, docstring, input_type_hints, output_type_hints, function_type)"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        \n        input_type_hints = []\n        output_type_hints = None\n        \n        for param in signature.parameters.values():\n            if param.annotation != param.empty:\n                input_type_hints.append(param.annotation)\n        \n        if 'return' in type_hints:\n            output_type_hints = type_hints['return']\n        \n        input_class_definitions = [get_class_definition(type_hint) for type_hint in input_type_hints]\n        output_class_definition = get_class_definition(output_type_hints)\n        \n        function_type = FunctionType.SYMBOLIC if output_type_hints and issubclass(output_type_hints, Embedding) else FunctionType.EMBEDDABLE\n        \n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=func_object.__doc__,\n            input_type_hints=input_type_hints,\n            output_type_hints=output_type_hints,\n            input_class_definitions=input_class_definitions,\n            output_class_definition=output_class_definition,\n            type=function_type\n        )"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "\n        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        docstring = func_object.__doc__\n\n        # Extract function name\n        function_name = func_object.__name__\n\n        # Extract input and output type hints\n        input_type_hints = [type_hints[param.name] for param in signature.parameters.values()]\n        output_type_hint = type_hints.get('return', None)\n\n        # Get class definitions for input and output type hints\n        input_class_definitions = [get_class_definition(type_hint) for type_hint in input_type_hints]\n        output_class_definition = get_class_definition(output_type_hint)\n\n        # Determine function type based on output type hint\n        function_type = FunctionType.SYMBOLIC if output_class_definition == Embedding else FunctionType.EMBEDDABLE\n\n        # Create FunctionDescription instance\n        function_description = FunctionDescription(\n            name=function_name,\n            docstring=docstring,\n            input_type_hints=input_type_hints,\n            output_type_hint=output_type_hint,\n            input_class_definitions=input_class_definitions,\n            output_class_definition=output_class_definition,\n            function_type=function_type\n        )\n\n        return function_description"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        docstring = inspect.getdoc(func_object)\n        type_hints = get_type_hints(func_object)\n\n        parameters = list(signature.parameters.values())\n        input_type_hints = [type_hints[param.annotation] for param in parameters if param.annotation != inspect.Parameter.empty]\n        output_type_hint = type_hints.get('return', None)\n\n        input_class_definitions = [get_class_definition(hint) for hint in input_type_hints]\n        output_class_definition = get_class_definition(output_type_hint) if output_type_hint else None\n\n        function_type = FunctionType.SYMBOLIC if output_type_hint and (get_origin(output_type_hint) == Union or issubclass(output_type_hint, Embedding)) else FunctionType.EMBEDDABLE\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=docstring,\n            input_type_hints=input_type_hints,\n            output_type_hint=output_type_hint,\n            input_class_definitions=input_class_definitions,\n            output_class_definition=output_class_definition,\n            type=function_type\n        )"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        name = func_object.__name__\n        docstring = func_object.__doc__\n        \n        # Extract input and output type hints\n        input_type_hints = list(signature.parameters.values())[0].annotation\n        output_type_hint = signature.return_annotation\n        \n        # Get class definitions for input and output types\n        input_class = get_class_definition(input_type_hints)\n        output_class = get_class_definition(output_type_hint)\n        \n        # Determine function type based on output type hint\n        function_type = FunctionType.SYMBOLIC if get_origin(output_type_hint) == Union else FunctionType.EMBEDDABLE\n        \n        return FunctionDescription(name, docstring, input_type_hints, output_type_hint, input_class, output_class, function_type)"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        name = func_object.__name__\n        docstring = func_object.__doc__\n        input_type_hints = [type_hints[param] for param in signature.parameters]\n        output_type_hint = type_hints.get('return')\n\n        input_class_definitions = [get_class_definition(param) for param in input_type_hints]\n        output_class_definition = get_class_definition(output_type_hint)\n\n        function_type = FunctionType.SYMBOLIC if output_type_hint.__class__.__name__ == 'Embedding' else FunctionType.EMBEDDABLE\n\n        return FunctionDescription(name, docstring, input_type_hints, output_type_hint, input_class_definitions, output_class_definition, function_type)"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        docstring = inspect.getdoc(func_object)\n\n        input_type_hints = {}\n        output_type_hints = None\n\n        for param in signature.parameters.values():\n            if param.annotation != inspect.Parameter.empty:\n                input_type_hints[param.name] = get_class_definition(param.annotation)\n\n        if signature.return_annotation != inspect.Parameter.empty:\n            output_type_hints = get_class_definition(signature.return_annotation)\n\n        function_type = determine_function_type(output_type_hints)\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=docstring,\n            input_type_hints=input_type_hints,\n            output_type_hints=output_type_hints,\n            function_type=function_type\n        )"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "\n        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        name = func_object.__name__\n        doc = func_object.__doc__\n        params = signature.parameters\n\n        input_type_hints = {}\n        output_type_hints = None\n\n        for param in params.values():\n            if param.annotation != inspect.Parameter.empty:\n                if param.default != inspect.Parameter.empty:\n                    input_type_hints[param.name] = (param.annotation, param.default)\n                else:\n                    input_type_hints[param.name] = param.annotation\n\n        if 'return' in type_hints:\n            output_type_hints = type_hints['return']\n\n        input_class_definitions = {param: get_class_definition(param_type) for param, param_type in input_type_hints.items()}\n        output_class_definition = get_class_definition(output_type_hints)\n\n        function_type = FunctionType.SYMBOLIC if isinstance(output_type_hints, type) and issubclass(output_type_hints, Embedding) else FunctionType.EMBEDDABLE\n\n        return FunctionDescription(name, doc, input_type_hints, input_class_definitions, output_type_hints, output_class_definition, function_type)"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n\n        # Extract function name and docstring\n        function_name = func_object.__name__\n        docstring = inspect.getdoc(func_object)\n\n        # Extract input and output type hints\n        input_type_hints = list(signature.parameters.values())[0].annotation\n        output_type_hint = signature.return_annotation\n\n        # Get class definitions for input and output types\n        input_class_definition = get_class_definition(input_type_hints)\n        output_class_definition = get_class_definition(output_type_hint)\n\n        # Determine function type based on output type hint\n        function_type = FunctionType.SYMBOLIC if get_origin(output_type_hint) is None else FunctionType.EMBEDDABLE\n\n        return FunctionDescription(\n            name=function_name,\n            docstring=docstring,\n            input_type_hints=input_type_hints,\n            output_type_hint=output_type_hint,\n            input_class_definition=input_class_definition,\n            output_class_definition=output_class_definition,\n            function_type=function_type\n        )"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "\n        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n\n        input_type_hints = [type_hints[param] for param in signature.parameters if param in type_hints]\n        output_type_hint = type_hints.get('return')\n\n        input_class_definitions = [get_class_definition(param) for param in input_type_hints]\n        output_class_definition = get_class_definition(output_type_hint)\n\n        function_name = func_object.__name__\n        docstring = func_object.__doc__\n\n        if output_type_hint and (inspect.isclass(output_type_hint) or get_origin(output_type_hint) == Union):\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        return FunctionDescription(\n            function_name=function_name,\n            docstring=docstring,\n            input_type_hints=input_type_hints,\n            output_type_hint=output_type_hint,\n            input_class_definitions=input_class_definitions,\n            output_class_definition=output_class_definition,\n            function_type=function_type\n        )"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        sig = inspect.signature(func_object)\n        hints = get_type_hints(func_object)\n        name = func_object.__name__\n        docstring = func_object.__doc__\n        params = sig.parameters\n        input_type_hints = {param: hints[param] for param in params if param in hints}\n        output_type_hint = hints.get('return')\n\n        input_class_definitions = {param: get_class_definition(hint) for param, hint in input_type_hints.items()}\n        output_class_definition = get_class_definition(output_type_hint)\n\n        function_type = FunctionType.EMBEDDABLE if output_class_definition == Embedding else FunctionType.SYMBOLIC\n\n        return FunctionDescription(name, docstring, input_type_hints, output_type_hint, input_class_definitions, output_class_definition, function_type)"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "\n        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n\n        # Extract function name\n        function_name = func_object.__name__\n\n        # Extract docstring\n        docstring = inspect.getdoc(func_object)\n\n        # Extract input and output type hints\n        input_type_hints = list(signature.parameters.values())[0]\n        output_type_hint = signature.return_annotation\n\n        # Get class definitions for input and output types\n        input_class_definition = get_class_definition(input_type_hints)\n        output_class_definition = get_class_definition(output_type_hint)\n\n        # Determine function type based on output type hint\n        function_type = FunctionType.SYMBOLIC if get_origin(output_type_hint) is None else FunctionType.EMBEDDABLE\n\n        return FunctionDescription(\n            function_name=function_name,\n            docstring=docstring,\n            input_type_hints=input_type_hints,\n            output_type_hint=output_type_hint,\n            input_class_definition=input_class_definition,\n            output_class_definition=output_class_definition,\n            function_type=function_type\n        )"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "\n        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        name = func_object.__name__\n        docstring = func_object.__doc__\n\n        input_type_hints = []\n        output_type_hints = None\n\n        for param in signature.parameters.values():\n            if param.annotation != inspect.Parameter.empty:\n                input_type_hints.append(get_class_definition(param.annotation))\n\n        if signature.return_annotation != inspect.Parameter.empty:\n            output_type_hints = get_class_definition(signature.return_annotation)\n\n        function_type = FunctionType.SYMBOLIC  # Default to SYMBOLIC\n        if output_type_hints:\n            if isinstance(output_type_hints, type) and issubclass(output_type_hints, Embedding):\n                function_type = FunctionType.EMBEDDABLE\n            elif get_origin(output_type_hints) == Union:\n                for union_type in get_args(output_type_hints):\n                    if isinstance(union_type, type) and issubclass(union_type, Embedding):\n                        function_type = FunctionType.EMBEDDABLE\n                        output_type_hints = union_type\n                        break\n\n        return FunctionDescription(name, docstring, input_type_hints, output_type_hints, function_type)"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Implementation of the function will go here"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        hints = get_type_hints(func_object)\n        name = func_object.__name__\n        docstring = inspect.getdoc(func_object)\n        parameters = signature.parameters\n        input_type_hints = {}\n        output_type_hint = None\n\n        for param_name, param in parameters.items():\n            if param_name != 'self':\n                if param.annotation != inspect.Parameter.empty:\n                    input_type_hints[param_name] = get_class_definition(hints[param_name])\n\n        for param_name, param in parameters.items():\n            if param.default == inspect.Parameter.empty:\n                output_type_hint = hints[param_name]\n\n        output_class_definition = get_class_definition(output_type_hint)\n        function_type = FunctionType.SYMBOLIC if get_origin(output_type_hint) == Literal else FunctionType.EMBEDDABLE\n        return FunctionDescription(name, docstring, input_type_hints, output_class_definition, function_type)"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n\n        input_type_hints = []\n        output_type_hints = None\n\n        for param in signature.parameters.values():\n            if param.annotation != inspect.Parameter.empty:\n                input_type_hints.append(param.annotation)\n\n        if 'return' in type_hints:\n            output_type_hints = type_hints['return']\n\n        input_class_definitions = [get_class_definition(t) for t in input_type_hints]\n        output_class_definition = get_class_definition(output_type_hints)\n\n        function_type = FunctionType.SYMBOLIC\n\n        if output_type_hints:\n            if inspect.isclass(output_type_hints):\n                if issubclass(output_type_hints, Embedding):\n                    function_type = FunctionType.EMBEDDABLE\n            elif get_origin(output_type_hints) == Union:\n                for type_arg in get_type_hints(output_type_hints):\n                    if inspect.isclass(type_arg) and issubclass(type_arg, Embedding):\n                        function_type = FunctionType.EMBEDDABLE\n                        output_class_definition = get_class_definition(type_arg)\n                        break\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=func_object.__doc__,\n            input_type_hints=input_type_hints,\n            output_type_hints=output_type_hints,\n            input_class_definitions=input_class_definitions,\n            output_class_definition=output_class_definition,\n            type=function_type\n        )"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        hints = get_type_hints(func_object)\n        docstring = inspect.getdoc(func_object)\n\n        input_type_hints = []\n        output_type_hints = None\n\n        for param in signature.parameters.values():\n            if param.annotation != inspect.Parameter.empty:\n                input_type_hints.append((param.name, get_class_definition(param.annotation)))\n\n        if signature.return_annotation != inspect.Parameter.empty:\n            output_type_hints = get_class_definition(signature.return_annotation)\n\n        function_type = FunctionType.SYMBOLIC if output_type_hints is None else FunctionType.EMBEDDABLE\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=docstring,\n            input_type_hints=input_type_hints,\n            output_type_hints=output_type_hints,\n            function_type=function_type\n        )"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        name = func_object.__name__\n        docstring = func_object.__doc__\n        \n        input_type_hints = []\n        output_type_hints = None\n        \n        for param in signature.parameters.values():\n            if param.annotation != param.empty:\n                if param.name != 'return':\n                    input_type_hints.append((param.name, get_class_definition(param.annotation)))\n                else:\n                    output_type_hints = param.annotation\n        \n        output_class_definition = get_class_definition(output_type_hints)\n        \n        function_type = FunctionType.SYMBOLIC if get_origin(output_type_hints) == Embedding else FunctionType.EMBEDDABLE\n        \n        return FunctionDescription(name, docstring, input_type_hints, output_type_hints, input_class_definitions, output_class_definition, function_type)"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        docstring = inspect.getdoc(func_object)\n        func_name = func_object.__name__\n\n        parameters = signature.parameters\n        input_type_hints = [type_hints[param.annotation] if param.annotation != inspect._empty else Any for param in parameters.values()]\n        output_type_hint = type_hints['return'] if 'return' in type_hints else Any\n\n        input_class_definitions = [get_class_definition(hint) for hint in input_type_hints]\n        output_class_definition = get_class_definition(output_type_hint)\n\n        if inspect.isclass(output_type_hint) or (isinstance(output_type_hint, type) and issubclass(output_type_hint, Union)):\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        return FunctionDescription(func_name, docstring, input_type_hints, output_type_hint, input_class_definitions, output_class_definition, function_type)"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "\n        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "\n        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "\n        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "\n        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "\n        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "\n        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Mismatch in loaded bit array length. Reinitializing bit array and indices.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Mismatch in loaded bit array length. Reinitializing bit array and indices.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Mismatch in loaded bit array length and expected length. Reinitializing bit array and indices.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Loaded bit array length does not match expected length. Reinitializing bit array.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Loaded bit array length does not match the expected length. Reinitializing bit array and indices.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Mismatch in loaded bit array length and expected length. Reinitializing bit array and indices.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Mismatch in bit array length. Reinitializing bit array and indices.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Loaded bit array length does not match expected length. Reinitializing...\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Mismatch between loaded bit array length and expected length. Reinitializing bit array and indices.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Mismatch in bit array length. Reinitializing bit array and indices.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Mismatch in loaded bit array length. Reinitializing and saving new state.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Mismatch in loaded bit array length. Reinitializing bit array and indices.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Loaded bit array length does not match expected length. Reinitializing and saving new state.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Mismatch in loaded bit array length. Reinitializing bit array and indices.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Loaded bit array length does not match expected length. Reinitializing bit array.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Mismatch in loaded bit array length and expected length. Reinitializing bit array and indices.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        expected_length = self.size\n        if len(loaded_bit_array) != expected_length:\n            logging.warning(\"Loaded bit array length does not match expected length. Reinitializing bit array.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Loaded bit array length does not match expected length. Reinitializing bit array and indices.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Mismatch between loaded bit array length and expected length. Reinitializing bit array and indices.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Mismatch in bit array length. Reinitializing bit array and indices.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            if not self.bit_array[index]:\n                return False\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            if self.bit_array[index] == 0:\n                return False\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            if not self.bit_array[index]:\n                return False\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            if self.bit_array[index] == 0:\n                return False\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            if not self.bit_array[index]:\n                return False\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            if not self.bit_array[index]:\n                return False\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            if not self.bit_array[index]:\n                return False\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            if self.bit_array[index] == 0:\n                return False\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            if not self.bit_array[index]:\n                return False\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            if not self.bit_array[index]:\n                return False\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            if not self.bit_array[index]:\n                return False\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            if not self.bit_array[index]:\n                return False\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            if not self.bit_array[index]:\n                return False\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            if not self.bit_array[index]:\n                return False\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            if not self.bit_array[index]:\n                return False\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            if not self.bit_array[index]:\n                return False\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            if not self.bit_array[index]:\n                return False\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            if not self.bit_array[index]:\n                return False\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            if not self.bit_array[index]:\n                return False\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            if not self.bit_array[index]:\n                return False\n        return True"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = np.random.dirichlet(np.ones(n))\n    if zeros > 0:\n        zero_indices = np.random.choice(range(n), zeros, replace=False)\n        weights[zero_indices] = 0\n        weights = weights / np.sum(weights)  # Normalize weights to sum to one\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = rand_weights_dirichlet(n)\n    if zeros > 0:\n        zero_indices = np.random.choice(range(n), zeros, replace=False)\n        weights[zero_indices] = 0\n        weights /= np.sum(weights)\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = np.random.dirichlet(np.ones(n))\n    if zeros > 0:\n        zero_indices = np.random.choice(range(n), zeros, replace=False)\n        weights[zero_indices] = 0\n        weights /= np.sum(weights)  # Normalize weights to ensure they sum up to one\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = rand_weights_dirichlet(n)\n    if zeros > 0:\n        idx = np.random.choice(range(n), zeros, replace=False)\n        weights[idx] = 0\n        weights = weights / np.sum(weights)  # Renormalize the weights\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = np.random.dirichlet(np.ones(n))\n    if zeros > 0:\n        zero_indices = np.random.choice(range(n), zeros, replace=False)\n        weights[zero_indices] = 0\n        weights = weights / np.sum(weights)  # Re-normalize weights to sum to one\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = np.random.dirichlet(np.ones(n))\n    if zeros > 0:\n        zero_indices = np.random.choice(range(n), zeros, replace=False)\n        weights[zero_indices] = 0\n        weights /= np.sum(weights)  # Re-normalize after setting some weights to zero\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zeros cannot exceed the total number of weights\")\n    weights = np.random.dirichlet(np.ones(n))\n    if zeros > 0:\n        zero_indices = np.random.choice(range(n), zeros, replace=False)\n        weights[zero_indices] = 0\n        weights /= np.sum(weights)  # Normalize the weights to ensure they sum up to one\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = np.random.dirichlet(np.ones(n))\n    if zeros > 0:\n        zero_indices = np.random.choice(range(n), zeros, replace=False)\n        weights[zero_indices] = 0\n        weights /= np.sum(weights)  # Normalize the weights\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = rand_weights_dirichlet(n)\n    if zeros > 0:\n        zero_indices = np.random.choice(range(n), zeros, replace=False)\n        weights[zero_indices] = 0\n        weights = weights / np.sum(weights)  # Normalize weights to sum up to one\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = np.random.dirichlet(np.ones(n))\n    if zeros > 0:\n        zero_indices = np.random.choice(range(n), zeros, replace=False)\n        weights[zero_indices] = 0\n        weights /= np.sum(weights)  # Normalize the weights to ensure they sum to one\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = rand_weights_dirichlet(n)\n    if zeros > 0:\n        zero_indices = np.random.choice(range(n), zeros, replace=False)\n        weights[zero_indices] = 0\n        weights /= np.sum(weights)  # Normalize weights to sum up to one\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = np.random.dirichlet(np.ones(n))\n    if zeros > 0:\n        zero_indices = np.random.choice(range(n), zeros, replace=False)\n        weights[zero_indices] = 0\n        weights = weights / np.sum(weights)  # Re-normalize after setting zeros\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = np.random.dirichlet(np.ones(n))\n    if zeros > 0:\n        zero_indices = np.random.choice(range(n), zeros, replace=False)\n        weights[zero_indices] = 0\n        weights = weights / np.sum(weights)  # Re-normalize the weights\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = np.random.dirichlet(np.ones(n))\n    if zeros > 0:\n        idx = np.random.choice(range(n), zeros, replace=False)\n        weights[idx] = 0\n        weights = weights / np.sum(weights)  # Renormalize weights to sum to one\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"`zeros` must not exceed `n`\")\n    weights = np.random.dirichlet(np.ones(n))\n    if zeros > 0:\n        zero_indices = np.random.choice(range(n), zeros, replace=False)\n        weights[zero_indices] = 0\n        weights /= np.sum(weights)  # Normalize weights\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = rand_weights_dirichlet(n)\n    if zeros > 0:\n        zero_indices = np.random.choice(range(n), size=zeros, replace=False)\n        weights[zero_indices] = 0\n        weights /= np.sum(weights)  # Renormalize after setting zeros\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = np.random.dirichlet(np.ones(n))\n    if zeros > 0:\n        zero_indices = np.random.choice(range(n), zeros, replace=False)\n        weights[zero_indices] = 0\n        weights /= np.sum(weights)  # Normalize the weights to sum up to one\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = rand_weights_dirichlet(n)\n    if zeros > 0:\n        zero_indices = np.random.choice(range(n), zeros, replace=False)\n        weights[zero_indices] = 0\n        weights /= np.sum(weights)  # Normalize the weights to sum up to one\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = np.random.dirichlet(np.ones(n))\n    if zeros > 0:\n        zero_indices = np.random.choice(n, zeros, replace=False)\n        weights[zero_indices] = 0\n    return weights / np.sum(weights)"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = rand_weights_dirichlet(n)\n    if zeros > 0:\n        zero_indices = np.random.choice(range(n), zeros, replace=False)\n        weights[zero_indices] = 0\n        weights /= np.sum(weights)  # Normalize weights to sum up to one\n    return weights"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        for key, value in json_dict.items():\n            if key == \"distilled_model\":\n                self.distilled_model = config_factory.create_model_config(value)\n            elif key == \"current_model_stats\":\n                self.current_model_stats = value\n            elif key == \"last_training_run\":\n                self.last_training_run = value\n            elif key == \"current_training_run\":\n                self.current_training_run = value\n            elif key == \"nr_of_training_runs\":\n                self.nr_of_training_runs = value\n            elif key == \"teacher_models\":\n                self.teacher_models = [config_factory.create_model_config(teacher_model) for teacher_model in value]\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        for key, value in json_dict.items():\n            if key == \"distilled_model\":\n                self.distilled_model = config_factory.create_model_config(value)\n            elif key == \"current_model_stats\":\n                self.current_model_stats = value\n            elif key == \"last_training_run\":\n                self.last_training_run = value\n            elif key == \"current_training_run\":\n                self.current_training_run = value\n            elif key == \"nr_of_training_runs\":\n                self.nr_of_training_runs = value\n            elif key == \"teacher_models\":\n                self.teacher_models = [config_factory.create_model_config(teacher_model) for teacher_model in value]\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        for key, value in json_dict.items():\n            if key == \"distilled_model\":\n                self.distilled_model = config_factory.create_model_config(value)\n            elif key == \"current_model_stats\":\n                self.current_model_stats = value\n            elif key == \"last_training_run\":\n                self.last_training_run = value\n            elif key == \"current_training_run\":\n                self.current_training_run = value\n            elif key == \"nr_of_training_runs\":\n                self.nr_of_training_runs = value\n            elif key == \"teacher_models\":\n                self.teacher_models = [config_factory.create_model_config(teacher_model) for teacher_model in value]\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        for key, value in json_dict.items():\n            if key == \"distilled_model\":\n                self.distilled_model = config_factory.create_model_config(value)\n            elif key == \"current_model_stats\":\n                self.current_model_stats = value\n            elif key == \"last_training_run\":\n                self.last_training_run = value\n            elif key == \"current_training_run\":\n                self.current_training_run = value\n            elif key == \"nr_of_training_runs\":\n                self.nr_of_training_runs = value\n            elif key == \"teacher_models\":\n                self.teacher_models = [config_factory.create_model_config(teacher_model) for teacher_model in value]\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        for key, value in json_dict.items():\n            if key == \"distilled_model\":\n                self.distilled_model = config_factory.load_from_dict(value)\n            elif key == \"current_model_stats\":\n                self.current_model_stats = value\n            elif key == \"last_training_run\":\n                self.last_training_run = value\n            elif key == \"current_training_run\":\n                self.current_training_run = value\n            elif key == \"nr_of_training_runs\":\n                self.nr_of_training_runs = value\n            elif key == \"teacher_models\":\n                self.teacher_models = [config_factory.load_from_dict(teacher_model) for teacher_model in value]\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        for key, value in json_dict.items():\n            if key == \"distilled_model\":\n                self.distilled_model = config_factory.create_model_config(value)\n            elif key == \"current_model_stats\":\n                self.current_model_stats = value\n            elif key == \"last_training_run\":\n                self.last_training_run = value\n            elif key == \"current_training_run\":\n                self.current_training_run = value\n            elif key == \"nr_of_training_runs\":\n                self.nr_of_training_runs = value\n            elif key == \"teacher_models\":\n                self.teacher_models = [config_factory.create_model_config(teacher_model) for teacher_model in value]\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        for key, value in json_dict.items():\n            if key == \"distilled_model\":\n                self.distilled_model = config_factory.get_model_config(value)\n            elif key == \"current_model_stats\":\n                self.current_model_stats = value\n            elif key == \"last_training_run\":\n                self.last_training_run = value\n            elif key == \"current_training_run\":\n                self.current_training_run = value\n            elif key == \"nr_of_training_runs\":\n                self.nr_of_training_runs = value\n            elif key == \"teacher_models\":\n                self.teacher_models = [config_factory.get_model_config(model) for model in value]\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        for key, value in json_dict.items():\n            if key == \"distilled_model\":\n                self.distilled_model = config_factory.create_model_config(value)\n            elif key == \"current_model_stats\":\n                self.current_model_stats = value\n            elif key == \"last_training_run\":\n                self.last_training_run = value\n            elif key == \"current_training_run\":\n                self.current_training_run = value\n            elif key == \"nr_of_training_runs\":\n                self.nr_of_training_runs = value\n            elif key == \"teacher_models\":\n                self.teacher_models = [config_factory.create_model_config(teacher_model) for teacher_model in value]\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.create_model_config(json_dict.get(\"distilled_model\"))\n        self.current_model_stats = json_dict.get(\"current_model_stats\", {\n            \"trained_on_datapoints\": 0,\n            \"running_faults\": []\n        })\n        self.last_training_run = json_dict.get(\"last_training_run\", {\"trained_on_datapoints\": 0})\n        self.current_training_run = json_dict.get(\"current_training_run\", {})\n        self.nr_of_training_runs = json_dict.get(\"nr_of_training_runs\", 0)\n        teacher_models = json_dict.get(\"teacher_models\")\n        if teacher_models:\n            self.teacher_models = [config_factory.create_model_config(teacher_model) for teacher_model in teacher_models]"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if \"distilled_model\" in json_dict:\n            self.distilled_model = config_factory.create_model_config(json_dict[\"distilled_model\"])\n        if \"current_model_stats\" in json_dict:\n            self.current_model_stats = json_dict[\"current_model_stats\"]\n        if \"last_training_run\" in json_dict:\n            self.last_training_run = json_dict[\"last_training_run\"]\n        if \"current_training_run\" in json_dict:\n            self.current_training_run = json_dict[\"current_training_run\"]\n        if \"nr_of_training_runs\" in json_dict:\n            self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.create_model_config(teacher_model) for teacher_model in json_dict[\"teacher_models\"]]\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        for key, value in json_dict.items():\n            if key == \"distilled_model\":\n                self.distilled_model = config_factory.create_model_config(value)\n            elif key == \"current_model_stats\":\n                self.current_model_stats = value\n            elif key == \"last_training_run\":\n                self.last_training_run = value\n            elif key == \"current_training_run\":\n                self.current_training_run = value\n            elif key == \"nr_of_training_runs\":\n                self.nr_of_training_runs = value\n            elif key == \"teacher_models\":\n                self.teacher_models = [config_factory.create_model_config(teacher_model) for teacher_model in value]\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        for key, value in json_dict.items():\n            if key == \"distilled_model\":\n                self.distilled_model = config_factory.create_model_config(value)\n            elif key == \"current_model_stats\":\n                self.current_model_stats = value\n            elif key == \"last_training_run\":\n                self.last_training_run = value\n            elif key == \"current_training_run\":\n                self.current_training_run = value\n            elif key == \"nr_of_training_runs\":\n                self.nr_of_training_runs = value\n            elif key == \"teacher_models\":\n                self.teacher_models = [config_factory.create_model_config(teacher_model) for teacher_model in value]\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        for key, value in json_dict.items():\n            if hasattr(self, key):\n                setattr(self, key, value)\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        for key, value in json_dict.items():\n            if key == \"distilled_model\":\n                self.distilled_model = config_factory.create_model_config(value)\n            elif key == \"current_model_stats\":\n                self.current_model_stats = value\n            elif key == \"last_training_run\":\n                self.last_training_run = value\n            elif key == \"current_training_run\":\n                self.current_training_run = value\n            elif key == \"nr_of_training_runs\":\n                self.nr_of_training_runs = value\n            elif key == \"teacher_models\":\n                self.teacher_models = [config_factory.create_model_config(teacher_model) for teacher_model in value]\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        for key, value in json_dict.items():\n            if key == \"distilled_model\":\n                self.distilled_model = config_factory.create_model_config(value)\n            elif key == \"current_model_stats\":\n                self.current_model_stats = value\n            elif key == \"last_training_run\":\n                self.last_training_run = value\n            elif key == \"current_training_run\":\n                self.current_training_run = value\n            elif key == \"nr_of_training_runs\":\n                self.nr_of_training_runs = value\n            elif key == \"teacher_models\":\n                self.teacher_models = [config_factory.create_model_config(teacher_model) for teacher_model in value]\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        for key, value in json_dict.items():\n            if key == \"distilled_model\":\n                self.distilled_model = config_factory.create_model_config(value)\n            elif key == \"current_model_stats\":\n                self.current_model_stats = value\n            elif key == \"last_training_run\":\n                self.last_training_run = value\n            elif key == \"current_training_run\":\n                self.current_training_run = value\n            elif key == \"nr_of_training_runs\":\n                self.nr_of_training_runs = value\n            elif key == \"teacher_models\":\n                self.teacher_models = [config_factory.create_model_config(teacher_model) for teacher_model in value]\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        for key, value in json_dict.items():\n            if key == \"distilled_model\":\n                self.distilled_model = config_factory.get_config(value)\n            elif key == \"current_model_stats\":\n                self.current_model_stats = value\n            elif key == \"last_training_run\":\n                self.last_training_run = value\n            elif key == \"current_training_run\":\n                self.current_training_run = value\n            elif key == \"nr_of_training_runs\":\n                self.nr_of_training_runs = value\n            elif key == \"teacher_models\":\n                self.teacher_models = [config_factory.get_config(teacher_model) for teacher_model in value]\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        for key, value in json_dict.items():\n            if key == \"distilled_model\":\n                self.distilled_model = config_factory.create_model_config(value)\n            elif key == \"current_model_stats\":\n                self.current_model_stats = value\n            elif key == \"last_training_run\":\n                self.last_training_run = value\n            elif key == \"current_training_run\":\n                self.current_training_run = value\n            elif key == \"nr_of_training_runs\":\n                self.nr_of_training_runs = value\n            elif key == \"teacher_models\":\n                self.teacher_models = [config_factory.create_model_config(model) for model in value]\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        for key, value in json_dict.items():\n            if key == \"distilled_model\":\n                self.distilled_model = config_factory.get_model_config(value)\n            elif key == \"current_model_stats\":\n                self.current_model_stats = value\n            elif key == \"last_training_run\":\n                self.last_training_run = value\n            elif key == \"current_training_run\":\n                self.current_training_run = value\n            elif key == \"nr_of_training_runs\":\n                self.nr_of_training_runs = value\n            elif key == \"teacher_models\":\n                self.teacher_models = [config_factory.get_model_config(teacher_model) for teacher_model in value]\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        for key, value in json_dict.items():\n            if hasattr(self, key):\n                setattr(self, key, value)\n        return self"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        try:\n            response = requests.post(\n                OPENAI_URL,\n                headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n                json={\n                    \"model\": model.model_name,\n                    \"messages\": [\n                        {\"role\": \"system\", \"content\": system_message},\n                        {\"role\": \"user\", \"content\": prompt}\n                    ],\n                    **kwargs\n                }\n            )\n\n            response.raise_for_status()\n\n            data = response.json()\n            generated_text = data[\"choices\"][0][\"message\"][\"content\"]\n            return generated_text\n        except Exception as e:\n            logging.error(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        try:\n            response = requests.post(\n                OPENAI_URL,\n                headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n                json={\n                    \"model\": model.model_name,\n                    \"messages\": [\n                        {\"role\": \"system\", \"content\": system_message},\n                        {\"role\": \"user\", \"content\": prompt}\n                    ],\n                    **kwargs\n                }\n            )\n            response.raise_for_status()\n            data = response.json()\n            generated_text = data[\"choices\"][0][\"message\"][\"content\"]\n            return generated_text\n        except requests.exceptions.RequestException as e:\n            print(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        try:\n            response = self.client.completions.create(\n                model=model.model_name,\n                messages=[{\"role\": \"system\", \"content\": system_message}, {\"role\": \"user\", \"content\": prompt}],\n                **kwargs\n            )\n            assert response.object == \"list\"\n            assert len(response.data) == 1\n            generated_text = response.data[0].text.strip()\n            return generated_text\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        try:\n            response = requests.post(\n                OPENAI_URL,\n                headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n                json={\n                    \"model\": model.model_name,\n                    \"messages\": [\n                        {\"role\": \"system\", \"content\": system_message},\n                        {\"role\": \"user\", \"content\": prompt},\n                    ],\n                    **kwargs\n                },\n            )\n            response.raise_for_status()\n            data = response.json()\n            generated_text = data[\"choices\"][0][\"message\"][\"content\"]\n            return generated_text\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        try:\n            response = requests.post(OPENAI_URL, \n                                     headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n                                     json={\n                                         \"model\": model.model_name,\n                                         \"messages\": [\n                                             {\"role\": \"system\", \"content\": system_message},\n                                             {\"role\": \"user\", \"content\": prompt}\n                                         ],\n                                         **kwargs\n                                     })\n            response.raise_for_status()\n            response_data = response.json()\n            generated_text = response_data[\"choices\"][0][\"message\"][\"content\"]\n            return generated_text\n        except requests.exceptions.RequestException as e:\n            logging.error(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        try:\n            response = requests.post(\n                OPENAI_URL,\n                headers={\n                    \"Authorization\": f\"Bearer {self.api_key}\",\n                    \"Content-Type\": \"application/json\"\n                },\n                json={\n                    \"model\": model.model_name,\n                    \"system_message\": system_message,\n                    \"prompt\": prompt,\n                    **kwargs\n                }\n            )\n            response.raise_for_status()\n            data = response.json()\n            generated_text = data['choices'][0]['text']\n            return generated_text\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        try:\n            response = requests.post(\n                OPENAI_URL,\n                headers={\n                    \"Authorization\": f\"Bearer {self.api_key}\",\n                    \"Content-Type\": \"application/json\"\n                },\n                json={\n                    \"model\": model.model_name,\n                    \"messages\": [\n                        {\n                            \"role\": \"system\",\n                            \"content\": system_message\n                        },\n                        {\n                            \"role\": \"user\",\n                            \"content\": prompt\n                        }\n                    ],\n                    **kwargs\n                }\n            )\n            response.raise_for_status()\n            response_json = response.json()\n            generated_text = response_json[\"choices\"][0][\"message\"][\"content\"]\n            return generated_text\n        except requests.exceptions.RequestException as e:\n            print(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        try:\n            response = self.client.completions.create(\n                model=model.model_name,\n                messages=[{\"role\": \"system\", \"content\": system_message}, {\"role\": \"user\", \"content\": prompt}],\n                **kwargs\n            )\n            generated_text = response.choices[0].text.strip()\n            return generated_text\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n        params = {\n            \"model\": model.model_name,\n            \"system_message\": system_message,\n            \"prompt\": prompt,\n            **kwargs\n        }\n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        retries = 5\n        backoff_time = 1\n        for _ in range(retries):\n            response = requests.post(OPENAI_URL, headers=headers, json=params)\n            if response.status_code == 200:\n                generated_text = response.json()[\"choices\"][0][\"text\"]\n                # Remove any parsing helper tokens\n                # (if any) from the generated text\n                return generated_text\n            else:\n                time.sleep(backoff_time)\n                backoff_time *= 2\n        return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        try:\n            response = self.client.completions.create(\n                model=model.model_name,\n                messages=[{\"role\": \"system\", \"content\": system_message}, {\"role\": \"user\", \"content\": prompt}],\n                **kwargs\n            )\n            generated_text = response.choices[0].text.strip()\n            return generated_text\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        try:\n            response = requests.post(\n                OPENAI_URL,\n                headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n                json={\n                    \"model\": model.model_name,\n                    \"messages\": [\n                        {\"role\": \"system\", \"content\": system_message},\n                        {\"role\": \"user\", \"content\": prompt}\n                    ],\n                    **kwargs\n                }\n            )\n            response.raise_for_status()\n            data = response.json()\n            generated_text = data[\"choices\"][0][\"message\"][\"content\"]\n            return generated_text\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        try:\n            response = requests.post(OPENAI_URL, headers={\"Authorization\": f\"Bearer {self.api_key}\"}, json={\n                \"model\": model.model_name,\n                \"messages\": [\n                    {\"role\": \"system\", \"content\": system_message},\n                    {\"role\": \"user\", \"content\": prompt}\n                ],\n                **kwargs\n            })\n            response.raise_for_status()\n            response_json = response.json()\n            generated_text = response_json[\"choices\"][0][\"message\"][\"content\"]\n            return generated_text\n        except requests.exceptions.RequestException as e:\n            logging.error(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n        try:\n            response = self.client.completions.create(\n                model=model.model_name,\n                messages=[{\"role\": \"system\", \"content\": system_message}, {\"role\": \"user\", \"content\": prompt}],\n                **kwargs\n            )\n            generated_text = response.choices[0].text.strip()\n            return generated_text\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        try:\n            response = requests.post(\n                OPENAI_URL,\n                headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n                json={\n                    \"model\": model.model_name,\n                    \"prompt\": f\"{system_message}\\n{prompt}\",\n                    **kwargs\n                }\n            )\n            response.raise_for_status()\n            data = response.json()\n            generated_text = data[\"choices\"][0][\"text\"]\n            return generated_text\n        except requests.exceptions.RequestException as e:\n            print(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        try:\n            response = requests.post(OPENAI_URL, headers={\"Authorization\": f\"Bearer {self.api_key}\"}, json={\n                \"model\": model.model_name,\n                \"prompt\": prompt,\n                \"system_message\": system_message,\n                **kwargs\n            })\n            response.raise_for_status()\n            data = response.json()\n            generated_text = data[\"choices\"][0][\"text\"].strip()\n            return generated_text\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        try:\n            response = requests.post(OPENAI_URL, headers={\"Authorization\": f\"Bearer {self.api_key}\"}, json={\n                \"model\": model.model_name,\n                \"messages\": [\n                    {\"role\": \"system\", \"content\": system_message},\n                    {\"role\": \"user\", \"content\": prompt}\n                ],\n                **kwargs\n            })\n            response.raise_for_status()\n            data = response.json()\n            generated_text = data[\"choices\"][0][\"message\"][\"content\"]\n            return generated_text\n        except Exception as e:\n            logging.error(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        try:\n            response = requests.post(\n                OPENAI_URL,\n                headers={\n                    \"Authorization\": f\"Bearer {self.api_key}\",\n                    \"Content-Type\": \"application/json\"\n                },\n                json={\n                    \"model\": model.model_name,\n                    \"system_message\": system_message,\n                    \"prompt\": prompt,\n                    **kwargs\n                }\n            )\n            response.raise_for_status()\n            generated_text = response.json()[\"choices\"][0][\"text\"]\n            return generated_text\n        except requests.exceptions.RequestException as e:\n            print(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        try:\n            response = requests.post(OPENAI_URL, headers={\"Authorization\": f\"Bearer {self.api_key}\"}, json={\n                \"model\": model.model_name,\n                \"system_message\": system_message,\n                \"prompt\": prompt,\n                **kwargs\n            })\n            response.raise_for_status()\n            data = response.json()\n            generated_text = data[\"choices\"][0][\"text\"]\n            # Remove any parsing helper tokens\n            return generated_text\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        try:\n            response = requests.post(OPENAI_URL, \n                                     headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n                                     json={\n                                         \"model\": model.model_name,\n                                         \"system_message\": system_message,\n                                         \"prompt\": prompt,\n                                         **kwargs\n                                     })\n            response.raise_for_status()\n            generated_text = response.json()[\"choices\"][0][\"text\"]\n            return generated_text\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        try:\n            response = requests.post(OPENAI_URL, \n                                     headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n                                     json={\"model\": model.model_name,\n                                           \"system_message\": system_message,\n                                           \"prompt\": prompt,\n                                           **kwargs})\n            response.raise_for_status()\n            generated_text = response.json()[\"choices\"][0][\"text\"]\n            return generated_text\n        except requests.exceptions.RequestException as e:\n            print(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"Input matrix must be a square matrix\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"Input matrix must be a square matrix\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"Input matrix must be a square matrix\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be a square matrix\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"Input matrix must be a square matrix\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The input matrix must be a square matrix\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"Input matrix must be a square matrix\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T, atol=1e-8):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T, atol=1e-8):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T, atol=1e-8):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T, atol=1e-8):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T, atol=1e-8):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "ref_utils.l2_normalize", "completion": "  norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  return x / jnp.maximum(norm, grad_eps)"}
{"namespace": "ref_utils.l2_normalize", "completion": "  norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  return x / jnp.maximum(norm, grad_eps)"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared norm of the input array\n  norm_squared = jnp.sum(x**2, axis=-1, keepdims=True)\n\n  # Compute the norm of the input array by taking the square root of the squared norm\n  norm = jnp.sqrt(jnp.maximum(norm_squared, grad_eps))\n\n  # Return the normalized array by dividing the input array by its norm\n  return x / norm"}
{"namespace": "ref_utils.l2_normalize", "completion": "  norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  return jnp.where(norm < grad_eps, x / grad_eps, x / norm)"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared norm of x along the last axis\n  squared_norm = jnp.sum(x**2, axis=-1, keepdims=True)\n\n  # Compute the norm of x along the last axis with a minimum value to prevent gradient explosion\n  norm = jnp.sqrt(jnp.maximum(squared_norm, grad_eps))\n\n  # Normalize x by dividing it by its norm\n  return x / norm"}
{"namespace": "ref_utils.l2_normalize", "completion": "  squared_norm = jnp.sum(x ** 2, axis=-1, keepdims=True)\n  norm = jnp.sqrt(jnp.maximum(squared_norm, grad_eps))\n  return x / norm"}
{"namespace": "ref_utils.l2_normalize", "completion": "  norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  norm = jnp.maximum(norm, grad_eps)  # Clamping the norm to avoid division by zero\n  return x / norm"}
{"namespace": "ref_utils.l2_normalize", "completion": "  norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  return x / jnp.maximum(norm, grad_eps)"}
{"namespace": "ref_utils.l2_normalize", "completion": "  norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  return x / jnp.maximum(norm, grad_eps)"}
{"namespace": "ref_utils.l2_normalize", "completion": "  norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  return x / jnp.maximum(norm, grad_eps)"}
{"namespace": "ref_utils.l2_normalize", "completion": "  norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  return x / jnp.maximum(norm, grad_eps)"}
{"namespace": "ref_utils.l2_normalize", "completion": "  norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  return x / jnp.maximum(norm, grad_eps)"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared norm of x along the last axis\n  norm_squared = jnp.sum(x**2, axis=-1, keepdims=True)\n\n  # Compute the norm of x along the last axis, clamping the squared norm to a minimum value\n  norm = jnp.sqrt(jnp.maximum(norm_squared, grad_eps))\n\n  # Return the normalized array\n  return x / norm"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared norm of the input array along its last axis\n  squared_norm = jnp.sum(x ** 2, axis=-1, keepdims=True)\n\n  # Compute the norm by taking the square root of the squared norm and clamping it to a minimum value\n  norm = jnp.sqrt(jnp.maximum(squared_norm, grad_eps))\n\n  # Return the normalized array by dividing the input array by its norm\n  return x / norm"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared norm of x along the last axis\n  sq_norm = jnp.sum(x**2, axis=-1, keepdims=True)\n\n  # Compute the norm of x along the last axis, clamping the squared norm to a minimum value\n  norm = jnp.sqrt(jnp.maximum(sq_norm, grad_eps))\n\n  # Normalize x by dividing each vector along the last axis by its norm\n  return x / norm"}
{"namespace": "ref_utils.l2_normalize", "completion": "  norm = jnp.sqrt(jnp.maximum(jnp.sum(x**2, axis=-1, keepdims=True), grad_eps))\n  return x / norm"}
{"namespace": "ref_utils.l2_normalize", "completion": "  norm_x = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  return x / jnp.maximum(norm_x, grad_eps)"}
{"namespace": "ref_utils.l2_normalize", "completion": "  norm_x = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  normalized_x = jnp.where(norm_x < grad_eps, x / grad_eps, x / norm_x)\n  return normalized_x"}
{"namespace": "ref_utils.l2_normalize", "completion": "  norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  return x / jnp.maximum(norm, grad_eps)"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared norm of x along the last axis\n  norm_squared = jnp.sum(x**2, axis=-1, keepdims=True)\n\n  # Compute the norm using the square root of the clamped squared norm\n  norm = jnp.sqrt(jnp.maximum(norm_squared, grad_eps))\n\n  # Normalize x by dividing by the norm\n  return x / norm"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    # if upper no lowers after\n    if word.isupper():\n        return word\n    # if mixed case\n    if word[0].isupper() and word[1].islower():\n        return word.capitalize()\n    else:\n        return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    # if upper no lowers after\n    if word.isupper():\n        return word\n    # if mixed case\n    if word[0].isupper() and word[1].islower():\n        return word.capitalize()\n    else:\n        return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    elif word.isupper():\n        return word\n    else:\n        if word[0].isupper() and word[1].islower():\n            return word.capitalize()\n        else:\n            return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    elif word.isupper():\n        return word\n    else:\n        if word[0].isupper() and word[1].islower():\n            return word.capitalize()\n        else:\n            return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    elif word.isupper():\n        return word\n    else:\n        if word[0].isupper() and word[1:].islower():\n            return word.capitalize()\n        else:\n            return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    # if upper no lowers after\n    elif word.isupper():\n        return word\n    # if mixed case\n    else:\n        if word[0].isupper() and word[1].islower():\n            return word.capitalize()\n        else:\n            return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    # if upper no lowers after\n    if word.isupper():\n        return word\n    # if mixed case\n    if word[0].isupper() and word[1].islower():\n        return word.capitalize()\n    else:\n        return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    elif word.isupper():\n        return word\n    else:\n        if word[0].isupper() and word[1].islower():\n            return word.capitalize()\n        else:\n            return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    # if upper no lowers after\n    if word.isupper():\n        return word\n    # if mixed case\n    if word[0].isupper() and word[1].islower():\n        return word.capitalize()\n    else:\n        return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():  # if lower no uppers after\n        return word\n    elif word.isupper():  # if upper no lowers after\n        return word\n    else:  # mixed case\n        if word[0].isupper() and word[1].islower():  # capitalize\n            return word.capitalize()\n        else:  # convert to lowercase\n            return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    # if upper no lowers after\n    if word.isupper():\n        return word\n    # if mixed case\n    if word[0].islower() and word[1].isupper():\n        return word.capitalize()\n    else:\n        return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    # if upper no lowers after\n    if word.isupper():\n        return word\n    # if mixed case\n    if word[0].isupper() and word[1].islower():\n        return word.capitalize()\n    else:\n        return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    elif word.isupper():\n        return word\n    else:\n        if word[0].islower() and word[1].isupper():\n            return word.capitalize()\n        else:\n            return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    elif word.isupper():\n        return word\n    elif word[0].isupper() and word[1:].islower():\n        return word\n    else:\n        return word.capitalize()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    elif word.isupper():\n        return word\n    elif word[0].isupper() and word[1:].islower():\n        return word\n    else:\n        return word.capitalize()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    # if upper no lowers after\n    if word.isupper():\n        return word\n    # if mixed case\n    if word[0].isupper() and word[1].islower():\n        return word.capitalize()\n    else:\n        return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    elif word.isupper():\n        return word\n    else:\n        if word[0].isupper() and word[1].islower():\n            return word.capitalize()\n        else:\n            return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    elif word.isupper():\n        return word\n    else:\n        if word[0].isupper() and word[1].islower():\n            return word.capitalize()\n        else:\n            return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    elif word.isupper():\n        return word\n    else:\n        if word[0].isupper() and word[1].islower():\n            return word.capitalize()\n        else:\n            return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():  # if lower no uppers after\n        return word\n    elif word.isupper():  # if upper no lowers after\n        return word\n    else:  # mixed case\n        if word[0].isupper() and word[1].islower():  # capitalize if first letter is uppercase and second letter is lowercase\n            return word.capitalize()\n        else:  # convert to lowercase\n            return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\" \", \"\")  # remove all whitespace characters\n    return list(line_text)  # segment the modified text into smaller parts or tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\" \", \"\")  # remove all whitespace characters\n    return [char for char in line_text]  # segment the modified text into smaller parts or tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\" \", \"\")  # Remove all whitespace characters\n    return list(line_text)  # Segment the modified text into smaller parts or tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\" \", \"\")  # remove all whitespace characters\n    return [char for char in line_text]  # segment the modified text into smaller parts or tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "\n    line_text = line_text.replace(\" \", \"\")  # remove all whitespace characters\n    return [char for char in line_text]  # segment the modified text into smaller parts or tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "\n    # Remove all whitespace characters from the input text\n    line_text = line_text.replace(\" \", \"\")\n\n    # Segment the modified text into smaller parts or tokens\n    tokens = []\n    start = 0\n    for end in range(1, len(line_text) + 1):\n        if end == len(line_text) or line_text[end].isupper():\n            tokens.append(line_text[start:end])\n            start = end\n    return tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = re.sub(r'\\s+', '', line_text)  # remove all whitespace characters\n    return [char for char in line_text]  # segment the modified text into smaller parts or tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\" \", \"\")  # Remove all whitespace characters\n    return list(line_text)  # Segment the modified text into smaller parts or tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\" \", \"\")  # remove all whitespace characters\n    return list(line_text)  # segment the modified text into smaller parts or tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\" \", \"\")  # Remove all whitespace characters\n    return list(line_text)  # Segment the modified input text into smaller parts or tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "\n    # Remove all whitespace characters\n    line_text = line_text.replace(\" \", \"\")\n\n    # Segment the modified text into smaller parts or tokens\n    tokens = [char for char in line_text]\n\n    return tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\" \", \"\")  # Remove all whitespace characters\n    return list(line_text)  # Segment the modified text into smaller parts or tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "\n    # Remove all whitespace characters\n    line_text = line_text.replace(\" \", \"\")\n\n    # Segment the modified text into smaller parts or tokens\n    tokens = [char for char in line_text]\n\n    return tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\" \", \"\")  # remove all whitespace characters\n    return [char for char in line_text]  # segment the modified text into smaller parts or tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\" \", \"\")  # Remove all whitespace characters\n    return list(line_text)  # Segment the modified text into smaller parts or tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\" \", \"\")  # Remove all whitespace characters\n    return list(line_text)  # Segment the modified text into smaller parts or tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all whitespace characters from the input text\n    line_text = line_text.replace(\" \", \"\")\n\n    # Segment the modified input text into smaller parts or tokens\n    segments = [char for char in line_text]\n\n    return segments"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\" \", \"\")  # Remove all whitespace characters\n    # Segment the modified text into smaller parts or tokens\n    segmented_text = [char for char in line_text]\n    return segmented_text"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\" \", \"\")  # remove all whitespace characters\n    return [char for char in line_text]  # segment the modified text into smaller parts or tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\" \", \"\")  # remove all whitespace characters\n    return list(line_text)  # segment the modified text into smaller parts or tokens"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  return generate_ide_fn(deg_view)"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "\n  # Generate integrated directional encoding (IDE) function\n  integrated_dir_enc_fn = generate_ide_fn(deg_view)\n\n  # Define the directional encoding function\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Function for evaluating directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    return integrated_dir_enc_fn(xyz, kappa_inv)\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  return generate_ide_fn(deg_view)"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  return generate_ide_fn(deg_view)"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  return generate_ide_fn(deg_view)"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  integrated_dir_enc_fn = generate_ide_fn(deg_view)  # Generate integrated directional encoding function\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Function for evaluating the directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    return integrated_dir_enc_fn(xyz, kappa_inv)  # Evaluate directional encoding using integrated directional encoding function\n\n  return dir_enc_fn  # Return the directional encoding function"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  return generate_ide_fn(deg_view)"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  return generate_ide_fn(deg_view)"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Function returning directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    integrated_dir_enc_fn = generate_ide_fn(deg_view)\n    return integrated_dir_enc_fn(xyz, kappa_inv)\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  return generate_ide_fn(deg_view)"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  ide_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    return ide_fn(xyz, kappa_inv)\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  ml_array = get_ml_array(deg_view)\n  integrated_dir_enc_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    return integrated_dir_enc_fn(xyz, kappa_inv)\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  return generate_ide_fn(deg_view)"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  return generate_ide_fn(deg_view)"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  return generate_ide_fn(deg_view)"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  return generate_ide_fn(deg_view)"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  return generate_ide_fn(deg_view)"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  ml_array = get_ml_array(deg_view)\n  ide_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    return ide_fn(xyz, kappa_inv)\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "\n  integrated_dir_enc_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Evaluates the directional encoding for given inputs.\n\n    Input-Output Arguments\n    :param xyz: Array. A 3D array of Cartesian coordinates of directions to evaluate at.\n    :param kappa_inv: Array. The reciprocal of the concentration parameter of the von Mises-Fisher distribution.\n    :return: Array. The resulting directional encoding.\n    \"\"\"\n    return integrated_dir_enc_fn(xyz, kappa_inv)\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def dir_enc_fn(xyz):\n    \"\"\"Function returning directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Split into real and imaginary parts and return\n    return jnp.concatenate([jnp.real(sph_harms), jnp.imag(sph_harms)], axis=-1)\n\n  return dir_enc_fn"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # Clean the lines\n    cleaned_lines = [clean_line(line) for line in lines]\n\n    # Remove duplicate lines ignoring numbers\n    cleaned_lines = list(set(cleaned_lines))\n\n    # Fix spaced characters\n    cleaned_lines = [fix_spaced_characters(line) for line in cleaned_lines]\n\n    # Connect incomplete lines\n    connected_lines = []\n    prev_line = \"\"\n    for line in cleaned_lines:\n        if prev_line:\n            connected_lines.append(connect(prev_line, line))\n            prev_line = \"\"\n        else:\n            if line.endswith(\"-\"):\n                prev_line = line[:-1]\n            else:\n                connected_lines.append(line)\n\n    # Categorize lines into blocks\n    page_blocks, line_set = visual_clean_lines(connected_lines, page_stats={}, page_info_dict={}, page_idx=0, line_set=set())\n\n    # Join blocks if needed\n    if len(page_blocks) > 1:\n        page_blocks, _ = join_blocks(page_blocks, page_blocks[1:])\n\n    return page_blocks"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # remove duplicate lines ignoring numbers\n    lines = list(set(lines))\n\n    # clean and organize lines into blocks\n    page_blocks, line_set = visual_clean_lines(lines, page_stats={}, page_info_dict={}, page_idx=0, line_set={})\n\n    # join blocks if needed\n    if len(page_blocks) > 1:\n        page_blocks, _ = join_blocks(page_blocks, page_blocks[1:])\n\n    return page_blocks"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # Clean the lines\n    page_blocks, line_set = visual_clean_lines(lines)\n    \n    # Join blocks if needed\n    blocks = page_blocks\n    page_blocks = [blocks[0]]\n    for block in blocks[1:]:\n        if check_block_join(page_blocks, block):\n            page_blocks, blocks = join_blocks(page_blocks, blocks)\n        else:\n            page_blocks.append(blocks[0])\n            blocks = blocks[1:]\n\n    return page_blocks"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "\n    page_blocks = []\n    line_set = set()\n    for page_idx, line in enumerate(lines):\n        line = clean_line(line)\n        line_set.add(line)\n        blocks, line_set = visual_clean_lines(\n            lines,\n            page_stats={},\n            page_info_dict={},\n            page_idx=0,\n            line_set=line_set,\n        )\n        page_blocks.extend(blocks)\n\n    # Join blocks\n    blocks_to_join = []\n    for idx, block in enumerate(page_blocks):\n        if idx > 0 and check_block_join(page_blocks[idx - 1], block):\n            blocks_to_join.append(block)\n        else:\n            if blocks_to_join:\n                page_blocks, blocks_to_join = join_blocks(page_blocks, blocks_to_join)\n            page_blocks.append(block)\n\n    return page_blocks"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    result = []\n    line_set = set()\n    page_blocks = []\n    for page_idx, page_lines in enumerate(lines):\n        # clean and organize the lines into blocks\n        cleaned_page_blocks, line_set = visual_clean_lines(\n            page_lines,\n            page_stats={},\n            page_info_dict={},\n            page_idx=page_idx,\n            line_set=line_set,\n        )\n        # join the blocks if needed\n        if page_blocks:\n            if check_block_join(page_blocks, cleaned_page_blocks):\n                page_blocks, cleaned_page_blocks = join_blocks(page_blocks, cleaned_page_blocks)\n        # append the blocks to the result\n        page_blocks.extend(cleaned_page_blocks)\n    # append the final result to the output\n    result.extend(page_blocks)\n    return result"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "\n    page_blocks = []\n    line_set = set()\n    for idx, line in enumerate(lines):\n        lines[idx] = clean_line(line)\n\n    for idx, line in enumerate(lines):\n        if should_skip(line, xml):\n            continue\n        line = fix_spaced_characters(line)\n        if line in line_set:\n            continue\n        line_set.add(line)\n        page_blocks, blocks = visual_clean_lines(\n            lines,\n            page_info_dict={},\n            line_set=line_set,\n        )\n        if len(page_blocks) and len(page_blocks[-1]) and len(blocks):\n            page_blocks, blocks = join_blocks(page_blocks, blocks)\n\n    return page_blocks"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    clean_lines, line_set = set(), []\n    for line in lines:\n        line = clean_line(line)\n        line = fix_spaced_characters(line)\n        line_set.add(line)\n    line_set = list(line_set)\n    page_blocks, line_set = visual_clean_lines(\n        line_set, page_stats={}, page_info_dict={}, page_idx=0, line_set=line_set\n    )\n\n    blocks = []\n    for block in page_blocks:\n        if blocks:\n            if check_block_join(blocks[-1], block):\n                page_blocks, blocks = join_blocks(page_blocks, blocks)\n        blocks.append(block)\n\n    return page_blocks"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # Clean the lines\n    clean_lines, line_set = visual_clean_lines(lines)\n\n    # Join the blocks\n    page_blocks = []\n    blocks = []\n    for block in clean_lines:\n        if not blocks:\n            blocks.append(block)\n        else:\n            prev_block = blocks[-1]\n            if check_block_join(prev_block, block):\n                blocks, remaining_blocks = join_blocks(blocks, [block])\n                page_blocks.append(blocks)\n                blocks = remaining_blocks\n            else:\n                page_blocks.append(blocks)\n                blocks = [block]\n    if blocks:\n        page_blocks.append(blocks)\n\n    return page_blocks"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # Clean the lines\n    page_blocks, line_set = visual_clean_lines(lines)\n\n    # Join blocks if necessary\n    blocks = page_blocks\n    page_blocks = [blocks[0]]\n    blocks = blocks[1:]\n    while len(blocks) > 0:\n        if check_block_join(page_blocks, blocks):\n            page_blocks, blocks = join_blocks(page_blocks, blocks)\n        else:\n            page_blocks.append(blocks[0])\n            blocks = blocks[1:]\n\n    return page_blocks"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # Clean the lines\n    cleaned_lines = []\n    for line in lines:\n        cleaned_line = clean_line(line)\n        cleaned_lines.append(cleaned_line)\n\n    # Fix spaced characters\n    fixed_lines = []\n    for line in cleaned_lines:\n        fixed_line = fix_spaced_characters(line)\n        fixed_lines.append(fixed_line)\n\n    # Connect incomplete lines\n    connected_lines = []\n    for i in range(len(fixed_lines) - 1):\n        connected_line = connect(fixed_lines[i], fixed_lines[i + 1])\n        connected_lines.append(connected_line)\n\n    # Remove duplicate lines\n    unique_lines = list(set(connected_lines))\n\n    # Categorize lines into blocks\n    page_blocks, _ = visual_clean_lines(unique_lines, page_stats={}, page_info_dict={}, page_idx=0, line_set=set())\n\n    return page_blocks"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    line_set = set()\n    page_blocks, _ = visual_clean_lines(lines, line_set=line_set)\n    blocks = []\n    for block in page_blocks:\n        blocks.append(block)\n    return blocks"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # Clean the lines\n    cleaned_lines = [clean_line(line) for line in lines]\n\n    # Remove duplicates (ignoring numbers)\n    line_set = set()\n    unique_lines = []\n    for line in cleaned_lines:\n        numbers = get_numbers(line)\n        if numbers:\n            line_without_numbers = line.replace(numbers.group(), \"\")\n        else:\n            line_without_numbers = line\n        if line_without_numbers not in line_set:\n            line_set.add(line_without_numbers)\n            unique_lines.append(line)\n\n    # Fix spaced characters\n    fixed_lines = [fix_spaced_characters(line) for line in unique_lines]\n\n    # Connect incomplete lines\n    connected_lines = []\n    prev_line = \"\"\n    for curr_line in fixed_lines:\n        if prev_line and prev_line.endswith(\"-\"):\n            connected = connect(prev_line, curr_line)\n            connected_lines[-1] = connected\n        else:\n            connected_lines.append(curr_line)\n        prev_line = curr_line\n\n    # Organize lines into blocks\n    page_blocks, _ = visual_clean_lines(connected_lines, line_set=line_set)\n\n    return page_blocks"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    line_set = set()\n    page_blocks, line_set = visual_clean_lines(lines, line_set=line_set)\n    blocks = []\n    for block in page_blocks:\n        blocks.append(block)\n    return blocks"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    cleaned_lines = []\n    page_stats = {}\n    page_info_dict = {}\n    line_set = set()\n    blocks = []\n\n    for line in lines:\n        line = clean_line(line)\n        line = fix_spaced_characters(line)\n        cleaned_lines.append(line)\n\n    page_blocks, line_set = visual_clean_lines(\n        cleaned_lines,\n        page_stats,\n        page_info_dict,\n        0,\n        line_set,\n    )\n\n    for block in page_blocks:\n        if blocks and check_block_join(blocks[-1], block):\n            blocks, remaining_blocks = join_blocks(blocks, [block])\n            blocks.extend(remaining_blocks)\n        else:\n            blocks.append([block])\n\n    result = []\n    for block_group in blocks:\n        if len(block_group) == 1:\n            result.append(block_group[0])\n        else:\n            merged_block = {\n                \"block_idx\": block_group[0][\"block_idx\"],\n                \"block_text\": \" \".join([block[\"block_text\"] for block in block_group]),\n                \"block_type\": block_group[0][\"block_type\"],\n                \"header_block_idx\": block_group[0][\"header_block_idx\"],\n                \"block_group\": [block[\"block_text\"] for block in block_group],\n                \"text_group_start_idx\": block_group[0][\"text_group_start_idx\"],\n                \"list_char\": block_group[0][\"list_char\"],\n                \"group_id\": block_group[0][\"group_id\"],\n                \"fs\": block_group[0][\"fs\"],\n                \"x\": block_group[0][\"x\"],\n                \"y\": block_group[0][\"y\"],\n                \"line\": block_group[0][\"line\"],\n                \"block_list\": [block[\"block_list\"] for block in block_group],\n            }\n            result.append(merged_block)\n\n    return result"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "\n    page_blocks = []\n    line_set = set()\n    for line in lines:\n        line = clean_line(line)\n        line_set.add(line)\n\n    page_blocks, blocks = visual_clean_lines(lines, page_blocks, line_set)\n    while blocks:\n        page_blocks, blocks = join_blocks(page_blocks, blocks)\n\n    return page_blocks"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    line_set = set()\n    page_blocks = []\n    for page_idx, lines in enumerate(lines):\n        page_blocks, line_set = visual_clean_lines(lines, page_blocks, line_set)\n    return page_blocks"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    cleaned_lines = []\n    for line in lines:\n        line = clean_line(line)\n        if line not in cleaned_lines:\n            cleaned_lines.append(line)\n\n    result, _ = visual_clean_lines(cleaned_lines)\n    return result"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # Clean the lines\n    cleaned_lines = [clean_line(line) for line in lines]\n\n    # Remove duplicate lines (ignoring numbers)\n    cleaned_lines = list(set(cleaned_lines))\n\n    # Fix spaced characters\n    cleaned_lines = [fix_spaced_characters(line) for line in cleaned_lines]\n\n    # Connect incomplete lines\n    connected_lines = []\n    prev_line = \"\"\n    for line in cleaned_lines:\n        if prev_line:\n            connected = connect(prev_line, line)\n            if connected:\n                connected_lines.pop()\n                connected_lines.append(connected)\n            else:\n                connected_lines.append(prev_line)\n        prev_line = line\n    if prev_line:\n        connected_lines.append(prev_line)\n\n    # Categorize lines into paragraphs, headers, or list items\n    page_blocks, line_set = visual_clean_lines(connected_lines, xml=xml)\n\n    return page_blocks"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "\n    page_blocks = []\n    line_set = set()\n    for page_idx, page in enumerate(lines):\n        cleaned_lines = [clean_line(line) for line in page]\n        page_blocks, line_set = visual_clean_lines(\n            cleaned_lines,\n            page_stats={},\n            page_info_dict={},\n            page_idx=page_idx,\n            line_set=line_set,\n        )\n        if page_idx > 0 and check_block_join(page_blocks, page_blocks[0]):\n            page_blocks, page_blocks[0] = join_blocks(page_blocks, page_blocks[0])\n        page_blocks.append(page_blocks)\n\n    return page_blocks"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    cleaned_lines = []\n    page_stats = {}\n    page_info_dict = {}\n    line_set = set()\n    for line in lines:\n        cleaned_line = clean_line(line)\n        cleaned_lines.append(cleaned_line)\n\n    page_blocks, blocks = visual_clean_lines(\n        cleaned_lines,\n        page_stats,\n        page_info_dict,\n        line_set=line_set,\n    )\n\n    # join blocks\n    while len(blocks) > 0:\n        if check_block_join(page_blocks, blocks):\n            page_blocks, blocks = join_blocks(page_blocks, blocks)\n        else:\n            page_blocks.append(blocks[0])\n            blocks = blocks[1:]\n\n    return page_blocks"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None or org_texts == \"\":\n        return org_texts\n\n    # Replace special characters with their normalized forms\n    org_texts = re.sub(quotation_pattern, '\"', org_texts)\n\n    # Apply predefined rules to normalize the text\n    for rule, replacement in rules:\n        org_texts = rule.sub(replacement, org_texts)\n\n    # Tokenize the text into sentences\n    tokenized_sentences = nltk_tokenzier.tokenize(org_texts)\n\n    # Remove extra spaces from the tokenized sentences\n    tokenized_sentences = [re.sub(space_rule, r\"\\1\", sent) for sent in tokenized_sentences]\n\n    # Join sentences split by brackets\n    joined_sentences = []\n    for sent in tokenized_sentences:\n        if joined_sentences and joined_sentences[-1][-1] == \"(\" and sent[0].islower():\n            joined_sentences[-1] = joined_sentences[-1][:-1] + sent\n        else:\n            joined_sentences.append(sent)\n\n    return joined_sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None or org_texts == \"\":\n        return org_texts\n\n    # Replace special characters with their normalized forms\n    org_texts = org_texts.replace(\"\u2019\", \"'\").replace(\"\u2018\", \"'\").replace(\"\u201d\", '\"').replace(\"\u201c\", '\"')\n\n    # Apply rules to handle special cases\n    for rule, replaced in rules:\n        org_texts = rule.sub(replaced, org_texts)\n\n    # Tokenize the text using the NLTK tokenizer\n    sents = nltk_tokenzier.tokenize(org_texts)\n\n    # Remove extra spaces and normalize quotation marks within the tokenized sentences\n    sents = [quotation_pattern.sub('\"', sent.strip()) for sent in sents]\n\n    return sents"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    # If the input text is empty or None, return it as is\n    if org_texts is None or org_texts == \"\":\n        return org_texts\n\n    # Normalize quotation marks within the text\n    org_texts = re.sub(quotation_pattern, '\"', org_texts)\n\n    # Tokenize the text into sentences using the NLTK tokenizer\n    sentences = nltk_tokenzier.tokenize(org_texts)\n\n    # Apply predefined rules and patterns to handle special cases\n    for rule, replaced in rules:\n        sentences = [rule.sub(replaced, sent) for sent in sentences]\n\n    # Remove any space between punctuations (.')\n    sentences = [space_rule.sub(r'\\1', sent) for sent in sentences]\n\n    # Match content inside brackets and ensure sentences within brackets are not broken\n    sentences = [bracket_rule.sub(r\"\\1\", sent) for sent in sentences]\n\n    return sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    # If input text is empty or None, return it as is\n    if not org_texts:\n        return org_texts\n\n    # Apply space rule to remove any space between punctuation\n    org_texts = space_rule.sub(r\"\\1\", org_texts)\n\n    # Apply bracket rule to ensure sentences within brackets are not broken\n    org_texts = bracket_rule.sub(r\"\\1\", org_texts)\n\n    # Normalize quotation marks within the text\n    org_texts = re.sub(quotation_pattern, '\"', org_texts)\n\n    # Tokenize the text into sentences using the NLTK tokenizer\n    sentences = nltk_tokenzier.tokenize(org_texts)\n\n    return sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    # check if the input text is empty or None\n    if org_texts is None or org_texts.strip() == \"\":\n        return org_texts\n\n    # apply predefined rules and patterns to the input text\n    texts = org_texts\n    texts = re.sub(space_rule, r\"\\1\", texts)  # Remove any space between punctuations (.')\n    texts = re.sub(bracket_rule, r\"\\1\", texts)  # Remove content inside brackets\n    texts = re.sub(quotation_pattern, '\"', texts)  # Normalize quotation marks\n\n    # tokenize the normalized text using the nltk tokenizer\n    tokenized_sentences = nltk_tokenzier.tokenize(texts)\n\n    return tokenized_sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None or org_texts == \"\":\n        return [org_texts]\n\n    # Replace any space between punctuations (.')\n    org_texts = re.sub(space_rule, r\"\\1\", org_texts)\n\n    # Ensure that sentences within brackets are not broken\n    org_texts = re.sub(bracket_rule, r\"\\1\", org_texts)\n\n    # Normalize quotation marks within the text\n    org_texts = re.sub(quotation_pattern, '\"', org_texts)\n\n    # Tokenize the text into sentences\n    tokenized_sentences = nltk_tokenzier.tokenize(org_texts)\n\n    # Apply predefined rules and patterns to the tokenized sentences\n    for rule, replaced in rules:\n        tokenized_sentences = [re.sub(rule, replaced, sent) for sent in tokenized_sentences]\n\n    return tokenized_sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # Replace special abbreviations with underscore to avoid tokenization\n    for rule, replaced in rules:\n        org_texts = rule.sub(replaced, org_texts)\n\n    # Remove any space between punctuations (.')\n    org_texts = space_rule.sub(r\"\\1\", org_texts)\n\n    # Normalize quotation marks\n    org_texts = quotation_pattern.sub('\"', org_texts)\n\n    # Tokenize the text into sentences\n    sentences = nltk_tokenzier.tokenize(org_texts)\n\n    return sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    # If the input text is empty or None, return the input as is\n    if not org_texts:\n        return org_texts\n\n    # Normalize quotation marks within the text\n    org_texts = re.sub(quotation_pattern, '\"', org_texts)\n\n    # Tokenize the text using the NLTK tokenizer\n    sentences = nltk_tokenzier.tokenize(org_texts)\n\n    # Apply predefined rules and patterns to handle special cases\n    for rule, replaced in rules:\n        sentences = [rule.sub(replaced, sent) for sent in sentences]\n\n    # Remove any space between punctuations (.')\n    sentences = [space_rule.sub(r\"\\1\", sent) for sent in sentences]\n\n    # Match content inside brackets and ensure that sentences within brackets are not broken\n    sentences = [bracket_rule.sub(r\"\\1\", sent) for sent in sentences]\n\n    return sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    # If the input text is empty or None, return it as is\n    if not org_texts:\n        return org_texts\n\n    # Apply space_rule to remove any space between punctuations\n    org_texts = re.sub(space_rule, r\"\\1\", org_texts)\n\n    # Apply bracket_rule to ensure that sentences within brackets are not broken\n    org_texts = re.sub(bracket_rule, r\"\\1\", org_texts)\n\n    # Normalize quotation marks within the text\n    org_texts = re.sub(quotation_pattern, '\"', org_texts)\n\n    # Tokenize the text using the nltk_tokenizer\n    tokenized_text = nltk_tokenzier.tokenize(org_texts)\n\n    return tokenized_text"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    # If the input text is empty or None, return the input as is\n    if not org_texts:\n        return org_texts\n\n    # Apply various tokenization and normalization rules to the input text\n    # such as handling special cases, normalizing quotation marks, and tokenizing into sentences\n    tokenized_texts = []\n\n    # Split the text into paragraphs separated by new lines\n    paragraphs = org_texts.split(\"\\n\")\n    for paragraph in paragraphs:\n        # Remove any leading or trailing whitespace\n        paragraph = paragraph.strip()\n\n        # Handle special case: punctuation at the beginning of the text\n        if paragraph and paragraph[0] in [\".\", \"!\", \"?\"]:\n            paragraph = paragraph[1:]\n\n        # Ensure that sentences within brackets are not broken\n        bracket_matches = bracket_rule.findall(paragraph)\n        for match in bracket_matches:\n            # Replace the content inside brackets with a placeholder\n            placeholder = f\"BRACKET_{len(tokenized_texts)}_PLACEHOLDER\"\n            paragraph = paragraph.replace(f\"({match})\", placeholder)\n\n        # Normalize quotation marks within the paragraph\n        paragraph = quotation_pattern.sub('\"', paragraph)\n\n        # Tokenize the paragraph into sentences using the NLTK tokenizer\n        sentences = nltk_tokenzier.tokenize(paragraph)\n\n        # Replace the placeholders with the original content inside brackets\n        for i, sentence in enumerate(sentences):\n            placeholder = f\"BRACKET_{len(tokenized_texts)}_PLACEHOLDER\"\n            sentences[i] = sentence.replace(placeholder, f\"({bracket_matches[i]})\")\n\n        # Append the tokenized sentences to the list of tokenized texts\n        tokenized_texts.extend(sentences)\n\n    return tokenized_texts"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    # If the input text is empty or None, return it as is\n    if org_texts is None or org_texts == \"\":\n        return org_texts\n\n    # Apply various tokenization and normalization rules to the input text\n    org_texts = re.sub(space_rule, r\"\\1\", org_texts)\n    org_texts = re.sub(bracket_rule, r\" \\1 \", org_texts)\n    org_texts = re.sub(quotation_pattern, '\"', org_texts)\n\n    # Tokenize the normalized text into sentences using the NLTK tokenizer\n    tokenized_sents = nltk_tokenzier.tokenize(org_texts)\n\n    return tokenized_sents"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    # If the input text is empty or None, return it as is\n    if not org_texts:\n        return org_texts\n\n    # Apply the space rule to remove any space between punctuations\n    org_texts = re.sub(space_rule, r\"\\1\", org_texts)\n\n    # Apply the bracket rule to ensure that sentences within brackets are not broken\n    org_texts = re.sub(bracket_rule, r\"\\1\", org_texts)\n\n    # Apply the predefined rules and patterns to perform tokenization and normalization\n    tokenized_texts = nltk_tokenzier.tokenize(org_texts)\n\n    # Normalize quotation marks within the tokenized texts\n    tokenized_texts = [re.sub(quotation_pattern, '\"', text) for text in tokenized_texts]\n\n    return tokenized_texts"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    # If the input text is empty or None, return the input as is\n    if not org_texts:\n        return org_texts\n\n    # Apply space rule to remove any space between punctuations\n    org_texts = re.sub(space_rule, r\"\\1\", org_texts)\n\n    # Apply bracket rule to ensure that sentences within brackets are not broken\n    org_texts = re.sub(bracket_rule, r\"(\\1)\", org_texts)\n\n    # Normalize quotation marks within the text\n    org_texts = re.sub(quotation_pattern, '\"', org_texts)\n\n    # Tokenize the text into sentences using the nltk_tokenizer\n    sentences = nltk_tokenzier.tokenize(org_texts)\n\n    return sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return [org_texts]\n\n    # Replace special characters with normalized ones\n    for rule, replaced in rules:\n        org_texts = rule.sub(replaced, org_texts)\n\n    # Remove any space between punctuations\n    org_texts = space_rule.sub(r\"\\1\", org_texts)\n\n    # Tokenize the text into sentences\n    sentences = nltk_tokenzier.tokenize(org_texts)\n\n    # Normalize quotation marks within the text\n    sentences = [quotation_pattern.sub('\"', sent) for sent in sentences]\n\n    return sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None or org_texts == \"\":\n        return [org_texts]\n\n    # Normalize quotation marks\n    org_texts = re.sub(quotation_pattern, '\"', org_texts)\n\n    # Apply space rule to remove spaces between punctuations\n    org_texts = re.sub(space_rule, r\"\\1\", org_texts)\n\n    # Apply bracket rule to prevent breaking sentences within brackets\n    org_texts = re.sub(bracket_rule, r\"(\\1)\", org_texts)\n\n    # Tokenize the text into sentences\n    tokenized_sentences = nltk_tokenzier.tokenize(org_texts)\n\n    # Apply abbreviation rules to replace abbreviations with underscore\n    for rule, replaced in rules:\n        tokenized_sentences = [rule.sub(replaced, sent) for sent in tokenized_sentences]\n\n    return tokenized_sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    # If the input text is empty or None, return the input as is\n    if not org_texts:\n        return org_texts\n\n    # Apply space rule to remove any space between punctuations\n    org_texts = re.sub(space_rule, r\"\\1\", org_texts)\n\n    # Normalize quotation marks within the text\n    org_texts = re.sub(quotation_pattern, '\"', org_texts)\n\n    # Tokenize the text into sentences using the NLTK tokenizer\n    sentences = nltk_tokenzier.tokenize(org_texts)\n\n    # Apply predefined rules and patterns to handle special cases\n    for rule, replaced in rules:\n        sentences = [re.sub(rule, replaced, sent) for sent in sentences]\n\n    # Return the tokenized sentences\n    return sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    # If the input text is empty or None, return the input as is\n    if not org_texts:\n        return org_texts\n\n    # Apply space rule to remove any space between punctuations\n    org_texts = re.sub(space_rule, r\"\\1\", org_texts)\n\n    # Apply bracket rule to ensure that sentences within brackets are not broken\n    org_texts = re.sub(bracket_rule, r\" \\1 \", org_texts)\n\n    # Apply predefined rules and patterns to perform tokenization and normalization\n    for rule, replaced in rules:\n        org_texts = rule.sub(replaced, org_texts)\n\n    # Normalize quotation marks within the text\n    org_texts = re.sub(quotation_pattern, '\"', org_texts)\n\n    # Use the instance of the tokenizer to tokenize the text into sentences\n    tokenized_sentences = nltk_tokenzier.tokenize(org_texts)\n\n    return tokenized_sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    # If the input text is empty or None, return the input as is\n    if not org_texts:\n        return org_texts\n\n    # Apply the space rule to remove any space between punctuations\n    org_texts = re.sub(space_rule, r\"\\1\", org_texts)\n\n    # Apply the bracket rule to ensure that sentences within brackets are not broken\n    org_texts = re.sub(bracket_rule, r\"\\1\", org_texts)\n\n    # Apply the predefined rules and patterns to normalize the text\n    for rule, replaced in rules:\n        org_texts = re.sub(rule, replaced, org_texts)\n\n    # Apply the quotation pattern to normalize quotation marks within the text\n    org_texts = re.sub(quotation_pattern, '\"', org_texts)\n\n    # Use the nltk tokenizer to tokenize the normalized text into sentences\n    tokenized_sentences = nltk_tokenzier.tokenize(org_texts)\n\n    return tokenized_sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None or org_texts == \"\":\n        return [org_texts]\n\n    # Replace special characters with space\n    org_texts = re.sub(r\"[^a-zA-Z0-9\\s\\.,']\", \" \", org_texts)\n\n    # Tokenize using NLTK tokenizer\n    tokenized_text = nltk_tokenzier.tokenize(org_texts)\n\n    # Apply rules for abbreviations\n    for rule, replacement in rules:\n        tokenized_text = [re.sub(rule, replacement, sentence) for sentence in tokenized_text]\n\n    # Remove spaces between punctuations\n    tokenized_text = [re.sub(space_rule, r\"\\1\", sentence) for sentence in tokenized_text]\n\n    # Remove spaces before and after quotation marks\n    tokenized_text = [re.sub(quotation_pattern, \"\", sentence) for sentence in tokenized_text]\n\n    # Remove empty sentences\n    tokenized_text = [sentence for sentence in tokenized_text if sentence.strip()]\n\n    return tokenized_text"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # Remove any space between punctuations (.')\n    org_texts = re.sub(space_rule, r\"\\1\", org_texts)\n\n    # Tokenize the text into sentences\n    sentences = nltk_tokenzier.tokenize(org_texts)\n\n    # Normalize quotation marks within the text\n    sentences = [re.sub(quotation_pattern, '\"', sent) for sent in sentences]\n\n    # Ensure that sentences within brackets are not broken\n    sentences = [re.sub(bracket_rule, r\"\\1\", sent) for sent in sentences]\n\n    # Apply predefined rules and patterns to the tokenized sentences\n    for rule, replaced in rules:\n        sentences = [re.sub(rule, replaced, sent) for sent in sentences]\n\n    return sentences"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return self.posns[token][key]\n        else:\n            return [self.posns[token][k] for k in self.posns]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return self.posns.doc_encoded_posns(self.term_dict.get_term_id(token), doc_id=key)\n        else:\n            return [self.posns.doc_encoded_posns(self.term_dict.get_term_id(token), doc_id=i) for i in range(len(self))]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return self.posns[token][key]\n        else:\n            return [posns for posns in self.posns[token].values()]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return self[key].positions(token)\n        else:\n            return [doc.positions(token) for doc in self]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return self[key].positions(token)\n        else:\n            return [doc.positions(token) for doc in self]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return self.posns[key][token]\n        else:\n            return [self.posns[doc][token] for doc in range(len(self))]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return self.posns[key][token]\n        else:\n            return [posns[token] for posns in self.posns]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return self.posns.doc_encoded_posns(self.term_dict.get_term_id(token), doc_id=key)\n        else:\n            return [self.posns.doc_encoded_posns(self.term_dict.get_term_id(token), doc_id=i) for i in range(len(self))]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return self.posns[token][key]\n        else:\n            return [self.posns[token][k] for k in self.posns[token]]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return self[key].positions(token)\n        else:\n            return [doc.positions(token) for doc in self]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            # Retrieve positions for a specific document\n            return self.posns[key][token]\n        else:\n            # Retrieve positions across all documents\n            return [self.posns[doc][token] for doc in self.posns]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return self[key].positions(token)\n        else:\n            return [doc.positions(token) for doc in self]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return self.posns[key][token]\n        else:\n            return [self.posns[doc][token] for doc in range(len(self))]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return self[key].positions(token)\n        else:\n            return [doc.positions(token) for doc in self]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return self[key].positions(token)\n        else:\n            return [doc.positions(token) for doc in self]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return self.posns[key][token]\n        else:\n            return [self.posns[doc][token] for doc in self.posns]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            if self.posns is None:\n                return []\n            else:\n                return self.posns[key][token]\n        else:\n            if self.posns is None:\n                return [np.array([]) for _ in range(len(self))]\n            else:\n                return [self.posns[doc_key][token] if doc_key in self.posns else np.array([]) for doc_key in range(len(self))]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return self[key].positions(token)\n        else:\n            return [doc.positions(token) for doc in self]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return self.posns[key][token]\n        else:\n            positions = []\n            for doc_key in range(len(self)):\n                positions.append(self.posns[doc_key][token])\n            return positions"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "\n        if key is not None:\n            return self[key].positions(token)\n        else:\n            return [doc.positions(token) for doc in self]"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif '%' in spec:\n        percentage = int(spec.strip('%'))\n        return int(num_clauses * (percentage / 100))\n    elif '<' in spec:\n        threshold = int(spec.strip('<'))\n        return max(num_clauses - threshold, 1)\n    else:\n        return int(spec)"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif '%' in spec:\n        percentage = int(spec.strip('%'))\n        return int(num_clauses * percentage / 100)\n    elif '<' in spec:\n        threshold = int(spec.strip('<'))\n        return min(num_clauses, threshold)\n    else:\n        raise ValueError(\"Invalid 'min should match' specification\")"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif '%' in spec:\n        percentage = int(spec.replace('%', ''))\n        return int(num_clauses * percentage / 100)\n    elif '<' in spec:\n        threshold = int(spec.replace('<', ''))\n        return min(num_clauses, threshold)\n    else:\n        raise ValueError(\"Invalid 'min should match' specification\")"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif spec.endswith(\"%\"):\n        percentage = int(spec[:-1])\n        return max(1, int(num_clauses * percentage / 100))\n    elif \"<\" in spec:\n        threshold = int(spec.split(\"<\")[1])\n        return min(num_clauses, threshold)\n    else:\n        raise ValueError(\"Invalid 'min should match' specification\")"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif '%' in spec:\n        percentage = int(spec.strip('%'))\n        return int(num_clauses * percentage / 100)\n    elif '<' in spec:\n        threshold = int(spec.strip('<'))\n        return min(num_clauses, threshold)\n    else:\n        raise ValueError(\"Invalid 'min should match' specification\")"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif '%' in spec:\n        percentage = int(spec.strip('%'))\n        return int(num_clauses * (percentage / 100))\n    elif '<' in spec:\n        threshold = int(spec.strip('<'))\n        return min(num_clauses, threshold)\n    else:\n        raise ValueError(\"Invalid 'min should match' specification\")"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif '%' in spec:\n        percentage = int(spec.strip('%'))\n        return int(num_clauses * percentage / 100)\n    elif '<' in spec:\n        threshold = int(spec.strip('<'))\n        return min(num_clauses, threshold)\n    else:\n        raise ValueError(\"Invalid min should match specification\")"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif '%' in spec:\n        percentage = int(spec.strip('%'))\n        return int(num_clauses * (percentage / 100))\n    elif '<' in spec:\n        threshold = int(spec.strip('<'))\n        return min(num_clauses, threshold)\n    else:\n        raise ValueError(\"Invalid 'min should match' specification\")"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif '%' in spec:\n        percentage = int(spec.strip('%'))\n        return int(num_clauses * percentage / 100)\n    elif '<' in spec:\n        threshold = int(spec.strip('<'))\n        return min(num_clauses, threshold)\n    else:\n        raise ValueError(\"Invalid 'min should match' specification\")"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif '%' in spec:\n        percentage = int(spec.strip('%'))\n        return int(num_clauses * (percentage / 100))\n    elif '<' in spec:\n        threshold = int(spec.strip('<'))\n        return min(num_clauses, threshold)\n    else:\n        raise ValueError(\"Invalid 'min should match' specification\")"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif '%' in spec:\n        percentage = int(spec.strip('%'))\n        return int(num_clauses * (percentage / 100))\n    elif '<' in spec:\n        threshold = int(spec.strip('<'))\n        return min(num_clauses, threshold)\n    else:\n        raise ValueError(\"Invalid 'min should match' specification\")"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif spec.endswith(\"%\"):\n        percentage = int(spec[:-1])\n        return int(num_clauses * (percentage / 100))\n    elif \"<\" in spec:\n        threshold = int(spec.split(\"<\")[1])\n        return min(num_clauses, threshold)\n    else:\n        raise ValueError(\"Invalid min should match specification\")"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif spec.endswith(\"%\"):\n        percentage = int(spec[:-1])\n        return int(num_clauses * (percentage / 100))\n    elif \"<\" in spec:\n        threshold = int(spec.split(\"<\")[1])\n        return min(num_clauses, threshold)\n    else:\n        raise ValueError(\"Invalid 'min should match' specification\")"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif '%' in spec:\n        percentage = int(spec.strip('%'))\n        return int(num_clauses * (percentage / 100))\n    elif '<' in spec:\n        threshold = int(spec.strip('<'))\n        return max(num_clauses - threshold, 1)\n    else:\n        raise ValueError(\"Invalid 'min should match' specification\")"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif '%' in spec:\n        percentage = int(spec.strip('%'))\n        return int(num_clauses * percentage / 100)\n    elif '<' in spec:\n        threshold = int(spec.strip('<'))\n        return min(num_clauses, threshold)\n    else:\n        raise ValueError(\"Invalid 'min should match' specification\")"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif '%' in spec:\n        percentage = int(spec.strip('%'))\n        return int(num_clauses * (percentage / 100))\n    elif '<' in spec:\n        threshold = int(spec.strip('<'))\n        return max(num_clauses - threshold, 1)\n    else:\n        raise ValueError(\"Invalid 'min should match' specification\")"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif '%' in spec:\n        percent = int(spec.strip('%'))\n        return int(num_clauses * percent / 100)\n    elif '<' in spec:\n        condition, threshold = spec.split('<')\n        threshold = int(threshold)\n        if condition.isdigit():\n            return min(int(condition), threshold)\n        elif '%' in condition:\n            percent = int(condition.strip('%'))\n            return min(int(num_clauses * percent / 100), threshold)\n    else:\n        raise ValueError(\"Invalid 'min should match' specification\")"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif '%' in spec:\n        percentage = int(spec.strip('%'))\n        return int(num_clauses * (percentage / 100))\n    elif '<' in spec:\n        threshold = int(spec.strip('<'))\n        return min(num_clauses, threshold)\n    else:\n        raise ValueError(\"Invalid 'min should match' specification\")"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif \"%\" in spec:\n        percentage = int(spec.strip(\"%\"))\n        return int(num_clauses * (percentage / 100))\n    elif \"<\" in spec:\n        threshold = int(spec.strip(\"<\"))\n        return max(num_clauses - threshold, 1)\n    else:\n        raise ValueError(\"Invalid 'min should match' specification\")"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif '%' in spec:\n        percent = int(spec.strip('%'))\n        return int(num_clauses * percent / 100)\n    elif '<' in spec:\n        threshold = int(spec.strip('<'))\n        return max(threshold, 1)\n    else:\n        raise ValueError(\"Invalid 'min should match' specification\")"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "\n        # Check if all tokens are unique\n        if len(tokens) == len(set(tokens)) and slop == 1:\n            return self.phrase_freq_every_diff(tokens, slop)\n        else:\n            return self.phrase_freq_scan(tokens, slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(set(tokens)) == len(tokens):\n            return self.phrase_freq_scan(tokens, slop=slop)\n        else:\n            return self.phrase_freq_every_diff(tokens, slop=slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(set(tokens)) == len(tokens):\n            return self.phrase_freq_scan(tokens, slop=slop)\n        else:\n            return self.phrase_freq_every_diff(tokens, slop=slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(set(tokens)) == len(tokens):\n            return self.phrase_freq_scan(tokens, slop=slop)\n        else:\n            return self.phrase_freq_every_diff(tokens, slop=slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "\n        if slop == 1 and len(set(tokens)) == len(tokens):\n            return self.phrase_freq_every_diff(tokens, slop=slop)\n        else:\n            return self.phrase_freq_scan(tokens, slop=slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "\n        # Check if the slop is 1 and all tokens are unique\n        if slop == 1 and len(set(tokens)) == len(tokens):\n            return self.phrase_freq_every_diff(tokens, slop)\n        else:\n            return self.phrase_freq_scan(tokens, slop=slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(set(tokens)) == len(tokens):\n            return self.phrase_freq_scan(tokens, slop=slop)\n        else:\n            return self.phrase_freq_every_diff(tokens, slop=slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "\n        if slop == 1 and len(set(tokens)) == len(tokens):\n            return self.phrase_freq_every_diff(tokens, slop=slop)\n        else:\n            return self.phrase_freq_scan(tokens, slop=slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if len(tokens) == len(set(tokens)) and slop == 1:\n            return self.phrase_freq_every_diff(tokens, slop=slop)\n        else:\n            return self.phrase_freq_scan(tokens, slop=slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(set(tokens)) == len(tokens):\n            return self.phrase_freq_scan(tokens, slop=slop)\n        else:\n            return self.phrase_freq_every_diff(tokens, slop=slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "\n        if slop == 1 and len(set(tokens)) == len(tokens):\n            return self.phrase_freq_scan(tokens, slop=slop)\n        else:\n            return self.phrase_freq_every_diff(tokens, slop=slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "\n        if slop == 1 and len(set(tokens)) == len(tokens):\n            return self.phrase_freq_scan(tokens, slop=slop)\n        else:\n            return self.phrase_freq_every_diff(tokens, slop=slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "\n        unique_tokens = list(set(tokens))\n        if len(unique_tokens) == len(tokens) and slop == 1:\n            return self.phrase_freq_scan(tokens, slop=slop)\n        else:\n            return self.phrase_freq_every_diff(tokens, slop=slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "\n        if slop == 1 and len(set(tokens)) == len(tokens):\n            return self.phrase_freq_scan(tokens)\n        else:\n            return self.phrase_freq_every_diff(tokens, slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(tokens) == len(set(tokens)):\n            return self.phrase_freq_scan(tokens)\n        else:\n            return self.phrase_freq_every_diff(tokens, slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "\n        if slop == 1 and len(set(tokens)) == len(tokens):\n            return self.phrase_freq_every_diff(tokens, slop=slop)\n        else:\n            return self.phrase_freq_scan(tokens, slop=slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "\n        if len(tokens) == 1:\n            return self.termfreqs(tokens[0])\n\n        if slop == 1 and len(set(tokens)) == len(tokens):\n            return self.phrase_freq_scan(tokens, slop=slop)\n        else:\n            return self.phrase_freq_every_diff(tokens, slop=slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(set(tokens)) == len(tokens):\n            return self.phrase_freq_every_diff(tokens, slop=slop)\n        else:\n            return self.phrase_freq_scan(tokens, slop=slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(set(tokens)) == len(tokens):\n            return self.phrase_freq_every_diff(tokens, slop)\n        else:\n            return self.phrase_freq_scan(tokens, slop=slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(set(tokens)) == len(tokens):\n            return self.phrase_freq_every_diff(tokens, slop=slop)\n        else:\n            return self.phrase_freq_scan(tokens, slop=slop)"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if truncate:\n            array = array[:truncate]\n\n        postings_arr = cls([], tokenizer=tokenizer, avoid_copies=avoid_copies)\n        batch_start = 0\n        while batch_start < len(array):\n            batch_end = min(batch_start + batch_size, len(array))\n            batch = array[batch_start:batch_end]\n\n            # Index the batch\n            batch_postings = build_index_from_tokenizer(batch, Terms, tokenizer)\n            postings_arr = cls(postings_arr + batch_postings, tokenizer=tokenizer, avoid_copies=avoid_copies)\n\n            batch_start = batch_end\n\n        return postings_arr"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "\n        # Initialize an empty list to store the indexed data\n        indexed_data = []\n\n        # Process the array in batches to handle large arrays\n        for i in range(0, len(array), batch_size):\n            batch = array[i:i + batch_size]  # Get a batch of data\n\n            # Tokenize the batch using the specified tokenizer\n            tokenized_batch = [tokenizer(data) for data in batch]\n\n            # Index the tokenized batch and store the indexed data\n            indexed_data.extend(build_index_from_tokenizer(tokenized_batch, Terms))\n\n        # Create an instance of SearchArray to hold the indexed data\n        indexed_array = cls(indexed_data, tokenizer=tokenizer, avoid_copies=avoid_copies)\n\n        return indexed_array"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if truncate:\n            array = array[:batch_size]\n\n        postings_arr = SearchArray(array, tokenizer=tokenizer, avoid_copies=avoid_copies)\n        return postings_arr"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if truncate:\n            array = array[:batch_size]\n\n        postings_arr = SearchArray(array, tokenizer=tokenizer, avoid_copies=avoid_copies)\n        return postings_arr"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "\n        if truncate:\n            array = array[:batch_size]\n\n        postings_arr = cls([], tokenizer=tokenizer, avoid_copies=avoid_copies)\n\n        for i in range(0, len(array), batch_size):\n            batch = array[i:i+batch_size]\n            postings_arr = postings_arr + cls(batch, tokenizer=tokenizer, avoid_copies=avoid_copies)\n\n        return postings_arr"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if truncate:\n            array = array[:batch_size]\n\n        postings_arr = cls([], tokenizer=tokenizer, avoid_copies=avoid_copies)\n        for i in range(0, len(array), batch_size):\n            batch = array[i:i + batch_size]\n            postings_arr = postings_arr._index_batch(batch)\n\n        return postings_arr"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if truncate:\n            array = array[:batch_size]\n\n        postings_arr = cls([], tokenizer=tokenizer, avoid_copies=avoid_copies)\n\n        for i in range(0, len(array), batch_size):\n            batch = array[i:i+batch_size]\n            postings_arr = postings_arr + cls(batch, tokenizer=tokenizer, avoid_copies=avoid_copies)\n\n        return postings_arr"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "\n        # Check if the input array is list-like\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object for array, got {}\".format(type(array)))\n\n        # Initialize variables to hold the indexed data\n        term_mat = []\n        posns = []\n        term_dict = None\n        avg_doc_length = 0\n        doc_lens = []\n\n        # Process the array in batches to handle large datasets\n        for i in range(0, len(array), batch_size):\n            batch = array[i:i+batch_size]\n            term_mat_batch, posns_batch, term_dict_batch, avg_doc_length_batch, doc_lens_batch = build_index_from_tokenizer(batch, tokenizer)\n\n            # Append the batch results to the overall indexed data\n            term_mat.append(term_mat_batch)\n            posns.append(posns_batch)\n            if term_dict is None:\n                term_dict = term_dict_batch\n            avg_doc_length = avg_doc_length_batch\n            doc_lens.append(doc_lens_batch)\n\n        # Concatenate the results from all batches\n        term_mat = np.concatenate(term_mat)\n        posns = np.concatenate(posns)\n        doc_lens = np.concatenate(doc_lens)\n\n        # Create a new instance of SearchArray with the indexed data\n        return cls(term_mat, posns, term_dict, avg_doc_length, doc_lens)"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if truncate:\n            array = array[:batch_size]\n\n        postings_arr = cls([], tokenizer=tokenizer, avoid_copies=avoid_copies)\n\n        for i in range(0, len(array), batch_size):\n            batch = array[i:i+batch_size]\n            postings_arr = cls._index_batch(postings_arr, batch, tokenizer)\n\n        return postings_arr"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if truncate:\n            array = array[:batch_size]\n\n        postings_arr = cls([], tokenizer=tokenizer, avoid_copies=avoid_copies)\n        for i in range(0, len(array), batch_size):\n            batch = array[i:i + batch_size]\n            postings_arr = cls._index_batch(postings_arr, batch, tokenizer)\n\n        return postings_arr"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if truncate:\n            array = array[:batch_size]\n\n        postings_arr = SearchArray(array, tokenizer=tokenizer, avoid_copies=avoid_copies)\n        return postings_arr"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        postings_arr = cls(array, tokenizer=tokenizer, avoid_copies=avoid_copies)\n        return postings_arr"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        postings_arr = SearchArray([], tokenizer=tokenizer, avoid_copies=avoid_copies)\n\n        if truncate:\n            array = array[:batch_size]\n\n        for i in range(0, len(array), batch_size):\n            batch = array[i:i + batch_size]\n            postings_arr = postings_arr._index_batch(batch)\n\n        return postings_arr"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if truncate:\n            array = array[:batch_size]\n\n        postings_arr = cls([], tokenizer=tokenizer, avoid_copies=avoid_copies)\n\n        for i in range(0, len(array), batch_size):\n            batch = array[i:i + batch_size]\n            postings_arr = cls._append_batch(postings_arr, batch, tokenizer)\n\n        return postings_arr"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if truncate:\n            array = array[:batch_size]\n\n        postings_arr = cls([], tokenizer=tokenizer, avoid_copies=avoid_copies)\n\n        for i in range(0, len(array), batch_size):\n            batch = array[i:i + batch_size]\n            postings_arr = cls._index_batch(postings_arr, batch, tokenizer)\n\n        return postings_arr"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        term_mat = []\n        posns = []\n        term_dict = set()\n        doc_lens = []\n\n        if truncate:\n            array = array[:batch_size]\n\n        for batch in range(0, len(array), batch_size):\n            batch_data = array[batch:batch + batch_size]\n            indexed_data = build_index_from_tokenizer(batch_data, tokenizer)\n            term_mat.extend(indexed_data[0])\n            posns.extend(indexed_data[1])\n            term_dict.update(indexed_data[2])\n            doc_lens.extend(indexed_data[4])\n\n        return cls(term_mat, tokenizer=tokenizer, avoid_copies=avoid_copies)"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if truncate:\n            array = array[:batch_size]\n\n        postings_arr = cls(array, tokenizer=tokenizer, avoid_copies=avoid_copies)\n        return postings_arr"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        term_mat, posns, term_dict, avg_doc_length, doc_lens = build_index_from_tokenizer(\n            array, tokenizer, truncate=truncate, batch_size=batch_size\n        )\n        return cls([], avoid_copies=avoid_copies).from_index(\n            term_mat, posns, term_dict, avg_doc_length, doc_lens, tokenizer\n        )"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if truncate:\n            array = array[:batch_size]\n\n        postings_arr = cls(array, tokenizer=tokenizer, avoid_copies=avoid_copies)\n        return postings_arr"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "\n        if truncate:\n            array = array[:batch_size]\n\n        postings_arr = cls(array, tokenizer=tokenizer, avoid_copies=avoid_copies)\n        return postings_arr"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['serverHost'], self.config['serverPort'])\n        self.connections = {}\n        self.lock = threading.Lock()\n        self.server.start()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['serverHost'], self.config['serverPort'])\n        self.connections = {}\n        self.lock = threading.Lock()\n        self.server.start()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server((self.config['serverHost'], self.config['serverPort']))\n        self.server.set_strategy(get_strategy(self.config['strategy'], self.config['strategies']))\n        self.server.start()\n        self.connections = {}\n        self.lock = threading.Lock()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server((self.config['serverHost'], self.config['serverPort']))\n        self.server.start()\n        self.connections = {}\n        self.lock = threading.Lock()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(host=self.config['serverHost'], port=self.config['serverPort'])\n        self.connections = {}\n        self.lock = threading.Lock()\n        self.server.start()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['serverHost'], self.config['serverPort'], self.logger)\n        self.connections = {}\n        self.lock = threading.Lock()\n        self.server.start()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['serverHost'], self.config['serverPort'])\n        self.connections = {}\n        self.lock = threading.Lock()\n        self.server.start()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['serverHost'], self.config['serverPort'])\n        self.connections = {}\n        self.lock = threading.Lock()\n        self.server.start()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['serverHost'], self.config['serverPort'])\n        self.connections = {}\n        self.lock = threading.Lock()\n        self.server.start()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['serverHost'], self.config['serverPort'])\n        self.connections = {}\n        self.lock = threading.Lock()\n        self.server.start()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['serverHost'], self.config['serverPort'])\n        self.connections = {}\n        self.lock = threading.Lock()\n        self.server.start()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['serverHost'], self.config['serverPort'])\n        self.server.start()\n        self.connections = {}\n        self.lock = threading.Lock()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['serverHost'], self.config['serverPort'])\n        self.connections = {}\n        self.lock = threading.Lock()\n        self.server.start()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "    def __init__(self, config: dict, logger: logging.Logger):\n        self.config = self.default_config()\n        self.config.update(config)\n        self.logger = logger\n\n        self.server = Server(self.config['serverHost'], self.config['serverPort'], self.logger)\n        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.server.start()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['serverHost'], self.config['serverPort'])\n        self.connections = {}\n        self.lock = threading.Lock()\n        self.server.start()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server((self.config['serverHost'], self.config['serverPort']))\n        self.connections = {}\n        self.lock = threading.Lock()\n        self.server.start()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['serverHost'], self.config['serverPort'])\n        self.connections = {}\n        self.lock = threading.Lock()\n        self.server.start()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(\n            host=self.config['serverHost'],\n            port=self.config['serverPort'],\n            strategy=get_strategy(self.config['strategy'], self.config['strategies']),\n            logger=self.logger,\n        )\n        self.connections = {}\n        self.lock = threading.Lock()\n        self.server.start()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['serverHost'], self.config['serverPort'])\n        self.server.start()\n        self.connections = {}\n        self.lock = threading.Lock()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['serverHost'], self.config['serverPort'])\n        self.connections = {}\n        self.lock = threading.Lock()\n        self.server.start()"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr = arr - ((arr >> _1) & s55)\n    arr = (arr & s33) + ((arr >> _2) & s33)\n    arr = (arr + (arr >> _4)) & s0F\n    arr = (arr * s01) >> all_but_one_bit\n    return arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr = arr - ((arr >> _1) & s55)\n    arr = (arr & m1) + ((arr >> _1) & m1)\n    arr = (arr & m2) + ((arr >> _2) & m2)\n    arr = (arr + (arr >> _4)) & s0F\n    arr = arr * s01\n    return arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & m1) + ((arr >> _1) & m1)\n    arr = (arr & m2) + ((arr >> _2) & m2)\n    arr = (arr + (arr >> _4)) & s0F\n    arr *= s01\n    return arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr = arr - ((arr >> _1) & s55)\n    arr = (arr & s33) + ((arr >> _2) & s33)\n    arr = (arr + (arr >> _4)) & s0F\n    arr = (arr * s01) >> all_but_one_bit\n    return arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & m1) + ((arr >> _1) & m1)\n    arr = (arr & m2) + ((arr >> _2) & m2)\n    arr = (arr + (arr >> _4)) & s0F\n    arr *= s01\n    arr >>= all_but_one_bit\n    return arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr = arr - ((arr >> _1) & s55)\n    arr = (arr & m1) + ((arr >> _1) & m1)\n    arr = (arr + (arr >> _2)) & m2\n    arr = (arr + (arr >> _4)) & m3\n    arr = (arr * s01) >> all_but_one_bit\n    return arr.astype(int)"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & m1) + ((arr >> _1) & m1)\n    arr = (arr & m2) + ((arr >> _2) & m2)\n    arr = (arr + (arr >> _4)) & s0F\n    arr *= s01\n    return arr >> all_but_one_bit"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & m1) + ((arr >> _1) & m1)\n    arr = (arr & m2) + ((arr >> _2) & m2)\n    arr = (arr + (arr >> _4)) & s0F\n    arr *= s01\n    return arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & m1) + ((arr >> _1) & m1)\n    arr = (arr & m2) + ((arr >> _2) & m2)\n    arr = (arr + (arr >> _4)) & s0F\n    arr *= s01\n    return arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr = arr - ((arr >> _1) & s55)\n    arr = (arr & m1) + ((arr >> _2) & m1)\n    arr = (arr + (arr >> _4)) & s0F\n    return (arr * s01) >> all_but_one_bit"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr = arr - ((arr >> _1) & s55)\n    arr = (arr & m1) + ((arr >> _2) & m1)\n    arr = (arr + (arr >> _4)) & m3\n    arr = (arr * s01) >> all_but_one_bit\n    return arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & m1) + ((arr >> _1) & m1)\n    arr = (arr & m2) + ((arr >> _2) & m2)\n    arr = (arr + (arr >> _4)) & s0F\n    arr = (arr * s01) >> all_but_one_bit\n    return arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr = arr - ((arr >> _1) & s55)\n    arr = (arr & m1) + ((arr >> _2) & m1)\n    arr = (arr + (arr >> _4)) & s0F\n    arr = (arr * s01) >> all_but_one_bit\n    return arr.astype(int)"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & m1) + ((arr >> _1) & m1)\n    arr = (arr & m2) + ((arr >> _2) & m2)\n    arr = (arr + (arr >> _4)) & m3\n    arr += arr >> _8\n    arr += arr >> _16\n    arr += arr >> _32\n    arr = arr & mask\n    return arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "\n    arr -= (arr >> _1) & s55\n    arr = (arr & m1) + ((arr >> _2) & m1)\n    arr = (arr + (arr >> _4)) & s0F\n    arr += arr >> _8\n    arr += arr >> _16\n    arr += arr >> _32\n    arr &= s01\n\n    return arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr = arr - ((arr >> _1) & s55)\n    arr = (arr & m1) + ((arr >> _2) & m1)\n    arr = (arr + (arr >> _4)) & s0F\n    arr = (arr * s01) >> all_but_one_bit\n    return arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & m1) + ((arr >> _1) & m1)\n    arr = (arr & m2) + ((arr >> _2) & m2)\n    arr = (arr + (arr >> _4)) & s0F\n    arr *= s01\n    arr >>= all_but_one_bit\n    return arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & m1) + ((arr >> _1) & m1)\n    arr = (arr & m2) + ((arr >> _2) & m2)\n    arr = (arr + (arr >> _4)) & s0F\n    arr *= s01\n    arr >>= all_but_one_bit\n    return arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & m1) + ((arr >> _1) & m1)\n    arr = (arr & m2) + ((arr >> _2) & m2)\n    arr = (arr + (arr >> _4)) & s0F\n    arr *= s01\n    return arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr = arr - ((arr >> _1) & s55)\n    arr = (arr & m1) + ((arr >> _2) & m1)\n    arr = (arr + (arr >> _4)) & s0F\n    arr = (arr * s01) >> all_but_one_bit\n    return arr"}
{"namespace": "searcharray.solr.edismax", "completion": "    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    # Parse query terms\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    # If mm is not provided, set it based on the query operator\n    if mm is None:\n        mm = \"100%\" if q_op == \"OR\" else \"0%\"\n\n    # Perform edismax search based on term-centric or field-centric approach\n    if term_centric:\n        return _edismax_term_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n    query_fields = parse_field_boosts(qf)\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n    \n    if term_centric:\n        return _edismax_term_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, {field: 1 for field in qf}, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, {field: 1 for field in qf}, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n    query_fields = parse_field_boosts(qf)\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            connection = self._get_connection(message)\n            message.data = connection.c2s(message.data)\n        elif isinstance(message, RecvMessage):\n            connection = self._get_connection(message)\n            message.data = connection.s2c(message.data)\n        elif isinstance(message, CloseMessage):\n            self._handle_connection_close_message(message)"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            connection = self._get_connection(message)\n            connection.c2s(message.data)\n        elif isinstance(message, RecvMessage):\n            connection = self._get_connection(message)\n            connection.s2c(message.data)\n        elif isinstance(message, CloseMessage):\n            self._handle_connection_close_message(message)"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            connection = self._get_connection(message)\n            message.data = connection.c2s(message.data)\n        elif isinstance(message, RecvMessage):\n            connection = self._get_connection(message)\n            message.data = connection.s2c(message.data)\n        elif isinstance(message, CloseMessage):\n            self._handle_connection_close_message(message)"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "\n        if isinstance(message, SendMessage):\n            connection = self._get_connection(message)\n            message.data = connection.c2s(message.data)\n\n        elif isinstance(message, RecvMessage):\n            connection = self._get_connection(message)\n            message.data = connection.s2c(message.data)\n\n        elif isinstance(message, CloseMessage):\n            self._handle_connection_close_message(message)"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "\n        if isinstance(message, SendMessage):\n            connection = self._get_connection(message)\n            message.data = connection.c2s(message.data)\n        elif isinstance(message, RecvMessage):\n            connection = self._get_connection(message)\n            message.data = connection.s2c(message.data)\n        elif isinstance(message, CloseMessage):\n            self._handle_connection_close_message(message)"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            connection = self._get_connection(message)\n            connection.c2s(message.data)\n        elif isinstance(message, RecvMessage):\n            connection = self._get_connection(message)\n            connection.s2c(message.data)\n        elif isinstance(message, CloseMessage):\n            self._handle_connection_close_message(message)"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            connection = self._get_connection(message)\n            message.data = connection.c2s(message.data)\n        elif isinstance(message, RecvMessage):\n            connection = self._get_connection(message)\n            message.data = connection.s2c(message.data)\n        elif isinstance(message, CloseMessage):\n            self._handle_connection_close_message(message)"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if message.type == MessageType.SEND:\n            connection = self._get_connection(message)\n            message.data = connection.c2s(message.data)\n        elif message.type == MessageType.RECV:\n            connection = self._get_connection(message)\n            message.data = connection.s2c(message.data)\n        elif message.type == MessageType.CLOSE:\n            self._handle_connection_close_message(message)"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            connection = self._get_connection(message)\n            message.data = connection.c2s(message.data)\n        elif isinstance(message, RecvMessage):\n            connection = self._get_connection(message)\n            message.data = connection.s2c(message.data)\n        elif isinstance(message, CloseMessage):\n            self._handle_connection_close_message(message)"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            connection = self._get_connection(message)\n            connection.c2s(message.data)\n        elif isinstance(message, RecvMessage):\n            connection = self._get_connection(message)\n            connection.s2c(message.data)\n        elif isinstance(message, CloseMessage):\n            self._handle_connection_close_message(message)"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "\n        if isinstance(message, SendMessage):\n            connection = self._get_connection(message)\n            message.data = connection.c2s(message.data)\n        elif isinstance(message, RecvMessage):\n            connection = self._get_connection(message)\n            message.data = connection.s2c(message.data)\n        elif isinstance(message, CloseMessage):\n            self._handle_connection_close_message(message)"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            connection = self._get_connection(message)\n            message.data = connection.c2s(message.data)\n        elif isinstance(message, RecvMessage):\n            connection = self._get_connection(message)\n            message.data = connection.s2c(message.data)\n        elif isinstance(message, CloseMessage):\n            self._handle_connection_close_message(message)"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if message.type == MessageType.SEND:\n            connection = self._get_connection(message)\n            connection.c2s(message)\n        elif message.type == MessageType.RECV:\n            connection = self._get_connection(message)\n            connection.s2c(message)\n        elif message.type == MessageType.CLOSE:\n            self._handle_connection_close_message(message)"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            connection = self._get_connection(message)\n            message.data = connection.c2s(message.data)\n        elif isinstance(message, RecvMessage):\n            connection = self._get_connection(message)\n            message.data = connection.s2c(message.data)\n        elif isinstance(message, CloseMessage):\n            self._handle_connection_close_message(message)"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "\n        if message.type == MessageType.SEND:\n            connection = self._get_connection(message)\n            connection.c2s(message.data)\n        elif message.type == MessageType.RECV:\n            connection = self._get_connection(message)\n            connection.s2c(message.data)\n        elif message.type == MessageType.CLOSE:\n            self._handle_connection_close_message(message)"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            connection = self._get_connection(message)\n            message.data = connection.c2s(message.data)\n        elif isinstance(message, RecvMessage):\n            connection = self._get_connection(message)\n            message.data = connection.s2c(message.data)\n        elif isinstance(message, CloseMessage):\n            self._handle_connection_close_message(message)"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            connection = self._get_connection(message)\n            message.data = connection.c2s(message.data)\n        elif isinstance(message, RecvMessage):\n            connection = self._get_connection(message)\n            message.data = connection.s2c(message.data)\n        elif isinstance(message, CloseMessage):\n            self._handle_connection_close_message(message)"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            connection = self._get_connection(message)\n            message.data = connection.c2s(message.data)\n        elif isinstance(message, RecvMessage):\n            connection = self._get_connection(message)\n            message.data = connection.s2c(message.data)\n        elif isinstance(message, CloseMessage):\n            self._handle_connection_close_message(message)"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "\n        if isinstance(message, SendMessage):\n            connection = self._get_connection(message)\n            message.data = connection.c2s(message.data)\n\n        elif isinstance(message, RecvMessage):\n            connection = self._get_connection(message)\n            message.data = connection.s2c(message.data)\n\n        elif isinstance(message, CloseMessage):\n            self._handle_connection_close_message(message)"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "\n        if message.type == MessageType.SEND:\n            connection = self._get_connection(message)\n            connection.c2s(message)\n        elif message.type == MessageType.RECV:\n            connection = self._get_connection(message)\n            connection.s2c(message)\n        elif message.type == MessageType.CLOSE:\n            self._handle_connection_close_message(message)"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection_id, connection in list(self.connections.items()):\n                self.logger.info('Connection %s is being closed due to destroy event.', connection.id)\n                connection.stop()\n                self.connections.pop(connection_id)\n            if self.server:\n                self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection_id, connection in list(self.connections.items()):\n                connection.stop()\n                del self.connections[connection_id]\n\n        if self.server:\n            self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection_id, connection in list(self.connections.items()):\n                connection.stop()\n                del self.connections[connection_id]\n            if self.server:\n                self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection_id, connection in list(self.connections.items()):\n                connection.stop()\n                del self.connections[connection_id]\n\n        if self.server:\n            self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection_id, connection in self.connections.items():\n                connection.stop()\n            self.connections.clear()\n\n        if self.server:\n            self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection_id, connection in list(self.connections.items()):\n                self.logger.info('Connection %s is being closed due to destroy event.', connection.id)\n                connection.stop()\n                self.connections.pop(connection_id)\n            if self.server:\n                self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection_id, connection in list(self.connections.items()):\n                connection.stop()\n                del self.connections[connection_id]\n            \n            if self.server:\n                self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection_id, connection in list(self.connections.items()):\n                if connection.is_alive():\n                    connection.stop()\n                    del self.connections[connection_id]\n            if self.server:\n                self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection_id, connection in list(self.connections.items()):\n                connection.stop()\n                del self.connections[connection_id]\n            if self.server:\n                self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection_id, connection in list(self.connections.items()):\n                self.logger.info('Connection %s is being closed during destroy.', connection.id)\n                connection.stop()\n                self.connections.pop(connection_id)\n\n        if self.server:\n            self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection_id, connection in list(self.connections.items()):\n                connection.stop()\n                del self.connections[connection_id]\n            if self.server:\n                self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection_id, connection in list(self.connections.items()):\n                connection.stop()\n                del self.connections[connection_id]\n            if self.server:\n                self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection_id, connection in self.connections.items():\n                connection.stop()\n            self.connections.clear()\n            if self.server:\n                self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection_id, connection in list(self.connections.items()):\n                connection.stop()\n                del self.connections[connection_id]\n            if self.server:\n                self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection_id, connection in self.connections.items():\n                connection.stop()\n            self.connections.clear()\n            if self.server is not None:\n                self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection_id, connection in list(self.connections.items()):\n                connection.stop()\n                del self.connections[connection_id]\n            \n            if self.server:\n                self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection_id, connection in list(self.connections.items()):\n                connection.stop()\n                del self.connections[connection_id]\n            if self.server:\n                self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection_id, connection in self.connections.items():\n                connection.stop()\n            self.connections.clear()\n\n        if self.server:\n            self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection_id, connection in list(self.connections.items()):\n                connection.stop()\n                del self.connections[connection_id]\n            if self.server:\n                self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection_id, connection in list(self.connections.items()):\n                connection.stop()\n                del self.connections[connection_id]\n\n        if self.server:\n            self.server.stop()"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if cov.ndim != 2:\n        raise ValueError(\"`cov` must be a 2D array\")\n\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    return corr, std"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if cov.ndim != 2:\n        raise ValueError(\"Covariance matrix must be a 2D array\")\n\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    return corr, std"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if cov.ndim != 2:\n        raise ValueError(\"`cov` must be a 2D array\")\n\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    \n    return corr, std"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if cov.ndim != 2:\n        raise ValueError(\"`cov` must be a 2D array\")\n    \n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    \n    return corr, std"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if cov.ndim != 2:\n        raise ValueError(\"`cov` must be a 2D array\")\n\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n\n    return corr, std"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if cov.ndim != 2:\n        raise ValueError(\"`cov` must be a 2D array\")\n    \n    std = np.sqrt(np.diag(cov))\n    corr = cov / (std[:, None] * std[None, :])\n    \n    return corr, std"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if cov.ndim != 2:\n        raise ValueError(\"`cov` must be a 2D array\")\n\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    return corr, std"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if cov.ndim != 2:\n        raise ValueError(\"`cov` must be a 2D array\")\n\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n\n    return corr, std"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if cov.ndim != 2:\n        raise ValueError(\"`cov` must be a 2D array\")\n\n    std = np.sqrt(np.diag(cov))\n    corr = cov / (std[:, None] * std[None, :])\n\n    return corr, std"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if cov.ndim != 2:\n        raise ValueError(\"`cov` must be a 2D array\")\n    \n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    \n    return corr, std"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if cov.ndim != 2:\n        raise ValueError(\"`cov` must be a 2D array\")\n\n    std = np.sqrt(np.diag(cov))\n    corr = cov / (std[:, None] * std)\n    return corr, std"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if cov.ndim != 2:\n        raise ValueError(\"`cov` must be a 2D array\")\n\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    return corr, std"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if cov.ndim != 2:\n        raise ValueError(\"`cov` must be a 2D array\")\n\n    std = np.sqrt(np.diag(cov))\n    std = np.atleast_2d(std).T\n    corr = cov / (std @ std.T)\n    return corr, std.flatten()"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if cov.ndim != 2:\n        raise ValueError(\"`cov` must be a 2D array\")\n\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    return corr, std"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if cov.ndim != 2:\n        raise ValueError(\"`cov` must be a 2D array\")\n\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    return corr, std"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if cov.ndim != 2:\n        raise ValueError(\"`cov` must be a 2D array\")\n    \n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    \n    return corr, std"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if cov.ndim != 2:\n        raise ValueError(\"`cov` must be a 2D array\")\n\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    np.fill_diagonal(corr, 1.0)  # Ensure diagonal elements are 1\n    return corr, std"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if cov.ndim != 2:\n        raise ValueError(\"`cov` must be a 2D array\")\n\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n\n    return corr, std"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if cov.ndim != 2:\n        raise ValueError(\"`cov` must be a 2D array\")\n\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    \n    return corr, std"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if cov.ndim != 2:\n        raise ValueError(\"`cov` must be a 2D array\")\n\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    return corr, std"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix diagonal elements must be close to zero\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix diagonal elements should be close to zero\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix diagonal elements must be close to zero\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix diagonal elements should be close to zero\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix diagonal elements should be close to zero\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix diagonal elements must be close to zero\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix must have close-to-zero diagonal elements\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix must have zeros on its diagonal\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix diagonal elements should be close to zero\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix diagonal elements must be close to zero\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            model = self.initialized_functions[func_hash][\"model\"]\n            save_to_finetune = False\n            is_distilled_model = False\n            prompt = self.construct_prompt(function_description.name, args, kwargs, self.initialized_functions[func_hash][\"examples\"], model)\n        else:\n            # Get the teacher and distilled models\n            teacher_models, distilled_models = self.function_modeler.get_models(function_description)\n\n            # Check if the inputs are suitable for distillation\n            suitable_for_distillation = self.suitable_for_finetuning_token_check(args, kwargs, function_description.name, distilled_models[0])\n\n            # Choose the appropriate model based on token count and suitability for distillation\n            if suitable_for_distillation:\n                model = distilled_models[0]\n                save_to_finetune = False\n                is_distilled_model = True\n                prompt = self.construct_prompt(function_description.name, args, kwargs, [], model)\n            else:\n                model = self.choose_model_from_tokens(teacher_models, approximate_token_count(str(args) + str(kwargs)), 0)\n                save_to_finetune = True\n                is_distilled_model = False\n                prompt = self.construct_prompt(function_description.name, args, kwargs, self.function_modeler.get_symbolic_alignments(func_hash), model)\n\n            # Initialize function-specific data\n            self.initialized_functions[func_hash] = {\"model\": model, \"examples\": []}\n\n        return prompt, model, save_to_finetune, is_distilled_model"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            prompt = self.construct_prompt(function_description.name, args, kwargs, self.initialized_functions[func_hash][\"examples\"], self.initialized_functions[func_hash][\"model\"])\n            model = self.function_modeler.get_model_by_name(self.initialized_functions[func_hash][\"model\"])\n            suitable_for_distillation = False\n            already_initialized = True\n        else:\n            # Check if the function is suitable for distillation\n            distilled_model = self.function_modeler.get_distilled_model(function_description)\n            suitable_for_distillation, input_prompt_token_count = self.suitable_for_finetuning_token_check(args, kwargs, function_description.name, distilled_model)\n\n            # If suitable for distillation, use the distilled model\n            if suitable_for_distillation:\n                prompt = self.construct_prompt(function_description.name, args, kwargs, [], distilled_model)\n                model = distilled_model\n                already_initialized = False\n            # If not suitable for distillation, use the teacher model for fine-tuning\n            else:\n                teacher_models = self.function_modeler.get_models(function_description)[1]\n                model = self.choose_model_from_tokens(teacher_models, input_prompt_token_count, 0)\n                prompt = self.construct_prompt(function_description.name, args, kwargs, [], model)\n                already_initialized = False\n\n        return prompt, model, suitable_for_distillation, already_initialized"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            # Function is already initialized, no need to save examples for fine-tuning\n            save_to_finetune = False\n            is_distilled_model = False\n        else:\n            # Function is not initialized, need to save examples for fine-tuning\n            save_to_finetune = True\n            is_distilled_model = True\n\n        # Check if the inputs are suitable for distillation\n        suitable_for_distillation, input_token_count = self.suitable_for_finetuning_token_check(args, kwargs, function_description.name, self.function_modeler.get_distilled_model(function_description))\n        \n        # Choose the appropriate model based on suitability for distillation and token count\n        if suitable_for_distillation:\n            model = self.function_modeler.get_distilled_model(function_description)\n            prompt = self.construct_prompt(function_description.name, args, kwargs, [], model)\n        else:\n            teacher_models = self.function_modeler.get_models(function_description)[0]\n            model = self.choose_model_from_tokens(teacher_models, input_token_count, 0)\n            prompt = self.construct_prompt(function_description.name, args, kwargs, self.function_modeler.get_symbolic_alignments(func_hash, max=5), model)\n\n        return prompt, model, save_to_finetune, is_distilled_model"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            initialized = True\n        else:\n            initialized = False\n\n        # Get the function-specific data\n        if not initialized:\n            self.initialized_functions[func_hash] = {\n                \"examples\": [],\n                \"model\": \"\"\n            }\n\n        # Check if the function is suitable for distillation\n        distilled_model = self.function_modeler.get_models(function_description)[0]\n        suitable_for_distillation, input_token_count = self.suitable_for_finetuning_token_check(args, kwargs, function_description, distilled_model)\n\n        # Choose the appropriate model based on the token count\n        if suitable_for_distillation:\n            model = distilled_model\n        else:\n            teacher_models = self.function_modeler.get_models(function_description)[1]\n            model = self.choose_model_from_tokens(teacher_models, input_token_count)\n\n        # Construct the prompt for generation\n        prompt = self.construct_prompt(function_description.name, args, kwargs, self.initialized_functions[func_hash][\"examples\"], model)\n\n        return prompt, model, suitable_for_distillation, initialized"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            current_function_setup = self.initialized_functions[func_hash]\n            model = self.api_provider[current_function_setup[\"model\"]]\n            is_distilled_model = False\n        else:\n            # Get the teacher and distilled models\n            teacher_models, distilled_models = self.function_modeler.get_models(function_description)\n            # Check if the inputs are suitable for distillation\n            suitable_for_distillation, input_prompt_token_count = self.suitable_for_finetuning_token_check(args, kwargs, function_description.name, distilled_models[0])\n            # Choose the appropriate model based on token count and suitability for distillation\n            model = self.choose_model_from_tokens(teacher_models, input_prompt_token_count, 0) if suitable_for_distillation else distilled_models[0]\n            is_distilled_model = not suitable_for_distillation\n            # Initialize function-specific data\n            self.initialized_functions[func_hash] = {\"model\": model.model_name, \"examples\": []}\n\n        # Construct the prompt for generation\n        prompt = self.construct_prompt(function_description.name, args, kwargs, self.initialized_functions[func_hash][\"examples\"], model)\n        return prompt, model, is_distilled_model, func_hash in self.initialized_functions"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # check if function is already initialized\n        if func_hash in self.initialized_functions:\n            current_function_setup = self.initialized_functions[func_hash]\n            model = BaseModelConfig(model_name=current_function_setup[\"model\"])\n            save_to_finetune = False\n            is_distilled_model = False\n        else:\n            # check if the function is suitable for distillation\n            distilled_model, suitable_for_distillation = self.function_modeler.get_distilled_model(function_description)\n            if suitable_for_distillation:\n                model = distilled_model\n                save_to_finetune = False\n                is_distilled_model = True\n            else:\n                # check if the inputs are suitable for fine-tuning\n                suitable_for_finetune, input_prompt_token_count = self.suitable_for_finetuning_token_check(args, kwargs, function_description, distilled_model)\n                if suitable_for_finetune:\n                    model = self.function_modeler.get_teacher_model(function_description)\n                    save_to_finetune = True\n                    is_distilled_model = False\n                    # update examples for fine-tuning\n                    self.function_modeler.update_finetune_examples(func_hash, function_description, input_prompt_token_count)\n                else:\n                    raise ValueError(\"Inputs are not suitable for distillation or fine-tuning\")\n        prompt = self.construct_prompt(function_description.name, args, kwargs, [], model)\n        return prompt, model, save_to_finetune, is_distilled_model"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            current_function_setup = self.initialized_functions[func_hash]\n            model = self.api_provider[current_function_setup[\"model\"]]\n            save_to_finetune = False\n            is_distilled_model = False\n        else:\n            # check if the function is suitable for distillation\n            suitable_for_distillation = self.function_modeler.check_suitability_for_distillation(function_description, args, kwargs)\n            if suitable_for_distillation:\n                model = self.function_modeler.get_distilled_model(function_description)\n                save_to_finetune = False\n                is_distilled_model = True\n            else:\n                teacher_models = self.function_modeler.get_models(function_description)[1]\n                model = self.choose_model_from_tokens(teacher_models, approximate_token_count(f\"{function_description.name} {args} {kwargs}\"), 0)\n                save_to_finetune = True\n                is_distilled_model = False\n\n            # initialize function-specific data\n            self.initialized_functions[func_hash] = {\n                \"model\": model.model_name,\n                \"examples\": None\n            }\n\n        # construct the prompt\n        prompt = self.construct_prompt(function_description.name, args, kwargs, self.initialized_functions[func_hash][\"examples\"], model)\n\n        return prompt, model, save_to_finetune, is_distilled_model"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            model = self.initialized_functions[func_hash][\"model\"]\n            save_to_finetune = False\n            is_distilled_model = False\n        else:\n            # Check if the function is suitable for distillation\n            distilled_model = self.function_modeler.get_models(function_description)[0]\n            suitable_for_distillation, input_prompt_token_count = self.suitable_for_finetuning_token_check(args, kwargs, function_description.name, distilled_model)\n            if suitable_for_distillation:\n                model = distilled_model\n                save_to_finetune = False\n                is_distilled_model = True\n            else:\n                # Choose a teacher model for fine-tuning\n                teacher_models = self.function_modeler.get_models(function_description)[1]\n                model = self.choose_model_from_tokens(teacher_models, input_prompt_token_count)\n                save_to_finetune = True\n                is_distilled_model = False\n                # Update function-specific data for fine-tuning\n                self.function_modeler.update_function_examples(function_description, args, kwargs, input_prompt_token_count)\n\n        # Construct the prompt\n        prompt = self.construct_prompt(function_description.name, args, kwargs, self.function_modeler.get_symbolic_alignments(func_hash, max=5), model)\n\n        return prompt, model, save_to_finetune, is_distilled_model"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            model = self.initialized_functions[func_hash][\"model\"]\n            save_to_finetune = False\n            is_distilled_model = False\n        else:\n            # Check if the function is suitable for distillation\n            distilled_model = self.function_modeler.get_distilled_model(function_description)\n            suitable_for_distillation, input_prompt_token_count = self.suitable_for_finetuning_token_check(args, kwargs, function_description, distilled_model)\n            if suitable_for_distillation:\n                model = distilled_model\n                save_to_finetune = False\n                is_distilled_model = True\n            else:\n                # Choose a teacher model for fine-tuning\n                teacher_models = self.function_modeler.get_models(function_description)[1]\n                model = self.choose_model_from_tokens(teacher_models, input_prompt_token_count)\n                save_to_finetune = True\n                is_distilled_model = False\n                # Initialize function-specific data\n                self.initialized_functions[func_hash] = {\"model\": model.model_name, \"examples\": []}\n\n        # Construct prompt for generation\n        prompt = self.construct_prompt(function_description.name, args, kwargs, self.initialized_functions[func_hash][\"examples\"], model)\n\n        return prompt, model, save_to_finetune, is_distilled_model"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            model = self.initialized_functions[func_hash][\"model\"]\n            save_to_finetune = False\n            is_distilled_model = False\n            examples = self.function_modeler.get_symbolic_alignments(func_hash)\n            prompt = self.construct_prompt(function_description.name, args, kwargs, examples, model)\n        else:\n            # Get the teacher and distilled models\n            teacher_models, distilled_models = self.function_modeler.get_models(function_description)\n            suitable_for_finetune, input_prompt_token_count = self.suitable_for_finetuning_token_check(args, kwargs, function_description.name, distilled_models[0])\n\n            if suitable_for_finetune:\n                model = teacher_models[0]\n                save_to_finetune = True\n                is_distilled_model = False\n                prompt = self.construct_prompt(function_description.name, args, kwargs, [], model)\n            else:\n                model = distilled_models[0]\n                save_to_finetune = False\n                is_distilled_model = True\n                examples = self.function_modeler.get_symbolic_alignments(func_hash)\n                prompt = self.construct_prompt(function_description.name, args, kwargs, examples, model)\n\n            # Initialize the function if not already done\n            if func_hash not in self.initialized_functions:\n                self.initialized_functions[func_hash] = {\"model\": model.model_name, \"examples\": examples}\n\n        return prompt, model, save_to_finetune, is_distilled_model"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            current_function_setup = self.initialized_functions[func_hash]\n            model = self.api_provider[current_function_setup[\"model\"]]\n            is_distilled_model = False\n            suitable_for_finetune = False\n        else:\n            # Get the suitable model for distillation\n            model, is_distilled_model = self.function_modeler.get_distilled_model(function_description)\n            if is_distilled_model:\n                suitable_for_finetune = False\n            else:\n                # Check if the inputs are suitable for fine-tuning\n                suitable_for_finetune, input_prompt_token_count = self.suitable_for_finetuning_token_check(args, kwargs, function_description, model)\n                if suitable_for_finetune:\n                    # Construct the prompt for fine-tuning\n                    prompt = self.construct_prompt(function_description.name, args, kwargs, function_description.examples, model)\n                    # Update the function-specific data for fine-tuning\n                    self.function_modeler.update_function_specific_data(function_description.__hash__(), function_description, prompt, model.model_name)\n                else:\n                    prompt = None\n        return prompt, model, suitable_for_finetune, is_distilled_model"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            model = self.initialized_functions[func_hash][\"model\"]\n            is_distilled_model = False\n            save_to_finetune = False\n            prompt = self.construct_prompt(function_description.name, args, kwargs, self.initialized_functions[func_hash][\"examples\"], model)\n        else:\n            # Get the suitable model for distillation\n            distilled_model = self.function_modeler.get_models(function_description)[0]\n            suitable_for_finetune, input_prompt_token_count = self.suitable_for_finetuning_token_check(args, kwargs, function_description.name, distilled_model)\n            if suitable_for_finetune:\n                model = distilled_model\n                is_distilled_model = True\n                save_to_finetune = True\n            else:\n                teacher_models = self.function_modeler.get_models(function_description)[1]\n                model = self.choose_model_from_tokens(teacher_models, input_prompt_token_count)\n                is_distilled_model = False\n                save_to_finetune = False\n            prompt = self.construct_prompt(function_description.name, args, kwargs, [], model)\n\n            # Initialize function-specific data\n            self.initialized_functions[func_hash] = {\"model\": model, \"examples\": []}\n\n        return prompt, model, save_to_finetune, is_distilled_model"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            model = self.initialized_functions[func_hash][\"model\"]\n            save_to_finetune = False\n            is_distilled_model = False\n        else:\n            # Check if the function is suitable for distillation\n            distilled_model = self.function_modeler.get_models(function_description)[0]\n            suitable_for_distillation, input_prompt_token_count = self.suitable_for_finetuning_token_check(args, kwargs, function_description, distilled_model)\n            \n            if suitable_for_distillation:\n                model = distilled_model\n                save_to_finetune = False\n                is_distilled_model = True\n            else:\n                teacher_models = self.function_modeler.get_models(function_description)[1]\n                model = self.choose_model_from_tokens(teacher_models, input_prompt_token_count)\n                save_to_finetune = True\n                is_distilled_model = False\n                if model:\n                    prompt = self.construct_prompt(function_description.name, args, kwargs, [], model)\n                    self.initialized_functions[func_hash] = {\"model\": model.model_name, \"examples\": []}\n                else:\n                    raise ValueError(\"No suitable model found for fine-tuning\")\n        \n        return prompt, model, save_to_finetune, is_distilled_model"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            current_function_setup = self.initialized_functions[func_hash]\n            model = self.api_provider[current_function_setup[\"model\"]]\n            is_distilled_model = False\n            save_to_finetune = False\n        else:\n            # get the suitable model for distillation\n            model, is_distilled_model = self.function_modeler.get_suitable_model(function_description)\n            save_to_finetune, _ = self.suitable_for_finetuning_token_check(args, kwargs, function_description.name, model)\n            self.initialized_functions[func_hash] = {\"model\": model.model_name, \"examples\": []}\n\n        # construct prompt\n        prompt = self.construct_prompt(function_description.name, args, kwargs, self.initialized_functions[func_hash][\"examples\"], model)\n\n        return prompt, model, save_to_finetune, is_distilled_model"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Check if the function is already initialized\n        initialized = func_hash in self.initialized_functions\n\n        # Get the function-specific data if not already done\n        if not initialized:\n            self.initialized_functions[func_hash] = {\n                \"examples\": [],\n                \"model\": \"\"\n            }\n\n        # Check if the function is suitable for distillation\n        distilled_model = self.function_modeler.get_models(function_description)[0]\n\n        # Check if the inputs are suitable for fine-tuning\n        suitable_for_finetune, input_prompt_token_count = self.suitable_for_finetuning_token_check(args, kwargs, function_description, distilled_model)\n\n        # Choose the appropriate model based on suitability for distillation and token count requirements\n        if distilled_model and suitable_for_finetune:\n            model = distilled_model\n            save_to_finetune = True\n        else:\n            teacher_models = self.function_modeler.get_models(function_description)[1]\n            model = self.choose_model_from_tokens(teacher_models, input_prompt_token_count)\n            save_to_finetune = False\n\n        # Construct the prompt to be used for generation\n        prompt = self.construct_prompt(function_description.name, args, kwargs, self.initialized_functions[func_hash][\"examples\"], model)\n\n        return prompt, model, save_to_finetune, distilled_model"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            model = self.function_modeler.get_models(function_description)[0]\n            save_to_finetune, is_distilled_model = self.suitable_for_finetuning_token_check(args, kwargs, function_description, model)\n            prompt = self.construct_prompt(function_description.name, args, kwargs, self.function_modeler.get_symbolic_alignments(func_hash, max=5), model)\n            return prompt, model, save_to_finetune, is_distilled_model\n        else:\n            # initialize the function\n            teacher_model, distilled_model = self.function_modeler.get_models(function_description)\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n            save_to_finetune, is_distilled_model = self.suitable_for_finetuning_token_check(args, kwargs, function_description, teacher_model)\n            prompt = self.construct_prompt(function_description.name, args, kwargs, self.function_modeler.get_symbolic_alignments(func_hash, max=5), teacher_model)\n            return prompt, teacher_model, save_to_finetune, is_distilled_model"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            current_function_setup = self.initialized_functions[func_hash]\n            model = self.api_provider[current_function_setup[\"model\"]]\n            save_to_finetune = False\n            is_distilled_model = False\n        else:\n            # Check if the function is suitable for distillation\n            distilled_model = self.function_modeler.get_models(function_description)[0]\n            suitable_for_distillation, input_prompt_token_count = self.suitable_for_finetuning_token_check(args, kwargs, function_description, distilled_model)\n            if suitable_for_distillation:\n                model = distilled_model\n                save_to_finetune = False\n                is_distilled_model = True\n            else:\n                # Choose a teacher model for fine-tuning\n                teacher_models = self.function_modeler.get_models(function_description)[1]\n                model = self.choose_model_from_tokens(teacher_models, input_prompt_token_count)\n                save_to_finetune = True\n                is_distilled_model = False\n\n            # Initialize function-specific data\n            self.initialized_functions[func_hash] = {\n                \"model\": model.model_name,\n                \"examples\": [],\n                \"input_prompt_token_count\": input_prompt_token_count\n            }\n\n        # Construct the prompt for generation\n        prompt = self.construct_prompt(function_description.name, args, kwargs, self.initialized_functions[func_hash][\"examples\"], model)\n\n        return prompt, model, save_to_finetune, is_distilled_model"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            current_function_setup = self.initialized_functions[func_hash]\n            model = self.api_provider[current_function_setup[\"model\"]]\n            is_distilled_model = False\n            save_to_finetune = False\n        else:\n            # Get the suitable model for the function\n            teacher_models, distilled_models = self.function_modeler.get_models(function_description)\n            suitable_for_distillation = self.function_modeler.is_suitable_for_distillation(function_description, args, kwargs)\n            if suitable_for_distillation and distilled_models:\n                model = distilled_models[0]\n                is_distilled_model = True\n                save_to_finetune, _ = self.suitable_for_finetuning_token_check(args, kwargs, function_description, model)\n            else:\n                model = teacher_models[0]\n                is_distilled_model = False\n                save_to_finetune = False\n            # Initialize function-specific data\n            self.initialized_functions[func_hash] = {\n                \"model\": model.model_name,\n                \"examples\": []\n            }\n        # Construct the prompt\n        prompt = self.construct_prompt(function_description.name, args, kwargs, self.initialized_functions[func_hash][\"examples\"], model)\n        return prompt, model, save_to_finetune, is_distilled_model"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            current_function_setup = self.initialized_functions[func_hash]\n            model = current_function_setup[\"model\"]\n            save_to_finetune = current_function_setup[\"save_to_finetune\"]\n            is_distilled_model = False\n        else:\n            # Get the suitable model for distillation or fine-tuning\n            model, save_to_finetune, is_distilled_model = self.function_modeler.get_suitable_model(function_description, llm_parameters)\n            self.initialized_functions[func_hash] = {\"model\": model, \"save_to_finetune\": save_to_finetune}\n\n        # Construct the prompt for generation\n        prompt = self.construct_prompt(function_description.name, args, kwargs, function_description.examples, model)\n\n        return prompt, model, save_to_finetune, is_distilled_model"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            # Get the model and align statements for the function\n            current_function_setup = self.initialized_functions[func_hash]\n            model = current_function_setup[\"model\"]\n            align_statements = current_function_setup[\"examples\"]\n            is_distilled_model = False\n            suitable_for_finetuning = False\n        else:\n            # Get the teacher and distilled models for the function\n            teacher_models, distilled_models = self.function_modeler.get_models(function_description)\n            # Check if the function is suitable for distillation\n            suitable_for_distillation = self.function_modeler.suitable_for_distillation(function_description)\n            if suitable_for_distillation:\n                model = distilled_models[0]  # Use the distilled model for zero-shot prompting\n                is_distilled_model = True\n                suitable_for_finetuning = False\n            else:\n                # Check if the inputs are suitable for finetuning\n                suitable_for_finetuning, input_prompt_token_count = self.suitable_for_finetuning_token_check(args, kwargs, function_description, teacher_models[0])\n                if suitable_for_finetuning:\n                    model = teacher_models[0]  # Use the teacher model for fine-tuning\n                    is_distilled_model = False\n                else:\n                    raise ValueError(\"Inputs are not suitable for fine-tuning\")\n            # Construct the prompt for the model\n            prompt = self.construct_prompt(function_description.name, args, kwargs, align_statements, model)\n            # Initialize function-specific data\n            self.initialized_functions[func_hash] = {\"model\": model, \"examples\": align_statements}\n        return prompt, model, suitable_for_finetuning, is_distilled_model"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return _nearest_covariance_higham(cov, max_iteration=higham_max_iteration)\n    else:\n        return _nearest_covariance_clipping(cov)"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return _nearest_cov_higham(cov, higham_max_iteration)\n    else:\n        return _nearest_cov_clip_eigenvalues(cov)"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        # Use Higham & Nick (2002) algorithm\n        return _nearest_corr_higham(cov, max_iteration=higham_max_iteration)\n    else:\n        # Clip eigenvalues to ensure positive definiteness\n        return _nearest_corr_clip_eigenvalues(cov)"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return _nearest_cov_higham(cov, higham_max_iteration)\n    else:\n        return _nearest_cov_clip_eigenvalues(cov)"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return _cov_nearest_higham(cov, higham_max_iteration)\n    else:\n        return _cov_nearest_clip_eigenvalues(cov)"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return _nearest_cov_higham(cov, max_iteration=higham_max_iteration)\n    else:\n        return _nearest_cov_clipped(cov)"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return _cov_nearest_higham(cov, higham_max_iteration)\n    else:\n        return _cov_nearest_clipping(cov)"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return _nearest_cov_higham(cov, max_iteration=higham_max_iteration)\n    else:\n        return _nearest_cov_eigenvalue(cov)"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "\n    if higham:\n        # Use Higham & Nick (2002) algorithm\n        return _nearest_corr_higham(cov, max_iteration=higham_max_iteration)\n    else:\n        # Clip eigenvalues to ensure positive definiteness\n        return _nearest_corr_eigenvalue(cov)"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        # Use Higham & Nick (2002) algorithm\n        nearest_cov = _nearest_cov_higham(cov, max_iteration=higham_max_iteration)\n    else:\n        # Clip eigenvalues to ensure positive definiteness\n        nearest_cov = _clip_eigenvalues(cov)\n    return nearest_cov"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        # Use Higham & Nick (2002) algorithm\n        nearest_cov = _nearest_cov_higham(cov, max_iteration=higham_max_iteration)\n    else:\n        # Clip eigenvalues to ensure positive definiteness\n        nearest_cov = _clip_eigenvalues(cov)\n    return nearest_cov"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return _nearest_cov_higham(cov, higham_max_iteration)\n    else:\n        return _nearest_cov_clip_eigenvalues(cov)"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return _nearest_higham(cov, max_iteration=higham_max_iteration)\n    else:\n        return _nearest_clipping(cov)"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return _nearest_covariance_higham(cov, max_iteration=higham_max_iteration)\n    else:\n        return _nearest_covariance_eigenvalues(cov)"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return _nearest_corr_higham(cov, higham_max_iteration)\n    else:\n        return _nearest_corr_eigenvalue(cov)"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return _nearest_cov_higham(cov, max_iteration=higham_max_iteration)\n    else:\n        return _nearest_cov_clip_eigenvalues(cov)"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        # Use Higham & Nick (2002) algorithm\n        if not is_positive_definite(cov):\n            return scs.nearest_correlation(cov, max_iteration=higham_max_iteration)\n        else:\n            return cov\n    else:\n        # Clip eigenvalues to ensure positive definiteness\n        w, v = np.linalg.eigh(cov)\n        w = np.maximum(w, _CLIPPING_VALUE)\n        return (v * w) @ v.T"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    \"\"\"\n    This function computes the nearest covariance matrix that is positive definite and allows for a Cholesky decomposition, keeping the variance unchanged. It either uses the Higham & Nick (2002) algorithm or clips eigenvalues based on the specified parameters to ensure the resulting matrix is positive definite.\n\n    Input-Output Arguments\n    :param cov: np.ndarray. The input covariance matrix to be adjusted. It is used as the base for computing the nearest positive definite covariance matrix.\n    :param higham: bool, default=False. Determines the method used to find the nearest positive definite matrix. If True, the Higham & Nick (2002) algorithm is used; otherwise, eigenvalues are clipped.\n    :param higham_max_iteration: int, default=100. Specifies the maximum number of iterations for the Higham & Nick (2002) algorithm when it is used.\n    :return: np.ndarray. The nearest covariance matrix that is positive definite and allows for a Cholesky decomposition.\n\n    References:\n    - \"Computing the nearest correlation matrix - a problem from finance\" IMA Journal of Numerical Analysis Higham & Nick (2002)\n    \"\"\"\n    if higham:\n        if not is_positive_definite(cov):\n            cov = scs.nearest_correlation(cov, max_iteration=higham_max_iteration)\n    else:\n        if not is_cholesky_dec(cov):\n            eigvals, eigvecs = np.linalg.eigh(cov)\n            eigvals = np.maximum(eigvals, _CLIPPING_VALUE)\n            cov = eigvecs @ np.diag(eigvals) @ eigvecs.T\n    return cov"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        # Use Higham & Nick (2002) algorithm\n        nearest_cov = higham_nearest_cov(cov, max_iteration=higham_max_iteration)\n    else:\n        # Clip eigenvalues to ensure positive definiteness\n        nearest_cov = clip_eigenvalues(cov)\n    return nearest_cov"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return _nearest_higham(cov, higham_max_iteration)\n    else:\n        return _nearest_clip_eigenvalues(cov)"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if len(arr) > 1:\n            midpoint = len(arr) // 2\n            yield [arr[:midpoint], arr[midpoint:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "\n    for array in x:\n        if len(array) > 1:\n            mid = len(array) // 2\n            yield [array[:mid], array[mid:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if len(arr) > 1:\n            midpoint = len(arr) // 2\n            yield [arr[:midpoint], arr[midpoint:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if len(arr) > 1:\n            midpoint = len(arr) // 2\n            yield [arr[:midpoint], arr[midpoint:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "\n    for array in x:\n        if len(array) > 1:\n            midpoint = len(array) // 2\n            yield [array[:midpoint], array[midpoint:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if len(arr) > 1:\n            midpoint = len(arr) // 2\n            yield [arr[:midpoint], arr[midpoint:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "\n    for arr in x:\n        if len(arr) > 1:\n            mid = len(arr) // 2\n            yield [arr[:mid], arr[mid:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "\n    for arr in x:\n        if len(arr) > 1:\n            mid = len(arr) // 2\n            yield [arr[:mid], arr[mid:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if len(arr) > 1:\n            midpoint = len(arr) // 2\n            yield [arr[:midpoint], arr[midpoint:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if len(arr) > 1:\n            mid = len(arr) // 2\n            yield [arr[:mid], arr[mid:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if len(arr) > 1:\n            mid = len(arr) // 2\n            yield [arr[:mid], arr[mid:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "\n    for arr in x:\n        if len(arr) > 1:\n            midpoint = len(arr) // 2\n            yield [arr[:midpoint], arr[midpoint:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "\n    for arr in x:\n        if len(arr) > 1:\n            mid = len(arr) // 2\n            yield [arr[:mid], arr[mid:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "\n    for arr in x:\n        if len(arr) > 1:\n            midpoint = len(arr) // 2\n            yield [arr[:midpoint], arr[midpoint:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "\n    for arr in x:\n        if len(arr) > 1:\n            midpoint = len(arr) // 2\n            yield [arr[:midpoint], arr[midpoint:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if len(arr) > 1:\n            midpoint = len(arr) // 2\n            yield [arr[:midpoint], arr[midpoint:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "\n    for arr in x:\n        if len(arr) > 1:\n            midpoint = len(arr) // 2\n            yield [arr[:midpoint], arr[midpoint:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "\n    for arr in x:\n        if len(arr) > 1:\n            mid = len(arr) // 2\n            yield [arr[:mid], arr[mid:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "\n    for arr in x:\n        if len(arr) > 1:\n            mid = len(arr) // 2\n            yield [arr[:mid], arr[mid:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if len(arr) > 1:\n            mid = len(arr) // 2\n            yield [arr[:mid], arr[mid:]]"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n    if abs(x) < 1:\n        return f\"{x:.4f}\"\n    elif abs(x) < 10:\n        return f\"{x:.3f}\"\n    elif abs(x) < 100:\n        return f\"{x:.2f}\"\n    else:\n        return f\"{x:.1f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n    if abs(x) >= 10 or abs(x) < 0.01:\n        return f\"{x:.2e}\"\n    elif 0.01 <= abs(x) < 10:\n        return f\"{x:.4f}\"\n    else:\n        return f\"{x:.3f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n    if abs(x) >= 10 or abs(x) < 0.01:\n        return f\"{x:.2f}\"\n    elif abs(x) >= 1 or abs(x) < 0.1:\n        return f\"{x:.3f}\"\n    else:\n        return f\"{x:.4f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n    if abs(x) >= 10 or abs(x) < 0.01:\n        return f\"{x:.2f}\"\n    elif abs(x) >= 1 or abs(x) < 0.1:\n        return f\"{x:.3f}\"\n    else:\n        return f\"{x:.4f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n    if abs(x) >= 10 or abs(x) < 0.01:\n        return f\"{x:.2e}\"\n    if abs(x) < 0.1:\n        return f\"{x:.4f}\"\n    return f\"{x:.3f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n    if abs(x) < 1:\n        return f\"{x:.4f}\"\n    elif abs(x) < 10:\n        return f\"{x:.3f}\"\n    elif abs(x) < 100:\n        return f\"{x:.2f}\"\n    else:\n        return f\"{x:.1f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n    if abs(x) >= 1000 or abs(x) < 0.01:\n        return f\"{x:.2e}\"\n    elif abs(x) < 1:\n        return f\"{x:.4f}\"\n    elif abs(x) < 10:\n        return f\"{x:.3f}\"\n    else:\n        return f\"{x:.2f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n    if abs(x) < 1:\n        return f\"{x:.2e}\"\n    elif abs(x) < 10:\n        return f\"{x:.4f}\"\n    else:\n        return f\"{x:.2f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n    if abs(x) >= 1:\n        return f\"{x:.2f}\"\n    if abs(x) >= 0.1:\n        return f\"{x:.3f}\"\n    if abs(x) >= 0.01:\n        return f\"{x:.4f}\"\n    return f\"{x:.6f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n    if abs(x) < 1:\n        return f\"{x:.2e}\"\n    elif abs(x) < 10:\n        return f\"{x:.4f}\"\n    else:\n        return f\"{x:.2f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n    if abs(x) < 0.01 or abs(x) >= 1000:\n        return f\"{x:.2e}\"\n    if abs(x) < 1:\n        return f\"{x:.4f}\"\n    return f\"{x:.2f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n    if abs(x) >= 1:\n        return f\"{x:.2f}\"\n    if abs(x) >= 0.01:\n        return f\"{x:.4f}\"\n    if abs(x) >= 0.0001:\n        return f\"{x:.6f}\"\n    return f\"{x:.8f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n    if abs(x) >= 1 or x == 0:\n        return f\"{x:.2f}\"\n    if abs(x) < 1e-2:\n        return f\"{x:.2e}\"\n    return f\"{x:.4f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n        if abs(x) < 1:\n            return f\"{x:.2f}%\"\n        elif abs(x) < 10:\n            return f\"{x:.1f}%\"\n        else:\n            return f\"{x:.0f}%\"\n    else:\n        if abs(x) < 1:\n            return f\"{x:.4f}\"\n        elif abs(x) < 10:\n            return f\"{x:.3f}\"\n        else:\n            return f\"{x:.2f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "\n    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n    if abs(x) < 1:\n        return f\"{x:.2e}\"\n    elif abs(x) < 10:\n        return f\"{x:.4f}\"\n    else:\n        return f\"{x:.2f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n    if abs(x) < 1:\n        return f\"{x:.2e}\"\n    elif abs(x) < 10:\n        return f\"{x:.2f}\"\n    elif abs(x) < 100:\n        return f\"{x:.1f}\"\n    else:\n        return f\"{x:.0f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n    if abs(x) < 1:\n        return f\"{x:.2f}\"\n    elif abs(x) < 10:\n        return f\"{x:.1f}\"\n    else:\n        return f\"{x:.0f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n    if abs(x) >= 1 or x == 0:\n        return f\"{x:.2f}\"\n    elif abs(x) < 1e-3:\n        return f\"{x:.2e}\"\n    else:\n        decimals = abs(int(np.log10(abs(x)))) + 2\n        return f\"{x:.{decimals}f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n    if abs(x) < 1:\n        return f\"{x:.2f}\"\n    elif abs(x) < 10:\n        return f\"{x:.1f}\"\n    else:\n        return f\"{x:.0f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n    if abs(x) < 1:\n        return f\"{x:.2%}\" if percent else f\"{x:.2f}\"\n    if abs(x) < 10:\n        return f\"{x:.1f}\" if percent else f\"{x:.1f}\"\n    return f\"{x:.0f}\" if percent else f\"{x:.0f}\""}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\"assets_names must be provided when items is a dictionary\")\n        array = np.full((n_assets,), fill_value)\n        for i, asset_name in enumerate(assets_names):\n            if asset_name in items:\n                array[i] = items[asset_name]\n    else:\n        array = np.asarray(items)\n\n    if dim == 1:\n        if array.shape != (n_assets,):\n            raise ValueError(f\"The shape of {name} must be ({n_assets},) for dim=1\")\n    elif dim == 2:\n        if array.shape[1] != n_assets:\n            raise ValueError(f\"The number of assets in {name} does not match n_assets\")\n    else:\n        raise ValueError(\"dim must be either 1 or 2\")\n\n    return array"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\"assets_names must be provided when items is a dictionary\")\n        array = np.full((n_assets,), fill_value)\n        for i, asset_name in enumerate(assets_names):\n            if asset_name in items:\n                array[i] = items[asset_name]\n    else:\n        array = np.asarray(items)\n\n    if dim == 1:\n        if array.shape != (n_assets,):\n            raise ValueError(f\"The shape of {name} must be ({n_assets},) for dim=1\")\n    elif dim == 2:\n        if array.shape[1] != n_assets:\n            raise ValueError(f\"The number of assets in {name} must be {n_assets} for dim=2\")\n    else:\n        raise ValueError(\"dim must be 1 or 2\")\n\n    return array"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\"assets_names must be provided when items is a dictionary\")\n        if len(assets_names) != n_assets:\n            raise ValueError(\"Length of assets_names must match the number of assets\")\n        array = np.full((n_assets,), fill_value)\n        for i, name in enumerate(assets_names):\n            if name in items:\n                array[i] = items[name]\n    else:\n        array = np.asarray(items)\n\n    if dim == 2:\n        if len(array.shape) != 2:\n            raise ValueError(f\"{name} must have shape (n_groups, n_assets)\")\n        if array.shape[1] != n_assets:\n            raise ValueError(f\"Number of assets in {name} must be equal to n_assets\")\n\n    elif dim == 1:\n        if len(array.shape) != 1:\n            raise ValueError(f\"{name} must have shape (n_assets,)\")\n\n    else:\n        raise ValueError(\"dim must be either 1 or 2\")\n\n    return array"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\"assets_names must be provided when items is a dictionary\")\n\n        if dim == 1:\n            result = np.full(n_assets, fill_value)\n            for i, asset_name in enumerate(assets_names):\n                if asset_name in items:\n                    result[i] = items[asset_name]\n        elif dim == 2:\n            result = np.full((1, n_assets), fill_value)\n            for i, asset_name in enumerate(assets_names):\n                if asset_name in items:\n                    result[0, i] = items[asset_name]\n        else:\n            raise ValueError(\"Invalid value for dim. It should be either 1 or 2.\")\n\n    else:\n        result = np.asarray(items)\n\n    if dim == 1 and result.shape != (n_assets,):\n        raise ValueError(f\"The shape of {name} is {result.shape}, but it should be ({n_assets},)\")\n    elif dim == 2 and result.shape != (1, n_assets):\n        raise ValueError(f\"The shape of {name} is {result.shape}, but it should be (1, {n_assets})\")\n\n    return result"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\"assets_names must be provided when items is a dictionary\")\n        if len(assets_names) != n_assets:\n            raise ValueError(\"Number of assets names must match the expected number of assets\")\n        \n        array = np.full((n_assets,), fill_value)\n        for i, asset_name in enumerate(assets_names):\n            if asset_name in items:\n                array[i] = items[asset_name]\n    else:\n        array = np.asarray(items)\n\n    if dim == 1:\n        if array.shape != (n_assets,):\n            raise ValueError(f\"The shape of {name} must be ({n_assets},)\")\n    elif dim == 2:\n        if array.shape[1] != n_assets:\n            raise ValueError(f\"The number of assets in {name} must be {n_assets}\")\n    else:\n        raise ValueError(\"dim must be either 1 or 2\")\n\n    return array"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\"assets_names must be provided when items is a dictionary\")\n        if len(assets_names) != n_assets:\n            raise ValueError(\"assets_names length must match n_assets\")\n        array = np.full((n_assets,), fill_value)\n        for i, asset_name in enumerate(assets_names):\n            if asset_name in items:\n                array[i] = items[asset_name]\n    else:\n        array = np.asarray(items)\n\n    if dim == 1:\n        if array.shape != (n_assets,):\n            raise ValueError(f\"The shape of {name} must be ({n_assets},)\")\n    elif dim == 2:\n        if array.shape[1] != n_assets:\n            raise ValueError(f\"The number of assets in {name} must be {n_assets}\")\n    else:\n        raise ValueError(\"dim must be 1 or 2\")\n\n    return array"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if dim == 1:\n            if len(items) != n_assets:\n                raise ValueError(f\"The number of assets in {name} does not match the expected number of assets\")\n            array = np.array([items.get(asset, fill_value) for asset in assets_names])\n        elif dim == 2:\n            array = np.array([items.get(asset, [fill_value] * n_assets) for asset in assets_names])\n            array = np.vstack(array)\n        else:\n            raise ValueError(\"Invalid value for 'dim'. It must be either 1 or 2.\")\n    else:\n        array = np.array(items)\n\n    if dim == 1 and array.shape != (n_assets,):\n        raise ValueError(f\"The shape of the array from {name} does not match the expected shape\")\n    elif dim == 2 and array.shape != (len(items), n_assets):\n        raise ValueError(f\"The shape of the array from {name} does not match the expected shape\")\n\n    return array"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is not None:\n            array = np.array([items.get(asset, fill_value) for asset in assets_names])\n        else:\n            raise ValueError(\"assets_names must be provided when items is a dictionary\")\n    else:\n        array = np.asarray(items)\n\n    if dim == 1:\n        if array.shape != (n_assets,):\n            raise ValueError(f\"The shape of {name} must be ({n_assets},) for dim=1\")\n    elif dim == 2:\n        if array.shape[1] != n_assets:\n            raise ValueError(f\"The number of assets in {name} must be {n_assets} for dim=2\")\n    else:\n        raise ValueError(\"dim must be either 1 or 2\")\n\n    return array"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\"assets_names must be provided when items is a dictionary\")\n        if len(assets_names) != n_assets:\n            raise ValueError(\"Number of assets names must match the expected number of assets\")\n        array = np.full((n_assets,), fill_value)\n        for i, asset_name in enumerate(assets_names):\n            if asset_name in items:\n                array[i] = items[asset_name]\n    else:\n        array = np.asarray(items)\n\n    if dim == 2:\n        if array.ndim == 1:\n            array = array[np.newaxis, :]\n        elif array.ndim != 2:\n            raise ValueError(f\"{name} must be a 1D or 2D array\")\n        if array.shape[1] != n_assets:\n            raise ValueError(f\"Number of assets in {name} must match the expected number of assets\")\n\n    elif dim == 1:\n        if array.ndim != 1:\n            raise ValueError(f\"{name} must be a 1D array\")\n        if array.shape[0] != n_assets:\n            raise ValueError(f\"Number of assets in {name} must match the expected number of assets\")\n\n    return array"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "\n    if isinstance(items, dict):\n        if dim == 1:\n            if len(items) != n_assets:\n                raise ValueError(f\"The number of {name} ({len(items)}) does not match the expected number of assets ({n_assets})\")\n            result = np.array([items.get(asset, fill_value) for asset in assets_names])\n        elif dim == 2:\n            result = np.array([[items.get(asset, fill_value) for asset in assets_names]])\n        else:\n            raise ValueError(\"Invalid value for 'dim'. It should be either 1 or 2.\")\n    else:\n        result = np.asarray(items)\n\n    if dim == 1 and result.shape != (n_assets,):\n        raise ValueError(f\"The shape of the {name} array ({result.shape}) does not match the expected shape ({n_assets},)\")\n    elif dim == 2 and result.shape != (1, n_assets):\n        raise ValueError(f\"The shape of the {name} array ({result.shape}) does not match the expected shape (1, {n_assets})\")\n\n    return result"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "\n    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\"assets_names must be provided when items is a dictionary\")\n\n        if dim == 1:\n            array = np.array([items.get(asset, fill_value) for asset in assets_names])\n        elif dim == 2:\n            array = np.array([[items.get(asset, fill_value) for asset in assets_names]])\n\n        if array.shape[1] != n_assets:\n            raise ValueError(f\"The number of assets in {name} does not match the expected number\")\n\n    else:\n        array = np.asarray(items)\n\n    if dim == 1 and array.shape != (n_assets,):\n        raise ValueError(f\"The shape of {name} does not match the expected shape\")\n\n    if dim == 2 and array.shape[1] != n_assets:\n        raise ValueError(f\"The number of assets in {name} does not match the expected number\")\n\n    return array"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "\n    if dim == 1:\n        if isinstance(items, dict):\n            array = np.full(n_assets, fill_value)\n            for i, asset in enumerate(assets_names):\n                if asset in items:\n                    array[i] = items[asset]\n        else:\n            array = np.asarray(items)\n            if len(array) != n_assets:\n                raise ValueError(f\"The length of {name} should be {n_assets}\")\n    elif dim == 2:\n        if isinstance(items, dict):\n            array = np.full((1, n_assets), fill_value)\n            for i, asset in enumerate(assets_names):\n                if asset in items:\n                    array[0, i] = items[asset]\n        else:\n            array = np.atleast_2d(items)\n            if array.shape[1] != n_assets:\n                raise ValueError(f\"The number of columns in {name} should be {n_assets}\")\n    else:\n        raise ValueError(\"Invalid value for dim. It should be either 1 or 2.\")\n\n    return array"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\"assets_names must be provided when items is a dictionary\")\n        array = np.full((n_assets,), fill_value)\n        for i, asset_name in enumerate(assets_names):\n            if asset_name in items:\n                array[i] = items[asset_name]\n    else:\n        array = np.asarray(items)\n\n    if dim == 1:\n        if array.shape != (n_assets,):\n            raise ValueError(f\"The shape of {name} must be ({n_assets},) when dim=1\")\n    elif dim == 2:\n        if array.shape[1] != n_assets:\n            raise ValueError(f\"The number of assets in {name} must be {n_assets} when dim=2\")\n\n    return array"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\"assets_names must be provided when items is a dictionary\")\n        if len(assets_names) != n_assets:\n            raise ValueError(\"Number of asset names must match the expected number of assets\")\n        array = np.full((n_assets,), fill_value)\n        for i, asset_name in enumerate(assets_names):\n            if asset_name in items:\n                array[i] = items[asset_name]\n    else:\n        array = np.asarray(items)\n\n    if dim == 2:\n        if array.ndim == 1:\n            array = array.reshape(1, -1)\n        if array.shape[1] != n_assets:\n            raise ValueError(f\"The number of assets in {name} does not match the expected number\")\n    elif dim == 1:\n        if array.ndim != 1:\n            raise ValueError(f\"{name} must be a 1-dimensional array\")\n\n    return array"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if dim == 1:\n            if len(items) != n_assets:\n                raise ValueError(f\"The number of {name} must be equal to n_assets\")\n            array = np.array([items.get(asset, fill_value) for asset in assets_names])\n        elif dim == 2:\n            array = np.array([items.get(asset, [fill_value] * n_assets) for asset in assets_names])\n        else:\n            raise ValueError(\"Invalid value for 'dim'. It must be either 1 or 2.\")\n    else:\n        array = np.array(items)\n\n    if dim == 1 and array.shape != (n_assets,):\n        raise ValueError(f\"The shape of {name} must be equal to (n_assets,)\")\n    elif dim == 2 and array.shape != (len(items), n_assets):\n        raise ValueError(f\"The shape of {name} must be equal to (len(items), n_assets)\")\n\n    return array"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\"assets_names must be provided when items is a dictionary\")\n\n        if dim == 1:\n            array = np.array([items.get(asset, fill_value) for asset in assets_names])\n        elif dim == 2:\n            array = np.array([[items.get(asset, fill_value) for asset in assets_names]])\n\n        if array.shape[1] != n_assets:\n            raise ValueError(f\"The number of assets in {name} does not match n_assets\")\n\n    else:\n        array = np.asarray(items)\n\n        if dim == 1 and array.shape != (n_assets,):\n            raise ValueError(f\"The shape of {name} does not match (n_assets,)\")\n        elif dim == 2 and array.shape[1] != n_assets:\n            raise ValueError(f\"The number of assets in {name} does not match n_assets\")\n\n    return array"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    \n    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\"assets_names must be provided when items is a dictionary\")\n        \n        # Fill missing values in the dictionary\n        for asset_name in assets_names:\n            if asset_name not in items:\n                items[asset_name] = fill_value\n        \n        # Convert the dictionary to a numpy array\n        array = np.array([items[asset_name] for asset_name in assets_names])\n    else:\n        array = np.array(items)\n    \n    # Verify the shape of the converted array\n    if dim == 1:\n        if array.shape != (n_assets,):\n            raise ValueError(f\"The shape of {name} is {array.shape}, but expected (n_assets,)\")\n    elif dim == 2:\n        if array.shape[1] != n_assets:\n            raise ValueError(f\"The number of assets in {name} is {array.shape[1]}, but expected n_assets\")\n    \n    return array"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if dim == 1:\n            if len(items) != n_assets:\n                raise ValueError(f\"The number of {name} ({len(items)}) does not match the expected number of assets ({n_assets})\")\n            return np.array([items.get(asset, fill_value) for asset in assets_names])\n        elif dim == 2:\n            if len(items) != len(assets_names):\n                raise ValueError(f\"The number of {name} groups ({len(items)}) does not match the number of assets ({len(assets_names)})\")\n            return np.array([items.get(asset, [fill_value] * n_assets) for asset in assets_names])\n        else:\n            raise ValueError(\"Invalid value for 'dim'. It should be either 1 or 2.\")\n    else:\n        array = np.array(items)\n        if dim == 1:\n            if array.shape != (n_assets,):\n                raise ValueError(f\"The shape of the {name} array ({array.shape}) does not match the expected shape ({(n_assets,)})\")\n        elif dim == 2:\n            if array.shape[1] != n_assets:\n                raise ValueError(f\"The number of assets in the {name} array ({array.shape[1]}) does not match the expected number of assets ({n_assets})\")\n        else:\n            raise ValueError(\"Invalid value for 'dim'. It should be either 1 or 2.\")\n        return array"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if dim == 1:\n            array = np.full(n_assets, fill_value)\n            for key, value in items.items():\n                if isinstance(value, (int, float)):\n                    array[assets_names.tolist().index(key)] = value\n                else:\n                    raise ValueError(f\"Invalid value type for {name} '{key}'. Expected int or float.\")\n        elif dim == 2:\n            array = np.full((1, n_assets), fill_value)\n            for key, value in items.items():\n                if isinstance(value, (list, np.ndarray)):\n                    array[0, assets_names.tolist().index(key)] = value\n                else:\n                    raise ValueError(f\"Invalid value type for {name} '{key}'. Expected list or np.ndarray.\")\n        else:\n            raise ValueError(\"Invalid value for dim. Expected 1 or 2.\")\n    else:\n        array = np.asarray(items)\n        if dim == 1:\n            if array.shape != (n_assets,):\n                raise ValueError(f\"Invalid shape for {name}. Expected shape: ({n_assets},), got: {array.shape}.\")\n        elif dim == 2:\n            if array.shape[1] != n_assets:\n                raise ValueError(f\"Invalid number of assets for {name}. Expected: {n_assets}, got: {array.shape[1]}.\")\n        else:\n            raise ValueError(\"Invalid value for dim. Expected 1 or 2.\")\n    return array"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\"assets_names must be provided when items is a dictionary\")\n        if len(assets_names) != n_assets:\n            raise ValueError(f\"The length of assets_names must be equal to n_assets: {n_assets}\")\n        array = np.full((n_assets,), fill_value)\n        for i, asset_name in enumerate(assets_names):\n            if asset_name in items:\n                array[i] = items[asset_name]\n    else:\n        array = np.asarray(items)\n\n    if dim == 2:\n        if array.ndim == 1:\n            array = array[np.newaxis, :]\n        if array.shape[1] != n_assets:\n            raise ValueError(f\"The number of assets in {name} does not match n_assets: {n_assets}\")\n    elif dim == 1:\n        if array.ndim != 1:\n            raise ValueError(f\"The shape of {name} does not match the expected dimension: 1\")\n\n    return array"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = Path.home() / \"skfolio_data\"\n    else:\n        data_home = Path(data_home)\n\n    if not data_home.exists():\n        data_home.mkdir(parents=True)\n\n    return str(data_home)"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.path.expanduser(\"~/skfolio_data\")\n    elif isinstance(data_home, str):\n        data_home = Path(data_home)\n    if not data_home.exists():\n        data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.path.expanduser(\"~/skfolio_data\")\n    elif isinstance(data_home, Path):\n        data_home = str(data_home)\n    elif not isinstance(data_home, str):\n        raise ValueError(\"data_home should be a string or Path-like object\")\n\n    if not os.path.exists(data_home):\n        os.makedirs(data_home)\n\n    return data_home"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = Path.home() / \"skfolio_data\"\n    else:\n        data_home = Path(data_home)\n\n    if not data_home.exists():\n        data_home.mkdir(parents=True, exist_ok=True)\n\n    return str(data_home)"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    data_home = Path(data_home).expanduser()\n    data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = Path.home() / \"skfolio_data\"\n    else:\n        data_home = Path(data_home)\n\n    if not data_home.exists():\n        data_home.mkdir(parents=True)\n\n    return str(data_home)"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    data_home = Path(data_home).expanduser()\n    data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    data_home = Path(data_home).expanduser()\n    if not data_home.exists():\n        data_home.mkdir(parents=True)\n    return str(data_home)"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    data_home = Path(data_home).expanduser()\n    data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.path.expanduser(\"~/skfolio_data\")\n    elif isinstance(data_home, Path):\n        data_home = str(data_home)\n    elif not isinstance(data_home, str):\n        raise ValueError(\"data_home should be a string or Path-like object\")\n    os.makedirs(data_home, exist_ok=True)\n    return data_home"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.path.expanduser(\"~/skfolio_data\")\n    elif isinstance(data_home, str):\n        data_home = Path(data_home)\n    if not data_home.exists():\n        data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    data_home = Path(data_home).expanduser()\n    if not data_home.exists():\n        data_home.mkdir(parents=True)\n    return str(data_home)"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = Path.home() / \"skfolio_data\"\n    else:\n        data_home = Path(data_home)\n\n    if not data_home.exists():\n        data_home.mkdir(parents=True)\n\n    return str(data_home)"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    data_home = Path(data_home).expanduser()\n    data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    data_home = Path(data_home).expanduser()\n    data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = Path.home() / \"skfolio_data\"\n    else:\n        data_home = Path(data_home)\n\n    data_home = str(data_home)\n    if not os.path.exists(data_home):\n        os.makedirs(data_home)\n\n    return data_home"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = Path.home() / \"skfolio_data\"\n    else:\n        data_home = Path(data_home)\n\n    if not data_home.exists():\n        data_home.mkdir(parents=True)\n\n    return str(data_home)"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = Path.home() / \"skfolio_data\"\n    else:\n        data_home = Path(data_home)\n\n    if not data_home.exists():\n        data_home.mkdir(parents=True, exist_ok=True)\n\n    return str(data_home)"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = Path.home() / \"skfolio_data\"\n    else:\n        data_home = Path(data_home)\n\n    if not data_home.exists():\n        data_home.mkdir(parents=True, exist_ok=True)\n\n    return str(data_home)"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = Path.home() / \"skfolio_data\"\n    elif isinstance(data_home, str):\n        data_home = Path(data_home)\n    if not data_home.exists():\n        data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    if os.path.exists(data_home):\n        shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    if os.path.exists(data_home):\n        shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    if os.path.exists(data_home):\n        shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n    os.makedirs(data_home, exist_ok=True)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    if os.path.exists(data_home):\n        shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    if os.path.exists(data_home):\n        shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    if os.path.exists(data_home):\n        shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    if os.path.exists(data_home):\n        shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    if os.path.exists(data_home):\n        shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    if os.path.exists(data_home):\n        shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    if os.path.exists(data_home):\n        shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    if os.path.exists(data_home):\n        shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    if os.path.exists(data_home):\n        shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    if os.path.exists(data_home):\n        shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n    os.makedirs(data_home, exist_ok=True)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    if os.path.exists(data_home):\n        shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    if os.path.exists(data_home):\n        shutil.rmtree(data_home)"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes, int, float, bool, type(None), torch.Tensor)):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = sorted(obj.keys())\n        values = [obj[k] for k in keys]\n        ret, schema = DictSchema.flatten(values)\n        return ret, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, (Boxes, Instances, ROIMasks)):\n        return obj.get_fields(), InstancesSchema()\n    else:\n        raise ValueError(f\"Unsupported type to flatten: {type(obj)}\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes, int, float, bool, type(None), torch.Tensor)):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        return ListSchema.flatten(obj)\n    elif isinstance(obj, dict):\n        return DictSchema.flatten(obj)\n    elif isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    elif isinstance(obj, (Boxes, ROIMasks)):\n        return TensorWrapSchema.flatten(obj)\n    else:\n        raise NotImplementedError(f\"Cannot flatten object of type {type(obj)}\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes, int, float, bool, type(None), torch.Tensor)):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    if isinstance(obj, collections.abc.Mapping):\n        keys = sorted(obj.keys())\n        values = [obj[k] for k in keys]\n        ret, schema = ListSchema.flatten(values)\n        return ret, DictSchema(schema.schemas, schema.sizes, keys)\n    if isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    if isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    if isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    raise NotImplementedError(f\"Cannot flatten object of type {type(obj)}\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes, int, float, bool, type(None), torch.Tensor)):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = sorted(obj.keys())\n        values = [obj[k] for k in keys]\n        ret, schema = DictSchema.flatten(values)\n        return ret, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    elif isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    elif isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    else:\n        raise NotImplementedError(f\"Type {type(obj)} is not supported for flattening.\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes, int, float, bool, type(None), torch.Tensor)):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = sorted(obj.keys())\n        values = [obj[k] for k in keys]\n        ret, schema = DictSchema.flatten(values)\n        return ret, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, (Boxes, Instances, ROIMasks)):\n        return obj.get_fields(), InstancesSchema()\n    else:\n        raise NotImplementedError(f\"Cannot flatten object of type {type(obj)}\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes, int, float, bool, type(None), torch.Tensor)):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = list(obj.keys())\n        values = [obj[k] for k in keys]\n        res, schema = ListSchema.flatten(values)\n        return res, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, Instances):\n        ret, schema = InstancesSchema.flatten(obj)\n        return ret, schema\n    elif isinstance(obj, (Boxes, ROIMasks)):\n        ret, schema = TensorWrapSchema.flatten(obj)\n        return ret, schema\n    else:\n        raise NotImplementedError(f\"Cannot flatten object of type {type(obj)}\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes, int, float, bool, type(None), torch.Tensor)):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = list(obj.keys())\n        values = [obj[k] for k in keys]\n        res, schema = DictSchema.flatten(values)\n        return res, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    elif isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    elif isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    else:\n        raise ValueError(f\"Unsupported type to flatten: {type(obj)}\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes, int, float, bool, type(None), torch.Tensor)):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = sorted(obj.keys())\n        values = [obj[k] for k in keys]\n        ret, schema = ListSchema.flatten(values)\n        return ret, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, Boxes):\n        tensor = obj.tensor if obj.tensor is not None else torch.empty((0, 4), dtype=torch.float32)\n        return (tensor,), TensorWrapSchema(\"detectron2.structures.Boxes\")\n    elif isinstance(obj, Instances):\n        ret, schema = InstancesSchema.flatten(obj)\n        return ret, schema\n    elif isinstance(obj, ROIMasks):\n        tensor = obj.tensor if obj.tensor is not None else torch.empty((0, 0, 0), dtype=torch.uint8)\n        return (tensor,), TensorWrapSchema(\"detectron2.structures.ROIMasks\")\n    else:\n        raise NotImplementedError(f\"Type {type(obj)} is not supported for flattening\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "\n    if isinstance(obj, (str, bytes, int, float, bool, type(None), torch.Tensor)):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = sorted(obj.keys())\n        values = [obj[k] for k in keys]\n        ret, schema = ListSchema.flatten(values)\n        return ret, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, Instances):\n        ret, schema = InstancesSchema.flatten(obj)\n        return ret, schema\n    elif isinstance(obj, (Boxes, ROIMasks)):\n        return TensorWrapSchema.flatten(obj)\n    else:\n        raise ValueError(f\"Unsupported type to flatten: {type(obj)}\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes, int, float, bool, type(None), torch.Tensor)):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = sorted(obj.keys())\n        values = [obj[k] for k in keys]\n        ret, schema = DictSchema.flatten(values)\n        return ret, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, (Boxes, Instances, ROIMasks)):\n        return obj.get_fields(), InstancesSchema()\n    else:\n        raise NotImplementedError(f\"Cannot flatten object of type {type(obj)}\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes, int, float, bool, type(None), torch.Tensor)):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = list(obj.keys())\n        values = [obj[k] for k in keys]\n        ret, schema = ListSchema.flatten(values)\n        return ret, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, Instances):\n        ret, schema = InstancesSchema.flatten(obj)\n        return ret, schema\n    elif isinstance(obj, (Boxes, ROIMasks)):\n        return TensorWrapSchema.flatten(obj)\n    else:\n        raise NotImplementedError(f\"Flattening {type(obj)} is not supported.\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes, int, float, bool, type(None), torch.Tensor)):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = sorted(obj.keys())\n        values = [obj[k] for k in keys]\n        ret, schema = DictSchema.flatten(values)\n        return ret, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, Boxes):\n        return Boxes.flatten(obj)\n    elif isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    elif isinstance(obj, ROIMasks):\n        return ROIMasks.flatten(obj)\n    else:\n        raise NotImplementedError(f\"Cannot flatten object of type {type(obj)}\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "\n    if isinstance(obj, (str, bytes, int, float, bool, type(None), torch.Tensor)):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = sorted(obj.keys())\n        values = [obj[k] for k in keys]\n        ret, schema = ListSchema.flatten(values)\n        return ret, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, Instances):\n        ret, schema = InstancesSchema.flatten(obj)\n        return ret, schema\n    elif isinstance(obj, (Boxes, ROIMasks)):\n        return TensorWrapSchema.flatten(obj)\n    else:\n        raise ValueError(f\"Unrecognized type {type(obj)} for flattening\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes, int, float, bool, type(None), torch.Tensor)):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = sorted(obj.keys())\n        values = [obj[k] for k in keys]\n        ret, schema = ListSchema.flatten(values)\n        return ret, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, (Boxes, Instances, ROIMasks)):\n        return obj.get_fields(), InstancesSchema()\n    else:\n        raise NotImplementedError(f\"Cannot flatten object of type {type(obj)}\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes, int, float, bool, type(None), torch.Tensor)):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = sorted(obj.keys())\n        values = [obj[k] for k in keys]\n        ret, schema = DictSchema.flatten(values)\n        return ret, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, (Boxes, Instances, ROIMasks)):\n        return obj.get_fields(), InstancesSchema()\n    else:\n        raise NotImplementedError(f\"Type {type(obj)} is not supported for flattening.\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "\n    if isinstance(obj, (str, bytes, int, float, bool, type(None), torch.Tensor)):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = sorted(obj.keys())\n        values = [obj[k] for k in keys]\n        ret, schema = ListSchema.flatten(values)\n        return ret, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, Instances):\n        ret, schema = InstancesSchema.flatten(obj)\n        return ret, schema\n    elif isinstance(obj, (Boxes, ROIMasks)):\n        ret, schema = TensorWrapSchema.flatten(obj)\n        return ret, schema\n    else:\n        raise ValueError(f\"Unsupported type to flatten: {type(obj)}\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes, int, float, bool, type(None), torch.Tensor)):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = sorted(obj.keys())\n        values = [obj[k] for k in keys]\n        ret, schema = DictSchema.flatten(values)\n        return ret, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, (Boxes, Instances, ROIMasks)):\n        return obj.get_fields(), locate(obj.__class__.__name__ + \"Schema\")\n    else:\n        raise ValueError(f\"Cannot flatten object of type {type(obj)}\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes, int, float, bool, type(None), torch.Tensor)):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = sorted(obj.keys())\n        values = [obj[k] for k in keys]\n        ret, schema = DictSchema.flatten(values)\n        return ret, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, (Boxes, Instances, ROIMasks)):\n        return obj.get_fields(), InstancesSchema()\n    else:\n        raise ValueError(f\"Unsupported type to flatten: {type(obj)}\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes)):\n        return (obj,), IdentitySchema()\n\n    if isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n\n    if isinstance(obj, collections.abc.Mapping):\n        keys = sorted(obj.keys())\n        values = [obj[k] for k in keys]\n        ret, schema = DictSchema.flatten(values)\n        return ret, DictSchema(schema.schemas, schema.sizes, keys)\n\n    if isinstance(obj, (Boxes, ROIMasks)):\n        return obj.tensor, TensorWrapSchema(_convert_target_to_string(type(obj)))\n\n    if isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n\n    raise NotImplementedError(f\"Flattening {type(obj)} is not supported!\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes, int, float, bool, type(None), torch.Tensor)):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = sorted(obj.keys())\n        values = [obj[k] for k in keys]\n        ret, schema = DictSchema.flatten(values)\n        return ret, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, (Boxes, Instances, ROIMasks)):\n        return obj.flatten()\n    else:\n        raise ValueError(f\"Unsupported type to flatten: {type(obj)}\")"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    n_groups, n_assets = groups.shape\n    left = np.zeros((len(equations), n_assets))\n    right = np.zeros(len(equations))\n\n    for i, equation in enumerate(equations):\n        try:\n            left[i], right[i] = _string_to_equation(groups, equation, sum_to_one)\n        except GroupNotFoundError as e:\n            if raise_if_group_missing:\n                raise e\n            else:\n                warnings.warn(str(e))\n\n    return left, right"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    if isinstance(groups, (list, tuple)):\n        groups = np.array(groups)\n    if isinstance(equations, (list, tuple)):\n        equations = np.array(equations)\n\n    if not isinstance(groups, np.ndarray):\n        raise EquationToMatrixError(f\"{names[0]} must be an array-like object\")\n\n    if not isinstance(equations, np.ndarray):\n        raise EquationToMatrixError(f\"{names[1]} must be an array-like object\")\n\n    if len(groups.shape) != 2:\n        raise EquationToMatrixError(f\"{names[0]} must be a 2D array\")\n\n    if len(equations.shape) != 1:\n        raise EquationToMatrixError(f\"{names[1]} must be a 1D array\")\n\n    n_groups, n_assets = groups.shape\n    left = np.zeros((len(equations), n_assets))\n    right = np.zeros(len(equations))\n\n    for i, equation in enumerate(equations):\n        try:\n            left[i], right[i] = _string_to_equation(groups, equation, sum_to_one)\n        except GroupNotFoundError as e:\n            if raise_if_group_missing:\n                raise e\n            else:\n                warnings.warn(str(e), UserWarning)\n\n    if not np.any(left):\n        return None\n\n    return left, right"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    n_groups, n_assets = groups.shape\n\n    left = []\n    right = []\n\n    for equation in equations:\n        try:\n            l, r = _string_to_equation(groups, equation, sum_to_one)\n            left.append(l)\n            right.append(r)\n        except GroupNotFoundError as e:\n            if raise_if_group_missing:\n                raise e\n            else:\n                warnings.warn(str(e))\n\n    if not left:\n        return None, None\n\n    return np.array(left), np.array(right)"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "\n    n = groups.shape[1]\n    left = []\n    right = []\n    for equation in equations:\n        l, r = _string_to_equation(groups, equation, sum_to_one)\n        left.append(l)\n        right.append(r)\n    left = np.array(left)\n    right = np.array(right)\n    return left, right"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    n_assets = groups.shape[1]\n    left = []\n    right = []\n    for equation in equations:\n        try:\n            l, r = _string_to_equation(groups, equation, sum_to_one)\n            left.append(l)\n            right.append(r)\n        except GroupNotFoundError as e:\n            if raise_if_group_missing:\n                raise e\n            else:\n                warnings.warn(str(e))\n\n    left = np.array(left)\n    right = np.array(right)\n    if len(left) == 0:\n        return None, None\n    return left, right"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    n = groups.shape[1]\n    left = np.zeros((len(equations), n))\n    right = np.zeros(len(equations))\n\n    for i, equation in enumerate(equations):\n        try:\n            left[i], right[i] = _string_to_equation(groups, equation, sum_to_one)\n        except GroupNotFoundError as e:\n            if raise_if_group_missing:\n                raise e\n            else:\n                warnings.warn(str(e))\n\n    return left, right"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    if not isinstance(groups, (np.ndarray, list, tuple)):\n        raise EquationToMatrixError(\n            f\"{names[0]} should be a numpy array or a list of lists\"\n        )\n    if not isinstance(equations, (np.ndarray, list, tuple)):\n        raise EquationToMatrixError(\n            f\"{names[1]} should be a numpy array or a list of strings\"\n        )\n\n    if isinstance(groups, (list, tuple)):\n        groups = np.array(groups)\n    if isinstance(equations, (list, tuple)):\n        equations = np.array(equations)\n\n    if groups.ndim != 2:\n        raise EquationToMatrixError(\n            f\"{names[0]} should be a 2D array of shape (n_groups, n_assets)\"\n        )\n    if equations.ndim != 1:\n        raise EquationToMatrixError(\n            f\"{names[1]} should be a 1D array of strings\"\n        )\n\n    n_groups, n_assets = groups.shape\n    left = np.zeros((len(equations), n_assets))\n    right = np.zeros(len(equations))\n\n    for i, eq in enumerate(equations):\n        try:\n            l, r = _string_to_equation(groups, eq, sum_to_one)\n            left[i] = l\n            right[i] = r\n        except GroupNotFoundError as e:\n            if raise_if_group_missing:\n                raise e\n            else:\n                warnings.warn(str(e))\n\n    return left, right"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    n_groups, n_assets = groups.shape\n    left = np.zeros((len(equations), n_assets))\n    right = np.zeros(len(equations))\n\n    for i, equation in enumerate(equations):\n        try:\n            left[i], right[i] = _string_to_equation(groups, equation, sum_to_one)\n        except GroupNotFoundError as e:\n            if raise_if_group_missing:\n                raise e\n            else:\n                warnings.warn(str(e))\n\n    return left, right"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    if not isinstance(groups, np.ndarray):\n        groups = np.array(groups)\n    if not isinstance(equations, np.ndarray):\n        equations = np.array(equations)\n\n    n_groups, n_assets = groups.shape\n    n_equations = len(equations)\n\n    left = np.zeros((n_equations, n_assets))\n    right = np.zeros(n_equations)\n\n    for i, equation in enumerate(equations):\n        try:\n            left[i, :], right[i] = _string_to_equation(groups, equation, sum_to_one)\n        except GroupNotFoundError as e:\n            if raise_if_group_missing:\n                raise e\n            else:\n                warnings.warn(str(e))\n\n    return left, right"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    if isinstance(groups, (list, tuple)):\n        groups = np.array(groups)\n\n    if isinstance(equations, (list, tuple)):\n        equations = np.array(equations)\n\n    if not isinstance(groups, np.ndarray) or not isinstance(equations, np.ndarray):\n        raise EquationToMatrixError(\n            f\"Both 'groups' and 'equations' should be array-like. Got {type(groups)} and {type(equations)}\"\n        )\n\n    if groups.ndim != 2 or equations.ndim != 1:\n        raise EquationToMatrixError(\n            f\"'groups' should be a 2D array and 'equations' should be a 1D array. \"\n            f\"Got {groups.ndim}D and {equations.ndim}D arrays\"\n        )\n\n    left = []\n    right = []\n\n    for equation in equations:\n        try:\n            l, r = _string_to_equation(groups, equation, sum_to_one)\n            left.append(l)\n            right.append(r)\n        except GroupNotFoundError as e:\n            if raise_if_group_missing:\n                raise e\n            else:\n                warnings.warn(str(e))\n\n    if not left:\n        return None, None\n\n    return np.array(left), np.array(right)"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    n_groups, n_assets = groups.shape\n    left_matrix = np.zeros((len(equations), n_assets))\n    right_matrix = np.zeros(len(equations))\n\n    for i, equation in enumerate(equations):\n        try:\n            left, right = _string_to_equation(groups, equation, sum_to_one)\n            left_matrix[i, :] = left\n            right_matrix[i] = right\n        except GroupNotFoundError as e:\n            if raise_if_group_missing:\n                raise e\n            else:\n                warnings.warn(str(e))\n\n    return left_matrix, right_matrix"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    n_groups, n_assets = groups.shape\n    n_equations = len(equations)\n\n    left = np.zeros((n_equations, n_assets))\n    right = np.zeros(n_equations)\n\n    for i, eq in enumerate(equations):\n        try:\n            left[i, :], right[i] = _string_to_equation(groups, eq, sum_to_one)\n        except GroupNotFoundError as e:\n            if raise_if_group_missing:\n                raise e\n            else:\n                warnings.warn(str(e))\n\n    return left, right"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    if isinstance(groups, list):\n        groups = np.array(groups)\n    if not isinstance(groups, np.ndarray):\n        raise EquationToMatrixError(f\"{names[0]} should be a numpy array\") from None\n    if isinstance(equations, list):\n        equations = np.array(equations)\n    if not isinstance(equations, np.ndarray):\n        raise EquationToMatrixError(f\"{names[1]} should be a numpy array\") from None\n\n    left = []\n    right = []\n    for equation in equations:\n        try:\n            l, r = _string_to_equation(groups, equation, sum_to_one)\n            left.append(l)\n            right.append(r)\n        except GroupNotFoundError as e:\n            if raise_if_group_missing:\n                raise e\n            else:\n                warnings.warn(str(e))\n\n    if len(left) == 0:\n        return None, None\n\n    return np.array(left), np.array(right)"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "\n    n_groups, n_assets = np.array(groups).shape\n    left = np.zeros((len(equations), n_assets))\n    right = np.zeros(len(equations))\n\n    for i, equation in enumerate(equations):\n        try:\n            left[i], right[i] = _string_to_equation(\n                groups=np.array(groups),\n                string=equation,\n                sum_to_one=sum_to_one,\n            )\n        except GroupNotFoundError as e:\n            if raise_if_group_missing:\n                raise e\n            else:\n                warnings.warn(str(e))\n\n    return left, right"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "\n    n = groups.shape[1]\n    left = np.zeros((len(equations), n))\n    right = np.zeros(len(equations))\n\n    for i, equation in enumerate(equations):\n        try:\n            left[i], right[i] = _string_to_equation(groups, equation, sum_to_one)\n        except GroupNotFoundError as e:\n            if raise_if_group_missing:\n                raise e\n            else:\n                warnings.warn(str(e))\n\n    return left, right"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "\n    n_groups, n_assets = groups.shape\n    left = np.zeros((len(equations), n_assets))\n    right = np.zeros(len(equations))\n\n    for i, equation in enumerate(equations):\n        try:\n            left[i], right[i] = _string_to_equation(groups, equation, sum_to_one)\n        except GroupNotFoundError as e:\n            if raise_if_group_missing:\n                raise e\n            else:\n                warnings.warn(str(e))\n\n    return left, right"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    n_groups, n_assets = np.shape(groups)\n    left = np.zeros((len(equations), n_assets))\n    right = np.zeros(len(equations))\n\n    for i, equation in enumerate(equations):\n        try:\n            left[i, :], right[i] = _string_to_equation(groups, equation, sum_to_one)\n        except GroupNotFoundError as e:\n            if raise_if_group_missing:\n                raise e\n            else:\n                warnings.warn(str(e))\n\n    if np.all(left == 0):\n        warnings.warn(f\"No groups from the equations were found in the input {names[0]}\")\n        return None\n\n    return left, right"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    n = groups.shape[1]\n    left = np.zeros((len(equations), n))\n    right = np.zeros(len(equations))\n    for i, eq in enumerate(equations):\n        try:\n            left[i, :], right[i] = _string_to_equation(groups, eq, sum_to_one)\n        except GroupNotFoundError as e:\n            if raise_if_group_missing:\n                raise e\n            else:\n                warnings.warn(str(e))\n\n    return left, right"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    n_groups, n_assets = groups.shape\n    left = np.zeros((len(equations), n_assets))\n    right = np.zeros(len(equations))\n\n    for i, equation in enumerate(equations):\n        try:\n            left[i], right[i] = _string_to_equation(groups, equation, sum_to_one)\n        except GroupNotFoundError as e:\n            if raise_if_group_missing:\n                raise e\n            else:\n                warnings.warn(str(e))\n\n    return left, right"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    n_groups = len(groups)\n    n_assets = len(groups[0])\n\n    left_matrix = []\n    right_matrix = []\n\n    for equation in equations:\n        left, right = _string_to_equation(groups, equation, sum_to_one)\n        if raise_if_group_missing and not np.any(left):\n            raise GroupNotFoundError(\n                f\"None of the groups in the equation '{equation}' were found in the groups\"\n                f\" {groups}\"\n            )\n        elif not np.any(left):\n            warnings.warn(\n                f\"None of the groups in the equation '{equation}' were found in the groups\"\n                f\" {groups}\"\n            )\n        left_matrix.append(left)\n        right_matrix.append(right)\n\n    return np.array(left_matrix), np.array(right_matrix)"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    cls_name, cls_def = _gen_instance_module(fields)\n    with tempfile.TemporaryDirectory() as d:\n        file_path = os.path.join(d, \"instances.py\")\n        with open(file_path, \"w\") as f:\n            f.write(cls_def)\n        module = _import(file_path)\n        newInstances = getattr(module, cls_name)\n        _add_instances_conversion_methods(newInstances)\n        with torch.jit._disable_tracing():\n            with patch_builtin_len([module.__name__]):\n                with freeze_training_mode(newInstances):\n                    with torch.jit.optimized_execution(True):\n                        with torch.jit.scope(capture_as_const=True):\n                            yield newInstances"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    cls_name, module_str = _gen_instance_module(fields)\n\n    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as f:\n        f.write(module_str)\n        temp_file = f.name\n\n    mod = _import(temp_file)\n    newInstances = getattr(mod, cls_name)\n    _add_instances_conversion_methods(newInstances)\n\n    # Replace the original Instances with the newInstances\n    original_instances = Instances\n    Instances = newInstances\n\n    try:\n        yield newInstances\n    finally:\n        # Clean up\n        Instances = original_instances\n        os.remove(temp_file)"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    cls_name, cls_def = _gen_instance_module(fields)\n    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as f:\n        f.write(cls_def)\n        module_name = f.name\n    module = _import(module_name)\n    newInstances = getattr(module, cls_name)\n    _add_instances_conversion_methods(newInstances)\n\n    class _PatchInstances:\n        def __enter__(self):\n            global Instances\n            self.prev_instances = Instances\n            Instances = newInstances\n\n        def __exit__(self, *args):\n            global Instances\n            Instances = self.prev_instances\n\n    return _PatchInstances()"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    cls_name, cls_def = _gen_instance_module(fields)\n    with tempfile.TemporaryDirectory(prefix=\"detectron2\") as d:\n        file_path = os.path.join(d, f\"{cls_name}.py\")\n        with open(file_path, \"w\") as f:\n            f.write(cls_def)\n        module = _import(file_path)\n        with ExitStack() as stack:\n            stack.enter_context(mock.patch.dict(sys.modules, {module.__name__: module}))\n            stack.enter_context(_patch_instances_methods(module))\n            yield getattr(module, cls_name)"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "\n    cls_name, module_str = _gen_instance_module(fields)\n    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as f:\n        f.write(module_str)\n        module_path = f.name\n\n    module = _import(module_path)\n    newInstances = getattr(module, cls_name)\n\n    _add_instances_conversion_methods(newInstances)\n\n    with ExitStack() as stack:\n        # replace the original Instances class with the new one\n        stack.enter_context(mock.patch(\"detectron2.structures.Instances\", newInstances))\n\n        # patch the builtin len() function for the newInstances class\n        stack.enter_context(patch_builtin_len([module.__name__]))\n\n        yield newInstances\n\n    os.remove(module_path)"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    cls_name, cls_def = _gen_instance_module(fields)\n    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as f:\n        f.write(cls_def)\n        module_name = f.name[:-3].replace(os.sep, \".\").replace(\"/\", \".\")\n    mod = _import(module_name)\n    with torch.jit._disable_tracing():\n        _add_instances_conversion_methods(getattr(mod, cls_name))\n    yield\n    del sys.modules[mod.__name__]"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    cls_name, cls_def = _gen_instance_module(fields)\n    with tempfile.NamedTemporaryFile(\"w\", delete=False) as f:\n        f.write(cls_def)\n    module = _import(f.name)\n    return module.__dict__[cls_name]"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    cls_name, module_str = _gen_instance_module(fields)\n    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as f:\n        f.write(module_str)\n        temp_file_path = f.name\n\n    try:\n        module = _import(temp_file_path)\n        new_instances = getattr(module, cls_name)\n        _add_instances_conversion_methods(new_instances)\n        with ExitStack() as stack:\n            stack.enter_context(\n                mock.patch.dict(sys.modules, {module.__name__: module, module.__name__.split(\".\")[0]: module})\n            )\n            yield new_instances\n    finally:\n        os.remove(temp_file_path)"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    cls_name, module_str = _gen_instance_module(fields)\n    with tempfile.NamedTemporaryFile(\"w\", delete=False) as f:\n        f.write(module_str)\n        temp_file_path = f.name\n\n    # import the temporary module\n    new_instances = _import(temp_file_path)\n    _add_instances_conversion_methods(new_instances)\n\n    # clean up\n    os.unlink(temp_file_path)\n\n    return new_instances"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    cls_name, cls_def = _gen_instance_module(fields)\n    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as f:\n        f.write(cls_def)\n        path = f.name\n    module = _import(path)\n    _add_instances_conversion_methods(module.__dict__[cls_name])\n    return module.__dict__[cls_name]"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "\n    cls_name, cls_def = _gen_instance_module(fields)\n    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as f:\n        f.write(cls_def)\n        file_path = f.name\n\n    module = _import(file_path)\n    newInstances = getattr(module, cls_name)\n    _add_instances_conversion_methods(newInstances)\n\n    # Patch the Instances class\n    originalInstances = Instances\n    Instances = newInstances\n\n    try:\n        yield newInstances\n    finally:\n        # Clean up\n        Instances = originalInstances\n        os.remove(file_path)"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    cls_name, cls_def = _gen_instance_module(fields)\n    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as f:\n        f.write(cls_def)\n        temp_file_path = f.name\n    module = _import(temp_file_path)\n    _add_instances_conversion_methods(module.__dict__[cls_name])\n    return _patch_instances_context_manager(cls_name, module, temp_file_path)"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "\n    cls_name, module_str = _gen_instance_module(fields)\n\n    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as f:\n        f.write(module_str)\n        module_path = f.name\n\n    module = _import(module_path)\n\n    # replace the original Instances class with the new one\n    original_instances = Instances\n    Instances.__module__ = module.__name__\n    Instances.__name__ = cls_name\n    module.__dict__[cls_name] = Instances\n\n    def cleanup():\n        Instances.__module__ = original_instances.__module__\n        Instances.__name__ = original_instances.__name__\n        module.__dict__[cls_name] = original_instances\n        os.remove(module_path)\n\n    return ExitStack().callback(cleanup)"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    cls_name, cls_def = _gen_instance_module(fields)\n    with tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as f:\n        f.write(cls_def)\n        module_name = f.name\n    module = _import(module_name)\n    newInstances = getattr(module, cls_name)\n    _add_instances_conversion_methods(newInstances)\n    with ExitStack() as stack:\n        stack.enter_context(mock.patch(\"detectron2.structures.Instances\", newInstances))\n        yield"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    cls_name, cls_def = _gen_instance_module(fields)\n    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as f:\n        f.write(cls_def)\n        temp_file = f.name\n\n    # import the new class\n    newInstances = _import(temp_file)\n\n    # add from_instances methods to the scripted Instances class\n    _add_instances_conversion_methods(newInstances)\n\n    # yield the new class\n    yield newInstances\n\n    # clean up\n    os.remove(temp_file)"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    cls_name, cls_def = _gen_instance_module(fields)\n    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as f:\n        f.write(cls_def)\n        module_name = f.name\n    try:\n        module = _import(module_name)\n        instances = module.__dict__[cls_name]\n        _add_instances_conversion_methods(instances)\n        with ExitStack() as stack:\n            stack.enter_context(mock.patch(\"detectron2.structures.Instances\", instances))\n            yield instances\n    finally:\n        os.remove(module_name)"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    cls_name, cls_def = _gen_instance_module(fields)\n    with tempfile.TemporaryDirectory(prefix=\"detectron2_torchscript\") as d:\n        file_path = os.path.join(d, \"instances.py\")\n        with open(file_path, \"w\") as f:\n            f.write(cls_def)\n        module = _import(file_path)\n        with ExitStack() as stack:\n            stack.enter_context(mock.patch.dict(sys.modules, {module.__name__: module}))\n            stack.enter_context(_add_instances_conversion_methods(module))\n            yield getattr(module, cls_name)"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    cls_name, mod_str = _gen_instance_module(fields)\n\n    with tempfile.NamedTemporaryFile(\"w\", delete=False, mode=\"w\") as f:\n        f.write(mod_str)\n        temp_file = f.name\n\n    module = _import(temp_file)\n    newInstances = getattr(module, cls_name)\n\n    _add_instances_conversion_methods(newInstances)\n\n    # Patch the original Instances class with the new one\n    original_instances = Instances\n    Instances = newInstances\n\n    try:\n        yield newInstances\n    finally:\n        # Clean up\n        os.remove(temp_file)\n        Instances = original_instances"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "\n    cls_name, cls_def = _gen_instance_module(fields)\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as f:\n        f.write(cls_def)\n        path = f.name\n    module = _import(path)\n\n    with ExitStack() as stack:\n        stack.enter_context(mock.patch(\"detectron2.structures.Instances\", module.__dict__[cls_name]))\n        stack.enter_context(_patch_builtin_len([module.__name__]))\n\n        yield module.__dict__[cls_name]\n\n    os.remove(path)"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    cls_name, module_str = _gen_instance_module(fields)\n    with tempfile.NamedTemporaryFile(\"w\", delete=False, suffix=\".py\") as f:\n        f.write(module_str)\n        module_path = f.name\n    try:\n        module = _import(module_path)\n        new_instances = getattr(module, cls_name)\n        _add_instances_conversion_methods(new_instances)\n        with torch.jit._disable_tracing():\n            with torch.jit.fork():\n                with torch.jit.optimized_execution(False):\n                    yield new_instances\n    finally:\n        os.remove(module_path)"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "\n    class FreezeTrainingModeContext:\n        def __init__(self, model):\n            self.model = model\n            self.training_states = {}\n\n        def __enter__(self):\n            for module in self.model.modules():\n                if hasattr(module, \"training\"):\n                    self.training_states[module] = module.training\n                    module.training = False\n\n        def __exit__(self, *args):\n            for module, training_state in self.training_states.items():\n                module.training = training_state\n\n    return FreezeTrainingModeContext(model)"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "\n    with torch.no_grad():\n        for param in model.parameters():\n            param.requires_grad = False"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "\n    with torch.no_grad():\n        for param in model.parameters():\n            param.requires_grad = False"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "\n    class FreezeTrainingModeContext:\n        def __init__(self, model):\n            self.model = model\n            self.training_states = {}\n\n        def __enter__(self):\n            for module in self.model.modules():\n                if hasattr(module, \"training\"):\n                    self.training_states[module] = module.training\n                    module.training = False\n\n        def __exit__(self, *args):\n            for module, training_state in self.training_states.items():\n                module.training = training_state\n\n    return FreezeTrainingModeContext(model)"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "\n    with torch.no_grad():\n        for param in model.parameters():\n            param.requires_grad = False"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    with torch.no_grad():\n        for param in model.parameters():\n            param.requires_grad = False"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    class FreezeTrainingModeContext:\n        def __init__(self, model):\n            self.model = model\n            self.training_states = {}\n\n        def __enter__(self):\n            for module in self.model.modules():\n                if hasattr(module, \"training\"):\n                    self.training_states[module] = module.training\n                    module.training = False\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            for module, training_state in self.training_states.items():\n                module.training = training_state\n\n    return FreezeTrainingModeContext(model)"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    with torch.no_grad():\n        for param in model.parameters():\n            param.requires_grad = False"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    class FreezeTrainingMode:\n        def __init__(self, model):\n            self.model = model\n            self.training_states = {}\n\n        def __enter__(self):\n            for name, module in self.model.named_modules():\n                if hasattr(module, \"training\"):\n                    self.training_states[name] = module.training\n                    module.training = False\n\n        def __exit__(self, type, value, traceback):\n            for name, module in self.model.named_modules():\n                if hasattr(module, \"training\"):\n                    module.training = self.training_states[name]\n\n    return FreezeTrainingMode(model)"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    class FreezeTrainingModeContext:\n        def __init__(self, model):\n            self.model = model\n            self.training_states = {}\n\n        def __enter__(self):\n            for module in self.model.modules():\n                if isinstance(module, torch.nn.Module):\n                    self.training_states[module] = module.training\n                    module.training = False\n\n        def __exit__(self, type, value, traceback):\n            for module, training_state in self.training_states.items():\n                module.training = training_state\n\n    return FreezeTrainingModeContext(model)"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "\n    with torch.no_grad():\n        for param in model.parameters():\n            param.requires_grad = False"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    with torch.no_grad():\n        for param in model.parameters():\n            param.requires_grad = False"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "\n    class _FreezeTrainingModeContext:\n        def __init__(self, model):\n            self.model = model\n            self.training_states = {}\n\n        def __enter__(self):\n            for module in self.model.modules():\n                if isinstance(module, torch.nn.Module):\n                    self.training_states[module] = module.training\n                    module.training = False\n\n        def __exit__(self, type, value, traceback):\n            for module, training_state in self.training_states.items():\n                module.training = training_state\n\n    return _FreezeTrainingModeContext(model)"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    class FreezeTrainingModeContext:\n        def __init__(self, model):\n            self.model = model\n            self.training_states = {}\n\n        def __enter__(self):\n            for module in self.model.modules():\n                if isinstance(module, torch.nn.Module):\n                    self.training_states[module] = module.training\n                    module.training = False\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            for module, training_state in self.training_states.items():\n                module.training = training_state\n\n    return FreezeTrainingModeContext(model)"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "\n    class FreezeTrainingModeContext:\n        def __init__(self, model):\n            self.model = model\n            self.training_states = {}\n\n        def __enter__(self):\n            for module in self.model.modules():\n                if hasattr(module, \"training\"):\n                    self.training_states[module] = module.training\n                    module.training = False\n\n        def __exit__(self, type, value, traceback):\n            for module, training_state in self.training_states.items():\n                module.training = training_state\n\n    return FreezeTrainingModeContext(model)"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    class FreezeTrainingModeContext:\n        def __init__(self, model):\n            self.model = model\n            self.training_states = {}\n\n        def __enter__(self):\n            for module in self.model.modules():\n                if isinstance(module, torch.nn.Module):\n                    self.training_states[module] = module.training\n                    module.train(False)\n\n        def __exit__(self, type, value, traceback):\n            for module, training_state in self.training_states.items():\n                module.train(training_state)\n\n    return FreezeTrainingModeContext(model)"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    class FreezeTrainingModeContext:\n        def __init__(self, model):\n            self.model = model\n            self.training_states = {}\n\n        def __enter__(self):\n            for module in self.model.modules():\n                if isinstance(module, torch.nn.Module):\n                    self.training_states[module] = module.training\n                    module.training = False\n\n        def __exit__(self, *args):\n            for module, training_state in self.training_states.items():\n                module.training = training_state\n\n    return FreezeTrainingModeContext(model)"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    class FreezeTrainingModeContext:\n        def __init__(self, model):\n            self.model = model\n            self.training_states = {}\n\n        def __enter__(self):\n            for module in self.model.modules():\n                if isinstance(module, torch.nn.Module):\n                    self.training_states[module] = module.training\n                    module.training = False\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            for module, training_state in self.training_states.items():\n                module.training = training_state\n\n    return FreezeTrainingModeContext(model)"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    class FreezingContext:\n        def __init__(self, model):\n            self.model = model\n            self.training_states = {}\n\n        def __enter__(self):\n            for module in self.model.modules():\n                if isinstance(module, torch.nn.Module):\n                    self.training_states[module] = module.training\n                    module.train(False)\n\n        def __exit__(self, type, value, traceback):\n            for module, training_state in self.training_states.items():\n                module.train(training_state)\n\n    return FreezingContext(model)"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    class FreezeTrainingModeContext:\n        def __enter__(self):\n            for module in model.modules():\n                module._original_training_mode = module.training\n                module.training = False\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            for module in model.modules():\n                module.training = module._original_training_mode\n                del module._original_training_mode\n\n    return FreezeTrainingModeContext()"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.sqrt(safe_x)"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.sqrt(safe_x)"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.sqrt(safe_x)"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.sqrt(safe_x)"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.sqrt(safe_x)"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.sqrt(safe_x)"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.sqrt(safe_x)"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.sqrt(safe_x)"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.sqrt(safe_x)"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.sqrt(safe_x)"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.sqrt(safe_x)"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.sqrt(safe_x)"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.sqrt(safe_x)"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.sqrt(safe_x)"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.sqrt(safe_x)"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.sqrt(safe_x)"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.sqrt(safe_x)"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.sqrt(safe_x)"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.sqrt(safe_x)"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.sqrt(safe_x)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  homogeneous_vectors = to_homogeneous(vectors)\n  transformed_vectors = jnp.matmul(homogeneous_vectors, jnp.transpose(transform))\n  return from_homogeneous(transformed_vectors)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return jnp.dot(vectors, transform[..., :-1].T) + transform[..., -1]"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return jnp.dot(vectors, transform[..., :-1].T) + transform[..., -1]"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return jnp.dot(vectors, transform.T)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  homogeneous_vectors = to_homogeneous(vectors)\n  transformed_homogeneous_vectors = jnp.matmul(homogeneous_vectors, transform.T)\n  return from_homogeneous(transformed_homogeneous_vectors)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Convert the vectors to homogeneous representation\n  homogeneous_vectors = to_homogeneous(vectors)\n\n  # Apply the transformation\n  transformed_vectors = jnp.matmul(homogeneous_vectors, transform.T)\n\n  # Convert the transformed vectors back to non-homogeneous representation\n  return from_homogeneous(transformed_vectors)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  homogeneous_vectors = to_homogeneous(vectors)\n  transformed_homogeneous_vectors = matmul(homogeneous_vectors, transform.T)\n  return from_homogeneous(transformed_homogeneous_vectors)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return jnp.dot(vectors, transform.T)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  homogeneous_vectors = to_homogeneous(vectors)\n  transformed_vectors = jnp.matmul(homogeneous_vectors, transform.T)\n  return from_homogeneous(transformed_vectors)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  homogeneous_vectors = to_homogeneous(vectors)\n  transformed_vectors = jnp.einsum('...ij,...j->...i', transform, homogeneous_vectors)\n  return from_homogeneous(transformed_vectors)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return jnp.dot(vectors, transform.T)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return jnp.dot(vectors, transform.T)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Convert the vectors to homogeneous representation\n  homogeneous_vectors = to_homogeneous(vectors)\n\n  # Apply the transformation\n  transformed_vectors = jnp.matmul(transform, homogeneous_vectors.T).T\n\n  # Convert the transformed vectors back to non-homogeneous representation\n  return from_homogeneous(transformed_vectors)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  homogeneous_vectors = to_homogeneous(vectors)\n  transformed_vectors = jnp.matmul(homogeneous_vectors, transform.T)\n  return from_homogeneous(transformed_vectors)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  homogeneous_vectors = to_homogeneous(vectors)\n  transformed_vectors = jnp.matmul(homogeneous_vectors, transform.T)\n  return from_homogeneous(transformed_vectors)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  homogeneous_vectors = to_homogeneous(vectors)\n  transformed_vectors = jnp.matmul(homogeneous_vectors, transform.T)\n  return from_homogeneous(transformed_vectors)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  homogeneous_vectors = to_homogeneous(vectors)\n  transformed_vectors = jnp.matmul(homogeneous_vectors, transform.T)\n  return from_homogeneous(transformed_vectors)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  homogeneous_vectors = to_homogeneous(vectors)\n  transformed_vectors = jnp.matmul(homogeneous_vectors, transform.T)\n  return from_homogeneous(transformed_vectors)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  homogeneous_vectors = to_homogeneous(vectors)\n  transformed_homogeneous_vectors = jnp.matmul(homogeneous_vectors, transform.T)\n  return from_homogeneous(transformed_homogeneous_vectors)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Convert vectors to homogeneous coordinates\n  homogeneous_vectors = to_homogeneous(vectors)\n\n  # Apply the homogeneous transformation\n  transformed_vectors = jnp.matmul(homogeneous_vectors, transform.T)\n\n  # Convert back to non-homogeneous coordinates\n  return from_homogeneous(transformed_vectors)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n\n  # Compute the width of each interval in tp.\n  dt = jnp.diff(tp)\n\n  # Compute the width of each interval in t.\n  dtq = jnp.diff(t)\n\n  # Compute the values at the new intervals defined by t.\n  vq = jnp.zeros(t.shape[:-1] + (tp.shape[-1],))\n  for i in range(tp.shape[-1]):\n    # Find the intervals in t that overlap with the interval in tp.\n    overlap = (t[Ellipsis, :-1] < tp[i]) & (tp[i] <= t[Ellipsis, 1:])\n    # Calculate the contribution of the original interval to the new intervals.\n    if use_avg:\n      vq += vp[Ellipsis, i:i + 1] * overlap * (tp[i + 1] - tp[i]) / dtq\n    else:\n      vq += vp[Ellipsis, i:i + 1] * overlap\n\n  return vq"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  utils.assert_valid_stepfun(t, jnp.ones_like(t))\n  \n  # Compute the widths of the original intervals.\n  dt = jnp.diff(tp)\n  \n  # Compute the widths of the new intervals.\n  dt_new = jnp.diff(t)\n  \n  # Compute the weights for averaging based on the new interval widths.\n  weights = dt_new / jnp.sum(dt_new, axis=-1, keepdims=True) if use_avg else dt_new\n  \n  # Compute the values of the resampled step function at the new intervals.\n  resampled_values = jnp.sum(query(t, tp, vp, left=0, right=0) * weights, axis=-1)\n  \n  return resampled_values"}
{"namespace": "stepfun.resample", "completion": "  # Compute the widths of the original intervals.\n  dt = jnp.diff(tp)\n\n  # Compute the widths of the new intervals.\n  dtq = jnp.diff(t)\n\n  # Compute the weights for each original interval.\n  w = vp * dt\n\n  # Initialize the resampled values.\n  vp_resampled = jnp.zeros(t.shape[:-1])\n\n  # Loop over the new intervals and compute the resampled values.\n  for i in range(len(t) - 1):\n      # Find the original intervals that intersect with the current new interval.\n      overlap = jnp.logical_and(tp[:-1] < t[i + 1], tp[1:] > t[i])\n\n      # Compute the weights for the intersecting original intervals.\n      w_overlap = jnp.where(overlap, w, 0)\n\n      if use_avg:\n          # Compute the average value, weighted by the width of each original interval.\n          vp_resampled = jax.ops.index_add(vp_resampled, jax.ops.index[i], jnp.sum(w_overlap * vp) / dtq[i])\n      else:\n          # Sum the values of the original intervals for each new interval.\n          vp_resampled = jax.ops.index_add(vp_resampled, jax.ops.index[i], jnp.sum(w_overlap))\n\n  return vp_resampled"}
{"namespace": "stepfun.resample", "completion": "  # Compute the widths of the original intervals.\n  dt = jnp.diff(tp)\n\n  # Compute the widths of the new intervals.\n  dtq = jnp.diff(t)\n\n  # Compute the weights for each interval in t.\n  weights = jnp.zeros_like(t)\n\n  for i in range(len(t)):\n    # Find the original intervals that overlap with the new interval.\n    overlap = jnp.logical_and(tp[:-1] < t[i], t[i] <= tp[1:])\n    \n    # Compute the contribution of each original interval to the new interval.\n    contribution = jnp.minimum(tp[1:], t[i] + dtq[i]) - jnp.maximum(tp[:-1], t[i])\n    \n    # Weight the contribution based on the resampling method.\n    if use_avg:\n      weights = jax.ops.index_add(weights, i, jnp.sum(vp[overlap] * contribution / dt[overlap]))\n    else:\n      weights = jax.ops.index_add(weights, i, jnp.sum(vp[overlap]))\n\n  return weights"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  # Compute the widths of the original intervals.\n  dt = jnp.diff(tp)\n\n  # Compute the widths of the new intervals.\n  dtq = jnp.diff(t)\n\n  # Compute the weights for the resampling.\n  weights = jnp.where(dtq == 0, 0, dt / dtq)\n\n  # Initialize the resampled values to 0.\n  vq = jnp.zeros(t.shape[:-1] + (tp.shape[-1],))\n\n  # Iterate over the original intervals and accumulate the resampled values.\n  for i in range(tp.shape[-1] - 1):\n    # Find the new intervals that overlap with the current original interval.\n    overlap = (tp[i] < t[Ellipsis, 1:]) & (tp[i + 1] > t[Ellipsis, :-1])\n    # Compute the contribution of the original interval to the new intervals.\n    contribution = jnp.minimum(tp[i + 1], t[Ellipsis, 1:]) - jnp.maximum(tp[i], t[Ellipsis, :-1])\n    # Accumulate the contribution, weighted by the resampling weights.\n    vq += jnp.where(overlap, contribution * vp[Ellipsis, i:i + 1] * weights, 0)\n\n  # If use_avg is True, divide the accumulated values by the width of the new intervals.\n  if use_avg:\n    vq /= dtq\n\n  return vq"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n\n  # Compute the width of the original intervals.\n  dt = jnp.diff(tp)\n\n  # Compute the width of the new intervals.\n  dtq = jnp.diff(t)\n\n  # Compute the values of the resampled step function at the new intervals.\n  if use_avg:\n    # Compute the weighted average of the values based on the width of each interval.\n    weights = jnp.minimum(dtq, dt[Ellipsis, :-1]) / dt[Ellipsis, :-1]\n    vp_resampled = jnp.sum(weights * vp, axis=-1)\n  else:\n    # Sum the values of the original step function for each interval in t.\n    vp_resampled = jnp.sum(\n        vp[..., :-1] * jnp.minimum(dtq, dt[Ellipsis, :-1]) / dt[Ellipsis, :-1],\n        axis=-1,\n    )\n\n  return vp_resampled"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  # Compute the widths of the original intervals.\n  dt = jnp.diff(tp)\n\n  # Compute the widths of the new intervals.\n  dtq = jnp.diff(t)\n\n  # Compute the weights for the resampling.\n  weights = jnp.where(dt == 0, 0, vp * dt)\n\n  if use_avg:\n    # Compute the average value, weighted by the width of each interval in `t`.\n    weights = weights / dt\n  else:\n    # Sum the values of the step function for each interval in `t`.\n    weights = weights\n\n  # Perform the resampling.\n  resampled_values = query((t[Ellipsis, 1:] + t[Ellipsis, :-1]) / 2, tp, weights)\n\n  return resampled_values"}
{"namespace": "stepfun.resample", "completion": "  # Compute the width of each interval in the original step function\n  dt = jnp.diff(tp)\n\n  # Compute the width of each interval in the new step function\n  dtq = jnp.diff(t)\n\n  # Compute the values of the resampled step function at the new intervals defined by t\n  if use_avg:\n    # Compute the average value, weighted by the width of each interval in t\n    vp_weighted = vp * dt\n    vp_resampled = jnp.zeros(t.shape[:-1])\n    for i in range(len(t) - 1):\n      mask = (tp >= t[i]) & (tp < t[i+1])\n      vp_resampled += jnp.sum(vp_weighted[mask]) / dtq[i]\n  else:\n    # Sum the values of the step function for each interval in t\n    vp_resampled = jnp.zeros(t.shape[:-1])\n    for i in range(len(t) - 1):\n      mask = (tp >= t[i]) & (tp < t[i+1])\n      vp_resampled += jnp.sum(vp[mask])\n\n  return vp_resampled"}
{"namespace": "stepfun.resample", "completion": "  # Compute the width of the original intervals.\n  dt = jnp.diff(tp)\n\n  # Compute the width of the new intervals.\n  dtq = jnp.diff(t)\n\n  # Compute the weights for resampling based on the original intervals.\n  if use_avg:\n    weights = dt / dtq\n  else:\n    weights = dt\n\n  # Resample the values of the step function at the new intervals.\n  resampled_values = jnp.zeros(t.shape[:-1] + (vp.shape[-1],))\n  for i in range(len(t) - 1):\n    mask = (tp >= t[i]) & (tp < t[i + 1])\n    resampled_values += jnp.where(mask, vp * weights[i], 0)\n\n  return resampled_values"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n\n  # Compute the width of the original intervals.\n  dt = jnp.diff(tp)\n\n  # Compute the width of the new intervals.\n  dtq = jnp.diff(t)\n\n  # Compute the weights for the resampling based on the method chosen.\n  if use_avg:\n    weights = dtq / dt\n  else:\n    weights = jnp.ones_like(dtq)\n\n  # Compute the resampled values.\n  vp_resampled = query(t, tp, vp) * weights\n\n  return vp_resampled"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n\n  # Compute the width of the original intervals.\n  dt = jnp.diff(tp)\n\n  # Compute the width of the new intervals.\n  dtq = jnp.diff(t)\n\n  # Compute the weights for the resampling based on the method selected.\n  if use_avg:\n    w = vp * dt\n  else:\n    w = vp\n\n  # Compute the cumulative sum of the weights for the original step function.\n  cw = jnp.cumsum(w, axis=-1)\n\n  # Compute the cumulative sum of the weights for the new intervals.\n  cwq = integrate_weights(w)\n\n  # Interpolate the cumulative sums to get the values at the new intervals.\n  vq = math.sorted_interp(cwq / cw[-1], vp, tp, utils.device_is_tpu())\n\n  # Adjust the values based on the width of the new intervals.\n  if use_avg:\n    vq *= dtq / dt\n\n  return vq"}
{"namespace": "stepfun.resample", "completion": "  # Compute the widths of the original intervals.\n  dt = jnp.diff(tp)\n\n  # Compute the widths of the new intervals.\n  dtq = jnp.diff(t)\n\n  # Compute the values of the resampled step function at the new intervals.\n  if use_avg:\n    # Compute the weighted average of the values in each interval.\n    vp_weighted = vp * dt\n    vp_resampled = jnp.zeros(t.shape[:-1] + (t.shape[-1] - 1,))\n    for i in range(len(t) - 1):\n      mask = (tp >= t[i]) & (tp <= t[i + 1])\n      vp_resampled = jax.ops.index_add(vp_resampled, jax.ops.index[i], jnp.sum(vp_weighted[mask]) / dtq[i])\n  else:\n    # Sum the values in each interval.\n    vp_resampled = jnp.zeros(t.shape[:-1] + (t.shape[-1] - 1,))\n    for i in range(len(t) - 1):\n      mask = (tp >= t[i]) & (tp <= t[i + 1])\n      vp_resampled = jax.ops.index_add(vp_resampled, jax.ops.index[i], jnp.sum(vp[mask]))\n\n  return vp_resampled"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n\n  # Compute the width of the original intervals.\n  dt = jnp.diff(tp)\n\n  # Compute the width of the new intervals.\n  dtq = jnp.diff(t)\n\n  # Compute the weights for the resampling.\n  weights = jnp.where(dtq == 0, 0, dt / dtq)\n\n  # Resample the values using the weights.\n  if use_avg:\n    resampled_values = jnp.sum(vp * weights, axis=-1)\n  else:\n    resampled_values = jnp.interp(t[:-1], tp, jnp.cumsum(vp * dt, axis=-1))\n\n  return resampled_values"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n\n  # Compute the widths of the original intervals.\n  dt = jnp.diff(tp)\n\n  # Compute the widths of the new intervals.\n  dtq = jnp.diff(t)\n\n  # Compute the weights for the resampling, either by summing or averaging.\n  if use_avg:\n    weights = dtq / dt\n  else:\n    weights = jnp.where(dt > 0, dtq / dt, 0)\n\n  # Resample the step function values using the computed weights.\n  vp_resampled = jnp.dot(vp, weights)\n\n  return vp_resampled"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n\n  # Compute the width of each interval in `tp`.\n  dt = jnp.diff(tp)\n\n  # Compute the width of each interval in `t`.\n  dtq = jnp.diff(t)\n\n  # Compute the value of the step function at the new intervals defined by `t`.\n  if use_avg:\n    # Compute the weighted average of the values, weighted by the width of each interval in `t`.\n    vp_avg = jnp.divide(vp, dt)\n    vp_resampled = jnp.dot(vp_avg, linspline.compute_integral(tp, jnp.ones_like(vp)))\n    vp_resampled /= dtq\n  else:\n    # Compute the sum of the values for each interval in `t`.\n    vp_resampled = jnp.dot(vp, linspline.compute_integral(tp, jnp.ones_like(vp)))\n\n  return vp_resampled"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n\n  # Compute the widths of the original intervals.\n  dt = jnp.diff(tp)\n\n  # Compute the widths of the new intervals.\n  dtq = jnp.diff(t)\n\n  # Compute the weights for each original interval to be distributed into the new intervals.\n  weights = jnp.where(dt == 0, 0, vp * dt)\n\n  # If use_avg is True, divide the weights by the width of the original intervals.\n  if use_avg:\n    weights = jnp.where(dt == 0, 0, vp)\n\n  # Distribute the weights into the new intervals based on their overlap with the original intervals.\n  wq = linspline.integrate_piecewise_constant(t, tp, weights)\n\n  return wq"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n\n  # Compute the width of the original intervals.\n  dt = jnp.diff(tp)\n\n  # Compute the width of the new intervals.\n  dtq = jnp.diff(t)\n\n  # Compute the weights for the resampling.\n  if use_avg:\n    w = vp * dt\n  else:\n    w = vp\n\n  # Resample the weights into the new intervals.\n  wq = jnp.zeros(t.shape[:-1] + (t.shape[-1] - 1,))\n  for i in range(t.shape[-1] - 1):\n    # Find the original intervals that overlap with the new interval.\n    mask = (tp >= t[i]) & (tp <= t[i + 1])\n    # Compute the weighted sum of the original values that overlap with the new interval.\n    wq[..., i] = jnp.sum(w[..., mask], axis=-1)\n\n  # Adjust the resampled weights for the width of the new intervals.\n  if use_avg:\n    wq /= dtq\n\n  return wq"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  utils.assert_valid_stepfun(t, jnp.ones_like(t))\n\n  # Compute the widths of the original intervals.\n  dt = jnp.diff(tp)\n\n  # Compute the widths of the new intervals.\n  dtq = jnp.diff(t)\n\n  # Compute the values of the resampled step function.\n  if use_avg:\n    # Compute the average value, weighted by the width of each interval in t.\n    vp_avg = vp / dt\n    vpq = jnp.dot(vp_avg, dtq)\n  else:\n    # Sum the values of the step function for each interval in t.\n    vpq = jnp.dot(vp, dtq / dt)\n\n  return vpq"}
{"namespace": "stepfun.resample", "completion": "  # Compute the width of each interval in t.\n  dt = jnp.diff(t)\n\n  # Initialize the resampled values.\n  vp_resampled = jnp.zeros(t.shape[:-1])\n\n  # Loop over the original intervals defined by tp.\n  for i in range(len(tp) - 1):\n    # Find the indices of the new intervals that overlap with the current original interval.\n    overlap_indices = jnp.where((tp[i] <= t) & (t < tp[i + 1]))\n\n    # Compute the contribution of the original interval to the overlapping new intervals based on the resampling method.\n    if use_avg:\n      contribution = vp[i] * (t[overlap_indices] - tp[i]) / (tp[i + 1] - tp[i])\n    else:\n      contribution = vp[i]\n\n    # Add the contribution to the resampled values at the overlapping new intervals.\n    vp_resampled = jax.ops.index_add(vp_resampled, overlap_indices, contribution)\n\n  return vp_resampled"}
{"namespace": "stepfun.resample", "completion": "  # Compute the widths of the original intervals.\n  dt = jnp.diff(tp)\n\n  # Compute the widths of the new intervals.\n  dt_new = jnp.diff(t)\n\n  # Compute the weights for each original interval.\n  if use_avg:\n    weights = dt / dt.sum()\n  else:\n    weights = dt\n\n  # Compute the weights for each new interval.\n  if use_avg:\n    weights_new = dt_new / dt_new.sum()\n  else:\n    weights_new = dt_new\n\n  # Initialize the resampled values.\n  vp_resampled = jnp.zeros(t.shape[:-1])\n\n  # Iterate over the original intervals and resample the values.\n  for i in range(len(tp) - 1):\n    # Find the new intervals that overlap with the current original interval.\n    overlap = jnp.logical_and(t[:-1] <= tp[i + 1], t[1:] >= tp[i])\n\n    # Compute the intersection widths.\n    intersection_widths = jnp.minimum(t[1:], tp[i + 1]) - jnp.maximum(t[:-1], tp[i])\n\n    # Compute the contribution of the original interval to the overlapping new intervals.\n    contribution = intersection_widths / dt_new[overlap]\n\n    # Update the resampled values for the overlapping new intervals.\n    vp_resampled = jax.ops.index_add(vp_resampled, jax.ops.index[overlap], contribution * vp[i] * weights[i] * weights_new[overlap])\n\n  return vp_resampled"}
{"namespace": "coord.contract", "completion": "  z_mag_sq = jnp.sum(x**2, axis=-1, keepdims=True)\n  scale = 2 * jnp.sqrt(z_mag_sq) - z_mag_sq\n  x = x / scale\n  return x"}
{"namespace": "coord.contract", "completion": "  z_mag_sq = jnp.sum(x**2, axis=-1, keepdims=True)\n  scale = 2 * jnp.sqrt(z_mag_sq) - z_mag_sq\n  return x / scale"}
{"namespace": "coord.contract", "completion": "  z_mag_sq = jnp.sum(x**2, axis=-1, keepdims=True)\n  scale = 2 * jnp.sqrt(z_mag_sq) - z_mag_sq\n  x = x / scale\n  return x"}
{"namespace": "coord.contract", "completion": "  # Clamping to 1 produces correct scale inside |z| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = 2 * jnp.sqrt(z_mag_sq) - z_mag_sq\n  return x / scale"}
{"namespace": "coord.contract", "completion": "  z_mag_sq = jnp.sum(x**2, axis=-1, keepdims=True)\n  scale = 2 * jnp.sqrt(z_mag_sq) - z_mag_sq\n  x = x / scale\n  return x"}
{"namespace": "coord.contract", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = 2 * jnp.sqrt(x_mag_sq) - x_mag_sq\n  z = x * scale\n  return z"}
{"namespace": "coord.contract", "completion": "  z = x\n  z_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = 2 / 3 * jnp.log(2 * jnp.sqrt(z_mag_sq) - 1) - jnp.log(z_mag_sq)\n  x = z * scale\n  return x"}
{"namespace": "coord.contract", "completion": "  z_mag_sq = jnp.sum(x**2, axis=-1, keepdims=True)\n  scale = 2 * jnp.sqrt(z_mag_sq) - z_mag_sq\n  return x / scale"}
{"namespace": "coord.contract", "completion": "  z_mag_sq = jnp.sum(x**2, axis=-1, keepdims=True)\n  scale = jnp.maximum(1, 2 * jnp.sqrt(z_mag_sq) - z_mag_sq)\n  return x / scale"}
{"namespace": "coord.contract", "completion": "  z_mag_sq = jnp.sum(x**2, axis=-1, keepdims=True)\n  scale = 2 * jnp.sqrt(z_mag_sq) - z_mag_sq\n  return x / scale"}
{"namespace": "coord.contract", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = 2 * jnp.sqrt(x_mag_sq) - x_mag_sq\n  z = x / scale\n  return z"}
{"namespace": "coord.contract", "completion": "  z_mag_sq = jnp.sum(x**2, axis=-1, keepdims=True)\n  scale = 2 / 3 * jnp.log(2 * jnp.sqrt(z_mag_sq) - 1) - jnp.log(z_mag_sq)\n  return x * scale"}
{"namespace": "coord.contract", "completion": "  z_mag_sq = jnp.sum(x**2, axis=-1, keepdims=True)\n  scale = 2 * jnp.sqrt(z_mag_sq) - z_mag_sq\n  x = x / scale\n  return x"}
{"namespace": "coord.contract", "completion": "  z_mag_sq = jnp.sum(x**2, axis=-1, keepdims=True)\n  scale = 2 * jnp.sqrt(z_mag_sq) - z_mag_sq\n  return x / scale"}
{"namespace": "coord.contract", "completion": "  z_mag_sq = jnp.sum(x**2, axis=-1, keepdims=True)\n  scale = 2 * jnp.sqrt(z_mag_sq) - z_mag_sq\n  return x / scale"}
{"namespace": "coord.contract", "completion": "  # Clamping to 1 produces correct scale inside |z| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = 2 * jnp.sqrt(z_mag_sq) - z_mag_sq\n  return x / scale"}
{"namespace": "coord.contract", "completion": "  z_mag_sq = jnp.sum(x**2, axis=-1, keepdims=True)\n  scale = 2 * jnp.sqrt(z_mag_sq) - z_mag_sq\n  return x / scale"}
{"namespace": "coord.contract", "completion": "  # Calculate the squared magnitude of the input points\n  x_mag_sq = jnp.sum(x**2, axis=-1, keepdims=True)\n  # Apply the scaling formula\n  scale = 2 * jnp.sqrt(x_mag_sq) - x_mag_sq\n  # Scale the input points towards the origin\n  contracted_x = x / scale\n  return contracted_x"}
{"namespace": "coord.contract", "completion": "  z_mag_sq = jnp.sum(x**2, axis=-1, keepdims=True)\n  scale = 2 / 3 * jnp.log(2 * jnp.sqrt(z_mag_sq) - 1) - jnp.log(z_mag_sq)\n  return x * scale"}
{"namespace": "coord.contract", "completion": "  z_mag_sq = jnp.sum(x**2, axis=-1, keepdims=True)\n  scale = 2 * jnp.sqrt(z_mag_sq) - z_mag_sq\n  return x / scale"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = (jnp.sqrt(x_mag_sq) + 1) / (2 * z)\n  x = scale * z\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = (jnp.sqrt(x_mag_sq) + 1) / (2 * z)\n  x = scale * z\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = (jnp.sqrt(x_mag_sq) + 1) / (2 * z)\n  x = scale * z\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = (1 + jnp.sqrt(1 + 4 * x_mag_sq)) / 2\n  x = z / scale\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = (jnp.sqrt(x_mag_sq) + 1) / (2 * z)\n  x = scale * z\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = (jnp.sqrt(x_mag_sq) + 1) / (2 * z)\n  x = scale * z\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = (jnp.sqrt(x_mag_sq) + 1) / (2 * z)\n  x = scale * z\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = (jnp.sqrt(x_mag_sq) + 1) / (2 * z)\n  x = scale * z\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = (1 + jnp.sqrt(1 + 4 * x_mag_sq)) / 2\n  x = z / scale\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = (jnp.sqrt(x_mag_sq) + 1) / (2 * z)\n  x = scale * z\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = (jnp.sqrt(x_mag_sq) + 1) / (2 * z)\n  x = scale * z\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = (jnp.sqrt(x_mag_sq) + 1) / (2 * z)\n  x = scale * z\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = (jnp.sqrt(x_mag_sq) + 1) / (2 * z)\n  x = scale * z\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = x_mag_sq / (2 * (jnp.sqrt(x_mag_sq) + 1))\n  x = z / scale\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = (jnp.sqrt(x_mag_sq) + 1) / (2 * z)\n  x = scale * z\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = jnp.sqrt(x_mag_sq) / (2 * (1 + jnp.sqrt(1 - x_mag_sq)))\n  x = z / scale\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = jnp.sqrt(x_mag_sq) / (2 * (1 + jnp.sqrt(1 - 1 / x_mag_sq)))\n  x = z / scale\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = jnp.sqrt(x_mag_sq) / (2 * (1 + jnp.sqrt(1 - 4 / (4 * x_mag_sq))))\n  x = z / scale\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  # The inverse operation of the contract function scales the input vector z.\n  # The scaling factor is calculated to correctly reverse the effect of the contract function.\n  scale = jnp.sqrt(jnp.sum(z**2, axis=-1, keepdims=True)) / (2 * jnp.sqrt(jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))) - 1)\n  x = z / scale  # Apply the scaling to the input vector z\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = (jnp.sqrt(x_mag_sq) + 1) / (2 * z)\n  x = scale * z\n  return x"}
{"namespace": "grid_utils.trilerp", "completion": "\n  if datastructure == 'grid':\n    return resample.trilinear_interpolation(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.trilinear_interpolation(values, coordinates)\n  else:\n    raise ValueError(\"Invalid datastructure. Supported data structures are 'grid' and 'hash'.\")"}
{"namespace": "grid_utils.trilerp", "completion": "\n  if datastructure == 'grid':\n    # Trilinear interpolation for 3D voxel grid\n    return resample.trilerp(values, coordinates)\n  elif datastructure == 'hash':\n    # Trilinear interpolation for hashed data structure\n    return hash_resample.trilerp(values, coordinates)\n  else:\n    raise ValueError(\"Invalid datastructure. Supported data structures are 'grid' or 'hash'.\")"}
{"namespace": "grid_utils.trilerp", "completion": "\n  if datastructure == 'grid':\n      # Trilinear interpolation for 3D voxel grid\n      return resample.trilinear_interpolation(values, coordinates)\n  elif datastructure == 'hash':\n      # Trilinear interpolation for hashed data structure\n      return hash_resample.trilinear_interpolation(values, coordinates)\n  else:\n      raise ValueError(\"Invalid datastructure. Supported data structures are 'grid' or 'hash'.\")"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n      # Trilinear interpolation for 3D voxel grid\n      return resample.trilinear_interpolation(values, coordinates)\n  elif datastructure == 'hash':\n      # Trilinear interpolation for hashed data structure\n      return hash_resample.trilinear_interpolation(values, coordinates)\n  else:\n      raise ValueError(\"Invalid datastructure. Supported data structures are 'grid' or 'hash'.\")"}
{"namespace": "grid_utils.trilerp", "completion": "\n  if datastructure == 'grid':\n      return resample.trilinear_interpolation(values, coordinates)\n  elif datastructure == 'hash':\n      return hash_resample.trilinear_interpolation(values, coordinates)\n  else:\n      raise ValueError(\"Invalid datastructure. Supported data structures are 'grid' and 'hash'.\")"}
{"namespace": "grid_utils.trilerp", "completion": "\n  if datastructure == 'grid':\n      return resample.trilinear_interpolation(values, coordinates)\n  elif datastructure == 'hash':\n      return hash_resample.trilinear_interpolation(values, coordinates)\n  else:\n      raise ValueError(\"Invalid datastructure. Only 'grid' or 'hash' are supported as valid data structures.\")"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return resample.trilerp(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.trilerp(values, coordinates)\n  else:\n    raise ValueError(\"Invalid datastructure. Supported data structures are 'grid' or 'hash'.\")"}
{"namespace": "grid_utils.trilerp", "completion": "\n  if datastructure == 'grid':\n      return resample.trilinear_interpolation(values, coordinates)\n  elif datastructure == 'hash':\n      return hash_resample.trilinear_interpolation(values, coordinates)\n  else:\n      raise ValueError(\"Invalid datastructure. Supported data structures are 'grid' and 'hash'.\")"}
{"namespace": "grid_utils.trilerp", "completion": "\n  if datastructure == 'grid':\n      # Trilinear interpolation on a 3D voxel grid\n      return resample.trilerp(values, coordinates)\n  elif datastructure == 'hash':\n      # Trilinear interpolation on a hashed data structure\n      return hash_resample.trilerp(values, coordinates)\n  else:\n      raise ValueError(\"Invalid datastructure. Supported data structures are 'grid' and 'hash'.\")"}
{"namespace": "grid_utils.trilerp", "completion": "\n  if datastructure == 'grid':\n      # Perform trilinear interpolation on a 3D voxel grid\n      return resample.trilinear_interpolation(values, coordinates)\n  elif datastructure == 'hash':\n      # Perform trilinear interpolation on a hashed data structure\n      return hash_resample.trilinear_interpolation(values, coordinates)\n  else:\n      raise ValueError(\"Invalid datastructure. Only 'grid' or 'hash' are supported as valid data structures.\")"}
{"namespace": "grid_utils.trilerp", "completion": "\n  if datastructure == 'grid':\n      # Perform trilinear interpolation on a 3D voxel grid\n      # Code for trilinear interpolation on a 3D voxel grid\n      pass\n  elif datastructure == 'hash':\n      # Perform trilinear interpolation on a hashed data structure\n      # Code for trilinear interpolation on a hashed data structure\n      pass\n  else:\n      raise ValueError(\"Invalid datastructure. Supported data structures are 'grid' and 'hash'.\")"}
{"namespace": "grid_utils.trilerp", "completion": "\n  if datastructure == 'grid':\n      # Trilinear interpolation for 3D voxel grid\n      return resample.trilinear_interpolation(values, coordinates)\n  elif datastructure == 'hash':\n      # Trilinear interpolation for hashed data structure\n      return hash_resample.trilinear_interpolation(values, coordinates)\n  else:\n      raise ValueError(\"Invalid datastructure. Supported data structures are 'grid' or 'hash'.\")"}
{"namespace": "grid_utils.trilerp", "completion": "\n  if datastructure == 'grid':\n    return resample.trilinear_interpolation(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.hash_trilinear_interpolation(values, coordinates)\n  else:\n    raise ValueError(\"Invalid datastructure. Supported data structures are 'grid' or 'hash'.\")"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n      # Trilinear interpolation for 3D voxel grid\n      return resample.trilinear_interpolation(values, coordinates)\n  elif datastructure == 'hash':\n      # Trilinear interpolation for hashed data structure\n      return hash_resample.trilinear_interpolation_hash(values, coordinates)\n  else:\n      raise ValueError(\"Invalid datastructure. Only 'grid' or 'hash' are supported as valid data structures.\")"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return resample.trilinear_interpolation(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.trilinear_interpolation(values, coordinates)\n  else:\n    raise ValueError(\"Invalid datastructure. Only 'grid' or 'hash' are supported as valid data structures.\")"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n      return resample.trilinear_interpolation_grid(values, coordinates)\n  elif datastructure == 'hash':\n      return hash_resample.trilinear_interpolation_hash(values, coordinates)\n  else:\n      raise ValueError(\"Invalid datastructure. Only 'grid' or 'hash' are supported as valid data structures.\")"}
{"namespace": "grid_utils.trilerp", "completion": "\n  if datastructure == 'grid':\n    return resample.trilinear_interpolation(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.trilinear_interpolation(values, coordinates)\n  else:\n    raise ValueError(\"Invalid datastructure. Supported data structures are 'grid' or 'hash'.\")"}
{"namespace": "grid_utils.trilerp", "completion": "\n  if datastructure == 'grid':\n    return resample.trilerp(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.trilerp(values, coordinates)\n  else:\n    raise ValueError(\"Invalid datastructure. Supported data structures are 'grid' and 'hash'.\")"}
{"namespace": "grid_utils.trilerp", "completion": "\n  if datastructure == 'grid':\n    return resample.trilinear_interpolation(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.trilinear_interpolation(values, coordinates)\n  else:\n    raise ValueError(\"Invalid datastructure. Supported data structures are 'grid' and 'hash'.\")"}
{"namespace": "grid_utils.trilerp", "completion": "\n  if datastructure == 'grid':\n      return resample.trilinear_interpolation(values, coordinates)\n  elif datastructure == 'hash':\n      return hash_resample.hash_trilinear_interpolation(values, coordinates)\n  else:\n      raise ValueError(\"Invalid datastructure. Supported data structures are 'grid' or 'hash'.\")"}
{"namespace": "coord.track_linearize", "completion": "  fn_mean, lin_fn = jax.linearize(fn, mean)\n\n  # Compute the Jacobian of fn function at the locations of each mean.\n  jac = jax.vmap(lin_fn, in_axes=-1, out_axes=-1)(\n      jnp.broadcast_to(jnp.eye(mean.shape[-1]), mean.shape + (mean.shape[-1],))\n  )\n\n  # The transformed means are obtained by applying the function to the mean.\n  fn_mean = fn(mean)\n\n  # The transformed covariances are obtained by transforming the covariances using the Jacobian.\n  fn_cov = math.matmul(jac, math.matmul(cov, jnp.swapaxes(jac, -1, -2)))\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  fn_mean, lin_fn = jax.linearize(fn, mean)\n\n  # Compute the Jacobian of fn function at the locations of each mean.\n  jac = jax.vmap(lin_fn, in_axes=-1, out_axes=-1)(\n      jnp.broadcast_to(jnp.eye(mean.shape[-1]), mean.shape + (mean.shape[-1],))\n  )\n\n  # The transformed means are obtained by applying the function to the means.\n  fn_mean = fn(mean)\n\n  # The transformed covariances are obtained by transforming the covariances using the Jacobian.\n  fn_cov = jnp.matmul(jnp.matmul(jac, cov), jnp.swapaxes(jac, -1, -2))\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  fn_mean, lin_fn = jax.linearize(fn, mean)\n\n  # Compute the Jacobian of fn function at the locations of each mean.\n  jac = jax.vmap(lin_fn, in_axes=-1, out_axes=-1)(\n      jnp.broadcast_to(jnp.eye(mean.shape[-1]), mean.shape + (mean.shape[-1],))\n  )\n\n  # The transformed mean is the result of applying the function to the mean.\n  fn_mean = fn(mean)\n\n  # The transformed covariance is the result of transforming the covariance using the Jacobian matrix.\n  fn_cov = math.matmul(jac, math.matmul(cov, jnp.swapaxes(jac, -1, -2)))\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  fn_mean, lin_fn = jax.linearize(fn, mean)\n\n  # Compute the Jacobian of fn function at the locations of each mean.\n  jac = jax.vmap(lin_fn, in_axes=-1, out_axes=-1)(\n      jnp.broadcast_to(jnp.eye(mean.shape[-1]), mean.shape + (mean.shape[-1],))\n  )\n\n  # Transform the covariances using the linearized function.\n  fn_cov = math.matmul(jac, math.matmul(cov, jnp.swapaxes(jac, -1, -2)))\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  fn_mean, lin_fn = jax.linearize(fn, mean)\n\n  # Compute the Jacobian of fn function at the locations of each mean.\n  jac = jax.vmap(lin_fn, in_axes=-1, out_axes=-1)(\n      jnp.broadcast_to(jnp.eye(mean.shape[-1]), mean.shape + (mean.shape[-1],))\n  )\n\n  # Transform the covariances using the Jacobian.\n  fn_cov = jnp.einsum('...ij,...jk->...ik', jac, jnp.einsum('...ij,...kj->...ik', cov, jac))\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  fn_mean, lin_fn = jax.linearize(fn, mean)\n\n  # Compute the Jacobian of fn function at the locations of each mean.\n  jac = jax.vmap(lin_fn, in_axes=-1, out_axes=-1)(\n      jnp.broadcast_to(jnp.eye(mean.shape[-1]), mean.shape + (mean.shape[-1],))\n  )\n\n  # The transformed means are obtained by applying the function to the mean.\n  fn_mean = fn(mean)\n\n  # The transformed covariances are obtained by transforming the covariances using the Jacobian.\n  fn_cov = math.matmul(jac, math.matmul(cov, jnp.swapaxes(jac, -2, -1)))\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  fn_mean, lin_fn = jax.linearize(fn, mean)\n\n  # Compute the Jacobian of fn function at the locations of each mean.\n  jac = jax.vmap(lin_fn, in_axes=-1, out_axes=-1)(\n      jnp.broadcast_to(jnp.eye(mean.shape[-1]), mean.shape + (mean.shape[-1],))\n  )\n\n  # The transformed means are obtained by applying the function to the mean.\n  fn_mean = fn(mean)\n\n  # The transformed covariances are obtained by transforming the covariances using the Jacobian.\n  fn_cov = math.matmul(jac, math.matmul(cov, jnp.swapaxes(jac, -1, -2)))\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  fn_mean, lin_fn = jax.linearize(fn, mean)\n\n  # Compute the Jacobian of fn function at the locations of each mean.\n  jac = jax.vmap(lin_fn, in_axes=-1, out_axes=-1)(\n      jnp.broadcast_to(jnp.eye(mean.shape[-1]), mean.shape + (mean.shape[-1],))\n  )\n\n  # The transformed means are obtained by applying the function to the mean.\n  fn_mean = fn(mean)\n\n  # The transformed covariances are obtained by transforming the covariances using the Jacobian.\n  fn_cov = jnp.matmul(jac, jnp.matmul(cov, jnp.swapaxes(jac, -1, -2)))\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  fn_mean, lin_fn = jax.linearize(fn, mean)\n\n  # Compute the Jacobian of fn function at the locations of each mean.\n  jac = jax.vmap(lin_fn, in_axes=-1, out_axes=-1)(\n      jnp.broadcast_to(jnp.eye(mean.shape[-1]), mean.shape + (mean.shape[-1],))\n  )\n\n  # Transform the covariances using the Jacobian matrix.\n  fn_cov = jnp.matmul(jac, jnp.matmul(cov, jnp.swapaxes(jac, -1, -2)))\n  \n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  fn_mean, lin_fn = jax.linearize(fn, mean)\n  jac = jax.vmap(lin_fn, in_axes=-1, out_axes=-1)(\n      jnp.broadcast_to(jnp.eye(mean.shape[-1]), mean.shape + (mean.shape[-1],))\n  )\n  fn_mean = fn(mean)\n  fn_cov = math.matmul(jac, math.matmul(cov, jnp.swapaxes(jac, -1, -2)))\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  fn_mean, lin_fn = jax.linearize(fn, mean)\n  jac = jax.vmap(lin_fn, in_axes=-1, out_axes=-1)(\n      jnp.broadcast_to(jnp.eye(mean.shape[-1]), mean.shape + (mean.shape[-1],))\n  )\n  fn_mean = fn(mean)\n  fn_cov = math.matmul(jac, math.matmul(cov, jnp.swapaxes(jac, -1, -2)))\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  fn_mean, lin_fn = jax.linearize(fn, mean)\n\n  # Compute the Jacobian of fn function at the locations of each mean.\n  jac = jax.vmap(lin_fn, in_axes=-1, out_axes=-1)(\n      jnp.broadcast_to(jnp.eye(mean.shape[-1]), mean.shape + (mean.shape[-1],))\n  )\n\n  # The transformed means are obtained by applying the function to the mean.\n  fn_mean = fn(mean)\n\n  # The transformed covariances are obtained by transforming the covariances using the Jacobian.\n  fn_cov = math.matmul(jac, math.matmul(cov, jnp.swapaxes(jac, -1, -2)))\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  fn_mean, lin_fn = jax.linearize(fn, mean)\n\n  # Compute the Jacobian of fn function at the locations of each mean.\n  jac = jax.vmap(lin_fn, in_axes=-1, out_axes=-1)(\n      jnp.broadcast_to(jnp.eye(mean.shape[-1]), mean.shape + (mean.shape[-1],))\n  )\n\n  # Transform the covariances using the linearized function and the Jacobian.\n  fn_cov = math.matmul(jac, math.matmul(cov, jnp.swapaxes(jac, -1, -2)))\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  fn_mean, lin_fn = jax.linearize(fn, mean)\n\n  # Compute the Jacobian of fn function at the locations of each mean.\n  jac = jax.vmap(lin_fn, in_axes=-1, out_axes=-1)(\n      jnp.broadcast_to(jnp.eye(mean.shape[-1]), mean.shape + (mean.shape[-1],))\n  )\n\n  # The transformed means are obtained by applying the function to the mean.\n  fn_mean = fn(mean)\n\n  # The transformed covariances are obtained by transforming the covariances using the Jacobian.\n  fn_cov = math.matmul(jac, math.matmul(cov, jnp.swapaxes(jac, -1, -2)))\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  fn_mean, lin_fn = jax.linearize(fn, mean)\n  jac = jax.vmap(lin_fn, in_axes=-1, out_axes=-1)(\n      jnp.broadcast_to(jnp.eye(mean.shape[-1]), mean.shape + (mean.shape[-1],))\n  )\n  fn_cov = math.matmul(jac, math.matmul(cov, jnp.swapaxes(jac, -1, -2)))\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  fn_mean, lin_fn = jax.linearize(fn, mean)\n  jac = jax.vmap(lin_fn, in_axes=-1, out_axes=-1)(\n      jnp.broadcast_to(jnp.eye(mean.shape[-1]), mean.shape + (mean.shape[-1],))\n  )\n  fn_mean = fn(mean)\n  fn_cov = math.matmul(jac, math.matmul(cov, jnp.swapaxes(jac, -1, -2)))\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  fn_mean, lin_fn = jax.linearize(fn, mean)\n\n  # Compute the Jacobian of fn function at the locations of each mean.\n  jac = jax.vmap(lin_fn, in_axes=-1, out_axes=-1)(\n      jnp.broadcast_to(jnp.eye(mean.shape[-1]), mean.shape + (mean.shape[-1],))\n  )\n\n  # Transform the covariances using the linearized function.\n  fn_cov = math.matmul(jac, math.matmul(cov, jnp.swapaxes(jac, -1, -2)))\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  fn_mean, lin_fn = jax.linearize(fn, mean)\n\n  # Compute the Jacobian of fn function at the locations of each mean.\n  jac = jax.vmap(lin_fn, in_axes=-1, out_axes=-1)(\n      jnp.broadcast_to(jnp.eye(mean.shape[-1]), mean.shape + (mean.shape[-1],))\n  )\n\n  # The transformed means are obtained by applying the function to the original means.\n  fn_mean = fn(mean)\n\n  # The transformed covariances are obtained by transforming the covariances using the Jacobian.\n  fn_cov = math.matmul(jac, math.matmul(cov, jnp.swapaxes(jac, -1, -2)))\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  fn_mean, lin_fn = jax.linearize(fn, mean)\n\n  # Compute the Jacobian of fn function at the locations of each mean.\n  jac = jax.vmap(lin_fn, in_axes=-1, out_axes=-1)(\n      jnp.broadcast_to(jnp.eye(mean.shape[-1]), mean.shape + (mean.shape[-1],))\n  )\n\n  # Transform the covariances using the linearized function and Jacobian matrix.\n  fn_cov = math.matmul(jac, math.matmul(cov, jnp.swapaxes(jac, -1, -2)))\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  fn_mean, lin_fn = jax.linearize(fn, mean)\n\n  # Compute the Jacobian of fn function at the locations of each mean.\n  jac = jax.vmap(lin_fn, in_axes=-1, out_axes=-1)(\n      jnp.broadcast_to(jnp.eye(mean.shape[-1]), mean.shape + (mean.shape[-1],))\n  )\n\n  # Transform the covariances using the Jacobian matrix.\n  fn_cov = jnp.matmul(jnp.matmul(jac, cov), jnp.swapaxes(jac, -1, -2))\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Compute the norm of the input array\n  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  \n  # Apply the isotropic scaling operation\n  scaled_x = x / x_norm\n  \n  return scaled_x"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Compute the norm of the input array\n  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  \n  # Apply the isotropic scaling operation based on the norm\n  scaled_x = x / x_norm\n  \n  return scaled_x"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Compute the norm of the input array\n  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  \n  # Apply the isotropic scaling operation based on the norm\n  scaled_x = x / x_norm\n  \n  return scaled_x"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Compute the norm of the input array\n  x_norm = jnp.sqrt(jnp.sum(x**2, axis=-1, keepdims=True))\n  \n  # Apply the isotropic scaling operation\n  scaled_x = x / x_norm\n\n  return scaled_x"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag = jnp.sqrt(jnp.sum(x**2, axis=-1, keepdims=True))\n  scale_factor = (2 * x_mag - 1) / x_mag\n  scaled_x = scale_factor * x\n  return scaled_x"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)  # Compute the norm of the input array\n  scale = (2 * jnp.sqrt(x_norm) - 1) / x_norm  # Calculate the scaling factor\n  scaled_x = scale * x  # Apply the scaling operation\n  return scaled_x  # Return the scaled version of the input array"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Compute the norm of the input array\n  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  \n  # Apply the isotropic scaling operation\n  scaled_x = x * (2 * jnp.sqrt(x_norm) - x_norm) / x_norm\n  \n  return scaled_x"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Compute the norm of the input array\n  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  \n  # Apply the isotropic scaling operation\n  scaled_x = x / x_norm\n  \n  return scaled_x"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_norm = jnp.sqrt(jnp.sum(x**2, axis=-1, keepdims=True))  # Compute the norm of the input array\n  scale = (2 * x_norm - 1) / x_norm  # Calculate the scaling factor\n  scaled_x = scale * x  # Apply the scaling operation\n  return scaled_x  # Return the scaled version of the input array"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z"}
{"namespace": "coord.pos_enc", "completion": "  encoded = integrated_pos_enc(x, jnp.zeros_like(x), min_deg, max_deg)\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.pos_enc", "completion": "  encoded = integrated_pos_enc(x, jnp.zeros_like(x), min_deg, max_deg)\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.pos_enc", "completion": "  encoded = integrated_pos_enc(x, jnp.zeros_like(x), min_deg, max_deg)\n  if append_identity:\n      encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.pos_enc", "completion": "  encoded = integrated_pos_enc(x, jnp.zeros_like(x), min_deg, max_deg)\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.pos_enc", "completion": "  encoded = integrated_pos_enc(x, jnp.zeros_like(x), min_deg, max_deg)\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.pos_enc", "completion": "  encoded = integrated_pos_enc(x, jnp.zeros_like(x), min_deg, max_deg)\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.pos_enc", "completion": "  encoded = integrated_pos_enc(x, jnp.zeros_like(x), min_deg, max_deg)\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.pos_enc", "completion": "  encoded = integrated_pos_enc(x, jnp.zeros_like(x), min_deg, max_deg)\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.pos_enc", "completion": "  encoded = integrated_pos_enc(x, jnp.zeros_like(x), min_deg, max_deg)\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.pos_enc", "completion": "  encoded = integrated_pos_enc(x, jnp.zeros_like(x), min_deg, max_deg)\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.pos_enc", "completion": "  encoded = integrated_pos_enc(x, jnp.zeros_like(x), min_deg, max_deg)\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.pos_enc", "completion": "  encoded = integrated_pos_enc(x, jnp.zeros_like(x), min_deg, max_deg)\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.pos_enc", "completion": "  encoded = integrated_pos_enc(x, jnp.zeros_like(x), min_deg, max_deg)\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.pos_enc", "completion": "  encoded = integrated_pos_enc(x, jnp.zeros_like(x), min_deg, max_deg)\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.pos_enc", "completion": "  encoded = integrated_pos_enc(x, jnp.zeros_like(x), min_deg, max_deg)\n  if append_identity:\n      encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.pos_enc", "completion": "  encoded = integrated_pos_enc(x, jnp.zeros_like(x), min_deg, max_deg)\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.pos_enc", "completion": "  encoded = integrated_pos_enc(x, jnp.zeros_like(x), min_deg, max_deg)\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.pos_enc", "completion": "  encoded = integrated_pos_enc(x, jnp.zeros_like(x), min_deg, max_deg)\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.pos_enc", "completion": "  encoded = integrated_pos_enc(x, jnp.zeros_like(x), min_deg, max_deg)\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded = expected_sin(\n      jnp.concatenate([scaled_x, scaled_x + 0.5 * jnp.pi], axis=-1),\n      jnp.concatenate([jnp.zeros_like(scaled_x), jnp.zeros_like(scaled_x)], axis=-1),\n  )\n  if append_identity:\n      encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.integrated_pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  scaled_mean = mean * scales\n  scaled_var = var * scales ** 2\n  scaled_input = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n  encodings = jnp.sin(scaled_input)\n  return encodings"}
{"namespace": "coord.integrated_pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  scaled_mean = mean * scales\n  scaled_var = var * scales ** 2\n  scaled_x = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n  enc = jnp.sin(scaled_x)\n  return enc"}
{"namespace": "coord.integrated_pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  scaled_mean = mean * scales\n  scaled_var = var * scales ** 2\n  scaled_input = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n  encoded_output = pos_enc(scaled_input, min_deg, max_deg, append_identity=True)\n  return encoded_output"}
{"namespace": "coord.integrated_pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  scaled_mean = mean * scales\n  scaled_var = var * scales ** 2\n  scaled_input = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n  enc_output = pos_enc(scaled_input, min_deg, max_deg, append_identity=True)\n  return enc_output"}
{"namespace": "coord.integrated_pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  scaled_mean = mean * scales\n  scaled_var = var * scales ** 2\n  scaled_input = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n  encoded_output = jnp.sin(scaled_input)\n  return encoded_output"}
{"namespace": "coord.integrated_pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  scaled_mean = mean * scales\n  scaled_var = var * scales ** 2\n  scaled_values = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n  encoded_values = pos_enc(scaled_values, min_deg, max_deg, append_identity=True)\n  return encoded_values"}
{"namespace": "coord.integrated_pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  scaled_mean = mean * scales\n  scaled_var = var * scales ** 2\n  scaled_input = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n  encoded_output = jnp.sin(scaled_input)\n  return encoded_output"}
{"namespace": "coord.integrated_pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  scaled_mean = mean * scales\n  scaled_var = var * scales ** 2\n  scaled_input = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n  encoded_output = jnp.sin(scaled_input)\n  return encoded_output"}
{"namespace": "coord.integrated_pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  scaled_mean = mean * scales\n  scaled_var = var * scales ** 2\n  scaled_input = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n  encoded_output = jnp.sin(scaled_input)\n  return encoded_output"}
{"namespace": "coord.integrated_pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  scaled_mean = mean * scales\n  scaled_var = var * scales ** 2\n  scaled_input = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n  encoded_output = pos_enc(scaled_input, min_deg, max_deg, append_identity=True)\n  return encoded_output"}
{"namespace": "coord.integrated_pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  scaled_mean = mean * scales\n  scaled_var = var * scales ** 2\n  scaled_inputs = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n  encoded_inputs = pos_enc(scaled_inputs, min_deg, max_deg, append_identity=True)\n  return encoded_inputs"}
{"namespace": "coord.integrated_pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  scaled_mean = mean * scales\n  scaled_var = var * scales ** 2\n  scaled_input = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n  encoded_output = pos_enc(scaled_input, min_deg, max_deg, append_identity=True)\n  return encoded_output"}
{"namespace": "coord.integrated_pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  scaled_mean = mean * scales\n  scaled_var = var * scales ** 2\n  scaled_inputs = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n  encoded_inputs = pos_enc(scaled_inputs, min_deg, max_deg, append_identity=True)\n  return encoded_inputs"}
{"namespace": "coord.integrated_pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  scaled_mean = mean * scales\n  scaled_var = var * scales ** 2\n  scaled_input = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n  encodings = jnp.sin(scaled_input)\n  return encodings"}
{"namespace": "coord.integrated_pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  scaled_mean = mean * scales\n  scaled_var = var * scales ** 2\n  scaled_input = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n  encoded_output = jnp.sin(scaled_input)\n  return encoded_output"}
{"namespace": "coord.integrated_pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  scaled_mean = mean * scales\n  scaled_var = var * scales ** 2\n  scaled_input = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n  encoded_output = jnp.sin(scaled_input)\n  return encoded_output"}
{"namespace": "coord.integrated_pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  scaled_mean = mean * scales\n  scaled_var = var * scales ** 2\n  scaled_input = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n  encoded_output = pos_enc(scaled_input, min_deg, max_deg, append_identity=False)\n  return encoded_output"}
{"namespace": "coord.integrated_pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  scaled_mean = mean * scales\n  scaled_var = var * scales ** 2\n  scaled_inputs = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n  encoded_inputs = pos_enc(scaled_inputs, min_deg, max_deg, append_identity=True)\n  return encoded_inputs"}
{"namespace": "coord.integrated_pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  scaled_mean = mean * scales\n  scaled_var = var * scales ** 2\n  scaled_inputs = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n  encoded_inputs = pos_enc(scaled_inputs, min_deg, max_deg, append_identity=False)\n  return encoded_inputs"}
{"namespace": "coord.integrated_pos_enc", "completion": "  scaled_mean = mean * (2.0 ** jnp.arange(min_deg, max_deg))\n  scaled_var = var * (2.0 ** (2 * jnp.arange(min_deg, max_deg)))\n  scaled_inputs = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n  encoded_inputs = pos_enc(scaled_inputs, min_deg, max_deg, append_identity=True)\n  return encoded_inputs"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # Compute the determinant directly\n    det = jnp.linalg.det(cov)\n    isotropic_cov = det ** (1 / cov.shape[-1]) * jnp.eye(cov.shape[-1])\n  elif mode == 'accurate':\n    # Use the logarithm of the determinant for stability\n    sign, logdet = jnp.linalg.slogdet(cov)\n    det = sign * jnp.exp(logdet)\n    isotropic_cov = det ** (1 / cov.shape[-1]) * jnp.eye(cov.shape[-1])\n  else:\n    raise ValueError(\"Invalid mode. Mode must be 'fast' or 'accurate'.\")\n\n  return isotropic_cov"}
{"namespace": "coord.isotropize", "completion": "  if mode not in ['fast', 'accurate']:\n    raise ValueError(\"Mode must be 'fast' or 'accurate'\")\n\n  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n    isotropic_cov = det ** (1 / cov.shape[-1]) * jnp.eye(cov.shape[-1])\n  else:\n    sign, logdet = jnp.linalg.slogdet(cov)\n    logdet = jnp.where(logdet < 0, 0, logdet)  # Handle negative logdets\n    isotropic_cov = jnp.exp(logdet / cov.shape[-1]) * jnp.eye(cov.shape[-1])\n\n  return isotropic_cov"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # Compute the determinant of the covariance matrix.\n    det = jnp.linalg.det(cov)\n    # Compute the isotropic scaling factor based on the determinant.\n    scale = jnp.abs(det) ** (1 / cov.shape[-1])\n    # Construct the isotropic covariance matrix using the scaling factor.\n    isotropic_cov = scale * jnp.eye(cov.shape[-1])\n  elif mode == 'accurate':\n    # Compute the logarithm of the determinant of the covariance matrix for stability.\n    log_det = jnp.log(jnp.abs(jnp.linalg.det(cov)))\n    # Compute the isotropic scaling factor based on the logarithm of the determinant.\n    scale = jnp.exp(log_det / cov.shape[-1])\n    # Construct the isotropic covariance matrix using the scaling factor.\n    isotropic_cov = scale * jnp.eye(cov.shape[-1])\n  else:\n    raise ValueError(\"Invalid mode. Mode must be 'fast' or 'accurate'.\")\n\n  return isotropic_cov"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # Compute the determinant of the covariance matrix\n    det = jnp.linalg.det(cov)\n    # Compute the isotropic scaling factor\n    scale_factor = jnp.abs(det) ** (-1 / cov.shape[-1])\n    # Create the isotropic covariance matrix\n    isotropic_cov = scale_factor * cov\n    return isotropic_cov\n  elif mode == 'accurate':\n    # Compute the logarithm of the determinant of the covariance matrix\n    log_det = jnp.log(jnp.abs(jnp.linalg.det(cov)))\n    # Compute the isotropic scaling factor\n    scale_factor = jnp.exp(-log_det / cov.shape[-1])\n    # Create the isotropic covariance matrix\n    isotropic_cov = scale_factor * cov\n    return isotropic_cov\n  else:\n    raise ValueError(\"Invalid mode. Mode must be 'fast' or 'accurate'.\")"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # Compute the determinant of the covariance matrix\n    det = jnp.linalg.det(cov)\n    # Compute the isotropic scaling factor\n    scale = jnp.power(det, 1 / cov.shape[-1])\n    # Construct the isotropic covariance matrix\n    isotropic_cov = scale * jnp.eye(cov.shape[-1])\n  elif mode == 'accurate':\n    # Compute the logarithm of the determinant for stability\n    log_det = jnp.log(jnp.abs(jnp.linalg.det(cov)))\n    # Compute the isotropic scaling factor\n    scale = jnp.exp(log_det / cov.shape[-1])\n    # Construct the isotropic covariance matrix\n    isotropic_cov = scale * jnp.eye(cov.shape[-1])\n  else:\n    raise ValueError(\"Invalid mode. Please choose 'fast' or 'accurate'.\")\n\n  return isotropic_cov"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n    isotropic_cov = det**(1/cov.shape[-1]) * jnp.eye(cov.shape[-1])\n  elif mode == 'accurate':\n    sign, logdet = jnp.linalg.slogdet(cov)\n    logdet = logdet / cov.shape[-1]\n    isotropic_cov = jnp.exp(logdet) * jnp.eye(cov.shape[-1])\n  else:\n    raise ValueError(\"Invalid mode. Mode must be 'fast' or 'accurate'.\")\n  \n  return isotropic_cov"}
{"namespace": "coord.isotropize", "completion": "  if mode not in ['fast', 'accurate']:\n    raise ValueError(\"Mode must be 'fast' or 'accurate'\")\n\n  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n    isotropic_cov = jnp.cbrt(det) * jnp.eye(cov.shape[-1])\n  else:\n    sign, logdet = jnp.linalg.slogdet(cov)\n    if jnp.any(jnp.isnan(logdet)):\n      raise ValueError(\"Invalid determinant in covariance matrix\")\n    logdet /= 3\n    isotropic_cov = jnp.exp(logdet) * jnp.eye(cov.shape[-1])\n\n  return isotropic_cov"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # Compute the determinant directly for isotropic scaling\n    det = jnp.linalg.det(cov)\n    isotropic_cov = det ** (1 / cov.shape[-1]) * jnp.eye(cov.shape[-1])\n  elif mode == 'accurate':\n    # Use the logarithm of the determinant for stability\n    sign, logdet = jnp.linalg.slogdet(cov)\n    logdet = logdet / cov.shape[-1]\n    isotropic_cov = jnp.exp(logdet) * jnp.eye(cov.shape[-1])\n  else:\n    raise ValueError(\"Invalid mode. Mode must be 'fast' or 'accurate'.\")\n\n  return isotropic_cov"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # Compute the determinant of the covariance matrix\n    det = jnp.linalg.det(cov)\n    # Compute the isotropic scaling factor\n    scale = jnp.abs(det) ** (1 / cov.shape[-1])\n    # Create an isotropic covariance matrix with the same determinant\n    isotropic_cov = scale * jnp.eye(cov.shape[-1])\n  elif mode == 'accurate':\n    # Compute the logarithm of the determinant for stability\n    log_det = jnp.log(jnp.abs(jnp.linalg.det(cov)))\n    # Compute the isotropic scaling factor\n    scale = jnp.exp(log_det / cov.shape[-1])\n    # Create an isotropic covariance matrix with the same determinant\n    isotropic_cov = scale * jnp.eye(cov.shape[-1])\n  else:\n    raise ValueError(\"Invalid mode. Please choose either 'fast' or 'accurate'.\")\n\n  return isotropic_cov"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # Compute the determinant directly for fast mode\n    det = jnp.linalg.det(cov)\n    isotropic_cov = det ** (1 / cov.shape[-1]) * jnp.eye(cov.shape[-1])\n  elif mode == 'accurate':\n    # Use the logarithm of the determinant for stability\n    sign, logdet = jnp.linalg.slogdet(cov)\n    det = jnp.exp(logdet)\n    isotropic_cov = det ** (1 / cov.shape[-1]) * jnp.eye(cov.shape[-1])\n  else:\n    raise ValueError(\"Invalid mode. Mode must be 'fast' or 'accurate'.\")\n\n  return isotropic_cov"}
{"namespace": "coord.isotropize", "completion": "    if mode == 'fast':\n        # Compute the determinant of the covariance matrix\n        det = jnp.linalg.det(cov)\n        # Compute the isotropic scaling factor based on the determinant\n        scale = jnp.abs(det) ** (-1 / cov.shape[-1])\n        # Construct the isotropic covariance matrix using the scaling factor\n        isotropic_cov = scale * cov\n    elif mode == 'accurate':\n        # Compute the logarithm of the determinant of the covariance matrix\n        log_det = jnp.log(jnp.abs(jnp.linalg.det(cov)))\n        # Compute the isotropic scaling factor based on the logarithm of the determinant\n        scale = jnp.exp(-log_det / cov.shape[-1])\n        # Construct the isotropic covariance matrix using the scaling factor\n        isotropic_cov = scale * cov\n    else:\n        raise ValueError(\"Invalid mode. Mode must be 'fast' or 'accurate'.\")\n\n    return isotropic_cov"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # Compute the determinant of the covariance matrix\n    det = jnp.linalg.det(cov)\n    # Compute the scaling factor to make the determinant equal to 1\n    scale = det ** (-1/cov.shape[-1])\n    # Apply the scaling factor to the covariance matrix\n    isotropic_cov = cov * scale\n  elif mode == 'accurate':\n    # Compute the logarithm of the determinant of the covariance matrix for stability\n    log_det = jnp.linalg.slogdet(cov)[1]\n    # Compute the scaling factor to make the determinant equal to 1\n    scale = jnp.exp(-log_det / cov.shape[-1])\n    # Apply the scaling factor to the covariance matrix\n    isotropic_cov = cov * scale\n  else:\n    raise ValueError(\"Invalid mode. Mode must be 'fast' or 'accurate'.\")\n\n  return isotropic_cov"}
{"namespace": "coord.isotropize", "completion": "  if mode not in ['fast', 'accurate']:\n    raise ValueError(\"Mode must be 'fast' or 'accurate'.\")\n\n  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n    isotropic_cov = det ** (1 / cov.shape[-1]) * jnp.eye(cov.shape[-1])\n  else:\n    log_det = jnp.linalg.slogdet(cov)[1]\n    isotropic_cov = jnp.exp(log_det / cov.shape[-1]) * jnp.eye(cov.shape[-1])\n\n  return isotropic_cov"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # Compute the determinant of the covariance matrix\n    det = jnp.linalg.det(cov)\n    # Compute the isotropic scaling factor\n    scale = jnp.abs(det) ** (1 / cov.shape[-1])\n    # Construct the isotropic covariance matrix\n    isotropic_cov = scale * jnp.eye(cov.shape[-1])\n    return isotropic_cov\n  elif mode == 'accurate':\n    # Compute the logarithm of the determinant for stability\n    log_det = jnp.log(jnp.abs(jnp.linalg.det(cov)))\n    # Compute the isotropic scaling factor\n    scale = jnp.exp(log_det / cov.shape[-1])\n    # Construct the isotropic covariance matrix\n    isotropic_cov = scale * jnp.eye(cov.shape[-1])\n    return isotropic_cov\n  else:\n    raise ValueError(\"Invalid mode. Mode must be 'fast' or 'accurate'.\")"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # Compute the determinant directly\n    det = jnp.linalg.det(cov)\n    isotropic_cov = det ** (1 / cov.shape[-1]) * jnp.eye(cov.shape[-1])\n  elif mode == 'accurate':\n    # Use the logarithm of the determinant for stability\n    sign, logdet = jnp.linalg.slogdet(cov)\n    det = sign * jnp.exp(logdet)\n    isotropic_cov = det ** (1 / cov.shape[-1]) * jnp.eye(cov.shape[-1])\n  else:\n    raise ValueError(\"Invalid mode. Mode must be 'fast' or 'accurate'.\")\n  \n  return isotropic_cov"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # Compute the determinant of the covariance matrix\n    det = jnp.linalg.det(cov)\n    # Compute the isotropic scaling factor\n    scale = jnp.abs(det) ** (-1 / cov.shape[-1])\n    # Create the isotropic covariance matrix\n    isotropic_cov = scale * cov\n  elif mode == 'accurate':\n    # Compute the logarithm of the determinant of the covariance matrix\n    log_det = jnp.linalg.slogdet(cov)[1]\n    # Compute the isotropic scaling factor using the logarithm of the determinant\n    scale = jnp.exp(-log_det / cov.shape[-1])\n    # Create the isotropic covariance matrix\n    isotropic_cov = scale * cov\n  else:\n    raise ValueError(\"Invalid mode. Mode must be 'fast' or 'accurate'.\")\n  \n  return isotropic_cov"}
{"namespace": "coord.isotropize", "completion": "  if mode not in ['fast', 'accurate']:\n    raise ValueError(\"Mode must be 'fast' or 'accurate'\")\n\n  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n    isotropic_cov = det ** (1 / cov.shape[-1]) * jnp.eye(cov.shape[-1])\n  else:  # mode == 'accurate'\n    sign, logdet = jnp.linalg.slogdet(cov)\n    logdet /= cov.shape[-1]\n    isotropic_cov = jnp.exp(logdet) * jnp.eye(cov.shape[-1])\n\n  return isotropic_cov"}
{"namespace": "coord.isotropize", "completion": "\n    if mode == 'fast':\n        # Compute the determinant directly\n        det = jnp.linalg.det(cov)\n        # Compute the isotropic scale factor\n        scale_factor = jnp.power(jnp.abs(det), -1 / cov.shape[-1])\n        # Create isotropic covariance matrix\n        isotropic_cov = scale_factor * cov\n\n    elif mode == 'accurate':\n        # Compute the logarithm of the determinant for stability\n        log_det = jnp.log(jnp.abs(jnp.linalg.det(cov)))\n        # Compute the isotropic scale factor\n        scale_factor = jnp.exp(-log_det / cov.shape[-1])\n        # Create isotropic covariance matrix\n        isotropic_cov = scale_factor * cov\n\n    else:\n        raise ValueError(\"Invalid mode. Mode must be 'fast' or 'accurate'.\")\n\n    return isotropic_cov"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # Compute the determinant of the covariance matrix\n    det = jnp.linalg.det(cov)\n    # Compute the isotropic scaling factor\n    scale = jnp.cbrt(abs(det))\n    # Create an isotropic covariance matrix with the same determinant\n    isotropic_cov = cov * (scale ** (2 / cov.shape[-1]))\n\n  elif mode == 'accurate':\n    # Compute the logarithm of the determinant of the covariance matrix for stability\n    log_det = jnp.log(jnp.abs(jnp.linalg.det(cov)))\n    # Compute the isotropic scaling factor\n    scale = jnp.exp(log_det / cov.shape[-1])\n    # Create an isotropic covariance matrix with the same determinant\n    isotropic_cov = cov * (scale ** (2 / cov.shape[-1]))\n\n  else:\n    raise ValueError(\"Invalid mode. Please choose 'fast' or 'accurate'.\")\n\n  return isotropic_cov"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # Compute the determinant of the covariance matrix\n    det = jnp.linalg.det(cov)\n    # Compute the isotropic scaling factor\n    scale = jnp.power(jnp.abs(det), -1/cov.shape[-1])\n    # Construct the isotropic covariance matrix\n    isotropic_cov = scale * cov\n  elif mode == 'accurate':\n    # Compute the logarithm of the determinant for stability\n    log_det = jnp.log(jnp.abs(jnp.linalg.det(cov)))\n    # Compute the isotropic scaling factor\n    scale = jnp.exp(-log_det / cov.shape[-1])\n    # Construct the isotropic covariance matrix\n    isotropic_cov = scale * cov\n  else:\n    raise ValueError(\"Invalid mode. Mode must be 'fast' or 'accurate'.\")\n\n  return isotropic_cov"}
{"namespace": "coord.construct_ray_warps", "completion": "  # Define the forward mapping from metric to normalized distances\n  def t_to_s(t):\n    return (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n  # Define the backward mapping from normalized to metric distances\n  if fn_inv is not None:\n    def s_to_t(s):\n      return fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n  else:\n    # Automatically determine the inverse based on a predefined mapping of functions to their inverses\n    if fn.__name__ == 'contract3_isoscale':\n      def s_to_t(s):\n        return fn_inv(s)\n    elif fn.__name__ == 'sqrtm':\n      def s_to_t(s):\n        return fn_inv(s, return_eigs=False)\n    else:\n      raise ValueError('Inverse function fn_inv must be provided for the given function fn.')\n\n  return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "  def t_to_s(t):\n    \"\"\"Maps metric distances to normalized distances in the range [0, 1].\"\"\"\n    return (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n  def s_to_t(s):\n    \"\"\"Maps normalized distances back to metric distances.\"\"\"\n    return fn_inv(fn(t_near) + s * (fn(t_far) - fn(t_near))) if fn_inv else None\n\n  return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "  def t_to_s(t):\n    \"\"\"Maps metric distances to normalized distances.\"\"\"\n    t_clipped = jnp.clip(t, t_near, t_far)\n    s = (fn(t_clipped) - fn(t_near)) / (fn(t_far) - fn(t_near))\n    return s\n\n  def s_to_t(s):\n    \"\"\"Maps normalized distances back to metric distances.\"\"\"\n    t = fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near)) if fn_inv is not None else None\n    return t\n\n  return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "  def t_to_s(t):\n    \"\"\"Maps metric distances to normalized distances in the range [0, 1].\"\"\"\n    s = (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n    return jnp.clip(s, 0.0, 1.0)\n\n  def s_to_t(s):\n    \"\"\"Maps normalized distances back to metric distances.\"\"\"\n    t = t_near + (t_far - t_near) * fn_inv(s) if fn_inv else None\n    return t\n\n  return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "  def t_to_s(t):\n    \"\"\"Maps metric distances to normalized distances in the range [0, 1].\"\"\"\n    return (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n  def s_to_t(s):\n    \"\"\"Maps normalized distances back to metric distances.\"\"\"\n    return fn_inv(fn(t_near) + s * (fn(t_far) - fn(t_near))) if fn_inv else None\n\n  return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "  def t_to_s(t):\n    \"\"\"Maps metric distances to normalized distances.\"\"\"\n    return (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n  def s_to_t(s):\n    \"\"\"Maps normalized distances back to metric distances.\"\"\"\n    return fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near)) if fn_inv else None\n\n  return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    if fn == jnp.exp:\n      fn_inv = jnp.log\n    elif fn == jnp.log:\n      fn_inv = jnp.exp\n    elif fn == jnp.sin:\n      fn_inv = jnp.arcsin\n    elif fn == jnp.arcsin:\n      fn_inv = jnp.sin\n    else:\n      raise ValueError(\"Inverse function fn_inv must be provided for the given function fn.\")\n\n  def t_to_s(t):\n    return (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n  def s_to_t(s):\n    return fn_inv(fn(t_near) + s * (fn(t_far) - fn(t_near)))\n\n  return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "  def t_to_s(t):\n    \"\"\"Maps metric distances to normalized distances.\"\"\"\n    s = (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n    return jnp.clip(s, 0.0, 1.0)\n\n  def s_to_t(s):\n    \"\"\"Maps normalized distances back to metric distances.\"\"\"\n    t = fn_inv(fn(t_near) + s * (fn(t_far) - fn(t_near))) if fn_inv is not None else None\n    return t\n\n  return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "  def t_to_s(t):\n    \"\"\"Maps metric distances to normalized distances in the range [0, 1].\"\"\"\n    return (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n  def s_to_t(s):\n    \"\"\"Maps normalized distances back to metric distances.\"\"\"\n    return fn_inv(fn(t_near) + s * (fn(t_far) - fn(t_near))) if fn_inv else None\n\n  return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "  def t_to_s(t):\n    \"\"\"Convert metric distances to normalized distances.\"\"\"\n    t_clipped = jnp.clip(t, t_near, t_far)\n    s = (fn(t_clipped) - fn(t_near)) / (fn(t_far) - fn(t_near))\n    return jnp.clip(s, 0.0, 1.0)\n\n  def s_to_t(s):\n    \"\"\"Convert normalized distances back to metric distances.\"\"\"\n    t = t_near + (t_far - t_near) * fn_inv(s) if fn_inv else None\n    return t\n\n  return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "  def t_to_s(t):\n    \"\"\"Maps metric distances to normalized distances.\"\"\"\n    return (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n  def s_to_t(s):\n    \"\"\"Maps normalized distances back to metric distances.\"\"\"\n    return fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n\n  return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "  def t_to_s(t):\n    \"\"\"Maps metric distances to normalized distances.\"\"\"\n    return (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n  def s_to_t(s):\n    \"\"\"Maps normalized distances back to metric distances.\"\"\"\n    return fn_inv(fn(t_near) + s * (fn(t_far) - fn(t_near))) if fn_inv else None\n\n  return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "  def t_to_s(t):\n    \"\"\"Maps metric distances to normalized distances in the range [0, 1].\"\"\"\n    s = (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n    return jnp.clip(s, 0, 1)\n\n  def s_to_t(s):\n    \"\"\"Maps normalized distances back to metric distances.\"\"\"\n    t = fn_inv(fn(t_near) + s * (fn(t_far) - fn(t_near))) if fn_inv is not None else None\n    return t\n\n  return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "  def t_to_s(t):\n    \"\"\"Maps metric distances to normalized distances.\"\"\"\n    return (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n  if fn_inv is not None:\n    def s_to_t(s):\n      \"\"\"Maps normalized distances back to metric distances.\"\"\"\n      return fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n  else:\n    def s_to_t(s):\n      \"\"\"Maps normalized distances back to metric distances.\"\"\"\n      raise NotImplementedError(\"Inverse function fn_inv is not provided.\")\n\n  return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "  def t_to_s(t):\n    \"\"\"Maps metric distances to normalized distances in the range [0, 1].\"\"\"\n    s = (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n    return jnp.clip(s, 0.0, 1.0)\n\n  if fn_inv is None:\n    # Attempt to automatically determine the inverse based on a predefined mapping of functions to their inverses.\n    if fn.__name__ == 'log':\n      fn_inv = jnp.exp\n    elif fn.__name__ == 'exp':\n      fn_inv = jnp.log\n    elif fn.__name__ == 'sqrt':\n      fn_inv = jnp.square\n    else:\n      raise ValueError(\"Inverse function `fn_inv` must be provided for the given function `fn`.\")\n\n  def s_to_t(s):\n    \"\"\"Maps normalized distances back to metric distances.\"\"\"\n    t = fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n    return t\n\n  return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "  t_range = t_far - t_near\n\n  def t_to_s(t):\n    return (fn(t) - fn(t_near)) / fn(t_range)\n\n  if fn_inv is not None:\n    def s_to_t(s):\n      return fn_inv(fn(t_near) + s * fn(t_range))\n  else:\n    def s_to_t(s):\n      raise NotImplementedError(\"Inverse function fn_inv must be provided for s_to_t\")\n\n  return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "  def t_to_s(t):\n    \"\"\"Maps metric distances to normalized distances in the range [0, 1].\"\"\"\n    return (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n  if fn_inv is not None:\n    def s_to_t(s):\n      \"\"\"Maps normalized distances back to metric distances.\"\"\"\n      return fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n  else:\n    def s_to_t(s):\n      \"\"\"Maps normalized distances back to metric distances.\"\"\"\n      return t_near + s * (t_far - t_near)\n\n  return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "  def t_to_s(t):\n    \"\"\"Maps metric distances to normalized distances in the range [0, 1].\"\"\"\n    return (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n  if fn_inv is not None:\n    def s_to_t(s):\n      \"\"\"Maps normalized distances back to metric distances.\"\"\"\n      return fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n  else:\n    def s_to_t(s):\n      \"\"\"Maps normalized distances back to metric distances.\"\"\"\n      return (fn(t_near) + s * (fn(t_far) - fn(t_near)))\n\n  return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "  def t_to_s(t):\n    \"\"\"Maps metric distances to normalized distances in the range [0, 1].\"\"\"\n    return (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n  def s_to_t(s):\n    \"\"\"Maps normalized distances back to metric distances.\"\"\"\n    return fn_inv(fn(t_near) + s * (fn(t_far) - fn(t_near)))\n\n  return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "  def t_to_s(distances):\n    \"\"\"Maps metric distances to normalized distances in the range [0, 1].\"\"\"\n    return (fn(distances) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n  def s_to_t(norm_distances):\n    \"\"\"Maps normalized distances back to metric distances.\"\"\"\n    return fn_inv(norm_distances) if fn_inv is not None else (t_near + (t_far - t_near) * norm_distances)\n\n  return t_to_s, s_to_t"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            if n_neurons <= 64:\n                return self._get_tinycudann_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n            else:\n                return self._get_torch_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n        else:\n            return self._get_torch_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            if n_neurons <= 128:\n                # Use tinycudann for small networks\n                return self._get_tinycudann_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n            else:\n                # Use PyTorch for larger networks\n                return self._get_pytorch_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n        else:\n            # Use PyTorch by default\n            return self._get_pytorch_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            if n_neurons <= 64:\n                # create network using tinycudann\n                pass\n            else:\n                # create network using PyTorch\n                layers = []\n                in_features = n_input_dims\n                for _ in range(n_layers - 1):\n                    layer = self._get_torch_layer(in_features, n_neurons, activation)\n                    layers.extend(layer)\n                    in_features = n_neurons\n                output_layer = self._get_torch_layer(in_features, n_output_dims, output_activation)\n                layers.extend(output_layer)\n                return nn.Sequential(*layers)\n        else:\n            # create network using tinycudann\n            pass"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            if n_neurons <= 16:\n                return self._get_tinycudann_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n            else:\n                return self._get_torch_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n        else:\n            return self._get_torch_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            # Use tinycudann\n            assert n_layers > 0, \"Number of layers must be greater than 0\"\n            assert n_neurons > 0, \"Number of neurons must be greater than 0\"\n            if n_neurons <= 32:\n                # Use tinycudann for small networks\n                return tinycudann.create_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n            else:\n                # Use PyTorch for larger networks\n                return self._create_pytorch_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n        else:\n            # Use PyTorch\n            return self._create_pytorch_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            if n_neurons < 256:\n                return self._get_tinycudann_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n            else:\n                return self._get_torch_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n        else:\n            return self._get_torch_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            if n_neurons < 128:\n                return self._get_tinycudann_network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    n_layers=n_layers,\n                    n_neurons=n_neurons,\n                    activation=activation,\n                    output_activation=output_activation,\n                )\n            else:\n                return self._get_torch_network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    n_layers=n_layers,\n                    n_neurons=n_neurons,\n                    activation=activation,\n                    output_activation=output_activation,\n                )\n        else:\n            return self._get_torch_network(\n                n_input_dims=n_input_dims,\n                n_output_dims=n_output_dims,\n                n_layers=n_layers,\n                n_neurons=n_neurons,\n                activation=activation,\n                output_activation=output_activation,\n            )"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            if n_neurons <= 128:\n                # Use tinycudann for small networks\n                return tinycudann.get_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n            else:\n                # Use PyTorch for larger networks\n                layers = []\n                for _ in range(n_layers - 1):\n                    layers.extend(self._get_torch_layer(n_input_dims, n_neurons, activation))\n                    n_input_dims = n_neurons\n                layers.extend(self._get_torch_layer(n_input_dims, n_output_dims, output_activation))\n                return nn.Sequential(*layers)\n        else:\n            # Use PyTorch for all networks\n            layers = []\n            for _ in range(n_layers - 1):\n                layers.extend(self._get_torch_layer(n_input_dims, n_neurons, activation))\n                n_input_dims = n_neurons\n            layers.extend(self._get_torch_layer(n_input_dims, n_output_dims, output_activation))\n            return nn.Sequential(*layers)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            if n_neurons <= 64:\n                # use tinycudann for small networks\n                # implement tinycudann network creation here\n                pass\n            else:\n                # implement tinycudann network creation for larger networks here\n                pass\n        else:\n            model_list = []\n            for _ in range(n_layers):\n                model_list.extend(self._get_torch_layer(n_input_dims, n_neurons, activation))\n                n_input_dims = n_neurons\n            model_list.extend(self._get_torch_layer(n_neurons, n_output_dims, output_activation))\n\n            return nn.Sequential(*model_list)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            if n_neurons <= 64:\n                return self._get_tinycudann_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n            else:\n                return self._get_torch_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n        else:\n            return self._get_torch_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            if n_neurons <= 32:\n                return self._get_tinycudann_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n            else:\n                return self._get_torch_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n        else:\n            return self._get_torch_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            if n_neurons <= 128:\n                return self._get_tinycudann_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n            else:\n                return self._get_torch_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n        else:\n            return self._get_torch_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            if n_layers == 1:\n                return tinycudann.Network(n_input_dims, n_output_dims, n_neurons)\n            else:\n                return tinycudann.Network(n_input_dims, n_output_dims, n_neurons, n_layers - 1, n_neurons)\n        else:\n            model = nn.Sequential()\n            in_features = n_input_dims\n            for _ in range(n_layers - 1):\n                model.extend(self._get_torch_layer(in_features, n_neurons, activation))\n                in_features = n_neurons\n            model.extend(self._get_torch_layer(in_features, n_output_dims, output_activation))\n            return model"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            if n_neurons <= 256:\n                return self._get_tinycudann_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n            else:\n                return self._get_torch_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n        else:\n            return self._get_torch_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            if n_neurons <= 32:\n                return self.get_tinycudann_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n            else:\n                return self.get_pytorch_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n        else:\n            return self.get_pytorch_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            if n_neurons <= 32:\n                return self._get_tinycudann_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n            else:\n                return self._get_torch_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n        else:\n            return self._get_torch_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn and n_neurons <= 32:\n            # create network using tinycudann\n            pass  # placeholder for tinycudann network creation\n        else:\n            # create network using PyTorch\n            model_list = []\n            in_features = n_input_dims\n            for _ in range(n_layers):\n                out_features = n_neurons\n                model_list.extend(self._get_torch_layer(in_features, out_features, activation))\n                in_features = out_features\n            model_list.extend(self._get_torch_layer(in_features, n_output_dims, output_activation))\n            return nn.Sequential(*model_list)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            if n_layers <= 0 or n_neurons <= 0:\n                raise ValueError(\"Both n_layers and n_neurons must be greater than 0\")\n\n            if n_neurons <= 32:\n                return self._get_tinycudann_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n            else:\n                return self._get_torch_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n        else:\n            return self._get_torch_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            if n_neurons <= 8:\n                model = self._get_tinycudann_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n            else:\n                model = self._get_torch_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n        else:\n            model = self._get_torch_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n        \n        return model"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            if n_neurons <= 16:\n                return self._get_tinycudann_network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    n_layers=n_layers,\n                    n_neurons=n_neurons,\n                    activation=activation,\n                    output_activation=output_activation,\n                )\n            else:\n                return self._get_pytorch_network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    n_layers=n_layers,\n                    n_neurons=n_neurons,\n                    activation=activation,\n                    output_activation=output_activation,\n                )\n        else:\n            return self._get_pytorch_network(\n                n_input_dims=n_input_dims,\n                n_output_dims=n_output_dims,\n                n_layers=n_layers,\n                n_neurons=n_neurons,\n                activation=activation,\n                output_activation=output_activation,\n            )"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n    filtered_polygons = [polygon for polygon, area in zip(polygons, areas) if area >= max_area * rel_tr and area >= abs_tr]\n    return filtered_polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n    filtered_polygons = [polygon for polygon, polygon_area in zip(polygons, areas) if polygon_area >= abs_tr and polygon_area >= max_area * rel_tr]\n    return filtered_polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n    filtered_polygons = [polygon for polygon, polygon_area in zip(polygons, areas) if polygon_area >= abs_tr and polygon_area >= rel_tr * max_area]\n    return filtered_polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n    filtered_polygons = [polygon for polygon, polygon_area in zip(polygons, areas) if polygon_area >= max_area * rel_tr and polygon_area >= abs_tr]\n    return filtered_polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    \n    areas = [area(poly) for poly in polygons]\n    max_area = max(areas)\n    filtered_polygons = [poly for poly, poly_area in zip(polygons, areas) if poly_area >= abs_tr and poly_area >= max_area * rel_tr]\n    \n    return filtered_polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n\n    filtered_polygons = [polygon for polygon, area in zip(polygons, areas) if area >= max_area * rel_tr and area >= abs_tr]\n\n    return filtered_polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = [area(poly) for poly in polygons]\n    max_area = max(areas)\n\n    filtered_polygons = [poly for poly, poly_area in zip(polygons, areas) if (poly_area >= abs_tr) and (poly_area >= rel_tr * max_area)]\n\n    return filtered_polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = [area(poly) for poly in polygons]\n    max_area = max(areas)\n    filtered_polygons = [poly for poly, poly_area in zip(polygons, areas) if poly_area >= abs_tr and poly_area >= rel_tr * max_area]\n    return filtered_polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    largest_area = max(area(poly) for poly in polygons)\n    filtered_polygons = [poly for poly in polygons if (area(poly) >= abs_tr) and (area(poly) >= rel_tr * largest_area)]\n    return filtered_polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n    filtered_polygons = [polygon for polygon, area in zip(polygons, areas) if area >= abs_tr and area >= max_area * rel_tr]\n    return filtered_polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n    filtered_polygons = [polygon for polygon, polygon_area in zip(polygons, areas) if polygon_area >= abs_tr and polygon_area >= rel_tr * max_area]\n    return filtered_polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n    filtered_polygons = [polygon for polygon, polygon_area in zip(polygons, areas) if polygon_area >= abs_tr and polygon_area >= rel_tr * max_area]\n    return filtered_polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n    filtered_polygons = [polygon for polygon, area in zip(polygons, areas) if area >= abs_tr and area >= rel_tr * max_area]\n    return filtered_polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = [area(poly) for poly in polygons]\n    max_area = max(areas)\n    filtered_polygons = [poly for poly, poly_area in zip(polygons, areas) if poly_area >= abs_tr and poly_area >= rel_tr * max_area]\n    return filtered_polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    polygon_areas = [area(polygon) for polygon in polygons]\n    max_area = max(polygon_areas)\n    filtered_polygons = [polygon for polygon, area in zip(polygons, polygon_areas) if area >= max_area * rel_tr and area >= abs_tr]\n    return filtered_polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = [area(poly) for poly in polygons]\n    max_area = max(areas)\n    filtered_polygons = [poly for poly, poly_area in zip(polygons, areas) if poly_area >= max_area * rel_tr and poly_area >= abs_tr]\n    return filtered_polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    max_area = max(area(poly) for poly in polygons)\n    filtered_polygons = [poly for poly in polygons if area(poly) >= max_area * rel_tr and area(poly) >= abs_tr]\n    return filtered_polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n    filtered_polygons = [polygon for polygon, polygon_area in zip(polygons, areas) if polygon_area >= max_area * rel_tr and polygon_area >= abs_tr]\n    return filtered_polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = [area(poly) for poly in polygons]\n    max_area = max(areas)\n    filtered_polygons = [poly for poly, area in zip(polygons, areas) if area >= abs_tr and area >= rel_tr * max_area]\n    return filtered_polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if rel_tr < 0 or abs_tr < 0:\n        raise ValueError(\"Thresholds must be non-negative.\")\n\n    if not polygons:\n        return []\n\n    max_area = max(area(polygon) for polygon in polygons)\n\n    filtered_polygons = [polygon for polygon in polygons if area(polygon) >= max_area * rel_tr and area(polygon) >= abs_tr]\n\n    return filtered_polygons"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        median = np.zeros(len(signal) - 2 * kernel_offset)\n        for i in range(kernel_offset, len(signal) - kernel_offset):\n            median[i - kernel_offset] = np.median(signal[i - kernel_offset : i + kernel_offset + 1])\n        return median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        medians = np.zeros(len(signal) - 2 * kernel_offset)\n        for i in range(kernel_offset, len(signal) - kernel_offset):\n            medians[i - kernel_offset] = np.median(signal[i - kernel_offset : i + kernel_offset + 1])\n        return medians"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        median = np.zeros(len(signal) - 2 * kernel_offset)\n        for i in range(kernel_offset, len(signal) - kernel_offset):\n            median[i - kernel_offset] = np.median(signal[i - kernel_offset : i + kernel_offset + 1])\n        return median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        medians = np.zeros(len(signal) - 2 * kernel_offset)\n        for i in range(kernel_offset, len(signal) - kernel_offset):\n            medians[i - kernel_offset] = np.median(signal[i - kernel_offset : i + kernel_offset + 1])\n        return medians"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        median = np.zeros(len(signal) - 2 * kernel_offset)\n        for i in range(kernel_offset, len(signal) - kernel_offset):\n            median[i - kernel_offset] = np.median(signal[i - kernel_offset : i + kernel_offset + 1])\n        return median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        signal_length = len(signal)\n        rolling_median = np.zeros(signal_length - 2 * kernel_offset)\n\n        for i in range(kernel_offset, signal_length - kernel_offset):\n            window = np.sort(signal[i - kernel_offset : i + kernel_offset + 1])\n            rolling_median[i - kernel_offset] = np.median(window)\n\n        return rolling_median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        medians = np.zeros(len(signal) - 2 * kernel_offset)\n        for i in range(kernel_offset, len(signal) - kernel_offset):\n            medians[i - kernel_offset] = np.median(signal[i - kernel_offset : i + kernel_offset + 1])\n        return medians"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        medians = np.zeros(len(signal) - 2 * kernel_offset)\n        for i in range(kernel_offset, len(signal) - kernel_offset):\n            medians[i - kernel_offset] = np.median(signal[i - kernel_offset : i + kernel_offset + 1])\n        return medians"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        median = np.zeros(len(signal) - 2 * kernel_offset)\n        for i in range(kernel_offset, len(signal) - kernel_offset):\n            median[i - kernel_offset] = np.median(signal[i - kernel_offset : i + kernel_offset + 1])\n        return median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        rolled = np.array([np.roll(signal, i) for i in range(-kernel_offset, kernel_offset + 1)])\n        rolled = np.sort(rolled, axis=0)\n        return np.median(rolled, axis=0)"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        medians = np.zeros(len(signal) - 2 * kernel_offset)\n        for i in range(kernel_offset, len(signal) - kernel_offset):\n            medians[i - kernel_offset] = np.median(signal[i - kernel_offset : i + kernel_offset + 1])\n        return medians"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        medians = np.zeros(len(signal) - 2 * kernel_offset)\n        for i in range(kernel_offset, len(signal) - kernel_offset):\n            medians[i - kernel_offset] = np.median(signal[i - kernel_offset : i + kernel_offset + 1])\n        return medians"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        median = np.zeros(len(signal) - 2 * kernel_offset)\n        for i in range(kernel_offset, len(signal) - kernel_offset):\n            median[i - kernel_offset] = np.median(signal[i - kernel_offset : i + kernel_offset + 1])\n        return median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        medians = np.zeros(len(signal) - 2 * kernel_offset)\n        for i in range(kernel_offset, len(signal) - kernel_offset):\n            medians[i - kernel_offset] = np.median(signal[i - kernel_offset : i + kernel_offset + 1])\n        return medians"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        rolling_median = np.zeros(len(signal) - 2 * kernel_offset)\n        for i in range(kernel_offset, len(signal) - kernel_offset):\n            rolling_median[i - kernel_offset] = np.median(signal[i - kernel_offset : i + kernel_offset + 1])\n        return rolling_median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        medians = np.zeros(len(signal) - 2 * kernel_offset)\n        for i in range(kernel_offset, len(signal) - kernel_offset):\n            medians[i - kernel_offset] = np.median(signal[i - kernel_offset : i + kernel_offset + 1])\n        return medians"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        rolled = np.lib.stride_tricks.sliding_window_view(signal, kernel_offset * 2 + 1)\n        median = np.median(rolled, axis=1)\n        return median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        median = np.zeros(len(signal) - 2 * kernel_offset)\n        for i in range(kernel_offset, len(signal) - kernel_offset):\n            median[i - kernel_offset] = np.median(signal[i - kernel_offset : i + kernel_offset + 1])\n        return median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        medians = np.zeros(len(signal) - 2 * kernel_offset)\n        for i in range(kernel_offset, len(signal) - kernel_offset):\n            medians[i - kernel_offset] = np.median(signal[i - kernel_offset : i + kernel_offset + 1])\n        return medians"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        rolled = np.lib.stride_tricks.sliding_window_view(signal, kernel_offset * 2 + 1)\n        medians = np.median(rolled, axis=1)\n        return medians[kernel_offset:-kernel_offset]"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    probe_irisbits = template_probe.iriscode\n    probe_maskbits = template_probe.mask\n    gallery_irisbits = template_gallery.iriscode\n    gallery_maskbits = template_gallery.mask\n\n    # Calculate the half width of the iris code\n    half_width = [probe_irisbits.shape[1] // 2, gallery_irisbits.shape[1] // 2]\n\n    # Calculate the total bit counts\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        probe_irisbits.size, half_width, weights\n    )\n\n    # Calculate the nonmatch bits for Hamming distance\n    irisbitcount_probe_top, maskbitcount_probe_top, irisbitcount_probe_bot, maskbitcount_probe_bot = count_nonmatchbits(\n        probe_irisbits, probe_maskbits, half_width, weights\n    )\n    irisbitcount_gallery_top, maskbitcount_gallery_top, irisbitcount_gallery_bot, maskbitcount_gallery_bot = count_nonmatchbits(\n        gallery_irisbits, gallery_maskbits, half_width, weights\n    )\n\n    # Calculate the normalized Hamming distance\n    if nm_dist is not None:\n        norm_HD_probe_top = normalized_HD(\n            irisbitcount_probe_top, maskbitcount_probe_top, sqrt_totalbitcount_top, nm_dist\n        )\n        norm_HD_probe_bot = normalized_HD(\n            irisbitcount_probe_bot, maskbitcount_probe_bot, sqrt_totalbitcount_bot, nm_dist\n        )\n        norm_HD_gallery_top = normalized_HD(\n            irisbitcount_gallery_top, maskbitcount_gallery_top, sqrt_totalbitcount_top, nm_dist\n        )\n        norm_HD_gallery_bot = normalized_HD(\n            irisbitcount_gallery_bot, maskbitcount_gallery_bot, sqrt_totalbitcount_bot, nm_dist\n        )\n    else:\n        norm_HD_probe_top, norm_HD_probe_bot, norm_HD_gallery_top, norm_HD_gallery_bot = 0, 0, 0, 0\n\n    # Calculate the Hamming distance\n    HD_top = (\n        np.sum(np.bitwise_xor(probe_irisbits[:, rotation_shift:, :], gallery_irisbits[:, :-rotation_shift, :]))\n        + irisbitcount_probe_top\n        + irisbitcount_gallery_top\n        - 2 * np.sum(\n            np.bitwise_and(probe_irisbits[:, rotation_shift:, :], gallery_irisbits[:, :-rotation_shift, :])\n        )\n        - maskbitcount_probe_top\n        - maskbitcount_gallery_top\n    )\n    HD_bot = (\n        np.sum(np.bitwise_xor(probe_irisbits[:, :-rotation_shift, :], gallery_irisbits[:, rotation_shift:, :]))\n        + irisbitcount_probe_bot\n        + irisbitcount_gallery_bot\n        - 2 * np.sum(\n            np.bitwise_and(probe_irisbits[:, :-rotation_shift, :], gallery_irisbits[:, rotation_shift:, :])\n        )\n        - maskbitcount_probe_bot\n        - maskbitcount_gallery_bot\n    )\n\n    # Return the minimum Hamming distance and the corresponding rotation shift\n    return min(HD_top + norm_HD_probe_top + norm_HD_gallery_top, HD_bot + norm_HD_probe_bot + norm_HD_gallery_bot), np.argmin([HD_top, HD_bot])"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    if nm_dist is not None and weights is not None:\n        raise MatcherError(\"Both normalized Hamming distance and weighted Hamming distance cannot be calculated together.\")\n\n    probe_bits = template_probe.iriscode\n    gallery_bits = template_gallery.iriscode\n\n    probe_mask = template_probe.mask\n    gallery_mask = template_gallery.mask\n\n    probe_half_width = template_probe.width // 2\n    gallery_half_width = template_gallery.width // 2\n\n    probe_irisbitcount = np.sum(probe_bits)\n    gallery_irisbitcount = np.sum(gallery_bits)\n\n    probe_maskbitcount = np.sum(probe_mask)\n    gallery_maskbitcount = np.sum(gallery_mask)\n\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        template_probe.size, [probe_half_width, gallery_half_width], weights\n    )\n\n    probe_irisbitcount_top, probe_maskbitcount_top, probe_irisbitcount_bot, probe_maskbitcount_bot = count_nonmatchbits(\n        probe_bits, probe_mask, [probe_half_width, gallery_half_width], weights\n    )\n\n    min_distance = float(\"inf\")\n    min_shift = 0\n\n    for shift in range(-rotation_shift, rotation_shift + 1):\n        shifted_probe = np.roll(probe_bits, shift, axis=1)\n        shifted_probe_mask = np.roll(probe_mask, shift, axis=1)\n\n        irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n            shifted_probe, gallery_bits, [probe_half_width, gallery_half_width], weights\n        )\n\n        norm_HD_top = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist)\n        norm_HD_bot = normalized_HD(irisbitcount_bot, maskbitcount_bot, sqrt_totalbitcount_bot, nm_dist)\n\n        distance = (\n            max(probe_irisbitcount, gallery_irisbitcount)\n            - (irisbitcount_top + irisbitcount_bot)\n            + (probe_irisbitcount_top - irisbitcount_top)\n            + (probe_irisbitcount_bot - irisbitcount_bot)\n            + (probe_maskbitcount - maskbitcount_top - maskbitcount_bot)\n            + (probe_maskbitcount_top - maskbitcount_top)\n            + (probe_maskbitcount_bot - maskbitcount_bot)\n            + norm_HD_top\n            + norm_HD_bot\n        )\n\n        if distance < min_distance:\n            min_distance = distance\n            min_shift = shift\n\n    return min_distance, min_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    probe_irisbits = template_probe.iriscode\n    probe_maskbits = template_probe.mask\n\n    gallery_irisbits = template_gallery.iriscode\n    gallery_maskbits = template_gallery.mask\n\n    half_width = [probe_irisbits.shape[1] // 2, gallery_irisbits.shape[1] // 2]\n\n    if nm_dist is not None:\n        irisbitcount_probe, maskbitcount_probe_top, irisbitcount_gallery, maskbitcount_gallery_top = count_nonmatchbits(\n            probe_irisbits, probe_maskbits, [half_width[0]], weights\n        )\n        irisbitcount_probe, maskbitcount_probe_bot, irisbitcount_gallery, maskbitcount_gallery_bot = count_nonmatchbits(\n            probe_irisbits, probe_maskbits, [half_width[1]], weights\n        )\n\n        sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n            probe_irisbits.size, half_width, weights\n        )\n\n        norm_HD_probe_top = normalized_HD(irisbitcount_probe, maskbitcount_probe_top, sqrt_totalbitcount_top, nm_dist)\n        norm_HD_probe_bot = normalized_HD(irisbitcount_probe, maskbitcount_probe_bot, sqrt_totalbitcount_bot, nm_dist)\n\n        norm_HD_gallery_top = normalized_HD(irisbitcount_gallery, maskbitcount_gallery_top, sqrt_totalbitcount_top, nm_dist)\n        norm_HD_gallery_bot = normalized_HD(irisbitcount_gallery, maskbitcount_gallery_bot, sqrt_totalbitcount_bot, nm_dist)\n\n        norm_HD = min(norm_HD_probe_top, norm_HD_probe_bot, norm_HD_gallery_top, norm_HD_gallery_bot)\n\n        return norm_HD, 0\n\n    else:\n        min_HD = float(\"inf\")\n        min_rotation_shift = 0\n        for shift in range(-rotation_shift, rotation_shift + 1):\n            rotated_gallery_irisbits = np.roll(gallery_irisbits, shift, axis=1)\n            HD = np.sum(probe_irisbits != rotated_gallery_irisbits)\n\n            if weights:\n                HD = np.sum(np.multiply(probe_irisbits != rotated_gallery_irisbits, weights[0]))\n\n            if HD < min_HD:\n                min_HD = HD\n                min_rotation_shift = shift\n\n        return min_HD, min_rotation_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Convert rotation shift to columns\n    rotation_shift = rotation_shift % template_probe.iriscode.shape[1]\n\n    # Apply rotation shift to probe iriscode\n    rotated_probe_iriscode = np.roll(template_probe.iriscode, rotation_shift, axis=1)\n\n    # Calculate Hamming distance\n    hd_values = []\n    for i in range(template_probe.iriscode.shape[1]):\n        hd = np.sum(rotated_probe_iriscode[:, i] != template_gallery.iriscode[:, i])\n        hd_values.append(hd)\n\n    min_hd = min(hd_values)\n    min_index = hd_values.index(min_hd)\n\n    return min_hd, min_index"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    probe_irisbits = template_probe.iriscode\n    gallery_irisbits = template_gallery.iriscode\n\n    half_width = [template_probe.width // 2, template_gallery.width // 2]\n\n    if nm_dist is not None:\n        irisbitcount_probe, maskbitcount_probe, irisbitcount_gallery, maskbitcount_gallery = count_nonmatchbits(\n            probe_irisbits, gallery_irisbits, half_width, weights\n        )\n        sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n            template_probe.size, half_width, weights\n        )\n        norm_HD_probe = normalized_HD(irisbitcount_probe, maskbitcount_probe, sqrt_totalbitcount, nm_dist)\n        norm_HD_gallery = normalized_HD(irisbitcount_gallery, maskbitcount_gallery, sqrt_totalbitcount, nm_dist)\n    else:\n        norm_HD_probe = 0\n        norm_HD_gallery = 0\n\n    min_HD = float(\"inf\")\n    min_shift = 0\n\n    for shift in range(-rotation_shift, rotation_shift + 1):\n        shifted_probe = np.roll(probe_irisbits, shift, axis=1)\n        HD = np.sum(shifted_probe != gallery_irisbits)\n        HD = HD + norm_HD_probe + norm_HD_gallery\n        if HD < min_HD:\n            min_HD = HD\n            min_shift = shift\n\n    return min_HD, min_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "\n    # Convert rotation shift to columns\n    rotation_shift = int(template_probe.iriscode.shape[1] * rotation_shift)\n\n    # Calculate total bit counts\n    totalbitcount = template_probe.iriscode.size\n    half_width = [code.shape[1] // 2 for code in template_probe.iriscode]\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        totalbitcount, half_width, weights\n    )\n\n    # Calculate nonmatch bits\n    irisbitcount_probe_top, maskbitcount_probe_top, irisbitcount_probe_bot, maskbitcount_probe_bot = count_nonmatchbits(\n        template_probe.iriscode, template_probe.mask, half_width, weights\n    )\n    irisbitcount_gallery_top, maskbitcount_gallery_top, irisbitcount_gallery_bot, maskbitcount_gallery_bot = count_nonmatchbits(\n        template_gallery.iriscode, template_gallery.mask, half_width, weights\n    )\n\n    # Calculate normalized Hamming distance\n    if nm_dist is not None:\n        norm_HD_probe_top = normalized_HD(\n            irisbitcount_probe_top, maskbitcount_probe_top, sqrt_totalbitcount_top, nm_dist\n        )\n        norm_HD_probe_bot = normalized_HD(\n            irisbitcount_probe_bot, maskbitcount_probe_bot, sqrt_totalbitcount_bot, nm_dist\n        )\n        norm_HD_gallery_top = normalized_HD(\n            irisbitcount_gallery_top, maskbitcount_gallery_top, sqrt_totalbitcount_top, nm_dist\n        )\n        norm_HD_gallery_bot = normalized_HD(\n            irisbitcount_gallery_bot, maskbitcount_gallery_bot, sqrt_totalbitcount_bot, nm_dist\n        )\n\n        # Calculate weighted Hamming distance\n        if weights:\n            weighted_HD_probe_top = np.sum(\n                [np.sum(np.multiply(x[:, hw:, ...] ^ y[:, hw:, ...], z[:, hw:, ...])) for x, y, hw, z in zip(template_probe.iriscode, template_gallery.iriscode, half_width, weights)]\n            )\n            weighted_HD_probe_bot = np.sum(\n                [np.sum(np.multiply(x[:, :hw, ...] ^ y[:, :hw, ...], z[:, :hw, ...])) for x, y, hw, z in zip(template_probe.iriscode, template_gallery.iriscode, half_width, weights)]\n            )\n            weighted_HD_gallery_top = np.sum(\n                [np.sum(np.multiply(x[:, hw:, ...] ^ y[:, hw:, ...], z[:, hw:, ...])) for x, y, hw, z in zip(template_probe.iriscode, template_gallery.iriscode, half_width, weights)]\n            )\n            weighted_HD_gallery_bot = np.sum(\n                [np.sum(np.multiply(x[:, :hw, ...] ^ y[:, :hw, ...], z[:, :hw, ...])) for x, y, hw, z in zip(template_probe.iriscode, template_gallery.iriscode, half_width, weights)]\n            )\n        else:\n            weighted_HD_probe_top = np.sum([np.sum(x[:, hw:, ...] ^ y[:, hw:, ...]) for x, y, hw in zip(template_probe.iriscode, template_gallery.iriscode, half_width)])\n            weighted_HD_probe_bot = np.sum([np.sum(x[:, :hw, ...] ^ y[:, :hw, ...]) for x, y, hw in zip(template_probe.iriscode, template_gallery.iriscode, half_width)])\n            weighted_HD_gallery_top = np.sum([np.sum(x[:, hw:, ...] ^ y[:, hw:, ...]) for x, y, hw in zip(template_probe.iriscode, template_gallery.iriscode, half_width)])\n            weighted_HD_gallery_bot = np.sum([np.sum(x[:, :hw, ...] ^ y[:, :hw, ...]) for x, y, hw in zip(template_probe.iriscode, template_gallery.iriscode, half_width)])\n\n        # Calculate Hamming distance\n        hamming_distances = [\n            norm_HD_probe_top + norm_HD_gallery_top + weighted_HD_probe_bot + weighted_HD_gallery_bot,\n            norm_HD_probe_bot + norm_HD_gallery_bot + weighted_HD_probe_top + weighted_HD_gallery_top,\n        ]\n        min_hamming_distance = min(hamming_distances)\n        min_rotation_shift = hamming_distances.index(min_hamming_distance)\n    else:\n        # Calculate Hamming distance\n        hamming_distances = [\n            irisbitcount_probe_top + maskbitcount_gallery_top + irisbitcount_probe_bot + maskbitcount_gallery_bot,\n            irisbitcount_probe_bot + maskbitcount_gallery_bot + irisbitcount_probe_top + maskbitcount_gallery_top,\n        ]\n        min_hamming_distance = min(hamming_distances)\n        min_rotation_shift = hamming_distances.index(min_hamming_distance)\n\n    return min_hamming_distance, min_rotation_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    probe_irisbits = template_probe.iriscode\n    probe_maskbits = template_probe.mask\n    gallery_irisbits = template_gallery.iriscode\n    gallery_maskbits = template_gallery.mask\n\n    half_width = [probe_irisbits.shape[1] // 2, gallery_irisbits.shape[1] // 2]\n\n    irisbitcount_probe_top, maskbitcount_probe_top, irisbitcount_probe_bot, maskbitcount_probe_bot = count_nonmatchbits(\n        probe_irisbits, probe_maskbits, half_width, weights\n    )\n    irisbitcount_gallery_top, maskbitcount_gallery_top, irisbitcount_gallery_bot, maskbitcount_gallery_bot = count_nonmatchbits(\n        gallery_irisbits, gallery_maskbits, half_width, weights\n    )\n\n    toal_codesize = probe_irisbits.size + gallery_irisbits.size\n\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        toal_codesize, half_width, weights\n    )\n\n    if nm_dist is not None:\n        norm_HD_probe_top = normalized_HD(\n            irisbitcount_probe_top, maskbitcount_probe_top, sqrt_totalbitcount_top, nm_dist\n        )\n        norm_HD_probe_bot = normalized_HD(\n            irisbitcount_probe_bot, maskbitcount_probe_bot, sqrt_totalbitcount_bot, nm_dist\n        )\n        norm_HD_gallery_top = normalized_HD(\n            irisbitcount_gallery_top, maskbitcount_gallery_top, sqrt_totalbitcount_top, nm_dist\n        )\n        norm_HD_gallery_bot = normalized_HD(\n            irisbitcount_gallery_bot, maskbitcount_gallery_bot, sqrt_totalbitcount_bot, nm_dist\n        )\n\n        norm_HD = (norm_HD_probe_top + norm_HD_probe_bot + norm_HD_gallery_top + norm_HD_gallery_bot) / 4\n        return norm_HD, 0\n\n    else:\n        HD = (\n            irisbitcount_probe_top + irisbitcount_probe_bot + irisbitcount_gallery_top + irisbitcount_gallery_bot\n            - (maskbitcount_probe_top + maskbitcount_probe_bot + maskbitcount_gallery_top + maskbitcount_gallery_bot)\n        )\n        return HD, 0"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    probe_irisbits = template_probe.iriscode\n    probe_maskbits = template_probe.mask\n\n    gallery_irisbits = template_gallery.iriscode\n    gallery_maskbits = template_gallery.mask\n\n    half_width = [probe_irisbits.shape[1] // 2, gallery_irisbits.shape[1] // 2]\n\n    irisbitcount_probe_top, maskbitcount_probe_top, irisbitcount_probe_bot, maskbitcount_probe_bot = count_nonmatchbits(\n        probe_irisbits, probe_maskbits, half_width, weights\n    )\n\n    irisbitcount_gallery_top, maskbitcount_gallery_top, irisbitcount_gallery_bot, maskbitcount_gallery_bot = count_nonmatchbits(\n        gallery_irisbits, gallery_maskbits, half_width, weights\n    )\n\n    totalbitcount, totalbitcount_top, totalbitcount_bot = count_sqrt_totalbits(\n        probe_irisbits.size, half_width, weights\n    )\n\n    if nm_dist:\n        norm_HD_probe_top = normalized_HD(irisbitcount_probe_top, maskbitcount_probe_top, totalbitcount_top, nm_dist)\n        norm_HD_probe_bot = normalized_HD(irisbitcount_probe_bot, maskbitcount_probe_bot, totalbitcount_bot, nm_dist)\n        norm_HD_gallery_top = normalized_HD(irisbitcount_gallery_top, maskbitcount_gallery_top, totalbitcount_top, nm_dist)\n        norm_HD_gallery_bot = normalized_HD(irisbitcount_gallery_bot, maskbitcount_gallery_bot, totalbitcount_bot)\n\n        min_norm_HD_top = min(norm_HD_probe_top, norm_HD_gallery_top)\n        min_norm_HD_bot = min(norm_HD_probe_bot, norm_HD_gallery_bot)\n\n        min_norm_HD = min(min_norm_HD_top, min_norm_HD_bot)\n\n        return min_norm_HD, rotation_shift\n\n    else:\n        HD_probe_top = irisbitcount_probe_top + maskbitcount_gallery_top - 2 * np.sum(\n            probe_irisbits[:, rotation_shift:, ...] & gallery_irisbits[:, :-rotation_shift, ...]\n        )\n        HD_probe_bot = irisbitcount_probe_bot + maskbitcount_gallery_bot - 2 * np.sum(\n            probe_irisbits[:, :-rotation_shift, ...] & gallery_irisbits[:, rotation_shift:, ...]\n        )\n        HD_gallery_top = irisbitcount_gallery_top + maskbitcount_probe_top - 2 * np.sum(\n            gallery_irisbits[:, rotation_shift:, ...] & probe_irisbits[:, :-rotation_shift, ...]\n        )\n        HD_gallery_bot = irisbitcount_gallery_bot + maskbitcount_probe_bot - 2 * np.sum(\n            gallery_irisbits[:, :-rotation_shift, ...] & probe_irisbits[:, rotation_shift:, ...]\n        )\n\n        min_HD_top = min(HD_probe_top, HD_gallery_top)\n        min_HD_bot = min(HD_probe_bot, HD_gallery_bot)\n\n        min_HD = min(min_HD_top, min_HD_bot)\n\n        return min_HD, rotation_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Convert rotation shift to columns\n    rotation_shift = int(template_probe.code_width * rotation_shift / 360)\n\n    # Extract iris and mask bits\n    irisbits_probe = template_probe.iriscode\n    maskbits_probe = template_probe.mask\n    irisbits_gallery = template_gallery.iriscode\n    maskbits_gallery = template_gallery.mask\n\n    # Calculate half width\n    half_width = [template_probe.code_width // 2, template_gallery.code_width // 2]\n\n    # Calculate nonmatch bits\n    irisbitcount_probe_top, maskbitcount_probe_top, irisbitcount_probe_bot, maskbitcount_probe_bot = count_nonmatchbits(\n        irisbits_probe, maskbits_probe, half_width, weights\n    )\n    irisbitcount_gallery_top, maskbitcount_gallery_top, irisbitcount_gallery_bot, maskbitcount_gallery_bot = count_nonmatchbits(\n        irisbits_gallery, maskbits_gallery, half_width, weights\n    )\n\n    # Calculate total bit counts\n    totalbitcount_probe, totalbitcount_gallery = len(irisbits_probe.flatten()), len(irisbits_gallery.flatten())\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        totalbitcount_probe, half_width, weights\n    )\n\n    # Calculate normalized Hamming distance\n    if nm_dist is not None:\n        norm_HD_probe_top = normalized_HD(irisbitcount_probe_top, maskbitcount_probe_top, sqrt_totalbitcount_top, nm_dist)\n        norm_HD_probe_bot = normalized_HD(irisbitcount_probe_bot, maskbitcount_probe_bot, sqrt_totalbitcount_bot, nm_dist)\n        norm_HD_gallery_top = normalized_HD(irisbitcount_gallery_top, maskbitcount_gallery_top, sqrt_totalbitcount_top, nm_dist)\n        norm_HD_gallery_bot = normalized_HD(irisbitcount_gallery_bot, maskbitcount_gallery_bot, sqrt_totalbitcount_bot, nm_dist)\n\n        norm_HD = min(norm_HD_probe_top + norm_HD_gallery_bot, norm_HD_probe_bot + norm_HD_gallery_top)\n    else:\n        # Calculate Hamming distance\n        HD_probe_top = irisbitcount_probe_top + maskbitcount_gallery_bot - (irisbits_gallery[:, -rotation_shift:] & maskbits_probe[:, :rotation_shift]).sum()\n        HD_probe_bot = irisbitcount_probe_bot + maskbitcount_gallery_top - (irisbits_gallery[:, :rotation_shift] & maskbits_probe[:, -rotation_shift:]).sum()\n        HD_gallery_top = irisbitcount_gallery_top + maskbitcount_probe_bot - (irisbits_probe[:, -rotation_shift:] & maskbits_gallery[:, :rotation_shift]).sum()\n        HD_gallery_bot = irisbitcount_gallery_bot + maskbitcount_probe_top - (irisbits_probe[:, :rotation_shift] & maskbits_gallery[:, -rotation_shift:]).sum()\n\n        HD = min(HD_probe_top + HD_gallery_bot, HD_probe_bot + HD_gallery_top)\n\n    return norm_HD if nm_dist is not None else HD, rotation_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "\n    # Get iris bits from templates\n    probe_irisbits = template_probe.get_irisbits(rotation_shift)\n    gallery_irisbits = template_gallery.get_irisbits(0)\n\n    # Get mask bits from templates\n    probe_maskbits = template_probe.get_maskbits(rotation_shift)\n    gallery_maskbits = template_gallery.get_maskbits(0)\n\n    # Calculate half width\n    half_width = [template_probe.code_width // 2, template_gallery.code_width // 2]\n\n    # Count nonmatch bits\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        probe_irisbits, probe_maskbits, half_width, weights\n    )\n\n    # Count sqrt total bits\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        template_probe.code_size, half_width, weights\n    )\n\n    # Calculate normalized Hamming distance\n    norm_HD = normalized_HD(irisbitcount_top + irisbitcount_bot, maskbitcount_top + maskbitcount_bot, sqrt_totalbitcount, nm_dist)\n\n    # Calculate Hamming distance\n    HD = irisbitcount_top + irisbitcount_bot + maskbitcount_top + maskbitcount_bot\n\n    return HD, norm_HD"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "\n    half_width = [template_probe.width // 2, template_gallery.width // 2]\n\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        template_probe.codesize + template_gallery.codesize, half_width, weights\n    )\n\n    irisbitcount_probe, maskbitcount_probe, irisbitcount_gallery, maskbitcount_gallery = count_nonmatchbits(\n        template_probe.iriscode, template_probe.mask, half_width, weights\n    )\n\n    irisbitcount_gallery = np.roll(irisbitcount_gallery, rotation_shift, axis=0)\n    maskbitcount_gallery = np.roll(maskbitcount_gallery, rotation_shift, axis=0)\n\n    irisbitcount = irisbitcount_probe + irisbitcount_gallery\n    maskbitcount = maskbitcount_probe + maskbitcount_gallery\n\n    if nm_dist is not None:\n        norm_HD = normalized_HD(irisbitcount, maskbitcount, sqrt_totalbitcount, nm_dist)\n        return norm_HD, rotation_shift\n    else:\n        HD = irisbitcount + maskbitcount\n        return HD, rotation_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    probe_irisbits = template_probe.iriscode\n    gallery_irisbits = template_gallery.iriscode\n    maskbits = template_probe.maskcode\n\n    half_width = [x // 2 for x in probe_irisbits.shape[2:]]\n    irisbitcount_probe_top, maskbitcount_probe_top, irisbitcount_probe_bot, maskbitcount_probe_bot = count_nonmatchbits(\n        probe_irisbits, maskbits, half_width, weights\n    )\n    irisbitcount_gallery_top, maskbitcount_gallery_top, irisbitcount_gallery_bot, maskbitcount_gallery_bot = count_nonmatchbits(\n        gallery_irisbits, maskbits, half_width, weights\n    )\n\n    totalbitcount, totalbitcount_top, totalbitcount_bot = count_sqrt_totalbits(probe_irisbits.size, half_width, weights)\n\n    if nm_dist is not None:\n        norm_HD_probe_top = normalized_HD(irisbitcount_probe_top, maskbitcount_probe_top, totalbitcount_top, nm_dist)\n        norm_HD_probe_bot = normalized_HD(irisbitcount_probe_bot, maskbitcount_probe_bot, totalbitcount_bot, nm_dist)\n        norm_HD_gallery_top = normalized_HD(irisbitcount_gallery_top, maskbitcount_gallery_top, totalbitcount_top, nm_dist)\n        norm_HD_gallery_bot = normalized_HD(irisbitcount_gallery_bot, maskbitcount_gallery_bot, totalbitcount_bot)\n\n        nm_dist = max(norm_HD_probe_top, norm_HD_probe_bot, norm_HD_gallery_top, norm_HD_gallery_bot)\n\n    if weights:\n        HD_probe_top = np.sum(\n            [\n                np.sum(np.bitwise_xor(x[:, hw:, ...] & y[:, hw:, ...], z[:, hw:, ...]))\n                for x, y, hw, z in zip(probe_irisbits, gallery_irisbits, half_width, weights)\n            ]\n        )\n        HD_probe_bot = np.sum(\n            [\n                np.sum(np.bitwise_xor(x[:, :hw, ...] & y[:, :hw, ...], z[:, :hw, ...]))\n                for x, y, hw, z in zip(probe_irisbits, gallery_irisbits, half_width, weights)\n            ]\n        )\n    else:\n        HD_probe_top = np.sum([np.sum(np.bitwise_xor(x[:, hw:, ...], y[:, hw:, ...])) for x, y, hw in zip(probe_irisbits, gallery_irisbits, half_width)])\n        HD_probe_bot = np.sum([np.sum(np.bitwise_xor(x[:, :hw, ...], y[:, :hw, ...])) for x, y, hw in zip(probe_irisbits, gallery_irisbits, half_width)])\n\n    HD_probe = HD_probe_top + HD_probe_bot\n\n    min_HD = np.inf\n    min_shift = 0\n\n    for shift in range(-rotation_shift, rotation_shift + 1):\n        HD_gallery_top = np.sum([np.sum(np.bitwise_xor(x[:, hw - shift :, ...], y[:, hw:, ...])) for x, y, hw in zip(probe_irisbits, gallery_irisbits, half_width)])\n        HD_gallery_bot = np.sum([np.sum(np.bitwise_xor(x[:, :hw - shift, ...], y[:, :hw, ...])) for x, y, hw in zip(probe_irisbits, gallery_irisbits, half_width)])\n        HD_gallery = HD_gallery_top + HD_gallery_bot\n\n        HD = HD_probe + HD_gallery\n\n        if HD < min_HD:\n            min_HD = HD\n            min_shift = shift\n\n    return min_HD, min_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    probe_irisbits = template_probe.iriscode\n    probe_maskbits = template_probe.mask\n    gallery_irisbits = template_gallery.iriscode\n    gallery_maskbits = template_gallery.mask\n\n    # Convert rotation shift to columns\n    rotation_shift = int(rotation_shift * probe_irisbits.shape[1] / 360)\n\n    # Apply rotation shift to gallery iris bits\n    gallery_irisbits = np.roll(gallery_irisbits, shift=rotation_shift, axis=1)\n\n    # Calculate half width\n    half_width = [probe_irisbits.shape[1] // 2, probe_irisbits.shape[1] // 2]\n\n    # Count nonmatch bits\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        [probe_irisbits, gallery_irisbits], [probe_maskbits, gallery_maskbits], half_width, weights\n    )\n\n    # Count total sqrt bits\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        probe_irisbits.size, half_width, weights\n    )\n\n    # Calculate normalized Hamming distance\n    if nm_dist is not None:\n        norm_HD = normalized_HD(\n            irisbitcount_top + irisbitcount_bot,\n            maskbitcount_top + maskbitcount_bot,\n            sqrt_totalbitcount,\n            nm_dist,\n        )\n        return norm_HD, rotation_shift\n\n    # Calculate Hamming distance\n    HD_top = (maskbitcount_top - irisbitcount_top) / sqrt_totalbitcount_top\n    HD_bot = (maskbitcount_bot - irisbitcount_bot) / sqrt_totalbitcount_bot\n    HD = max(HD_top, HD_bot)\n\n    return HD, rotation_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    probe_irisbits = template_probe.iriscode\n    gallery_irisbits = template_gallery.iriscode\n    maskbits = template_probe.mask\n\n    if nm_dist is not None:\n        irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n            probe_irisbits, maskbits, template_probe.half_width, weights\n        )\n        sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n            template_probe.total_codesize, template_probe.half_width, weights\n        )\n        norm_HD_top = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist)\n        norm_HD_bot = normalized_HD(irisbitcount_bot, maskbitcount_bot, sqrt_totalbitcount_bot, nm_dist)\n        norm_HD = (norm_HD_top + norm_HD_bot) / 2\n        return norm_HD, 0\n\n    rotated_gallery_irisbits = np.roll(gallery_irisbits, rotation_shift, axis=1)\n    xor_result = np.bitwise_xor(probe_irisbits, rotated_gallery_irisbits)\n    hamming_distances = np.count_nonzero(xor_result, axis=1)\n    min_hamming_distance = np.min(hamming_distances)\n    min_rotation_shift = np.argmin(hamming_distances)\n    return float(min_hamming_distance), min_rotation_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "\n    # Extract iris bits and mask bits from the probe and gallery templates\n    probe_irisbits = template_probe.iriscode\n    gallery_irisbits = template_gallery.iriscode\n    probe_maskbits = template_probe.mask\n    gallery_maskbits = template_gallery.mask\n\n    # Get half width of the iris codes\n    half_width = [probe_irisbits.shape[1] // 2, gallery_irisbits.shape[1] // 2]\n\n    # Calculate the square root of bit counts\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        probe_irisbits.size + gallery_irisbits.size, half_width, weights\n    )\n\n    # Count nonmatch bits for Hammming distance\n    irisbitcount_probe_top, maskbitcount_probe_top, irisbitcount_probe_bot, maskbitcount_probe_bot = count_nonmatchbits(\n        probe_irisbits, probe_maskbits, half_width, weights\n    )\n    irisbitcount_gallery_top, maskbitcount_gallery_top, irisbitcount_gallery_bot, maskbitcount_gallery_bot = count_nonmatchbits(\n        gallery_irisbits, gallery_maskbits, half_width, weights\n    )\n\n    # Calculate normalized Hamming distance if nm_dist is provided\n    if nm_dist is not None:\n        norm_HD_probe_top = normalized_HD(irisbitcount_probe_top, maskbitcount_probe_top, sqrt_totalbitcount_top, nm_dist)\n        norm_HD_probe_bot = normalized_HD(irisbitcount_probe_bot, maskbitcount_probe_bot, sqrt_totalbitcount_bot, nm_dist)\n        norm_HD_gallery_top = normalized_HD(irisbitcount_gallery_top, maskbitcount_gallery_top, sqrt_totalbitcount_top, nm_dist)\n        norm_HD_gallery_bot = normalized_HD(irisbitcount_gallery_bot, maskbitcount_gallery_bot, sqrt_totalbitcount_bot, nm_dist)\n\n        # Calculate the Hamming distance for both top and bottom iris\n        hamming_dist_top = np.bitwise_xor(probe_irisbits[:, rotation_shift:], gallery_irisbits[:, :-rotation_shift]).sum(axis=1) + norm_HD_probe_top + norm_HD_gallery_top\n        hamming_dist_bot = np.bitwise_xor(probe_irisbits[:, :-rotation_shift], gallery_irisbits[:, rotation_shift:]).sum(axis=1) + norm_HD_probe_bot + norm_HD_gallery_bot\n\n        # Find the minimum Hamming distance and corresponding rotation shift\n        min_hamming_dist = min(np.min(hamming_dist_top), np.min(hamming_dist_bot))\n        min_rotation_shift = np.argmin([np.min(hamming_dist_top), np.min(hamming_dist_bot)])\n\n    else:\n        # Calculate the Hamming distance for both top and bottom iris\n        hamming_dist_top = np.bitwise_xor(probe_irisbits[:, rotation_shift:], gallery_irisbits[:, :-rotation_shift]).sum(axis=1)\n        hamming_dist_bot = np.bitwise_xor(probe_irisbits[:, :-rotation_shift], gallery_irisbits[:, rotation_shift:]).sum(axis=1)\n\n        # Find the minimum Hamming distance and corresponding rotation shift\n        min_hamming_dist = min(np.min(hamming_dist_top), np.min(hamming_dist_bot))\n        min_rotation_shift = np.argmin([np.min(hamming_dist_top), np.min(hamming_dist_bot)])\n\n    return min_hamming_dist, min_rotation_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "\n    # Extract iris bits and half width from the probe and gallery templates\n    probe_irisbits = template_probe.iriscode\n    probe_half_width = template_probe.half_width\n    gallery_irisbits = template_gallery.iriscode\n    gallery_half_width = template_gallery.half_width\n\n    # Calculate the total bit count and nonmatch bits for the probe and gallery templates\n    totalbits = probe_irisbits.shape[1]\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        totalbits, probe_half_width, weights\n    )\n    probe_irisbitcount_top, probe_maskbitcount_top, probe_irisbitcount_bot, probe_maskbitcount_bot = count_nonmatchbits(\n        probe_irisbits, gallery_irisbits, probe_half_width, weights\n    )\n    gallery_irisbitcount_top, gallery_maskbitcount_top, gallery_irisbitcount_bot, gallery_maskbitcount_bot = count_nonmatchbits(\n        gallery_irisbits, probe_irisbits, gallery_half_width, weights\n    )\n\n    # Calculate the Hamming distance for the probe and gallery templates\n    min_distance = float(\"inf\")\n    min_shift = 0\n    for shift in range(-rotation_shift, rotation_shift + 1):\n        shifted_probe_irisbits = np.roll(probe_irisbits, shift, axis=1)\n        distance_top = np.sum(shifted_probe_irisbits[:, :probe_half_width, ...] != gallery_irisbits[:, :probe_half_width, ...])\n        distance_bot = np.sum(shifted_probe_irisbits[:, probe_half_width:, ...] != gallery_irisbits[:, gallery_half_width:, ...])\n        distance = distance_top + distance_bot\n\n        if nm_dist is not None:\n            distance = normalized_HD(\n                np.sum(distance_top), np.sum(probe_maskbitcount_top), sqrt_totalbitcount_top, nm_dist\n            ) + normalized_HD(\n                np.sum(distance_bot), np.sum(probe_maskbitcount_bot), sqrt_totalbitcount_bot, nm_dist\n            )\n\n        if distance < min_distance:\n            min_distance = distance\n            min_shift = shift\n\n    return min_distance, min_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Convert rotation shift to columns\n    rotation_shift = int(template_probe.ncols * rotation_shift / 360)\n\n    # Apply rotation shift to the gallery template\n    template_gallery.rotate(rotation_shift)\n\n    # Get the iris and mask bits from the probe and gallery templates\n    probe_irisbits = template_probe.get_iris_bits()\n    probe_maskbits = template_probe.get_mask_bits()\n    gallery_irisbits = template_gallery.get_iris_bits()\n    gallery_maskbits = template_gallery.get_mask_bits()\n\n    # Count nonmatch bits for Hamming distance\n    half_width = [template_probe.ncols // 2, template_probe.ncols // 2]\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        probe_irisbits, probe_maskbits, half_width, weights\n    )\n    gallery_irisbitcount_top, gallery_maskbitcount_top, gallery_irisbitcount_bot, gallery_maskbitcount_bot = count_nonmatchbits(\n        gallery_irisbits, gallery_maskbits, half_width, weights\n    )\n\n    # Calculate the total bit counts\n    totalbitcount, totalbitcount_top, totalbitcount_bot = count_sqrt_totalbits(\n        template_probe.ncols, half_width, weights\n    )\n\n    # Calculate the Hamming distance\n    if nm_dist is not None:\n        norm_HD = normalized_HD(\n            irisbitcount_top + irisbitcount_bot,\n            maskbitcount_top + maskbitcount_bot,\n            totalbitcount,\n            nm_dist\n        )\n        gallery_norm_HD = normalized_HD(\n            gallery_irisbitcount_top + gallery_irisbitcount_bot,\n            gallery_maskbitcount_top + gallery_maskbitcount_bot,\n            totalbitcount,\n            nm_dist\n        )\n        min_HD = min(norm_HD, gallery_norm_HD)\n    else:\n        HD = irisbitcount_top + irisbitcount_bot + gallery_irisbitcount_top + gallery_irisbitcount_bot - (\n            maskbitcount_top + maskbitcount_bot + gallery_maskbitcount_top + gallery_maskbitcount_bot\n        )\n        min_HD = HD\n\n    return min_HD, rotation_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "\n    # Calculate the irisbitcount, maskbitcount, and sqrt_totalbitcount\n    irisbitcount_probe_top, maskbitcount_probe_top, irisbitcount_probe_bot, maskbitcount_probe_bot = count_nonmatchbits(\n        template_probe.iriscode, template_probe.mask, template_probe.half_width, weights\n    )\n\n    irisbitcount_gallery_top, maskbitcount_gallery_top, irisbitcount_gallery_bot, maskbitcount_gallery_bot = count_nonmatchbits(\n        template_gallery.iriscode, template_gallery.mask, template_gallery.half_width, weights\n    )\n\n    irisbitcount = min(irisbitcount_probe_top + irisbitcount_probe_bot, irisbitcount_gallery_top + irisbitcount_gallery_bot)\n    maskbitcount = min(maskbitcount_probe_top + maskbitcount_probe_bot, maskbitcount_gallery_top + maskbitcount_gallery_bot)\n\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        template_probe.iriscode.size, template_probe.half_width, weights\n    )\n\n    # Calculate the normalized Hamming distance\n    if nm_dist is not None:\n        norm_HD_probe = normalized_HD(irisbitcount_probe_top + irisbitcount_probe_bot, maskbitcount_probe_top + maskbitcount_probe_bot, sqrt_totalbitcount, nm_dist)\n        norm_HD_gallery = normalized_HD(irisbitcount_gallery_top + irisbitcount_gallery_bot, maskbitcount_gallery_top + maskbitcount_gallery_bot, sqrt_totalbitcount, nm_dist)\n        norm_HD = max(norm_HD_probe, norm_HD_gallery)\n        return norm_HD, 0\n\n    # Calculate the Hamming distance\n    else:\n        # Perform Hamming distance calculation\n        hd = max(\n            0, irisbitcount - (irisbitcount - maskbitcount) * min(1.0, np.sqrt(maskbitcount) / sqrt_totalbitcount)\n        )\n        return hd, 0"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    probe_bits = template_probe.iriscode\n    gallery_bits = template_gallery.iriscode\n\n    if probe_bits.shape != gallery_bits.shape:\n        raise MatcherError(\"Iriscode sizes are different\")\n\n    if nm_dist is not None:\n        irisbitcount_probe = np.sum(probe_bits)\n        irisbitcount_gallery = np.sum(gallery_bits)\n        maskbitcount = np.sum(probe_bits & gallery_bits)\n        sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n            probe_bits.size, template_probe.half_width, weights\n        )\n        norm_HD_probe = normalized_HD(irisbitcount_probe, maskbitcount, sqrt_totalbitcount, nm_dist)\n        norm_HD_gallery = normalized_HD(irisbitcount_gallery, maskbitcount, sqrt_totalbitcount, nm_dist)\n\n        norm_HD = (norm_HD_probe + norm_HD_gallery) / 2\n\n        return norm_HD, 0\n\n    else:\n        irisbitcount_probe_top, maskbitcount_probe_top, irisbitcount_probe_bot, maskbitcount_probe_bot = count_nonmatchbits(\n            probe_bits, template_probe.mask, template_probe.half_width, weights\n        )\n        irisbitcount_gallery_top, maskbitcount_gallery_top, irisbitcount_gallery_bot, maskbitcount_gallery_bot = count_nonmatchbits(\n            gallery_bits, template_gallery.mask, template_gallery.half_width, weights\n        )\n\n        HD_top = irisbitcount_probe_top + maskbitcount_gallery_top - 2 * (probe_bits.shape[0] - irisbitcount_probe_top - maskbitcount_gallery_top)\n        HD_bot = irisbitcount_probe_bot + maskbitcount_gallery_bot - 2 * (probe_bits.shape[0] - irisbitcount_probe_bot - maskbitcount_gallery_bot)\n\n        min_HD = min(HD_top, HD_bot)\n        min_shift = 0 if min_HD == HD_top else template_probe.half_width[0]\n\n        return min_HD, min_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Extract irisbits and maskbits from the probe and gallery templates\n    irisbits_probe = template_probe.iriscode\n    maskbits_probe = template_probe.mask\n    irisbits_gallery = template_gallery.iriscode\n    maskbits_gallery = template_gallery.mask\n\n    # Calculate the half width of the iris codes\n    half_width = [irisbits_probe.shape[1] // 2, irisbits_gallery.shape[1] // 2]\n\n    # Calculate the total bit counts\n    totalbitcount, totalbitcount_top, totalbitcount_bot = count_sqrt_totalbits(\n        irisbits_probe.size + irisbits_gallery.size, half_width, weights\n    )\n\n    # Calculate the nonmatch bits for Hamming distance\n    irisbitcount_probe_top, maskbitcount_probe_top, irisbitcount_probe_bot, maskbitcount_probe_bot = count_nonmatchbits(\n        irisbits_probe, maskbits_probe, half_width, weights\n    )\n    irisbitcount_gallery_top, maskbitcount_gallery_top, irisbitcount_gallery_bot, maskbitcount_gallery_bot = count_nonmatchbits(\n        irisbits_gallery, maskbits_gallery, half_width, weights\n    )\n\n    # Calculate the normalized Hamming distance\n    if nm_dist is not None:\n        norm_HD_probe_top = normalized_HD(irisbitcount_probe_top, maskbitcount_probe_top, totalbitcount_top, nm_dist)\n        norm_HD_probe_bot = normalized_HD(irisbitcount_probe_bot, maskbitcount_probe_bot, totalbitcount_bot, nm_dist)\n        norm_HD_gallery_top = normalized_HD(irisbitcount_gallery_top, maskbitcount_gallery_top, totalbitcount_top, nm_dist)\n        norm_HD_gallery_bot = normalized_HD(irisbitcount_gallery_bot, maskbitcount_gallery_bot, totalbitcount_bot, nm_dist)\n    else:\n        norm_HD_probe_top, norm_HD_probe_bot, norm_HD_gallery_top, norm_HD_gallery_bot = 0, 0, 0, 0\n\n    # Calculate the Hamming distance\n    HD_top = np.sum(irisbits_probe[:, rotation_shift:, ...] != irisbits_gallery[:, :-rotation_shift, ...]) + np.sum(\n        maskbits_probe[:, rotation_shift:, ...] != maskbits_gallery[:, :-rotation_shift, ...]\n    )\n    HD_bot = np.sum(irisbits_probe[:, :-rotation_shift, ...] != irisbits_gallery[:, rotation_shift:, ...]) + np.sum(\n        maskbits_probe[:, :-rotation_shift, ...] != maskbits_gallery[:, rotation_shift:, ...]\n    )\n\n    # Calculate the weighted Hamming distance\n    if weights:\n        HD_top = np.sum(np.multiply(HD_top, weights[0][:, rotation_shift:, ...])) + np.sum(\n            np.multiply(HD_top, weights[1][:, rotation_shift:, ...])\n        )\n        HD_bot = np.sum(np.multiply(HD_bot, weights[0][:, :-rotation_shift, ...])) + np.sum(\n            np.multiply(HD_bot, weights[1][:, :-rotation_shift, ...])\n        )\n\n    # Calculate the total Hamming distance\n    total_HD = HD_top + HD_bot + norm_HD_probe_top + norm_HD_probe_bot + norm_HD_gallery_top + norm_HD_gallery_bot\n\n    return total_HD, rotation_shift"}
{"namespace": "iris.utils.math.area", "completion": "    if array.ndim != 2 or array.shape[1] != 2:\n        raise ValueError(f\"This function expects a polygon, i.e. an array of shape (_, 2). Got {array.shape}\")\n\n    x = array[:, 0]\n    y = array[:, 1]\n\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))"}
{"namespace": "iris.utils.math.area", "completion": "    if array.ndim != 2 or array.shape[1] != 2:\n        raise ValueError(f\"This function expects a polygon, i.e. an array of shape (_, 2). Got {array.shape}\")\n\n    x = array[:, 0]\n    y = array[:, 1]\n\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))"}
{"namespace": "iris.utils.math.area", "completion": "    if array.ndim != 2 or array.shape[1] != 2:\n        raise ValueError(f\"This function expects a polygon, i.e. an array of shape (_, 2). Got {array.shape}\")\n\n    x = array[:, 0]\n    y = array[:, 1]\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))"}
{"namespace": "iris.utils.math.area", "completion": "    if array.ndim != 2 or array.shape[1] != 2:\n        raise ValueError(f\"This function expects a polygon, i.e. an array of shape (_, 2). Got {array.shape}\")\n\n    x = array[:, 0]\n    y = array[:, 1]\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))"}
{"namespace": "iris.utils.math.area", "completion": "    if array.ndim != 2 or array.shape[1] != 2:\n        raise ValueError(f\"This function expects a polygon, i.e. an array of shape (_, 2). Got {array.shape}\")\n\n    x = array[:, 0]\n    y = array[:, 1]\n\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))"}
{"namespace": "iris.utils.math.area", "completion": "    if array.ndim != 2 or array.shape[1] != 2:\n        raise ValueError(f\"This function expects a polygon, i.e. an array of shape (_, 2). Got {array.shape}\")\n\n    x = array[:, 0]\n    y = array[:, 1]\n\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))"}
{"namespace": "iris.utils.math.area", "completion": "    if array.ndim != 2 or array.shape[1] != 2:\n        raise ValueError(f\"This function expects a polygon, i.e. an array of shape (_, 2). Got {array.shape}\")\n\n    x = array[:, 0]\n    y = array[:, 1]\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))"}
{"namespace": "iris.utils.math.area", "completion": "    if array.ndim != 2 or array.shape[1] != 2:\n        raise ValueError(f\"This function expects a polygon, i.e. an array of shape (_, 2). Got {array.shape}\")\n\n    x = array[:, 0]\n    y = array[:, 1]\n\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))"}
{"namespace": "iris.utils.math.area", "completion": "    if array.ndim != 2 or array.shape[1] != 2:\n        raise ValueError(f\"This function expects a polygon, i.e. an array of shape (_, 2). Got {array.shape}\")\n\n    x = array[:, 0]\n    y = array[:, 1]\n\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))"}
{"namespace": "iris.utils.math.area", "completion": "    if array.ndim != 2 or array.shape[1] != 2:\n        raise ValueError(f\"This function expects a polygon, i.e. an array of shape (_, 2). Got {array.shape}\")\n\n    x = array[:, 0]\n    y = array[:, 1]\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))"}
{"namespace": "iris.utils.math.area", "completion": "    if array.ndim != 2 or array.shape[1] != 2:\n        raise ValueError(f\"This function expects a polygon, i.e. an array of shape (_, 2). Got {array.shape}\")\n\n    x = array[:, 0]\n    y = array[:, 1]\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))"}
{"namespace": "iris.utils.math.area", "completion": "    if array.ndim != 2 or array.shape[1] != 2:\n        raise ValueError(f\"This function expects a polygon, i.e. an array of shape (_, 2). Got {array.shape}\")\n\n    x = array[:, 0]\n    y = array[:, 1]\n\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))"}
{"namespace": "iris.utils.math.area", "completion": "    if array.ndim != 2 or array.shape[1] != 2:\n        raise ValueError(f\"This function expects a polygon, i.e. an array of shape (_, 2). Got {array.shape}\")\n\n    x = array[:, 0]\n    y = array[:, 1]\n\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))"}
{"namespace": "iris.utils.math.area", "completion": "    if array.ndim != 2 or array.shape[1] != 2:\n        raise ValueError(f\"This function expects a polygon, i.e. an array of shape (_, 2). Got {array.shape}\")\n\n    x = array[:, 0]\n    y = array[:, 1]\n\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))"}
{"namespace": "iris.utils.math.area", "completion": "    if array.ndim != 2 or array.shape[1] != 2:\n        raise ValueError(f\"This function expects an array of shape (_, 2) representing a list of polygon points. Got {array.shape}\")\n\n    x = array[:, 0]\n    y = array[:, 1]\n\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))"}
{"namespace": "iris.utils.math.area", "completion": "    if array.ndim != 2 or array.shape[1] != 2:\n        raise ValueError(f\"This function expects a polygon, i.e. an array of shape (_, 2). Got {array.shape}\")\n\n    x = array[:, 0]\n    y = array[:, 1]\n\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))"}
{"namespace": "iris.utils.math.area", "completion": "    if array.ndim != 2 or array.shape[1] != 2:\n        raise ValueError(f\"This function expects a polygon, i.e. an array of shape (_, 2). Got {array.shape}\")\n\n    # Shoelace formula\n    x = array[:, 0]\n    y = array[:, 1]\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))"}
{"namespace": "iris.utils.math.area", "completion": "    if array.ndim != 2 or array.shape[1] != 2:\n        raise ValueError(f\"This function expects a polygon, i.e. an array of shape (_, 2). Got {array.shape}\")\n\n    x = array[:, 0]\n    y = array[:, 1]\n\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))"}
{"namespace": "iris.utils.math.area", "completion": "    if array.ndim != 2 or array.shape[1] != 2:\n        raise ValueError(f\"This function expects a polygon, i.e. an array of shape (_, 2). Got {array.shape}\")\n\n    x = array[:, 0]\n    y = array[:, 1]\n\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))"}
{"namespace": "iris.utils.math.area", "completion": "    if array.ndim != 2 or array.shape[1] != 2:\n        raise ValueError(f\"This function expects a polygon, i.e. an array of shape (_, 2). Got {array.shape}\")\n\n    x = array[:, 0]\n    y = array[:, 1]\n\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "\n        num_points = polygon.shape[0]\n        max_iterations = self.params.max_iterations\n        bisector_start_points = []\n        bisector_end_points = []\n\n        for _ in range(self.params.num_bisectors):\n            for _ in range(max_iterations):\n                # Randomly select two points from the polygon\n                idx1, idx2 = np.random.choice(num_points, size=2, replace=False)\n                point1, point2 = polygon[idx1], polygon[idx2]\n\n                # Calculate the distance between the selected points\n                distance = np.linalg.norm(point2 - point1)\n\n                # If the distance is greater than the minimum required distance, calculate the bisector\n                if distance > min_distance_between_sector_points_in_px:\n                    bisector_start, bisector_end = self._calculate_bisector(point1, point2)\n                    bisector_start_points.append(bisector_start)\n                    bisector_end_points.append(bisector_end)\n                    break\n            else:\n                raise EyeCentersEstimationError(\"Failed to find sufficient point pairs within the maximum iterations\")\n\n        return np.array(bisector_start_points), np.array(bisector_end_points)"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "\n        num_points = polygon.shape[0]\n        max_iterations = self.params.max_iterations\n\n        first_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n        second_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n\n        for i in range(self.params.num_bisectors):\n            for _ in range(max_iterations):\n                idx1, idx2 = np.random.choice(num_points, size=2, replace=False)\n                point1, point2 = polygon[idx1], polygon[idx2]\n\n                if np.linalg.norm(point1 - point2) > min_distance_between_sector_points_in_px:\n                    midpoint = (point1 + point2) / 2\n                    direction = np.array([-1 * (point2[1] - point1[1]), point2[0] - point1[0]])\n                    direction /= np.linalg.norm(direction)\n                    first_bisectors_point[i] = midpoint + direction * 1000\n                    second_bisectors_point[i] = midpoint - direction * 1000\n                    break\n            else:\n                raise EyeCentersEstimationError(\"Failed to find a sufficient number of point pairs within the max iterations\")\n\n        return first_bisectors_point, second_bisectors_point"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Your implementation here\n        # Calculate perpendicular bisectors and return the starting and ending points as numpy arrays\n        pass"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n\n        num_points = polygon.shape[0]\n        bisector_start_points = []\n        bisector_end_points = []\n\n        for _ in range(max_iterations):\n            indices = np.random.choice(num_points, size=(num_bisectors, 2), replace=False)\n            selected_points = polygon[indices]\n\n            distances = np.linalg.norm(selected_points[:, 0] - selected_points[:, 1], axis=1)\n            valid_pairs = selected_points[distances > min_distance_between_sector_points_in_px]\n\n            if len(valid_pairs) >= num_bisectors:\n                bisector_start_points = valid_pairs[:, 0, :]\n                bisector_end_points = valid_pairs[:, 1, :]\n                break\n\n        if len(bisector_start_points) < num_bisectors:\n            raise EyeCentersEstimationError(\n                f\"Failed to find {num_bisectors} valid pairs of points within {max_iterations} iterations.\"\n            )\n\n        return bisector_start_points, bisector_end_points"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_points = polygon.shape[0]\n        max_iterations = self.params.max_iterations\n        bisector_start_points = []\n        bisector_end_points = []\n\n        for _ in range(self.params.num_bisectors):\n            for _ in range(max_iterations):\n                idx1, idx2 = np.random.choice(num_points, size=2, replace=False)\n                point1, point2 = polygon[idx1], polygon[idx2]\n                distance = np.linalg.norm(point2 - point1)\n                if distance > min_distance_between_sector_points_in_px:\n                    midpoint = (point1 + point2) / 2\n                    direction_vector = point2 - point1\n                    perpendicular_vector = np.array([-direction_vector[1], direction_vector[0]])\n                    bisector_start_points.append(midpoint)\n                    bisector_end_points.append(midpoint + perpendicular_vector)\n                    break\n            else:\n                raise EyeCentersEstimationError(\"Failed to find sufficient point pairs within the maximum iterations.\")\n\n        return np.array(bisector_start_points), np.array(bisector_end_points)"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Implementation of the function goes here\n        # Calculate perpendicular bisectors and return the starting and ending points\n        pass"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_points = polygon.shape[0]\n        max_iterations = self.params.max_iterations\n        bisector_starts = []\n        bisector_ends = []\n\n        for _ in range(self.params.num_bisectors):\n            for _ in range(max_iterations):\n                idx1, idx2 = np.random.choice(num_points, size=2, replace=False)\n                point1, point2 = polygon[idx1], polygon[idx2]\n                distance = np.linalg.norm(point2 - point1)\n\n                if distance > min_distance_between_sector_points_in_px:\n                    midpoint = (point1 + point2) / 2\n                    direction = np.array([point2[1] - point1[1], point1[0] - point2[0]])\n                    direction /= np.linalg.norm(direction)\n                    bisector_start = midpoint - direction * 1000\n                    bisector_end = midpoint + direction * 1000\n                    bisector_starts.append(bisector_start)\n                    bisector_ends.append(bisector_end)\n                    break\n            else:\n                raise EyeCentersEstimationError(\"Failed to find sufficient point pairs within max iterations\")\n\n        return np.array(bisector_starts), np.array(bisector_ends)"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n\n        # Initialize arrays to store the starting and ending points of the bisectors\n        first_bisectors_point = np.zeros((num_bisectors, 2))\n        second_bisectors_point = np.zeros((num_bisectors, 2))\n\n        # Iterate to find num_bisectors pairs of points that satisfy the minimum distance criterion\n        for i in range(num_bisectors):\n            for _ in range(max_iterations):\n                # Randomly select two points from the polygon\n                indices = np.random.choice(len(polygon), size=2, replace=False)\n                point1 = polygon[indices[0]]\n                point2 = polygon[indices[1]]\n\n                # Calculate the distance between the selected points\n                distance = np.linalg.norm(point2 - point1)\n\n                # If the distance is greater than the minimum distance criterion, store the points and break the loop\n                if distance > min_distance_between_sector_points_in_px:\n                    first_bisectors_point[i] = point1\n                    second_bisectors_point[i] = point2\n                    break\n            else:\n                # If no suitable pair of points is found within the maximum iterations, raise an error\n                raise EyeCentersEstimationError(\"Failed to find sufficient point pairs within the maximum iterations\")\n\n        return first_bisectors_point, second_bisectors_point"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_points = polygon.shape[0]\n        max_iterations = self.params.max_iterations\n        bisector_start_points = []\n        bisector_end_points = []\n\n        for _ in range(self.params.num_bisectors):\n            for _ in range(max_iterations):\n                idx1, idx2 = np.random.choice(num_points, size=2, replace=False)\n                point1, point2 = polygon[idx1], polygon[idx2]\n                distance = np.linalg.norm(point2 - point1)\n                if distance > min_distance_between_sector_points_in_px:\n                    midpoint = (point1 + point2) / 2\n                    direction = np.array([point2[1] - point1[1], point1[0] - point2[0]])\n                    direction /= np.linalg.norm(direction)\n                    bisector_start_points.append(midpoint)\n                    bisector_end_points.append(midpoint + direction)\n                    break\n            else:\n                raise EyeCentersEstimationError(\"Failed to find sufficient point pairs within the maximum iterations.\")\n\n        return np.array(bisector_start_points), np.array(bisector_end_points)"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Implementation of the function goes here\n        pass  # Placeholder for the actual implementation"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Implementation of the function goes here\n        pass"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n\n        bisector_start_points = []\n        bisector_end_points = []\n\n        for _ in range(max_iterations):\n            # Randomly select a pair of points from the polygon\n            indices = np.random.choice(len(polygon), size=2, replace=False)\n            point1, point2 = polygon[indices]\n\n            # Calculate the distance between the selected points\n            distance = np.linalg.norm(point2 - point1)\n\n            # Check if the distance between the points is greater than the minimum distance\n            if distance > min_distance_between_sector_points_in_px:\n                # Calculate the midpoint between the selected points\n                midpoint = (point1 + point2) / 2\n\n                # Calculate the direction vector of the bisector\n                direction_vector = point2 - point1\n                perpendicular_vector = np.array([-direction_vector[1], direction_vector[0]])\n\n                # Normalize the perpendicular vector\n                normalized_perpendicular_vector = perpendicular_vector / np.linalg.norm(perpendicular_vector)\n\n                # Extend the bisector from the midpoint in both directions\n                start_point = midpoint - normalized_perpendicular_vector * 1000\n                end_point = midpoint + normalized_perpendicular_vector * 1000\n\n                bisector_start_points.append(start_point)\n                bisector_end_points.append(end_point)\n\n                # Check if the number of bisectors has been reached\n                if len(bisector_start_points) == num_bisectors:\n                    return np.array(bisector_start_points), np.array(bisector_end_points)\n\n        # If the maximum number of iterations is reached without finding enough point pairs, raise an error\n        raise EyeCentersEstimationError(\"Failed to find sufficient number of valid point pairs for bisectors calculation\")"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_points = polygon.shape[0]\n        max_iterations = self.params.max_iterations\n        bisector_start_points = []\n        bisector_end_points = []\n\n        for _ in range(self.params.num_bisectors):\n            for _ in range(max_iterations):\n                idx1, idx2 = np.random.choice(num_points, size=2, replace=False)\n                point1, point2 = polygon[idx1], polygon[idx2]\n\n                distance = np.linalg.norm(point2 - point1)\n                if distance > min_distance_between_sector_points_in_px:\n                    bisector_start_points.append((point1 + point2) / 2)\n                    bisector_end_points.append((point1 - point2) / 2)\n                    break\n            else:\n                raise EyeCentersEstimationError(\"Failed to find a sufficient number of point pairs within the maximum iterations.\")\n\n        return np.array(bisector_start_points), np.array(bisector_end_points)"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_points = polygon.shape[0]\n        max_iterations = self.params.max_iterations\n\n        first_bisectors_point = np.empty((self.params.num_bisectors, 2))\n        second_bisectors_point = np.empty((self.params.num_bisectors, 2))\n\n        for i in range(self.params.num_bisectors):\n            for _ in range(max_iterations):\n                idx1, idx2 = np.random.choice(num_points, size=2, replace=False)\n                point1, point2 = polygon[idx1], polygon[idx2]\n                distance = np.linalg.norm(point2 - point1)\n                if distance > min_distance_between_sector_points_in_px:\n                    midpoint = (point1 + point2) / 2\n                    direction = np.array([point2[1] - point1[1], point1[0] - point2[0]])\n                    direction /= np.linalg.norm(direction)\n                    first_bisectors_point[i] = midpoint + direction\n                    second_bisectors_point[i] = midpoint - direction\n                    break\n            else:\n                raise EyeCentersEstimationError(\"Failed to find a sufficient number of point pairs within the maximum iterations.\")\n\n        return first_bisectors_point, second_bisectors_point"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n\n        # Ensure that the number of bisectors is less than the number of vertices in the polygon\n        if num_bisectors > len(polygon):\n            raise EyeCentersEstimationError(\"Number of bisectors cannot exceed the number of vertices in the polygon\")\n\n        # Initialize arrays to store the starting and ending points of the perpendicular bisectors\n        first_bisectors_point = np.zeros((num_bisectors, 2))\n        second_bisectors_point = np.zeros((num_bisectors, 2))\n\n        # Attempt to find num_bisectors pairs of points that satisfy the distance criterion\n        for i in range(num_bisectors):\n            found_points = False\n            iterations = 0\n\n            # Randomly select two points from the polygon\n            while not found_points and iterations < max_iterations:\n                point1, point2 = np.random.choice(polygon, size=2, replace=False)\n\n                # Calculate the distance between the two selected points\n                distance = np.linalg.norm(point2 - point1)\n\n                # Check if the distance between the points meets the minimum distance criterion\n                if distance > min_distance_between_sector_points_in_px:\n                    first_bisectors_point[i] = point1\n                    second_bisectors_point[i] = point2\n                    found_points = True\n\n                iterations += 1\n\n            # If the maximum number of iterations is reached without finding suitable points, raise an error\n            if not found_points:\n                raise EyeCentersEstimationError(\"Failed to find suitable point pairs within the maximum iterations\")\n\n        return first_bisectors_point, second_bisectors_point"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "\n        # Initialize an empty array to store the starting points of the perpendicular bisectors\n        first_bisectors_point = np.array([])\n\n        # Initialize an empty array to store the ending points of the perpendicular bisectors\n        second_bisectors_point = np.array([])\n\n        # Add logic here to calculate the perpendicular bisectors and populate the first_bisectors_point and second_bisectors_point arrays\n\n        # Return the calculated perpendicular bisectors\n        return first_bisectors_point, second_bisectors_point"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "\n        num_points = polygon.shape[0]\n        max_iterations = self.params.max_iterations\n        bisector_start_points = []\n        bisector_end_points = []\n\n        for _ in range(self.params.num_bisectors):\n            for _ in range(max_iterations):\n                # Randomly select two points from the polygon\n                idx1, idx2 = np.random.choice(num_points, 2, replace=False)\n                point1, point2 = polygon[idx1], polygon[idx2]\n\n                # Calculate the distance between the selected points\n                distance = np.linalg.norm(point1 - point2)\n\n                # Check if the distance is greater than the minimum distance\n                if distance > min_distance_between_sector_points_in_px:\n                    # Calculate the midpoint of the line segment between the two points\n                    midpoint = (point1 + point2) / 2\n\n                    # Calculate the perpendicular bisector slope\n                    slope = -(point2[0] - point1[0]) / (point2[1] - point1[1])\n\n                    # Calculate the perpendicular bisector line equation\n                    b = midpoint[1] - slope * midpoint[0]\n\n                    # Calculate the end points of the perpendicular bisector\n                    end_point1 = np.array([midpoint[0] + 1, slope * (midpoint[0] + 1) + b])\n                    end_point2 = np.array([midpoint[0] - 1, slope * (midpoint[0] - 1) + b])\n\n                    # Add the start and end points to the lists\n                    bisector_start_points.append(midpoint)\n                    bisector_end_points.append([end_point1, end_point2])\n                    break\n            else:\n                # If maximum iterations are reached without finding a suitable pair, raise an error\n                raise EyeCentersEstimationError(\"Failed to find sufficient point pairs within the maximum iterations\")\n\n        return np.array(bisector_start_points), np.array(bisector_end_points)"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Add implementation here\n        pass"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "\n        # Add implementation here\n        pass  # Placeholder for the implementation of the perpendicular bisectors calculation"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n\n        bisector_start_points = []\n        bisector_end_points = []\n\n        for _ in range(max_iterations):\n            # Randomly select two points from the polygon\n            indices = np.random.choice(len(polygon), size=2, replace=False)\n            point1 = polygon[indices[0]]\n            point2 = polygon[indices[1]]\n\n            # Calculate the distance between the two points\n            distance = np.linalg.norm(point2 - point1)\n\n            # If the distance is greater than the minimum distance required\n            if distance > min_distance_between_sector_points_in_px:\n                # Calculate the midpoint of the line segment\n                midpoint = (point1 + point2) / 2\n\n                # Calculate the direction vector of the line segment\n                direction_vector = point2 - point1\n\n                # Calculate the perpendicular bisector direction vector\n                perpendicular_direction = np.array([-direction_vector[1], direction_vector[0]])\n\n                # Normalize the perpendicular direction vector\n                normalized_perpendicular_direction = perpendicular_direction / np.linalg.norm(perpendicular_direction)\n\n                # Extend the perpendicular bisector in both directions from the midpoint\n                start_point = midpoint - normalized_perpendicular_direction * 1000\n                end_point = midpoint + normalized_perpendicular_direction * 1000\n\n                # Append the start and end points to the lists\n                bisector_start_points.append(start_point)\n                bisector_end_points.append(end_point)\n\n                # If enough bisectors have been found, exit the loop\n                if len(bisector_start_points) == num_bisectors:\n                    return np.array(bisector_start_points), np.array(bisector_end_points)\n\n        # If the loop completes without finding enough bisectors, raise an error\n        raise EyeCentersEstimationError(\"Failed to find sufficient perpendicular bisectors within the maximum iterations allowed.\")"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    total_length = 0.0\n    for i in range(len(polygon) - 1):\n        dist = np.linalg.norm(polygon[i + 1] - polygon[i])\n        if dist <= max_point_distance:\n            total_length += dist\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "\n    # Ensure the polygon is closed by adding the first point at the end\n    if not np.array_equal(polygon[0], polygon[-1]):\n        polygon = np.vstack([polygon, polygon[0]])\n\n    # Calculate the distances between consecutive points\n    distances = np.linalg.norm(polygon[1:] - polygon[:-1], axis=1)\n\n    # Exclude distances that exceed the maximum point distance\n    valid_distances = distances[distances <= max_point_distance]\n\n    # Compute the total length of the polygon\n    total_length = np.sum(valid_distances)\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    total_length = 0.0\n    for i in range(len(polygon) - 1):\n        distance = np.linalg.norm(polygon[i + 1] - polygon[i])\n        if distance <= max_point_distance:\n            total_length += distance\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    total_length = 0.0\n    for i in range(len(polygon) - 1):\n        distance = np.linalg.norm(polygon[i + 1] - polygon[i])\n        if distance <= max_point_distance:\n            total_length += distance\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    total_length = 0.0\n    for i in range(len(polygon) - 1):\n        distance = np.linalg.norm(polygon[i + 1] - polygon[i])\n        if distance <= max_point_distance:\n            total_length += distance\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    distances = np.linalg.norm(np.diff(polygon, axis=0), axis=1)\n    valid_distances = distances[distances <= max_point_distance]\n    total_length = np.sum(valid_distances)\n    return float(total_length)"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    distances = np.linalg.norm(np.diff(polygon, axis=0), axis=1)\n    valid_distances = distances[distances <= max_point_distance]\n    total_length = np.sum(valid_distances)\n    return float(total_length)"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    distances = np.linalg.norm(np.diff(polygon, axis=0), axis=1)\n    valid_distances = distances[distances <= max_point_distance]\n    total_length = np.sum(valid_distances)\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    total_length = 0.0\n    for i in range(len(polygon) - 1):\n        distance = np.linalg.norm(polygon[i + 1] - polygon[i])\n        if distance <= max_point_distance:\n            total_length += distance\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    distances = np.linalg.norm(np.diff(polygon, axis=0), axis=1)\n    valid_distances = distances[distances <= max_point_distance]\n    total_length = np.sum(valid_distances)\n    return float(total_length)"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    total_length = 0\n    for i in range(len(polygon) - 1):\n        distance = np.linalg.norm(polygon[i + 1] - polygon[i])\n        if distance <= max_point_distance:\n            total_length += distance\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    total_length = 0.0\n    for i in range(len(polygon)):\n        point1 = polygon[i]\n        point2 = polygon[(i + 1) % len(polygon)]  # Wrap around to the first point when at the last point\n        distance = np.linalg.norm(point2 - point1)\n        if distance <= max_point_distance:\n            total_length += distance\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    total_length = 0.0\n    for i in range(len(polygon) - 1):\n        distance = np.linalg.norm(polygon[i + 1] - polygon[i])\n        if distance <= max_point_distance:\n            total_length += distance\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    distances = np.linalg.norm(np.diff(polygon, axis=0), axis=1)\n    valid_distances = distances[distances <= max_point_distance]\n    total_length = np.sum(valid_distances)\n    return float(total_length)"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    distances = np.linalg.norm(np.diff(polygon, axis=0), axis=1)\n    valid_distances = distances[distances <= max_point_distance]\n    total_length = np.sum(valid_distances)\n    return float(total_length)"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    total_length = 0\n    for i in range(len(polygon)):\n        p1 = polygon[i]\n        p2 = polygon[(i + 1) % len(polygon)]  # Wrap around to the first point if at the last point\n        distance = np.linalg.norm(p2 - p1)\n        if distance <= max_point_distance:\n            total_length += distance\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "\n    # Ensure that the polygon is closed\n    if not np.array_equal(polygon[0], polygon[-1]):\n        polygon = np.vstack([polygon, polygon[0]])\n\n    # Calculate the distances between consecutive points\n    distances = np.linalg.norm(np.diff(polygon, axis=0), axis=1)\n\n    # Exclude distances that exceed the maximum distance\n    valid_distances = distances[distances <= max_point_distance]\n\n    # Compute the total length of the polygon\n    total_length = np.sum(valid_distances)\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    distances = np.linalg.norm(np.diff(polygon, axis=0), axis=1)  # Compute distances between consecutive points\n    valid_distances = distances[distances <= max_point_distance]  # Exclude distances that exceed the maximum\n    total_length = np.sum(valid_distances)  # Sum the valid distances to get the total length\n    return float(total_length)"}
{"namespace": "iris.utils.math.polygon_length", "completion": "\n    total_length = 0.0\n    for i in range(len(polygon) - 1):\n        distance = np.linalg.norm(polygon[i + 1] - polygon[i])\n        if distance <= max_point_distance:\n            total_length += distance\n\n    # Add the distance between the last and first point to close the polygon\n    distance = np.linalg.norm(polygon[0] - polygon[-1])\n    if distance <= max_point_distance:\n        total_length += distance\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    total_length = 0\n    for i in range(len(polygon) - 1):\n        distance = np.linalg.norm(polygon[i + 1] - polygon[i])\n        if distance <= max_point_distance:\n            total_length += distance\n    return total_length"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if v.dtype != bool:\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if v.dtype != np.dtype('bool'):\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if v.dtype != bool:\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if v.dtype != bool:\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if v.dtype != bool:\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if v.dtype != bool:\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if v.dtype != bool:\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if v.dtype != bool:\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if v.dtype != bool:\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if v.dtype != bool:\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if v.dtype != bool:\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if v.dtype != bool:\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if v.dtype != bool:\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if v.dtype != np.dtype('bool'):\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if v.dtype != np.bool:\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if v.dtype != np.bool:\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if v.dtype != bool:\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if v.dtype != np.bool:\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if v.dtype != bool:\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if v.dtype != bool:\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Got shape {v.shape}\")\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Got shape {v.shape}\")\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Got shape {v.shape}\")\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points.\")\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points.\")\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Got shape {v.shape}\")\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Got shape {v.shape}\")\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Got shape {v.shape}\")\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if len(v.shape) != 2 or v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points.\")\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Got shape {v.shape}\")\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Got shape {v.shape}\")\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Got shape {v.shape}\")\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Got shape {v.shape}\")\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Got shape {v.shape}\")\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Got shape {v.shape}\")\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Got shape {v.shape}\")\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Got shape {v.shape}\")\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points with shape (_, 2).\")\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Got shape {v.shape}\")\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Got shape {v.shape}\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for value in v:\n            if value <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for val in v:\n            if val <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for value in v:\n            if value <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for val in v:\n            if val <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for val in v:\n            if val <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for val in v:\n            if val <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for value in v:\n            if value <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if any(x <= 0 for x in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for val in v:\n            if val <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for val in v:\n            if val <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for val in v:\n            if val <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for value in v:\n            if value <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if any(x <= 0 for x in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for val in v:\n            if val <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for val in v:\n            if val <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for val in v:\n            if val <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for val in v:\n            if val <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for value in v:\n            if value <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for val in v:\n            if val <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for val in v:\n            if val <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n\n    return v"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n    \n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    x_min, x_max, y_min, y_max = values[\"x_min\"], values[\"x_max\"], values[\"y_min\"], values[\"y_max\"]\n    if x_min >= x_max:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n    if y_min >= y_max:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"] or values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: Invalid bounding box values. x_min must be less than x_max and y_min must be less than y_max.\")\n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"] or values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: Invalid bounding box values. x_min must be less than x_max and y_min must be less than y_max.\")\n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"] or values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: Invalid bounding box values. x_min must be less than x_max and y_min must be less than y_max.\")\n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"] or values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: Invalid bounding box values. x_min must be less than x_max and y_min must be less than y_max.\")\n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "        if values[\"x_min\"] >= values[\"x_max\"]:\n            raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n\n        if values[\"y_min\"] >= values[\"y_max\"]:\n            raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n        return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"] or values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: Invalid bounding box values. x_min must be less than x_max and y_min must be less than y_max.\")\n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    x_min, x_max, y_min, y_max = values[\"x_min\"], values[\"x_max\"], values[\"y_min\"], values[\"y_max\"]\n\n    if x_min >= x_max:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n    if y_min >= y_max:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"] or values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: Invalid bounding box values. x_min and y_min must be less than x_max and y_max, respectively.\")\n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"] or values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: Invalid bounding box values. x_min and y_min must be less than x_max and y_max, respectively.\")\n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values['x_min'] >= values['x_max']:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n\n    if values['y_min'] >= values['y_max']:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"] or values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: Invalid bounding box values. x_min must be less than x_max and y_min must be less than y_max.\")\n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"] or values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: Invalid bounding box values. x_min and y_min must be less than x_max and y_max, respectively.\")\n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "\n    x_min = values.get(\"x_min\", 0)\n    x_max = values.get(\"x_max\", 0)\n    y_min = values.get(\"y_min\", 0)\n    y_max = values.get(\"y_max\", 0)\n\n    if x_min >= x_max or y_min >= y_max:\n        raise ValueError(f\"{cls.__name__}: Invalid bounding box values. x_min must be less than x_max and y_min must be less than y_max.\")\n\n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    x_min = values.get(\"x_min\", 0)\n    x_max = values.get(\"x_max\", 0)\n    y_min = values.get(\"y_min\", 0)\n    y_max = values.get(\"y_max\", 0)\n\n    if x_min >= x_max:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n\n    if y_min >= y_max:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "\n    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "\n    if values[\"x_min\"] >= values[\"x_max\"] or values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: Invalid bounding box values. x_min must be less than x_max and y_min must be less than y_max.\")\n\n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    x_min, x_max, y_min, y_max = values[\"x_min\"], values[\"x_max\"], values[\"y_min\"], values[\"y_max\"]\n\n    if x_min >= x_max:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n    if y_min >= y_max:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "\n    def __validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if np.ndarray has a specific number of dimensions.\"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n        return v\n\n    return __validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "\n    def __validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if the array has the specified number of dimensions.\"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n\n        return v\n\n    return __validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "\n    def __validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if the array has the specified number of dimensions.\"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n        return v\n\n    return __validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def __array_n_dimensions_validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if the array has the specified number of dimensions.\"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n        return v\n\n    return __array_n_dimensions_validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "\n    def __validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if the array has the specified number of dimensions.\"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n        return v\n\n    return __validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "\n    def __array_n_dimensions_validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if the array has the specified number of dimensions.\"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n        return v\n\n    return __array_n_dimensions_validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "\n    def __validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if the array has the specified number of dimensions.\"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n        return v\n\n    return __validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "\n    def __array_n_dimensions_validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if the array has the specified number of dimensions.\"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n        return v\n\n    return __array_n_dimensions_validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "\n    def __validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if the array has the specified number of dimensions.\"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n        return v\n\n    return __validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "\n    def __validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if the array has the specified number of dimensions.\"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n        return v\n\n    return __validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "\n    def __validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if np.ndarray has the specified number of dimensions.\"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n\n        return v\n\n    return __validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def __validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if the array has the specified number of dimensions.\"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n        return v\n\n    return __validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "\n    def __validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if the array has the specified number of dimensions.\"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n        return v\n\n    return __validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def __validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if np.ndarray has the specified number of dimensions.\"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n        return v\n\n    return __validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "\n    def __validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if the array has the specified number of dimensions.\"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n        return v\n\n    return __validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "\n    def __validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if the array has the specified number of dimensions.\"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n        return v\n\n    return __validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "\n    def __validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if the array has the specified number of dimensions.\"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n        return v\n\n    return __validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def __validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if the array has the specified number of dimensions.\"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n        return v\n\n    return __validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "\n    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if the array has the specified number of dimensions.\"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n        return v\n\n    return validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "\n    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if the array has the specified number of dimensions.\"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n        return v\n\n    return validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1 and field2 contain lists of numpy arrays with equal shapes.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for arr1, arr2 in zip(values[field1], values[field2]):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1 and field2 have the same shapes.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch.\")\n\n        for arr1, arr2 in zip(values[field1], values[field2]):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch.\")\n\n        for arr1, arr2 in zip(values[field1], values[field2]):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1 and field2 have the same shapes for each corresponding numpy array.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch.\")\n        for arr1, arr2 in zip(values[field1], values[field2]):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch for corresponding arrays.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1 and field2 have the same shapes.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch.\")\n        for arr1, arr2 in zip(values[field1], values[field2]):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch.\")\n        for arr1, arr2 in zip(values[field1], values[field2]):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1 and field2 have arrays with equal shapes.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for arr1, arr2 in zip(values[field1], values[field2]):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch.\")\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1}[{i}] and {field2}[{i}] shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                             f\"resp. {len(values[field1])} and {len(values[field2])}\")\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1}[{i}] and {field2}[{i}] shape mismatch.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1 and field2 have the same shapes for each corresponding pair of arrays.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n        for arr1, arr2 in zip(values[field1], values[field2]):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1 and field2 have the same shapes for each corresponding array.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch.\")\n\n        for arr1, arr2 in zip(values[field1], values[field2]):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1 and field2 have the same shape for each corresponding pair of arrays.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n        for arr1, arr2 in zip(values[field1], values[field2]):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1 and field2 have the same shapes.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch.\")\n\n        for arr1, arr2 in zip(values[field1], values[field2]):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1 and field2 have the same shapes for each corresponding array.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n        for arr1, arr2 in zip(values[field1], values[field2]):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1.shape equals field2.shape for all corresponding pairs of arrays.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n        for arr1, arr2 in zip(values[field1], values[field2]):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1 and field2 have the same shapes.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch.\")\n\n        for arr1, arr2 in zip(values[field1], values[field2]):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1 and field2 arrays have the same shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch.\")\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1}[{i}] and {field2}[{i}] shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1 and field2 have the same shapes.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch.\")\n\n        for arr1, arr2 in zip(values[field1], values[field2]):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch.\")\n        for arr1, arr2 in zip(values[field1], values[field2]):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1 and field2 have arrays with equal shapes.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch.\")\n        for arr1, arr2 in zip(values[field1], values[field2]):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(\n      jnp.log,\n      lambda x, _, x_dot: safe_div(x_dot, jnp.maximum(tiny_val, x)),\n      (tiny_val, max_val),\n  )(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(\n      jnp.log,\n      lambda x, _, x_dot: safe_div(x_dot, jnp.maximum(tiny_val, x)),\n      (tiny_val, max_val),\n  )(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(\n      jnp.log,\n      lambda x, _, x_dot: safe_div(x_dot, jnp.maximum(tiny_val, x)),\n      (tiny_val, max_val),\n  )(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(\n      jnp.log,\n      lambda x, _, x_dot: safe_div(x_dot, jnp.maximum(tiny_val, x)),\n      (tiny_val, max_val),\n  )(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(\n      jnp.log,\n      lambda x, _, x_dot: safe_div(x_dot, jnp.maximum(tiny_val, x)),\n      (tiny_val, max_val),\n  )(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(\n      jnp.log,\n      lambda x, _, x_dot: safe_div(x_dot, jnp.maximum(tiny_val, x)),\n      (tiny_val, max_val),\n  )(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(\n      jnp.log,\n      lambda x, _, x_dot: safe_div(x_dot, jnp.maximum(tiny_val, x)),\n      (tiny_val, max_val),\n  )(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(\n      jnp.log,\n      lambda x, _, x_dot: safe_div(x_dot, jnp.maximum(tiny_val, x)),\n      (tiny_val, max_val),\n  )(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(\n      jnp.log,\n      lambda x, _, x_dot: safe_div(x_dot, jnp.maximum(tiny_val, x)),\n      (tiny_val, max_val),\n  )(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(\n      jnp.log,\n      lambda x, _, x_dot: safe_div(x_dot, jnp.maximum(tiny_val, x)),\n      (tiny_val, max_val),\n  )(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(\n      jnp.log,\n      lambda x, _, x_dot: safe_div(x_dot, jnp.maximum(tiny_val, x)),\n      (tiny_val, max_val),\n  )(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(\n      jnp.log,\n      lambda x, _, x_dot: safe_div(x_dot, jnp.maximum(tiny_val, x)),\n      (tiny_val, max_val),\n  )(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(\n      jnp.log,\n      lambda x, _, x_dot: safe_div(x_dot, jnp.maximum(tiny_val, x)),\n      (tiny_val, max_val),\n  )(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(\n      jnp.log,\n      lambda x, _, x_dot: safe_div(x_dot, jnp.maximum(tiny_val, x)),\n      (tiny_val, max_val),\n  )(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(\n      jnp.log,\n      lambda x, _, x_dot: safe_div(x_dot, jnp.maximum(tiny_val, x)),\n      (tiny_val, max_val),\n  )(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(\n      jnp.log,\n      lambda x, _, x_dot: safe_div(x_dot, jnp.maximum(tiny_val, x)),\n      (tiny_val, max_val),\n  )(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(\n      jnp.log,\n      lambda x, _, x_dot: x_dot / jnp.maximum(tiny_val, x),\n      (tiny_val, max_val),\n  )(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(\n      jnp.log,\n      lambda x, _, x_dot: x_dot / jnp.maximum(tiny_val, x),\n      (tiny_val, max_val),\n  )(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(\n      jnp.log,\n      lambda x, _, x_dot: x_dot / jnp.maximum(tiny_val, x),\n      (tiny_val, max_val),\n  )(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(\n      jnp.log,\n      lambda x, _, x_dot: x_dot / jnp.maximum(tiny_val, x),\n      (tiny_val, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return fake_clip(jnp.sqrt(fake_clip(x, 0, max_val)), 0, max_val)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, _, x_dot: 0.5 * x_dot / jnp.maximum(1e-5, jnp.sqrt(x)),\n      (0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, _, x_dot: 0.5 * safe_div(1, jnp.sqrt(x)) * x_dot,\n      (0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return fake_clip(jnp.sqrt(x), 0, max_val)"}
{"namespace": "math.safe_sqrt", "completion": "  return fake_clip(jnp.sqrt(x), 0, max_val)"}
{"namespace": "math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.clip(x, 0, max_val))"}
{"namespace": "math.safe_sqrt", "completion": "  return fake_clip(jnp.sqrt(jnp.maximum(0, x)), 0, max_val)"}
{"namespace": "math.safe_sqrt", "completion": "  return fake_clip(jnp.sqrt(jnp.maximum(0, x)), 0, max_val)"}
{"namespace": "math.safe_sqrt", "completion": "  return fake_clip(jnp.sqrt(x), 0, max_val)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, _, x_dot: 0.5 * x_dot / jnp.maximum(jnp.sqrt(x), tiny_val),\n      (0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return fake_clip(jnp.sqrt(x), 0, max_val)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, _, x_dot: 0.5 * x_dot / jnp.maximum(tiny_val, jnp.sqrt(x)),\n      (0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * safe_div(1, jnp.sqrt(x)) * x_dot,\n      (0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, _, x_dot: 0.5 * x_dot / jnp.sqrt(x),\n      (0, max_val),  # Assuming max_val is defined somewhere in the code\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, _, x_dot: 0.5 * x_dot / jnp.sqrt(x),\n      (0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return fake_clip(jnp.sqrt(fake_clip(x, 0, max_val)), 0, max_val)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, _, x_dot: 0.5 * safe_div(1, jnp.sqrt(x)) * x_dot,\n      (0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * safe_div(y, x),\n      (0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.clip(x, 0, max_val))"}
{"namespace": "math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.clip(x, 0, max_val))"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return max_val\n  elif p == 0:\n    return 1.0\n  elif p == -jnp.inf:\n    return 0.0\n  elif p == jnp.inf:\n    return max_val\n  else:\n    return (max_val / jnp.abs(p - 1))**p"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return 1\n  elif p == 0:\n    return 1\n  elif p == -jnp.inf:\n    return 0\n  elif p == jnp.inf:\n    return jnp.inf\n  else:\n    return jnp.inf"}
{"namespace": "math.power_ladder_max_output", "completion": "  p_safe = clip_finite_nograd(remove_zero(p))\n  if p == 1:\n    return max_val\n  elif p == 0:\n    return 0\n  elif p == -jnp.inf:\n    return 0\n  elif p == jnp.inf:\n    return max_val\n  else:\n    return (jnp.abs(p_safe - 1) / p_safe) * (jnp.inf ** p_safe - 1)"}
{"namespace": "math.power_ladder_max_output", "completion": "  return jnp.where(\n      p == 1, jnp.inf,\n      jnp.where(\n          p == 0, 1,\n          jnp.where(\n              p == -jnp.inf, -1,\n              jnp.where(\n                  p == jnp.inf, jnp.inf,\n                  jnp.nan\n              )\n          )\n      )\n  )"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return 1.0\n  elif p == 0:\n    return 0.0\n  elif p == -np.inf:\n    return -1.0\n  elif p == np.inf:\n    return 1.0\n  else:\n    return np.nan"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return 1.0\n  elif p == 0:\n    return 0.0\n  elif p == -np.inf:\n    return -1.0\n  elif p == np.inf:\n    return 1.0\n  else:\n    return np.inf"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return 1.0\n  elif p == 0:\n    return 0.0\n  elif p == -jnp.inf:\n    return -1.0\n  elif p == jnp.inf:\n    return 1.0\n  else:\n    return jnp.sign(p) * jnp.inf"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return 1.0\n  elif p == 0:\n    return 0.0\n  elif p == -jnp.inf:\n    return -1.0\n  elif p == jnp.inf:\n    return 1.0\n  else:\n    return jnp.inf"}
{"namespace": "math.power_ladder_max_output", "completion": "  p_safe = clip_finite_nograd(remove_zero(p))\n  return jnp.where(\n      p == 1, jnp.inf,\n      jnp.where(p == -jnp.inf, 0,\n                jnp.where(p > 1, jnp.inf, -jnp.inf))\n  )"}
{"namespace": "math.power_ladder_max_output", "completion": "  p_safe = clip_finite_nograd(remove_zero(p))\n  return jnp.where(\n      p == 1, jnp.inf,\n      jnp.where(p == 0, 1,\n                jnp.where(p == -jnp.inf, 0,\n                          jnp.where(p == jnp.inf, jnp.inf,\n                                    (jnp.abs(p_safe - 1) / p_safe) + 1)\n                )\n      )\n  )"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return 1\n  elif p == 0:\n    return 0\n  elif p == -jnp.inf:\n    return -1\n  elif p == jnp.inf:\n    return 1\n  else:\n    return jnp.nan"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return 1\n  elif p == 0:\n    return 0\n  elif p == -jnp.inf:\n    return -1\n  elif p == jnp.inf:\n    return 1\n  else:\n    return jnp.nan"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return 1\n  elif p == 0:\n    return 0\n  elif p == -np.inf:\n    return -1\n  elif p == np.inf:\n    return 1\n  else:\n    return (np.abs(p - 1) / p) * ((1 + 1) ** p - 1)"}
{"namespace": "math.power_ladder_max_output", "completion": "  p_safe = clip_finite_nograd(remove_zero(p))\n  return jnp.where(\n      p == 1, jnp.inf,\n      jnp.where(p == 0, 1, jnp.where(p == -jnp.inf, 0, jnp.where(p == jnp.inf, jnp.inf, jnp.nan)))\n  )"}
{"namespace": "math.power_ladder_max_output", "completion": "  p_safe = clip_finite_nograd(remove_zero(p))\n  return jnp.where(\n      p == 1, jnp.inf,\n      jnp.where(p == 0, 1,\n                jnp.where(p == -jnp.inf, 0,\n                          jnp.where(p == jnp.inf, jnp.inf,\n                                    (jnp.abs(p_safe - 1) / p_safe) + 1)\n                          )\n                )\n      )"}
{"namespace": "math.power_ladder_max_output", "completion": "  \"\"\"\n  Calculates the limit of the power_ladder function as its input x approaches infinity, based on the provided power parameter p. It uses conditions to determine the output based on the value of p.\n  Input-Output Arguments\n  :param p: A numeric value representing the power parameter in the power_ladder function. It determines the behavior of the function as x approaches infinity.\n  :return: A numeric value representing the limit of the power_ladder function as x goes to infinity, which varies depending on the value of p.\n  \"\"\"\n  if p == 1:\n    return 1\n  elif p == 0:\n    return 0\n  elif p == -jnp.inf:\n    return -1\n  elif p == jnp.inf:\n    return 1\n  else:\n    return jnp.nan"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return 1\n  elif p == 0:\n    return 0\n  elif p == -np.inf:\n    return -1\n  elif p == np.inf:\n    return 1\n  else:\n    return (np.abs(p - 1) / p) * ((1 + 1) ** p - 1)"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return 1\n  elif p == 0:\n    return 0\n  elif p == -jnp.inf:\n    return -1\n  elif p == jnp.inf:\n    return 1\n  else:\n    return jnp.nan"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return max_val\n  elif p == 0:\n    return 0\n  elif p == -jnp.inf:\n    return -max_val\n  elif p == jnp.inf:\n    return max_val\n  else:\n    return (jnp.abs(p - 1) / p) * (jnp.inf ** p - 1)"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return 1\n  elif p == 0:\n    return 0\n  elif p == -np.inf:\n    return -1\n  elif p == np.inf:\n    return 1\n  else:\n    return (np.abs(p - 1) / p) * ((1 + 1) ** p - 1)"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(f'base_shape {base_shape} must be \"tetrahedron\", \"icosahedron\", or \"octahedron\"')\n\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n      [1, 1, 1],\n      [1, -1, -1],\n      [-1, 1, -1],\n      [-1, -1, 1]\n    ], dtype=np.float32)\n    base_faces = np.array([\n      [0, 1, 2],\n      [0, 1, 3],\n      [0, 2, 3],\n      [1, 2, 3]\n    ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n      [0, 1, phi],\n      [0, -1, phi],\n      [0, 1, -phi],\n      [0, -1, -phi],\n      [1, phi, 0],\n      [-1, phi, 0],\n      [1, -phi, 0],\n      [-1, -phi, 0],\n      [phi, 0, 1],\n      [-phi, 0, 1],\n      [phi, 0, -1],\n      [-phi, 0, -1]\n    ], dtype=np.float32)\n    base_faces = np.array([\n      [0, 1, 4],\n      [0, 1, 6],\n      [0, 4, 8],\n      [0, 6, 8],\n      [0, 4, 9],\n      [0, 6, 10],\n      [0, 1, 9],\n      [0, 1, 10],\n      [1, 4, 8],\n      [1, 6, 8],\n      [1, 4, 9],\n      [1, 6, 10],\n      [4, 8, 9],\n      [6, 8, 10],\n      [9, 10, 1],\n      [9, 10, 0]\n    ], dtype=np.int32)\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n      [1, 0, 0],\n      [-1, 0, 0],\n      [0, 1, 0],\n      [0, -1, 0],\n      [0, 0, 1],\n      [0, 0, -1]\n    ], dtype=np.float32)\n    base_faces = np.array([\n      [0, 2, 4],\n      [0, 3, 4],\n      [0, 2, 5],\n      [0, 3, 5],\n      [1, 2, 4],\n      [1, 3, 4],\n      [1, 2, 5],\n      [1, 3, 5]\n    ], dtype=np.int32)\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    unique_verts = np.unique(np.argwhere(sq_dist <= eps)[:, 0])\n    verts = verts[unique_verts]\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(f'base_shape {base_shape} must be \"tetrahedron\", \"icosahedron\", or \"octahedron\"')\n\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [1, -1, -1],\n        [-1, 1, -1],\n        [-1, -1, 1]\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 1, 3],\n        [0, 2, 3],\n        [1, 2, 3]\n    ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n        [0, 1, phi],\n        [0, -1, phi],\n        [0, 1, -phi],\n        [0, -1, -phi],\n        [1, phi, 0],\n        [-1, phi, 0],\n        [1, -phi, 0],\n        [-1, -phi, 0],\n        [phi, 0, 1],\n        [-phi, 0, 1],\n        [phi, 0, -1],\n        [-phi, 0, -1]\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 8, 4],\n        [0, 4, 6],\n        [0, 6, 9],\n        [0, 9, 2],\n        [0, 2, 8],\n        [1, 10, 3],\n        [1, 3, 11],\n        [1, 11, 7],\n        [1, 7, 5],\n        [1, 5, 10],\n        [2, 9, 5],\n        [2, 5, 7],\n        [2, 7, 11],\n        [2, 11, 8],\n        [2, 8, 0],\n        [3, 10, 4],\n        [3, 4, 8],\n        [3, 8, 11],\n        [3, 11, 5],\n        [3, 5, 9],\n        [4, 10, 6],\n        [6, 10, 5],\n        [6, 5, 9],\n        [6, 9, 7],\n        [6, 7, 11]\n    ], dtype=np.int32)\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0],\n        [0, 0, 1],\n        [0, 0, -1]\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 2, 4],\n        [0, 4, 3],\n        [0, 3, 5],\n        [0, 5, 2],\n        [1, 4, 2],\n        [1, 3, 4],\n        [1, 5, 3],\n        [1, 2, 5]\n    ], dtype=np.int32)\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    unique = np.unique(np.argwhere(sq_dist <= eps)[:, 0])\n    verts = verts[unique, :]\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(f'base_shape {base_shape} must be \"tetrahedron\", \"icosahedron\", or \"octahedron\"')\n\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [1, -1, -1],\n        [-1, 1, -1],\n        [-1, -1, 1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 1, 3],\n        [0, 2, 3],\n        [1, 2, 3],\n    ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n        [-1, phi, 0],\n        [1, phi, 0],\n        [-1, -phi, 0],\n        [1, -phi, 0],\n        [0, -1, phi],\n        [0, 1, phi],\n        [0, -1, -phi],\n        [0, 1, -phi],\n        [phi, 0, -1],\n        [phi, 0, 1],\n        [-phi, 0, -1],\n        [-phi, 0, 1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 11, 5],\n        [0, 5, 1],\n        [0, 1, 7],\n        [0, 7, 10],\n        [0, 10, 11],\n        [1, 5, 9],\n        [5, 11, 4],\n        [11, 10, 2],\n        [10, 7, 6],\n        [7, 1, 8],\n        [3, 9, 4],\n        [3, 4, 2],\n        [3, 2, 6],\n        [3, 6, 8],\n        [3, 8, 9],\n        [4, 9, 5],\n        [2, 4, 11],\n        [6, 2, 10],\n        [8, 6, 7],\n        [9, 8, 1],\n    ], dtype=np.int32)\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0],\n        [0, 0, 1],\n        [0, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 2, 4],\n        [0, 4, 3],\n        [0, 3, 5],\n        [0, 5, 2],\n        [1, 2, 4],\n        [1, 4, 3],\n        [1, 3, 5],\n        [1, 5, 2],\n    ], dtype=np.int32)\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    unique = np.unique(np.argwhere(np.min(sq_dist, axis=0) <= eps))\n    verts = verts[unique, :]\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(\"base_shape must be either 'tetrahedron', 'icosahedron', or 'octahedron'\")\n\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n      [1, 1, 1],\n      [1, -1, -1],\n      [-1, 1, -1],\n      [-1, -1, 1]\n    ], dtype=np.float32)\n    base_faces = np.array([\n      [0, 1, 2],\n      [0, 1, 3],\n      [0, 2, 3],\n      [1, 2, 3]\n    ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    t = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n      [-1, t, 0],\n      [1, t, 0],\n      [-1, -t, 0],\n      [1, -t, 0],\n      [0, -1, t],\n      [0, 1, t],\n      [0, -1, -t],\n      [0, 1, -t],\n      [t, 0, -1],\n      [t, 0, 1],\n      [-t, 0, -1],\n      [-t, 0, 1]\n    ], dtype=np.float32)\n    base_faces = np.array([\n      [0, 11, 5],\n      [0, 5, 1],\n      [0, 1, 7],\n      [0, 7, 10],\n      [0, 10, 11],\n      [1, 5, 9],\n      [5, 11, 4],\n      [11, 10, 2],\n      [10, 7, 6],\n      [7, 1, 8],\n      [3, 9, 4],\n      [3, 4, 2],\n      [3, 2, 6],\n      [3, 6, 8],\n      [3, 8, 9],\n      [4, 9, 5],\n      [2, 4, 11],\n      [6, 2, 10],\n      [8, 6, 7],\n      [9, 8, 1]\n    ], dtype=np.int32)\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n      [1, 0, 0],\n      [-1, 0, 0],\n      [0, 1, 0],\n      [0, -1, 0],\n      [0, 0, 1],\n      [0, 0, -1]\n    ], dtype=np.float32)\n    base_faces = np.array([\n      [0, 2, 4],\n      [0, 4, 3],\n      [0, 3, 5],\n      [0, 5, 2],\n      [1, 2, 4],\n      [1, 4, 3],\n      [1, 3, 5],\n      [1, 5, 2]\n    ], dtype=np.int32)\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    unique = np.unique(np.argwhere(sq_dist <= eps)[:, 0])\n    verts = verts[unique, :]\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(f'base_shape {base_shape} must be \"tetrahedron\", \"icosahedron\", or \"octahedron\"')\n\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [1, -1, -1],\n        [-1, 1, -1],\n        [-1, -1, 1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 2, 1],\n        [0, 1, 3],\n        [0, 3, 2],\n        [1, 2, 3],\n    ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n        [-1, phi, 0],\n        [1, phi, 0],\n        [-1, -phi, 0],\n        [1, -phi, 0],\n        [0, -1, phi],\n        [0, 1, phi],\n        [0, -1, -phi],\n        [0, 1, -phi],\n        [phi, 0, -1],\n        [phi, 0, 1],\n        [-phi, 0, -1],\n        [-phi, 0, 1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 11, 5],\n        [0, 5, 1],\n        [0, 1, 7],\n        [0, 7, 10],\n        [0, 10, 11],\n        [1, 5, 9],\n        [5, 11, 4],\n        [11, 10, 2],\n        [10, 7, 6],\n        [7, 1, 8],\n        [3, 9, 4],\n        [3, 4, 2],\n        [3, 2, 6],\n        [3, 6, 8],\n        [3, 8, 9],\n        [4, 9, 5],\n        [2, 4, 11],\n        [6, 2, 10],\n        [8, 6, 7],\n        [9, 8, 1],\n    ], dtype=np.int32)\n  else:  # base_shape == 'octahedron'\n    base_verts = np.array([\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0],\n        [0, 0, 1],\n        [0, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 2, 4],\n        [0, 4, 3],\n        [0, 3, 5],\n        [0, 5, 2],\n        [1, 2, 4],\n        [1, 4, 3],\n        [1, 3, 5],\n        [1, 5, 2],\n    ], dtype=np.int32)\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    unique = np.unique(np.argwhere(sq_dist <= eps)[:, 0])\n    verts = verts[unique, :]\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(f'base_shape {base_shape} must be \"tetrahedron\", \"icosahedron\", or \"octahedron\"')\n\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [-1, -1, 1],\n        [-1, 1, -1],\n        [1, -1, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 2, 3],\n        [0, 3, 1],\n        [1, 3, 2],\n    ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n        [0, 1, phi],\n        [0, -1, phi],\n        [0, 1, -phi],\n        [0, -1, -phi],\n        [1, phi, 0],\n        [-1, phi, 0],\n        [1, -phi, 0],\n        [-1, -phi, 0],\n        [phi, 0, 1],\n        [-phi, 0, 1],\n        [phi, 0, -1],\n        [-phi, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 4],\n        [0, 4, 8],\n        [0, 8, 9],\n        [0, 9, 5],\n        [0, 5, 1],\n        [1, 5, 7],\n        [1, 7, 4],\n        [4, 7, 11],\n        [4, 11, 8],\n        [8, 11, 10],\n        [8, 10, 9],\n        [9, 10, 6],\n        [9, 6, 5],\n        [5, 6, 7],\n        [7, 6, 3],\n        [7, 3, 11],\n        [11, 3, 10],\n        [10, 3, 2],\n        [10, 2, 6],\n        [6, 2, 3],\n    ], dtype=np.int32)\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0],\n        [0, 0, 1],\n        [0, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 2, 4],\n        [0, 4, 3],\n        [0, 3, 5],\n        [0, 5, 2],\n        [1, 2, 5],\n        [1, 5, 3],\n        [1, 3, 4],\n        [1, 4, 2],\n    ], dtype=np.int32)\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    assignment = np.array([np.min(np.argwhere(d <= eps)) for d in sq_dist])\n    unique = np.unique(assignment)\n    verts = verts[unique, :]\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(f'base_shape {base_shape} must be \"tetrahedron\", \"icosahedron\", or \"octahedron\"')\n\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [1, -1, -1],\n        [-1, 1, -1],\n        [-1, -1, 1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 1, 3],\n        [0, 2, 3],\n        [1, 2, 3],\n    ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n        [-1, phi, 0],\n        [1, phi, 0],\n        [-1, -phi, 0],\n        [1, -phi, 0],\n        [0, -1, phi],\n        [0, 1, phi],\n        [0, -1, -phi],\n        [0, 1, -phi],\n        [phi, 0, -1],\n        [phi, 0, 1],\n        [-phi, 0, -1],\n        [-phi, 0, 1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 11, 5],\n        [0, 5, 1],\n        [0, 1, 7],\n        [0, 7, 10],\n        [0, 10, 11],\n        [1, 5, 9],\n        [5, 11, 4],\n        [11, 10, 2],\n        [10, 7, 6],\n        [7, 1, 8],\n        [3, 9, 4],\n        [3, 4, 2],\n        [3, 2, 6],\n        [3, 6, 8],\n        [3, 8, 9],\n        [4, 9, 5],\n        [2, 4, 11],\n        [6, 2, 10],\n        [8, 6, 7],\n        [9, 8, 1],\n    ], dtype=np.int32)\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0],\n        [0, 0, 1],\n        [0, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 2, 4],\n        [0, 4, 3],\n        [0, 3, 5],\n        [0, 5, 2],\n        [1, 2, 4],\n        [1, 4, 3],\n        [1, 3, 5],\n        [1, 5, 2],\n    ], dtype=np.int32)\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    unique = np.unique(np.argwhere(sq_dist < eps)[:, 0])\n    verts = verts[unique, :]\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [1, -1, -1],\n        [-1, 1, -1],\n        [-1, -1, 1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 1, 3],\n        [0, 2, 3],\n        [1, 2, 3],\n    ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n        [0, 1, phi],\n        [0, -1, phi],\n        [0, 1, -phi],\n        [0, -1, -phi],\n        [1, phi, 0],\n        [-1, phi, 0],\n        [1, -phi, 0],\n        [-1, -phi, 0],\n        [phi, 0, 1],\n        [-phi, 0, 1],\n        [phi, 0, -1],\n        [-phi, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 4],\n        [0, 1, 5],\n        [0, 4, 8],\n        [0, 5, 8],\n        [0, 4, 9],\n        [0, 5, 10],\n        [1, 4, 9],\n        [1, 5, 10],\n        [1, 6, 8],\n        [1, 7, 10],\n        [1, 6, 9],\n        [1, 7, 10],\n        [2, 3, 6],\n        [2, 3, 7],\n        [2, 6, 8],\n        [2, 7, 8],\n        [2, 6, 9],\n        [2, 7, 10],\n        [3, 6, 9],\n        [3, 7, 10],\n        [3, 4, 8],\n        [3, 5, 8],\n        [3, 4, 9],\n        [3, 5, 10],\n    ], dtype=np.int32)\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0],\n        [0, 0, 1],\n        [0, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 2, 4],\n        [0, 3, 4],\n        [0, 2, 5],\n        [0, 3, 5],\n        [1, 2, 4],\n        [1, 3, 4],\n        [1, 2, 5],\n        [1, 3, 5],\n    ], dtype=np.int32)\n  else:\n    raise ValueError(f'base_shape {base_shape} is not supported')\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    assignment = np.array([np.min(np.argwhere(d <= eps)) for d in sq_dist])\n    unique = np.unique(assignment)\n    verts = verts[unique, :]\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError('base_shape must be either \"tetrahedron\", \"icosahedron\", or \"octahedron\"')\n\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [1, -1, -1],\n        [-1, 1, -1],\n        [-1, -1, 1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 1, 3],\n        [0, 2, 3],\n        [1, 2, 3],\n    ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n        [0, 1, phi],\n        [0, -1, phi],\n        [0, 1, -phi],\n        [0, -1, -phi],\n        [1, phi, 0],\n        [-1, phi, 0],\n        [1, -phi, 0],\n        [-1, -phi, 0],\n        [phi, 0, 1],\n        [-phi, 0, 1],\n        [phi, 0, -1],\n        [-phi, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 4],\n        [0, 1, 5],\n        [0, 4, 8],\n        [0, 5, 8],\n        [0, 4, 9],\n        [0, 5, 10],\n        [1, 4, 9],\n        [1, 5, 10],\n        [1, 2, 6],\n        [1, 2, 7],\n        [1, 6, 9],\n        [1, 7, 10],\n        [2, 6, 11],\n        [2, 7, 11],\n        [2, 6, 8],\n        [2, 7, 8],\n        [2, 8, 9],\n        [2, 8, 10],\n        [3, 6, 11],\n        [3, 7, 11],\n        [3, 6, 8],\n        [3, 7, 8],\n        [3, 8, 9],\n        [3, 8, 10],\n    ], dtype=np.int32)\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0],\n        [0, 0, 1],\n        [0, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 2, 4],\n        [0, 3, 4],\n        [0, 2, 5],\n        [0, 3, 5],\n        [1, 2, 4],\n        [1, 3, 4],\n        [1, 2, 5],\n        [1, 3, 5],\n    ], dtype=np.int32)\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    symmetric_pairs = np.argwhere(sq_dist <= eps)\n    unique_pairs = np.unique(symmetric_pairs)\n    unique_verts = verts[unique_pairs]\n    return unique_verts.T\n  else:\n    return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError('base_shape must be either tetrahedron, icosahedron, or octahedron')\n\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1.0, 1.0, 1.0],\n        [1.0, -1.0, -1.0],\n        [-1.0, 1.0, -1.0],\n        [-1.0, -1.0, 1.0]\n    ])\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 1, 3],\n        [0, 2, 3],\n        [1, 2, 3]\n    ])\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n        [0, 1, phi],\n        [0, -1, phi],\n        [0, 1, -phi],\n        [0, -1, -phi],\n        [1, phi, 0],\n        [-1, phi, 0],\n        [1, -phi, 0],\n        [-1, -phi, 0],\n        [phi, 0, 1],\n        [-phi, 0, 1],\n        [phi, 0, -1],\n        [-phi, 0, -1]\n    ])\n    base_faces = np.array([\n        [0, 1, 8],\n        [0, 1, 10],\n        [0, 5, 8],\n        [0, 5, 6],\n        [0, 6, 10],\n        [1, 7, 8],\n        [1, 7, 10],\n        [1, 8, 9],\n        [2, 3, 11],\n        [2, 3, 4],\n        [2, 4, 9],\n        [2, 4, 5],\n        [2, 5, 6],\n        [3, 7, 10],\n        [3, 7, 11],\n        [3, 9, 11],\n        [4, 5, 8],\n        [4, 5, 9],\n        [6, 8, 10],\n        [7, 9, 11]\n    ])\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0],\n        [0, 0, 1],\n        [0, 0, -1]\n    ])\n    base_faces = np.array([\n        [0, 2, 4],\n        [0, 2, 5],\n        [0, 3, 4],\n        [0, 3, 5],\n        [1, 2, 4],\n        [1, 2, 5],\n        [1, 3, 4],\n        [1, 3, 5]\n    ])\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    unique = np.unique(np.argwhere(sq_dist <= eps)[:, 0])\n    verts = verts[unique, :]\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(f'base_shape {base_shape} must be \"tetrahedron\", \"icosahedron\", or \"octahedron\"')\n\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [1, -1, -1],\n        [-1, 1, -1],\n        [-1, -1, 1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 2, 1],\n        [0, 1, 3],\n        [0, 3, 2],\n        [1, 2, 3],\n    ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    base_verts = np.array([\n        [0, 1, PHI],\n        [0, -1, PHI],\n        [0, 1, -PHI],\n        [0, -1, -PHI],\n        [1, PHI, 0],\n        [-1, PHI, 0],\n        [1, -PHI, 0],\n        [-1, -PHI, 0],\n        [PHI, 0, 1],\n        [-PHI, 0, 1],\n        [PHI, 0, -1],\n        [-PHI, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 8, 4],\n        [0, 4, 2],\n        [0, 2, 6],\n        [0, 6, 9],\n        [0, 9, 8],\n        [1, 3, 5],\n        [1, 5, 11],\n        [1, 11, 7],\n        [1, 7, 10],\n        [1, 10, 3],\n        [2, 4, 8],\n        [2, 8, 6],\n        [3, 10, 7],\n        [3, 7, 5],\n        [4, 10, 2],\n        [5, 7, 11],\n        [6, 8, 9],\n        [9, 11, 8],\n        [9, 6, 11],\n        [10, 4, 3],\n    ], dtype=np.int32)\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0],\n        [0, 0, 1],\n        [0, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 2, 4],\n        [0, 4, 3],\n        [0, 3, 5],\n        [0, 5, 2],\n        [1, 4, 2],\n        [1, 3, 4],\n        [1, 5, 3],\n        [1, 2, 5],\n    ], dtype=np.int32)\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    unique = np.unique(np.argwhere(sq_dist <= eps)[:, 1])\n    verts = verts[unique, :]\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(\"base_shape must be 'tetrahedron', 'icosahedron', or 'octahedron'\")\n\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [1, -1, -1],\n        [-1, 1, -1],\n        [-1, -1, 1]\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 1, 3],\n        [0, 2, 3],\n        [1, 2, 3]\n    ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    # Define icosahedron vertices and faces\n    # ...\n    # Define icosahedron vertices and faces\n    # ...\n  elif base_shape == 'octahedron':\n    # Define octahedron vertices and faces\n    # ...\n    # Define octahedron vertices and faces\n    # ...\n\n  # Tessellate the base polyhedron\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    # Remove symmetric basis columns\n    # ...\n    # Remove symmetric basis columns\n    # ...\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(f'base_shape {base_shape} must be \"tetrahedron\", \"icosahedron\", or \"octahedron\"')\n\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [1, -1, -1],\n        [-1, 1, -1],\n        [-1, -1, 1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 1, 3],\n        [0, 2, 3],\n        [1, 2, 3],\n    ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n        [-1, phi, 0],\n        [1, phi, 0],\n        [-1, -phi, 0],\n        [1, -phi, 0],\n        [0, -1, phi],\n        [0, 1, phi],\n        [0, -1, -phi],\n        [0, 1, -phi],\n        [phi, 0, -1],\n        [phi, 0, 1],\n        [-phi, 0, -1],\n        [-phi, 0, 1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 11, 5],\n        [0, 5, 1],\n        [0, 1, 7],\n        [0, 7, 10],\n        [0, 10, 11],\n        [1, 5, 9],\n        [5, 11, 4],\n        [11, 10, 2],\n        [10, 7, 6],\n        [7, 1, 8],\n        [3, 9, 4],\n        [3, 4, 2],\n        [3, 2, 6],\n        [3, 6, 8],\n        [3, 8, 9],\n        [4, 9, 5],\n        [2, 4, 11],\n        [6, 2, 10],\n        [8, 6, 7],\n        [9, 8, 1],\n    ], dtype=np.int32)\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0],\n        [0, 0, 1],\n        [0, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 2, 4],\n        [0, 4, 3],\n        [0, 3, 5],\n        [0, 5, 2],\n        [1, 2, 4],\n        [1, 4, 3],\n        [1, 3, 5],\n        [1, 5, 2],\n    ], dtype=np.int32)\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    unique = np.unique(np.argwhere(sq_dist <= eps)[:, 0])\n    verts = verts[unique, :]\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(f'base_shape {base_shape} must be \"tetrahedron\", \"icosahedron\", or \"octahedron\"')\n\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [1, -1, -1],\n        [-1, 1, -1],\n        [-1, -1, 1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 1, 3],\n        [0, 2, 3],\n        [1, 2, 3],\n    ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n        [0, 1, phi],\n        [0, -1, phi],\n        [0, 1, -phi],\n        [0, -1, -phi],\n        [1, phi, 0],\n        [-1, phi, 0],\n        [1, -phi, 0],\n        [-1, -phi, 0],\n        [phi, 0, 1],\n        [-phi, 0, 1],\n        [phi, 0, -1],\n        [-phi, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 4],\n        [0, 1, 5],\n        [0, 4, 8],\n        [0, 5, 8],\n        [0, 4, 9],\n        [0, 5, 10],\n        [1, 4, 9],\n        [1, 5, 10],\n        [1, 6, 11],\n        [1, 7, 11],\n        [1, 6, 4],\n        [1, 7, 5],\n        [2, 3, 6],\n        [2, 3, 7],\n        [2, 6, 10],\n        [2, 7, 11],\n        [2, 6, 8],\n        [2, 7, 9],\n        [3, 6, 8],\n        [3, 7, 9],\n        [3, 4, 8],\n        [3, 5, 9],\n        [3, 4, 10],\n        [3, 5, 11],\n    ], dtype=np.int32)\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0],\n        [0, 0, 1],\n        [0, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 2, 4],\n        [0, 3, 4],\n        [0, 2, 5],\n        [0, 3, 5],\n        [1, 2, 4],\n        [1, 3, 4],\n        [1, 2, 5],\n        [1, 3, 5],\n    ], dtype=np.int32)\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    unique = np.unique(np.argwhere(sq_dist <= eps)[:, 0])\n    verts = verts[unique, :]\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(\"base_shape must be 'tetrahedron', 'icosahedron', or 'octahedron'\")\n\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [1, -1, -1],\n        [-1, 1, -1],\n        [-1, -1, 1]\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 1, 3],\n        [0, 2, 3],\n        [1, 2, 3]\n    ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n        [-1, phi, 0],\n        [1, phi, 0],\n        [-1, -phi, 0],\n        [1, -phi, 0],\n        [0, -1, phi],\n        [0, 1, phi],\n        [0, -1, -phi],\n        [0, 1, -phi],\n        [phi, 0, -1],\n        [phi, 0, 1],\n        [-phi, 0, -1],\n        [-phi, 0, 1]\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 11, 5],\n        [0, 5, 1],\n        [0, 1, 7],\n        [0, 7, 10],\n        [0, 10, 11],\n        [1, 5, 9],\n        [5, 11, 4],\n        [11, 10, 2],\n        [10, 7, 6],\n        [7, 1, 8],\n        [3, 9, 4],\n        [3, 4, 2],\n        [3, 2, 6],\n        [3, 6, 8],\n        [3, 8, 9],\n        [4, 9, 5],\n        [2, 4, 11],\n        [6, 2, 10],\n        [8, 6, 7],\n        [9, 8, 1]\n    ], dtype=np.int32)\n  else:  # base_shape == 'octahedron'\n    base_verts = np.array([\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0],\n        [0, 0, 1],\n        [0, 0, -1]\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 2, 4],\n        [0, 4, 3],\n        [0, 3, 5],\n        [0, 5, 2],\n        [1, 2, 4],\n        [1, 4, 3],\n        [1, 3, 5],\n        [1, 5, 2]\n    ], dtype=np.int32)\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    unique = np.unique(np.argwhere(sq_dist <= eps)[:, 0])\n    verts = verts[unique, :]\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(f'base_shape {base_shape} must be \"tetrahedron\", \"icosahedron\", or \"octahedron\"')\n\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [1, -1, -1],\n        [-1, 1, -1],\n        [-1, -1, 1]\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 1, 3],\n        [0, 2, 3],\n        [1, 2, 3]\n    ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n        [-1, phi, 0],\n        [1, phi, 0],\n        [-1, -phi, 0],\n        [1, -phi, 0],\n        [0, -1, phi],\n        [0, 1, phi],\n        [0, -1, -phi],\n        [0, 1, -phi],\n        [phi, 0, -1],\n        [phi, 0, 1],\n        [-phi, 0, -1],\n        [-phi, 0, 1]\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 11, 5],\n        [0, 5, 1],\n        [0, 1, 7],\n        [0, 7, 10],\n        [0, 10, 11],\n        [1, 5, 9],\n        [5, 11, 4],\n        [11, 10, 2],\n        [10, 7, 6],\n        [7, 1, 8],\n        [3, 9, 4],\n        [3, 4, 2],\n        [3, 2, 6],\n        [3, 6, 8],\n        [3, 8, 9],\n        [4, 9, 5],\n        [2, 4, 11],\n        [6, 2, 10],\n        [8, 6, 7],\n        [9, 8, 1]\n    ], dtype=np.int32)\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0],\n        [0, 0, 1],\n        [0, 0, -1]\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 2, 4],\n        [0, 4, 3],\n        [0, 3, 5],\n        [0, 5, 2],\n        [1, 2, 4],\n        [1, 4, 3],\n        [1, 3, 5],\n        [1, 5, 2]\n    ], dtype=np.int32)\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    unique = np.unique(np.argwhere(sq_dist <= eps)[:, 1])\n    verts = verts[unique, :]\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(f'base_shape {base_shape} must be \"tetrahedron\", \"icosahedron\", or \"octahedron\"')\n\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [1, -1, -1],\n        [-1, 1, -1],\n        [-1, -1, 1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 1, 3],\n        [0, 2, 3],\n        [1, 2, 3],\n    ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n        [0, 1, phi],\n        [0, -1, phi],\n        [0, 1, -phi],\n        [0, -1, -phi],\n        [1, phi, 0],\n        [-1, phi, 0],\n        [1, -phi, 0],\n        [-1, -phi, 0],\n        [phi, 0, 1],\n        [-phi, 0, 1],\n        [phi, 0, -1],\n        [-phi, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 4],\n        [0, 1, 5],\n        [0, 4, 8],\n        [0, 5, 9],\n        [0, 8, 9],\n        [1, 4, 6],\n        [1, 6, 10],\n        [1, 5, 7],\n        [1, 7, 11],\n        [2, 3, 8],\n        [2, 3, 9],\n        [2, 8, 10],\n        [2, 9, 11],\n        [2, 10, 11],\n        [3, 8, 9],\n        [3, 9, 11],\n        [3, 8, 10],\n        [3, 10, 11],\n        [4, 6, 8],\n        [4, 6, 10],\n        [5, 7, 9],\n        [5, 7, 11],\n        [6, 8, 10],\n        [7, 9, 11],\n    ], dtype=np.int32)\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0],\n        [0, 0, 1],\n        [0, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 2, 4],\n        [0, 3, 4],\n        [0, 2, 5],\n        [0, 3, 5],\n        [1, 2, 4],\n        [1, 3, 4],\n        [1, 2, 5],\n        [1, 3, 5],\n    ], dtype=np.int32)\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    unique = np.unique([np.min(np.argwhere(d <= eps)) for d in sq_dist])\n    verts = verts[unique, :]\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(\"base_shape must be either 'tetrahedron', 'icosahedron', or 'octahedron'\")\n  \n  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [1, -1, -1],\n        [-1, 1, -1],\n        [-1, -1, 1]\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 1, 3],\n        [0, 2, 3],\n        [1, 2, 3]\n    ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    base_verts = np.array([\n        [0, 1, phi],\n        [0, -1, phi],\n        [0, 1, -phi],\n        [0, -1, -phi],\n        [1, phi, 0],\n        [-1, phi, 0],\n        [1, -phi, 0],\n        [-1, -phi, 0],\n        [phi, 0, 1],\n        [-phi, 0, 1],\n        [phi, 0, -1],\n        [-phi, 0, -1]\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 4],\n        [0, 1, 6],\n        [0, 4, 8],\n        [0, 6, 8],\n        [0, 4, 9],\n        [0, 6, 10],\n        [1, 4, 9],\n        [1, 6, 10],\n        [1, 4, 5],\n        [1, 6, 7],\n        [1, 5, 7],\n        [1, 7, 11],\n        [2, 3, 5],\n        [2, 3, 7],\n        [2, 5, 11],\n        [2, 7, 11],\n        [2, 3, 8],\n        [2, 5, 10],\n        [3, 8, 9],\n        [3, 7, 11],\n        [3, 9, 10],\n        [3, 10, 11],\n        [4, 5, 9],\n        [5, 9, 10],\n        [6, 7, 10],\n        [7, 10, 11],\n        [8, 9, 10],\n        [8, 10, 11]\n    ], dtype=np.int32)\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0],\n        [0, 0, 1],\n        [0, 0, -1]\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 2, 4],\n        [0, 3, 4],\n        [0, 2, 5],\n        [0, 3, 5],\n        [1, 2, 4],\n        [1, 3, 4],\n        [1, 2, 5],\n        [1, 3, 5]\n    ], dtype=np.int32)\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    assignment = np.array([np.min(np.argwhere(d <= eps)) for d in sq_dist])\n    unique = np.unique(assignment)\n    verts = verts[unique, :]\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(f'base_shape {base_shape} must be \"tetrahedron\", \"icosahedron\", or \"octahedron\"')\n\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [1, -1, -1],\n        [-1, 1, -1],\n        [-1, -1, 1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 1, 3],\n        [0, 2, 3],\n        [1, 2, 3],\n    ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n        [0, 1, phi],\n        [0, -1, phi],\n        [0, 1, -phi],\n        [0, -1, -phi],\n        [1, phi, 0],\n        [-1, phi, 0],\n        [1, -phi, 0],\n        [-1, -phi, 0],\n        [phi, 0, 1],\n        [-phi, 0, 1],\n        [phi, 0, -1],\n        [-phi, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 4],\n        [0, 1, 5],\n        [0, 4, 8],\n        [0, 5, 8],\n        [0, 4, 9],\n        [0, 5, 10],\n        [1, 4, 6],\n        [1, 5, 7],\n        [1, 6, 9],\n        [1, 7, 10],\n        [2, 3, 8],\n        [2, 3, 9],\n        [2, 8, 6],\n        [2, 9, 7],\n        [2, 6, 10],\n        [2, 7, 10],\n        [3, 8, 4],\n        [3, 9, 5],\n        [3, 4, 6],\n        [3, 5, 7],\n    ], dtype=np.int32)\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0],\n        [0, 0, 1],\n        [0, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 2, 4],\n        [0, 3, 4],\n        [0, 2, 5],\n        [0, 3, 5],\n        [1, 2, 4],\n        [1, 3, 4],\n        [1, 2, 5],\n        [1, 3, 5],\n    ], dtype=np.int32)\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    assignment = np.array([np.min(np.argwhere(d <= eps)) for d in sq_dist])\n    unique = np.unique(assignment)\n    verts = verts[unique, :]\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(f'base_shape {base_shape} must be \"tetrahedron\", \"icosahedron\", or \"octahedron\"')\n\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [1, -1, -1],\n        [-1, 1, -1],\n        [-1, -1, 1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 2, 3],\n        [0, 3, 1],\n        [1, 3, 2],\n    ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n        [0, 1, phi],\n        [0, -1, phi],\n        [0, 1, -phi],\n        [0, -1, -phi],\n        [1, phi, 0],\n        [-1, phi, 0],\n        [1, -phi, 0],\n        [-1, -phi, 0],\n        [phi, 0, 1],\n        [-phi, 0, 1],\n        [phi, 0, -1],\n        [-phi, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 4],\n        [0, 4, 8],\n        [0, 8, 9],\n        [0, 9, 6],\n        [0, 6, 1],\n        [1, 6, 10],\n        [1, 10, 11],\n        [1, 11, 4],\n        [2, 3, 5],\n        [2, 5, 7],\n        [2, 7, 8],\n        [2, 8, 4],\n        [2, 4, 11],\n        [2, 11, 3],\n        [3, 11, 10],\n        [3, 10, 9],\n        [3, 9, 5],\n        [3, 5, 7],\n        [3, 7, 6],\n        [3, 6, 10],\n    ], dtype=np.int32)\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0],\n        [0, 0, 1],\n        [0, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 2, 4],\n        [0, 4, 3],\n        [0, 3, 5],\n        [0, 5, 2],\n        [1, 4, 2],\n        [1, 3, 4],\n        [1, 5, 3],\n        [1, 2, 5],\n    ], dtype=np.int32)\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    unique = np.unique(np.argwhere(sq_dist <= eps)[:, 1])\n    verts = verts[unique, :]\n\n  return verts.T"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1, max_val - 1),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1, max_val - 1),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1, max_val - 1),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1, max_val - 1),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1, max_val - 1),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1, max_val - 1),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1, max_val - 1),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1, max_val - 1),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1, max_val - 1),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1, max_val - 1),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1, max_val - 1),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1, max_val - 1),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1.0, max_val - 1.0),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1, max_val - 1),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1, max_val - 1),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1, max_val - 1),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1.0, max_val - 1.0),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1.0, max_val - 1.0),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1, max_val - 1),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1, max_val - 1),\n  )(x)"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x *= premult\n\n  xp = jnp.abs(x)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  y_max = minus_eps(power_ladder_max_output(p))\n  xp = override_gradient(jnp.clip(xp, -y_max, y_max), xp)  # Clip val, not grad.\n\n  x_transformed = safe_sign(x) * select(\n      [\n          (p == 1, xp),\n          (p == 0, safe_expm1(xp)),\n          (p == -jnp.inf, -safe_log1p(-xp)),\n          (p == jnp.inf, safe_log1p(xp)),\n      ],\n      jnp.abs(p_safe - 1)\n      * (\n          ((safe_div(p_safe, jnp.abs(p_safe - 1)) * xp + 1)) ** (1 / p_safe) - 1\n      ),\n  )\n\n  if postmult is not None:\n    x_transformed *= postmult\n\n  return x_transformed"}
{"namespace": "math.power_ladder", "completion": "\n  if premult is not None:\n    x *= premult\n\n  xp = jnp.abs(x)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  y_max = minus_eps(power_ladder_max_output(p))\n  xp = override_gradient(jnp.clip(xp, -y_max, y_max), xp)  # Clip val, not grad.\n\n  x_transformed = safe_sign(x) * select(\n      [\n          (p == 1, xp),\n          (p == 0, safe_expm1(xp)),\n          (p == -jnp.inf, -safe_log1p(-xp)),\n          (p == jnp.inf, safe_log1p(xp)),\n      ],\n      jnp.abs(p_safe - 1)\n      * (\n          ((safe_div(p_safe, jnp.abs(p_safe - 1)) * xp + 1)) ** (1 / p_safe) - 1\n      ),\n  )\n\n  if postmult is not None:\n    x_transformed *= postmult\n\n  return x_transformed"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x *= premult\n  xp = jnp.abs(x)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x_max = minus_eps(power_ladder_max_output(p))\n  xp = override_gradient(jnp.clip(xp, -x_max, x_max), xp)  # Clip val, not grad.\n  y = safe_sign(x) * select(\n      [\n          (p == 1, xp),\n          (p == 0, safe_exp(xp) - 1),\n          (p == -jnp.inf, -safe_expm1(-xp)),\n          (p == jnp.inf, safe_expm1(xp)),\n      ],\n      jnp.abs(p_safe - 1)\n      * (\n          ((safe_div(p_safe, jnp.abs(p_safe - 1)) * xp + 1)) ** p_safe - 1\n      ),\n  )\n  if postmult is not None:\n    y *= postmult\n  return y"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x *= premult\n\n  xp = jnp.abs(x)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  y_max = minus_eps(power_ladder_max_output(p))\n  xp = override_gradient(jnp.clip(xp, -y_max, y_max), xp)  # Clip val, not grad.\n  y = safe_sign(x) * select(\n      [\n          (p == 1, xp),\n          (p == 0, safe_expm1(xp)),\n          (p == -jnp.inf, -safe_log1p(-xp)),\n          (p == jnp.inf, safe_log1p(xp)),\n      ],\n      jnp.abs(p_safe - 1)\n      * (\n          ((safe_div(p_safe, jnp.abs(p_safe - 1)) * xp + 1)) ** (1 / p_safe) - 1\n      ),\n  )\n\n  if postmult is not None:\n    y *= postmult\n\n  return y"}
{"namespace": "math.power_ladder", "completion": "\n  if premult is not None:\n    x *= premult\n\n  xp = jnp.abs(x)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  y_max = minus_eps(power_ladder_max_output(p))\n  xp = override_gradient(jnp.clip(xp, -y_max, y_max), xp)  # Clip val, not grad.\n\n  x_transformed = safe_sign(x) * select(\n      [\n          (p == 1, xp),\n          (p == 0, safe_expm1(xp)),\n          (p == -jnp.inf, -safe_log1p(-xp)),\n          (p == jnp.inf, safe_log1p(xp)),\n      ],\n      jnp.abs(p_safe - 1)\n      * (\n          ((safe_div(p_safe, jnp.abs(p_safe - 1)) * xp + 1)) ** (1 / p_safe) - 1\n      ),\n  )\n\n  if postmult is not None:\n    x_transformed *= postmult\n\n  return x_transformed"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x *= premult\n  xp = jnp.abs(x)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x_max = minus_eps(power_ladder_max_output(p))\n  xp = override_gradient(jnp.clip(xp, -x_max, x_max), xp)  # Clip val, not grad.\n  y = safe_sign(x) * select(\n      [\n          (p == 1, xp),\n          (p == 0, safe_exp(xp) - 1),\n          (p == -jnp.inf, safe_log1p(xp)),\n          (p == jnp.inf, safe_expm1(xp)),\n      ],\n      jnp.abs(p_safe - 1)\n      * (\n          ((jnp.abs(p_safe) / jnp.abs(p_safe - 1) * xp + 1)) ** (1 / jnp.abs(p_safe)) - 1\n      ),\n  )\n  if postmult is not None:\n    y *= postmult\n  return y"}
{"namespace": "math.power_ladder", "completion": "\n  if premult is not None:\n    x *= premult\n\n  xp = jnp.abs(x)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  y_max = minus_eps(power_ladder_max_output(p))\n  xp = override_gradient(jnp.clip(xp, -y_max, y_max), xp)  # Clip val, not grad.\n\n  x_transformed = safe_sign(x) * select(\n      [\n          (p == 1, xp),\n          (p == 0, safe_expm1(xp)),\n          (p == -jnp.inf, -safe_log1p(-xp)),\n          (p == jnp.inf, safe_log1p(xp)),\n      ],\n      jnp.abs(p_safe - 1)\n      * (\n          ((safe_div(p_safe, jnp.abs(p_safe - 1)) * xp + 1)) ** (1 / p_safe) - 1\n      ),\n  )\n\n  if postmult is not None:\n    x_transformed *= postmult\n\n  return x_transformed"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x *= premult\n\n  xp = jnp.abs(x)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x_max = minus_eps(power_ladder_max_output(p))\n  xp = override_gradient(jnp.clip(xp, -x_max, x_max), xp)  # Clip val, not grad.\n\n  result = safe_sign(x) * select(\n      [\n          (p == 1, xp),\n          (p == 0, safe_log1p(xp)),\n          (p == -jnp.inf, safe_expm1(-xp)),\n          (p == jnp.inf, safe_expm1(xp)),\n      ],\n      jnp.abs(p_safe - 1)\n      * (\n          ((safe_div(p_safe, jnp.abs(p_safe - 1)) * xp + 1)) ** (1 / p_safe) - 1\n      ),\n  )\n\n  if postmult is not None:\n    result *= postmult\n\n  return result"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x *= premult\n  xp = jnp.abs(x)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x_max = minus_eps(power_ladder_max_output(p))\n  xp = override_gradient(jnp.clip(xp, -x_max, x_max), xp)  # Clip val, not grad.\n  y = safe_sign(x) * select(\n      [\n          (p == 1, xp),\n          (p == 0, safe_expm1(xp)),\n          (p == -jnp.inf, -safe_log1p(-xp)),\n          (p == jnp.inf, safe_log1p(xp)),\n      ],\n      jnp.abs(p_safe - 1)\n      * (\n          ((safe_div(p_safe, jnp.abs(p_safe - 1)) * xp + 1)) ** (1 / p_safe) - 1\n      ),\n  )\n  if postmult is not None:\n    y *= postmult\n  return y"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x *= premult\n  xp = jnp.abs(x)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  xp_max = minus_eps(power_ladder_max_output(p))\n  xp = override_gradient(jnp.clip(xp, -xp_max, xp_max), xp)  # Clip val, not grad.\n  y = safe_sign(x) * select(\n      [\n          (p == 1, xp),\n          (p == 0, safe_expm1(xp)),\n          (p == -jnp.inf, -safe_log1p(-xp)),\n          (p == jnp.inf, safe_log1p(xp)),\n      ],\n      jnp.abs(p_safe - 1)\n      * (\n          ((safe_div(p_safe, jnp.abs(p_safe - 1)) * xp + 1)) ** (1 / p_safe) - 1\n      ),\n  )\n  if postmult is not None:\n    y *= postmult\n  return y"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x *= premult\n\n  # Handle special cases for p values\n  if p == 1:\n    y = jnp.log1p(x)\n  elif p == 0:\n    y = safe_expm1(x)\n  elif p == -jnp.inf:\n    y = -safe_log1p(-x)\n  elif p == jnp.inf:\n    y = safe_log1p(x)\n  else:\n    y = jnp.sign(x) * (jnp.abs(x) ** p - 1) / p\n\n  if postmult is not None:\n    y *= postmult\n\n  return y"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x *= premult\n  xp = jnp.abs(x)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x_max = minus_eps(power_ladder_max_output(p))\n  xp = override_gradient(jnp.clip(xp, -x_max, x_max), xp)  # Clip val, not grad.\n  y = safe_sign(x) * select(\n      [\n          (p == 1, xp),\n          (p == 0, safe_expm1(xp)),\n          (p == -jnp.inf, -safe_log1p(-xp)),\n          (p == jnp.inf, safe_log1p(xp)),\n      ],\n      jnp.abs(p_safe - 1)\n      * (\n          ((safe_div(p_safe, jnp.abs(p_safe - 1)) * xp + 1)) ** (1 / p_safe) - 1\n      ),\n  )\n  if postmult is not None:\n    y *= postmult\n  return y"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x *= premult\n  xp = jnp.abs(x)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  xp_max = minus_eps(power_ladder_max_output(p))\n  xp = override_gradient(jnp.clip(xp, -xp_max, xp_max), xp)  # Clip val, not grad.\n  y = safe_sign(x) * select(\n      [\n          (p == 1, xp),\n          (p == 0, safe_expm1(xp)),\n          (p == -jnp.inf, -safe_log1p(-xp)),\n          (p == jnp.inf, safe_log1p(xp)),\n      ],\n      jnp.abs(p_safe - 1)\n      * (\n          ((safe_div(p_safe, jnp.abs(p_safe - 1)) * xp + 1)) ** (1 / p_safe) - 1\n      ),\n  )\n  if postmult is not None:\n    y *= postmult\n  return y"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x *= premult\n  xp = jnp.abs(x)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x_max = power_ladder_max_output(p)\n  xp = override_gradient(jnp.clip(xp, -x_max, x_max), xp)  # Clip val, not grad.\n  y = safe_sign(x) * select(\n      [\n          (p == 1, xp),\n          (p == 0, safe_expm1(xp)),\n          (p == -jnp.inf, -safe_log1p(-xp)),\n          (p == jnp.inf, safe_log1p(xp)),\n      ],\n      jnp.abs(p_safe - 1)\n      * (\n          ((safe_div(p_safe, jnp.abs(p_safe - 1)) * xp + 1)) ** (1 / p_safe) - 1\n      ),\n  )\n  if postmult is not None:\n    y *= postmult\n  return y"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x *= premult\n\n  # Handle special cases for p\n  if p == 1:\n    x = jnp.where(x >= 0, jnp.log1p(x), -jnp.log1p(-x))\n  elif p == 0:\n    x = jnp.where(x >= 0, safe_log1p(x), -safe_log1p(-x))\n  elif p == -jnp.inf:\n    x = jnp.where(x >= 0, safe_expm1(x), -safe_expm1(-x))\n  elif p == jnp.inf:\n    x = jnp.where(x >= 0, safe_log1p(x), -safe_log1p(-x))\n  else:\n    x = jnp.where(x >= 0, safe_sign(x) * (jnp.abs(x) + 1)**p - 1, -safe_sign(x) * (jnp.abs(x) + 1)**p + 1)\n\n  if postmult is not None:\n    x *= postmult\n\n  return x"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x *= premult\n\n  xp = jnp.abs(x)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  y_max = minus_eps(power_ladder_max_output(p))\n  xp = override_gradient(jnp.clip(xp, -y_max, y_max), xp)  # Clip val, not grad.\n\n  x_transformed = safe_sign(x) * select(\n      [\n          (p == 1, xp),\n          (p == 0, safe_expm1(xp)),\n          (p == -jnp.inf, -safe_log1p(-xp)),\n          (p == jnp.inf, safe_log1p(xp)),\n      ],\n      jnp.abs(p_safe - 1)\n      * (\n          ((safe_div(p_safe, jnp.abs(p_safe - 1)) * xp + 1)) ** (1 / p_safe) - 1\n      ),\n  )\n\n  if postmult is not None:\n    x_transformed *= postmult\n\n  return x_transformed"}
{"namespace": "math.power_ladder", "completion": "\n  if premult is not None:\n    x *= premult\n\n  xp = jnp.abs(x)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x_max = power_ladder_max_output(p)\n  xp = override_gradient(jnp.clip(xp, -x_max, x_max), xp)  # Clip val, not grad.\n\n  result = safe_sign(x) * select(\n      [\n          (p == 1, xp),\n          (p == 0, safe_expm1(xp)),\n          (p == -jnp.inf, -safe_log1p(-xp)),\n          (p == jnp.inf, safe_log1p(xp)),\n      ],\n      jnp.abs(p_safe - 1)\n      * (\n          ((safe_div(p_safe, jnp.abs(p_safe - 1)) * xp + 1)) ** (1 / p_safe) - 1\n      ),\n  )\n\n  if postmult is not None:\n    result *= postmult\n\n  return result"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x *= premult\n\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x_safe = jnp.clip(x, -max_val, max_val)\n\n  result = jnp.sign(x_safe) * jnp.select(\n      [\n          (p == 1, x_safe),\n          (p == 0, safe_log1p(x_safe)),\n          (p == -jnp.inf, -safe_expm1(-x_safe)),\n          (p == jnp.inf, safe_expm1(x_safe)),\n      ],\n      (safe_div(p_safe, jnp.abs(p_safe - 1)) * x_safe + 1) ** (1 / p_safe) - 1\n  )\n\n  if postmult is not None:\n    result *= postmult\n\n  return result"}
{"namespace": "math.power_ladder", "completion": "  # Apply the optional pre-multiplication\n  if premult is not None:\n    x = x * premult\n\n  # Apply the power ladder transformation\n  x_abs = jnp.abs(x)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  y_max = minus_eps(power_ladder_max_output(p))\n  x_abs_clipped = override_gradient(jnp.clip(x_abs, -y_max, y_max), x_abs)  # Clip val, not grad.\n  y = safe_sign(x) * select(\n      [\n          (p == 1, x_abs_clipped),\n          (p == 0, safe_expm1(x_abs_clipped)),\n          (p == -jnp.inf, -safe_log1p(-x_abs_clipped)),\n          (p == jnp.inf, safe_log1p(x_abs_clipped)),\n      ],\n      jnp.abs(p_safe - 1)\n      * (\n          ((safe_div(p_safe, jnp.abs(p_safe - 1)) * x_abs_clipped + 1)) ** (1 / p_safe) - 1\n      ),\n  )\n\n  # Apply the optional post-multiplication\n  if postmult is not None:\n    y = y * postmult\n\n  return y"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x *= premult\n\n  # Handle special cases for p\n  if p == 1:\n    y = x\n  elif p == 0:\n    y = safe_log1p(x)\n  elif p == -jnp.inf:\n    y = -safe_log1p(-x)\n  elif p == jnp.inf:\n    y = safe_log1p(x)\n  else:\n    y = jnp.sign(x) * safe_expm1(safe_log(jnp.abs(x) * (p - 1) + 1) / p)\n\n  if postmult is not None:\n    y *= postmult\n\n  return y"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute the sign of y\n  sign_y = safe_sign(y)\n  \n  # Compute the absolute value of y\n  abs_y = jnp.abs(y)\n  \n  # Compute the absolute value of p\n  abs_p = jnp.abs(p)\n  \n  # Compute the inverse transformation based on the value of p\n  if p == 1:\n    result = abs_y\n  elif p == 0:\n    result = safe_exp(abs_y) - 1\n  elif p == -jnp.inf:\n    result = -safe_log1p(-abs_y)\n  elif p == jnp.inf:\n    result = safe_log1p(abs_y)\n  else:\n    result = safe_sign(y) * (safe_exp(abs_p * safe_log1p(abs_y)) - 1) / (abs_p - 1)\n  \n  # Apply optional post-multiplication adjustment\n  if postmult is not None:\n    result *= postmult\n  \n  # Apply optional pre-multiplication adjustment\n  if premult is not None:\n    result *= premult\n  \n  return result"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute the sign of y\n  sign_y = safe_sign(y)\n  \n  # Compute the absolute value of y\n  abs_y = jnp.abs(y)\n  \n  # Check for special cases of p\n  if p == 1:\n    # Inverse operation for p = 1\n    result = abs_y\n  elif p == 0:\n    # Inverse operation for p = 0\n    result = safe_exp(abs_y) - 1\n  elif p == -jnp.inf:\n    # Inverse operation for p = -\u221e\n    result = -safe_log1p(-abs_y)\n  elif p == jnp.inf:\n    # Inverse operation for p = \u221e\n    result = safe_log1p(abs_y)\n  else:\n    # Inverse operation for other values of p\n    result = jnp.sign(p) * (jnp.power((abs_y + 1) / jnp.abs(p - 1), jnp.abs(p)) - 1) * jnp.abs(p - 1)\n  \n  # Apply pre-multiplication and post-multiplication adjustments\n  if premult is not None:\n    result = result * premult\n  if postmult is not None:\n    result = result * postmult\n  \n  # Return the result of the inverse power ladder transformation\n  return result"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y / premult\n  if postmult is not None:\n    y = y / postmult\n\n  # Compute the inverse of the power ladder transformation\n  if p == 1:\n    return y\n  elif p == 0:\n    return safe_exp(y) - 1\n  elif p == -jnp.inf:\n    return -safe_log1p(-y)\n  elif p == jnp.inf:\n    return safe_log1p(y)\n  else:\n    return (jnp.abs(p - 1) / p) * (safe_sign(y) * (jnp.abs(y) + 1) ** (1 / jnp.abs(p - 1)) - 1)"}
{"namespace": "math.inv_power_ladder", "completion": "    if postmult is not None:\n        y = y * postmult\n    yp = jnp.abs(y)\n    ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n    p_safe = clip_finite_nograd(remove_zero(p))\n    x = safe_sign(y) * select(\n        [\n            (p == 1, yp),\n            (p == 0, safe_exp(yp) - 1),\n            (p == -jnp.inf, -safe_log1p(-yp)),\n            (p == jnp.inf, safe_log1p(yp)),\n        ],\n        jnp.power(1 + jnp.maximum(tiny_val, jnp.abs(p_safe - 1)) * ys, 1 / p_safe) - 1\n    )\n    if premult is not None:\n        x = x * premult\n    return x"}
{"namespace": "math.inv_power_ladder", "completion": "  if postmult is not None:\n    y = y / postmult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_exp(yp) - 1),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      safe_expm1(clip_finite_nograd(yp * p_safe / jnp.abs(p - 1))),\n  )\n  if premult is not None:\n    x = x / premult\n  return x"}
{"namespace": "math.inv_power_ladder", "completion": "  if postmult is not None:\n    y = y / postmult\n  if p == 1:\n    return y\n  elif p == 0:\n    return safe_exp(y) - 1\n  elif p == -jnp.inf:\n    return -safe_log1p(-y)\n  elif p == jnp.inf:\n    return safe_log1p(y)\n  else:\n    return safe_sign(y) * (safe_expm1(jnp.abs(y) * jnp.abs(p - 1) / jnp.abs(p)) * jnp.abs(p - 1) / jnp.abs(p))"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y / premult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_exp(yp) - 1),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          (jnp.maximum(1, jnp.exp(1 / p_safe * safe_log1p(ys))) - 1)\n          * jnp.maximum(tiny_val, jnp.abs(p_safe - 1)) / p_safe\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute the inverse of the power ladder transformation\n  if postmult is not None:\n    y = y * postmult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          (jnp.power(ys + 1, 1 / p_safe) - 1) * jnp.abs(p_safe - 1) / p_safe\n      ),\n  )\n  if premult is not None:\n    x = x * premult\n  return x"}
{"namespace": "math.inv_power_ladder", "completion": "  # Inverse power ladder transformation\n  if postmult is not None:\n    y = y * postmult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          (ys + 1) ** (1 / p_safe) - 1\n      ),\n  )\n  if premult is not None:\n    x = x * premult\n  return x"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y / premult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * (jnp.exp(ys) - 1)\n      ),\n  )\n  if postmult is not None:\n    x = x / postmult\n  return x"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y / premult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * (jnp.power(1 + ys, 1 / p_safe) - 1)\n      ),\n  )\n  if postmult is not None:\n    x = x / postmult\n  return x"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute the sign of the input `y`\n  sign_y = safe_sign(y)\n  \n  # Compute the absolute value of the input `y`\n  abs_y = jnp.abs(y)\n  \n  # Check for special cases based on the value of `p`\n  if p == 1:\n    # Inverse transformation for p=1\n    result = abs_y\n  elif p == 0:\n    # Inverse transformation for p=0\n    result = safe_exp(abs_y) - 1\n  elif p == -jnp.inf:\n    # Inverse transformation for p=-infinity\n    result = -safe_log1p(-abs_y)\n  elif p == jnp.inf:\n    # Inverse transformation for p=infinity\n    result = safe_log1p(abs_y)\n  else:\n    # General inverse transformation for other values of p\n    result = safe_sign(y) * (safe_expm1((1 / jnp.abs(p)) * safe_log1p(jnp.abs(p) * abs_y)))\n  \n  # Apply optional post-multiplication adjustment\n  if postmult is not None:\n    result = result * postmult\n  \n  # Apply optional pre-multiplication adjustment\n  if premult is not None:\n    result = result * premult\n  \n  return result"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y / premult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_exp(yp) - 1),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      safe_div(yp + 1, jnp.abs(p_safe - 1))**(1 / p_safe) - 1\n  )\n  if postmult is not None:\n    x = x / postmult\n  return x"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute the inverse of the power ladder transformation\n  if postmult is not None:\n    y = y / postmult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          (jnp.maximum(tiny_val, jnp.abs(p_safe - 1)) / p_safe) * (jnp.power(1 + ys, 1 / p_safe) - 1)\n      ),\n  )\n  if premult is not None:\n    x = x * premult\n  return x"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute the inverse of the power ladder transformation\n  if postmult is not None:\n    y = y * postmult\n  yp = jnp.abs(y)\n  ps = jnp.abs(p - 1)\n  y_sign = safe_sign(y)\n  \n  # Compute the inverse transformation based on the value of p\n  if p == 1:\n    x = yp\n  elif p == 0:\n    x = safe_exp(yp) - 1\n  elif p == -jnp.inf:\n    x = -safe_log1p(-yp)\n  elif p == jnp.inf:\n    x = safe_log1p(yp)\n  else:\n    x = y_sign * (safe_expm1(ps * yp / jnp.maximum(tiny_val, ps))) / ps\n  \n  if premult is not None:\n    x = x * premult\n  \n  return x"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute the inverse power ladder transformation\n  if postmult is not None:\n    y = y / postmult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * (jnp.maximum(0, (ys + 1)) ** (1 / p_safe) - 1)\n      ),\n  )\n  if premult is not None:\n    x = x / premult\n  return x"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute the inverse power ladder transformation\n  if postmult is not None:\n    y = y / postmult\n\n  # Compute the inverse transformation based on the value of p\n  if p == 1:\n    x = y\n  elif p == 0:\n    x = safe_exp(y) - 1\n  elif p == -jnp.inf:\n    x = -safe_log1p(-y)\n  elif p == jnp.inf:\n    x = safe_log1p(y)\n  else:\n    x = jnp.sign(y) * (jnp.abs(y) / safe_expm1(safe_log1p(jnp.abs(y))) + 1) ** (1 / (p - 1)) - 1\n\n  # Apply pre-multiplication if provided\n  if premult is not None:\n    x = x * premult\n\n  return x"}
{"namespace": "math.inv_power_ladder", "completion": "  if postmult is not None:\n    y = y / postmult\n  # Compute the inverse operation of the power ladder transformation\n  if p == 1:\n    return y\n  elif p == 0:\n    return safe_exp(y) - 1\n  elif p == -jnp.inf:\n    return -safe_log1p(-y)\n  elif p == jnp.inf:\n    return safe_log1p(y)\n  else:\n    return safe_sign(y) * (jnp.abs(y) + 1) ** (1 / jnp.abs(p) + 1) - 1"}
{"namespace": "math.inv_power_ladder", "completion": "  if postmult is not None:\n    y = y / postmult\n  xp = jnp.abs(y)\n  xs = xp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, xp),\n          (p == 0, safe_exp(xp) - 1),\n          (p == -jnp.inf, -safe_log1p(-xp)),\n          (p == jnp.inf, safe_log1p(xp)),\n      ],\n      clip_finite_nograd(\n          (jnp.power(jnp.maximum(0, 1 + xp), 1 / p_safe) - 1) * jnp.abs(p_safe - 1) / p_safe\n      ),\n  )\n  if premult is not None:\n    x = x / premult\n  return x"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute the inverse power ladder transformation\n  if postmult is not None:\n    y = y / postmult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_exp(yp) - 1),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          (jnp.power(1 + ys, 1 / p_safe) - 1) * jnp.abs(p_safe - 1) / p_safe\n      ),\n  )\n  if premult is not None:\n    x = x * premult\n  return x"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  near = xnp.broadcast_to(near, origins.shape[:-1] + (1,))\n  origins = xnp.concatenate([origins, xnp.ones_like(origins[..., :1])], axis=-1)\n  origins_ndc = xnp.matmul(pixtocam, origins)\n  origins_ndc = origins_ndc[..., :2] / origins_ndc[..., 2:3]\n  directions_ndc = xnp.matmul(pixtocam, directions)\n  return origins_ndc, directions_ndc"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  \"\"\"\n  Converts a set of rays from world space to normalized device coordinates (NDC) using a perspective projection model. This is useful for rendering or processing 3D scenes in a standardized coordinate system.\n\n  Input-Output Arguments\n  :param origins: ndarray(float32), The origins of the rays in world space, used to determine their starting points in NDC.\n  :param directions: ndarray(float32), The directions of the rays in world space, used to calculate their orientation in NDC.\n  :param pixtocam: ndarray(float32), The inverse intrinsic matrix of the camera, used for the perspective projection calculation.\n  :param near: float, The distance to the near plane along the negative z-axis, used to define the depth range of the projection.\n  :param xnp: module, Either numpy or jax.numpy, specifies the numerical library to use for calculations.\n  :return: Tuple of ndarray(float32), The origins and directions of the rays in normalized device coordinates.\n\n  This function performs a perspective projection of rays defined in world space into a normalized device coordinate system, assuming an identity extrinsic matrix (camera pose) and intrinsic parameters defined by the pixtocam matrix. The function adjusts ray origins to the near plane and calculates the corresponding directions in NDC, facilitating the rendering or analysis of 3D scenes from a standardized viewpoint.\n  \"\"\"\n  # Convert origins and directions to homogeneous coordinates.\n  origins_h = xnp.concatenate([origins, xnp.ones_like(origins[..., :1])], axis=-1)\n  directions_h = xnp.concatenate([directions, xnp.zeros_like(directions[..., :1])], axis=-1)\n\n  # Apply perspective projection using the inverse intrinsic matrix.\n  origins_ndc = xnp.einsum('...ij,...j->...i', pixtocam, origins_h)\n  directions_ndc = xnp.einsum('...ij,...j->...i', pixtocam, directions_h)\n\n  # Normalize the directions to ensure they are unit vectors.\n  directions_ndc = xnp.divide(directions_ndc, xnp.linalg.norm(directions_ndc, axis=-1, keepdims=True))\n\n  # Adjust the origins to the near plane.\n  origins_ndc = origins_ndc * near / -origins_ndc[..., -1:]\n\n  return origins_ndc, directions_ndc"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert origins and directions to homogeneous coordinates\n  origins_h = xnp.concatenate([origins, xnp.ones_like(origins[..., :1])], axis=-1)\n  directions_h = xnp.concatenate([directions, xnp.zeros_like(directions[..., :1])], axis=-1)\n\n  # Apply perspective projection to the origins and directions\n  origins_ndc = xnp.einsum('...ij,...j->...i', pixtocam, origins_h)\n  directions_ndc = xnp.einsum('...ij,...j->...i', pixtocam, directions_h)\n\n  # Normalize the directions to have unit length\n  directions_ndc = directions_ndc / xnp.linalg.norm(directions_ndc, axis=-1, keepdims=True)\n\n  # Adjust the origins to the near plane\n  origins_ndc = origins_ndc - directions_ndc * near\n\n  return origins_ndc, directions_ndc"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  \"\"\"\n  Converts a set of rays from world space to normalized device coordinates (NDC) using a perspective projection model. This is useful for rendering or processing 3D scenes in a standardized coordinate system.\n\n  Input-Output Arguments\n  :param origins: ndarray(float32), The origins of the rays in world space, used to determine their starting points in NDC.\n  :param directions: ndarray(float32), The directions of the rays in world space, used to calculate their orientation in NDC.\n  :param pixtocam: ndarray(float32), The inverse intrinsic matrix of the camera, used for the perspective projection calculation.\n  :param near: float, The distance to the near plane along the negative z-axis, used to define the depth range of the projection.\n  :param xnp: module, Either numpy or jax.numpy, specifies the numerical library to use for calculations.\n  :return: Tuple of ndarray(float32), The origins and directions of the rays in normalized device coordinates.\n\n  This function performs a perspective projection of rays defined in world space into a normalized device coordinate system, assuming an identity extrinsic matrix (camera pose) and intrinsic parameters defined by the pixtocam matrix. The function adjusts ray origins to the near plane and calculates the corresponding directions in NDC, facilitating the rendering or analysis of 3D scenes from a standardized viewpoint.\n  \"\"\"\n  # Convert origins and directions to homogeneous coordinates.\n  origins_h = xnp.concatenate([origins, xnp.ones_like(origins[..., :1])], axis=-1)\n  directions_h = xnp.concatenate([directions, xnp.zeros_like(directions[..., :1])], axis=-1)\n\n  # Apply the perspective projection using the inverse intrinsic matrix.\n  origins_ndc = xnp.einsum('...ij,...j->...i', pixtocam, origins_h)\n  directions_ndc = xnp.einsum('...ij,...j->...i', pixtocam, directions_h)\n\n  # Adjust the origins to the near plane and normalize the directions.\n  t = near / -directions_ndc[..., -1:]\n  origins_ndc = origins_ndc + t * directions_ndc\n  directions_ndc = directions_ndc / directions_ndc[..., -1:]\n\n  # Return the origins and directions in normalized device coordinates.\n  return origins_ndc, directions_ndc"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  \"\"\"\n  Converts a set of rays from world space to normalized device coordinates (NDC) using a perspective projection model. This is useful for rendering or processing 3D scenes in a standardized coordinate system.\n\n  Input-Output Arguments\n  :param origins: ndarray(float32), The origins of the rays in world space, used to determine their starting points in NDC.\n  :param directions: ndarray(float32), The directions of the rays in world space, used to calculate their orientation in NDC.\n  :param pixtocam: ndarray(float32), The inverse intrinsic matrix of the camera, used for the perspective projection calculation.\n  :param near: float, The distance to the near plane along the negative z-axis, used to define the depth range of the projection.\n  :param xnp: module, Either numpy or jax.numpy, specifies the numerical library to use for calculations.\n  :return: Tuple of ndarray(float32), The origins and directions of the rays in normalized device coordinates.\n\n  This function performs a perspective projection of rays defined in world space into a normalized device coordinate system, assuming an identity extrinsic matrix (camera pose) and intrinsic parameters defined by the pixtocam matrix. The function adjusts ray origins to the near plane and calculates the corresponding directions in NDC, facilitating the rendering or analysis of 3D scenes from a standardized viewpoint.\n  \"\"\"\n  # Convert ray origins and directions into projective NDC space.\n  ndc_origins = xnp.matmul(pixtocam, origins)\n  ndc_directions = xnp.matmul(pixtocam, directions)\n\n  # Adjust ray origins to the near plane.\n  t = near / ndc_directions[..., 2:3]\n  ndc_origins -= t * ndc_directions\n\n  return ndc_origins, ndc_directions"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  \"\"\"\n  Converts a set of rays from world space to normalized device coordinates (NDC) using a perspective projection model. This is useful for rendering or processing 3D scenes in a standardized coordinate system.\n\n  Input-Output Arguments\n  :param origins: ndarray(float32), The origins of the rays in world space, used to determine their starting points in NDC.\n  :param directions: ndarray(float32), The directions of the rays in world space, used to calculate their orientation in NDC.\n  :param pixtocam: ndarray(float32), The inverse intrinsic matrix of the camera, used for the perspective projection calculation.\n  :param near: float, The distance to the near plane along the negative z-axis, used to define the depth range of the projection.\n  :param xnp: module, Either numpy or jax.numpy, specifies the numerical library to use for calculations.\n  :return: Tuple of ndarray(float32), The origins and directions of the rays in normalized device coordinates.\n\n  This function performs a perspective projection of rays defined in world space into a normalized device coordinate system, assuming an identity extrinsic matrix (camera pose) and intrinsic parameters defined by the pixtocam matrix. The function adjusts ray origins to the near plane and calculates the corresponding directions in NDC, facilitating the rendering or analysis of 3D scenes from a standardized viewpoint.\n  \"\"\"\n  # Apply perspective projection to convert rays to NDC\n  origins_ndc = xnp.matmul(pixtocam, origins)\n  directions_ndc = xnp.matmul(pixtocam, directions)\n\n  # Adjust ray origins to the near plane\n  t_near = near / -directions_ndc[..., 2:3]\n  origins_ndc = origins_ndc + t_near * directions_ndc\n\n  return origins_ndc, directions_ndc"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  \"\"\"\n  Converts a set of rays from world space to normalized device coordinates (NDC) using a perspective projection model. This is useful for rendering or processing 3D scenes in a standardized coordinate system.\n\n  Input-Output Arguments\n  :param origins: ndarray(float32), The origins of the rays in world space, used to determine their starting points in NDC.\n  :param directions: ndarray(float32), The directions of the rays in world space, used to calculate their orientation in NDC.\n  :param pixtocam: ndarray(float32), The inverse intrinsic matrix of the camera, used for the perspective projection calculation.\n  :param near: float, The distance to the near plane along the negative z-axis, used to define the depth range of the projection.\n  :param xnp: module, Either numpy or jax.numpy, specifies the numerical library to use for calculations.\n  :return: Tuple of ndarray(float32), The origins and directions of the rays in normalized device coordinates.\n\n  This function performs a perspective projection of rays defined in world space into a normalized device coordinate system, assuming an identity extrinsic matrix (camera pose) and intrinsic parameters defined by the pixtocam matrix. The function adjusts ray origins to the near plane and calculates the corresponding directions in NDC, facilitating the rendering or analysis of 3D scenes from a standardized viewpoint.\n  \"\"\"\n  # Convert origins and directions to homogeneous coordinates\n  origins_h = xnp.concatenate([origins, xnp.ones_like(origins[..., :1])], axis=-1)\n  directions_h = xnp.concatenate([directions, xnp.zeros_like(directions[..., :1])], axis=-1)\n\n  # Apply the perspective projection\n  origins_ndc = xnp.einsum('...ij,...j->...i', pixtocam, origins_h)\n  directions_ndc = xnp.einsum('...ij,...j->...i', pixtocam, directions_h)\n\n  # Normalize the directions to have unit length\n  directions_ndc = directions_ndc / xnp.linalg.norm(directions_ndc, axis=-1, keepdims=True)\n\n  # Scale the directions by the near plane distance\n  origins_ndc = origins_ndc / origins_ndc[..., -1, None]\n  directions_ndc = directions_ndc / origins_ndc[..., -1, None]\n\n  return origins_ndc[..., :3], directions_ndc[..., :3]"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  \"\"\"\n  Converts a set of rays from world space to normalized device coordinates (NDC) using a perspective projection model. This is useful for rendering or processing 3D scenes in a standardized coordinate system.\n\n  Input-Output Arguments\n  :param origins: ndarray(float32), The origins of the rays in world space, used to determine their starting points in NDC.\n  :param directions: ndarray(float32), The directions of the rays in world space, used to calculate their orientation in NDC.\n  :param pixtocam: ndarray(float32), The inverse intrinsic matrix of the camera, used for the perspective projection calculation.\n  :param near: float, The distance to the near plane along the negative z-axis, used to define the depth range of the projection.\n  :param xnp: module, Either numpy or jax.numpy, specifies the numerical library to use for calculations.\n  :return: Tuple of ndarray(float32), The origins and directions of the rays in normalized device coordinates.\n\n  This function performs a perspective projection of rays defined in world space into a normalized device coordinate system, assuming an identity extrinsic matrix (camera pose) and intrinsic parameters defined by the pixtocam matrix. The function adjusts ray origins to the near plane and calculates the corresponding directions in NDC, facilitating the rendering or analysis of 3D scenes from a standardized viewpoint.\n  \"\"\"\n  # Apply the inverse intrinsic matrix to convert to NDC.\n  origins_ndc = xnp.matmul(pixtocam, origins)\n  directions_ndc = xnp.matmul(pixtocam, directions)\n  \n  # Adjust the ray origins to the near plane.\n  t = near / -directions_ndc[..., 2:]\n  origins_ndc += t * directions_ndc\n\n  return origins_ndc, directions_ndc"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "\n    # Convert origins and directions to homogeneous coordinates.\n    origins_h = xnp.concatenate([origins, xnp.ones_like(origins[..., :1])], axis=-1)\n    directions_h = xnp.concatenate([directions, xnp.zeros_like(directions[..., :1])], axis=-1)\n\n    # Apply perspective projection using the inverse intrinsic matrix.\n    origins_ndc = xnp.tensordot(origins_h, pixtocam.T, axes=(-1, -1))[..., :2]\n    directions_ndc = xnp.tensordot(directions_h, pixtocam.T, axes=(-1, -1))[..., :2]\n\n    # Normalize the directions to ensure they are unit vectors.\n    directions_ndc = xnp.divide(directions_ndc, xnp.linalg.norm(directions_ndc, axis=-1, keepdims=True))\n\n    # Adjust the origins to the near plane.\n    t = -origins[..., 2:3] / directions[..., 2:3]\n    origins_ndc = origins_ndc + t * directions_ndc\n\n    return origins_ndc, directions_ndc"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Apply the look-at function.\n  new_cameras = []\n  for camera, camera_position, look_at_position, up_vector in zip(\n      cameras,\n      camera_positions_perturbed,\n      look_at_positions_perturbed,\n      up_vectors,\n  ):\n    new_cameras.append(\n        jax_camera_from_tuple(\n            (\n                camera.inv_intrinsics,\n                camera.extrinsics,\n                camera.distortion_params,\n            ),\n            camera.image_size,\n            ProjectionType.PERSPECTIVE,\n        ).look_at(camera_position, look_at_position, up_vector)\n    )\n\n  return new_cameras"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Apply the look-at function.\n  new_cameras = []\n  for camera, camera_position, look_at_position, up_vector in zip(\n      cameras,\n      camera_positions_perturbed,\n      look_at_positions_perturbed,\n      up_vectors,\n  ):\n    new_cameras.append(\n        jaxcam.look_at(\n            camera_position, look_at_position, up_vector, focal_length=camera.focal_length\n        )\n    )\n  cameras = jaxcam.Cameras(new_cameras)\n\n  return cameras"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  \"\"\"\n  Converts a set of rays from world space to normalized device coordinates (NDC) using a perspective projection model. This is useful for rendering or processing 3D scenes in a standardized coordinate system.\n\n  Input-Output Arguments\n  :param origins: ndarray(float32), The origins of the rays in world space, used to determine their starting points in NDC.\n  :param directions: ndarray(float32), The directions of the rays in world space, used to calculate their orientation in NDC.\n  :param pixtocam: ndarray(float32), The inverse intrinsic matrix of the camera, used for the perspective projection calculation.\n  :param near: float, The distance to the near plane along the negative z-axis, used to define the depth range of the projection.\n  :param xnp: module, Either numpy or jax.numpy, specifies the numerical library to use for calculations.\n  :return: Tuple of ndarray(float32), The origins and directions of the rays in normalized device coordinates.\n\n  This function performs a perspective projection of rays defined in world space into a normalized device coordinate system, assuming an identity extrinsic matrix (camera pose) and intrinsic parameters defined by the pixtocam matrix. The function adjusts ray origins to the near plane and calculates the corresponding directions in NDC, facilitating the rendering or analysis of 3D scenes from a standardized viewpoint.\n  \"\"\"\n  # Adjust ray origins to the near plane\n  origins_ndc = origins / origins[..., -1, None] * near\n\n  # Calculate the corresponding directions in NDC\n  directions_ndc = directions / origins[..., -1, None]\n\n  return origins_ndc, directions_ndc"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  \"\"\"\n  Converts a set of rays from world space to normalized device coordinates (NDC) using a perspective projection model. This is useful for rendering or processing 3D scenes in a standardized coordinate system.\n\n  Input-Output Arguments\n  :param origins: ndarray(float32), The origins of the rays in world space, used to determine their starting points in NDC.\n  :param directions: ndarray(float32), The directions of the rays in world space, used to calculate their orientation in NDC.\n  :param pixtocam: ndarray(float32), The inverse intrinsic matrix of the camera, used for the perspective projection calculation.\n  :param near: float, The distance to the near plane along the negative z-axis, used to define the depth range of the projection.\n  :param xnp: module, Either numpy or jax.numpy, specifies the numerical library to use for calculations.\n  :return: Tuple of ndarray(float32), The origins and directions of the rays in normalized device coordinates.\n\n  This function performs a perspective projection of rays defined in world space into a normalized device coordinate system, assuming an identity extrinsic matrix (camera pose) and intrinsic parameters defined by the pixtocam matrix. The function adjusts ray origins to the near plane and calculates the corresponding directions in NDC, facilitating the rendering or analysis of 3D scenes from a standardized viewpoint.\n  \"\"\"\n  # Convert origins and directions to homogeneous coordinates.\n  origins_h = xnp.concatenate([origins, xnp.ones_like(origins[..., :1])], axis=-1)\n  directions_h = xnp.concatenate([directions, xnp.zeros_like(directions[..., :1])], axis=-1)\n\n  # Apply the perspective projection using the inverse intrinsic matrix.\n  origins_ndc = xnp.einsum('...ij,...j->...i', pixtocam, origins_h)\n  directions_ndc = xnp.einsum('...ij,...j->...i', pixtocam, directions_h)\n\n  # Normalize the directions to unit length.\n  directions_ndc = xnp.divide(directions_ndc, xnp.linalg.norm(directions_ndc, axis=-1, keepdims=True))\n\n  # Adjust the origins to the near plane.\n  t = -origins_ndc[..., -1] / directions_ndc[..., -1]\n  origins_ndc = origins_ndc + t[..., None] * directions_ndc\n\n  return origins_ndc, directions_ndc"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  origins = origins @ pixtocam.T\n  directions = directions @ pixtocam.T\n  t = -origins[..., 2:3] / directions[..., 2:3]\n  origins = origins + t * directions\n  directions = directions / origins[..., 2:3]\n\n  return origins, directions"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  \"\"\"\n  Converts a set of rays from world space to normalized device coordinates (NDC) using a perspective projection model. This is useful for rendering or processing 3D scenes in a standardized coordinate system.\n\n  Input-Output Arguments\n  :param origins: ndarray(float32), The origins of the rays in world space, used to determine their starting points in NDC.\n  :param directions: ndarray(float32), The directions of the rays in world space, used to calculate their orientation in NDC.\n  :param pixtocam: ndarray(float32), The inverse intrinsic matrix of the camera, used for the perspective projection calculation.\n  :param near: float, The distance to the near plane along the negative z-axis, used to define the depth range of the projection.\n  :param xnp: module, Either numpy or jax.numpy, specifies the numerical library to use for calculations.\n  :return: Tuple of ndarray(float32), The origins and directions of the rays in normalized device coordinates.\n\n  This function performs a perspective projection of rays defined in world space into a normalized device coordinate system, assuming an identity extrinsic matrix (camera pose) and intrinsic parameters defined by the pixtocam matrix. The function adjusts ray origins to the near plane and calculates the corresponding directions in NDC, facilitating the rendering or analysis of 3D scenes from a standardized viewpoint.\n  \"\"\"\n  # Convert origins and directions to homogeneous coordinates.\n  origins_h = xnp.concatenate([origins, xnp.ones_like(origins[..., :1])], axis=-1)\n  directions_h = xnp.concatenate([directions, xnp.zeros_like(directions[..., :1])], axis=-1)\n\n  # Apply the inverse intrinsic matrix to the origins and directions.\n  origins_ndc = xnp.einsum('...ij,...j->...i', pixtocam, origins_h)\n  directions_ndc = xnp.einsum('...ij,...j->...i', pixtocam, directions_h)\n\n  # Normalize the directions to have unit length.\n  directions_ndc = directions_ndc / xnp.linalg.norm(directions_ndc, axis=-1, keepdims=True)\n\n  # Adjust the origins to the near plane.\n  origins_ndc = origins_ndc * near / -origins_ndc[..., -1:]\n\n  return origins_ndc, directions_ndc"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  near_origins = origins\n  near_directions = directions\n\n  # Apply the inverse intrinsic matrix to the ray origins and directions.\n  near_origins = xnp.matmul(pixtocam, xnp.concatenate([near_origins, xnp.ones_like(near_origins[..., :1])], axis=-1).T).T[..., :3]\n  near_directions = xnp.matmul(pixtocam, xnp.concatenate([near_directions, xnp.zeros_like(near_directions[..., :1])], axis=-1).T).T[..., :3]\n\n  # Normalize the ray directions.\n  near_directions = math.normalize(near_directions)\n\n  # Calculate the NDC origins and directions.\n  ndc_origins = near_origins / near_origins[..., -1:]\n  ndc_directions = near_directions\n\n  return ndc_origins, ndc_directions"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  \"\"\"\n  Converts a set of rays from world space to normalized device coordinates (NDC) using a perspective projection model. This is useful for rendering or processing 3D scenes in a standardized coordinate system.\n\n  Input-Output Arguments\n  :param origins: ndarray(float32), The origins of the rays in world space, used to determine their starting points in NDC.\n  :param directions: ndarray(float32), The directions of the rays in world space, used to calculate their orientation in NDC.\n  :param pixtocam: ndarray(float32), The inverse intrinsic matrix of the camera, used for the perspective projection calculation.\n  :param near: float, The distance to the near plane along the negative z-axis, used to define the depth range of the projection.\n  :param xnp: module, Either numpy or jax.numpy, specifies the numerical library to use for calculations.\n  :return: Tuple of ndarray(float32), The origins and directions of the rays in normalized device coordinates.\n\n  This function performs a perspective projection of rays defined in world space into a normalized device coordinate system, assuming an identity extrinsic matrix (camera pose) and intrinsic parameters defined by the pixtocam matrix. The function adjusts ray origins to the near plane and calculates the corresponding directions in NDC, facilitating the rendering or analysis of 3D scenes from a standardized viewpoint.\n  \"\"\"\n  # Convert ray origins and directions into projective NDC space.\n  ndc_fn = functools.partial(convert_to_ndc, pixtocam=pixtocam, xnp=xnp)\n  origins_ndc, directions_ndc = ndc_fn(origins, directions)\n\n  return origins_ndc, directions_ndc"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  inv_pixtocam = xnp.linalg.inv(pixtocam)\n  near_origins = origins - near * directions\n  ndc_origins = xnp.einsum('...ij,...j->...i', inv_pixtocam, near_origins)\n  ndc_directions = xnp.einsum('...ij,...j->...i', inv_pixtocam, directions)\n  return ndc_origins, ndc_directions"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  import jax.numpy as jnp\n\n  # Apply inverse intrinsic matrices to the ray origins and directions.\n  ray_origins_ndc = xnp.matmul(pixtocam, origins)\n  ray_directions_ndc = xnp.matmul(pixtocam, directions)\n\n  # Normalize the ray directions.\n  ray_directions_ndc = xnp.divide(ray_directions_ndc, xnp.linalg.norm(ray_directions_ndc, axis=-1, keepdims=True))\n\n  # Adjust ray origins to the near plane.\n  ray_origins_ndc = ray_origins_ndc * near / -ray_origins_ndc[..., -1:]\n\n  return ray_origins_ndc, ray_directions_ndc"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  \"\"\"\n  Converts a set of rays from world space to normalized device coordinates (NDC) using a perspective projection model. This is useful for rendering or processing 3D scenes in a standardized coordinate system.\n\n  Input-Output Arguments\n  :param origins: ndarray(float32), The origins of the rays in world space, used to determine their starting points in NDC.\n  :param directions: ndarray(float32), The directions of the rays in world space, used to calculate their orientation in NDC.\n  :param pixtocam: ndarray(float32), The inverse intrinsic matrix of the camera, used for the perspective projection calculation.\n  :param near: float, The distance to the near plane along the negative z-axis, used to define the depth range of the projection.\n  :param xnp: module, Either numpy or jax.numpy, specifies the numerical library to use for calculations.\n  :return: Tuple of ndarray(float32), The origins and directions of the rays in normalized device coordinates.\n\n  This function performs a perspective projection of rays defined in world space into a normalized device coordinate system, assuming an identity extrinsic matrix (camera pose) and intrinsic parameters defined by the pixtocam matrix. The function adjusts ray origins to the near plane and calculates the corresponding directions in NDC, facilitating the rendering or analysis of 3D scenes from a standardized viewpoint.\n  \"\"\"\n  # Convert origins and directions to homogeneous coordinates.\n  origins_homogeneous = xnp.concatenate([origins, xnp.ones_like(origins[..., :1])], axis=-1)\n  directions_homogeneous = xnp.concatenate([directions, xnp.zeros_like(directions[..., :1])], axis=-1)\n\n  # Apply inverse intrinsic matrix to origins and directions.\n  origins_ndc = xnp.einsum('...ij,...j->...i', pixtocam, origins_homogeneous)\n  directions_ndc = xnp.einsum('...ij,...j->...i', pixtocam, directions_homogeneous)\n\n  # Adjust origins and directions to the near plane.\n  t = (near - origins_ndc[..., 2]) / directions_ndc[..., 2]\n  origins_ndc = origins_ndc + t[..., None] * directions_ndc\n\n  return origins_ndc, directions_ndc"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "    from scipy.interpolate import UnivariateSpline\n  from scipy.interpolate import UnivariateSpline\n\n  # Adjust the spline degree to be at most one less than the number of points in x\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Create a spline interpolation function\n  spline = UnivariateSpline(t_input, x, k=spline_degree, s=smoothness)\n\n  # Interpolate the signal at the specified output times\n  interpolated_values = spline(t_output)\n\n  return interpolated_values"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "        from scipy.interpolate import UnivariateSpline\n    from scipy.interpolate import UnivariateSpline\n    spline_degree = min(spline_degree, len(x) - 1)\n    spline = UnivariateSpline(t_input, x, k=spline_degree, s=smoothness)\n    return spline(t_output)"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  if spline_degree > len(x) - 1:\n    spline_degree = len(x) - 1\n  f = scipy.interpolate.UnivariateSpline(t_input, x, k=spline_degree, s=smoothness)\n  return f(t_output)"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n  return scipy.interpolate.splev(t_output, tck)"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Check if the input signal x is empty\n  if len(x) == 0:\n    raise ValueError(\"Input signal x is empty\")\n\n  # Check if the input times t_input and t_output are empty\n  if len(t_input) == 0 or len(t_output) == 0:\n    raise ValueError(\"Input or output times are empty\")\n\n  # Check if the length of input times t_input is not equal to the length of the input signal x\n  if len(t_input) != len(x):\n    raise ValueError(\"Length of input times t_input must be equal to the length of the input signal x\")\n\n  # Check if the spline degree is less than 1\n  if spline_degree < 1:\n    raise ValueError(\"Spline degree must be at least 1\")\n\n  # Check if the smoothness is less than 0\n  if smoothness < 0:\n    raise ValueError(\"Smoothness must be non-negative\")\n\n  # Check if the length of input times t_output is not equal to the length of the output signal\n  if len(t_output) != len(x):\n    raise ValueError(\"Length of output times t_output must be equal to the length of the input signal x\")\n\n  # Perform spline interpolation\n  interpolated_values = scipy.interpolate.UnivariateSpline(t_input, x, k=spline_degree, s=smoothness)(t_output)\n\n  return interpolated_values"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Check if the degree of the spline is greater than or equal to the number of points in x.\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Interpolate the 1-dimensional signal x at the specified output times t_output using spline interpolation.\n  interpolated_values = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n  return scipy.interpolate.splev(t_output, interpolated_values)"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Check if the spline degree is too high and adjust if necessary.\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Fit a spline to the input signal.\n  spline = scipy.interpolate.UnivariateSpline(t_input, x, k=spline_degree, s=smoothness)\n\n  # Interpolate the signal at the specified output times.\n  interpolated_values = spline(t_output)\n\n  return interpolated_values"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Check if the spline degree is too high for the number of points in x\n  if spline_degree >= len(x):\n    spline_degree = len(x) - 1\n  \n  # Create a 1D spline interpolation function\n  spline_func = scipy.interpolate.UnivariateSpline(t_input, x, k=spline_degree, s=smoothness)\n  \n  # Interpolate the signal at the specified output times\n  interpolated_values = spline_func(t_output)\n  \n  return interpolated_values"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Check if the input signal x is a scalar or a 1D array\n  if isinstance(x, (int, float)):\n    x = [x]\n  else:\n    x = x\n\n  # Adjust spline degree to be at most one less than the number of points in x\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Perform spline interpolation\n  f = scipy.interpolate.UnivariateSpline(t_input, x, k=spline_degree, s=smoothness)\n  interpolated_values = f(t_output)\n\n  return interpolated_values"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  if spline_degree > len(x) - 1:\n    spline_degree = len(x) - 1\n  tck = interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n  return interpolate.splev(t_output, tck)"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "    from scipy.interpolate import UnivariateSpline\n  from scipy.interpolate import UnivariateSpline\n  spline_degree = min(spline_degree, len(x) - 1)\n  spline = UnivariateSpline(t_input, x, k=spline_degree, s=smoothness)\n  return spline(t_output)"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "    if spline_degree >= len(x):\n        spline_degree = len(x) - 1\n    tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n    return scipy.interpolate.splev(t_output, tck)"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "    from scipy.interpolate import UnivariateSpline\n  from scipy.interpolate import UnivariateSpline\n  spline_degree = min(spline_degree, len(x) - 1)\n  spline = UnivariateSpline(t_input, x, k=spline_degree, s=smoothness)\n  return spline(t_output)"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "    from scipy.interpolate import UnivariateSpline\n  from scipy.interpolate import UnivariateSpline\n\n  # Ensure spline_degree is at most one less than the number of points in x\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Create a spline interpolation function\n  spline = UnivariateSpline(t_input, x, k=spline_degree, s=smoothness)\n\n  # Interpolate the signal at the specified output times\n  interpolated_values = spline(t_output)\n\n  return interpolated_values"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Adjust spline degree\n  spline_degree = min(spline_degree, len(x) - 1)\n  \n  # Spline interpolation\n  interpolated_values = scipy.interpolate.UnivariateSpline(t_input, x, k=spline_degree, s=smoothness)(t_output)\n  \n  return interpolated_values"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  if spline_degree >= len(x):\n    spline_degree = len(x) - 1\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n  return scipy.interpolate.splev(t_output, tck)"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "    from scipy.interpolate import UnivariateSpline\n  from scipy.interpolate import UnivariateSpline\n  spline_degree = min(spline_degree, len(x) - 1)\n  spline = UnivariateSpline(t_input, x, k=spline_degree, s=smoothness)\n  return spline(t_output)"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  tck = scipy.interpolate.splrep(t_input, x, k=min(spline_degree, len(x) - 1), s=smoothness)\n  return scipy.interpolate.splev(t_output, tck)"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  \"\"\"\n  Interpolates a 1-dimensional signal defined at certain input times and queries it at specified output times using spline interpolation of a given degree and smoothness.\n  Input-Output Arguments\n  :param x: Array-like. The 1-dimensional signal to be interpolated.\n  :param spline_degree: Integer. The degree of the spline used for interpolation. It is adjusted to be at most one less than the number of points in x.\n  :param smoothness: Float. A parameter controlling the smoothness of the spline fit. \n  :param t_input: Array-like. The times at which the signal x is defined.\n  :param t_output: Array-like. The times at which the interpolated signal is queried.\n  :return: Array-like. The interpolated values of the signal at t_output times.\n  \"\"\"\n  return scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)(t_output)"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  \"\"\"\n  Interpolates a 1-dimensional signal defined at certain input times and queries it at specified output times using spline interpolation of a given degree and smoothness.\n  Input-Output Arguments\n  :param x: Array-like. The 1-dimensional signal to be interpolated.\n  :param spline_degree: Integer. The degree of the spline used for interpolation. It is adjusted to be at most one less than the number of points in x.\n  :param smoothness: Float. A parameter controlling the smoothness of the spline fit. \n  :param t_input: Array-like. The times at which the signal x is defined.\n  :param t_output: Array-like. The times at which the interpolated signal is queried.\n  :return: Array-like. The interpolated values of the signal at t_output times.\n  \"\"\"\n  import scipy.interpolate\n  tck = scipy.interpolate.splrep(t_input, x, k=min(spline_degree, len(x) - 1), s=smoothness)\n  return scipy.interpolate.splev(t_output, tck)"}
{"namespace": "math.learning_rate_decay", "completion": "  if step < lr_delay_steps:\n    # Apply the delay multiplier to the initial learning rate\n    lr = lr_init * lr_delay_mult\n  else:\n    # Calculate the progress through the optimization process\n    progress = step / max_steps\n    # Use log-linear interpolation to decay the learning rate\n    lr = lr_init * jnp.exp(jnp.log(lr_final / lr_init) * progress)\n\n  return lr"}
{"namespace": "math.learning_rate_decay", "completion": "  if step < lr_delay_steps:\n    return lr_init * lr_delay_mult\n  else:\n    alpha = jnp.log(lr_final / lr_init) / max_steps\n    return lr_init * jnp.exp(alpha * (step - lr_delay_steps))"}
{"namespace": "math.learning_rate_decay", "completion": "    if step < lr_delay_steps:\n        # Apply the delayed learning rate with the specified multiplier\n        return lr_init * lr_delay_mult\n    else:\n        # Calculate the decayed learning rate using log-linear interpolation\n        alpha = step / max_steps\n        return lr_final + (lr_init - lr_final) * (1 - alpha)"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    lr_init = lr_init * lr_delay_mult\n    lr_init = lr_init + (lr_final - lr_init) * (step / lr_delay_steps)\n    lr_init = jnp.clip(lr_init, lr_final, lr_init)\n\n  alpha = jnp.log(lr_init / lr_final)\n  decay = jnp.exp(alpha * (step / max_steps))\n  lr = lr_init / decay\n  return jnp.maximum(lr, lr_final)"}
{"namespace": "math.learning_rate_decay", "completion": "  if step < lr_delay_steps:\n    return lr_init * lr_delay_mult\n  else:\n    alpha = jnp.log(lr_final / lr_init) / max_steps\n    return lr_init * jnp.exp(alpha * (step - lr_delay_steps))"}
{"namespace": "math.learning_rate_decay", "completion": "    if step < lr_delay_steps:\n        # Apply the delayed learning rate with the specified multiplier\n        return lr_init * lr_delay_mult\n    else:\n        # Calculate the progression of steps\n        progress = min(step / max_steps, 1)\n        # Calculate the learning rate using log-linear interpolation\n        return lr_init * (lr_final / lr_init) ** progress"}
{"namespace": "math.learning_rate_decay", "completion": "    if lr_delay_steps > 0:\n        lr_init = lr_init * lr_delay_mult * jnp.minimum(1.0, step / lr_delay_steps)\n    decay_factor = lr_final / lr_init\n    return lr_init * (decay_factor ** (step / max_steps))"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    lr_init = lr_init * lr_delay_mult\n    lr_init = lr_init + (lr_final - lr_init) * (step / lr_delay_steps)\n    lr_init = jnp.clip(lr_init, lr_final, lr_init)\n\n  alpha = jnp.log(lr_init / lr_final)\n  decayed_lr = lr_init * jnp.exp(-alpha * step / max_steps)\n  decayed_lr = jnp.maximum(lr_final, decayed_lr)\n\n  return decayed_lr"}
{"namespace": "math.learning_rate_decay", "completion": "    if step < lr_delay_steps:\n        # Apply the delayed learning rate with the multiplier\n        lr = lr_init * lr_delay_mult\n    else:\n        # Calculate the progression of steps\n        progress = min(step / max_steps, 1)\n        # Calculate the log-linear interpolation (exponential decay) of the learning rate\n        lr = lr_init * ((lr_final / lr_init) ** progress)\n    return lr"}
{"namespace": "math.learning_rate_decay", "completion": "  if step < lr_delay_steps:\n    return lr_init * lr_delay_mult\n  else:\n    return lr_final + (lr_init - lr_final) * jnp.exp(-5 * step / max_steps)"}
{"namespace": "math.learning_rate_decay", "completion": "    if step < lr_delay_steps:\n        return lr_init * (lr_delay_mult + (1 - lr_delay_mult) * step / lr_delay_steps)\n    else:\n        return lr_init * (lr_final / lr_init) ** (step / max_steps)"}
{"namespace": "math.learning_rate_decay", "completion": "  if step < lr_delay_steps:\n    return lr_init * lr_delay_mult\n  else:\n    alpha = jnp.log(lr_init / lr_final) / max_steps\n    return lr_final + (lr_init - lr_final) * jnp.exp(-alpha * step)"}
{"namespace": "math.learning_rate_decay", "completion": "\n  if step < lr_delay_steps:\n    # Apply the delayed learning rate with the specified multiplier\n    return lr_init * lr_delay_mult\n  else:\n    # Calculate the log-linear interpolation (exponential decay) between initial and final learning rates\n    alpha = step / max_steps\n    return lr_init * (lr_final / lr_init) ** alpha"}
{"namespace": "math.learning_rate_decay", "completion": "    if step < lr_delay_steps:\n        return lr_init * lr_delay_mult\n    else:\n        alpha = jnp.log(lr_final / lr_init) / max_steps\n        return lr_init * jnp.exp(alpha * (step - lr_delay_steps))"}
{"namespace": "math.learning_rate_decay", "completion": "  # Apply the delay to the initial learning rate\n  if step < lr_delay_steps:\n    lr_init = lr_init * lr_delay_mult\n\n  # Calculate the progression of the optimization step\n  progression = step / max_steps\n\n  # Calculate the learning rate using log-linear interpolation\n  lr = lr_final + (lr_init - lr_final) * jnp.exp(-5 * progression)\n\n  return lr"}
{"namespace": "math.learning_rate_decay", "completion": "    if step < lr_delay_steps:\n        # Apply the delayed learning rate with the multiplier\n        return lr_init * lr_delay_mult\n    else:\n        # Calculate the learning rate decay using log-linear interpolation\n        alpha = jnp.log(lr_init / lr_final) / max_steps\n        return lr_init * jnp.exp(-alpha * step)"}
{"namespace": "math.learning_rate_decay", "completion": "    if lr_delay_steps > 0:\n        lr_init = lr_init * lr_delay_mult * jnp.minimum(1.0, step / lr_delay_steps)\n\n    alpha = jnp.log(lr_final / lr_init) / max_steps\n    lr = lr_init * jnp.exp(alpha * step)\n    return jnp.maximum(lr, lr_final)"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0 and step < lr_delay_steps:\n    # Apply the delay multiplier to the initial learning rate and gradually return to the normal rate\n    lr = lr_init * lr_delay_mult + (lr_init - lr_init * lr_delay_mult) * (step / lr_delay_steps)\n  else:\n    # Calculate the learning rate using log-linear interpolation between initial and final learning rates\n    alpha = step / max_steps\n    lr = lr_init * (lr_final / lr_init) ** alpha\n\n  return lr"}
{"namespace": "math.learning_rate_decay", "completion": "    if lr_delay_steps > 0:\n        lr_init = lr_init * jnp.minimum(1.0, step / lr_delay_steps) * lr_delay_mult\n    return lr_final + (lr_init - lr_final) * jnp.exp(-step / max_steps)"}
{"namespace": "math.learning_rate_decay", "completion": "    if lr_delay_steps > 0 and step < lr_delay_steps:\n        # Apply delay with a scaled initial learning rate\n        return lr_init * lr_delay_mult\n    else:\n        # Calculate the learning rate using log-linear interpolation\n        alpha = step / max_steps\n        return lr_init * (lr_final / lr_init) ** alpha"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([\n      [fx, 0, cx],\n      [0, fy, cy],\n      [0, 0, 1]\n  ])"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([\n      [fx, 0, cx],\n      [0, fy, cy],\n      [0, 0, 1]\n  ])"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([\n      [fx, 0, cx],\n      [0, fy, cy],\n      [0, 0, 1]\n  ])"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([\n      [fx, 0, cx],\n      [0, fy, cy],\n      [0, 0, 1]\n  ])"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([\n      [fx, 0, cx],\n      [0, fy, cy],\n      [0, 0, 1]\n  ])"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([\n      [fx, 0, cx],\n      [0, fy, cy],\n      [0, 0, 1]\n  ])"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([\n      [fx, 0, cx],\n      [0, fy, cy],\n      [0, 0, 1]\n  ])"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([\n      [fx, 0, cx],\n      [0, fy, cy],\n      [0, 0, 1]\n  ])"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([\n      [fx, 0, cx],\n      [0, fy, cy],\n      [0, 0, 1]\n  ])"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([\n      [fx, 0, cx],\n      [0, fy, cy],\n      [0, 0, 1]\n  ])"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([\n      [fx, 0, cx],\n      [0, fy, cy],\n      [0, 0, 1]\n  ])"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([\n      [fx, 0, cx],\n      [0, fy, cy],\n      [0, 0, 1]\n  ])"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx],\n                    [0, fy, cy],\n                    [0, 0, 1]])"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  K = xnp.array([[fx, 0, cx],\n                 [0, fy, cy],\n                 [0, 0, 1]])\n  return K"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([\n      [fx, 0, cx],\n      [0, fy, cy],\n      [0, 0, 1]\n  ])"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx],\n                    [0, fy, cy],\n                    [0, 0, 1]])"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=jax.random.PRNGKey(0),\n      n=100,  # Specify the number of rays to generate\n      origin_lo=-1.0,\n      origin_hi=1.0,\n      radius_lo=0.1,\n      radius_hi=0.5,\n      near_lo=1.0,\n      near_hi=5.0,\n      far_lo=10.0,\n      far_hi=20.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )"}
{"namespace": "utils.dummy_rays", "completion": "  # Utilize the predefined function to generate random rays\n  return generate_random_rays(\n      rng=random.PRNGKey(0),  # Use a fixed RNG key for reproducibility\n      n=100,  # Number of rays to generate\n      origin_lo=-1.0,  # Lower bound for ray origins\n      origin_hi=1.0,  # Upper bound for ray origins\n      radius_lo=0.1,  # Lower bound for ray radii\n      radius_hi=0.5,  # Upper bound for ray radii\n      near_lo=0.1,  # Lower bound for near plane\n      near_hi=1.0,  # Upper bound for near plane\n      far_lo=2.0,  # Lower bound for far plane\n      far_hi=5.0,  # Upper bound for far plane\n      include_exposure_idx=include_exposure_idx,  # Include exposure index based on input\n      include_exposure_values=include_exposure_values,  # Include exposure values based on input\n      include_device_idx=include_device_idx,  # Include device index based on input\n  )"}
{"namespace": "utils.dummy_rays", "completion": "  rng = jax.random.PRNGKey(0)\n  n = 100  # Example number of rays\n  origin_lo = 0\n  origin_hi = 1\n  radius_lo = 0.1\n  radius_hi = 0.5\n  near_lo = 0.1\n  near_hi = 0.5\n  far_lo = 1.0\n  far_hi = 2.0\n\n  random_rays = generate_random_rays(\n      rng,\n      n,\n      origin_lo,\n      origin_hi,\n      radius_lo,\n      radius_hi,\n      near_lo,\n      near_hi,\n      far_lo,\n      far_hi,\n      include_exposure_idx,\n      include_exposure_values,\n      include_device_idx,\n  )\n  return random_rays"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=100,\n      origin_lo=0,\n      origin_hi=1,\n      radius_lo=0,\n      radius_hi=1,\n      near_lo=0,\n      near_hi=1,\n      far_lo=1,\n      far_hi=10,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )"}
{"namespace": "utils.dummy_rays", "completion": "  rng = jax.random.PRNGKey(0)\n  n = 100  # Number of random rays\n  origin_lo = 0\n  origin_hi = 1\n  radius_lo = 0.1\n  radius_hi = 0.5\n  near_lo = 0.1\n  near_hi = 1.0\n  far_lo = 1.0\n  far_hi = 10.0\n\n  return generate_random_rays(\n      rng,\n      n,\n      origin_lo,\n      origin_hi,\n      radius_lo,\n      radius_hi,\n      near_lo,\n      near_hi,\n      far_lo,\n      far_hi,\n      include_exposure_idx,\n      include_exposure_values,\n      include_device_idx,\n  )"}
{"namespace": "utils.dummy_rays", "completion": "  rng = jax.random.PRNGKey(0)  # Initialize a random number generator\n  n = 100  # Number of rays to generate\n  origin_lo = 0.0\n  origin_hi = 1.0\n  radius_lo = 0.1\n  radius_hi = 0.5\n  near_lo = 0.1\n  near_hi = 1.0\n  far_lo = 5.0\n  far_hi = 10.0\n\n  # Generate random rays using the predefined function\n  random_rays = generate_random_rays(\n      rng,\n      n,\n      origin_lo,\n      origin_hi,\n      radius_lo,\n      radius_hi,\n      near_lo,\n      near_hi,\n      far_lo,\n      far_hi,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n  \n  return random_rays"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=100,\n      origin_lo=0,\n      origin_hi=1,\n      radius_lo=0.1,\n      radius_hi=0.5,\n      near_lo=0.1,\n      near_hi=1.0,\n      far_lo=1.0,\n      far_hi=5.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )"}
{"namespace": "utils.dummy_rays", "completion": "  rng = jax.random.PRNGKey(0)\n  n = 100  # Number of rays\n  origin_lo = 0.0\n  origin_hi = 1.0\n  radius_lo = 0.1\n  radius_hi = 0.5\n  near_lo = 0.1\n  near_hi = 1.0\n  far_lo = 1.0\n  far_hi = 10.0\n\n  return generate_random_rays(\n      rng,\n      n,\n      origin_lo,\n      origin_hi,\n      radius_lo,\n      radius_hi,\n      near_lo,\n      near_hi,\n      far_lo,\n      far_hi,\n      include_exposure_idx,\n      include_exposure_values,\n      include_device_idx,\n  )"}
{"namespace": "utils.dummy_rays", "completion": "  rng = jax.random.PRNGKey(0)\n  n = 100  # Number of random rays\n  origin_lo = 0\n  origin_hi = 1\n  radius_lo = 0\n  radius_hi = 1\n  near_lo = 0\n  near_hi = 1\n  far_lo = 1\n  far_hi = 10\n\n  return generate_random_rays(\n      rng,\n      n,\n      origin_lo,\n      origin_hi,\n      radius_lo,\n      radius_hi,\n      near_lo,\n      near_hi,\n      far_lo,\n      far_hi,\n      include_exposure_idx,\n      include_exposure_values,\n      include_device_idx,\n  )"}
{"namespace": "utils.dummy_rays", "completion": "  # Utilize the predefined function to create random rays based on the input conditions\n  return generate_random_rays(\n      rng=random.PRNGKey(0),  # Use a fixed PRNGKey for reproducibility\n      n=100,  # Number of random rays to generate\n      origin_lo=-1.0,\n      origin_hi=1.0,\n      radius_lo=0.1,\n      radius_hi=0.5,\n      near_lo=0.1,\n      near_hi=1.0,\n      far_lo=2.0,\n      far_hi=5.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )"}
{"namespace": "utils.dummy_rays", "completion": "  # Utilize the predefined function to generate random rays\n  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=100,  # Specify the number of rays\n      origin_lo=0.0,\n      origin_hi=1.0,\n      radius_lo=0.1,\n      radius_hi=0.5,\n      near_lo=0.1,\n      near_hi=1.0,\n      far_lo=1.0,\n      far_hi=10.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )"}
{"namespace": "utils.dummy_rays", "completion": "  # Utilize the predefined function to create random rays\n  return generate_random_rays(\n      random.PRNGKey(0),  # Use a fixed PRNGKey for consistency\n      n=100,  # Number of random rays to generate\n      origin_lo=0.0,  # Lower bound for ray origins\n      origin_hi=1.0,  # Upper bound for ray origins\n      radius_lo=0.1,  # Lower bound for ray radii\n      radius_hi=0.5,  # Upper bound for ray radii\n      near_lo=0.1,  # Lower bound for near plane\n      near_hi=1.0,  # Upper bound for near plane\n      far_lo=2.0,  # Lower bound for far plane\n      far_hi=5.0,  # Upper bound for far plane\n      include_exposure_idx=include_exposure_idx,  # Include exposure index based on input\n      include_exposure_values=include_exposure_values,  # Include exposure values based on input\n      include_device_idx=include_device_idx,  # Include device index based on input\n  )"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      random.PRNGKey(0),\n      n=100,\n      origin_lo=0,\n      origin_hi=1,\n      radius_lo=0.1,\n      radius_hi=0.5,\n      near_lo=0.1,\n      near_hi=1.0,\n      far_lo=1.0,\n      far_hi=10.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )"}
{"namespace": "utils.dummy_rays", "completion": "  rng = jax.random.PRNGKey(0)\n  n = 100  # Example value, can be adjusted\n  origin_lo = 0.0  # Example value, can be adjusted\n  origin_hi = 1.0  # Example value, can be adjusted\n  radius_lo = 0.1  # Example value, can be adjusted\n  radius_hi = 0.5  # Example value, can be adjusted\n  near_lo = 0.1  # Example value, can be adjusted\n  near_hi = 1.0  # Example value, can be adjusted\n  far_lo = 10.0  # Example value, can be adjusted\n  far_hi = 20.0  # Example value, can be adjusted\n\n  return generate_random_rays(\n      rng,\n      n,\n      origin_lo,\n      origin_hi,\n      radius_lo,\n      radius_hi,\n      near_lo,\n      near_hi,\n      far_lo,\n      far_hi,\n      include_exposure_idx,\n      include_exposure_values,\n      include_device_idx,\n  )"}
{"namespace": "utils.dummy_rays", "completion": "  rng = jax.random.PRNGKey(0)  # Initialize random number generator\n  n = 100  # Number of rays to generate\n  origin_lo = 0.0  # Lower bound for ray origins\n  origin_hi = 1.0  # Upper bound for ray origins\n  radius_lo = 0.1  # Lower bound for ray radii\n  radius_hi = 0.5  # Upper bound for ray radii\n  near_lo = 0.1  # Lower bound for near plane\n  near_hi = 1.0  # Upper bound for near plane\n  far_lo = 10.0  # Lower bound for far plane\n  far_hi = 100.0  # Upper bound for far plane\n\n  return generate_random_rays(\n      rng,\n      n,\n      origin_lo,\n      origin_hi,\n      radius_lo,\n      radius_hi,\n      near_lo,\n      near_hi,\n      far_lo,\n      far_hi,\n      include_exposure_idx,\n      include_exposure_values,\n      include_device_idx,\n  )"}
{"namespace": "utils.dummy_rays", "completion": "  # Utilize the predefined function to generate random rays\n  return generate_random_rays(\n      rng=random.PRNGKey(0),  # Example PRNG key, replace with appropriate key\n      n=100,  # Example number of rays, replace with desired number\n      origin_lo=0.0,  # Example lower bound for ray origins, replace with desired value\n      origin_hi=1.0,  # Example upper bound for ray origins, replace with desired value\n      radius_lo=0.1,  # Example lower bound for ray radii, replace with desired value\n      radius_hi=0.5,  # Example upper bound for ray radii, replace with desired value\n      near_lo=0.1,  # Example lower bound for near plane, replace with desired value\n      near_hi=1.0,  # Example upper bound for near plane, replace with desired value\n      far_lo=5.0,  # Example lower bound for far plane, replace with desired value\n      far_hi=10.0,  # Example upper bound for far plane, replace with desired value\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )"}
{"namespace": "utils.dummy_rays", "completion": "  rng = jax.random.PRNGKey(0)\n  n = 100  # Number of rays\n  origin_lo = 0.0\n  origin_hi = 1.0\n  radius_lo = 0.1\n  radius_hi = 0.5\n  near_lo = 0.1\n  near_hi = 1.0\n  far_lo = 2.0\n  far_hi = 3.0\n\n  return generate_random_rays(\n      rng,\n      n,\n      origin_lo,\n      origin_hi,\n      radius_lo,\n      radius_hi,\n      near_lo,\n      near_hi,\n      far_lo,\n      far_hi,\n      include_exposure_idx,\n      include_exposure_values,\n      include_device_idx,\n  )"}
{"namespace": "utils.dummy_rays", "completion": "  rng = jax.random.PRNGKey(0)\n  n = 100  # Example value, can be adjusted\n  origin_lo = 0  # Example value, can be adjusted\n  origin_hi = 1  # Example value, can be adjusted\n  radius_lo = 0  # Example value, can be adjusted\n  radius_hi = 1  # Example value, can be adjusted\n  near_lo = 0  # Example value, can be adjusted\n  near_hi = 1  # Example value, can be adjusted\n  far_lo = 1  # Example value, can be adjusted\n  far_hi = 10  # Example value, can be adjusted\n\n  return generate_random_rays(\n      rng,\n      n,\n      origin_lo,\n      origin_hi,\n      radius_lo,\n      radius_hi,\n      near_lo,\n      near_hi,\n      far_lo,\n      far_hi,\n      include_exposure_idx,\n      include_exposure_values,\n      include_device_idx,\n  )"}
{"namespace": "utils.dummy_rays", "completion": "  rng = jax.random.PRNGKey(0)\n  n = 100  # Number of rays to generate\n  origin_lo = 0.0\n  origin_hi = 1.0\n  radius_lo = 0.1\n  radius_hi = 0.5\n  near_lo = 0.1\n  near_hi = 1.0\n  far_lo = 1.0\n  far_hi = 10.0\n\n  return generate_random_rays(\n      rng,\n      n,\n      origin_lo,\n      origin_hi,\n      radius_lo,\n      radius_hi,\n      near_lo,\n      near_hi,\n      far_lo,\n      far_hi,\n      include_exposure_idx,\n      include_exposure_values,\n      include_device_idx,\n  )"}
{"namespace": "utils.dummy_rays", "completion": "  rng = jax.random.PRNGKey(0)\n  n = 100  # Number of rays\n  origin_lo = 0.0\n  origin_hi = 1.0\n  radius_lo = 0.1\n  radius_hi = 0.5\n  near_lo = 0.1\n  near_hi = 0.5\n  far_lo = 1.0\n  far_hi = 10.0\n\n  return generate_random_rays(\n      rng,\n      n,\n      origin_lo,\n      origin_hi,\n      radius_lo,\n      radius_hi,\n      near_lo,\n      near_hi,\n      far_lo,\n      far_hi,\n      include_exposure_idx,\n      include_exposure_values,\n      include_device_idx,\n  )"}
{"namespace": "camera_utils.points_to_pixels", "completion": "\n  # Apply extrinsic matrices.\n  camera_points = spin_math.matmul(camtoworlds, points[..., None])[..., 0]\n\n  # Apply inverse intrinsic matrices.\n  pixel_coords = spin_math.matmul(pixtocams, camera_points[..., None])[..., 0]\n\n  if distortion_params is not None:\n    # Apply distortion parameters.\n    x, y = _radial_and_tangential_distort(\n        pixel_coords[Ellipsis, 0],\n        pixel_coords[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    pixel_coords = xnp.stack([x, y], axis=-1)\n\n  if camtype == ProjectionType.FISHEYE:\n    # Normalize the pixel coordinates for fisheye projection.\n    pixel_coords = xnp.stack(\n        [\n            pixel_coords[Ellipsis, 0] / pixel_coords[Ellipsis, 2],\n            pixel_coords[Ellipsis, 1] / pixel_coords[Ellipsis, 2],\n        ],\n        axis=-1,\n    )\n\n  depth = pixel_coords[Ellipsis, 2]"}
{"namespace": "camera_utils.points_to_pixels", "completion": "\n  # Transform points to camera coordinates.\n  camera_points = xnp.matmul(camtoworlds, points[..., None])[..., :3, 0]\n\n  # Project the camera points onto the image plane.\n  projected_points = xnp.matmul(pixtocams, camera_points[..., None])[..., :2, 0]\n\n  # Apply distortion correction if distortion parameters are provided.\n  if distortion_params is not None:\n    k1 = distortion_params.get('k1', 0)\n    k2 = distortion_params.get('k2', 0)\n    k3 = distortion_params.get('k3', 0)\n    k4 = distortion_params.get('k4', 0)\n    p1 = distortion_params.get('p1', 0)\n    p2 = distortion_params.get('p2', 0)\n\n    x, y = projected_points[..., 0], projected_points[..., 1]\n    x, y = _radial_and_tangential_distort(x, y, k1, k2, k3, k4, p1, p2)\n    projected_points = xnp.stack"}
{"namespace": "camera_utils.points_to_pixels", "completion": "\n  # Project 3D points to 2D pixel coordinates\n  pixel_coordinates = xnp.matmul(pixtocams, xnp.matmul(camtoworlds, xnp.concatenate([points, xnp.ones((points.shape[0], 1))], axis=1).T)).T\n  pixel_coordinates = pixel_coordinates[:, :2] / pixel_coordinates[:, 2, None]\n\n  # Calculate depth values\n  depth = pixel_coordinates[:, 2]\n\n  return pixel_coordinates, depth"}
{"namespace": "camera_utils.points_to_pixels", "completion": "\n  # Apply camera rotation matrices.\n  points = jnp.array(points)\n  camera_points = jax.vmap(spin_math.matmul)(camtoworlds, points)\n\n  # Compute rays from camera points.\n  origins, directions, _, _ = pixels_to_rays(\n      camera_points[Ellipsis, 0],\n      camera_points[Ellipsis, 1],\n      pixtocams,\n      camtoworlds,\n      distortion_params=distortion_params,\n      camtype=camtype,\n      xnp=xnp,\n  )\n\n  # Calculate intersection of rays with z=0 plane to get pixel coordinates.\n  t = -origins[Ellipsis, 2] / directions[Ellipsis, 2]\n  coordinates = origins + t[..., None] * directions\n  depth = t\n\n  return coordinates, depth"}
{"namespace": "camera_utils.points_to_pixels", "completion": "\n  # Apply camera rotation matrices.\n  world_to_cam = jnp.linalg.inv(camtoworlds)\n  camera_points = jnp.dot(points, world_to_cam[:, :3].T) + world_to_cam[:, 3]\n\n  # Apply inverse intrinsic matrices.\n  pixel_coords = jnp.dot(camera_points, pixtocams.T)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_distort(\n        pixel_coords[:, 0],\n        pixel_coords[:, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    pixel_coords = jnp.stack([x, y], axis=-1)\n\n  # Convert to pixel coordinates.\n  image_coords = pixel_coords[:, :2] / pixel_coords[:, 2, None]\n\n  return image_coords, pixel_coords[:, 2]"}
{"namespace": "camera_utils.points_to_pixels", "completion": "\n  # Apply camera rotation matrices.\n  camera_points = jax.vmap(spin_math.matmul)(\n      camtoworlds[Ellipsis, :3, :3], points\n  )\n  camera_points = camera_points + camtoworlds[Ellipsis, :3, 3:4]\n\n  # Compute the projected 2D pixel coordinates.\n  projected_points = jax.vmap(spin_math.matmul)(\n      pixtocams, camera_points\n  )\n  projected_points = projected_points / projected_points[..., 2:3]\n\n  # Apply distortion correction if distortion parameters are provided.\n  if distortion_params is not None:\n    x, y = _radial_and_tangential_distort(\n        projected_points[Ellipsis, 0],\n        projected_points[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    projected_points = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  return projected_points[Ellipsis, :2], camera_points[Ellipsis, 2]"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Apply camera extrinsics.\n  points = jax.vmap(spin_math.matmul)(\n      camtoworlds[Ellipsis, :3, :3], points[..., None]\n  )\n  points = points[..., :3, 0]\n\n  # Apply inverse intrinsic matrices.\n  camera_coords = jax.vmap(spin_math.matmul)(\n      pixtocams, points[..., None]\n  )\n  camera_coords = camera_coords[..., :2, 0] / camera_coords[..., 2, None]\n\n  # Correct for distortion.\n  if distortion_params is not None:\n    k1 = distortion_params.get('k1', 0)\n    k2 = distortion_params.get('k2', 0)\n    k3 = distortion_params.get('k3', 0)\n    k4 = distortion_params.get('k4', 0)\n    p1 = distortion_params.get('p1', 0)\n    p2 = distortion_params.get('p2', 0)\n    x, y = _radial_and_tangential_distort(\n        camera_coords[..., 0], camera_coords[..., 1"}
{"namespace": "camera_utils.points_to_pixels", "completion": "\n  # Apply extrinsic matrices to points.\n  points_cam = jnp.matmul(camtoworlds, jnp.concatenate([points, jnp.ones_like(points[..., :1])], axis=-1)[..., None])[..., :3]\n  \n  # Apply inverse intrinsic matrices to obtain pixel coordinates.\n  pixel_coords = jnp.matmul(pixtocams, jnp.concatenate([points_cam, jnp.ones_like(points_cam[..., :1])], axis=-1)[..., None])[..., :2]\n\n  # Apply distortion correction if distortion parameters are provided.\n  if distortion_params:\n    k1, k2, p1, p2 = distortion_params['k1'], distortion_params['k2'], distortion_params['p1'], distortion_params['p2']\n    x, y = pixel_coords[..., 0], pixel_coords[..., 1]\n    r2 = x**2 + y**2\n    x_dist = x * (1 + k1 * r2 + k2 * r2**2 + k3 * r2**3) + 2*p1*x*y + p2*(r2 + "}
{"namespace": "camera_utils.points_to_pixels", "completion": "\n  # Apply camera extrinsics.\n  world_to_cam = jnp.linalg.inv(camtoworlds)\n  camera_points = jax.vmap(spin_math.matmul)(\n      world_to_cam, points\n  )\n\n  # Apply camera intrinsics.\n  if distortion_params is not None:\n    # Correct for distortion.\n    camera_points = camera_points[Ellipsis, :3] / camera_points[Ellipsis, 2, None]\n    x, y = camera_points[Ellipsis, 0], camera_points[Ellipsis, 1]\n    x, y = _radial_and_tangential_distort(\n        x, y, **distortion_params\n    )\n    camera_points = xnp.stack([x, y, xnp.ones_like(x)], axis=-1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.arctan2(camera_points[Ellipsis, 1], camera_points[Ellipsis, 0])\n    phi = xnp.arctan2(camera_points[Ellipsis, 2], xnp.sqrt(camera_points[Ellipsis, 0"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Apply camera rotation matrices.\n  camera_points = jax.vmap(spin_math.matmul)(\n      camtoworlds, points\n  )\n  camera_points = camera_points[Ellipsis, :3]\n  \n  # Project points to the image plane.\n  projected_points = jax.vmap(spin_math.matmul)(\n      pixtocams, camera_points\n  )\n  projected_points = projected_points[Ellipsis, :2] / projected_points[Ellipsis, 2, None]\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_distort(\n        projected_points[Ellipsis, 0],\n        projected_points[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    projected_points = xnp.stack([x, y], -1)\n\n  return projected_points, camera_points[..., 2]"}
{"namespace": "camera_utils.points_to_pixels", "completion": "\n  # Apply camera extrinsics to the points.\n  points = jax.vmap(spin_math.matmul)(camtoworlds, points)\n\n  # Apply inverse intrinsic matrices to transform points into pixel coordinates.\n  pixel_coords = jax.vmap(spin_math.matmul)(pixtocams, points)\n\n  # Normalize pixel coordinates by their depth values to get the final 2D pixel coordinates.\n  coordinates = pixel_coords[:, :2] / pixel_coords[:, 2:3]\n\n  # Compute depth values of the points in the camera coordinate system.\n  depth = pixel_coords[:, 2]\n\n  return coordinates, depth"}
{"namespace": "camera_utils.points_to_pixels", "completion": "\n  # Apply camera extrinsics to points to transform them into camera coordinates\n  cam_points = jax.vmap(spin_math.matmul)(camtoworlds, points)\n\n  # Apply inverse camera intrinsics to transform points from camera coordinates to pixel coordinates\n  pix_points = jax.vmap(spin_math.matmul)(pixtocams, cam_points)\n\n  # Normalize the pixel coordinates by the depth value to get the 2D pixel coordinates\n  coordinates = pix_points[..., :2] / pix_points[..., 2:3]\n\n  # Compute the depth values of the points in the camera coordinate system\n  depth = jnp.linalg.norm(cam_points, axis=-1)\n\n  return coordinates, depth"}
{"namespace": "camera_utils.points_to_pixels", "completion": "\n  # Apply camera rotation matrices.\n  world_to_cam = jnp.linalg.inv(camtoworlds)\n  camera_points = spin_math.matmul(world_to_cam, points[..., None])[..., 0]\n\n  # Compute rays from camera coordinates.\n  origins = jnp.zeros_like(camera_points)\n  directions = camera_points\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_distort(\n        camera_points[Ellipsis, 0],\n        camera_points[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_points = jnp.stack([x, y, camera_points[Ellipsis, 2]], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = jnp.sqrt(jnp.sum(jnp.square(camera_points[Ellipsis, :2]), axis=-1))\n    theta = jnp.minimum(jnp.pi, theta)\n\n    sin_theta_over_theta = jnp.sin(theta) / theta\n    camera_points = jnp.stack(\n        [\n            camera_points[Ell"}
{"namespace": "camera_utils.points_to_pixels", "completion": "\n  # Apply camera extrinsics.\n  points_cam = spin_math.matmul(camtoworlds, points[..., None])[..., 0]\n\n  # Apply camera intrinsics.\n  points_pix = spin_math.matmul(pixtocams, points_cam)\n\n  # Apply distortion correction if distortion parameters are provided.\n  if distortion_params is not None:\n    points_x, points_y = _radial_and_tangential_distort(\n        points_pix[Ellipsis, 0],\n        points_pix[Ellipsis, 1],\n        **distortion_params,\n    )\n    points_pix = xnp.stack([points_x, points_y], axis=-1)\n\n  # Convert to homogeneous coordinates.\n  points_pix_homogeneous = xnp.concatenate([points_pix, xnp.ones_like(points_pix[..., :1])], axis=-1)\n\n  # Normalize by the z coordinate to obtain pixel coordinates.\n  coordinates = points_pix_homogeneous[Ellipsis, :2] / points_pix_homogeneous[Ellipsis, 2:3]\n\n  return coordinates, points_cam[Ellipsis, 2]"}
{"namespace": "camera_utils.points_to_pixels", "completion": "\n  # Apply camera rotation matrices.\n  world_to_cam = jnp.linalg.inv(camtoworlds)\n  camera_points = jnp.matmul(world_to_cam, jnp.concatenate([points, jnp.ones((points.shape[0], 1))], axis=-1).T).T\n  camera_points = camera_points[..., :3]\n\n  # Project points to pixel coordinates.\n  pixel_coordinates = jnp.matmul(pixtocams, camera_points.T).T\n  pixel_coordinates = pixel_coordinates / pixel_coordinates[..., 2:3]\n\n  # Apply distortion parameters if available.\n  if distortion_params is not None:\n    k1, k2, k3, k4 = distortion_params['k1'], distortion_params['k2'], distortion_params['k3'], distortion_params['k4']\n    p1, p2 = distortion_params['p1'], distortion_params['p2']\n    x, y = pixel_coordinates[..., 0], pixel_coordinates[..., 1]\n    r2 = x**2 + y**2\n    radial_distortion = 1 + k1 * r2 + k2 * r"}
{"namespace": "camera_utils.points_to_pixels", "completion": "\n  # Apply camera extrinsics.\n  points_cam = spin_math.matmul(camtoworlds, points[..., None])[..., 0]\n\n  # Apply inverse intrinsic matrices.\n  points_pix = spin_math.matmul(pixtocams, points_cam[..., None])[..., 0]\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_distort(\n        points_pix[..., 0],\n        points_pix[..., 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    points_pix = xnp.stack([x, y], axis=-1)\n\n  # Convert to homogeneous 2D pixel coordinates.\n  points_pix_hom = xnp.concatenate([points_pix, xnp.ones_like(points_pix[..., 0:1])], axis=-1)\n\n  # Extract 2D pixel coordinates.\n  coordinates = points_pix_hom[..., :2]\n\n  # Compute depth values.\n  depth = points_cam[..., 2]\n\n  return coordinates, depth"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Shift the points to the camera coordinate system.\n  cam_points = jax.vmap(spin_math.matmul)(camtoworlds, points)\n\n  # Apply inverse intrinsic matrices to transform points to pixel coordinates.\n  pixel_coords = jax.vmap(spin_math.matmul)(pixtocams, cam_points)\n\n  # Normalize the pixel coordinates by the z-component to obtain the depth values.\n  depth = pixel_coords[Ellipsis, 2]\n  normalized_coords = pixel_coords / depth[..., None]\n\n  # Apply lens distortion correction if distortion parameters are provided.\n  if distortion_params is not None:\n    x, y = normalized_coords[..., 0], normalized_coords[..., 1]\n    x, y = _radial_and_tangential_distort(\n        x, y, **distortion_params\n    )\n    normalized_coords = xnp.stack([x, y, xnp.ones_like(x)], axis=-1)\n\n  # Compute the 2D pixel coordinates by removing the z-component.\n  coordinates = normalized_coords[..., :2]\n\n  return coordinates, depth"}
{"namespace": "camera_utils.points_to_pixels", "completion": "\n  # Calculate 2D pixel coordinates from 3D points.\n  pixel_coords = xnp.matmul(pixtocams, xnp.matmul(camtoworlds, xnp.concatenate([points, xnp.ones((points.shape[0], 1))], axis=1).T))\n  pixel_coords = pixel_coords[:2] / pixel_coords[2]\n\n  # Apply distortion correction if distortion parameters are provided.\n  if distortion_params is not None:\n    k1, k2, k3, p1, p2 = distortion_params['k1'], distortion_params['k2'], distortion_params['k3'], distortion_params['p1'], distortion_params['p2']\n    x, y = pixel_coords[0], pixel_coords[1]\n    r2 = x**2 + y**2\n    x = x * (1 + k1 * r2 + k2 * r2**2 + k3 * r2**3) + 2 * p1 * x * y + p2 * (r2 + 2 * x**2)\n    y = y * (1 +"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  \"\"\"\n  This function calculates the 2D pixel coordinates and depth values from 3D point coordinates using camera intrinsics, extrinsics, and optionally distortion parameters. It supports vectorized operations over the leading dimensions of the input arrays and can work with either numpy or jax.numpy for computations.\n\n  Input-Output Arguments\n  :param points: float array, 3D coordinates of points to project. These are the world coordinates that need to be projected onto the 2D image plane.\n  :param pixtocams: float array, inverse of the camera intrinsics matrices. These are used to transform points from pixel coordinates to camera coordinates.\n  :param camtoworlds: float array, camera extrinsics matrices. These describe the position and orientation of the camera in the world coordinate system.\n  :param distortion_params: dict of floats or float arrays, optional. These parameters are used to model the camera lens distortion. If provided, the function will correct for radial and tangential distortion.\n  :param camtype: camera_utils.ProjectionType, specifies the type of camera projection model to use. Currently, only perspective projection is supported.\n  :param xnp: module, either numpy or jax.numpy. This parameter allows the function to be used for computations on different devices (CPU or GPU/TPU).\n  :return: A tuple containing two elements:\n           coordinates: float array, the computed 2D pixel coordinates of the input 3D points.\n           depth: float array, the depth values of the points in the camera coordinate system, useful for depth-aware applications.\n  \"\"\"\n\n  # Apply camera rotation matrices.\n  cam_points = spin_math.matmul(camtoworlds, points[..., None])[..., 0]\n\n  # Compute pixel coordinates from camera coordinates.\n  pix_coords = spin_math.matmul(pixtocams, cam_points)\n\n  # Normalize pixel coordinates by the z-coordinate to get the depth.\n  depth = pix_coords[Ellipsis, 2]\n  pix_coords = pix_coords[Ellipsis, :2] / depth[..., None]\n\n  if distortion_params is not None:\n    # Correct for radial and tangential distortion.\n    pix_coords = jaxcam.correct_distortion(\n        pix_coords, distortion_params, camtype, xnp=xnp\n    )\n\n  return pix_coords, depth"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  \"\"\"\n  This function calculates the 2D pixel coordinates and depth values from 3D point coordinates using camera intrinsics, extrinsics, and optionally distortion parameters. It supports vectorized operations over the leading dimensions of the input arrays and can work with either numpy or jax.numpy for computations.\n\n  Input-Output Arguments\n  :param points: float array, 3D coordinates of points to project. These are the world coordinates that need to be projected onto the 2D image plane.\n  :param pixtocams: float array, inverse of the camera intrinsics matrices. These are used to transform points from pixel coordinates to camera coordinates.\n  :param camtoworlds: float array, camera extrinsics matrices. These describe the position and orientation of the camera in the world coordinate system.\n  :param distortion_params: dict of floats or float arrays, optional. These parameters are used to model the camera lens distortion. If provided, the function will correct for radial and tangential distortion.\n  :param camtype: camera_utils.ProjectionType, specifies the type of camera projection model to use. Currently, only perspective projection is supported.\n  :param xnp: module, either numpy or jax.numpy. This parameter allows the function to be used for computations on different devices (CPU or GPU/TPU).\n  :return: A tuple containing two elements:\n           coordinates: float array, the computed 2D pixel coordinates of the input 3D points.\n           depth: float array, the depth values of the points in the camera coordinate system, useful for depth-aware applications.\n  \"\"\"\n\n  # Apply camera rotation matrices.\n  world_to_cam = jnp.linalg.inv(camtoworlds)\n  camera_points = jax.vmap(spin_math.matmul)(world_to_cam, points)\n\n  # Compute pixel coordinates from camera coordinates.\n  pixel_coords = mat_vec_mul(pixtocams, camera_points)\n  pixel_coords = xnp.divide(pixel_coords[:, :2], pixel_coords[:, 2:])\n\n  # Apply distortion correction if distortion parameters are provided.\n  if distortion_params is not None:\n    k1, k2, k3, k4 = 0.0, 0.0, 0.0, 0.0\n    p1, p2 = 0.0, 0.0\n    if 'k1' in distortion_params:\n      k1 = distortion_params['k1']\n    if 'k2' in distortion_params:\n      k2 = distortion_params['k2']\n    if 'k3' in distortion_params:\n      k3 = distortion_params['k3']\n    if 'k4' in distortion_params:\n      k4 = distortion_params['k4']\n    if 'p1' in distortion_params:\n      p1 = distortion_params['p1']\n    if 'p2' in distortion_params:\n      p2 = distortion_params['p2']"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    retrieval_funcs = [evaluate_one_query_expansion_node] * len(modules)\n    retrieval_params = make_retrieval_callable_params(strategies)\n    expanded_queries = list(map(lambda module: module(previous_result['queries']), modules))\n    retrieval_gt = previous_result['retrieval_gt']\n    metrics = strategies['metrics']\n    project_dir = pathlib.Path(node_line_dir)\n    \n    best_result = evaluate_one_query_expansion_node(retrieval_funcs, retrieval_params, expanded_queries, retrieval_gt, metrics, project_dir, previous_result)\n    \n    return best_result"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    retrieval_funcs = [evaluate_one_query_expansion_node] * len(modules)\n    retrieval_params = make_retrieval_callable_params(strategies)\n\n    expanded_queries = list(map(lambda module: module(previous_result['queries'], **module_params),\n                                modules))\n    retrieval_gt = previous_result['queries']\n    metrics = strategies['metrics']\n\n    return evaluate_one_query_expansion_node(retrieval_funcs, retrieval_params, expanded_queries, retrieval_gt, metrics, node_line_dir, previous_result)"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    retrieval_funcs = [evaluate_one_query_expansion_node]\n    retrieval_params = make_retrieval_callable_params(strategies)\n    expanded_queries = previous_result['queries']\n    retrieval_gt = previous_result['retrieval_gt']\n    metrics = strategies['metrics']\n    project_dir = node_line_dir\n\n    best_result = evaluate_one_query_expansion_node(retrieval_funcs, retrieval_params, expanded_queries, retrieval_gt, metrics, project_dir, previous_result)\n\n    return best_result"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    retrieval_funcs = [evaluate_one_query_expansion_node] * len(modules)\n    retrieval_params = make_retrieval_callable_params(strategies)\n    expanded_queries = list(map(lambda module: module(previous_result), modules))\n    retrieval_gt = previous_result['retrieval_gt']\n    metrics = strategies['metrics']\n    project_dir = pathlib.Path(node_line_dir)\n    return evaluate_one_query_expansion_node(retrieval_funcs, retrieval_params, expanded_queries, retrieval_gt, metrics, project_dir, previous_result)"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    retrieval_funcs = [evaluate_one_query_expansion_node]\n    retrieval_params = make_retrieval_callable_params(strategies)\n\n    expanded_queries = previous_result['queries'].tolist()\n    retrieval_gt = previous_result['retrieval_gt'].tolist()\n    metrics = strategies['metrics']\n\n    best_result = evaluate_one_query_expansion_node(retrieval_funcs, retrieval_params, expanded_queries, retrieval_gt, metrics, node_line_dir, previous_result)\n    \n    return best_result"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    retrieval_funcs = [evaluate_one_query_expansion_node]\n    retrieval_params = make_retrieval_callable_params(strategies)\n    expanded_queries = previous_result['expanded_queries']\n    retrieval_gt = previous_result['retrieval_gt']\n    metrics = strategies['metrics']\n    project_dir = node_line_dir\n\n    return evaluate_one_query_expansion_node(retrieval_funcs, retrieval_params, expanded_queries, retrieval_gt, metrics, project_dir, previous_result)"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    retrieval_funcs = [evaluate_one_query_expansion_node] * len(modules)\n    retrieval_params = make_retrieval_callable_params(strategies)\n    expanded_queries = list(map(lambda module: module(previous_result['queries']), modules))\n    retrieval_gt = previous_result['retrieval_gt']\n    metrics = strategies['metrics']\n    project_dir = os.path.join(node_line_dir, \"query_expansion\")\n    return evaluate_one_query_expansion_node(retrieval_funcs, retrieval_params, expanded_queries, retrieval_gt, metrics, project_dir, previous_result)"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    retrieval_funcs = modules\n    retrieval_params = module_params\n    expanded_queries = previous_result['queries']\n    retrieval_gt = previous_result['retrieval_gt']\n    metrics = strategies['metrics']\n    project_dir = node_line_dir\n\n    expanded_result = evaluate_one_query_expansion_node(retrieval_funcs, retrieval_params, expanded_queries, retrieval_gt, metrics, project_dir, previous_result)\n    return expanded_result"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    retrieval_funcs = [evaluate_one_query_expansion_node] * len(modules)\n    retrieval_params = make_retrieval_callable_params(strategies)\n    expanded_queries = list(map(lambda module: module(previous_result), modules))\n    retrieval_gt = previous_result['ground_truth']\n    metrics = strategies['metrics']\n    best_result = evaluate_one_query_expansion_node(retrieval_funcs, retrieval_params, expanded_queries, retrieval_gt, metrics, node_line_dir, previous_result)\n    return best_result"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    retrieval_funcs = [evaluate_one_query_expansion_node] * len(modules)\n    retrieval_params = make_retrieval_callable_params(strategies)\n    expanded_queries = list(map(lambda module: module(previous_result['queries'], **module_params),\n                                modules))\n    retrieval_gt = previous_result['queries']\n    metrics = strategies['metrics']\n    best_result = evaluate_one_query_expansion_node(retrieval_funcs, retrieval_params, expanded_queries, retrieval_gt, metrics, node_line_dir, previous_result)\n    return best_result"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    retrieval_funcs = [evaluate_one_query_expansion_node] * len(modules)\n    retrieval_params = make_retrieval_callable_params(strategies)\n\n    expanded_queries = list(map(lambda module: module(previous_result['queries']), modules))\n    retrieval_gt = previous_result['retrieval_gt']\n    metrics = strategies['metrics']\n\n    best_result = evaluate_one_query_expansion_node(retrieval_funcs, retrieval_params, expanded_queries, retrieval_gt, metrics, node_line_dir, previous_result)\n    return best_result"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    retrieval_funcs = [evaluate_one_query_expansion_node] * len(modules)\n    retrieval_params = make_retrieval_callable_params(strategies)\n    expanded_queries = list(map(lambda module: module(previous_result['queries']), modules))\n    retrieval_gt = previous_result['ground_truth']\n    metrics = strategies['metrics']\n    project_dir = node_line_dir\n\n    return evaluate_one_query_expansion_node(retrieval_funcs, retrieval_params, expanded_queries, retrieval_gt, metrics, project_dir, previous_result)"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    retrieval_funcs = [evaluate_one_query_expansion_node] * len(modules)\n    retrieval_params = make_retrieval_callable_params(strategies)\n    expanded_queries = list(map(lambda module: module(previous_result), modules)\n    retrieval_gt = previous_result['ground_truth']\n    metrics = strategies['metrics']\n    best_result = evaluate_one_query_expansion_node(retrieval_funcs, retrieval_params, expanded_queries, retrieval_gt, metrics, node_line_dir, previous_result)\n    return best_result"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    retrieval_funcs = modules\n    retrieval_params = module_params\n\n    expanded_queries = previous_result['expanded_queries']\n    retrieval_gt = previous_result['retrieval_gt']\n    metrics = strategies['metrics']\n    project_dir = node_line_dir\n\n    return evaluate_one_query_expansion_node(retrieval_funcs, retrieval_params, expanded_queries, retrieval_gt, metrics, project_dir, previous_result)"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    retrieval_funcs = modules\n    retrieval_params = module_params\n    expanded_queries = previous_result['queries']\n    retrieval_gt = previous_result['retrieval_gt']\n    metrics = strategies['metrics']\n    project_dir = node_line_dir\n\n    expanded_result = evaluate_one_query_expansion_node(retrieval_funcs, retrieval_params, expanded_queries, retrieval_gt, metrics, project_dir, previous_result)\n\n    speed_measure = measure_speed(expanded_result)\n    filtered_result = filter_by_threshold(expanded_result, speed_measure, strategies.get('speed_threshold', None))\n    best_result = select_best_average(filtered_result, metrics)\n\n    summary = pd.concat([speed_measure, best_result], axis=1)\n    summary.to_csv(os.path.join(node_line_dir, 'summary.csv'), index=False)\n\n    best_result.to_csv(os.path.join(node_line_dir, 'best_result.csv'), index=False)\n\n    return best_result"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    retrieval_funcs = modules\n    retrieval_params = module_params\n    expanded_queries = previous_result['queries']\n    retrieval_gt = previous_result['retrieval_ground_truth']\n    metrics = strategies['metrics']\n    project_dir = node_line_dir\n\n    retrieval_results = list(map(lambda x: x[0](project_dir=project_dir, previous_result=previous_result, **x[1]),\n                                 zip(retrieval_funcs, retrieval_params)))\n    evaluation_results = list(map(lambda x: evaluate_retrieval_node(x, retrieval_gt, metrics),\n                                  retrieval_results))\n    best_result, _ = select_best_average(evaluation_results, metrics)\n    best_result = pd.concat([previous_result, best_result], axis=1)\n    return best_result"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    retrieval_funcs = [evaluate_one_query_expansion_node]\n    retrieval_params = make_retrieval_callable_params(strategies)\n    expanded_queries = previous_result['queries']\n    retrieval_gt = previous_result['retrieval_gt']\n    metrics = strategies['metrics']\n    project_dir = node_line_dir\n\n    best_result = evaluate_one_query_expansion_node(retrieval_funcs, retrieval_params, expanded_queries, retrieval_gt, metrics, project_dir, previous_result)\n    \n    return best_result"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    retrieval_funcs = [evaluate_one_query_expansion_node] * len(modules)\n    retrieval_params = make_retrieval_callable_params(strategies)\n    expanded_queries = list(map(lambda x: x(previous_result['queries']), modules))\n    retrieval_gt = previous_result['ground_truth']\n    metrics = strategies['metrics']\n    project_dir = node_line_dir\n    return evaluate_one_query_expansion_node(retrieval_funcs, retrieval_params, expanded_queries, retrieval_gt, metrics, project_dir, previous_result)"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    retrieval_funcs = [evaluate_one_query_expansion_node] * len(modules)\n    retrieval_params = make_retrieval_callable_params(strategies)\n    expanded_queries = list(map(lambda module: module(previous_result['queries'], **module_params),\n                                modules))\n    retrieval_gt = previous_result['retrieval_gt']\n    metrics = strategies['metrics']\n    project_dir = pathlib.Path(node_line_dir)\n    return evaluate_one_query_expansion_node(retrieval_funcs, retrieval_params, expanded_queries, retrieval_gt, metrics, project_dir, previous_result)"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    retrieval_funcs = modules\n    retrieval_params = module_params\n    expanded_queries = previous_result['queries']\n    retrieval_gt = previous_result['ground_truth']\n    metrics = strategies['metrics']\n    project_dir = node_line_dir\n\n    retrieval_results = list(map(lambda x: x[0](project_dir=project_dir, previous_result=previous_result, **x[1]),\n                                 zip(retrieval_funcs, retrieval_params)))\n    evaluation_results = list(map(lambda x: evaluate_retrieval_node(x, retrieval_gt, metrics),\n                                  retrieval_results))\n    best_result, _ = select_best_average(evaluation_results, metrics)\n    best_result = pd.concat([previous_result, best_result], axis=1)\n    return best_result"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    generator_funcs = modules\n    generator_params = module_params\n    prompts = previous_result['prompts'].tolist()\n    generation_gt = previous_result['generation_gt'].tolist()\n    metrics = strategies.get('metrics', ['bleu', 'f1'])\n    project_dir = pathlib.Path(node_line_dir)\n\n    generator_callable_params = make_generator_callable_params(strategies)\n    generator_funcs.extend(generator_callable_params[0])\n    generator_params.extend(generator_callable_params[1])\n\n    best_result = evaluate_one_prompt_maker_node(generator_funcs, generator_params, prompts, generation_gt, metrics, project_dir)\n\n    return best_result"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    generator_funcs = modules\n    generator_params = module_params\n\n    # Run prompt maker modules\n    input_df = previous_result\n    generator_results = list(map(lambda x: x[0](project_dir=node_line_dir, previous_result=input_df, **x[1]),\n                                 zip(generator_funcs, generator_params)))\n\n    # Evaluate prompt maker module results\n    metrics = strategies.get('metrics', ['bleu', 'rouge'])\n    generation_gt = previous_result['ground_truth'].tolist()\n    evaluation_results = list(map(lambda x: evaluate_generator_result(x[0], generation_gt, metrics),\n                                  zip(generator_results, generator_funcs)))\n\n    # Select the best prompt maker module based on specified strategies\n    metric_names = list(map(lambda x: x['metric_name'], metrics)) if isinstance(metrics[0], dict) else metrics\n    best_result, _ = select_best_average(evaluation_results, metric_names)\n    best_result = pd.concat([input_df, best_result], axis=1)\n\n    return best_result  # it has 'generated_texts' column"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    generator_funcs = modules\n    generator_params = module_params\n    prompts = previous_result['prompts'].tolist()\n\n    # Get generator modules and parameters\n    generator_callables = make_generator_callable_params(strategies)\n    generator_funcs.extend(generator_callables)\n\n    # Evaluate prompt maker nodes\n    generation_gt = validate_qa_dataset(strategies.get('generation_gt', None))\n    metrics = cast_metrics(strategies.get('metrics', ['bleu', 'f1']))\n    project_dir = os.path.join(node_line_dir, 'prompt_maker_node')\n    best_prompt_maker_result = evaluate_one_prompt_maker_node(generator_funcs, generator_params, prompts, generation_gt, metrics, project_dir)\n\n    return best_prompt_maker_result"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    generator_funcs = modules\n    generator_params = module_params\n    prompts = previous_result['prompts'].tolist()\n    generation_gt = previous_result['ground_truth'].tolist()\n    metrics = strategies.get('metrics', ['bleu', 'f1'])\n    project_dir = os.path.join(node_line_dir, 'prompt_maker')\n    \n    generator_results = list(map(lambda x: x[0](project_dir=project_dir, previous_result=previous_result, **x[1]),\n                                 zip(generator_funcs, generator_params)))\n    evaluation_results = list(map(lambda x: evaluate_generator_result(x[0], generation_gt, metrics),\n                                  zip(generator_results, generator_funcs)))\n    metric_names = list(map(lambda x: x['metric_name'], metrics)) if isinstance(metrics[0], dict) else metrics\n    best_result, _ = select_best_average(evaluation_results, metric_names)\n    best_result = pd.concat([previous_result, best_result], axis=1)\n    return best_result  # it has 'generated_texts' column"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    generator_funcs = modules\n    generator_params = module_params\n    prompts = previous_result['prompts'].tolist()\n    generation_gt = previous_result['generation_gt'].tolist()\n    metrics = strategies.get('metrics', ['bleu', 'f1', 'precision', 'recall'])\n    project_dir = os.path.join(node_line_dir, 'prompt_maker')\n    \n    # Run prompt maker modules\n    generator_results = list(map(lambda x: x[0](project_dir=project_dir, previous_result=previous_result, **x[1]),\n                                 zip(generator_funcs, generator_params)))\n    \n    # Evaluate prompt maker module results\n    evaluation_results = list(map(lambda x: evaluate_generator_result(x[0], generation_gt, metrics),\n                                  zip(generator_results, generator_funcs)))\n    \n    # Select the best prompt maker module based on specified strategies\n    metric_names = list(map(lambda x: x['metric_name'], metrics)) if isinstance(metrics[0], dict) else metrics\n    best_result, _ = select_best_average(evaluation_results, metric_names)\n    best_result = pd.concat([previous_result, best_result], axis=1)\n    \n    return best_result  # it has 'generated_texts' column"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    generator_params = make_generator_callable_params(strategies)\n    prompt_results = list(map(lambda x: x[0](**x[1], previous_result=previous_result), zip(modules, module_params)))\n    best_prompt_result = evaluate_one_prompt_maker_node(modules, generator_params, prompt_results, [], [], node_line_dir)\n    return best_prompt_result"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    generator_params = make_generator_callable_params(strategies)\n    prompt_results = list(map(lambda x: x[0](project_dir=node_line_dir, previous_result=previous_result, **x[1]),\n                              zip(modules, module_params)))\n    best_prompt_result = evaluate_one_prompt_maker_node(modules, module_params, prompt_results, generation_gt, strategies['metrics'], node_line_dir)\n    return best_prompt_result"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    generator_params = make_generator_callable_params(strategies)\n    generator_results = list(map(lambda x: x[0](**x[1], previous_result=previous_result),\n                                 zip(modules, module_params)))\n    best_prompt_maker_result = evaluate_one_prompt_maker_node(modules, module_params, generator_results, previous_result, generator_params, node_line_dir)\n    return best_prompt_maker_result"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    generator_params = make_generator_callable_params(strategies)\n    generator_results = list(map(lambda x: x[0](project_dir=node_line_dir, previous_result=previous_result, **x[1]),\n                                 zip(modules, module_params)))\n    evaluation_results = list(map(lambda x: evaluate_generator_result(x[0], generator_results, strategies['metrics']),\n                                  zip(generator_results, modules)))\n    metric_names = cast_metrics(strategies['metrics'])\n    best_result, _ = select_best_average(evaluation_results, metric_names)\n    best_result = pd.concat([previous_result, best_result], axis=1)\n    return best_result"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    generator_funcs = modules\n    generator_params = module_params\n    prompts = previous_result['prompts'].tolist()\n    generation_gt = previous_result['generation_gt'].tolist()\n    metrics = strategies.get('metrics', ['bleu', 'f1'])\n    project_dir = pathlib.Path(node_line_dir)\n\n    generator_callable_params = make_generator_callable_params(strategies)\n    generator_funcs.extend(generator_callable_params[0])\n    generator_params.extend(generator_callable_params[1])\n\n    best_result = evaluate_one_prompt_maker_node(generator_funcs, generator_params, prompts, generation_gt, metrics, project_dir)\n\n    return best_result"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    generator_params = make_generator_callable_params(strategies)\n    generator_results = list(map(lambda x: x[0](project_dir=node_line_dir, previous_result=previous_result, **x[1]),\n                                 zip(modules, module_params)))\n    evaluation_results = list(map(lambda x: evaluate_generator_result(x[0], generation_gt, strategies['metrics']),\n                                  zip(generator_results, modules)))\n    metric_names = list(map(lambda x: x['metric_name'], strategies['metrics'])) if isinstance(strategies['metrics'][0], dict) else strategies['metrics']\n    best_result, _ = select_best_average(evaluation_results, metric_names)\n    best_result = pd.concat([previous_result, best_result], axis=1)\n    return best_result  # it has 'generated_texts' column"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    generator_funcs = modules\n    generator_params = module_params\n    prompts = previous_result['prompts'].tolist()\n    generation_gt = previous_result['generation_gt'].tolist()\n    metrics = strategies.get('metrics', ['bleu', 'f1'])\n    project_dir = os.path.join(node_line_dir, 'prompt_maker_node')\n\n    # Run prompt maker modules\n    generator_results = list(map(lambda x: x[0](project_dir=project_dir, previous_result=previous_result, **x[1]),\n                                 zip(generator_funcs, generator_params)))\n\n    # Evaluate prompt maker module results\n    evaluation_results = list(map(lambda x: evaluate_generator_result(x[0], generation_gt, metrics),\n                                  zip(generator_results, generator_funcs)))\n\n    # Select the best prompt maker module based on strategies\n    metric_names = list(map(lambda x: x['metric_name'], metrics)) if isinstance(metrics[0], dict) else metrics\n    best_result, _ = select_best_average(evaluation_results, metric_names)\n    best_result = pd.concat([previous_result, best_result], axis=1)\n\n    return best_result"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    generator_funcs = modules\n    generator_params = module_params\n    prompts = previous_result['prompts'].tolist()\n    generation_gt = previous_result['ground_truth'].tolist()\n    metrics = strategies.get('metrics', ['bleu', 'f1'])\n    project_dir = os.path.join(node_line_dir, 'prompt_maker')\n    os.makedirs(project_dir, exist_ok=True)\n    \n    generator_callable_params = make_generator_callable_params(strategies)\n    generator_funcs.extend(generator_callable_params[0])\n    generator_params.extend(generator_callable_params[1])\n    \n    result = evaluate_one_prompt_maker_node(generator_funcs, generator_params, prompts, generation_gt, metrics, project_dir)\n    \n    return result"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    generator_params = make_generator_callable_params(strategies)\n    prompt_results = list(map(lambda x: x[0](**x[1], previous_result=previous_result), zip(modules, module_params)))\n    best_prompt_result = evaluate_one_prompt_maker_node(modules, generator_params, prompt_results,\n                                                        strategies.get('generation_gt'), strategies.get('metrics'),\n                                                        node_line_dir)\n    return best_prompt_result"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    generator_funcs = modules\n    generator_params = module_params\n    prompts = previous_result['prompts'].tolist()\n    generation_gt = previous_result['generation_gt'].tolist()\n    metrics = cast_metrics(strategies.get('metrics', ['bleu', 'rouge']))\n    project_dir = os.path.join(node_line_dir, 'prompt_maker')\n    \n    generator_callable_params = make_generator_callable_params(strategies)\n    generator_funcs.extend(generator_callable_params[0])\n    generator_params.extend(generator_callable_params[1])\n    \n    best_prompt_maker_result = evaluate_one_prompt_maker_node(generator_funcs, generator_params, prompts, generation_gt, metrics, project_dir)\n    \n    return best_prompt_maker_result"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    generator_funcs = modules\n    generator_params = module_params\n\n    # Run prompt maker modules\n    input_df = previous_result\n    generator_results = list(map(lambda x: x[0](**x[1], previous_result=input_df), zip(generator_funcs, generator_params)))\n\n    # Evaluate prompt maker module results\n    evaluation_metrics = strategies.get('metrics', ['accuracy'])\n    generation_gt = input_df['prompts'].tolist()\n    evaluation_results = list(map(lambda x: evaluate_generator_result(x[0], generation_gt, evaluation_metrics), zip(generator_results, generator_funcs)))\n\n    # Select the best prompt maker module based on specified strategies\n    metric_names = list(map(lambda x: x['metric_name'], evaluation_metrics)) if isinstance(evaluation_metrics[0], dict) else evaluation_metrics\n    best_result, _ = select_best_average(evaluation_results, metric_names)\n    best_result = pd.concat([input_df, best_result], axis=1)\n\n    # Save results and summary to the specified directory\n    os.makedirs(node_line_dir, exist_ok=True)\n    result_file_path = os.path.join(node_line_dir, 'result.csv')\n    summary_file_path = os.path.join(node_line_dir, 'summary.csv')\n    best_result.to_csv(result_file_path, index=False)\n\n    # Create summary including execution times and evaluation metrics\n    execution_times = list(map(lambda x: measure_speed(x[0], **x[1]), zip(generator_funcs, generator_params)))\n    summary_df = pd.DataFrame({\n        'module_name': [f.__name__ for f in generator_funcs],\n        'execution_time': execution_times,\n        **cast_metrics(evaluation_results)\n    })\n    summary_df.to_csv(summary_file_path, index=False)\n\n    return best_result"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    generator_params = make_generator_callable_params(strategies)\n    generator_results = list(map(lambda x: x[0](project_dir=node_line_dir, previous_result=previous_result, **x[1]),\n                                 zip(modules, module_params)))\n    evaluation_results = evaluate_one_prompt_maker_node(modules, generator_params, previous_result, generator_results, strategies, node_line_dir)\n    return evaluation_results"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    generator_params = make_generator_callable_params(strategies)\n    generator_results = list(map(lambda x: x[0](previous_result, **x[1]), zip(modules, module_params)))\n    evaluation_results = evaluate_one_prompt_maker_node(modules, module_params, generator_results, previous_result, generator_params, node_line_dir)\n    return evaluation_results"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    generator_params = make_generator_callable_params(strategies)\n    generator_results = list(map(lambda x: x[0](project_dir=node_line_dir, previous_result=previous_result, **x[1]),\n                                 zip(modules, module_params)))\n    evaluation_results = list(map(lambda x: evaluate_generator_result(x[0], generation_gt, strategies['metrics']),\n                                  zip(generator_results, modules)))\n    metric_names = strategies['metrics'] if isinstance(strategies['metrics'][0], str) else list(map(lambda x: x['metric_name'], strategies['metrics']))\n    best_result, _ = select_best_average(evaluation_results, metric_names)\n    best_result = pd.concat([previous_result, best_result], axis=1)\n    return best_result"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    generator_params = make_generator_callable_params(strategies)\n    generator_results = list(map(lambda x: x[0](project_dir=node_line_dir, previous_result=previous_result, **x[1]),\n                                 zip(modules, module_params)))\n    evaluation_results = list(map(lambda x: evaluate_generator_result(x[0], generation_gt=[], metrics=[]),\n                                  zip(generator_results)))\n    metric_names = list(map(lambda x: x['metric_name'], strategies['metrics'])) if isinstance(strategies['metrics'][0], dict) else strategies['metrics']\n    best_result, _ = select_best_average(evaluation_results, metric_names)\n    best_result = pd.concat([previous_result, best_result], axis=1)\n    return best_result  # it has 'generated_texts' column"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = []\n    for node in nodes:\n        values.extend(extract_values(node, key))\n    return list(set(values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = []\n    for node in nodes:\n        values.extend(extract_values(node, key))\n    return list(set(values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = []\n    for node in nodes:\n        values.extend(extract_values(node, key))\n    return list(set(values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(set(list(itertools.chain.from_iterable(map(lambda node: extract_values(node, key), nodes))))\n    return values"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(set(list(itertools.chain.from_iterable(extract_values(node, key) for node in nodes)))\n    return values"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(set(list(itertools.chain.from_iterable(extract_values(node, key) for node in nodes)))\n    return values"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = []\n    for node in nodes:\n        extracted_values = extract_values(node, key)\n        values.extend(extracted_values)\n    return list(set(values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = []\n    for node in nodes:\n        values.extend(extract_values(node, key))\n    return list(set(values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = []\n    for node in nodes:\n        values.extend(extract_values(node, key))\n    return list(set(values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(set(list(itertools.chain.from_iterable([extract_values(node, key) for node in nodes])))\n    return values"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = []\n    for node in nodes:\n        values.extend(extract_values(node, key))\n    return list(set(values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(set(list(itertools.chain.from_iterable([extract_values(node, key) for node in nodes])))\n    return values"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(set(list(itertools.chain.from_iterable(extract_values(node, key) for node in nodes)))\n    return values"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = []\n    for node in nodes:\n        values.extend(extract_values(node, key))\n    return list(set(values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = []\n    for node in nodes:\n        values.extend(extract_values(node, key))\n    return list(set(values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = []\n    for node in nodes:\n        values.extend(extract_values(node, key))\n    return list(set(values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = []\n    for node in nodes:\n        extracted_values = extract_values(node, key)\n        values.extend(extracted_values)\n    return list(set(values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = []\n    for node in nodes:\n        values.extend(extract_values(node, key))\n    return list(set(values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = []\n    for node in nodes:\n        values.extend(extract_values(node, key))\n    return list(set(values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(set(list(itertools.chain.from_iterable(map(lambda node: extract_values(node, key), nodes))))\n    return values"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    df = pd.read_csv(summary_path)\n    if dict_columns:\n        for col in dict_columns:\n            df[col] = df[col].apply(ast.literal_eval)\n    return df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    summary_df = pd.read_csv(summary_path)\n    if dict_columns is not None:\n        for col in dict_columns:\n            summary_df[col] = summary_df[col].apply(ast.literal_eval)\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for col in dict_columns:\n        summary_df[col] = summary_df[col].apply(ast.literal_eval)\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for col in dict_columns:\n        summary_df[col] = summary_df[col].apply(ast.literal_eval)\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "\n    summary_df = pd.read_csv(summary_path)\n\n    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(ast.literal_eval)\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(ast.literal_eval)\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "\n    # Load the summary file into a DataFrame\n    summary_df = pd.read_csv(summary_path)\n\n    # Convert specified columns to dictionary objects\n    if dict_columns is not None:\n        for column in dict_columns:\n            summary_df[column] = summary_df[column].apply(ast.literal_eval)\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n    for col in dict_columns:\n        summary_df[col] = summary_df[col].apply(ast.literal_eval)\n    \n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "\n    summary_df = pd.read_csv(summary_path)\n\n    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(ast.literal_eval)\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    df = pd.read_csv(summary_path)\n    if dict_columns:\n        for col in dict_columns:\n            df[col] = df[col].apply(ast.literal_eval)\n    return df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    summary_df = pd.read_csv(summary_path)\n    if dict_columns is not None:\n        for col in dict_columns:\n            summary_df[col] = summary_df[col].apply(ast.literal_eval)\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    summary_df = pd.read_csv(summary_path)\n\n    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(ast.literal_eval)\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    summary_df = pd.read_csv(summary_path)\n    if dict_columns is not None:\n        for col in dict_columns:\n            summary_df[col] = summary_df[col].apply(ast.literal_eval)\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    summary_df = pd.read_csv(summary_path)\n    if dict_columns is not None:\n        for col in dict_columns:\n            summary_df[col] = summary_df[col].apply(ast.literal_eval)\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(ast.literal_eval)\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for col in dict_columns:\n        summary_df[col] = summary_df[col].apply(ast.literal_eval)\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    df = pd.read_csv(summary_path)\n    for column in dict_columns:\n        if column in df.columns:\n            df[column] = df[column].apply(ast.literal_eval)\n    return df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for col in dict_columns:\n        summary_df[col] = summary_df[col].apply(ast.literal_eval)\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(ast.literal_eval)\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for col in dict_columns:\n        summary_df[col] = summary_df[col].apply(ast.literal_eval)\n\n    return summary_df"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        return cls(module_type=module_type, module_param=module_dict)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.get('module_type')\n        module_params = {k: v for k, v in module_dict.items() if k != 'module_type'}\n        return cls(module_type=module_type, module_param=module_params)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.get('module_type')\n        module_param = deepcopy(module_dict)\n        module_param.pop('module_type', None)\n        return cls(module_type=module_type, module_param=module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.get('module_type')\n        module_param = deepcopy(module_dict)\n        module_param.pop('module_type', None)\n        return cls(module_type=module_type, module_param=module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.get('module_type')\n        module_param = {k: v for k, v in module_dict.items() if k != 'module_type'}\n        return cls(module_type=module_type, module_param=module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        return cls(module_type=module_type, module_param=deepcopy(module_dict))"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.get('module_type')\n        module_param = deepcopy(module_dict)\n        module_param.pop('module_type', None)\n        return cls(module_type=module_type, module_param=module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.get('module_type')\n        module_param = deepcopy(module_dict)\n        del module_param['module_type']\n        return cls(module_type=module_type, module_param=module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        return cls(module_type=module_type, module_param=module_dict)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.get('module_type')\n        module_param = {k: v for k, v in module_dict.items() if k != 'module_type'}\n        return cls(module_type=module_type, module_param=module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.get('module_type')\n        module_param = deepcopy(module_dict)\n        module_param.pop('module_type', None)\n        return cls(module_type=module_type, module_param=module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.get('module_type')\n        module_param = deepcopy(module_dict)\n        module_param.pop('module_type', None)\n        return cls(module_type=module_type, module_param=module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.get('module_type')\n        module_param = deepcopy(module_dict)\n        module_param.pop('module_type', None)\n        return cls(module_type=module_type, module_param=module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.get('module_type')\n        module_params = {k: v for k, v in module_dict.items() if k != 'module_type'}\n        return cls(module_type, module_params)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.get('module_type')\n        module_param = {k: v for k, v in module_dict.items() if k != 'module_type'}\n        return cls(module_type=module_type, module_param=module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.get('module_type')\n        module_param = {k: v for k, v in module_dict.items() if k != 'module_type'}\n        return cls(module_type=module_type, module_param=module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        return cls(module_type=module_type, module_param=deepcopy(module_dict))"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.get('module_type')\n        module_param = deepcopy(module_dict)\n        del module_param['module_type']\n        return cls(module_type=module_type, module_param=module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        return cls(module_type=module_type, module_param=module_dict)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.get('module_type')\n        module_param = deepcopy(module_dict)\n        module_param.pop('module_type')\n\n        return cls(module_type=module_type, module_param=module_param)"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            name = list(metric.keys())[0]\n            params = metric[name]\n            metric_names.append(name)\n            metric_params.append(params)\n        else:\n            raise ValueError(\"Invalid format for metric. Please provide either a string or a dictionary.\")\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric['name'])\n            params = deepcopy(metric)\n            del params['name']\n            metric_params.append(params)\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric['name'])\n            metric_params.append({cast_embedding_model(k, v) for k, v in metric.items() if k != 'name'})\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric.get('name'))\n            metric_params.append({cast_embedding_model(k, v) for k, v in metric.items()})\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric['name'])\n            metric_params.append({cast_embedding_model(key, value) for key, value in metric.items()})\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric['name'])\n            metric_params.append({cast_embedding_model(key, value) for key, value in metric.items()})\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            name = list(metric.keys())[0]\n            params = metric[name]\n            metric_names.append(name)\n            metric_params.append(params)\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric['name'])\n            params = deepcopy(metric)\n            del params['name']\n            metric_params.append({cast_embedding_model(k, v) for k, v in params.items()})\n        else:\n            raise ValueError(\"Invalid format for metric. Must be either a string or a dictionary.\")\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_name = list(metric.keys())[0]\n            metric_params_dict = metric[metric_name]\n            metric_names.append(metric_name)\n            cast_params = {cast_embedding_model(k, v) for k, v in metric_params_dict.items()}\n            metric_params.append(cast_params)\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(list(metric.keys())[0])\n            metric_params.append(list(metric.values())[0])\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric['name'])\n            metric_params.append({cast_embedding_model(k, v) for k, v in metric.items()})\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metric_names = []\n    metric_params = []\n    \n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric.get('name', ''))\n            metric_params.append({cast_embedding_model(k, v) for k, v in metric.items()})\n    \n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            name = list(metric.keys())[0]\n            params = metric[name]\n            if isinstance(params, dict):\n                metric_names.append(name)\n                metric_params.append(params)\n            else:\n                metric_names.append(name)\n                metric_params.append({})\n        else:\n            raise ValueError(\"Invalid format for metrics. Expected list of strings or dictionaries.\")\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric['name'])\n            metric_params.append({cast_embedding_model(k, v) for k, v in metric.items()})\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(list(metric.keys())[0])\n            metric_params.append(list(metric.values())[0])\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric['name'])\n            metric_params.append({cast_embedding_model(k, v) for k, v in metric.items()})\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric['name'])\n            params = deepcopy(metric)\n            del params['name']\n            metric_params.append(params)\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "\n    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(list(metric.keys())[0])\n            metric_params.append(list(metric.values())[0])\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric['name'])\n            params = deepcopy(metric)\n            del params['name']\n            metric_params.append(params)\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric['name'])\n            params = deepcopy(metric)\n            del params['name']\n            metric_params.append(params)\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "\n    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding_model()\n\n    similarity_scores = [calculate_cosine_similarity(embedding_model.encode(pred), embedding_model.encode(gt)) for gt in generation_gt]\n    return max(similarity_scores)"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "\n    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding_model()\n\n    similarity_scores = []\n    for gt in generation_gt:\n        gt_embedding = embedding_model.encode(gt)\n        pred_embedding = embedding_model.encode(pred)\n        similarity = calculate_cosine_similarity(gt_embedding, pred_embedding)\n        similarity_scores.append(similarity)\n\n    return max(similarity_scores)"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "\n    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding_model()\n\n    max_similarity = 0\n    for gt in generation_gt:\n        similarity = calculate_cosine_similarity(embedding_model.encode(gt), embedding_model.encode(pred))\n        max_similarity = max(max_similarity, similarity)\n\n    return max_similarity"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "\n    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding_model()\n\n    max_similarity = 0\n    for gt in generation_gt:\n        similarity = calculate_cosine_similarity(embedding_model.encode(gt), embedding_model.encode(pred))\n        max_similarity = max(max_similarity, similarity)\n\n    return max_similarity"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "\n    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding_model()\n\n    max_similarity = 0\n    for gt in generation_gt:\n        similarity = calculate_cosine_similarity(embedding_model.encode(gt), embedding_model.encode(pred))\n        max_similarity = max(max_similarity, similarity)\n\n    return max_similarity"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "\n    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding_model()\n\n    max_similarity = 0\n    for gt in generation_gt:\n        similarity = calculate_cosine_similarity(embedding_model.encode(gt), embedding_model.encode(pred))\n        if similarity > max_similarity:\n            max_similarity = similarity\n\n    return max_similarity"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "\n    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding_model()\n\n    max_similarity = 0\n    for gt in generation_gt:\n        similarity = calculate_cosine_similarity(embedding_model.encode(gt), embedding_model.encode(pred))\n        max_similarity = max(max_similarity, similarity)\n\n    return max_similarity"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "\n    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding_model()\n\n    similarity_scores = [\n        calculate_cosine_similarity(embedding_model.encode(pred), embedding_model.encode(gt))\n        for gt in generation_gt\n    ]\n\n    return max(similarity_scores)"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding_model()\n\n    def calculate_max_cosine_similarity(gt: str, pred: str) -> float:\n        gt_embedding = embedding_model.encode(gt)\n        pred_embedding = embedding_model.encode(pred)\n        similarities = calculate_cosine_similarity(gt_embedding, pred_embedding)\n        return max(similarities)\n\n    return max([calculate_max_cosine_similarity(gt, pred) for gt in generation_gt])"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "\n    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding_model()\n\n    similarity_scores = []\n    for gt in generation_gt:\n        gt_embedding = embedding_model.encode(gt)\n        pred_embedding = embedding_model.encode(pred)\n        similarity = calculate_cosine_similarity(gt_embedding, pred_embedding)\n        similarity_scores.append(similarity)\n\n    return max(similarity_scores)"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "\n    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding_model()\n\n    max_similarity = 0\n    for gt in generation_gt:\n        similarity = calculate_cosine_similarity(embedding_model.encode(gt), embedding_model.encode(pred))\n        max_similarity = max(max_similarity, similarity)\n\n    return max_similarity"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding_model()\n\n    pred_embedding = embedding_model.encode(pred)\n    gt_embeddings = [embedding_model.encode(gt) for gt in generation_gt]\n\n    max_similarity = 0\n    for gt_embedding in gt_embeddings:\n        similarity = calculate_cosine_similarity(pred_embedding, gt_embedding)\n        max_similarity = max(max_similarity, similarity)\n\n    return max_similarity"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n\n    similarities = [calculate_cosine_similarity(embedding_model.encode(pred), embedding_model.encode(gt)) for gt in generation_gt]\n    return max(similarities)"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding_model()  # Assuming this function exists to get the default model\n    similarity_scores = [calculate_cosine_similarity(embedding_model.encode(pred), embedding_model.encode(gt)) for gt in generation_gt]\n    return max(similarity_scores)"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n\n    similarity_scores = [calculate_cosine_similarity(embedding_model.embed([pred]), embedding_model.embed([gt])) for gt in generation_gt]\n    return max(similarity_scores)"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding_model()\n\n    gt_embeddings = [embedding_model.encode(gt) for gt in generation_gt]\n    pred_embedding = embedding_model.encode(pred)\n\n    similarities = [calculate_cosine_similarity(pred_embedding, gt_emb) for gt_emb in gt_embeddings]\n    return max(similarities)"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "\n    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n\n    max_similarity = 0\n    for gt in generation_gt:\n        similarity = calculate_cosine_similarity(embedding_model, pred, gt)\n        max_similarity = max(max_similarity, similarity)\n\n    return max_similarity"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding_model()\n\n    similarity_scores = []\n    for gt in generation_gt:\n        gt_embedding = embedding_model.encode(gt)\n        pred_embedding = embedding_model.encode(pred)\n        similarity = calculate_cosine_similarity(gt_embedding, pred_embedding)\n        similarity_scores.append(similarity)\n\n    return max(similarity_scores)"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "\n    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding_model()\n\n    pred_embedding = embedding_model.encode(pred)\n    gt_embeddings = [embedding_model.encode(gt) for gt in generation_gt]\n\n    max_similarity = 0\n    for gt_embedding in gt_embeddings:\n        similarity = calculate_cosine_similarity(pred_embedding, gt_embedding)\n        max_similarity = max(max_similarity, similarity)\n\n    return max_similarity"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "\n    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n\n    similarity_scores = []\n    for gt in generation_gt:\n        gt_embedding = embedding_model.encode(gt)\n        pred_embedding = embedding_model.encode(pred)\n        similarity_score = calculate_cosine_similarity(gt_embedding, pred_embedding)\n        similarity_scores.append(similarity_score)\n\n    return max(similarity_scores)"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up, cannot fix faces\")\n        return np_image\n\n    try:\n        restored_image = gfpgan_face_restorer.restore(np_image)\n        return restored_image\n    except Exception:\n        errors.report(\"Error restoring faces with GFPGAN\", exc_info=True)\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up, cannot fix faces\")\n        return np_image\n\n    try:\n        restored_image = gfpgan_face_restorer.restore(np_image)\n        return restored_image\n    except Exception:\n        logger.exception(\"Error restoring faces with GFPGAN\")\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is not None:\n        try:\n            restored_image = gfpgan_face_restorer.restore(np_image)\n            return restored_image\n        except Exception as e:\n            logger.warning(\"Error restoring faces with GFPGAN: %s\", e)\n            return np_image\n    else:\n        logger.warning(\"GFPGAN face restorer is not set up\")\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is not None:\n        try:\n            restored_image = gfpgan_face_restorer.restore(np_image)\n            return restored_image\n        except Exception as e:\n            logger.warning(\"GFPGAN face restoration failed: %s\", str(e))\n    else:\n        logger.warning(\"GFPGAN face restorer is not set up\")\n    \n    return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "\n    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is not None:\n        try:\n            restored_image = gfpgan_face_restorer.restore(np_image)\n            return restored_image\n        except Exception as e:\n            logger.warning(\"Error restoring faces using GFPGAN: %s\", e)\n            return np_image\n    else:\n        logger.warning(\"GFPGAN face restorer is not set up\")\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logging.warning(\"GFPGAN face restorer is not set up. Returning original image.\")\n        return np_image\n\n    try:\n        restored_image = gfpgan_face_restorer.restore(np_image)\n        return restored_image\n    except Exception as e:\n        logging.error(\"Error restoring faces with GFPGAN:\", exc_info=True)\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up, cannot fix faces\")\n        return np_image\n\n    try:\n        restored_image = gfpgan_face_restorer.restore(np_image)\n        return restored_image\n    except Exception as e:\n        logger.warning(\"Error restoring faces with GFPGAN: %s\", e)\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up. Returning original image.\")\n        return np_image\n\n    try:\n        restored_image = gfpgan_face_restorer.restore(np_image)\n        return restored_image\n    except Exception as e:\n        logger.error(\"Error restoring faces using GFPGAN: %s\", e)\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up. Returning original image.\")\n        return np_image\n\n    try:\n        restored_image = gfpgan_face_restorer.restore(np_image)\n        return restored_image\n    except Exception as e:\n        logger.error(\"Error restoring faces with GFPGAN: %s\", str(e))\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is not None:\n        try:\n            restored_image = gfpgan_face_restorer.restore(np_image)\n            return restored_image\n        except Exception as e:\n            logger.warning(\"Error restoring faces with GFPGAN: %s\", e)\n    else:\n        logger.warning(\"GFPGAN face restorer is not set up\")\n    \n    return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logging.warning(\"GFPGAN face restorer is not set up. Cannot fix faces.\")\n        return np_image\n\n    try:\n        restored_image = gfpgan_face_restorer.restore(np_image)\n        return restored_image\n    except Exception:\n        logging.warning(\"Error restoring faces with GFPGAN face restorer. Returning original image.\")\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "\n    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is not None:\n        try:\n            restored_image = gfpgan_face_restorer.restore(np_image)\n            return restored_image\n        except Exception:\n            logger.warning(\"GFPGAN face restorer failed to restore faces\")\n            return np_image\n    else:\n        logger.warning(\"GFPGAN face restorer is not set up\")\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logging.warning(\"GFPGAN face restorer is not set up. Returning original image.\")\n        return np_image\n\n    try:\n        restored_image = gfpgan_face_restorer.restore(np_image)\n        return restored_image\n    except Exception as e:\n        logging.error(\"Error restoring faces using GFPGAN:\", exc_info=True)\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is not None:\n        try:\n            restored_image = gfpgan_face_restorer.restore(np_image)\n            return restored_image\n        except Exception as e:\n            logger.warning(\"GFPGAN face restoration failed: %s\", str(e))\n    else:\n        logger.warning(\"GFPGAN face restorer is not set up. Skipping face restoration.\")\n    \n    return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is not None:\n        try:\n            restored_image = gfpgan_face_restorer.restore(np_image)\n            return restored_image\n        except Exception as e:\n            logger.warning(\"Failed to restore faces using GFPGAN: %s\", str(e))\n    else:\n        logger.warning(\"GFPGAN face restorer is not set up. Skipping face restoration.\")\n    \n    return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up. Returning original image.\")\n        return np_image\n\n    try:\n        restored_image = gfpgan_face_restorer.restore(np_image)\n        return restored_image\n    except Exception as e:\n        logger.error(\"Error restoring faces with GFPGAN: %s\", str(e))\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is not None:\n        try:\n            return gfpgan_face_restorer.restore(np_image)\n        except Exception as e:\n            logger.warning(\"GFPGAN face restoration failed: %s\", e)\n    else:\n        logger.warning(\"GFPGAN face restorer is not set up\")\n    return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up. Returning original image.\")\n        return np_image\n\n    try:\n        restored_image = gfpgan_face_restorer.restore(np_image)\n        return restored_image\n    except Exception:\n        errors.report(\"Error restoring faces with GFPGAN\", exc_info=True)\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up, cannot restore faces\")\n        return np_image\n    try:\n        restored_image = gfpgan_face_restorer.restore(np_image)\n        return restored_image\n    except Exception:\n        errors.report(\"Error restoring faces with GFPGAN\", exc_info=True)\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is not None:\n        try:\n            return gfpgan_face_restorer.restore(np_image)\n        except Exception:\n            errors.report(\"Error restoring faces with GFPGAN\", exc_info=True)\n    else:\n        logging.warning(\"GFPGAN face restorer is not set up, returning the original image.\")\n        return np_image"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        codeformer = FaceRestorerCodeFormer(model_path=dirname)\n    except errors.ModelNotFoundError as e:\n        logger.error(f\"Model not found in {dirname}: {e}\")\n    except Exception as e:\n        logger.error(f\"Error setting up FaceRestorerCodeFormer: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.ModelLoadingError as e:\n        logger.error(f\"Failed to setup CodeFormer model: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.ModelNotFoundError as e:\n        logger.error(f\"Model not found: {e}\")\n    except Exception as e:\n        logger.error(f\"Error setting up model: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except Exception as e:\n        logger.error(f\"Failed to set up FaceRestorerCodeFormer: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except Exception as e:\n        logger.error(f\"Failed to set up CodeFormer model: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except Exception as e:\n        logger.error(f\"Error setting up CodeFormer model: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.ModelLoadError as e:\n        logger.warning(f\"Failed to load model for FaceRestorerCodeFormer: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.ModelLoadingError as e:\n        logger.error(f\"Failed to load CodeFormer model: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except Exception as e:\n        logger.error(f\"Error setting up CodeFormer model: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except Exception as e:\n        logger.error(f\"Error setting up model: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.ModelError as e:\n        logger.error(f\"Error setting up CodeFormer model: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        codeformer = FaceRestorerCodeFormer(model_path=dirname)\n    except errors.ModelLoadError as e:\n        logger.error(f\"Failed to load CodeFormer model from {dirname}: {e}\")\n    except Exception as e:\n        logger.error(f\"Failed to set up CodeFormer model from {dirname}: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.ModelLoadingError as e:\n        logger.error(f\"Failed to set up CodeFormer model: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except Exception as e:\n        logger.error(f\"Failed to set up CodeFormer model: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.ModelNotFoundError as e:\n        logger.error(f\"Model not found: {e}\")\n    except Exception as e:\n        logger.error(f\"Error setting up model: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.ModelLoadError as e:\n        logger.error(f\"Error setting up CodeFormer model: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.ModelLoadingError as e:\n        logger.error(f\"Error setting up CodeFormer model: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        fr = FaceRestorerCodeFormer(dirname)\n        codeformer = fr\n    except Exception as e:\n        logger.error(f\"Error setting up CodeFormer model: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(model_path=dirname)\n    except Exception as e:\n        logger.error(f\"Error setting up CodeFormer model: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.ModelLoadError as e:\n        logger.error(f\"Failed to set up CodeFormer model: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        face_restorer = FaceRestorerGFPGAN()\n        face_restorer.set_model_path(dirname)\n        face_restorer.setup()\n        gfpgan_face_restorer = face_restorer\n    except Exception as e:\n        logger.error(f\"Failed to set up GFPGAN face restorer: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        face_restorer = FaceRestorerGFPGAN()\n        face_restorer.set_model_path(dirname)\n        face_restorer.setup()\n        gfpgan_face_restorer = face_restorer\n    except Exception as e:\n        logger.error(f\"Failed to set up GFPGAN face restorer: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        face_restoration.patch_facexlib(dirname)\n        face_restorer = FaceRestorerGFPGAN()\n        face_restorer.setup_model(dirname)\n        gfpgan_face_restorer = face_restorer\n    except Exception as e:\n        logger.error(f\"Error setting up GFPGAN model: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        face_restoration.patch_facexlib(dirname)\n        gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=dirname)\n    except Exception as e:\n        logger.error(f\"Error setting up GFPGAN model: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        face_restorer = FaceRestorerGFPGAN()\n        face_restorer.model_path = dirname\n        face_restorer.net = face_restorer.load_net()\n        gfpgan_face_restorer = face_restorer\n    except Exception as e:\n        logger.error(f\"Failed to set up GFPGAN model: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        face_restoration_utils.patch_facexlib(dirname)\n        gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=dirname)\n    except Exception as e:\n        logger.exception(\"Error setting up GFPGAN model: %s\", str(e))"}
{"namespace": "gfpgan_model.setup_model", "completion": "\n    global gfpgan_face_restorer\n\n    try:\n        shared.patch_facexlib(dirname)\n        gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=dirname)\n    except Exception as e:\n        logger.error(f\"Failed to set up GFPGAN model: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        face_restorer = FaceRestorerGFPGAN()\n        face_restorer.set_model_path(dirname)\n        face_restorer.setup()\n        gfpgan_face_restorer = face_restorer\n    except Exception as e:\n        logger.error(f\"Failed to set up GFPGAN model: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        face_restorer = FaceRestorerGFPGAN()\n        face_restorer.patch_facexlib(dirname)\n        face_restorer.set_model_path(dirname)\n        face_restorer.setup()\n        gfpgan_face_restorer = face_restorer\n    except Exception as e:\n        logger.error(f\"Failed to set up GFPGAN face restorer: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        face_restorer_gfpgan = FaceRestorerGFPGAN()\n        face_restorer_gfpgan.set_model_path(dirname)\n        face_restorer_gfpgan.setup()\n        gfpgan_face_restorer = face_restorer_gfpgan\n        logger.info(\"GFPGAN model set up successfully\")\n    except Exception as e:\n        logger.error(f\"Failed to set up GFPGAN model: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        face_restoration_utils.patch_facexlib(dirname)\n        gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=dirname)\n    except Exception as e:\n        logger.error(f\"Error setting up GFPGAN model: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        face_restoration_utils.patch_facexlib(dirname)\n        gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=dirname)\n    except Exception as e:\n        logger.error(f\"Error setting up GFPGAN model: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        face_restorer = FaceRestorerGFPGAN()\n        face_restorer.set_model_path(dirname)\n        face_restorer.setup()\n        gfpgan_face_restorer = face_restorer\n    except Exception as e:\n        logger.error(f\"Failed to set up GFPGAN face restorer: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        shared.patch_facexlib(dirname)\n        gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=dirname)\n    except Exception as e:\n        logger.error(f\"Error setting up GFPGAN model: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "\n    global gfpgan_face_restorer\n\n    try:\n        face_restorer = FaceRestorerGFPGAN()\n        face_restorer.patch_facexlib(dirname)\n        face_restorer.initialize_model(dirname)\n        gfpgan_face_restorer = face_restorer\n        logger.info(\"GFPGAN face restorer set up successfully\")\n    except Exception as e:\n        logger.error(f\"Error setting up GFPGAN face restorer: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        face_restorer = FaceRestorerGFPGAN()\n        face_restorer.model_path = dirname\n        face_restorer.setup()\n        gfpgan_face_restorer = face_restorer\n    except Exception as e:\n        logger.error(f\"Error setting up GFPGAN face restorer: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        shared.patch_facexlib(dirname)\n        face_restorer = FaceRestorerGFPGAN()\n        face_restorer.set_model_path(dirname)\n        face_restorer.setup()\n        gfpgan_face_restorer = face_restorer\n        logger.info(\"GFPGAN face restorer set up successfully\")\n    except Exception as e:\n        logger.error(f\"Error setting up GFPGAN face restorer: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        shared.patch_facexlib(dirname)\n        gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=dirname)\n    except Exception as e:\n        logger.error(f\"Error setting up GFPGAN model: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n\n    try:\n        shared.patch_facexlib(dirname)\n        gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=dirname)\n        logger.info(\"GFPGAN face restorer set up successfully\")\n    except Exception as e:\n        logger.error(f\"Error setting up GFPGAN face restorer: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        face_restorer = FaceRestorerGFPGAN()\n        face_restorer.model_path = dirname\n        face_restorer.setup()\n        gfpgan_face_restorer = face_restorer\n    except Exception as e:\n        logger.error(f\"Failed to set up GFPGAN face restorer: {e}\")"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format for rotation\n  v_quaternion = jnp.concatenate([v, jnp.array([0.0])])\n  \n  # Apply the quaternion rotation\n  rotated_v_quaternion = multiply(multiply(q, v_quaternion), conjugate(q))\n  \n  # Convert the rotated quaternion back to a vector format\n  rotated_v = rotated_v_quaternion[:3]\n  \n  return rotated_v"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format for rotation\n  v_quat = jnp.concatenate([v, jnp.array([0.0])])\n  \n  # Apply the quaternion rotation\n  rotated_v_quat = multiply(multiply(q, v_quat), conjugate(q))\n  \n  # Convert the rotated quaternion back to a vector format\n  rotated_v = rotated_v_quat[:3]\n  \n  return rotated_v"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector v into a pure quaternion format\n  v_quaternion = jnp.concatenate([v, jnp.array([0.0])])\n\n  # Apply the quaternion rotation\n  rotated_v_quaternion = multiply(multiply(q, v_quaternion), conjugate(q))\n\n  # Convert the rotated quaternion back to a vector format\n  rotated_v = rotated_v_quaternion[:3]\n\n  return rotated_v"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  v_quat = jnp.concatenate([v, jnp.zeros_like(v[..., :1])], axis=-1)\n\n  # Apply the rotation using quaternion multiplication\n  rotated_v_quat = multiply(multiply(q, v_quat), conjugate(q))\n\n  # Convert the rotated quaternion back to a vector format\n  rotated_v = rotated_v_quat[..., :3]\n\n  return rotated_v"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  v_quaternion = jnp.concatenate([v, jnp.array([0.0])])\n\n  # Perform the rotation\n  rotated_v_quaternion = multiply(multiply(q, v_quaternion), conjugate(q))\n\n  # Convert the rotated quaternion back to a vector\n  rotated_v = rotated_v_quaternion[:3]\n\n  return rotated_v"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  v_quaternion = jnp.concatenate([v, jnp.array([0.0])])\n\n  # Apply the rotation\n  rotated_v_quaternion = multiply(multiply(q, v_quaternion), conjugate(q))\n\n  # Convert the rotated vector back to 3D space format\n  rotated_v = rotated_v_quaternion[:3]\n\n  return rotated_v"}
{"namespace": "quaternion.rotate", "completion": "  v_quat = jnp.concatenate([v, jnp.zeros_like(v[..., :1])], axis=-1)\n  rotated_v_quat = multiply(multiply(q, v_quat), conjugate(q))\n  return rotated_v_quat[..., :3]"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  v_quat = jnp.concatenate([v, jnp.array([0.0])])\n\n  # Apply the quaternion rotation\n  rotated_v_quat = multiply(multiply(q, v_quat), conjugate(q))\n\n  # Convert the rotated quaternion back to a vector format\n  rotated_v = rotated_v_quat[:3]\n\n  return rotated_v"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  v_quat = jnp.concatenate([v, jnp.zeros_like(v[..., :1])], axis=-1)\n\n  # Apply the quaternion rotation\n  rotated_v_quat = multiply(multiply(q, v_quat), conjugate(q))\n\n  # Convert the rotated quaternion back to a vector format\n  rotated_v = rotated_v_quat[..., :3]\n\n  return rotated_v"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  v_quaternion = jnp.concatenate([v, jnp.array([0.0])])\n\n  # Apply the quaternion rotation\n  rotated_v_quaternion = multiply(multiply(q, v_quaternion), conjugate(q))\n\n  # Convert the rotated quaternion back to a vector format\n  rotated_v = rotated_v_quaternion[:3]\n\n  return rotated_v"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  v_quaternion = jnp.concatenate([v, jnp.array([0.0])])\n\n  # Apply the quaternion rotation\n  rotated_v_quaternion = multiply(multiply(q, v_quaternion), conjugate(q))\n\n  # Convert the rotated quaternion back to a vector format\n  rotated_v = rotated_v_quaternion[:3]\n\n  return rotated_v"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  v_quat = jnp.concatenate([v, jnp.array([0.0])])\n\n  # Apply the rotation\n  q_conj = conjugate(q)\n  v_rotated = multiply(multiply(q, v_quat), q_conj)\n\n  # Convert the rotated vector back to 3D space\n  return v_rotated[:3]"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  v_quaternion = jnp.concatenate([v, jnp.array([0.0])])\n\n  # Apply the rotation using quaternion multiplication\n  rotated_v_quaternion = multiply(multiply(q, v_quaternion), conjugate(q))\n\n  # Convert the rotated quaternion back to a vector format\n  rotated_v = rotated_v_quaternion[:3]\n\n  return rotated_v"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  v_quat = jnp.concatenate([v, jnp.array([0.0])])\n\n  # Apply the rotation\n  rotated_v_quat = multiply(multiply(q, v_quat), conjugate(q))\n\n  # Convert the rotated quaternion back to a vector format\n  rotated_v = rotated_v_quat[:3]\n\n  return rotated_v"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  v_quat = jnp.concatenate([v, jnp.array([0.0])])\n\n  # Apply the rotation using quaternion multiplication\n  rotated_v_quat = multiply(multiply(q, v_quat), conjugate(q))\n\n  # Convert the rotated quaternion back to a vector format\n  rotated_v = rotated_v_quat[:3]\n\n  return rotated_v"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  v_quaternion = jnp.concatenate([v, jnp.array([0.0])])\n\n  # Apply the quaternion rotation\n  rotated_v_quaternion = multiply(multiply(q, v_quaternion), conjugate(q))\n\n  # Convert the rotated quaternion back to a vector format\n  rotated_v = rotated_v_quaternion[:3]\n\n  return rotated_v"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  v_quat = jnp.concatenate([v, jnp.array([0.0])])\n\n  # Apply the rotation using quaternion multiplication\n  rotated_v_quat = multiply(multiply(q, v_quat), conjugate(q))\n\n  # Convert the rotated quaternion back to a vector format\n  rotated_v = rotated_v_quat[:3]\n\n  return rotated_v"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  v_quaternion = jnp.concatenate([v, jnp.array([0.0])])\n\n  # Apply the rotation using quaternion multiplication\n  q_conj = conjugate(q)\n  rotated_v_quaternion = multiply(multiply(q, v_quaternion), q_conj)\n\n  # Convert the rotated quaternion back to a vector format\n  rotated_v = rotated_v_quaternion[:3]\n\n  return rotated_v"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  v_quaternion = jnp.concatenate([v, jnp.array([0.0])])\n\n  # Perform the quaternion rotation\n  q_conj = conjugate(q)\n  v_rotated = multiply(q, multiply(v_quaternion, q_conj))[:3]\n\n  return v_rotated"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  v_quaternion = jnp.concatenate([v, jnp.array([0.0])])\n\n  # Apply the rotation using quaternion multiplication\n  rotated_v_quaternion = multiply(multiply(q, v_quaternion), conjugate(q))\n\n  # Convert the rotated quaternion back to a vector format\n  rotated_v = rotated_v_quaternion[:3]\n\n  return rotated_v"}
{"namespace": "quaternion.from_axis_angle", "completion": "  half_angle = jnp.linalg.norm(axis_angle) / 2.0\n  sin_half_angle = jnp.sin(half_angle)\n  cos_half_angle = jnp.cos(half_angle)\n\n  # If the angle is close to zero, use a small angle approximation to avoid\n  # division by zero and ensure numerical stability.\n  small_angle = sin_half_angle < eps\n  scale = jnp.where(small_angle, 0.5 - (half_angle ** 2) / 12.0, sin_half_angle / half_angle)\n\n  return jnp.concatenate([axis_angle * scale, cos_half_angle], axis=-1)"}
{"namespace": "quaternion.from_axis_angle", "completion": "  half_angle = jnp.linalg.norm(axis_angle) / 2.0\n  axis = axis_angle / jnp.maximum(jnp.linalg.norm(axis_angle), eps * jnp.ones_like(axis_angle))\n  w = jnp.cos(half_angle)\n  xyz = jnp.sin(half_angle) * axis\n  return jnp.concatenate((xyz, w), axis=-1)"}
{"namespace": "quaternion.from_axis_angle", "completion": "  half_angle = linalg.norm(axis_angle) / 2.0\n  axis = axis_angle / (linalg.norm(axis_angle) + eps)\n  w = jnp.cos(half_angle)\n  xyz = jnp.sin(half_angle) * axis\n  return jnp.concatenate((xyz, w), axis=-1)"}
{"namespace": "quaternion.from_axis_angle", "completion": "  half_angle = jnp.linalg.norm(axis_angle) / 2.0\n  direction = jnp.divide(axis_angle, jnp.maximum(jnp.linalg.norm(axis_angle), eps * jnp.ones_like(axis_angle)))\n  w = jnp.cos(half_angle)\n  xyz = jnp.sin(half_angle) * direction\n  return jnp.concatenate((xyz, w), axis=-1)"}
{"namespace": "quaternion.from_axis_angle", "completion": "  half_angle = jnp.linalg.norm(axis_angle) / 2.0\n  sin_half_angle = jnp.sin(half_angle)\n  cos_half_angle = jnp.cos(half_angle)\n\n  # If the angle is close to zero, use a small angle approximation to avoid division by zero\n  small_angle_mask = half_angle < eps\n  k = jnp.where(small_angle_mask, 0.5 - half_angle**2 / 24.0, sin_half_angle / half_angle)\n\n  # Construct the quaternion\n  w = cos_half_angle\n  xyz = axis_angle * k\n  return jnp.concatenate([xyz, w], axis=-1)"}
{"namespace": "quaternion.from_axis_angle", "completion": "  theta = linalg.norm(axis_angle)\n  half_theta = 0.5 * theta\n  k = jnp.where(theta > eps, jnp.sin(half_theta) / theta, 0.5)\n\n  return jnp.concatenate([jnp.sin(half_theta) * axis_angle * k, jnp.cos(half_theta)], axis=-1)"}
{"namespace": "quaternion.from_axis_angle", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  half_theta = theta / 2.0\n  sin_half_theta = jnp.sin(half_theta)\n  cos_half_theta = jnp.cos(half_theta)\n\n  # Avoid division by zero for small angles\n  k = jnp.where(theta > eps, sin_half_theta / theta, 0.5)\n\n  # Construct the quaternion\n  return jnp.concatenate([k * axis_angle, cos_half_theta], axis=-1)"}
{"namespace": "quaternion.from_axis_angle", "completion": "  half_angle = jnp.linalg.norm(axis_angle) / 2\n  axis = jnp.divide(axis_angle, jnp.linalg.norm(axis_angle) + eps)\n  w = jnp.cos(half_angle)\n  xyz = jnp.sin(half_angle) * axis\n  return jnp.concatenate((xyz, w), axis=-1)"}
{"namespace": "quaternion.from_axis_angle", "completion": "  half_angle = jnp.linalg.norm(axis_angle) / 2.0\n  sin_half_angle = jnp.sin(half_angle)\n  cos_half_angle = jnp.cos(half_angle)\n\n  # If the angle is close to zero, use a small angle approximation to avoid division by zero\n  sin_half_angle = jnp.where(sin_half_angle < eps, jnp.sqrt(eps), sin_half_angle)\n\n  # Normalize the axis of rotation\n  axis = axis_angle / jnp.linalg.norm(axis_angle)\n\n  # Construct the quaternion\n  return jnp.concatenate([axis * sin_half_angle, cos_half_angle])"}
{"namespace": "quaternion.from_axis_angle", "completion": "  half_angle = jnp.linalg.norm(axis_angle) / 2.0\n  sin_half_angle = jnp.sin(half_angle)\n  cos_half_angle = jnp.cos(half_angle)\n\n  # If the angle is close to zero, use a small angle approximation to avoid division by zero\n  small_angle = sin_half_angle < eps\n  scale = jnp.where(small_angle, 0.5 - (half_angle ** 2) / 12.0, sin_half_angle / (2.0 * half_angle))\n\n  # Construct the quaternion\n  w = cos_half_angle\n  xyz = axis_angle * scale\n  return jnp.concatenate((xyz, w))"}
{"namespace": "quaternion.from_axis_angle", "completion": "  half_angle = jnp.linalg.norm(axis_angle) / 2.0\n  sin_half_angle = jnp.sin(half_angle)\n  cos_half_angle = jnp.cos(half_angle)\n\n  # If the angle is close to zero, use a small angle approximation to avoid division by zero\n  if half_angle < eps:\n      return jnp.array([axis_angle[0], axis_angle[1], axis_angle[2], 1.0])\n\n  # Normalize the axis of rotation\n  axis = axis_angle / jnp.linalg.norm(axis_angle)\n\n  # Construct the quaternion\n  return jnp.concatenate([axis * sin_half_angle, cos_half_angle], axis=-1)"}
{"namespace": "quaternion.from_axis_angle", "completion": "  half_angle = jnp.linalg.norm(axis_angle) / 2.0\n  axis = axis_angle / (jnp.linalg.norm(axis_angle) + eps)\n  w = jnp.cos(half_angle)\n  xyz = jnp.sin(half_angle) * axis\n  return jnp.concatenate((xyz, w))"}
{"namespace": "quaternion.from_axis_angle", "completion": "  half_angle = jnp.linalg.norm(axis_angle) / 2.0\n  sin_half_angle = jnp.sin(half_angle)\n  cos_half_angle = jnp.cos(half_angle)\n\n  # Ensure numerical stability for small angles\n  sin_half_angle = jnp.maximum(sin_half_angle, eps)\n\n  # Normalize the axis of rotation\n  axis = axis_angle / jnp.linalg.norm(axis_angle)\n\n  # Construct the quaternion\n  return jnp.concatenate([axis * sin_half_angle, cos_half_angle])"}
{"namespace": "quaternion.from_axis_angle", "completion": "  half_angle = jnp.linalg.norm(axis_angle) / 2.0\n  direction = axis_angle / (jnp.linalg.norm(axis_angle) + eps)\n  w = jnp.cos(half_angle)\n  xyz = jnp.sin(half_angle) * direction\n  return jnp.concatenate((xyz, w), axis=-1)"}
{"namespace": "quaternion.from_axis_angle", "completion": "  half_angle = jnp.linalg.norm(axis_angle) / 2.0\n  sin_half_angle = jnp.sin(half_angle)\n  cos_half_angle = jnp.cos(half_angle)\n\n  # If the angle is close to zero, use a small angle approximation to avoid division by zero\n  small_angle = jnp.where(half_angle < eps, 1.0 - (half_angle ** 2) / 6.0, sin_half_angle / half_angle)\n\n  # Construct the quaternion\n  return jnp.concatenate([small_angle * axis_angle, cos_half_angle], axis=-1)"}
{"namespace": "quaternion.from_axis_angle", "completion": "  half_angle = jnp.linalg.norm(axis_angle) / 2.0\n  sin_half_angle = jnp.sin(half_angle)\n  cos_half_angle = jnp.cos(half_angle)\n\n  # If the angle is close to zero, use a small angle approximation to avoid division by zero\n  sin_half_angle = jnp.where(sin_half_angle < eps, jnp.sqrt(eps), sin_half_angle)\n\n  # Normalize the axis of rotation\n  axis = axis_angle / jnp.linalg.norm(axis_angle)\n\n  # Construct the quaternion\n  return jnp.concatenate([axis * sin_half_angle, cos_half_angle])"}
{"namespace": "quaternion.from_axis_angle", "completion": "  half_angle = jnp.linalg.norm(axis_angle) / 2.0\n  axis = axis_angle / jnp.maximum(jnp.linalg.norm(axis_angle), eps * jnp.ones_like(axis_angle))\n  w = jnp.cos(half_angle)\n  xyz = jnp.sin(half_angle) * axis\n  return jnp.concatenate((xyz, w), axis=-1)"}
{"namespace": "quaternion.from_axis_angle", "completion": "  half_angle = jnp.linalg.norm(axis_angle) / 2.0\n  axis = axis_angle / (jnp.linalg.norm(axis_angle) + eps)\n  w = jnp.cos(half_angle)\n  xyz = jnp.sin(half_angle) * axis\n  return jnp.concatenate((xyz, w))"}
{"namespace": "quaternion.from_axis_angle", "completion": "  half_angle = jnp.linalg.norm(axis_angle) / 2\n  sin_half_angle = jnp.sin(half_angle)\n  cos_half_angle = jnp.cos(half_angle)\n  axis = axis_angle / jnp.maximum(jnp.linalg.norm(axis_angle), eps * jnp.ones_like(axis_angle))\n\n  w = cos_half_angle\n  xyz = axis * sin_half_angle\n\n  return jnp.concatenate((xyz, w), axis=-1)"}
{"namespace": "quaternion.from_axis_angle", "completion": "  half_angle = jnp.linalg.norm(axis_angle) / 2.0\n  sin_half_angle = jnp.sin(half_angle)\n  cos_half_angle = jnp.cos(half_angle)\n\n  # Ensure numerical stability for small angles\n  sin_half_angle = jnp.maximum(sin_half_angle, eps)\n\n  # Normalize the axis of rotation\n  axis = axis_angle / jnp.linalg.norm(axis_angle)\n\n  # Construct the quaternion\n  return jnp.concatenate([axis * sin_half_angle, cos_half_angle])"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    low = 0\n    num_calls = k\n    # check if idx is the argmax\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    logit_bias = {idx: high}\n    num_calls = k\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    low = 0\n    mid = (high + low) / 2\n    eps = 1e-8\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    logit_bias = {idx: high}\n    num_calls = k\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    low = 0\n    eps = 1e-8\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    logit_bias = {idx: high}\n    num_calls = k\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    low = 0\n    eps = 1e-8\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    logit_bias = {idx: high}\n    num_calls = k\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    low = 0\n    eps = 1e-8\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n\n    return -mid, num_calls"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    logit_bias = {idx: high}\n    num_calls = k\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    low = 0\n    eps = 1e-8\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return model.logprob(prefix, logit_bias), num_calls"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    logit_bias = {idx: high}\n    num_calls = k\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    low = 0\n    eps = 1e-8\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    logit_bias = {idx: high}\n    num_calls = k\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    low = 0\n    eps = 1e-8\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n\n    return model.topk(prefix, logit_bias)[idx], num_calls"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    mid = high / 2\n    while high >= 1:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            high -= 1\n        mid = high / 2\n        num_calls += k\n    return -mid, num_calls"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # get raw topk, could be done outside and passed in\n    logit_bias = {idx: high}\n    num_calls = k\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    low = 0\n    eps = 1e-8\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    logit_bias = {idx: high}\n    num_calls = k\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    low = 0\n    eps = 1e-8\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    logprob = -mid\n    return logprob, num_calls"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    top_logprob = model.topk(prefix)[idx]\n    num_calls = 0\n    logit_bias = {idx: high}\n    while model.topk(prefix, logit_bias)[0] != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    low = high / 2\n    while high - low > 1:\n        mid = (high + low) / 2\n        logit_bias[idx] = mid\n        if model.topk(prefix, logit_bias)[0] == idx:\n            high = mid\n        else:\n            low = mid\n        num_calls += k\n    return high, num_calls"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    logit_bias = {idx: high}\n    num_calls = k\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    low = 0\n    eps = 1e-8\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n\n    return model.topk(prefix, logit_bias)[idx], num_calls"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    logit_bias = {idx: high}\n    num_calls = k\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    low = 0\n    eps = 1e-8\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return model.topk(prefix, logit_bias)[idx], num_calls"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    logit_bias = {idx: high}\n    num_calls = k\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    low = 0\n    eps = 1e-8\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    logprob = -mid\n    return logprob, num_calls"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    logit_bias = {idx: high}\n    num_calls = k\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    low = 0\n    eps = 1e-8\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    logit_bias = {idx: high}\n    num_calls = k\n    while idx not in model.topk(prefix, logit_bias):\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    low = 0\n    while high >= low + 1:\n        mid = (high + low) // 2\n        logit_bias[idx] = mid\n        if idx in model.topk(prefix, logit_bias):\n            high = mid\n        else:\n            low = mid + 1\n        num_calls += k\n    return high, num_calls"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    logit_bias = {idx: high}\n    num_calls = k\n    while True:\n        topk_words = model.topk(prefix, logit_bias)\n        if idx in topk_words:\n            return topk_words[idx], num_calls\n        logit_bias[idx] *= 2\n        num_calls += k"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    logit_bias = {idx: high}\n    num_calls = k\n    topk_words = model.topk(prefix, logit_bias)\n    while idx not in topk_words:\n        logit_bias[idx] *= 2\n        topk_words = model.topk(prefix, logit_bias)\n        num_calls += k\n\n    low = 0\n    high = logit_bias[idx]\n    mid = (high + low) / 2\n    while high >= low + 1e-8:\n        logit_bias[idx] = mid\n        topk_words = model.topk(prefix, logit_bias)\n        if idx in topk_words:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n\n    return topk_words[idx], num_calls"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    logit_bias = {idx: high}\n    num_calls = k\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    low = 0\n    eps = 1e-8\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    prefix = obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\"\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=prefix,\n    )\n\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` is not empty.\")\n\n    if append:\n        raise NotImplementedError(\"Appending data to the directory is not currently supported.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in the directory is not currently supported.\")"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    prefix = obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\"\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=prefix,\n    )\n\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` already contains data.\")\n\n    if append:\n        raise NotImplementedError(\"Appending data to the directory is not implemented yet.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in the directory is not implemented yet.\")"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    prefix = obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\"\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=prefix,\n    )\n\n    # No files are found in this folder\n    if objects[\"KeyCount\"] == 0:\n        return\n\n    if append:\n        raise NotImplementedError(\"Appending data to the directory is not yet supported.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in the directory is not yet supported.\")\n\n    raise RuntimeError(f\"The provided output_dir `{output_dir.path}` already contains data.\")"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    prefix = obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\"\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=prefix,\n    )\n\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` is not empty.\")\n\n    if append:\n        raise NotImplementedError(\"Appending data to the directory is not currently implemented.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in the directory is not currently implemented.\")"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    prefix = obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\"\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=prefix,\n    )\n\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` is not empty.\")"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "\n    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    prefix = obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\"\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=prefix,\n    )\n\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` already contains data.\")\n\n    if append:\n        raise NotImplementedError(\"Appending data to the directory is not yet implemented.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in the directory is not yet implemented.\")"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "\n    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    prefix = obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\"\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=prefix,\n    )\n\n    # Check if the directory is empty\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` is not empty.\")\n\n    if append:\n        raise NotImplementedError(\"Appending data to the directory is not implemented yet.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in the directory is not implemented yet.\")"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    prefix = obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\"\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=prefix,\n    )\n\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` already contains data.\")\n\n    if append:\n        raise NotImplementedError(\"Appending data to the directory is not currently supported.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in the directory is not currently supported.\")"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    prefix = obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\"\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=prefix,\n    )\n\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` already contains data.\")\n\n    if append:\n        raise NotImplementedError(\"Appending data to the directory is not implemented.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in the directory is not implemented.\")"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "\n    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    prefix = obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\"\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=prefix,\n    )\n\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` already contains data.\")\n\n    if append:\n        raise NotImplementedError(\"Appending data to the directory is currently not implemented.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in the directory is currently not implemented.\")"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    prefix = obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\"\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=prefix,\n    )\n\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` is not empty.\")\n\n    if append:\n        raise NotImplementedError(\"Appending data to the directory is not currently supported.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in the directory is not currently supported.\")"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    prefix = obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\"\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=prefix,\n    )\n\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` is not empty.\")\n\n    if append:\n        raise NotImplementedError(\"Appending data to the directory is not currently supported.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in the directory is not currently supported.\")"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    prefix = obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\"\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=prefix,\n    )\n\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` is not empty.\")"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "\n    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    prefix = obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\"\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=prefix,\n    )\n\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` already contains data.\")\n\n    if append:\n        raise NotImplementedError(\"Appending data to the directory is not currently supported.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in the directory is not currently supported.\")"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "\n    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    prefix = obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\"\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=prefix,\n    )\n\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` already contains data.\")\n\n    if append:\n        raise NotImplementedError(\"Appending data to the directory is not currently supported.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in the directory is not currently supported.\")"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "\n    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    prefix = obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\"\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=prefix,\n    )\n\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` already contains data.\")\n\n    if append:\n        raise NotImplementedError(\"Appending data to the directory is not currently supported.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in the directory is not currently supported.\")"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "\n    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    prefix = obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\"\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=prefix,\n    )\n\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` already contains data.\")\n\n    if append:\n        raise NotImplementedError(\"Appending data to the directory is not supported yet.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in the directory is not supported yet.\")"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "\n    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    prefix = obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\"\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=prefix,\n    )\n\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` already contains data.\")\n\n    if append:\n        raise NotImplementedError(\"Appending data to the directory is not implemented.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in the directory is not implemented.\")"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "\n    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    prefix = obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\"\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=prefix,\n    )\n\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` is not empty.\")"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    prefix = obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\"\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=prefix,\n    )\n\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` already contains data.\")\n\n    if append:\n        raise NotImplementedError(\"Appending data to the directory is not implemented.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in the directory is not implemented.\")"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # Check if the directory already contains an index file\n    index_file_exists = False\n    for content in objects.get('Contents', []):\n        if content['Key'].endswith('index.json'):\n            index_file_exists = True\n            break\n\n    if index_file_exists:\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` already contains an index file 'index.json'.\")\n\n    # If index file is not found, delete all objects within the specified prefix in the bucket\n    for content in objects.get('Contents', []):\n        s3.delete_object(Bucket=obj.netloc, Key=content['Key'])"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        raise ValueError(\"The provided folder should start with s3://. Found None.\")\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    index_file_exists = any(\n        file[\"Key\"].endswith(\"index.json\") for file in objects.get(\"Contents\", [])\n    )\n\n    if index_file_exists:\n        raise ValueError(f\"The provided output_dir `{output_dir.path}` already contains an index file named 'index.json'.\")\n\n    if objects.get(\"KeyCount\") == 0:\n        return  # No objects found, nothing to delete\n\n    # Delete all objects within the specified prefix in the bucket\n    s3.delete_objects(\n        Bucket=obj.netloc,\n        Delete={\n            \"Objects\": [{\"Key\": file[\"Key\"]} for file in objects.get(\"Contents\", [])],\n            \"Quiet\": False,\n        },\n    )"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "\n    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    index_file_exists = False\n    for content in objects.get(\"Contents\", []):\n        if content[\"Key\"].endswith(\"index.json\"):\n            index_file_exists = True\n            break\n\n    if index_file_exists:\n        raise ValueError(f\"The directory already contains an index file named 'index.json'.\")\n\n    if objects[\"KeyCount\"] > 0:\n        # Delete all objects within the specified prefix in the bucket\n        s3.delete_objects(\n            Bucket=obj.netloc,\n            Delete={\n                \"Objects\": [{\"Key\": content[\"Key\"]} for content in objects.get(\"Contents\", [])],\n                \"Quiet\": False,\n            },\n        )"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    try:\n        s3.head_object(Bucket=obj.netloc, Key=f\"{obj.path.lstrip('/').rstrip('/')}/index.json\")\n        raise RuntimeError(f\"The directory {output_dir.path} already contains an index file named 'index.json'.\")\n    except botocore.exceptions.ClientError as e:\n        if e.response[\"Error\"][\"Code\"] == \"404\":\n            # Index file not found, delete all objects within the specified prefix in the bucket\n            objects = s3.list_objects_v2(Bucket=obj.netloc, Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\")\n\n            if objects.get(\"Contents\"):\n                for content in objects[\"Contents\"]:\n                    s3.delete_object(Bucket=obj.netloc, Key=content[\"Key\"])"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "\n    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        raise ValueError(\"The provided folder should start with s3://. Found None.\")\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if objects[\"KeyCount\"] > 0:\n        for content in objects.get(\"Contents\", []):\n            if content[\"Key\"].endswith(\"index.json\"):\n                raise RuntimeError(f\"The provided output_dir `{output_dir.path}` already contains an index file.\")\n\n        # If index file is not found, delete all objects within the specified prefix in the bucket\n        for content in objects.get(\"Contents\", []):\n            s3.delete_object(Bucket=obj.netloc, Key=content[\"Key\"])"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # Check if \"index.json\" file exists\n    index_file_exists = False\n    for content in objects.get('Contents', []):\n        if content['Key'].endswith('index.json'):\n            index_file_exists = True\n            break\n\n    if index_file_exists:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains an index file named 'index.json'.\"\n        )\n    else:\n        # Delete all objects within the specified prefix in the bucket\n        for content in objects.get('Contents', []):\n            s3.delete_object(Bucket=obj.netloc, Key=content['Key'])"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if objects[\"KeyCount\"] > 0:\n        index_file_exists = any(obj[\"Key\"].endswith(\"index.json\") for obj in objects.get(\"Contents\", []))\n        if index_file_exists:\n            raise RuntimeError(f\"The provided output_dir `{output_dir.path}` already contains an index file named 'index.json'.\")\n\n        # Delete all objects within the specified prefix in the bucket\n        for obj in objects.get(\"Contents\", []):\n            s3.delete_object(Bucket=obj[\"Bucket\"], Key=obj[\"Key\"])"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if objects[\"KeyCount\"] > 0:\n        # Check if index.json file exists\n        index_file_exists = any(obj[\"Key\"].endswith(\"index.json\") for obj in objects.get(\"Contents\", []))\n        if index_file_exists:\n            raise RuntimeError(f\"The provided output_dir `{output_dir.path}` already contains an index file 'index.json'.\")\n        else:\n            # Delete all objects within the specified prefix in the bucket\n            s3.delete_objects(\n                Bucket=obj.netloc,\n                Delete={\n                    \"Objects\": [{\"Key\": obj[\"Key\"]} for obj in objects.get(\"Contents\", [])],\n                    \"Quiet\": False,\n                },\n            )"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        raise ValueError(\"The provided folder should start with s3://. Found None.\")\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    for content in objects.get(\"Contents\", []):\n        if content[\"Key\"].endswith(\"index.json\"):\n            raise ValueError(f\"The directory already contains an index file: {content['Key']}.\")\n\n    if objects[\"KeyCount\"] == 0:\n        raise ValueError(f\"No objects found in the specified prefix: {obj.path}\")\n\n    # Delete all objects within the specified prefix in the bucket\n    s3.delete_objects(\n        Bucket=obj.netloc,\n        Delete={\n            \"Objects\": [{\"Key\": content[\"Key\"]} for content in objects.get(\"Contents\", [])],\n            \"Quiet\": True,\n        },\n    )"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "\n    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    index_file_found = False\n    for content in objects.get(\"Contents\", []):\n        if content[\"Key\"].endswith(\"index.json\"):\n            index_file_found = True\n            break\n\n    if index_file_found:\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` already contains an index file.\")\n\n    # If index file is not found, delete all objects within the specified prefix in the bucket\n    for content in objects.get(\"Contents\", []):\n        s3.delete_object(Bucket=obj.netloc, Key=content[\"Key\"])"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # Check if an index file already exists\n    index_file_exists = False\n    for content in objects.get(\"Contents\", []):\n        if content[\"Key\"].endswith(\"index.json\"):\n            index_file_exists = True\n            break\n\n    if index_file_exists:\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` already contains an index file.\")\n\n    # If index file doesn't exist, delete all objects within the specified prefix in the bucket\n    for content in objects.get(\"Contents\", []):\n        s3.delete_object(Bucket=obj.netloc, Key=content[\"Key\"])"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # Check if index.json file exists\n    index_file_exists = False\n    for content in objects.get(\"Contents\", []):\n        if content[\"Key\"].endswith(\"index.json\"):\n            index_file_exists = True\n            break\n\n    if index_file_exists:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains an index file named 'index.json'.\"\n        )\n\n    # Delete all objects within the specified prefix in the bucket\n    for content in objects.get(\"Contents\", []):\n        s3.delete_object(Bucket=obj.netloc, Key=content[\"Key\"])"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    index_file_exists = False\n    for content in objects.get(\"Contents\", []):\n        if content[\"Key\"].endswith(\"index.json\"):\n            index_file_exists = True\n            break\n\n    if index_file_exists:\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` already contains an index file.\")\n\n    # If index file is not found, delete all objects within the specified prefix in the bucket\n    for content in objects.get(\"Contents\", []):\n        s3.delete_object(Bucket=obj.netloc, Key=content[\"Key\"])"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if \"Contents\" in objects and any(obj[\"Key\"].endswith(\"index.json\") for obj in objects[\"Contents\"]):\n        raise ValueError(f\"The directory already contains an index file named 'index.json'.\")\n\n    # If index file not found, delete all objects within the specified prefix in the bucket\n    for content in objects.get(\"Contents\", []):\n        s3.delete_object(Bucket=obj.netloc, Key=content[\"Key\"])"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if objects[\"KeyCount\"] > 0:\n        for content in objects.get(\"Contents\", []):\n            if content[\"Key\"].endswith(\"index.json\"):\n                raise RuntimeError(f\"The provided output_dir `{output_dir.path}` already contains an index file.\")\n\n        # If index file not found, delete all objects within the specified prefix in the bucket\n        for content in objects.get(\"Contents\", []):\n            s3.delete_object(Bucket=obj.netloc, Key=content[\"Key\"])"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    index_file_present = False\n    for content in objects.get(\"Contents\", []):\n        if content[\"Key\"].endswith(\"index.json\"):\n            index_file_present = True\n            break\n\n    if index_file_present:\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` already contains an index file 'index.json'.\")\n\n    # If index file is not present, delete all objects within the specified prefix in the bucket\n    for content in objects.get(\"Contents\", []):\n        s3.delete_object(Bucket=obj.netloc, Key=content[\"Key\"])"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    index_file_exists = False\n    for content in objects.get(\"Contents\", []):\n        if content[\"Key\"].endswith(\"index.json\"):\n            index_file_exists = True\n            break\n\n    if index_file_exists:\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` already contains an index file.\")\n\n    # Delete all objects within the specified prefix in the bucket\n    for content in objects.get(\"Contents\", []):\n        s3.delete_object(Bucket=obj.netloc, Key=content[\"Key\"])"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "\n    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        raise ValueError(\"The provided output_dir doesn't have a URL.\")\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    index_file_exists = any(obj[\"Key\"].endswith(\"index.json\") for obj in objects.get(\"Contents\", []))\n\n    if index_file_exists:\n        raise ValueError(f\"The provided output_dir `{output_dir.path}` already contains an index file named 'index.json'.\")\n\n    # Delete all objects within the specified prefix in the bucket\n    for obj in objects.get(\"Contents\", []):\n        s3.delete_object(Bucket=obj[\"Bucket\"], Key=obj[\"Key\"])"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    for content in objects.get(\"Contents\", []):\n        if content[\"Key\"].endswith(\"index.json\"):\n            raise RuntimeError(f\"The provided output_dir `{output_dir.path}` already contains an index file.\")\n\n    # Delete all objects within the specified prefix in the bucket\n    for content in objects.get(\"Contents\", []):\n        s3.delete_object(Bucket=obj.netloc, Key=content[\"Key\"])"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "\n    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    index_file_exists = False\n    for content in objects.get('Contents', []):\n        if content['Key'] == 'index.json':\n            index_file_exists = True\n            break\n\n    if index_file_exists:\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` already contains an index file.\")\n\n    # Delete all objects within the specified prefix in the bucket\n    if objects[\"KeyCount\"] > 0:\n        s3.delete_objects(\n            Bucket=obj.netloc,\n            Delete={\n                'Objects': [{'Key': content['Key']} for content in objects.get('Contents', [])]\n            }\n        )"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "\n        if node_rank is not None and node_rank != 0:\n            # Wait for the master node to perform the merge\n            while not os.path.exists(os.path.join(self._cache_dir, _INDEX_FILENAME)):\n                sleep(1)\n            return\n\n        # Perform the merge operation\n        self._merge_no_wait(node_rank)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if self.rank != 0 and node_rank is None:\n            # Wait for the master node to perform the merge\n            while not os.path.exists(os.path.join(self._cache_dir, _INDEX_FILENAME)):\n                sleep(1)\n            return\n\n        self._merge_no_wait(node_rank)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "\n        if node_rank is not None and node_rank != 0:\n            # Wait for the master node to perform the merge\n            while not os.path.exists(os.path.join(self._cache_dir, _INDEX_FILENAME)):\n                sleep(1)\n            return\n\n        # Master node (rank 0) performs the merge\n        self._merge_no_wait(node_rank)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if self.rank != 0 and node_rank is None:\n            # Wait for the master node to perform the merge\n            while not os.path.exists(os.path.join(self._cache_dir, _INDEX_FILENAME)):\n                sleep(1)\n\n        if self.rank == 0 or node_rank is not None:\n            # Master node or specified node_rank performs the merge\n            self._merge_no_wait(node_rank)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "\n        if self.rank != 0:\n            # Wait for the master node to perform the merge\n            while not os.path.exists(os.path.join(self._cache_dir, _INDEX_FILENAME)):\n                sleep(1)\n            return\n\n        self._merge_no_wait(node_rank)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            # Check if all workers have written their index\n            while len(os.listdir(self._cache_dir)) < num_workers:\n                sleep(1)\n\n            # Merge the index files\n            self._merge_no_wait()\n        else:\n            # Wait for the master node to finish merging\n            while not os.path.exists(os.path.join(self._cache_dir, _INDEX_FILENAME)):\n                sleep(1)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "\n        if self.rank != 0:\n            # Wait for the master node to perform the merge\n            while not os.path.exists(os.path.join(self._cache_dir, _INDEX_FILENAME)):\n                sleep(1)\n            return\n\n        self._merge_no_wait(node_rank)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if self.rank != 0:\n            while not os.path.exists(os.path.join(self._cache_dir, _INDEX_FILENAME)):\n                sleep(1)\n\n        self._merge_no_wait(node_rank)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "\n        if self.rank != 0 and node_rank is None:\n            while not os.path.exists(os.path.join(self._cache_dir, _INDEX_FILENAME)):\n                sleep(1)\n            return\n\n        self._merge_no_wait(node_rank)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if self.rank != 0:\n            # Wait for the master node to merge\n            while not os.path.exists(os.path.join(self._cache_dir, _INDEX_FILENAME)):\n                sleep(1)\n            return\n\n        self._merge_no_wait(node_rank)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "\n        if node_rank is not None and node_rank != 0:\n            # Wait for the master node to perform the merge\n            while not os.path.exists(os.path.join(self._cache_dir, _INDEX_FILENAME)):\n                sleep(1)\n            return\n\n        # Perform the merge\n        self._merge_no_wait(node_rank)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is not None and node_rank != 0:\n            # Wait for the master node to perform the merge\n            while not os.path.exists(os.path.join(self._cache_dir, _INDEX_FILENAME)):\n                sleep(1)\n            return\n\n        # Perform the merge\n        self._merge_no_wait(node_rank)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "\n        # Wait for all workers to write their index files\n        while len(os.listdir(self._cache_dir)) < num_workers:\n            sleep(1)\n\n        # Merge the index files only if it's the master node (rank 0)\n        if node_rank is None or node_rank == 0:\n            self._merge_no_wait()\n        else:\n            # Wait for the master node to finish merging\n            while not os.path.exists(os.path.join(self._cache_dir, _INDEX_FILENAME)):\n                sleep(1)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if self.rank != 0 and node_rank is None:\n            while not os.path.exists(os.path.join(self._cache_dir, _INDEX_FILENAME)):\n                sleep(1)\n            return\n\n        self._merge_no_wait(node_rank)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "\n        # Check if all workers have written their index files\n        if self.rank == 0:\n            while len(os.listdir(self._cache_dir)) < num_workers:\n                sleep(1)\n\n        # Perform the merge only if it's the master node (rank 0)\n        if self.rank == 0:\n            self._merge_no_wait(node_rank)\n        else:\n            while not os.path.isfile(os.path.join(self._cache_dir, _INDEX_FILENAME)):\n                sleep(1)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if self.rank != 0:\n            # Wait until the merged index file is available\n            while not os.path.isfile(os.path.join(self._cache_dir, _INDEX_FILENAME)):\n                sleep(1)\n            return\n\n        self._merge_no_wait(node_rank)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "\n        # Wait for all workers to write their index files\n        while len(os.listdir(self._cache_dir)) < num_workers:\n            sleep(1)\n\n        # Perform merge only if it's the master node (rank 0)\n        if node_rank is None or node_rank == 0:\n            self._merge_no_wait(node_rank)\n        else:\n            # Wait for the merged index file to be available\n            while f\"{node_rank}-{_INDEX_FILENAME}\" not in os.listdir(self._cache_dir):\n                sleep(1)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "\n        # Wait for all workers to write their index files\n        while len(os.listdir(self._cache_dir)) < num_workers:\n            sleep(1)\n\n        # If the node is not the master node, wait for the master node to finish the merge\n        if node_rank is not None and node_rank != 0:\n            while not os.path.exists(os.path.join(self._cache_dir, _INDEX_FILENAME)):\n                sleep(1)\n            return\n\n        # Once all parts are available and it's the master node, proceed with the merge\n        self._merge_no_wait(node_rank)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if num_workers > 1 and (node_rank is None or node_rank == 0):\n            self._merge_no_wait(node_rank)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "\n        if self.rank != 0:\n            # Wait until the master node has finished merging\n            while not os.path.exists(os.path.join(self._cache_dir, _INDEX_FILENAME)):\n                sleep(1)\n            return\n\n        # Master node (rank 0) performs the merge\n        self._merge_no_wait(node_rank)"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install the Lightning SDK to use this function.\")\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\"The boto3 library is not available. Please install boto3 to use this function.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_CLOUD_COMMAND', 'python')} {sys.argv[0]}\"\n\n    client = LightningClient(max_tries=2)\n    studio = Studio()\n\n    job = studio.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command,\n    )\n\n    print(f\"Job created: {job.url}\")\n\n    while True:\n        job.refresh()\n        if job.status in [\"failed\", \"finished\"]:\n            if job.status == \"failed\":\n                raise RuntimeError(f\"The job {job.name} failed. Check the job logs for more details.\")\n            break\n        sleep(10)\n\n    print(f\"Job finished: {job.url}\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise ImportError(\"The `lightning_sdk` is required to execute jobs on the Lightning Cloud.\")\n\n    if not machine:\n        machine = Machine()\n\n    if not command:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_CLOUD_COMMAND', 'echo Hello, Lightning Cloud!')}\"\n\n    studio = Studio()\n\n    job = studio.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command\n    )\n\n    print(f\"Job created: {job.url}\")\n\n    while True:\n        job.refresh()\n        if job.status == \"failed\":\n            raise RuntimeError(f\"The job '{name}' has failed. Please check the job logs for more details.\")\n        if job.status == \"succeeded\":\n            print(f\"The job '{name}' has succeeded. You can access the job output at: {job.output_dir.url}\")\n            break\n        sleep(5)"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install the SDK to use this function.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_COMMAND', 'echo No command provided')}\"\n\n    studio = Studio()\n\n    job = studio.job.create(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command\n    )\n\n    job_url = f\"{_get_lightning_cloud_url()}/jobs/{job.id}\"\n\n    print(f\"Job started: {job_url}\")\n\n    while job.status not in [\"failed\", \"completed\"]:\n        job.refresh()\n        sleep(5)\n\n    if job.status == \"failed\":\n        raise RuntimeError(f\"The job {job_url} failed. Please check the job logs for more details.\")\n\n    print(f\"The job {job_url} has completed successfully.\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install the SDK to use this function.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_COMMAND', 'python')} {sys.argv[0]}\"\n\n    studio = Studio()\n\n    job = studio.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command\n    )\n\n    job_url = f\"{_get_lightning_cloud_url()}/jobs/{job.id}\"\n\n    print(f\"Job started. Check the status at: {job_url}\")\n\n    while job.status not in [\"completed\", \"failed\"]:\n        sleep(10)\n        job.refresh()\n\n    if job.status == \"failed\":\n        raise RuntimeError(f\"The job '{name}' failed. Check the job details at: {job_url}\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install the SDK to use this function.\")\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\"The boto3 library is not available. Please install boto3 to use this function.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_COMMAND', 'python')} operator.py\"\n\n    studio = Studio()\n\n    job = studio.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command\n    )\n\n    print(f\"Job started: {job.url}\")\n\n    while True:\n        job.refresh()\n        if job.status in [\"failed\", \"stopped\"]:\n            raise RuntimeError(f\"The job {job.name} has failed. Please check the job logs for more details.\")\n        if job.status == \"running\":\n            break\n        sleep(5)"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install the SDK before using this function.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_COMMAND', 'python')} -m lightning_sdk.operator {name}\"\n\n    studio = Studio()\n\n    job = studio.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command\n    )\n\n    print(f\"Job created: {job.url}\")\n\n    while job.status not in [\"failed\", \"succeeded\"]:\n        sleep(5)\n        job.refresh()\n\n    if job.status == \"failed\":\n        raise RuntimeError(f\"The job {job.name} failed. Please check the job logs for more information.\")\n\n    print(f\"Job {job.name} succeeded. Job URL: {job.url}\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install the SDK to use this function.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_CLOUD_COMMAND', 'python')} -m lightning_cloud.operator\"\n\n    studio = Studio()\n\n    job = studio.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command\n    )\n\n    job_url = f\"{_get_lightning_cloud_url()}/jobs/{job.id}\"\n    print(f\"The job has started. You can monitor the job at: {job_url}\")\n\n    while job.status in [\"PENDING\", \"RUNNING\"]:\n        sleep(10)\n        job.refresh()\n\n    if job.status != \"SUCCEEDED\":\n        raise RuntimeError(f\"The job failed with status: {job.status}. Please check the job logs for more information.\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK isn't available. Please install it to use this feature.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_COMMAND', 'echo No command provided.')}\"\n\n    studio = Studio()\n    job = studio.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command,\n    )\n\n    print(f\"Job started: {job.url}\")\n\n    while not job.is_finished():\n        sleep(5)\n\n    if job.status != \"SUCCEEDED\":\n        raise RuntimeError(f\"Job failed: {job.url}\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The `lightning_sdk` is not available. Please install the `lightning-sdk` package.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_JOB_COMMAND', 'echo No command provided.')}\"\n\n    studio = Studio()\n    job = studio.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command\n    )\n\n    print(f\"Job started: {job.url}\")\n\n    while True:\n        job.refresh()\n        if job.status in [\"failed\", \"stopped\"]:\n            raise RuntimeError(f\"The job {job.name} failed. Please check the logs for more details.\")\n        if job.status == \"succeeded\":\n            print(f\"Job succeeded: {job.url}\")\n            break\n        sleep(5)"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install the Lightning SDK to use this function.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {Path.cwd()} && {os.getenv('LIGHTNING_CLOUD_COMMAND', 'python')} operator.py\"\n\n    studio = Studio()\n    job = studio.jobs.create(name=name, num_nodes=num_nodes, machine=machine, command=command)\n\n    job_url = f\"{_get_lightning_cloud_url()}/jobs/{job.id}\"\n    print(f\"Job started: {job_url}\")\n\n    while job.status != \"succeeded\" and job.status != \"failed\":\n        job.refresh()\n        sleep(5)\n\n    if job.status == \"failed\":\n        raise RuntimeError(f\"The job failed. Check the job details at: {job_url}\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install the Lightning SDK to use this function.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_OPERATOR_COMMAND')}\"\n\n    studio = Studio()\n\n    job = studio.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command\n    )\n\n    job_url = f\"{_get_lightning_cloud_url()}/jobs/{job.id}\"\n\n    print(f\"Job started! Check the status at: {job_url}\")\n\n    while job.status not in [\"failed\", \"completed\"]:\n        job.refresh()\n        sleep(5)\n\n    if job.status == \"failed\":\n        raise RuntimeError(f\"The job {name} failed. Check the job status at: {job_url}\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install the SDK to use this function.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_OPERATOR_COMMAND', 'python operator.py')}\"\n\n    studio = Studio()\n    job = studio.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command\n    )\n\n    job_url = f\"{_get_lightning_cloud_url()}/projects/{os.getenv('LIGHTNING_CLOUD_PROJECT_ID')}/jobs/{job.id}\"\n    print(f\"The job has been created. You can monitor the job status at: {job_url}\")\n\n    while job.status == \"PENDING\" or job.status == \"RUNNING\":\n        sleep(5)\n        job.refresh()\n\n    if job.status == \"FAILED\":\n        raise RuntimeError(f\"The job {name} has failed. Please check the job logs for more details.\")\n\n    if job.status == \"SUCCEEDED\":\n        print(f\"The job {name} has completed successfully. You can access the job output at: {job.output_dir.url}\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install the SDK to use this function.\")\n\n    if not machine:\n        machine = Machine()\n\n    if not command:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_COMMAND', 'echo No command provided')}\"\n\n    studio = Studio()\n\n    job = studio.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command\n    )\n\n    print(f\"Job started: {job.url}\")\n\n    while True:\n        job.refresh()\n        if job.status in [\"pending\", \"running\"]:\n            sleep(10)\n        elif job.status == \"failed\":\n            raise RuntimeError(f\"The job {name} has failed. Please check the job logs for more information.\")\n        elif job.status == \"succeeded\":\n            break"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install the SDK to use this function.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"python -m lightning_cloud execute {os.getcwd()}\"\n\n    studio = Studio()\n\n    job = studio.jobs.create(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command\n    )\n\n    print(f\"Job created: {job.url}\")\n\n    while True:\n        job.refresh()\n        if job.status == \"running\":\n            print(f\"Job started: {job.url}\")\n            break\n        elif job.status == \"failed\":\n            raise RuntimeError(f\"Job failed: {job.url}\")\n        elif job.status == \"stopped\":\n            raise RuntimeError(f\"Job stopped: {job.url}\")\n        sleep(5)"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install the SDK to use this function.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_OPERATOR_COMMAND', 'python -m lightning_operator')}\"\n\n    studio = Studio()\n\n    job = studio.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command\n    )\n\n    print(f\"Job created: {job.url}\")\n\n    while job.status != \"running\":\n        sleep(5)\n        job.refresh()\n\n    print(f\"Job started: {job.url}\")\n\n    if job.status == \"failed\":\n        raise RuntimeError(f\"The job {job.name} failed. Please check the job logs for more information.\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install the SDK to use this function.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_CLOUD_PREPARE_CMD', 'prepare')}\"\n\n    studio = Studio()\n\n    job = studio.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command\n    )\n\n    job_url = f\"{_get_lightning_cloud_url()}/jobs/{job.id}\"\n\n    print(f\"The job has been started. You can monitor the job at: {job_url}\")\n\n    while job.status != \"completed\" and job.status != \"failed\":\n        job.refresh()\n        sleep(10)\n\n    if job.status == \"failed\":\n        raise RuntimeError(f\"The job {name} has failed. Please check the job logs for more information.\")\n\n    print(f\"The job {name} has completed successfully.\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install the lightning-sdk package.\")\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\"The boto3 package is not available. Please install the boto3 package.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd $PWD && {sys.executable} -m lightning_sdk.operator_execution\"\n\n    studio = Studio()\n\n    job = studio.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command\n    )\n\n    print(f\"Job started: {job.url}\")\n\n    while job.status != \"running\":\n        sleep(5)\n        job.refresh()\n\n    if job.status != \"running\":\n        raise RuntimeError(f\"Job failed: {job.url}\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install the SDK and try again.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_COMMAND', 'python -m lightning')}\"\n\n    studio = Studio()\n\n    job = studio.jobs.create(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command\n    )\n\n    job_url = f\"{_get_lightning_cloud_url()}/jobs/{job.id}\"\n\n    print(f\"Job started: {job_url}\")\n\n    while True:\n        job.refresh()\n        if job.status in [\"failed\", \"stopped\"]:\n            raise RuntimeError(f\"Job failed: {job_url}\")\n        if job.status == \"succeeded\":\n            break\n        sleep(5)"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install the SDK to use this function.\")\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\"The boto3 library is not available. Please install boto3 to use this function.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_OPERATOR_COMMAND', 'python -m lightning_operators')}\"\n\n    studio = Studio()\n\n    job = studio.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command\n    )\n\n    print(f\"Job started: {job.url}\")\n\n    while job.status not in [\"completed\", \"failed\", \"stopped\"]:\n        sleep(5)\n        job.refresh()\n\n    if job.status == \"failed\":\n        raise RuntimeError(f\"The job {name} failed. Please check the job logs for more details.\")\n\n    if job.status == \"stopped\":\n        raise RuntimeError(f\"The job {name} was stopped. Please check the job logs for more details.\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install the SDK to use this function.\")\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\"The boto3 library is not available. Please install boto3 to use this function.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_OPERATOR_COMMAND', 'python')} operator.py\"\n\n    studio = Studio()\n    job = studio.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command\n    )\n\n    print(f\"Job started. Job URL: {job.url}\")\n\n    while job.status not in [\"failed\", \"succeeded\"]:\n        job.refresh()\n        sleep(5)\n\n    if job.status == \"failed\":\n        raise RuntimeError(f\"Job execution failed. Job URL: {job.url}\")"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Your code to load the configuration goes here\n        # Example:\n        if os.path.exists(self._cache_dir):\n            # Load the configuration\n            config = ChunksConfig.load_from_cache(self._cache_dir, self._serializers, self._remote_input_dir, self._item_loader)\n            if config:\n                self._config = config\n                return config\n        return None"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        index_file = os.path.join(self._cache_dir, \"index.json\")\n        if os.path.exists(index_file):\n            try:\n                config = ChunksConfig.load(index_file, self._cache_dir, self._remote_input_dir, self._compression, self._item_loader, self._serializers)\n                self._config = config\n                return config\n            except Exception as e:\n                logger.warning(f\"Failed to load chunks configuration: {e}\")\n        return None"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        config_file = os.path.join(self._cache_dir, \"config\")\n        if os.path.exists(config_file):\n            try:\n                with open(config_file, \"rb\") as f:\n                    config = ChunksConfig.deserialize(f, self._cache_dir, self._remote_input_dir, self._serializers, self._item_loader)\n                    self._config = config\n                    return config\n            except Exception as e:\n                logger.warning(f\"Failed to load config from {config_file}: {e}\")\n        return None"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        if self._config is not None:\n            return self._config\n\n        # Logic to load the chunks configuration from index files\n        # ...\n        # ...\n\n        # If configuration is successfully loaded, update the instance's configuration\n        # self._config = loaded_chunks_config\n\n        # Return the loaded configuration\n        # return loaded_chunks_config\n        return None  # Placeholder until the actual logic to load the configuration is implemented"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        config_path = os.path.join(self._cache_dir, \"config.pkl\")\n        if os.path.exists(config_path):\n            try:\n                with open(config_path, \"rb\") as f:\n                    config = ChunksConfig.deserialize(f, self._serializers)\n                    if (\n                        config.remote_dir == self._remote_input_dir\n                        and config.compressor == self._compression\n                        and config.item_loader == self._item_loader\n                    ):\n                        self._config = config\n                        return config\n            except Exception as e:\n                logger.warning(f\"Error loading config: {e}\")\n        return None"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        index_file = os.path.join(self._cache_dir, \"index.json\")\n        if os.path.exists(index_file):\n            try:\n                config = ChunksConfig.from_index_file(\n                    index_file,\n                    cache_dir=self._cache_dir,\n                    remote_input_dir=self._remote_input_dir,\n                    serializers=self._serializers,\n                    item_loader=self._item_loader,\n                )\n                self._config = config\n                return config\n            except Exception as e:\n                logger.warning(f\"Failed to load ChunksConfig from index file: {e}\")\n        return None"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Your implementation here\n        if os.path.exists(self._cache_dir):\n            try:\n                config = ChunksConfig.load(self._cache_dir, serializers=self._serializers)\n                self._config = config\n                return config\n            except Exception as e:\n                logger.warning(f\"Failed to load ChunksConfig from cache directory: {e}\")\n        return None"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "    # Your code to load the chunks configuration goes here\n    # ..."}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Add your implementation here\n        # ..."}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "    if self._config is not None:\n        return self._config\n\n    # Add logic here to load the chunks configuration based on the attributes of the BinaryReader instance\n    # For example:\n    # if self._cache_dir and self._serializers and self._remote_input_dir and self._item_loader:\n    #     # Load the chunks configuration\n    #     self._config = ChunksConfig(...)  # Instantiate ChunksConfig based on the attributes\n    #     return self._config\n    # else:\n    #     return None\n\n    return None  # Placeholder, replace with actual logic to load and return ChunksConfig"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "    # Your implementation here\n    if os.path.exists(self._cache_dir):\n        # Load the chunks configuration if index files are available\n        config = ChunksConfig.load(self._cache_dir, serializers=self._serializers, remote_dir=self._remote_input_dir, item_loader=self._item_loader)\n        if config:\n            self._config = config  # Update the instance's configuration\n            return config\n    return None"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        if self._config is not None:\n            return self._config  # Configuration already loaded\n\n        config_path = os.path.join(self._cache_dir, \"config.json\")\n        if os.path.exists(config_path):\n            try:\n                config = ChunksConfig.load(config_path)\n                if config._serializers != self._serializers:\n                    config._serializers = self._serializers  # Update serializers if they have changed\n                if config._remote_dir != self._remote_input_dir:\n                    config._remote_dir = self._remote_input_dir  # Update remote directory if it has changed\n                if config._item_loader != self._item_loader:\n                    config._item_loader = self._item_loader  # Update item loader if it has changed\n                self._config = config\n                return self._config\n            except Exception as e:\n                logger.warning(f\"Failed to load config from {config_path}: {e}\")\n        return None"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        if self._config is not None:\n            return self._config  # Return the existing config if it's already loaded\n\n        config_file = os.path.join(self._cache_dir, \"config.json\")\n        if os.path.exists(config_file):\n            try:\n                self._config = ChunksConfig.from_file(\n                    config_file,\n                    cache_dir=self._cache_dir,\n                    remote_dir=self._remote_input_dir,\n                    serializers=self._serializers,\n                )\n                return self._config\n            except Exception as e:\n                logger.warning(f\"Failed to load config from {config_file}: {e}\")\n\n        return None"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        index_file = os.path.join(self._cache_dir, \"index.json\")\n        if os.path.exists(index_file):\n            try:\n                config = ChunksConfig(\n                    self._cache_dir,\n                    remote_dir=self._remote_input_dir,\n                    compression=self._compression,\n                    serializers=self._serializers,\n                )\n                self._config = config\n                return config\n            except Exception as e:\n                logger.warning(f\"Failed to load ChunksConfig from index file: {e}\")\n        return None"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "    # Your implementation here\n    config = ChunksConfig.load(self._cache_dir, serializers=self._serializers, remote_dir=self._remote_input_dir)\n    if config:\n        self._config = config\n        return config\n    else:\n        return None"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "    # Add code here to attempt to load the chunks configuration\n    # Use the attributes _cache_dir, _serializers, _remote_input_dir, and _item_loader to load the configuration\n    # If the configuration is successfully loaded, update the instance's configuration with the loaded ChunksConfig object\n    # Return the loaded ChunksConfig object if successful, otherwise return None\n    pass  # Placeholder for the actual implementation"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Your code to load the chunks configuration goes here\n        # ...\n        # ...\n        # ...\n        # Return the loaded ChunksConfig object or None\n        # return loaded_chunks_config"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Add code to attempt loading the chunks configuration here\n        # ...\n        pass"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "    config = ChunksConfig.try_load(self._cache_dir, self._remote_input_dir, self._serializers)\n    if config:\n        self._config = config\n        return config\n    return None"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        config_path = os.path.join(self._cache_dir, \"config.json\")\n        if os.path.exists(config_path):\n            try:\n                with open(config_path, \"r\") as f:\n                    config_dict = json.load(f)\n                self._config = ChunksConfig.from_dict(config_dict, self._cache_dir, self._remote_input_dir, self._serializers)\n                return self._config\n            except Exception as e:\n                logger.warning(f\"Failed to load configuration from {config_path}: {e}\")\n        return None"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration should be defined before accessing it.\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"Configuration should be defined before accessing it.\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"Configuration should be defined before accessing it.\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"Configuration should be defined before accessing it.\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"Configuration should be defined before accessing it.\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"Configuration should be defined before accessing it.\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"Configuration should be defined before accessing it.\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration should be defined before accessing it.\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"Configuration should be defined before accessing it.\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration should be defined before accessing it.\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"Configuration should be defined before accessing it.\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"Configuration should be defined before accessing it.\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"Configuration should be defined before accessing it.\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"Configuration should be defined before accessing it.\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"Configuration should be defined before accessing it.\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration should be defined before accessing it.\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration should be defined before accessing it.\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"Configuration should be defined before accessing it.\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"Configuration should be defined before accessing it.\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"Configuration should be defined before accessing it.\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index must be an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise AssertionError(\"The prepare thread is not defined. Ensure the thread is correctly managing the chunks.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        self._prepare_thread.download([chunk_index])\n\n        return self._item_loader.load(self.config[chunk_index], index.item_index)"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index must be an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread is not defined. Unable to manage chunks.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        self._prepare_thread.download([chunk_index])\n\n        return self._item_loader.load_item(index)"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index is not an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread is not defined. Make sure it is correctly managing the chunks.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        self._prepare_thread.download([chunk_index])\n\n        while True:\n            if self._prepare_thread._has_exited:\n                raise Exception(\"The prepare thread has exited unexpectedly.\")\n\n            if self._item_loader.is_chunk_ready(chunk_index):\n                return self._item_loader.load_item(chunk_index, index.item_index)"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index must be an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread is not available. Please ensure it is correctly managing the chunks.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        self._prepare_thread.download([chunk_index])\n\n        return self._item_loader.load(index)"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index must be an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread is not defined. Unable to manage chunks.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        self._prepare_thread.download([chunk_index])\n\n        return self._item_loader.load(index)"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index must be an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise AssertionError(\"The prepare thread is not defined. Ensure it is correctly managing the chunks.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        self._prepare_thread.download([chunk_index])\n\n        return self._item_loader.load_item(index)"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index must be an instance of ChunkedIndex\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread is not defined. Please ensure the thread is correctly managing the chunks.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        self._prepare_thread.download([chunk_index])\n\n        return self._item_loader.load_item(index)"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index is not an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise AssertionError(\"The prepare thread is not defined.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        self._prepare_thread.download([chunk_index])\n\n        while True:\n            if self._prepare_thread._has_exited:\n                raise Exception(\"The prepare thread has exited unexpectedly.\")\n\n            if self._item_loader.is_chunk_loaded(chunk_index):\n                return self._item_loader.load_item(chunk_index, index.item_index)"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index must be an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise AssertionError(\"The prepare thread is not present. Ensure the thread is correctly managing the chunks.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        self._prepare_thread.download([chunk_index])\n\n        return self._item_loader.load(index)"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index must be an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread is not defined. Please ensure the thread is correctly managing the chunks.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        self._prepare_thread.download([chunk_index])\n\n        return self._item_loader.get_item_from_chunk(index.item, chunk_index)"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index must be an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise AssertionError(\"The prepare thread is not defined. It should be present to manage the chunks.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        self._prepare_thread.download([chunk_index])\n\n        return self._item_loader.load_item(index)"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index must be an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise AssertionError(\"The prepare thread is not defined. Ensure the thread is correctly managing the chunks.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        self._prepare_thread.download([chunk_index])\n\n        return self._item_loader.load_item(index)"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index must be an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise AssertionError(\"The prepare thread is not defined. It should be present to manage the chunks.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        self._prepare_thread.download([chunk_index])\n\n        item = self._item_loader.load_item(index)\n        return item"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index is not an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise AssertionError(\"The prepare thread is not defined. Ensure the thread is correctly managing the chunks.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        self._prepare_thread.download([chunk_index])\n\n        return self._item_loader.load(index)"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index is not an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise AssertionError(\"The prepare thread is not defined. It should be initiated before reading chunks.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        self._prepare_thread.download([chunk_index])\n\n        return self._item_loader.load(index)"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index is not an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise AssertionError(\"The prepare thread is not present. Please ensure it is correctly managing the chunks.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        self._prepare_thread.download([chunk_index])\n\n        # Read the item from the specified chunk using the item loader\n        return self._item_loader.read(index)"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index must be an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread is not defined. Please ensure it is correctly managing the chunks.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        self._prepare_thread.download([chunk_index])\n\n        return self._item_loader.load_item(index)"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index must be an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise AssertionError(\"The prepare thread is not defined. Please ensure it is correctly managing the chunks.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        self._prepare_thread.download([chunk_index])\n\n        return self._item_loader.load(index)"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index must be an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise AssertionError(\"The prepare thread is not defined. Please ensure it is correctly managing the chunks.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        self._prepare_thread.download([chunk_index])\n\n        return self._item_loader.load_item(index)"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index must be an instance of ChunkedIndex.\")\n        \n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index configuration is not defined.\")\n        \n        if self._prepare_thread is None:\n            raise AssertionError(\"The prepare thread is not defined. Please ensure the thread is correctly managing the chunks.\")\n        \n        chunk_index = self._get_chunk_index_from_index(index.index)\n        if chunk_index != self._last_chunk_index:\n            self._prepare_thread.download([chunk_index])\n            self._last_chunk_index = chunk_index\n        \n        return self._item_loader.load_item(index)"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for file in filenames:\n            file_path = os.path.join(dirpath, file)\n            try:\n                total_size += os.path.getsize(file_path)\n            except FileNotFoundError:\n                # Ignore if the file is deleted during the calculation\n                pass\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                # Ignore and continue if the file is not found\n                pass\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for filename in filenames:\n            file_path = os.path.join(dirpath, filename)\n            try:\n                total_size += os.path.getsize(file_path)\n            except FileNotFoundError:\n                # Ignore FileNotFoundError exceptions\n                pass\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                # Ignore if the file is not found\n                pass\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for filename in filenames:\n            file_path = os.path.join(dirpath, filename)\n            try:\n                total_size += os.path.getsize(file_path)\n            except FileNotFoundError:\n                # Ignore if the file is deleted during the size calculation\n                pass\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for filename in filenames:\n            file_path = os.path.join(dirpath, filename)\n            try:\n                total_size += os.path.getsize(file_path)\n            except FileNotFoundError:\n                # Ignore FileNotFoundError and continue to the next file\n                pass\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                # Ignore if file is deleted during the size calculation process\n                pass\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for filename in filenames:\n            file_path = os.path.join(dirpath, filename)\n            try:\n                total_size += os.path.getsize(file_path)\n            except FileNotFoundError:\n                pass\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for filename in filenames:\n            file_path = os.path.join(dirpath, filename)\n            try:\n                # If the file is a symbolic link, os.path.getsize() will raise an OSError, so we skip it\n                if not os.path.islink(file_path):\n                    total_size += os.path.getsize(file_path)\n            except (FileNotFoundError, OSError):\n                # Ignore FileNotFoundError and OSError exceptions\n                pass\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                # Ignore if file is deleted during calculation\n                pass\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "\n    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for filename in filenames:\n            filepath = os.path.join(dirpath, filename)\n            try:\n                total_size += os.path.getsize(filepath)\n            except FileNotFoundError:\n                # Ignore FileNotFoundError exceptions if the file is deleted during the size calculation process\n                pass\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for filename in filenames:\n            try:\n                filepath = os.path.join(dirpath, filename)\n                total_size += os.path.getsize(filepath)\n            except FileNotFoundError:\n                # Ignore FileNotFoundError exceptions\n                pass\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for filename in filenames:\n            filepath = os.path.join(dirpath, filename)\n            try:\n                total_size += os.path.getsize(filepath)\n            except FileNotFoundError:\n                # Ignore FileNotFoundError exceptions if the file is deleted during the size calculation process\n                pass\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                # Ignore if the file is not found\n                pass\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for filename in filenames:\n            file_path = os.path.join(dirpath, filename)\n            try:\n                total_size += os.path.getsize(file_path)\n            except FileNotFoundError:\n                continue\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "\n    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for filename in filenames:\n            file_path = os.path.join(dirpath, filename)\n            try:\n                total_size += os.path.getsize(file_path)\n            except FileNotFoundError:\n                pass\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                # Ignore FileNotFoundError exceptions and continue with the next file\n                pass\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for filename in filenames:\n            file_path = os.path.join(dirpath, filename)\n            try:\n                total_size += os.path.getsize(file_path)\n            except FileNotFoundError:\n                # Ignore FileNotFoundError exceptions\n                pass\n    return total_size"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    distributed_map = _ImmutableDistributedMap()\n    try:\n        return distributed_map.set_and_get(key, obj)\n    except RuntimeError:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    distributed_map = _ImmutableDistributedMap()\n    try:\n        return distributed_map.set_and_get(key, obj)\n    except RuntimeError:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    distributed_map = _ImmutableDistributedMap()\n    try:\n        return distributed_map.set_and_get(key, obj)\n    except RuntimeError:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    distributed_map = _ImmutableDistributedMap()\n    try:\n        return distributed_map.set_and_get(key, obj)\n    except RuntimeError:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    distributed_map = _ImmutableDistributedMap()\n    try:\n        return distributed_map.set_and_get(key, obj)\n    except RuntimeError:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    distributed_map = _ImmutableDistributedMap()\n    try:\n        return distributed_map.set_and_get(key, obj)\n    except RuntimeError:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    distributed_map = _ImmutableDistributedMap()\n    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\"):\n        return distributed_map.set_and_get(key, obj)\n    else:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    distributed_map = _ImmutableDistributedMap()\n    try:\n        return distributed_map.set_and_get(key, obj)\n    except RuntimeError:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    distributed_map = _ImmutableDistributedMap()\n    try:\n        return distributed_map.set_and_get(key, obj)\n    except RuntimeError:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    distributed_map = _ImmutableDistributedMap()\n    try:\n        return distributed_map.set_and_get(key, obj)\n    except RuntimeError:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "\n    distributed_map = _ImmutableDistributedMap()\n\n    try:\n        return distributed_map.set_and_get(key, obj)\n    except RuntimeError:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    distributed_map = _ImmutableDistributedMap()\n\n    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is not None:\n        return distributed_map.set_and_get(key, obj)\n    else:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    distributed_map = _ImmutableDistributedMap()\n    try:\n        return distributed_map.set_and_get(key, obj)\n    except RuntimeError:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    distributed_map = _ImmutableDistributedMap()\n    try:\n        return distributed_map.set_and_get(key, obj)\n    except RuntimeError:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    distributed_map = _ImmutableDistributedMap()\n    try:\n        return distributed_map.set_and_get(key, obj)\n    except RuntimeError:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "\n    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") and os.getenv(\"LIGHTNING_APP_STATE_URL\"):\n        distributed_map = _ImmutableDistributedMap()\n        return distributed_map.set_and_get(key, obj)\n    else:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    distributed_map = _ImmutableDistributedMap()\n\n    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\"):\n        return distributed_map.set_and_get(key, obj)\n    else:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "\n    distributed_map = _ImmutableDistributedMap()\n    try:\n        return distributed_map.set_and_get(key, obj)\n    except RuntimeError:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    distributed_map = _ImmutableDistributedMap()\n    try:\n        return distributed_map.set_and_get(key, obj)\n    except RuntimeError:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    distributed_map = _ImmutableDistributedMap()\n    try:\n        return distributed_map.set_and_get(key, obj)\n    except RuntimeError:\n        return obj"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    bin_contents = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    # Sort items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Place each item into the bin with the current lowest total weight\n    for item, weight in sorted_items:\n        min_bin = min(bin_weights, key=bin_weights.get)\n        bin_contents[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n        # If the number of bins is exceeded, remove the item from the bin with the highest weight and place it in the bin with the next lowest weight\n        if min_bin >= num_bins:\n            max_bin = max(bin_weights, key=bin_weights.get)\n            max_weight_item = bin_contents[max_bin].pop()\n            bin_weights[max_bin] -= weights[items.index(max_weight_item)]\n            bin_contents[min_bin].append(max_weight_item)\n            bin_weights[min_bin] += weight\n\n    return bin_contents, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    bin_items = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    for item, weight in sorted_items:\n        min_bin = min(bin_weights, key=bin_weights.get)\n        bin_items[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n    return dict(bin_items), dict(bin_weights)"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    # Sort items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Place each item into the bin with the current lowest total weight\n    for item, weight in sorted_items:\n        min_bin = min(bin_weights, key=bin_weights.get)\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    bin_items = defaultdict(list)\n    bin_weights = defaultdict(int)\n    \n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n    \n    for item, weight in sorted_items:\n        min_bin = min(bin_weights, key=bin_weights.get)\n        bin_items[min_bin].append(item)\n        bin_weights[min_bin] += weight\n        \n    return dict(bin_items), dict(bin_weights)"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    # Sort items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    for item, weight in sorted_items:\n        min_bin = min(bin_weights, key=bin_weights.get)\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    for item, weight in sorted_items:\n        min_bin = min(bin_weights, key=bin_weights.get)\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n    return dict(bins), dict(bin_weights)"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    for item, weight in sorted_items:\n        min_bin = min(bin_weights, key=bin_weights.get)\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    bin_items = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    for item, weight in sorted_items:\n        min_bin = min(bin_weights, key=bin_weights.get)\n        bin_items[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n    return dict(bin_items), dict(bin_weights)"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    # Sort items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Place each item into the bin with the current lowest total weight\n    for item, weight in sorted_items:\n        min_bin = min(bin_weights, key=bin_weights.get)\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n    \n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n    \n    for item, weight in sorted_items:\n        min_bin = min(bin_weights, key=bin_weights.get)\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n        \n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Initialize the bins and their total weights\n    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    # Place each item into the bin with the current lowest total weight\n    for item, weight in sorted_items:\n        min_bin = min(bin_weights, key=bin_weights.get)\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n    \n    # Sort items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n    \n    for item, weight in sorted_items:\n        # Find the bin with the lowest total weight\n        min_bin = min(bin_weights, key=bin_weights.get)\n        # Add the item to the bin\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n        \n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    # Sort items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Place each item into the bin with the current lowest total weight\n    for item, weight in sorted_items:\n        min_bin = min(bin_weights, key=bin_weights.get)\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    for item, weight in sorted_items:\n        min_bin = min(bin_weights, key=bin_weights.get)\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n    \n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n    \n    for item, weight in sorted_items:\n        min_bin = min(bin_weights, key=bin_weights.get)\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n        \n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    bin_contents = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    for item, weight in sorted_items:\n        min_bin = min(bin_weights, key=bin_weights.get)\n        bin_contents[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n    return dict(bin_contents), dict(bin_weights)"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n    \n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n    \n    for item, weight in sorted_items:\n        min_bin = min(bin_weights, key=bin_weights.get)\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n        \n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    # Sort items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Place each item into the bin with the current lowest total weight\n    for item, weight in sorted_items:\n        min_bin = min(bin_weights, key=bin_weights.get)\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    for item, weight in sorted_items:\n        min_bin = min(bin_weights, key=bin_weights.get)\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    for item, weight in sorted_items:\n        min_bin = min(bin_weights, key=bin_weights.get)\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n    return bins, bin_weights"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Flatten the list of chunks_per_ranks\n    flat_chunks = [chunk for sublist in chunks_per_ranks for chunk in sublist]\n\n    # Set the random seed based on the current epoch\n    np.random.seed(seed + current_epoch)\n\n    # Shuffle the chunk indexes\n    np.random.shuffle(flat_chunks)\n\n    return flat_chunks"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    np.random.seed(seed + current_epoch)\n    shuffled_chunks = []\n    for rank_chunks in chunks_per_ranks:\n        np.random.shuffle(rank_chunks)\n        shuffled_chunks.extend(rank_chunks)\n    return shuffled_chunks"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    np.random.seed(seed + current_epoch)\n    shuffled_chunks = []\n    for rank_chunks in chunks_per_ranks:\n        np.random.shuffle(rank_chunks)\n        shuffled_chunks.extend(rank_chunks)\n    return shuffled_chunks"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Flatten the list of chunk indexes\n    flattened_chunks = [chunk for sublist in chunks_per_ranks for chunk in sublist]\n\n    # Set the random seed for reproducibility\n    np.random.seed(seed + current_epoch)\n\n    # Shuffle the chunk indexes\n    np.random.shuffle(flattened_chunks)\n\n    return flattened_chunks"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Flatten the chunk indexes assigned to each rank\n    flat_chunks = [chunk for chunks in chunks_per_ranks for chunk in chunks]\n\n    # Set the random seed based on the current epoch\n    np.random.seed(seed + current_epoch)\n\n    # Shuffle the chunk indexes\n    np.random.shuffle(flat_chunks)\n\n    return flat_chunks"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    np.random.seed(seed + current_epoch)\n    flattened_chunks = [chunk for chunks in chunks_per_ranks for chunk in chunks]\n    np.random.shuffle(flattened_chunks)\n\n    return flattened_chunks"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Flatten the list of chunk indexes\n    all_chunks = [chunk for chunks in chunks_per_ranks for chunk in chunks]\n\n    # Set the random seed based on the current epoch\n    np.random.seed(seed + current_epoch)\n\n    # Shuffle the chunk indexes\n    np.random.shuffle(all_chunks)\n\n    return all_chunks"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Flatten the list of chunks_per_ranks\n    all_chunks = [chunk for chunks in chunks_per_ranks for chunk in chunks]\n\n    # Set the seed for reproducibility\n    np.random.seed(seed + current_epoch)\n\n    # Shuffle the chunks\n    np.random.shuffle(all_chunks)\n\n    return all_chunks"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Flatten the list of chunk indexes\n    all_chunks = [chunk for chunks in chunks_per_ranks for chunk in chunks]\n\n    # Set the random seed based on the current epoch\n    np.random.seed(seed + current_epoch)\n\n    # Shuffle the chunk indexes\n    np.random.shuffle(all_chunks)\n\n    return all_chunks"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    np.random.seed(seed + current_epoch)\n    shuffled_chunks = []\n    for rank_chunks in chunks_per_ranks:\n        np.random.shuffle(rank_chunks)\n        shuffled_chunks.extend(rank_chunks)\n    return shuffled_chunks"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Flatten the list of chunk indexes\n    flat_chunks = [chunk for sublist in chunks_per_ranks for chunk in sublist]\n\n    # Set the random seed based on the current epoch\n    np.random.seed(seed + current_epoch)\n\n    # Shuffle the chunk indexes\n    np.random.shuffle(flat_chunks)\n\n    return flat_chunks"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    np.random.seed(seed + current_epoch)\n    flattened_chunks = [chunk for chunks in chunks_per_ranks for chunk in chunks]\n    np.random.shuffle(flattened_chunks)\n    return flattened_chunks"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Flatten the chunks_per_ranks list\n    all_chunks = [chunk for chunks in chunks_per_ranks for chunk in chunks]\n\n    # Set the random seed\n    np.random.seed(seed + current_epoch)\n\n    # Shuffle the chunk indexes\n    np.random.shuffle(all_chunks)\n\n    return all_chunks"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Flatten the chunks_per_ranks list\n    all_chunks = [chunk for chunks in chunks_per_ranks for chunk in chunks]\n\n    # Set the random seed based on the current epoch\n    np.random.seed(seed + current_epoch)\n\n    # Shuffle the chunks\n    np.random.shuffle(all_chunks)\n\n    return all_chunks"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Flatten the list of chunk indexes across all nodes\n    all_chunks = [chunk for chunks in chunks_per_ranks for chunk in chunks]\n\n    # Set the random seed based on the current epoch\n    np.random.seed(seed + current_epoch)\n\n    # Shuffle the chunk indexes\n    np.random.shuffle(all_chunks)\n\n    return all_chunks"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    np.random.seed(seed + current_epoch)\n    shuffled_chunks = []\n    for rank_chunks in chunks_per_ranks:\n        np.random.shuffle(rank_chunks)\n        shuffled_chunks.extend(rank_chunks)\n    return shuffled_chunks"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Flatten the list of chunk indexes\n    all_chunks = [chunk for chunks in chunks_per_ranks for chunk in chunks]\n\n    # Set the random seed based on the current epoch\n    np.random.seed(seed + current_epoch)\n\n    # Shuffle the chunk indexes\n    np.random.shuffle(all_chunks)\n\n    return all_chunks"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    np.random.seed(seed + current_epoch)\n    flattened_chunks = [chunk for chunks in chunks_per_ranks for chunk in chunks]\n    np.random.shuffle(flattened_chunks)\n    return flattened_chunks"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Flatten the list of chunk indexes\n    all_chunks = [chunk for rank_chunks in chunks_per_ranks for chunk in rank_chunks]\n\n    # Set the random seed based on the current epoch\n    np.random.seed(seed + current_epoch)\n\n    # Shuffle the chunk indexes\n    np.random.shuffle(all_chunks)\n\n    return all_chunks"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    np.random.seed(seed + current_epoch)\n    shuffled_chunks = []\n    for rank_chunks in chunks_per_ranks:\n        np.random.shuffle(rank_chunks)\n        shuffled_chunks.extend(rank_chunks)\n    return shuffled_chunks"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1000:\n            return f\"{num_bytes:.2f} {suffix}\"\n        num_bytes /= 1000\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if abs(num_bytes) < 1000.0:\n            return f\"{num_bytes:.2f} {unit}\"\n        num_bytes /= 1000.0\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1000:\n            return f\"{num_bytes:.2f} {suffix}\"\n        num_bytes /= 1000\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1000:\n            return f\"{num_bytes:.2f} {suffix}\"\n        num_bytes /= 1000\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "\n    for suffix in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1000:\n            return f\"{num_bytes:.2f} {suffix}\"\n        num_bytes /= 1000\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if abs(num_bytes) < 1000.0:\n            return f\"{num_bytes:.2f} {unit}\"\n        num_bytes /= 1000.0\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1000:\n            return f\"{num_bytes:.2f} {suffix}\"\n        num_bytes /= 1000\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1000:\n            return f\"{num_bytes:.2f} {suffix}\"\n        num_bytes /= 1000\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if abs(num_bytes) < 1000.0:\n            return f\"{num_bytes:.2f} {unit}\"\n        num_bytes /= 1000.0\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if abs(num_bytes) < 1000.0:\n            return f\"{num_bytes:.2f} {suffix}\"\n        num_bytes /= 1000.0\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in ['B', 'KB', 'MB', 'GB', 'TB', 'PB']:\n        if abs(num_bytes) < 1000.0:\n            return f\"{num_bytes:.2f} {unit}\"\n        num_bytes /= 1000.0\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if abs(num_bytes) < 1000:\n            return f\"{num_bytes:.2f} {unit}\"\n        num_bytes /= 1000\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if abs(num_bytes) < 1000:\n            return f\"{num_bytes:.2f} {suffix}\"\n        num_bytes /= 1000\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1000:\n            return f\"{num_bytes:.2f} {suffix}\"\n        num_bytes /= 1000\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1000:\n            return f\"{num_bytes:.2f} {suffix}\"\n        num_bytes /= 1000\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1000:\n            return f\"{num_bytes:.2f} {suffix}\"\n        num_bytes /= 1000\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1000:\n            return f\"{num_bytes:.2f} {suffix}\"\n        num_bytes /= 1000\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1000:\n            return f\"{num_bytes:.2f} {unit}\"\n        num_bytes /= 1000\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "\n    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if abs(num_bytes) < 1000.0:\n            return f\"{num_bytes:.1f} {unit}\"\n        num_bytes /= 1000.0\n    return f\"{num_bytes:.1f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1000:\n            return f\"{num_bytes:.2f} {unit}\"\n        num_bytes /= 1000\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n    if not indexed_paths:\n        return None\n\n    input_dirs = [os.path.dirname(path) for path in indexed_paths.values()]\n    if len(set(input_dirs)) > 1:\n        raise ValueError(\"Inconsistent input directories found in the provided inputs.\")\n\n    input_dir = input_dirs[0]\n    if not os.path.isabs(input_dir):\n        project_root = os.path.abspath(os.curdir)\n        input_dir = os.path.join(project_root, input_dir)\n\n    return input_dir"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    if not inputs:\n        return None\n\n    indexed_paths = _get_indexed_paths(inputs[0])\n    if not indexed_paths:\n        if len(inputs) > 1:\n            indexed_paths = _get_indexed_paths(inputs[1])\n\n    if not indexed_paths:\n        return None\n\n    input_dir = os.path.commonpath(indexed_paths.values())\n    if not os.path.exists(input_dir):\n        raise ValueError(f\"The input directory {input_dir} does not exist.\")\n\n    return input_dir"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n    if not indexed_paths:\n        return None\n\n    input_dirs = set(Path(indexed_paths[index]).parent for index in indexed_paths)\n    if len(input_dirs) > 1:\n        raise ValueError(\"Inconsistent file paths found in the input sequence.\")\n\n    input_dir = input_dirs.pop()\n    if not input_dir.exists():\n        raise FileNotFoundError(f\"The input directory {input_dir} does not exist.\")\n\n    return str(input_dir)"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if not indexed_paths:\n        return None\n\n    input_dirs = [os.path.dirname(path) for path in indexed_paths.values()]\n    unique_input_dirs = set(input_dirs)\n\n    if len(unique_input_dirs) > 1:\n        raise ValueError(\"Inconsistent input directories found in the input sequence.\")\n\n    input_dir = unique_input_dirs.pop()\n    return os.path.abspath(input_dir)"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n    if not indexed_paths:\n        return None\n\n    input_dirs = [os.path.dirname(path) for path in indexed_paths.values()]\n    if len(set(input_dirs)) > 1:\n        raise ValueError(\"Inconsistent input directories found in the input sequence.\")\n\n    input_dir = input_dirs[0]\n    return os.path.abspath(input_dir)"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if not indexed_paths:\n        return None\n\n    input_dirs = [os.path.dirname(path) for path in indexed_paths.values()]\n    unique_input_dirs = set(input_dirs)\n\n    if len(unique_input_dirs) > 1:\n        raise ValueError(\"Inconsistent input directories found in the provided inputs.\")\n\n    input_dir = unique_input_dirs.pop()\n    return input_dir"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if not indexed_paths:\n        return None\n\n    input_dirs = [os.path.dirname(path) for path in indexed_paths.values()]\n    common_prefix = os.path.commonprefix(input_dirs)\n\n    if not common_prefix:\n        raise ValueError(\"Inconsistent file paths found in the input sequence.\")\n\n    return common_prefix"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n    if not indexed_paths:\n        return None\n\n    input_dirs = [Path(path).parent for path in indexed_paths.values()]\n    if len(set(input_dirs)) > 1:\n        raise ValueError(\"Inconsistent file paths found in the input sequence.\")\n\n    input_dir = input_dirs[0]\n    if input_dir.is_file():\n        input_dir = input_dir.parent\n\n    return str(input_dir)"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n    if not indexed_paths:\n        return None\n\n    input_dirs = set(os.path.dirname(path) for path in indexed_paths.values())\n    if len(input_dirs) > 1:\n        raise ValueError(\"Inconsistent input directories found in the provided inputs.\")\n\n    input_dir = input_dirs.pop()\n    if not os.path.isabs(input_dir):\n        input_dir = str(Path.cwd() / input_dir)\n\n    return input_dir"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n    if not indexed_paths:\n        return None\n\n    input_dirs = [Path(indexed_paths[index]).parent for index in indexed_paths]\n    if len(set(input_dirs)) > 1:\n        raise ValueError(\"Inconsistent input directories found.\")\n\n    input_dir = input_dirs[0]\n    if not input_dir.exists():\n        raise ValueError(f\"Input directory {input_dir} does not exist.\")\n\n    return str(input_dir)"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if not indexed_paths:\n        return None\n\n    first_path = indexed_paths.get(0)\n    second_path = indexed_paths.get(1)\n\n    if first_path and second_path:\n        if Path(first_path).parent != Path(second_path).parent:\n            raise ValueError(\"Inconsistent file paths found in the input sequence.\")\n\n    input_dir = Path(first_path).parent if first_path else Path(second_path).parent\n\n    if input_dir:\n        return str(input_dir.resolve())\n\n    return None"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if not indexed_paths:\n        return None\n\n    input_dirs = [os.path.dirname(path) for path in indexed_paths.values()]\n    unique_input_dirs = set(input_dirs)\n\n    if len(unique_input_dirs) > 1:\n        raise ValueError(\"Inconsistent input directories found in the input sequence.\")\n\n    input_dir = unique_input_dirs.pop()\n    return os.path.abspath(input_dir)"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if not indexed_paths:\n        return None\n\n    input_dirs = set(os.path.dirname(path) for path in indexed_paths.values())\n    if len(input_dirs) > 1:\n        raise ValueError(\"Inconsistent input directories found: {}\".format(input_dirs))\n\n    input_dir = input_dirs.pop()\n    if not os.path.isabs(input_dir):\n        input_dir = os.path.join(Path.cwd(), input_dir)\n\n    return input_dir"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n    if not indexed_paths:\n        return None\n\n    input_dirs = set(Path(path).parent for path in indexed_paths.values())\n    if len(input_dirs) > 1:\n        raise ValueError(\"Inconsistent file paths found. All file paths should have the same parent directory.\")\n\n    input_dir = input_dirs.pop()\n    if not input_dir.exists():\n        raise ValueError(f\"The input directory {input_dir} does not exist.\")\n\n    return str(input_dir)"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if not indexed_paths:\n        return None\n\n    input_dirs = {os.path.dirname(path) for path in indexed_paths.values()}\n    if len(input_dirs) > 1:\n        raise ValueError(\"Inconsistent input directories found in the provided inputs.\")\n\n    input_dir = input_dirs.pop()\n    return str(Path(input_dir).resolve())"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n    if not indexed_paths:\n        return None\n\n    input_dirs = [os.path.dirname(path) for path in indexed_paths.values()]\n    if len(set(input_dirs)) > 1:\n        raise ValueError(\"Inconsistent input directories found in the provided inputs.\")\n\n    input_dir = input_dirs[0]\n    if not os.path.isabs(input_dir):\n        project_root = Path(__file__).resolve().parent.parent\n        input_dir = str(project_root / input_dir)\n\n    return input_dir"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n    if not indexed_paths:\n        return None\n\n    input_dirs = [os.path.dirname(path) for path in indexed_paths.values()]\n    if len(set(input_dirs)) > 1:\n        raise ValueError(\"Inconsistent input directories found in the provided inputs.\")\n\n    input_dir = input_dirs[0]\n    if not os.path.isabs(input_dir):\n        input_dir = os.path.abspath(input_dir)\n\n    return input_dir"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n    if not indexed_paths:\n        return None\n\n    input_dirs = [os.path.dirname(path) for path in indexed_paths.values()]\n    unique_input_dirs = set(input_dirs)\n\n    if len(unique_input_dirs) > 1:\n        raise ValueError(\"Inconsistent input directories found in the provided inputs.\")\n\n    input_dir = unique_input_dirs.pop()\n    return input_dir"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if not indexed_paths:\n        return None\n\n    input_dir = os.path.commonpath([os.path.dirname(path) for path in indexed_paths.values()])\n\n    if not all(path.startswith(input_dir) for path in indexed_paths.values()):\n        raise ValueError(\"Inconsistent file paths found in the input sequence.\")\n\n    return input_dir"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n    if not indexed_paths:\n        return None\n\n    input_dirs = [os.path.dirname(path) for path in indexed_paths.values()]\n    if len(set(input_dirs)) > 1:\n        raise ValueError(\"Inconsistent input directories found\")\n\n    input_dir = os.path.commonpath(input_dirs)\n    return input_dir"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, p = matchup_channels(t, w)\n    dt = t[..., 1:] - t[..., :-1]\n    t_dilate = torch.clamp(t[..., :-1] + dilation * dt, min=domain[0], max=domain[1])\n    p_dilate = torch.max(p[..., :-1], p[..., 1:])\n    return t_dilate, p_dilate"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, p = matchup_channels(t, w)\n    dt = t[..., 1:] - t[..., :-1]\n    t_dilate = t[..., :-1] + dilation * dt\n    t_dilate = torch.clip(t_dilate, domain[0], domain[1])\n    p_dilate = p / dt\n    return t_dilate, p_dilate"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "\n    t_pdf = t\n    w_pdf = w / (t[..., 1:] - t[..., :-1]).clip(1e-8)\n\n    # Apply max-pooling to dilate the time steps\n    t_dilated = torch.nn.functional.max_pool1d(t_pdf.unsqueeze(0), dilation, stride=1, padding=0).squeeze(0)\n\n    # Clip the dilated time steps within the specified domain\n    t_dilated = torch.clip(t_dilated, domain[0], domain[1])\n\n    # Adjust the weights to match the dilated time steps\n    w_dilated = torch.zeros_like(w_pdf)\n    for i in range(len(t_dilated) - 1):\n        mask = (t_pdf >= t_dilated[i]) & (t_pdf < t_dilated[i + 1])\n        w_dilated[i] = torch.max(w_pdf[mask])\n\n    return t_dilated, w_dilated"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "\n    # Compute the dilated time steps and adjust the weights accordingly\n    t_dilate = (t * dilation).clamp(min=domain[0], max=domain[1])\n    w_dilate = w / dilation\n\n    return t_dilate, w_dilate"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "\n    # Compute the dilated time steps and adjust the weights\n    t_dilate = (t - dilation).clamp(domain[0], domain[1])\n    w_dilate = torch.nn.functional.max_pool1d(w.unsqueeze(0), kernel_size=int(dilation * 2 + 1), stride=1, padding=int(dilation), dilation=1).squeeze(0)\n\n    return t_dilate, w_dilate"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, p = matchup_channels(t, w)\n    dt = t[..., 1:] - t[..., :-1]\n    t_dilate = torch.clamp(t[..., :-1] + dilation * dt, min=domain[0], max=domain[1])\n    p_dilate = torch.nn.functional.max_pool1d(p[None, None, :], kernel_size=2, stride=1).squeeze(1).squeeze(0)\n    p_dilate /= (t_dilate[..., 1:] - t_dilate[..., :-1]).clip(min=1e-8)\n    return t_dilate, p_dilate"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "\n    t_pdf = weight_to_pdf(t, w)\n    t_dilated = t * dilation\n    t_dilated = torch.clip(t_dilated, domain[0], domain[1])\n    t_dilate, p_dilate = matchup_channels(t_dilated, t_pdf)\n    w_dilate = pdf_to_weight(t_dilate, p_dilate)\n    return t_dilate, w_dilate"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "\n    # Perform dilation on the time steps\n    t_dilated = t * dilation\n\n    # Clip the dilated time steps within the specified domain\n    t_dilated = torch.clamp(t_dilated, min=domain[0], max=domain[1])\n\n    # Adjust the weights to match the dilated time steps\n    w_dilated = w / dilation\n\n    return t_dilated, w_dilated"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "\n    # Compute the dilated time steps\n    t_dilate = t * dilation\n\n    # Clip the dilated time steps within the specified domain\n    t_dilate = torch.clamp(t_dilate, min=domain[0], max=domain[1])\n\n    # Adjust the weights to match the dilated time steps\n    p = weight_to_pdf(t, w)\n    p_dilate = interpolate(t_dilate, t, p)\n    w_dilate = pdf_to_weight(t_dilate, p_dilate)\n\n    return t_dilate, w_dilate"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "\n    # Compute the dilated time steps\n    t_dilate = t * dilation\n\n    # Clip the dilated time steps within the specified domain\n    t_dilate = torch.clamp(t_dilate, min=domain[0], max=domain[1])\n\n    # Adjust the weights to match the dilated time steps\n    w_dilate = w / dilation\n\n    return t_dilate, w_dilate"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "\n    t, p = matchup_channels(t, w)\n    dt = t[..., 1:] - t[..., :-1]\n    t_dilate = t[..., :-1] + dt * dilation\n    t_dilate = torch.clip(t_dilate, domain[0], domain[1])\n\n    # Adjust weights for dilation\n    p_dilate = p * (dt / (t_dilate[..., 1:] - t_dilate[..., :-1])).clip(min=1e-8)\n    return t_dilate, p_dilate"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "\n    # Perform dilation on the time steps\n    t_dilated = t * dilation\n\n    # Clip the dilated time steps within the specified domain\n    t_dilated = torch.clamp(t_dilated, min=domain[0], max=domain[1])\n\n    # Adjust the weights to match the dilated time steps\n    # No adjustment needed for the weights\n\n    return t_dilated, w"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "\n    # Compute the dilated time steps and adjust the weights accordingly\n    t_dilated = t * dilation\n    t_dilated = torch.clamp(t_dilated, min=domain[0], max=domain[1])\n\n    # Adjust the weights based on the dilation factor\n    w_dilated = w / dilation\n\n    return t_dilated, w_dilated"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "\n    # Dilate the time steps\n    t_dilate = t * dilation\n\n    # Clip the dilated time steps within the specified domain\n    t_dilate = torch.clamp(t_dilate, min=domain[0], max=domain[1])\n\n    # Adjust the weights to match the dilated time steps\n    w_dilate = w / dilation\n\n    return t_dilate, w_dilate"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "\n    # Compute the dilated time steps\n    t_dilate = t * dilation\n\n    # Clip the dilated time steps within the specified domain\n    t_dilate = torch.clip(t_dilate, domain[0], domain[1])\n\n    # Adjust the weights to match the dilated time steps\n    w_dilate = w / dilation\n\n    return t_dilate, w_dilate"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "\n    t, p = matchup_channels(t, w)\n    dt = t[..., 1:] - t[..., :-1]\n    t_dilate = (t * dilation).clamp(domain[0], domain[1])\n    t_dilate, indices = torch.sort(t_dilate)\n    p_dilate = torch.zeros_like(p)\n\n    for i in range(len(indices)):\n        if i == 0:\n            p_dilate[i] = p[indices[i]]\n        else:\n            p_dilate[i] = torch.max(p_dilate[i - 1], p[indices[i]])\n\n    w_dilate = pdf_to_weight(t_dilate, p_dilate)\n    return t_dilate, w_dilate"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    p = weight_to_pdf(t, w)\n    t_dilate, p_dilate = max_dilate(t, p, dilation, domain=domain)\n    w_dilate = pdf_to_weight(t_dilate, p_dilate)\n    return t_dilate, w_dilate"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "\n    # Compute the PDF and CDF for each weight vector.\n    p = weight_to_pdf(t, w)\n    t_dilate, p_dilate = max_dilate(t, p, dilation, domain=domain)\n    w_dilate = pdf_to_weight(t_dilate, p_dilate)\n    return t_dilate, w_dilate"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "\n    # Compute the PDF and CDF for each weight vector.\n    p = weight_to_pdf(t, w)\n    t_dilate, p_dilate = max_dilate(t, p, dilation, domain=domain)\n    w_dilate = pdf_to_weight(t_dilate, p_dilate)\n    return t_dilate, w_dilate"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "\n    # Compute the new dilated time steps\n    t_dilate = t * dilation\n\n    # Clip the dilated time steps within the specified domain\n    t_dilate = torch.clamp(t_dilate, min=domain[0], max=domain[1])\n\n    # Adjust the weights to match the dilated time steps\n    p = weight_to_pdf(t, w)\n    t_dilate, p_dilate = max_dilate(t, p, dilation, domain=domain)\n    w_dilate = pdf_to_weight(t_dilate, p_dilate)\n\n    return t_dilate, w_dilate"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    indices = torch.sum(torch.ge(tq[..., :, None], t[..., None, :]), -1) - 1  # torch.ge:  tq[i] >= t[i] ? true: false\n    indices = torch.clamp(indices, 0, y.shape[-1] - 1)\n    interpolated_values = y.gather(dim=-1, index=indices)\n    return torch.where(tq[..., None] == t[..., None, :], outside_value, interpolated_values)"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    indices = torch.sum(torch.ge(tq[..., :, None], t[..., None, :]), -1) - 1\n    indices = torch.clamp(indices, 0, y.shape[-1] - 1)\n    values = y.gather(dim=-1, index=indices)\n    result = torch.where(tq[..., None] == t[..., None, :], outside_value, values)\n    return result"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Find the indices where tq should be inserted into t to maintain order\n    idx_lo, idx_hi = searchsorted(t, tq)\n\n    # Check if query times exactly match a step change time\n    exact_match = tq == t[idx_lo]\n\n    # Interpolate the values at the query times based on the step function\n    interpolated_values = interpolate(tq, t, y)\n\n    # Return outside value for exact matches, otherwise return interpolated values\n    result = torch.where(exact_match, outside_value, interpolated_values)\n\n    return result"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    indices = searchsorted(t, tq)\n    lo_indices, hi_indices = indices\n    lo_values = torch.gather(y, -1, lo_indices)\n    hi_values = torch.gather(y, -1, hi_indices)\n    matched = tq == t[lo_indices]\n    result = torch.where(matched, outside_value, interpolate(tq, t[lo_indices], lo_values, t[hi_indices], hi_values))\n    return result"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    idx_lo, idx_hi = searchsorted(t, tq)\n    is_exact_match = idx_lo == idx_hi\n    result = torch.where(\n        is_exact_match,\n        outside_value,\n        interpolate(tq, t, y)\n    )\n    return result"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    indices = torch.searchsorted(t, tq)\n    mask = indices == 0\n    indices = indices - 1\n    result = torch.where(mask, outside_value, interpolate(tq, t, y)[indices])\n    return result"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    idx_lo, idx_hi = searchsorted(t, tq)\n    match = idx_lo == idx_hi\n    result = interpolate(tq, t, y)\n    result[match] = outside_value\n    return result"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Find the indices where tq should be inserted into t to maintain order\n    idx_lo, idx_hi = searchsorted(t, tq)\n\n    # Check if query time exactly matches a step change time\n    exact_match = tq == t[idx_lo]\n\n    # Interpolate the value at the query time based on the step function\n    interpolated_values = interpolate(tq, t, y)\n\n    # Return outside value for query times that exactly match a step change time\n    result = torch.where(exact_match, outside_value, interpolated_values)\n\n    return result"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Find the indices of the step changes that are less than or equal to the query times\n    idx = torch.searchsorted(t, tq, side='right') - 1\n\n    # Initialize the result tensor with the outside value\n    result = torch.full_like(tq, outside_value)\n\n    # Interpolate the values for query times that do not match a step change time\n    mask = idx < len(y)\n    result[mask] = interpolate(tq[mask], t[idx[mask]:idx[mask]+2], y[idx[mask]:idx[mask]+1])\n\n    return result"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    idx_lo, idx_hi = searchsorted(t, tq)\n    match = idx_lo == idx_hi\n    result = interpolate(tq, t, y)\n    result[match] = outside_value\n    return result"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    indices = torch.searchsorted(t, tq)\n    matches = (t[indices] == tq).float()\n    result = (1 - matches) * interpolate(tq, t, y) + matches * outside_value\n    return result"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Find the indices where the query times should be inserted into the step function times to maintain order\n    idx_lo, idx_hi = searchsorted(t, tq)\n\n    # Check if the query times exactly match a step change time\n    exact_match = tq == t[idx_lo]\n\n    # Interpolate the values at the query times based on the step function\n    interpolated_values = (y[..., idx_lo] * (t[idx_hi] - tq) + y[..., idx_hi] * (tq - t[idx_lo])) / (t[idx_hi] - t[idx_lo])\n\n    # Set the values for exact matches to the outside value\n    result = torch.where(exact_match, outside_value, interpolated_values)\n\n    return result"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    indices = torch.searchsorted(t, tq)\n    indices = torch.clamp(indices, 0, t.shape[-1] - 1)\n    values = torch.where(tq == t[indices], outside_value, interpolate(tq, t, y))\n    return values"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Find the indices where tq should be inserted into t to maintain order\n    idx_lo, idx_hi = searchsorted(t, tq)\n\n    # Check if query times match a step change time\n    match = torch.where(t[idx_lo] == tq, outside_value, 0)\n\n    # Interpolate the value at the query time based on the step function\n    interpolated_values = interpolate(tq, t, y)\n\n    # Return the interpolated or outside values of the step function at the query times\n    return match + interpolated_values"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    idx_lo, idx_hi = searchsorted(t, tq)\n    is_exact_match = idx_lo == idx_hi\n    result = torch.where(\n        is_exact_match,\n        outside_value,\n        interpolate(tq, t, y)\n    )\n    return result"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    indices = torch.sum(torch.ge(tq[..., :, None], t[..., None, :]), -1) - 1\n    indices = torch.clamp(indices, 0, y.shape[-1] - 1)\n    interpolated_values = y.gather(dim=-1, index=indices)\n    result = torch.where(tq[..., :, None] == t[..., None, :], outside_value, interpolated_values)\n    return result"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    indices = torch.searchsorted(t, tq)\n    mask = (t[indices] == tq).float()\n    result = (y[indices - 1] * (1 - mask) + outside_value * mask)\n    return result"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    idx_lo, idx_hi = searchsorted(t, tq)\n    matched = torch.where(tq == t[idx_hi], outside_value, torch.zeros_like(tq))\n    interpolated = interpolate(tq, t, y)\n    result = torch.where(matched != 0, matched, interpolated)\n    return result"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    idx_lo, idx_hi = searchsorted(t, tq)\n    match = torch.where(tq == t[idx_lo], outside_value, torch.zeros_like(tq))\n    interpolated_values = interpolate(tq, t, y)\n    result = torch.where(match != 0, match, interpolated_values)\n    return result"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    indices = searchsorted(t, tq)\n    lo_indices, hi_indices = indices\n    lo_values = y[lo_indices]\n    hi_values = y[hi_indices]\n    matched = tq == t[lo_indices]\n    result = torch.where(matched, outside_value, interpolate(tq, t[lo_indices], lo_values, t[hi_indices], hi_values))\n    return result"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # Calculate the annealing factor based on the training fraction and annealing slope\n    anneal_factor = torch.exp(-anneal_slope * train_frac)\n\n    # Calculate the adjusted weights using Schlick's bias function\n    adjusted_weights = w / (1 + (1 / anneal_factor - 1) * (t[..., 1:] - t[..., :-1])).clip(eps)\n\n    # Handle cases where adjacent intervals have zero distance, set their weight to zero\n    adjusted_weights = torch.where((t[..., 1:] - t[..., :-1]) < eps, torch.zeros_like(adjusted_weights), adjusted_weights)\n\n    # Prevent NaN values by using a softmax operation on the adjusted weights\n    adjusted_weights = torch.nn.functional.softmax(adjusted_weights, dim=-1)\n\n    return adjusted_weights"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # Calculate the bias function using Schlick's bias function\n    bias = 1 / (1 + (train_frac / (1 - train_frac)) ** (-anneal_slope))\n\n    # Adjust the weights based on the bias function\n    w_adjusted = w ** bias\n\n    # Handle cases where adjacent intervals have zero distance\n    t_diff = t[..., 1:] - t[..., :-1]\n    zero_dist_mask = t_diff < eps\n    w_adjusted = torch.where(zero_dist_mask, torch.zeros_like(w_adjusted), w_adjusted)\n\n    # Prevent NaN values by using softmax operation on the adjusted weights\n    w_normalized = torch.nn.functional.softmax(w_adjusted, dim=-1)\n\n    return w_normalized"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # Calculate the bias function based on the training fraction and annealing slope\n    bias = 1 / (1 + torch.exp(-anneal_slope * (train_frac - 0.5)))\n\n    # Calculate the adjusted weights using the bias function\n    adjusted_weights = w.pow(bias)\n\n    # Handle cases where adjacent intervals have zero distance by setting their weight to zero\n    adjusted_weights = torch.where((t[..., 1:] - t[..., :-1]) < eps, torch.zeros_like(adjusted_weights), adjusted_weights)\n\n    # Normalize the adjusted weights using softmax operation to prevent NaN values\n    normalized_weights = torch.nn.functional.softmax(adjusted_weights, dim=-1)\n\n    return normalized_weights"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # Calculate the bias function using Schlick's bias function\n    bias = 1 / (1 + torch.exp(-anneal_slope * (train_frac - 0.5)))\n\n    # Calculate the adjusted weights based on the bias function\n    adjusted_weights = w ** bias\n\n    # Handle cases where adjacent intervals have zero distance\n    adjusted_weights = torch.where(t[..., 1:] - t[..., :-1] <= 0, 0, adjusted_weights)\n\n    # Prevent NaN values by using a softmax operation on the adjusted weights\n    adjusted_weights = torch.nn.functional.softmax(adjusted_weights, dim=-1)\n\n    return adjusted_weights"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    # Calculate the bias function based on the training fraction and annealing slope\n    bias = 1 / (1 + torch.exp(-anneal_slope * (train_frac - 0.5)))\n    \n    # Adjust the weights based on the bias function\n    w_adjusted = w ** bias\n    \n    # Handle cases where adjacent intervals have zero distance\n    w_adjusted = torch.where((t[..., 1:] - t[..., :-1]) < eps, torch.zeros_like(w_adjusted), w_adjusted)\n    \n    # Prevent NaN values by using a softmax operation on the adjusted weights\n    w_adjusted = torch.nn.functional.softmax(w_adjusted, dim=-1)\n    \n    return w_adjusted"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # Compute the cumulative sum of the weights\n    cw = integrate_weights(w)\n\n    # Calculate the annealing factor using Schlick's bias function\n    annealing_factor = torch.exp(-anneal_slope * (1 - train_frac))\n\n    # Adjust the weights based on the annealing factor\n    adjusted_weights = (cw[..., 1:] - cw[..., :-1]) * annealing_factor\n    adjusted_weights = torch.cat([torch.zeros_like(adjusted_weights[..., :1]), adjusted_weights], dim=-1)\n\n    # Apply softmax to prevent NaN values and ensure stability\n    adjusted_weights = torch.softmax(adjusted_weights, dim=-1)\n\n    return adjusted_weights"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # Compute the cumulative sum of w\n    cw = integrate_weights(w)\n\n    # Calculate the annealing factor using Schlick's bias function\n    annealing_factor = torch.exp(-anneal_slope * (1 - train_frac))\n\n    # Adjust the weights based on the annealing factor\n    adjusted_w = (cw[..., 1:] - cw[..., :-1]) * annealing_factor\n    adjusted_w = torch.cat([adjusted_w, torch.ones_like(adjusted_w[..., -1:])], dim=-1)  # Ensure the size matches original w\n\n    # Handle cases where adjacent intervals have zero distance\n    zero_distance_mask = t[..., 1:] - t[..., :-1] < eps\n    adjusted_w = torch.where(zero_distance_mask, torch.zeros_like(adjusted_w), adjusted_w)\n\n    # Prevent NaN values by applying softmax operation on the adjusted weights\n    adjusted_w = torch.nn.functional.softmax(adjusted_w, dim=-1)\n\n    return adjusted_w"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # Calculate the annealing factor based on the training fraction and anneal slope\n    anneal_factor = torch.exp(-anneal_slope * (1 - train_frac))\n\n    # Calculate the adjusted weights using Schlick's bias function\n    adjusted_weights = w * (1 - anneal_factor) / (t[..., 1:] - t[..., :-1]).clip(eps)\n\n    # Handle cases where adjacent intervals have zero distance\n    adjusted_weights = torch.where((t[..., 1:] - t[..., :-1]) < eps, 0, adjusted_weights)\n\n    # Apply softmax operation to prevent NaN values\n    adjusted_weights = torch.nn.functional.softmax(adjusted_weights, dim=-1)\n\n    return adjusted_weights"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # Calculate the annealing factor using Schlick's bias function\n    anneal_factor = 1 / (1 + torch.exp(-anneal_slope * (train_frac - 0.5)))\n\n    # Adjust the weights based on the annealing factor\n    adjusted_weights = w ** anneal_factor\n\n    # Handle cases where adjacent intervals have zero distance\n    adjusted_weights = torch.where(t[..., 1:] - t[..., :-1] < eps, 0, adjusted_weights)\n\n    # Prevent NaN values by applying softmax operation on the adjusted weights\n    adjusted_weights = torch.nn.functional.softmax(adjusted_weights, dim=-1)\n\n    return adjusted_weights"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # Calculate the annealing factor based on the training fraction and annealing slope\n    annealing_factor = torch.sigmoid(anneal_slope * (train_frac - 0.5))\n\n    # Calculate the adjusted weights using Schlick's bias function\n    adjusted_weights = (w + eps) ** (1 / (annealing_factor + eps))\n\n    # Ensure stability by handling cases where adjacent intervals have zero distance\n    adjusted_weights = torch.where(t[..., 1:] - t[..., :-1] < eps, 0, adjusted_weights)\n\n    # Normalize the adjusted weights using softmax operation to prevent NaN values\n    normalized_weights = torch.nn.functional.softmax(adjusted_weights, dim=-1)\n\n    return normalized_weights"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # Calculate the annealing factor based on the training fraction and annealing slope\n    annealing_factor = torch.exp(-anneal_slope * (1 - train_frac))\n\n    # Calculate the adjusted weights using Schlick's bias function\n    adjusted_weights = w ** annealing_factor\n\n    # Handle cases where adjacent intervals have zero distance by setting their weight to zero\n    adjusted_weights = torch.where(t[..., 1:] - t[..., :-1] < eps, torch.zeros_like(adjusted_weights), adjusted_weights)\n\n    # Prevent NaN values by using a softmax operation on the adjusted weights\n    normalized_weights = torch.softmax(adjusted_weights, dim=-1)\n\n    return normalized_weights"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    dt = t[..., 1:] - t[..., :-1]\n    dt = torch.where(dt < eps, torch.full_like(dt, eps), dt)  # handle zero distance intervals\n    alpha = 1.0 - torch.exp(-anneal_slope * train_frac * dt)  # Schlick's bias function\n    w_adj = w * alpha\n    w_adj = w_adj / torch.sum(w_adj, dim=-1, keepdim=True).clip(eps)  # prevent NaN values\n    return w_adj"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # Calculate the bias function using Schlick's bias function\n    bias = 1 / (1 + torch.exp(-anneal_slope * (train_frac - 0.5)))\n\n    # Adjust the weights based on the bias function\n    w_adjusted = w ** bias\n\n    # Handle cases where adjacent intervals have zero distance\n    t_diff = t[..., 1:] - t[..., :-1]\n    w_adjusted = torch.where(t_diff < eps, torch.zeros_like(w_adjusted), w_adjusted)\n\n    # Prevent NaN values by using softmax operation on adjusted weights\n    w_softmax = torch.nn.functional.softmax(w_adjusted, dim=-1)\n\n    return w_softmax"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "\n    # Calculate the annealing factor using Schlick's bias function\n    anneal_factor = 1 / (1 + (anneal_slope * (1 - train_frac)))\n\n    # Adjust the weights based on the annealing factor\n    w_adjusted = w ** anneal_factor\n\n    # Handle cases where adjacent intervals have zero distance\n    t_diff = t[..., 1:] - t[..., :-1]\n    zero_distance_mask = t_diff < eps\n    w_adjusted = torch.where(zero_distance_mask, torch.zeros_like(w_adjusted), w_adjusted)\n\n    # Prevent NaN values by using a softmax operation on the adjusted weights\n    w_softmax = torch.nn.functional.softmax(w_adjusted, dim=-1)\n\n    return w_softmax"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # Calculate the distance between intervals\n    interval_distance = t[..., 1:] - t[..., :-1]\n    \n    # Calculate the bias function using Schlick's bias function\n    bias = 1 / (1 + (train_frac / (1 - train_frac)) * torch.exp(-anneal_slope * interval_distance))\n    \n    # Apply the bias function to adjust the weights\n    adjusted_weights = w * bias\n    \n    # Handle cases where adjacent intervals have zero distance\n    adjusted_weights = torch.where(interval_distance < eps, torch.zeros_like(adjusted_weights), adjusted_weights)\n    \n    # Normalize the adjusted weights using softmax to prevent NaN values\n    normalized_weights = torch.nn.functional.softmax(adjusted_weights, dim=-1)\n    \n    return normalized_weights"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    dt = t[..., 1:] - t[..., :-1]\n    dt = torch.where(dt < eps, torch.zeros_like(dt), dt)  # handle zero distance intervals\n    alpha = torch.exp(-anneal_slope * (1 - train_frac))\n    adjusted_w = w * (alpha ** (t[..., :-1] / dt))\n    adjusted_w = adjusted_w / torch.sum(adjusted_w, dim=-1, keepdim=True)  # softmax operation\n    return adjusted_w"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    dt = t[..., 1:] - t[..., :-1]\n    bias = torch.exp(-anneal_slope * train_frac * dt)\n    w_adj = w * bias\n    w_adj = w_adj / torch.sum(w_adj, dim=-1, keepdim=True).clip(eps)\n    return w_adj"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # Calculate the annealing factor using Schlick's bias function\n    annealing_factor = 1 / (1 + (anneal_slope * (1 - train_frac)))\n\n    # Adjust the weights based on the annealing factor\n    adjusted_weights = w ** annealing_factor\n\n    # Handle cases where adjacent intervals have zero distance\n    adjusted_weights = torch.where(t[..., 1:] - t[..., :-1] <= 0, 0, adjusted_weights)\n\n    # Prevent NaN values by using a softmax operation on the adjusted weights\n    normalized_weights = torch.nn.functional.softmax(adjusted_weights, dim=-1)\n\n    return normalized_weights"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    # Calculate the distance between adjacent intervals\n    dt = t[..., 1:] - t[..., :-1]\n    # Calculate the annealing factor based on the training fraction and anneal slope\n    anneal_factor = torch.exp(-anneal_slope * (1 - train_frac))\n    # Adjust the weights based on the annealing factor and distance between intervals\n    w_adjusted = w * anneal_factor.pow(dt)\n    # Handle cases where adjacent intervals have zero distance, setting their weight to zero\n    w_adjusted = torch.where(dt < eps, 0.0, w_adjusted)\n    # Apply softmax operation to prevent NaN values\n    w_adjusted = torch.nn.functional.softmax(w_adjusted, dim=-1)\n    return w_adjusted"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    \n    # Calculate the annealing factor using Schlick's bias function\n    annealing_factor = 1 / (1 + torch.exp(-anneal_slope * (train_frac - 0.5)))\n\n    # Adjust the weights based on the annealing factor\n    adjusted_weights = w ** annealing_factor\n\n    # Handle cases where adjacent intervals have zero distance by setting their weight to zero\n    adjusted_weights = torch.where(t[..., 1:] - t[..., :-1] < eps, torch.zeros_like(adjusted_weights), adjusted_weights)\n\n    # Prevent NaN values by using a softmax operation on the adjusted weights\n    adjusted_weights = torch.nn.functional.softmax(adjusted_weights, dim=-1)\n\n    return adjusted_weights"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: to_cuda(v, device, ignore_list) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.to(device, non_blocking=True)\n    else:\n        pass  # do nothing here, used for typed in to_x for methods\n        # FIXME: Incosistent behavior here, might lead to undebuggable bugs\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "\n    if isinstance(batch, (tuple, list)) and not ignore_list:\n        batch = [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: to_cuda(v, device, ignore_list) for k, v in batch.items() if k != \"meta\"})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.to(device, non_blocking=True)\n    else:\n        pass  # do nothing here, used for typed in to_x for methods\n        # FIXME: Incosistent behavior here, might lead to undebuggable bugs\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    # Check if the input batch is a list or tuple\n    if isinstance(batch, (list, tuple)):\n        # Iterate through each element in the list or tuple and convert it to a CUDA tensor\n        return [to_cuda(b, device, ignore_list) for b in batch]\n    # Check if the input batch is a dictionary\n    elif isinstance(batch, dict):\n        # Iterate through each key-value pair in the dictionary\n        return {k: to_cuda(v, device, ignore_list) if k != 'meta' else v for k, v in batch.items()}\n    # Check if the input batch is a torch tensor\n    elif isinstance(batch, torch.Tensor):\n        # Move the tensor to the specified CUDA device\n        return batch.to(device)\n    else:\n        # Return the input batch as is\n        return batch"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: to_cuda(v, device, ignore_list) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.to(device, non_blocking=True)\n    else:\n        pass  # do nothing here, used for typed in to_x for methods\n        # FIXME: Incosistent behavior here, might lead to undebuggable bugs\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, (tuple, list)) and not ignore_list:\n        batch = [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, dict):\n        if \"meta\" in batch:\n            batch = dotdict({k: to_cuda(v, device, ignore_list) for k, v in batch.items()})\n        else:\n            batch = {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.to(device, non_blocking=True)\n    else:\n        pass  # do nothing here, used for typed in to_x for methods\n        # FIXME: Incosistent behavior here, might lead to undebuggable bugs\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "\n    if isinstance(batch, (tuple, list)):\n        batch = [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, dict):\n        if \"meta\" in batch:\n            batch = dotdict({k: to_cuda(v, device, ignore_list) for k, v in batch.items()})\n        else:\n            batch = {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.to(device, non_blocking=True)\n    else:\n        pass  # do nothing here, used for typed in to_x for methods\n        # FIXME: Incosistent behavior here, might lead to undebuggable bugs\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [to_cuda(b, device) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: to_cuda(v, device) if k != 'meta' else v for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.to(device, non_blocking=True)\n    elif isinstance(batch, np.ndarray):  # numpy and others\n        batch = torch.as_tensor(batch).to(device, non_blocking=True)\n    else:\n        pass  # do nothing here, used for typed in to_x for methods\n        # FIXME: Incosistent behavior here, might lead to undebuggable bugs\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: to_cuda(v, device, ignore_list) if k != 'meta' else v for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.to(device)\n    else:\n        pass  # do nothing here, used for typed in to_cuda for methods\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: to_cuda(v, device, ignore_list) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.to(device, non_blocking=True)\n    else:\n        pass  # do nothing here, used for typed in to_x for methods\n        # FIXME: Incosistent behavior here, might lead to undebuggable bugs\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: to_cuda(v, device, ignore_list) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.to(device, non_blocking=True)\n    else:\n        pass  # do nothing here, used for typed in to_x for methods\n        # FIXME: Incosistent behavior here, might lead to undebuggable bugs\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: to_cuda(v, device, ignore_list) if k != \"meta\" else v for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.to(device, non_blocking=True)\n    else:\n        pass  # do nothing here, used for typed in to_cuda for methods\n        # FIXME: Incosistent behavior here, might lead to undebuggable bugs\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: to_cuda(v, device, ignore_list) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.to(device, non_blocking=True)\n    else:\n        pass  # do nothing here, used for typed in to_x for methods\n        # FIXME: Incosistent behavior here, might lead to undebuggable bugs\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: to_cuda(v, device, ignore_list) if k != \"meta\" else v for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.to(device)\n    else:\n        pass  # do nothing here, used for typed in to_cuda for methods\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, dict):\n        if 'meta' in batch:\n            batch = dotdict({k: to_cuda(v, device, ignore_list) for k, v in batch.items()})\n        else:\n            batch = {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.to(device, non_blocking=True)\n    else:\n        pass  # do nothing here, used for typed in to_cuda for methods\n        # FIXME: Incosistent behavior here, might lead to undebuggable bugs\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: to_cuda(v, device, ignore_list) if k != 'meta' else v for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.to(device)\n    else:\n        pass  # do nothing here, used for typed in to_x for methods\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "\n    if isinstance(batch, (tuple, list)):\n        batch = [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, dict):\n        if 'meta' in batch:\n            batch = dotdict({k: to_cuda(v, device, ignore_list) for k, v in batch.items()})\n        else:\n            batch = {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.to(device, non_blocking=True)\n    else:\n        pass  # do nothing here, used for typed in to_x for methods\n        # FIXME: Incosistent behavior here, might lead to undebuggable bugs\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, dict):\n        if 'meta' in batch:\n            batch['meta'] = to_cuda(batch['meta'], device, ignore_list)\n        else:\n            batch = {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.to(device, non_blocking=True)\n    else:\n        pass  # do nothing here, used for typed in to_x for methods\n        # FIXME: Incosistent behavior here, might lead to undebuggable bugs\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: to_cuda(v, device, ignore_list) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.to(device, non_blocking=True)\n    else:\n        pass  # do nothing here, used for typed in to_x for methods\n        # FIXME: Incosistent behavior here, might lead to undebuggable bugs\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, dict):\n        if 'meta' in batch:\n            batch = dotdict({k: to_cuda(v, device, ignore_list) for k, v in batch.items()})\n        else:\n            batch = {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.to(device, non_blocking=True)\n    else:\n        pass  # do nothing here, used for typed in to_cuda for methods\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: to_cuda(v, device, ignore_list) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.to(device, non_blocking=True)\n    else:\n        pass  # do nothing here, used for typed in to_x for methods\n        # FIXME: Incosistent behavior here, might lead to undebuggable bugs\n    return batch"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # Gather the vertices for each face using the faces tensor\n    gathered_vertices = multi_gather(v, f, dim=dim)\n\n    # Compute the edges of the triangles\n    edge1 = gathered_vertices[:, 1] - gathered_vertices[:, 0]\n    edge2 = gathered_vertices[:, 2] - gathered_vertices[:, 0]\n\n    # Compute the face normals by taking the cross product of the edges\n    face_normals = torch.cross(edge1, edge2, dim=dim)\n\n    return face_normals"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # Gather the vertices for each face\n    vertices_per_face = multi_gather(v, f, dim=dim)\n\n    # Compute the vectors forming the edges of each face\n    edge1 = vertices_per_face[:, 1, ...] - vertices_per_face[:, 0, ...]\n    edge2 = vertices_per_face[:, 2, ...] - vertices_per_face[:, 0, ...]\n\n    # Compute the face normals\n    face_normals = torch.cross(edge1, edge2, dim=dim)\n\n    return face_normals"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # Gather the vertices for each face\n    gathered_vertices = multi_gather(v, f, dim)\n\n    # Compute the vectors of the edges of each face\n    edge1 = gathered_vertices[:, 1] - gathered_vertices[:, 0]\n    edge2 = gathered_vertices[:, 2] - gathered_vertices[:, 0]\n\n    # Compute the face normals\n    face_normals = torch.cross(edge1, edge2, dim=dim)\n\n    return face_normals"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    return multi_gather(v, f, dim)"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # expand the faces tensor to match the batch dimension of the vertices tensor\n    f_expanded = multi_indexing(f, v.shape, dim)\n\n    # gather the vertices using the expanded faces tensor\n    gathered_vertices = multi_gather(v, f_expanded, dim)\n\n    return gathered_vertices"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # Gather the vertices for each face\n    vertices_per_face = multi_gather(v, f, dim=dim)\n\n    # Compute the vectors between vertices\n    edge1 = vertices_per_face[:, 1] - vertices_per_face[:, 0]\n    edge2 = vertices_per_face[:, 2] - vertices_per_face[:, 0]\n\n    # Compute the face normals\n    face_normals = torch.cross(edge1, edge2, dim=dim)\n\n    return face_normals"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # Gather the vertices for each face\n    triangles = multi_gather(v, f, dim)\n\n    # Compute the face normals\n    edge1 = triangles[:, 1, ...] - triangles[:, 0, ...]\n    edge2 = triangles[:, 2, ...] - triangles[:, 0, ...]\n    face_normals = torch.cross(edge1, edge2, dim=dim)\n\n    return face_normals"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # Gather the vertices for each face\n    gathered_vertices = multi_gather(v, f, dim)\n\n    # Compute the normals of the faces\n    face_normals = torch.cross(gathered_vertices[:, :, 1, :] - gathered_vertices[:, :, 0, :], \n                               gathered_vertices[:, :, 2, :] - gathered_vertices[:, :, 0, :], dim=2)\n\n    return face_normals"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    return multi_gather(v, f, dim)"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # Gather the vertices for each face\n    vertices_per_face = multi_gather(v, f, dim=dim)\n\n    # Compute the edges of each face\n    edges = torch.roll(vertices_per_face, shifts=-1, dims=-2) - vertices_per_face\n\n    # Compute the cross product of the edges to get the face normals\n    face_normals = torch.cross(edges[:, 0], edges[:, 1], dim=dim)\n\n    return face_normals"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    return multi_gather(v, f, dim)"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # Gather the vertices for each face\n    gathered_vertices = multi_gather(v, f, dim)\n\n    # Compute the normals of the faces\n    edge1 = gathered_vertices[:, 1, ...] - gathered_vertices[:, 0, ...]\n    edge2 = gathered_vertices[:, 2, ...] - gathered_vertices[:, 0, ...]\n    face_normals = torch.cross(edge1, edge2, dim=dim)\n\n    return face_normals"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # Gather the vertices for each face\n    gathered_vertices = multi_gather(v, f, dim)\n\n    # Compute the normals of the faces\n    face_normals = torch.cross(gathered_vertices[:, :, 1, :] - gathered_vertices[:, :, 0, :],\n                               gathered_vertices[:, :, 2, :] - gathered_vertices[:, :, 0, :], dim=2)\n\n    # Reshape the result to maintain the structure of the original faces tensor with additional dimensions for batch processing\n    return face_normals"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # Gather the vertices for each face\n    gathered_vertices = multi_gather(v, f, dim=dim)\n\n    # Compute the vectors for each edge of the triangle\n    edge1 = gathered_vertices[:, 1] - gathered_vertices[:, 0]\n    edge2 = gathered_vertices[:, 2] - gathered_vertices[:, 0]\n\n    # Compute the face normals\n    face_normals = torch.cross(edge1, edge2, dim=dim)\n\n    return face_normals"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # Gather the vertices for each face\n    gathered_vertices = multi_gather(v, f, dim=dim)\n\n    # Compute the vectors representing the edges of the triangles\n    edge1 = gathered_vertices[:, 1, ...] - gathered_vertices[:, 0, ...]\n    edge2 = gathered_vertices[:, 2, ...] - gathered_vertices[:, 0, ...]\n\n    # Compute the face normals\n    face_normals = torch.cross(edge1, edge2, dim=dim)\n\n    return face_normals"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    v = v if f.ndim == v.ndim else expand_at_the_back(v, f)  # expand v to match the batch dimension of f if necessary\n    return multi_gather(v, f, dim)"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # expand the faces tensor to match the batch dimension of the vertices tensor if necessary\n    f_expanded = multi_indexing(f, v.shape, dim)\n\n    # gather the vertices using the expanded faces tensor\n    gathered_vertices = multi_gather(v, f_expanded, dim)\n\n    return gathered_vertices"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # expand the faces tensor to match the batch dimension of the vertices tensor\n    f_expanded = multi_indexing(f, v.shape, dim)\n\n    # gather the vertices using the expanded faces tensor\n    gathered_vertices = multi_gather(v, f_expanded, dim)\n\n    return gathered_vertices"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # expand faces tensor to match the batch dimension of the vertices tensor if necessary\n    f_expanded = multi_indexing(f, v.shape, dim)\n\n    # gather vertices using the expanded faces tensor\n    gathered_vertices = multi_gather(v, f_expanded, dim)\n\n    return gathered_vertices"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # expand f to match the batch dimension of v if necessary\n    f_expanded = multi_indexing(f, v.shape, dim)\n\n    # gather the vertices using the expanded faces tensor\n    gathered_vertices = multi_gather(v, f_expanded, dim)\n\n    return gathered_vertices"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n        batch = [b[None] for b in batch]  # add batch dimension\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):\n        batch = batch[None]  # add batch dimension\n    else:\n        raise NotImplementedError('Unsupported data type')\n\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = {k: add_batch(v) for k, v in batch.items()}\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        batch = np.expand_dims(batch, axis=0)\n    else:\n        raise ValueError(\"Unsupported data type\")\n\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    batch = to_tensor(batch)\n    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    else:  # numpy and others\n        batch = torch.as_tensor(batch)[None]\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n        batch = torch.stack(batch, dim=0) if isinstance(batch[0], torch.Tensor) else np.stack(batch, axis=0)\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        batch = np.expand_dims(batch, axis=0)\n    else:\n        raise NotImplementedError(f\"Unsupported data type: {type(batch)}\")\n\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n        batch = torch.stack(batch) if isinstance(batch[0], torch.Tensor) else np.stack(batch)\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):\n        if isinstance(batch, torch.Tensor):\n            batch = batch[None, ...]  # add new dimension at the zeroth position\n        else:\n            batch = batch[np.newaxis, ...]  # add new dimension at the zeroth position\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):  # numpy and others\n        batch = np.expand_dims(batch, axis=0)\n    else:\n        raise NotImplementedError('Supported overloading')\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        batch = np.expand_dims(batch, axis=0)\n    else:\n        pass  # do nothing here, used for typed in to_x for methods\n        # FIXME: Incosistent behavior here, might lead to undebuggable bugs\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n        batch = torch.stack(batch, dim=0) if isinstance(batch[0], torch.Tensor) else np.stack(batch, axis=0)\n    elif isinstance(batch, dict):\n        batch = {k: add_batch(v) for k, v in batch.items()}\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        batch = np.expand_dims(batch, axis=0)\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        batch = np.expand_dims(batch, axis=0)\n    else:\n        raise ValueError(\"Unsupported data type\")\n\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n        batch = np.stack(batch, axis=0)\n    elif isinstance(batch, dict):\n        batch = {k: add_batch(v) for k, v in batch.items()}\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        batch = np.expand_dims(batch, axis=0)\n    else:\n        raise NotImplementedError(f\"The data type {type(batch)} is not supported.\")\n\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n        batch = torch.stack(batch) if isinstance(batch[0], torch.Tensor) else np.stack(batch)\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch[None, ...]\n    else:  # numpy and others\n        batch = np.expand_dims(batch, axis=0)\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n        batch = to_tensor(batch)\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = to_tensor(batch)\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n        batch = torch.stack(batch, dim=0) if isinstance(batch[0], torch.Tensor) else np.stack(batch, axis=0)\n    elif isinstance(batch, dict):\n        batch = {k: add_batch(v) for k, v in batch.items()}\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        batch = np.expand_dims(batch, axis=0)\n    else:\n        raise ValueError(\"Unsupported data type\")\n\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n        batch = [to_tensor(b) for b in batch]\n        batch = torch.stack(batch)\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        batch = np.expand_dims(batch, axis=0)\n    else:\n        raise ValueError(\"Unsupported data type\")\n\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n        batch = np.stack(batch)  # adding new dimension to the zeroth position\n    elif isinstance(batch, dict):\n        batch = {k: add_batch(v) for k, v in batch.items()}\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):\n        batch = np.expand_dims(batch, axis=0)  # adding new dimension to the zeroth position\n    else:\n        raise NotImplementedError(f'Unsupported type: {type(batch)}')\n\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        batch = np.expand_dims(batch, axis=0)\n    else:\n        pass  # do nothing here, used for typed in to_x for methods\n        # FIXME: Incosistent behavior here, might lead to undebuggable bugs\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    else:  # numpy and others\n        batch = np.expand_dims(batch, axis=0)\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = {k: add_batch(v) for k, v in batch.items()}\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        batch = np.expand_dims(batch, axis=0)\n    else:\n        raise NotImplementedError('Unsupported data type for adding batch dimension')\n\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n        batch = torch.stack(batch)\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    else:  # numpy and others\n        batch = torch.as_tensor(batch).unsqueeze(0)\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        batch = np.expand_dims(batch, axis=0)\n    else:\n        raise NotImplementedError('Unsupported input type')\n\n    return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H = torch.tensor(self.H)\n        batch.W = torch.tensor(self.W)\n        batch.K = torch.tensor(self.K.mT.ravel())\n        batch.R = torch.tensor(self.R.mT.ravel())\n        batch.T = torch.tensor(self.T.ravel())\n        batch.n = torch.tensor(self.n)\n        batch.f = torch.tensor(self.f)\n        batch.t = torch.tensor(self.t)\n        batch.v = torch.tensor(self.v)\n        batch.bounds = torch.tensor(self.bounds.ravel())\n\n        meta = dotdict()\n        meta.mass = torch.tensor(self.mass)\n        meta.moment_of_inertia = torch.tensor(self.moment_of_inertia)\n        meta.movement_force = torch.tensor(self.movement_force)\n        meta.movement_torque = torch.tensor(self.movement_torque)\n        meta.movement_speed = torch.tensor(self.movement_speed)\n        meta.origin = torch.tensor(self.origin.ravel())\n        meta.world_up = torch.tensor(self.world_up.ravel())\n\n        batch.meta = meta\n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H = torch.tensor(self.H)\n        batch.W = torch.tensor(self.W)\n        batch.K = torch.tensor(self.K.mT.ravel())\n        batch.R = torch.tensor(self.R.mT.ravel())\n        batch.T = torch.tensor(self.T.ravel())\n        batch.n = torch.tensor(self.n)\n        batch.f = torch.tensor(self.f)\n        batch.t = torch.tensor(self.t)\n        batch.v = torch.tensor(self.v)\n        batch.bounds = torch.tensor(self.bounds.mT.ravel())\n        \n        meta = dotdict()\n        meta.mass = torch.tensor(self.mass)\n        meta.moment_of_inertia = torch.tensor(self.moment_of_inertia)\n        meta.movement_force = torch.tensor(self.movement_force)\n        meta.movement_torque = torch.tensor(self.movement_torque)\n        meta.movement_speed = torch.tensor(self.movement_speed)\n        meta.origin = torch.tensor(self.origin.ravel())\n        meta.world_up = torch.tensor(self.world_up.ravel())\n        \n        batch.meta = meta\n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H = torch.tensor(self.H)\n        batch.W = torch.tensor(self.W)\n        batch.K = torch.tensor(self.K.mT.ravel())\n        batch.R = torch.tensor(self.R.mT.ravel())\n        batch.T = torch.tensor(self.T.ravel())\n        batch.n = torch.tensor(self.n)\n        batch.f = torch.tensor(self.f)\n        batch.t = torch.tensor(self.t)\n        batch.v = torch.tensor(self.v)\n        batch.bounds = torch.tensor(self.bounds.ravel())\n        \n        meta = dotdict()\n        meta.mass = torch.tensor(self.mass)\n        meta.moment_of_inertia = torch.tensor(self.moment_of_inertia)\n        meta.movement_force = torch.tensor(self.movement_force)\n        meta.movement_torque = torch.tensor(self.movement_torque)\n        meta.movement_speed = torch.tensor(self.movement_speed)\n        meta.origin = torch.tensor(self.origin.ravel())\n        meta.world_up = torch.tensor(self.world_up.ravel())\n        \n        batch.meta = meta\n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H = torch.tensor(self.H)\n        batch.W = torch.tensor(self.W)\n        batch.K = torch.tensor(self.K.mT.ravel())\n        batch.R = torch.tensor(self.R.mT.ravel())\n        batch.T = torch.tensor(self.T.ravel())\n        batch.n = torch.tensor(self.n)\n        batch.f = torch.tensor(self.f)\n        batch.t = torch.tensor(self.t)\n        batch.v = torch.tensor(self.v)\n        batch.bounds = torch.tensor(self.bounds.mT.ravel())\n        \n        meta = dotdict()\n        meta.mass = torch.tensor(self.mass)\n        meta.moment_of_inertia = torch.tensor(self.moment_of_inertia)\n        meta.movement_force = torch.tensor(self.movement_force)\n        meta.movement_torque = torch.tensor(self.movement_torque)\n        meta.movement_speed = torch.tensor(self.movement_speed)\n        meta.origin = torch.tensor(self.origin.ravel())\n        meta.world_up = torch.tensor(self.world_up.ravel())\n        \n        batch.meta = meta\n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H = torch.tensor(self.H)\n        batch.W = torch.tensor(self.W)\n        batch.K = torch.tensor(self.K.mT.ravel())\n        batch.R = torch.tensor(self.R.mT.ravel())\n        batch.T = torch.tensor(self.T.ravel())\n        batch.n = torch.tensor(self.n)\n        batch.f = torch.tensor(self.f)\n        batch.t = torch.tensor(self.t)\n        batch.v = torch.tensor(self.v)\n        batch.bounds = torch.tensor(self.bounds.ravel())\n\n        meta = dotdict()\n        meta.H = batch.H\n        meta.W = batch.W\n        meta.K = batch.K\n        meta.R = batch.R\n        meta.T = batch.T\n        meta.n = batch.n\n        meta.f = batch.f\n        meta.t = batch.t\n        meta.v = batch.v\n        meta.bounds = batch.bounds\n\n        batch.meta = meta\n\n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H = torch.tensor(self.H)\n        batch.W = torch.tensor(self.W)\n        batch.K = torch.tensor(self.K.mT.ravel())\n        batch.R = torch.tensor(self.R.mT.ravel())\n        batch.T = torch.tensor(self.T.ravel())\n        batch.n = torch.tensor(self.n)\n        batch.f = torch.tensor(self.f)\n        batch.t = torch.tensor(self.t)\n        batch.v = torch.tensor(self.v)\n        batch.bounds = torch.tensor(self.bounds.ravel())\n        \n        meta = dotdict()\n        meta.H = batch.H\n        meta.W = batch.W\n        meta.K = batch.K\n        meta.R = batch.R\n        meta.T = batch.T\n        meta.n = batch.n\n        meta.f = batch.f\n        meta.t = batch.t\n        meta.v = batch.v\n        meta.bounds = batch.bounds\n        \n        batch.meta = meta\n        \n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H = torch.tensor(self.H)\n        batch.W = torch.tensor(self.W)\n        batch.K = torch.tensor(self.K.mT.ravel())\n        batch.R = torch.tensor(self.R.mT.ravel())\n        batch.T = torch.tensor(self.T.ravel())\n        batch.n = torch.tensor(self.n)\n        batch.f = torch.tensor(self.f)\n        batch.t = torch.tensor(self.t)\n        batch.v = torch.tensor(self.v)\n        batch.bounds = torch.tensor(self.bounds.ravel())\n        \n        meta = dotdict()\n        meta.H = batch.H\n        meta.W = batch.W\n        meta.K = batch.K\n        meta.R = batch.R\n        meta.T = batch.T\n        meta.n = batch.n\n        meta.f = batch.f\n        meta.t = batch.t\n        meta.v = batch.v\n        meta.bounds = batch.bounds\n        \n        batch.meta = meta\n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H = torch.tensor(self.H)\n        batch.W = torch.tensor(self.W)\n        batch.K = torch.tensor(self.K.mT.ravel())\n        batch.R = torch.tensor(self.R.mT.ravel())\n        batch.T = torch.tensor(self.T.ravel())\n        batch.n = torch.tensor(self.n)\n        batch.f = torch.tensor(self.f)\n        batch.t = torch.tensor(self.t)\n        batch.v = torch.tensor(self.v)\n        batch.bounds = torch.tensor(self.bounds.ravel())\n\n        meta = dotdict()\n        meta.H = batch.H\n        meta.W = batch.W\n        meta.K = batch.K\n        meta.R = batch.R\n        meta.T = batch.T\n        meta.n = batch.n\n        meta.f = batch.f\n        meta.t = batch.t\n        meta.v = batch.v\n        meta.bounds = batch.bounds\n\n        batch.meta = meta\n\n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H = torch.tensor(self.H)\n        batch.W = torch.tensor(self.W)\n        batch.K = torch.tensor(self.K.mT.ravel())\n        batch.R = torch.tensor(self.R.mT.ravel())\n        batch.T = torch.tensor(self.T.ravel())\n        batch.n = torch.tensor(self.n)\n        batch.f = torch.tensor(self.f)\n        batch.t = torch.tensor(self.t)\n        batch.v = torch.tensor(self.v)\n        batch.bounds = torch.tensor(self.bounds.ravel())\n        \n        meta = dotdict()\n        meta.H = batch.H\n        meta.W = batch.W\n        meta.K = batch.K\n        meta.R = batch.R\n        meta.T = batch.T\n        meta.n = batch.n\n        meta.f = batch.f\n        meta.t = batch.t\n        meta.v = batch.v\n        meta.bounds = batch.bounds\n        \n        batch.meta = meta\n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H = torch.tensor(self.H)\n        batch.W = torch.tensor(self.W)\n        batch.K = torch.tensor(self.K.mT.ravel())\n        batch.R = torch.tensor(self.R.mT.ravel())\n        batch.T = torch.tensor(self.T.ravel())\n        batch.n = torch.tensor(self.n)\n        batch.f = torch.tensor(self.f)\n        batch.t = torch.tensor(self.t)\n        batch.v = torch.tensor(self.v)\n        batch.bounds = torch.tensor(self.bounds.ravel())\n\n        meta = dotdict()\n        meta.H = batch.H\n        meta.W = batch.W\n        meta.K = batch.K\n        meta.R = batch.R\n        meta.T = batch.T\n        meta.n = batch.n\n        meta.f = batch.f\n        meta.t = batch.t\n        meta.v = batch.v\n        meta.bounds = batch.bounds\n\n        batch.meta = meta\n\n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H = torch.tensor(self.H)\n        batch.W = torch.tensor(self.W)\n        batch.K = torch.tensor(self.K.mT.ravel())\n        batch.R = torch.tensor(self.R.mT.ravel())\n        batch.T = torch.tensor(self.T.ravel())\n        batch.n = torch.tensor(self.n)\n        batch.f = torch.tensor(self.f)\n        batch.t = torch.tensor(self.t)\n        batch.v = torch.tensor(self.v)\n        batch.bounds = torch.tensor(self.bounds.ravel())\n\n        meta = dotdict()\n        meta.mass = torch.tensor(self.mass)\n        meta.moment_of_inertia = torch.tensor(self.moment_of_inertia)\n        meta.movement_force = torch.tensor(self.movement_force)\n        meta.movement_torque = torch.tensor(self.movement_torque)\n        meta.movement_speed = torch.tensor(self.movement_speed)\n        meta.origin = torch.tensor(self.origin.ravel())\n        meta.world_up = torch.tensor(self.world_up.ravel())\n\n        batch.meta = meta\n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H = torch.tensor(self.H)\n        batch.W = torch.tensor(self.W)\n        batch.K = torch.tensor(self.K.mT.ravel())\n        batch.R = torch.tensor(self.R.mT.ravel())\n        batch.T = torch.tensor(self.T.ravel())\n        batch.n = torch.tensor(self.n)\n        batch.f = torch.tensor(self.f)\n        batch.t = torch.tensor(self.t)\n        batch.v = torch.tensor(self.v)\n        batch.bounds = torch.tensor(self.bounds.ravel())\n\n        meta = dotdict()\n        meta.mass = torch.tensor(self.mass)\n        meta.moment_of_inertia = torch.tensor(self.moment_of_inertia)\n        meta.movement_force = torch.tensor(self.movement_force)\n        meta.movement_torque = torch.tensor(self.movement_torque)\n        meta.movement_speed = torch.tensor(self.movement_speed)\n        meta.origin = torch.tensor(self.origin.ravel())\n        meta.world_up = torch.tensor(self.world_up.ravel())\n\n        batch.meta = meta\n\n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H = self.H\n        batch.W = self.W\n        batch.K = torch.as_tensor(self.K)\n        batch.R = torch.as_tensor(self.R)\n        batch.T = torch.as_tensor(self.T)\n        batch.n = self.n\n        batch.f = self.f\n        batch.t = self.t\n        batch.v = self.v\n        batch.bounds = torch.as_tensor(self.bounds)\n        batch.mass = self.mass\n        batch.moment_of_inertia = self.moment_of_inertia\n        batch.movement_force = self.movement_force\n        batch.movement_torque = self.movement_torque\n        batch.movement_speed = self.movement_speed\n        batch.origin = torch.as_tensor(self.origin)\n        batch.world_up = torch.as_tensor(self.world_up)\n\n        meta = dotdict()\n        meta.H = self.H\n        meta.W = self.W\n        meta.K = torch.as_tensor(self.K)\n        meta.R = torch.as_tensor(self.R)\n        meta.T = torch.as_tensor(self.T)\n        meta.n = self.n\n        meta.f = self.f\n        meta.t = self.t\n        meta.v = self.v\n        meta.bounds = torch.as_tensor(self.bounds)\n        meta.mass = self.mass\n        meta.moment_of_inertia = self.moment_of_inertia\n        meta.movement_force = self.movement_force\n        meta.movement_torque = self.movement_torque\n        meta.movement_speed = self.movement_speed\n        meta.origin = torch.as_tensor(self.origin)\n        meta.world_up = torch.as_tensor(self.world_up)\n\n        batch.meta = meta\n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H = torch.tensor(self.H)\n        batch.W = torch.tensor(self.W)\n        batch.K = torch.tensor(self.K.mT.ravel())\n        batch.R = torch.tensor(self.R.mT.ravel())\n        batch.T = torch.tensor(self.T.ravel())\n        batch.n = torch.tensor(self.n)\n        batch.f = torch.tensor(self.f)\n        batch.t = torch.tensor(self.t)\n        batch.v = torch.tensor(self.v)\n        batch.bounds = torch.tensor(self.bounds.ravel())\n        \n        meta = dotdict()\n        meta.H = batch.H\n        meta.W = batch.W\n        meta.K = batch.K\n        meta.R = batch.R\n        meta.T = batch.T\n        meta.n = batch.n\n        meta.f = batch.f\n        meta.t = batch.t\n        meta.v = batch.v\n        meta.bounds = batch.bounds\n        \n        batch.meta = meta\n        \n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H = torch.tensor(self.H)\n        batch.W = torch.tensor(self.W)\n        batch.K = torch.tensor(self.K.mT.ravel())\n        batch.R = torch.tensor(self.R.mT.ravel())\n        batch.T = torch.tensor(self.T.ravel())\n        batch.n = torch.tensor(self.n)\n        batch.f = torch.tensor(self.f)\n        batch.t = torch.tensor(self.t)\n        batch.v = torch.tensor(self.v)\n        batch.bounds = torch.tensor(self.bounds.ravel())\n        \n        meta = dotdict()\n        meta.H = batch.H\n        meta.W = batch.W\n        meta.K = batch.K\n        meta.R = batch.R\n        meta.T = batch.T\n        meta.n = batch.n\n        meta.f = batch.f\n        meta.t = batch.t\n        meta.v = batch.v\n        meta.bounds = batch.bounds\n        \n        batch.meta = meta\n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H = torch.tensor(self.H)\n        batch.W = torch.tensor(self.W)\n        batch.K = torch.tensor(self.K.mT.ravel())\n        batch.R = torch.tensor(self.R.mT.ravel())\n        batch.T = torch.tensor(self.T.ravel())\n        batch.n = torch.tensor(self.n)\n        batch.f = torch.tensor(self.f)\n        batch.t = torch.tensor(self.t)\n        batch.v = torch.tensor(self.v)\n        batch.bounds = torch.tensor(self.bounds.ravel())\n\n        meta = dotdict()\n        meta.mass = torch.tensor(self.mass)\n        meta.moment_of_inertia = torch.tensor(self.moment_of_inertia)\n        meta.movement_force = torch.tensor(self.movement_force)\n        meta.movement_torque = torch.tensor(self.movement_torque)\n        meta.movement_speed = torch.tensor(self.movement_speed)\n        meta.origin = torch.tensor(self.origin.ravel())\n        meta.world_up = torch.tensor(self.world_up.ravel())\n\n        batch.meta = meta\n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H = torch.tensor(self.H)\n        batch.W = torch.tensor(self.W)\n        batch.K = torch.tensor(self.K.mT.ravel())\n        batch.R = torch.tensor(self.R.mT.ravel())\n        batch.T = torch.tensor(self.T.ravel())\n        batch.n = torch.tensor(self.n)\n        batch.f = torch.tensor(self.f)\n        batch.t = torch.tensor(self.t)\n        batch.v = torch.tensor(self.v)\n        batch.bounds = torch.tensor(self.bounds.ravel())\n        \n        meta = dotdict()\n        meta.H = batch.H\n        meta.W = batch.W\n        meta.K = batch.K\n        meta.R = batch.R\n        meta.T = batch.T\n        meta.n = batch.n\n        meta.f = batch.f\n        meta.t = batch.t\n        meta.v = batch.v\n        meta.bounds = batch.bounds\n        \n        batch.meta = meta\n        \n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H = torch.tensor(self.H)\n        batch.W = torch.tensor(self.W)\n        batch.K = torch.tensor(self.K.mT.ravel())\n        batch.R = torch.tensor(self.R.mT.ravel())\n        batch.T = torch.tensor(self.T.ravel())\n        batch.n = torch.tensor(self.n)\n        batch.f = torch.tensor(self.f)\n        batch.t = torch.tensor(self.t)\n        batch.v = torch.tensor(self.v)\n        batch.bounds = torch.tensor(self.bounds.ravel())\n\n        meta = dotdict()\n        meta.H = batch.H\n        meta.W = batch.W\n        meta.K = batch.K\n        meta.R = batch.R\n        meta.T = batch.T\n        meta.n = batch.n\n        meta.f = batch.f\n        meta.t = batch.t\n        meta.v = batch.v\n        meta.bounds = batch.bounds\n\n        batch.meta = meta\n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H = torch.tensor(self.H)\n        batch.W = torch.tensor(self.W)\n        batch.K = torch.tensor(self.K.mT.ravel())\n        batch.R = torch.tensor(self.R.mT.ravel())\n        batch.T = torch.tensor(self.T.ravel())\n        batch.n = torch.tensor(self.n)\n        batch.f = torch.tensor(self.f)\n        batch.t = torch.tensor(self.t)\n        batch.v = torch.tensor(self.v)\n        batch.bounds = torch.tensor(self.bounds.ravel())\n\n        meta = dotdict()\n        meta.H = batch.H\n        meta.W = batch.W\n        meta.K = batch.K\n        meta.R = batch.R\n        meta.T = batch.T\n        meta.n = batch.n\n        meta.f = batch.f\n        meta.t = batch.t\n        meta.v = batch.v\n        meta.bounds = batch.bounds\n\n        batch.meta = meta\n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H = torch.tensor(self.H)\n        batch.W = torch.tensor(self.W)\n        batch.K = torch.tensor(self.K.mT.ravel())\n        batch.R = torch.tensor(self.R.mT.ravel())\n        batch.T = torch.tensor(self.T.ravel())\n        batch.n = torch.tensor(self.n)\n        batch.f = torch.tensor(self.f)\n        batch.t = torch.tensor(self.t)\n        batch.v = torch.tensor(self.v)\n        batch.bounds = torch.tensor(self.bounds.ravel())\n        \n        meta = dotdict()\n        meta.H = batch.H\n        meta.W = batch.W\n        meta.K = batch.K\n        meta.R = batch.R\n        meta.T = batch.T\n        meta.n = batch.n\n        meta.f = batch.f\n        meta.t = batch.t\n        meta.v = batch.v\n        meta.bounds = batch.bounds\n        \n        batch.meta = meta\n        return batch"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.to_dict(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.to_dict(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.to_dict(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.to_dict(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.to_dict(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.to_dict(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.to_dict(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.to_dict(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.to_dict(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.to_dict(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.to_dict(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.to_dict(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.to_dict(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.to_dict(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.to_dict(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.to_dict(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.to_dict(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.to_dict(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.to_dict(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.to_dict(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if not self.agents:\n                return None, float('-inf')\n\n            max_similarity = float('-inf')\n            closest_agent = None\n\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, float('-inf')"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if not self.agents:\n                return None, float('-inf')\n\n            similarities = [cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0] for agent in self.agents]\n            max_similarity = max(similarities)\n            closest_agent = self.agents[similarities.index(max_similarity)]\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, float('-inf')"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            max_similarity = -np.inf\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -np.inf"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            max_similarity = -np.inf\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -np.inf"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if not self.agents:\n                return None, float('-inf')\n\n            max_similarity = float('-inf')\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, float('-inf')"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            max_similarity = -1\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -float('inf')"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if not self.agents:\n                return None, float('-inf')\n\n            max_similarity = float('-inf')\n            closest_agent = None\n\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, float('-inf')"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if not self.agents:\n                return None, float('-inf')\n\n            max_similarity = float('-inf')\n            closest_agent = None\n\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, float('-inf')"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            max_similarity = -np.inf\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -np.inf"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            max_similarity = -1\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -float('inf')"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            max_similarity = -float('inf')\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -float('inf')"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            max_similarity = -np.inf\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -np.inf"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            highest_similarity = -np.inf\n            closest_agent = None\n\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > highest_similarity:\n                    highest_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, highest_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -np.inf"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            max_similarity = -float('inf')\n            closest_agent = None\n\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -float('inf')"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if not self.agents:\n                return None, float('-inf')\n\n            max_similarity = float('-inf')\n            closest_agent = None\n\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, float('-inf')"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            max_similarity = -np.inf\n            closest_agent = None\n\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -np.inf"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            closest_agent = None\n            highest_similarity = -float('inf')\n\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > highest_similarity:\n                    highest_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, highest_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -float('inf')"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            max_similarity = -float('inf')\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -float('inf')"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if not self.agents:\n                return None, float('-inf')\n\n            max_similarity = float('-inf')\n            closest_agent = None\n\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, float('-inf')"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if not self.agents:\n                return None, float('-inf')\n\n            max_similarity = float('-inf')\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, float('-inf')"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(prompt=PRIME_PROMPT, name=PRIME_NAME, weight=PRIME_AGENT_WEIGHT, is_prime=True, unspecified_flag=True)\n        self.add_agent(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\"prime_agent_prompt\", PRIME_NAME, 1, self, self.openai_wrapper)\n        prime_agent.weight = PRIME_AGENT_WEIGHT\n        prime_agent.is_prime = True\n        prime_agent.unspecified_flag = True\n        self.agents.append(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\"prime_prompt\", PRIME_NAME, 1, self, self.openai_wrapper)\n        prime_agent.weight = PRIME_AGENT_WEIGHT\n        prime_agent.is_prime = True\n        prime_agent.unspecified_flag = True\n        self.agents.append(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(PRIME_PROMPT, PRIME_NAME, weight=PRIME_AGENT_WEIGHT, is_prime=True, unspecified_flag=False)\n        self.add_agent(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(PRIME_PROMPT, PRIME_NAME, weight=PRIME_AGENT_WEIGHT, is_prime=True, unspecified_flag=True)\n        self.add_agent(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\"\", PRIME_NAME, 0, self, self.openai_wrapper)\n        prime_agent.weight = PRIME_AGENT_WEIGHT\n        prime_agent.is_prime = True\n        prime_agent.unspecified_flag = True\n        self.agents.append(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(prompt=PRIME_PROMPT, name=PRIME_NAME, weight=PRIME_AGENT_WEIGHT, is_prime=True, unspecified_flag=True)\n        self.add_agent(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\"prime_agent_prompt\", PRIME_NAME, 0, self, self.openai_wrapper)\n        prime_agent.weight = PRIME_AGENT_WEIGHT\n        prime_agent.is_prime = True\n        prime_agent.unspecified_flag = True\n        self.agents.append(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(PRIME_PROMPT, PRIME_NAME, 0, self, self.openai_wrapper)\n        prime_agent.weight = PRIME_AGENT_WEIGHT\n        prime_agent.is_prime = True\n        prime_agent.flag = True  # Set any other flags as needed\n        self.agents.append(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\"prime prompt\", PRIME_NAME, 0, self, self.openai_wrapper)\n        prime_agent.weight = PRIME_AGENT_WEIGHT\n        prime_agent.is_prime = True\n        prime_agent.unspecified_flag = True\n        self.agents.append(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(PRIME_PROMPT, PRIME_NAME, weight=PRIME_AGENT_WEIGHT, prime=True, unspecified_flag=False)\n        self.add_agent(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\"prime prompt\", PRIME_NAME, 0, self, self.openai_wrapper)\n        prime_agent.weight = PRIME_AGENT_WEIGHT\n        prime_agent.is_prime = True\n        prime_agent.unspecified_flag = True\n        self.agents.append(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\"Prime Agent Prompt\", PRIME_NAME, 0, self, self.openai_wrapper)\n        prime_agent.weight = PRIME_AGENT_WEIGHT\n        prime_agent.is_prime = True\n        prime_agent.unspecified_flag = True\n        self.agents.append(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\"prime_prompt\", PRIME_NAME, 1, self, self.openai_wrapper)\n        prime_agent.weight = PRIME_AGENT_WEIGHT\n        prime_agent.is_prime = True\n        prime_agent.unspecified_flag = True\n        self.agents.append(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(PRIME_PROMPT, PRIME_NAME, weight=PRIME_AGENT_WEIGHT, is_prime=True, unspecified_flag=True)\n        self.add_agent(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\"Prime agent prompt\", PRIME_NAME, 0, self, self.openai_wrapper)\n        prime_agent.weight = PRIME_AGENT_WEIGHT\n        prime_agent.is_prime = True\n        prime_agent.unspecified_flag = True\n        self.agents.append(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\"prime_agent_prompt\", PRIME_NAME, 0, self, self.openai_wrapper)\n        prime_agent.weight = PRIME_AGENT_WEIGHT\n        prime_agent.is_prime = True\n        prime_agent.unspecified_flag = True\n        self.agents.append(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\"prime prompt\", PRIME_NAME, 1, self, self.openai_wrapper, is_prime=True)\n        prime_agent.weight = PRIME_AGENT_WEIGHT\n        prime_agent.is_prime = True\n        prime_agent.unspecified_flag = True\n        self.agents.append(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\"prime agent prompt\", PRIME_NAME, 0, self, self.openai_wrapper)\n        prime_agent.weight = PRIME_AGENT_WEIGHT\n        prime_agent.is_prime = True\n        prime_agent.unspecified_flag = None\n        self.agents.append(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\"prime prompt\", PRIME_NAME, 0, self, self.openai_wrapper)\n        prime_agent.weight = PRIME_AGENT_WEIGHT\n        prime_agent.is_prime = True\n        prime_agent.unspecified_flag = True\n        self.agents.append(prime_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "        agent_dict = self.persistence.load_agent(purpose)\n        if agent_dict:\n            agent = AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n            return agent\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "        agent_dict = self.persistence.load_agent(purpose)\n        if agent_dict:\n            agent = AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n            return agent\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "        agent_dict = self.persistence.load_agent_by_purpose(purpose)\n        if agent_dict:\n            agent = AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n            return agent\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "        agent_dict = self.persistence.load_agent(purpose)\n        if agent_dict:\n            return AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "        agent_dict = self.persistence.load_agent_by_purpose(purpose)\n        if agent_dict:\n            agent = AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n            return agent\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "        agent_dict = self.persistence.load_agent(purpose)\n        if agent_dict:\n            agent = AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n            return agent\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "        agent_dict = self.persistence.load_agent_by_purpose(purpose)\n        if agent_dict:\n            agent = AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n            return agent\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "        agent_dict = self.persistence.load_agent_by_purpose(purpose)\n        if agent_dict:\n            agent = AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n            return agent\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "        agent_dict = self.persistence.load_agent(purpose)\n        if agent_dict:\n            agent = AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n            return agent\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "        agent_dict = self.persistence.load_agent(purpose)\n        if agent_dict:\n            agent = AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n            return agent\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "        agent_dict = self.persistence.load_agent(purpose)\n        if agent_dict:\n            agent = AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n            return agent\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "        agent_dict = self.persistence.load_agent(purpose)\n        if agent_dict:\n            agent = AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n            return agent\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "        agent_dict = self.persistence.load_agent_by_purpose(purpose)\n        if agent_dict:\n            agent = AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n            return agent\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "        agent_dict = self.persistence.load_agent_by_purpose(purpose)\n        if agent_dict:\n            agent = AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n            return agent\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "        agent_dict = self.persistence.load_agent(purpose)\n        if agent_dict:\n            agent = AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n            return agent\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "        agent_dict = self.persistence.load_agent_by_purpose(purpose)\n        if agent_dict:\n            agent = AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n            return agent\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "        agent_dict = self.persistence.load_agent_by_purpose(purpose)\n        if agent_dict:\n            agent = AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n            return agent\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "        agent_dict = self.persistence.load_agent(purpose)\n        if agent_dict:\n            agent = AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n            return agent\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "        agent_dict = self.persistence.load_agent_by_purpose(purpose)\n        if agent_dict:\n            agent = AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n            return agent\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "        agent_dict = self.persistence.load_agent(purpose)\n        if agent_dict:\n            agent = AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n            return agent\n        else:\n            return None"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "    agent_info = response[response.find(\"Use Agent[\") + len(\"Use Agent[\"):response.find(\"]\")]\n    agent_name, input_text = agent_info.split(\":\") if \":\" in agent_info else (agent_info, \"\")\n    return agent_name, input_text.strip()"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "    agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n    agent_name, input_text = agent_info.split(\":\") if \":\" in agent_info else (agent_info, \"\")\n    return agent_name, input_text.strip()"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response[response.find(\"Use Agent[\") + len(\"Use Agent[\"):response.find(\"]\")]\n        agent_name, input_text = agent_info.split(\":\") if \":\" in agent_info else (agent_info, \"\")\n        return agent_name, input_text"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name = agent_info.split(\":\")[0]\n        input_text = agent_info.split(\":\")[1] if \":\" in agent_info else \"\"\n        return agent_name, input_text"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response[response.find('Use Agent[') + len('Use Agent['):response.find(']')].split(':')\n        agent_name = agent_info[0]\n        input_text = agent_info[1] if len(agent_info) > 1 else \"\"\n        return agent_name, input_text"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name, input_text = agent_info.split(\":\") if \":\" in agent_info else (agent_info, \"\")\n        return agent_name, input_text"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name, input_text = agent_info.split(\":\") if \":\" in agent_info else (agent_info, \"\")\n        return agent_name, input_text"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split('Use Agent[')[1].split(']')[0]\n        agent_name, input_text = agent_info.split(':') if ':' in agent_info else (agent_info, '')\n        return agent_name, input_text"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "    agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n    agent_name, input_text = agent_info.split(\":\") if \":\" in agent_info else (agent_info, \"\")\n    return agent_name, input_text.strip()"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split('Use Agent[')[1].split(']')[0].split(':')\n        agent_name = agent_info[0]\n        input_text = agent_info[1] if len(agent_info) > 1 else \"\"\n        return agent_name, input_text"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response[response.find('Use Agent[') + len('Use Agent['):response.find(']')]\n        agent_name, input_text = agent_info.split(':') if ':' in agent_info else (agent_info, '')\n        return agent_name, input_text"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info_start = response.find('Use Agent[')\n        agent_info_end = response.find(']', agent_info_start)\n        if agent_info_start != -1 and agent_info_end != -1:\n            agent_info = response[agent_info_start + len('Use Agent['):agent_info_end]\n            agent_name, input_text = agent_info.split(':') if ':' in agent_info else (agent_info, '')\n            return agent_name, input_text\n        else:\n            return '', ''"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split('Use Agent[')[1].split(']')[0]\n        agent_name, input_text = agent_info.split(':') if ':' in agent_info else (agent_info, \"\")\n        return agent_name, input_text"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "    agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n    agent_name, input_text = agent_info.split(\":\") if \":\" in agent_info else (agent_info, \"\")\n    return agent_name, input_text.strip()"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        start_index = response.find(\"Use Agent[\") + len(\"Use Agent[\")\n        end_index = response.find(\"]\", start_index)\n        agent_info = response[start_index:end_index]\n        agent_name, input_text = agent_info.split(\":\") if \":\" in agent_info else (agent_info, \"\")\n        return agent_name, input_text"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response[response.find('Use Agent[') + len('Use Agent['):response.find(']')].split(':')\n        agent_name = agent_info[0]\n        input_text = agent_info[1] if len(agent_info) > 1 else \"\"\n        return agent_name, input_text"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name, input_text = agent_info.split(\":\") if \":\" in agent_info else (agent_info, \"\")\n        return agent_name, input_text"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split('Use Agent[')[1].split(']')[0]\n        agent_name, input_text = agent_info.split(':') if ':' in agent_info else (agent_info, '')\n        return agent_name, input_text"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name, input_text = agent_info.split(\":\") if \":\" in agent_info else (agent_info, \"\")\n        return agent_name, input_text"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name, input_text = agent_info.split(\":\") if \":\" in agent_info else (agent_info, \"\")\n        return agent_name, input_text"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        loaded_agents = []\n        # Fetch all serialized agents from the database\n        serialized_agents = self.persistence.fetch_all_agents()\n        \n        # Deserialize each agent and add it to the list of loaded agents\n        for serialized_agent in serialized_agents:\n            loaded_agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if loaded_agent:\n                loaded_agents.append(loaded_agent)\n        \n        return loaded_agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        loaded_agents = []\n        # Fetch all serialized agents from the database\n        serialized_agents = self.persistence.fetch_all_agents()\n        # Deserialize and load each agent\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if agent:\n                loaded_agents.append(agent)\n        return loaded_agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        loaded_agents = []\n        # Fetch all serialized agents from the database\n        serialized_agents = self.persistence.fetch_all_agents()\n        \n        # Deserialize and load each agent using the provided agent lifecycle and OpenAI wrapper\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if agent:\n                loaded_agents.append(agent)\n        \n        return loaded_agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        loaded_agents = []\n        # Fetch all agents from the database\n        all_agents = self.persistence.fetch_all_agents()\n        \n        # Load each agent and add it to the list of loaded agents\n        for serialized_agent in all_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if agent:\n                loaded_agents.append(agent)\n        \n        return loaded_agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        agents = []\n        # Fetch all agents from the database\n        all_serialized_agents = self.persistence.fetch_all_agents()\n        \n        # Load each agent and add it to the list if successfully loaded\n        for serialized_agent in all_serialized_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if agent:\n                agents.append(agent)\n        \n        return agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        all_agents = []\n        # Load all agents from the database\n        # Iterate through each agent and load it using the load_agent method\n        # Append the loaded agent to the list of all_agents\n        # Return the list of all_agents\n        return all_agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        loaded_agents = []\n        # Fetch all serialized agents from the database\n        serialized_agents = self.persistence.fetch_all_agents()\n        \n        # Deserialize and load each agent\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if agent:\n                loaded_agents.append(agent)\n        \n        return loaded_agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        loaded_agents = []\n        # Fetch all agents from the database\n        all_agents = self.persistence.fetch_all_agents()\n        \n        # Load each agent and add it to the list of loaded agents\n        for serialized_agent in all_agents:\n            loaded_agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if loaded_agent:\n                loaded_agents.append(loaded_agent)\n        \n        return loaded_agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        loaded_agents = []\n        # Fetch all serialized agents from the database\n        serialized_agents = self.persistence.fetch_all_agents()\n        \n        # Deserialize and load each agent\n        for serialized_agent in serialized_agents:\n            loaded_agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if loaded_agent:\n                loaded_agents.append(loaded_agent)\n        \n        return loaded_agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        loaded_agents = []\n        # Fetch all agents from the database\n        all_agents = self.persistence.fetch_all_agents()\n        # Load each agent and add it to the list of loaded agents\n        for serialized_agent in all_agents:\n            loaded_agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if loaded_agent:\n                loaded_agents.append(loaded_agent)\n        return loaded_agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        loaded_agents = []\n        # Fetch all serialized agents from the database\n        serialized_agents = self.persistence.fetch_all_agents()\n        \n        # Deserialize and load each agent using the provided agent lifecycle and OpenAI wrapper\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if agent:\n                loaded_agents.append(agent)\n        \n        return loaded_agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        loaded_agents = []\n        # Fetch all serialized agents from the database\n        serialized_agents = self.persistence.fetch_all_agents()\n        \n        # Deserialize and load each agent\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if agent:\n                loaded_agents.append(agent)\n        \n        return loaded_agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        loaded_agents = []\n        # Fetch all agents from the database\n        all_agents = self.persistence.fetch_all_agents()\n        # Load each agent and add it to the list of loaded agents\n        for serialized_agent in all_agents:\n            loaded_agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            loaded_agents.append(loaded_agent)\n        return loaded_agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        loaded_agents = []\n        # Fetch all agents from the database\n        all_serialized_agents = self.persistence.fetch_all_agents()\n        \n        # Load each agent and add it to the list of loaded agents\n        for serialized_agent in all_serialized_agents:\n            loaded_agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if loaded_agent:\n                loaded_agents.append(loaded_agent)\n        \n        return loaded_agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        loaded_agents = []\n        # Fetch all agents from the database\n        all_agents = self.persistence.fetch_all_agents()\n        # Load each agent and add it to the list of loaded agents\n        for serialized_agent in all_agents:\n            loaded_agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if loaded_agent:\n                loaded_agents.append(loaded_agent)\n        return loaded_agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        loaded_agents = []\n        # Fetch all serialized agents from the database\n        all_serialized_agents = self.persistence.fetch_all_agents()\n        # Deserialize and load each agent\n        for serialized_agent in all_serialized_agents:\n            loaded_agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if loaded_agent:\n                loaded_agents.append(loaded_agent)\n        return loaded_agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        loaded_agents = []\n        # Fetch all serialized agents from the database\n        serialized_agents = self.persistence.fetch_all_agents()\n        \n        # Deserialize and load each agent\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if agent:\n                loaded_agents.append(agent)\n        \n        return loaded_agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        loaded_agents = []\n        # Fetch all agents from the database\n        all_serialized_agents = self.persistence.fetch_all_agents()\n        \n        # Load each agent and add it to the list of loaded agents\n        for serialized_agent in all_serialized_agents:\n            loaded_agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            loaded_agents.append(loaded_agent)\n        \n        return loaded_agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        agents = []\n        # Fetch all agents from the database\n        all_agents = self.persistence.fetch_all_agents()\n        # Load each agent and add it to the list if successfully loaded\n        for serialized_agent in all_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if agent:\n                agents.append(agent)\n        return agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        all_agents = []\n        # Fetch all agents from the database\n        serialized_agents = self.persistence.fetch_all_agents()\n        if serialized_agents:\n            # Deserialize and load each agent\n            for serialized_agent in serialized_agents:\n                agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n                if agent:\n                    all_agents.append(agent)\n        return all_agents"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error in saving agent: {e}\")\n            raise"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error in saving agent: {e}\")\n            raise"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error in saving agent: {e}\")\n            raise"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error in saving agent: {e}\")\n            raise"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error in saving agent: {e}\")\n            raise"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error in saving agent: {e}\")\n            raise"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error in saving agent: {e}\")\n            raise"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error in saving agent: {e}\")\n            raise"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error in saving agent: {e}\")\n            raise"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error in saving agent: {e}\")\n            raise"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error in saving agent: {e}\")\n            raise"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error in saving agent: {e}\")\n            raise"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error in saving agent: {e}\")\n            raise"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error in saving agent: {e}\")\n            raise"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error in saving agent: {e}\")\n            raise"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error in saving agent: {e}\")\n            raise"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error in saving agent: {e}\")\n            raise"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error in saving agent: {e}\")\n            raise"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error in saving agent: {e}\")\n            raise"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error in saving agent: {e}\")\n            raise"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Get the bounding box of the instance\n    bbox = instance[\"bbox\"]\n    \n    # Calculate the center of the bounding box\n    center_x = (bbox[0] + bbox[2]) / 2\n    center_y = (bbox[1] + bbox[3]) / 2\n    \n    # Calculate the crop region based on the instance's bounding box and the desired crop size\n    crop_x1 = max(0, int(center_x - crop_size[1] / 2))\n    crop_y1 = max(0, int(center_y - crop_size[0] / 2))\n    crop_x2 = min(image_size[1], crop_x1 + crop_size[1])\n    crop_y2 = min(image_size[0], crop_y1 + crop_size[0])\n    \n    # Create a CropTransform object with the calculated crop region\n    crop_transform = T.CropTransform(crop_x1, crop_y1, crop_x2, crop_y2)\n    \n    return crop_transform"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Get the bounding box of the instance\n    bbox = instance[\"bbox\"]\n\n    # Calculate the center of the bounding box\n    center_x = (bbox[0] + bbox[2]) / 2\n    center_y = (bbox[1] + bbox[3]) / 2\n\n    # Calculate the top-left corner of the crop region\n    crop_x1 = max(0, center_x - crop_size[1] // 2)\n    crop_y1 = max(0, center_y - crop_size[0] // 2)\n\n    # Calculate the bottom-right corner of the crop region\n    crop_x2 = min(image_size[1], center_x + crop_size[1] // 2)\n    crop_y2 = min(image_size[0], center_y + crop_size[0] // 2)\n\n    # Create a CropTransform object\n    crop_transform = T.CropTransform(crop_x1, crop_y1, crop_x2, crop_y2)\n\n    return crop_transform"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_x = (bbox[0] + bbox[2]) / 2\n    center_y = (bbox[1] + bbox[3]) / 2\n\n    crop_height, crop_width = crop_size\n    half_height = crop_height / 2\n    half_width = crop_width / 2\n\n    # Calculate the top-left corner of the crop\n    crop_x1 = max(0, center_x - half_width)\n    crop_y1 = max(0, center_y - half_height)\n\n    # Adjust the top-left corner if it exceeds image boundaries\n    crop_x1 = min(crop_x1, image_size[1] - crop_width)\n    crop_y1 = min(crop_y1, image_size[0] - crop_height)\n\n    return T.CropTransform(crop_x1, crop_y1, crop_width, crop_height)"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Get the bounding box of the instance\n    bbox = instance[\"bbox\"]\n    \n    # Calculate the center of the bounding box\n    center_x = bbox[0] + bbox[2] / 2\n    center_y = bbox[1] + bbox[3] / 2\n    \n    # Calculate the top-left corner of the crop region\n    crop_x = max(0, center_x - crop_size[1] / 2)\n    crop_y = max(0, center_y - crop_size[0] / 2)\n    \n    # Adjust the crop region to fit within the image boundaries\n    crop_x = min(crop_x, image_size[1] - crop_size[1])\n    crop_y = min(crop_y, image_size[0] - crop_size[0])\n    \n    # Create a CropTransform object with the calculated crop region\n    return T.CropTransform(crop_x, crop_y, crop_size[1], crop_size[0])"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = instance[\"bbox\"]\n    bbox_mode = instance[\"bbox_mode\"]\n    bbox = BoxMode.convert(bbox, bbox_mode, BoxMode.XYXY_ABS)\n    \n    # Calculate the center of the instance's bounding box\n    center_x = (bbox[0] + bbox[2]) / 2\n    center_y = (bbox[1] + bbox[3]) / 2\n    \n    # Calculate the top-left corner of the crop region\n    crop_x1 = max(0, center_x - crop_size[1] // 2)\n    crop_y1 = max(0, center_y - crop_size[0] // 2)\n    \n    # Calculate the bottom-right corner of the crop region\n    crop_x2 = min(image_size[1], center_x + crop_size[1] // 2)\n    crop_y2 = min(image_size[0], center_y + crop_size[0] // 2)\n    \n    return T.CropTransform(crop_x1, crop_y1, crop_x2, crop_y2, crop_size[1], crop_size[0])"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = instance[\"bbox\"]\n    bbox_mode = instance[\"bbox_mode\"]\n    bbox = BoxMode.convert(bbox, bbox_mode, BoxMode.XYXY_ABS)\n    \n    # Calculate the center of the bounding box\n    center_x = (bbox[2] + bbox[0]) / 2\n    center_y = (bbox[3] + bbox[1]) / 2\n    \n    # Calculate the top-left corner of the crop\n    crop_x1 = max(0, int(center_x - crop_size[1] / 2))\n    crop_y1 = max(0, int(center_y - crop_size[0] / 2))\n    \n    # Calculate the bottom-right corner of the crop\n    crop_x2 = min(image_size[1], crop_x1 + crop_size[1])\n    crop_y2 = min(image_size[0], crop_y1 + crop_size[0])\n    \n    return T.CropTransform(crop_x1, crop_y1, crop_x2, crop_y2)"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    x1, y1, x2, y2 = bbox\n    center_x = (x1 + x2) / 2\n    center_y = (y1 + y2) / 2\n\n    crop_height, crop_width = crop_size\n    crop_x1 = max(0, int(center_x - crop_width / 2))\n    crop_y1 = max(0, int(center_y - crop_height / 2))\n    crop_x2 = min(image_size[1], crop_x1 + crop_width)\n    crop_y2 = min(image_size[0], crop_y1 + crop_height)\n\n    return T.CropTransform(crop_x1, crop_y1, crop_x2, crop_y2)"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Get the bounding box of the instance\n    bbox = instance[\"bbox\"]\n\n    # Calculate the center of the bounding box\n    center_x = (bbox[0] + bbox[2]) / 2\n    center_y = (bbox[1] + bbox[3]) / 2\n\n    # Calculate the top-left corner of the crop\n    crop_x1 = max(0, center_x - crop_size[1] // 2)\n    crop_y1 = max(0, center_y - crop_size[0] // 2)\n\n    # Calculate the bottom-right corner of the crop\n    crop_x2 = min(image_size[1], center_x + crop_size[1] // 2)\n    crop_y2 = min(image_size[0], center_y + crop_size[0] // 2)\n\n    # Create a CropTransform object\n    crop_transform = T.CropTransform(crop_x1, crop_y1, crop_x2, crop_y2)\n\n    return crop_transform"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Get the bounding box of the instance\n    bbox = instance[\"bbox\"]\n\n    # Calculate the center of the bounding box\n    center_x = (bbox[0] + bbox[2]) / 2\n    center_y = (bbox[1] + bbox[3]) / 2\n\n    # Calculate the top-left corner of the crop\n    crop_x1 = max(0, center_x - crop_size[1] // 2)\n    crop_y1 = max(0, center_y - crop_size[0] // 2)\n\n    # Calculate the bottom-right corner of the crop\n    crop_x2 = min(image_size[1], center_x + crop_size[1] // 2)\n    crop_y2 = min(image_size[0], center_y + crop_size[0] // 2)\n\n    # Create a CropTransform object with the calculated crop coordinates\n    crop_transform = T.CropTransform(crop_x1, crop_y1, crop_x2, crop_y2)\n\n    return crop_transform"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Get the bounding box of the instance\n    bbox = instance[\"bbox\"]\n\n    # Calculate the center of the bounding box\n    center_x = bbox[0] + (bbox[2] - bbox[0]) / 2\n    center_y = bbox[1] + (bbox[3] - bbox[1]) / 2\n\n    # Calculate the top-left corner of the crop based on the center and crop size\n    crop_x1 = max(0, int(center_x - crop_size[1] / 2))\n    crop_y1 = max(0, int(center_y - crop_size[0] / 2))\n\n    # Calculate the bottom-right corner of the crop based on the top-left corner and crop size\n    crop_x2 = min(image_size[1], crop_x1 + crop_size[1])\n    crop_y2 = min(image_size[0], crop_y1 + crop_size[0])\n\n    # Create a CropTransform object with the calculated crop coordinates\n    crop_transform = T.CropTransform(crop_x1, crop_y1, crop_x2, crop_y2)\n\n    return crop_transform"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Get the bounding box of the instance\n    bbox = instance[\"bbox\"]\n\n    # Calculate the center of the bounding box\n    center_x = (bbox[0] + bbox[2]) / 2\n    center_y = (bbox[1] + bbox[3]) / 2\n\n    # Calculate the top-left corner of the crop\n    crop_x1 = max(0, int(center_x - crop_size[1] / 2))\n    crop_y1 = max(0, int(center_y - crop_size[0] / 2))\n\n    # Calculate the bottom-right corner of the crop\n    crop_x2 = min(image_size[1], crop_x1 + crop_size[1])\n    crop_y2 = min(image_size[0], crop_y1 + crop_size[0])\n\n    # Create a CropTransform object with the calculated crop parameters\n    crop_transform = T.CropTransform(crop_x1, crop_y1, crop_x2, crop_y2)\n\n    return crop_transform"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = instance[\"bbox\"]\n    bbox_mode = instance[\"bbox_mode\"]\n    x0, y0, x1, y1 = BoxMode.convert(bbox, bbox_mode, BoxMode.XYXY_ABS)\n    \n    # Calculate the center of the instance\n    center_x = (x0 + x1) / 2\n    center_y = (y0 + y1) / 2\n    \n    # Calculate the top-left corner of the crop\n    crop_x0 = max(0, int(center_x - crop_size[1] / 2))\n    crop_y0 = max(0, int(center_y - crop_size[0] / 2))\n    \n    # Adjust the crop size if it goes beyond the image boundaries\n    crop_x1 = min(image_size[1], crop_x0 + crop_size[1])\n    crop_y1 = min(image_size[0], crop_y0 + crop_size[0])\n    \n    # Adjust the top-left corner if the crop size is adjusted\n    crop_x0 = max(0, crop_x1 - crop_size[1])\n    crop_y0 = max(0, crop_y1 - crop_size[0])\n    \n    return T.CropTransform(crop_x0, crop_y0, crop_x1, crop_y1)"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = instance[\"bbox\"]\n    bbox_mode = instance[\"bbox_mode\"]\n    x1, y1, x2, y2 = BoxMode.convert(bbox, bbox_mode, BoxMode.XYXY_ABS)\n    \n    center_x = (x1 + x2) / 2\n    center_y = (y1 + y2) / 2\n    \n    crop_height, crop_width = crop_size\n    half_crop_height = crop_height / 2\n    half_crop_width = crop_width / 2\n    \n    # Calculate the top-left corner of the crop\n    crop_x1 = max(0, center_x - half_crop_width)\n    crop_y1 = max(0, center_y - half_crop_height)\n    \n    # Adjust the crop to fit within the image boundaries\n    crop_x2 = min(image_size[1], crop_x1 + crop_width)\n    crop_y2 = min(image_size[0], crop_y1 + crop_height)\n    \n    # Adjust the top-left corner if the crop is not centered on the instance\n    crop_x1 = max(0, crop_x2 - crop_width) if crop_x2 - crop_x1 < crop_width else crop_x1\n    crop_y1 = max(0, crop_y2 - crop_height) if crop_y2 - crop_y1 < crop_height else crop_y1\n    \n    return T.CropTransform(crop_x1, crop_y1, crop_x2, crop_y2)"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = instance[\"bbox\"]\n    bbox_mode = instance[\"bbox_mode\"]\n    x0, y0, x1, y1 = BoxMode.convert(bbox, bbox_mode, BoxMode.XYXY_ABS)\n    \n    # Calculate the center of the bounding box\n    center_x = (x0 + x1) / 2\n    center_y = (y0 + y1) / 2\n    \n    # Calculate the half-width and half-height of the crop size\n    crop_width = crop_size[1] // 2\n    crop_height = crop_size[0] // 2\n    \n    # Calculate the top-left corner of the crop\n    crop_x0 = max(0, int(center_x - crop_width))\n    crop_y0 = max(0, int(center_y - crop_height))\n    \n    # Calculate the bottom-right corner of the crop\n    crop_x1 = min(image_size[1], int(center_x + crop_width))\n    crop_y1 = min(image_size[0], int(center_y + crop_height))\n    \n    return T.CropTransform(crop_x0, crop_y0, crop_x1, crop_y1)"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Get the bounding box of the instance\n    bbox = instance[\"bbox\"]\n\n    # Calculate the center of the bounding box\n    center_x = (bbox[0] + bbox[2]) / 2\n    center_y = (bbox[1] + bbox[3]) / 2\n\n    # Calculate the top-left corner of the crop\n    crop_x1 = max(0, center_x - crop_size[1] // 2)\n    crop_y1 = max(0, center_y - crop_size[0] // 2)\n\n    # Calculate the bottom-right corner of the crop\n    crop_x2 = min(image_size[1], center_x + crop_size[1] // 2)\n    crop_y2 = min(image_size[0], center_y + crop_size[0] // 2)\n\n    # Create a CropTransform object\n    crop_transform = T.CropTransform(crop_x1, crop_y1, crop_x2, crop_y2)\n\n    return crop_transform"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Get the bounding box of the instance\n    bbox = instance[\"bbox\"]\n    \n    # Calculate the center of the bounding box\n    center_x = (bbox[0] + bbox[2]) / 2\n    center_y = (bbox[1] + bbox[3]) / 2\n    \n    # Calculate the top-left corner of the crop region\n    crop_x1 = max(0, int(center_x - crop_size[1] / 2))\n    crop_y1 = max(0, int(center_y - crop_size[0] / 2))\n    \n    # Calculate the bottom-right corner of the crop region\n    crop_x2 = min(image_size[1], crop_x1 + crop_size[1])\n    crop_y2 = min(image_size[0], crop_y1 + crop_size[0])\n    \n    # Create the CropTransform object\n    crop_transform = T.CropTransform(crop_x1, crop_y1, crop_x2, crop_y2)\n    \n    return crop_transform"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = instance[\"bbox\"]\n    bbox_mode = instance[\"bbox_mode\"]\n    x0, y0, x1, y1 = BoxMode.convert(bbox, bbox_mode, BoxMode.XYXY_ABS)\n    center_x = (x0 + x1) / 2\n    center_y = (y0 + y1) / 2\n    crop_h, crop_w = crop_size\n\n    # Adjust the cropping region to fit within the image boundaries\n    crop_x0 = max(0, center_x - crop_w // 2)\n    crop_y0 = max(0, center_y - crop_h // 2)\n    crop_x1 = min(image_size[1], center_x + crop_w // 2)\n    crop_y1 = min(image_size[0], center_y + crop_h // 2)\n\n    return T.CropTransform(crop_x0, crop_y0, crop_x1, crop_y1)"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Get the bounding box of the instance\n    bbox = instance[\"bbox\"]\n\n    # Calculate the center of the bounding box\n    center_x = (bbox[0] + bbox[2]) / 2\n    center_y = (bbox[1] + bbox[3]) / 2\n\n    # Calculate the top-left corner of the crop region\n    crop_x1 = max(0, center_x - crop_size[1] // 2)\n    crop_y1 = max(0, center_y - crop_size[0] // 2)\n\n    # Calculate the bottom-right corner of the crop region\n    crop_x2 = min(image_size[1], center_x + crop_size[1] // 2)\n    crop_y2 = min(image_size[0], center_y + crop_size[0] // 2)\n\n    # Create a CropTransform object with the calculated crop region\n    crop_transform = T.CropTransform(crop_x1, crop_y1, crop_x2, crop_y2)\n\n    return crop_transform"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    box = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    x1, y1, x2, y2 = box\n    center_x = (x1 + x2) / 2\n    center_y = (y1 + y2) / 2\n\n    crop_height, crop_width = crop_size\n    crop_x1 = max(0, int(center_x - crop_width / 2))\n    crop_y1 = max(0, int(center_y - crop_height / 2))\n    crop_x2 = min(image_size[1], crop_x1 + crop_width)\n    crop_y2 = min(image_size[0], crop_y1 + crop_height)\n\n    return T.CropTransform(crop_x1, crop_y1, crop_x2, crop_y2)"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Get the bounding box of the instance\n    bbox = instance[\"bbox\"]\n\n    # Calculate the center of the bounding box\n    center_x = (bbox[0] + bbox[2]) / 2\n    center_y = (bbox[1] + bbox[3]) / 2\n\n    # Calculate the top-left corner of the crop region\n    crop_x1 = max(0, int(center_x - crop_size[1] / 2))\n    crop_y1 = max(0, int(center_y - crop_size[0] / 2))\n\n    # Calculate the bottom-right corner of the crop region\n    crop_x2 = min(image_size[1], crop_x1 + crop_size[1])\n    crop_y2 = min(image_size[0], crop_y1 + crop_size[0])\n\n    # Create a CropTransform object\n    crop_transform = T.CropTransform(crop_x1, crop_y1, crop_x2, crop_y2)\n\n    return crop_transform"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)  # Apply EXIF orientation\n        image = convert_PIL_to_numpy(image, format)  # Convert to numpy array\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Transform bounding box\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    bbox = transforms.apply_box([bbox])[0]\n    annotation[\"bbox\"] = [bbox[0], bbox[1], bbox[2], bbox[3]]\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Transform segmentation\n    if \"segmentation\" in annotation:\n        if annotation[\"segmentation\"] is None:\n            return annotation\n        if isinstance(annotation[\"segmentation\"], list):\n            # Polygons\n            annotation[\"segmentation\"] = [\n                transforms.apply_polygons([poly])[0] for poly in annotation[\"segmentation\"]\n            ]\n        else:\n            # RLE\n            mask = mask_util.decode(annotation[\"segmentation\"])\n            mask = transforms.apply_segmentation(mask)\n            annotation[\"segmentation\"] = mask_util.encode(np.array(mask[:, :, None], order=\"F\"))[0]\n\n    # Transform keypoints\n    if \"keypoints\" in annotation:\n        annotation[\"keypoints\"] = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n        )\n\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Transform bounding box\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    bbox = transforms.apply_box(np.array([bbox]))[0]\n    annotation[\"bbox\"] = [bbox[0], bbox[1], bbox[2], bbox[3]]\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Transform segmentation\n    if \"segmentation\" in annotation:\n        polygons = annotation[\"segmentation\"]\n        if isinstance(polygons, list):\n            # Convert segmentation polygons to bitmask\n            polygons = [np.array(p).reshape(-1, 2) for p in polygons]\n            polygons = [transforms.apply_polygons([p])[0] for p in polygons]\n            annotation[\"segmentation\"] = [p.flatten().tolist() for p in polygons]\n        elif isinstance(polygons, dict):\n            # Convert segmentation RLE to bitmask\n            mask = mask_util.decode(polygons)\n            mask = transforms.apply_segmentation(mask)\n            rle = mask_util.encode(np.array(mask[:, :, None], order=\"F\", dtype=\"uint8\"))[0]\n            annotation[\"segmentation\"] = rle\n        else:\n            raise ValueError(\"Unsupported segmentation format\")\n\n    # Transform keypoints\n    if \"keypoints\" in annotation:\n        keypoints = annotation[\"keypoints\"]\n        annotation[\"keypoints\"] = transform_keypoint_annotations(\n            keypoints, transforms, image_size, keypoint_hflip_indices\n        )\n\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Transform bounding box\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    bbox = transforms.apply_box(np.array([bbox]))[0]\n    annotation[\"bbox\"] = [bbox[0], bbox[1], bbox[2], bbox[3]]\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Transform segmentation\n    if \"segmentation\" in annotation:\n        segmentation = annotation[\"segmentation\"]\n        if isinstance(segmentation, list):\n            # Polygon format\n            polygons = [np.array(seg).reshape(-1, 2) for seg in segmentation]\n            for i, poly in enumerate(polygons):\n                poly = transforms.apply_polygons([poly])[0]\n                polygons[i] = poly.flatten().tolist()\n            annotation[\"segmentation\"] = polygons\n        elif isinstance(segmentation, dict):\n            # RLE format\n            mask = mask_util.decode(segmentation)\n            mask = transforms.apply_segmentation(mask)\n            rle = mask_util.encode(np.array(mask, order=\"F\", dtype=np.uint8))\n            annotation[\"segmentation\"] = rle\n        else:\n            raise ValueError(\"Unsupported segmentation format\")\n\n    # Transform keypoints\n    if \"keypoints\" in annotation:\n        keypoints = annotation[\"keypoints\"]\n        keypoints = transform_keypoint_annotations(\n            keypoints, transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints.tolist()\n\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "\n    # Transform bounding box\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    bbox = transforms.apply_box(np.array([bbox]))[0]\n    annotation[\"bbox\"] = [float(x) for x in bbox]\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Transform segmentation\n    if \"segmentation\" in annotation:\n        segm = annotation[\"segmentation\"]\n        if isinstance(segm, list):\n            # Polygons\n            transformed_segm = [transforms.apply_polygons([segm])[0]]\n        elif isinstance(segm, dict):\n            # RLE\n            mask = mask_util.decode(segm)\n            mask = transforms.apply_segmentation(mask)\n            rle = mask_util.encode(np.asarray(mask, order=\"F\", dtype=np.uint8))\n            transformed_segm = rle\n        else:\n            raise ValueError(\"Unknown segmentation type: {}\".format(type(segm)))\n        annotation[\"segmentation\"] = transformed_segm\n\n    # Transform keypoints\n    if \"keypoints\" in annotation:\n        keypoints = annotation[\"keypoints\"]\n        transformed_keypoints = transform_keypoint_annotations(\n            keypoints, transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = transformed_keypoints.tolist()\n\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "\n    # Transform bounding box\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    bbox = transforms.apply_box(np.array([bbox]))[0]\n    annotation[\"bbox\"] = [bbox[0], bbox[1], bbox[2], bbox[3]]\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Transform segmentation\n    if \"segmentation\" in annotation:\n        if annotation[\"segmentation\"] is None:\n            annotation[\"segmentation\"] = []\n        else:\n            annotation[\"segmentation\"] = [\n                transforms.apply_segmentation(s) for s in annotation[\"segmentation\"]\n            ]\n\n    # Transform keypoints\n    if \"keypoints\" in annotation:\n        annotation[\"keypoints\"] = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n        )\n\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Transform bounding box\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    bbox = transforms.apply_box([bbox])[0]\n    annotation[\"bbox\"] = [bbox[0], bbox[1], bbox[2], bbox[3]]\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Transform segmentation\n    if \"segmentation\" in annotation:\n        segm = annotation[\"segmentation\"]\n        if isinstance(segm, list):\n            # Polygon\n            segm = [transforms.apply_polygons([s])[0] for s in segm]\n        elif isinstance(segm, dict):\n            # RLE\n            segm = mask_util.decode(segm)\n            segm = transforms.apply_segmentation(segm)\n            segm = mask_util.encode(np.array(segm, order=\"F\", dtype=np.uint8))\n        annotation[\"segmentation\"] = segm\n\n    # Transform keypoints\n    if \"keypoints\" in annotation:\n        keypoints = annotation[\"keypoints\"]\n        keypoints = transform_keypoint_annotations(\n            keypoints, transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Transform bounding box\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    bbox = torch.as_tensor([bbox])\n    bbox = transforms.apply_box(bbox)\n    bbox = bbox[0].tolist()\n    annotation[\"bbox\"] = bbox\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Transform segmentation\n    if \"segmentation\" in annotation:\n        if annotation[\"segmentation\"] is None:\n            del annotation[\"segmentation\"]\n        else:\n            segmentation = annotation[\"segmentation\"]\n            if isinstance(segmentation, list):\n                # Polygons\n                # Note: This assumes that the segmentation is a list of polygons, each represented as a list of points\n                # If segmentation is in RLE format, additional handling is needed\n                for i, poly in enumerate(segmentation):\n                    segmentation[i] = transforms.apply_polygons([poly])[0]\n            elif isinstance(segmentation, dict):\n                # RLE\n                # Additional handling needed for RLE format\n                pass  # Add code to handle RLE format\n            else:\n                # Other formats\n                pass  # Add code to handle other segmentation formats\n\n    # Transform keypoints\n    if \"keypoints\" in annotation:\n        keypoints = annotation[\"keypoints\"]\n        annotation[\"keypoints\"] = transform_keypoint_annotations(\n            keypoints, transforms, image_size, keypoint_hflip_indices\n        )\n\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Transform bounding box\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    bbox = transforms.apply_box(np.array([bbox]))[0]\n    annotation[\"bbox\"] = [bbox[0], bbox[1], bbox[2], bbox[3]]\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Transform segmentation\n    if \"segmentation\" in annotation:\n        polygons = [anno[\"segmentation\"] for anno in [annotation]]\n        if len(polygons):\n            # Apply transforms to segmentation polygons\n            polygons = [transforms.apply_polygons(polygons)]\n            annotation[\"segmentation\"] = polygons[0]\n\n    # Transform keypoints\n    if \"keypoints\" in annotation:\n        keypoints = annotation[\"keypoints\"]\n        keypoints = transform_keypoint_annotations(\n            keypoints, transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints.tolist()\n\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Transform bounding box\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    bbox = transforms.apply_box(np.array([bbox]))[0]\n    annotation[\"bbox\"] = [bbox[0], bbox[1], bbox[2], bbox[3]]\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Transform segmentation\n    if \"segmentation\" in annotation:\n        segmentation = annotation[\"segmentation\"]\n        if isinstance(segmentation, list):\n            # Polygons\n            polygons = [Polygon(polygon) for polygon in segmentation]\n            polygons = [transforms.apply_polygons([polygon])[0] for polygon in polygons]\n            annotation[\"segmentation\"] = [polygon.exterior.coords[:-1] for polygon in polygons]\n        elif isinstance(segmentation, dict):\n            # RLE\n            mask = mask_util.decode(segmentation)\n            mask = transforms.apply_segmentation(mask)\n            rle = mask_util.encode(np.asarray(mask, order=\"F\", dtype=np.uint8))\n            annotation[\"segmentation\"] = rle\n        else:\n            raise ValueError(\"Unsupported segmentation format\")\n\n    # Transform keypoints\n    if \"keypoints\" in annotation:\n        keypoints = annotation[\"keypoints\"]\n        annotation[\"keypoints\"] = transform_keypoint_annotations(\n            keypoints, transforms, image_size, keypoint_hflip_indices\n        )\n\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "\n    # Transform bounding box\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    bbox = transforms.apply_box(np.array([bbox]))[0]\n    annotation[\"bbox\"] = [float(x) for x in bbox]\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Transform segmentation\n    if \"segmentation\" in annotation:\n        segm = annotation[\"segmentation\"]\n        if isinstance(segm, list):\n            # Polygons\n            transformed_segm = [transforms.apply_polygons([segm])[0]]\n        elif isinstance(segm, dict):\n            # RLE\n            mask = mask_util.decode(segm)\n            mask = transforms.apply_segmentation(mask)\n            rle = mask_util.encode(np.asarray(mask, order=\"F\", dtype=np.uint8))\n            transformed_segm = rle\n        else:\n            # Unsupported segmentation format\n            raise ValueError(\"Unsupported segmentation format\")\n        annotation[\"segmentation\"] = transformed_segm\n\n    # Transform keypoints\n    if \"keypoints\" in annotation:\n        keypoints = annotation[\"keypoints\"]\n        transformed_keypoints = transform_keypoint_annotations(\n            keypoints, transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = transformed_keypoints.tolist()\n\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Transform bounding box\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    bbox = transforms.apply_box([bbox])[0]\n    annotation[\"bbox\"] = [bbox[0], bbox[1], bbox[2], bbox[3]]\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Transform segmentation\n    if \"segmentation\" in annotation:\n        segm = annotation[\"segmentation\"]\n        if isinstance(segm, list):\n            # polygon\n            segm = [transforms.apply_coords(s) for s in segm]\n        elif isinstance(segm, dict):\n            # COCO RLE\n            segm = mask_util.frPyObjects([segm], image_size[0], image_size[1])\n            segm = mask_util.merge(segm)\n            segm = mask_util.decode(segm)\n            segm = mask_util.encode(np.asarray(transforms.apply_segmentation(segm), order=\"F\"))\n        annotation[\"segmentation\"] = segm\n\n    # Transform keypoints\n    if \"keypoints\" in annotation:\n        keypoints = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints.tolist()\n\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Transform bounding box\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    bbox = transforms.apply_box(np.array([bbox]))[0]\n    annotation[\"bbox\"] = [bbox[0], bbox[1], bbox[2], bbox[3]]\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Transform segmentation\n    if \"segmentation\" in annotation:\n        if annotation[\"segmentation\"]:\n            polygons = [np.asarray(p, dtype=np.float64).reshape(-1, 2) for p in annotation[\"segmentation\"]]\n            for i, poly in enumerate(polygons):\n                transformed_poly = transforms.apply_polygons([poly])[0]\n                annotation[\"segmentation\"][i] = transformed_poly.flatten().tolist()\n\n    # Transform keypoints\n    if \"keypoints\" in annotation and keypoint_hflip_indices is not None:\n        annotation[\"keypoints\"] = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n        )"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Transform bounding box\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    bbox = list(bbox)\n    bbox = transforms.apply_box([bbox])[0]\n    annotation[\"bbox\"] = bbox\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Transform segmentation\n    if \"segmentation\" in annotation:\n        segm = annotation[\"segmentation\"]\n        if isinstance(segm, list):\n            # polygon\n            segm = [transforms.apply_polygons([s])[0] for s in segm]\n        elif isinstance(segm, dict):\n            # COCO RLE\n            segm = mask_util.decode(segm)\n            segm = transforms.apply_segmentation(segm)\n        elif isinstance(segm, np.ndarray):\n            assert segm.ndim == 2, \"Expect segmentation of 2 dimensions, got {}.\".format(segm.ndim)\n            # mask array\n            segm = transforms.apply_segmentation(segm)\n        else:\n            raise ValueError(\n                \"Cannot transform segmentation of type '{}'! Supported types are: polygons as list[list[float] or ndarray], COCO-style RLE as a dict, or a binary segmentation mask in a 2D numpy array of shape HxW.\".format(type(segm))\n            )\n        annotation[\"segmentation\"] = segm\n\n    # Transform keypoints\n    if \"keypoints\" in annotation:\n        kpts = annotation[\"keypoints\"]\n        kpts = transform_keypoint_annotations(kpts, transforms, image_size, keypoint_hflip_indices)\n        annotation[\"keypoints\"] = kpts\n\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Transform bounding box\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    bbox = transforms.apply_box(np.array([bbox]))[0]\n    annotation[\"bbox\"] = [float(x) for x in bbox]\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Transform segmentation\n    if \"segmentation\" in annotation:\n        if annotation[\"segmentation\"] is None:\n            annotation[\"segmentation\"] = []\n        else:\n            polygons = [np.asarray(polygon, dtype=np.float64) for polygon in annotation[\"segmentation\"]]\n            for i, polygon in enumerate(polygons):\n                polygons[i] = transforms.apply_polygons([polygon])[0]\n            annotation[\"segmentation\"] = [polygon.flatten().tolist() for polygon in polygons]\n\n    # Transform keypoints\n    if \"keypoints\" in annotation:\n        keypoints = annotation[\"keypoints\"]\n        annotation[\"keypoints\"] = transform_keypoint_annotations(\n            keypoints, transforms, image_size, keypoint_hflip_indices\n        )\n\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Transform bounding box\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    bbox = transforms.apply_box(np.array([bbox]))[0]\n    annotation[\"bbox\"] = [float(x) for x in bbox]\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Transform segmentation\n    if \"segmentation\" in annotation:\n        segm = annotation[\"segmentation\"]\n        if isinstance(segm, list):\n            # Polygons\n            polygons = [np.asarray(p).reshape(-1, 2) for p in segm]\n            for i, poly in enumerate(polygons):\n                poly = transforms.apply_polygons([poly])[0]\n                polygons[i] = poly.flatten().tolist()\n            annotation[\"segmentation\"] = polygons\n        elif isinstance(segm, dict):\n            # RLE\n            mask = mask_util.decode(segm)\n            mask = transforms.apply_segmentation(mask)\n            rle = mask_util.encode(np.array(mask, order=\"F\", dtype=np.uint8))\n            annotation[\"segmentation\"] = rle\n        else:\n            raise ValueError(\"Cannot transform segmentation of type '{}'!\".format(type(segm)))\n\n    # Transform keypoints\n    if \"keypoints\" in annotation:\n        keypoints = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints.tolist()\n\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Transform bounding box\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    bbox = list(bbox)\n    bbox = transforms.apply_box([bbox])[0]\n    bbox = BoxMode.convert(bbox, BoxMode.XYXY_ABS, annotation[\"bbox_mode\"])\n    annotation[\"bbox\"] = bbox\n\n    # Transform segmentation\n    if \"segmentation\" in annotation:\n        segmentation = annotation[\"segmentation\"]\n        if isinstance(segmentation, list):\n            # Polygons\n            transformed_segmentation = [transforms.apply_polygons(segmentation)]\n        else:\n            # RLE\n            mask = mask_util.decode(segmentation)\n            mask = transforms.apply_segmentation(mask)\n            transformed_segmentation = mask_util.encode(np.array(mask[:, :, None], order=\"F\"))[0]\n        annotation[\"segmentation\"] = transformed_segmentation\n\n    # Transform keypoints\n    if \"keypoints\" in annotation:\n        keypoints = annotation[\"keypoints\"]\n        transformed_keypoints = transform_keypoint_annotations(\n            keypoints, transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = transformed_keypoints\n\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Transform bounding box\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    bbox = transforms.apply_box([bbox])[0]\n    annotation[\"bbox\"] = [bbox[0], bbox[1], bbox[2], bbox[3]]\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Transform segmentation\n    if \"segmentation\" in annotation:\n        segm = annotation[\"segmentation\"]\n        if isinstance(segm, list):\n            # Polygon format\n            polygons = [np.array(p).reshape(-1, 2) for p in segm]\n            transformed_polygons = [transforms.apply_polygons([p])[0] for p in polygons]\n            annotation[\"segmentation\"] = [p.flatten().tolist() for p in transformed_polygons]\n        elif isinstance(segm, dict):\n            # RLE format\n            rle = mask_util.frPyObjects(segm, image_size[0], image_size[1])\n            rle = transforms.apply_segmentation(rle)\n            annotation[\"segmentation\"] = mask_util.merge(rle)\n\n    # Transform keypoints\n    if \"keypoints\" in annotation:\n        kpts = annotation[\"keypoints\"]\n        kpts = transform_keypoint_annotations(kpts, transforms, image_size, keypoint_hflip_indices)\n        annotation[\"keypoints\"] = kpts.tolist()\n\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Transform bounding box\n    if \"bbox\" in annotation:\n        bbox = BoxMode.convert(annotation[\"bbox\"], annotation.get(\"bbox_mode\", BoxMode.XYXY_ABS), BoxMode.XYXY_ABS)\n        bbox = transforms.apply_box([bbox])[0]\n        bbox = BoxMode.convert(bbox, BoxMode.XYXY_ABS, annotation.get(\"bbox_mode\", BoxMode.XYXY_ABS))\n        annotation[\"bbox\"] = bbox\n\n    # Transform segmentation\n    if \"segmentation\" in annotation:\n        if annotation[\"segmentation\"] is None:\n            annotation[\"segmentation\"] = []\n        else:\n            if annotation.get(\"segmentation_mode\", \"poly\") == \"poly\":\n                # Transform segmentation polygons\n                segmentation = annotation[\"segmentation\"]\n                if isinstance(segmentation, dict):\n                    segmentation = mask_util.decode(segmentation)\n                polygons = [p for p in segmentation if len(p) >= 6]\n                polygons = transforms.apply_polygons(polygons)\n                annotation[\"segmentation\"] = polygons\n            elif annotation[\"segmentation_mode\"] == \"compressed\":\n                # Transform RLE\n                rle = mask_util.frPyObjects(annotation[\"segmentation\"], image_size[0], image_size[1])\n                rle = transforms.apply_segmentation(rle)\n                rle = mask_util.merge(rle)\n                annotation[\"segmentation\"] = mask_util.frPyObjects(rle, image_size[0], image_size[1])\n\n    # Transform keypoints\n    if \"keypoints\" in annotation:\n        keypoints = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints.tolist()\n\n    # Set bbox_mode to XYXY_ABS\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "\n    # Transform bounding box\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    bbox = list(bbox)\n    bbox = transforms.apply_box([bbox])[0]\n    bbox = BoxMode.convert(bbox, BoxMode.XYXY_ABS, annotation[\"bbox_mode\"])\n    annotation[\"bbox\"] = bbox\n\n    # Transform segmentation\n    if \"segmentation\" in annotation:\n        if annotation[\"segmentation\"] is None:\n            return annotation\n        if annotation[\"segmentation\"][\"mode\"] == \"poly\":\n            segmentation = annotation[\"segmentation\"][\"polygons\"]\n            segmentation = [transforms.apply_polygons([s])[0] for s in segmentation]\n            annotation[\"segmentation\"][\"polygons\"] = segmentation\n        elif annotation[\"segmentation\"][\"mode\"] == \"mask\":\n            mask = annotation[\"segmentation\"][\"mask\"]\n            mask = transforms.apply_segmentation(mask)\n            annotation[\"segmentation\"][\"mask\"] = mask\n\n    # Transform keypoints\n    if \"keypoints\" in annotation:\n        keypoints = annotation[\"keypoints\"]\n        keypoints = transform_keypoint_annotations(\n            keypoints, transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Transform bounding box\n    if \"bbox\" in annotation:\n        bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n        bbox = transforms.apply_box([bbox])[0]\n        bbox = BoxMode.convert(bbox, BoxMode.XYXY_ABS, annotation[\"bbox_mode\"])\n        annotation[\"bbox\"] = bbox\n\n    # Transform segmentation\n    if \"segmentation\" in annotation:\n        if annotation[\"segmentation\"] is None:\n            return annotation\n        if isinstance(annotation[\"segmentation\"], list):\n            # Polygon format\n            segmentation = [transforms.apply_polygons(s) for s in annotation[\"segmentation\"]]\n        else:\n            # RLE format\n            segmentation = annotation[\"segmentation\"]\n            if isinstance(segmentation, dict):\n                segmentation[\"counts\"] = transforms.apply_segmentation(segmentation[\"counts\"])\n        annotation[\"segmentation\"] = segmentation\n\n    # Transform keypoints\n    if \"keypoints\" in annotation:\n        annotation[\"keypoints\"] = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n        )\n\n    return annotation"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        # Apply the rotation matrix to the coordinates\n        new_coords = np.dot(coords, self.rm_coords[:, :2].T) + self.rm_coords[:, 2]\n        return new_coords"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        # Apply the rotation matrix to the coordinates\n        new_coords = np.dot(coords, self.rm_coords.T)\n        return new_coords"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        # Transform the coordinates using the rotation matrix\n        coords = np.dot(coords - self.center, self.rm_coords.T) + self.center\n        return coords"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        new_coords = np.column_stack((coords, np.ones(coords.shape[0])))\n        new_coords = np.dot(new_coords, self.rm_coords.T)\n        return new_coords[:, :2]"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        new_coords = np.hstack([coords, np.ones((len(coords), 1))])\n        new_coords = np.dot(new_coords, self.rm_coords.T)\n        return new_coords[:, :2]"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        new_coords = np.column_stack((coords, np.ones(coords.shape[0])))\n        new_coords = np.dot(new_coords, self.rm_coords.T)\n        return new_coords[:, :2]"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        new_coords = np.column_stack((coords, np.ones(len(coords))))\n        new_coords = np.dot(new_coords, self.rm_coords.T)\n        return new_coords[:, :2]"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords  # Return original coordinates if empty or angle is a multiple of 360 degrees\n        coords = np.dot(coords - self.center, self.rm_coords[:, :2].T) + self.center\n        return coords"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n\n        # Apply rotation matrix to each coordinate\n        new_coords = np.dot(coords - self.center, self.rm_coords.T) + self.center\n        return new_coords"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        # Apply the rotation matrix to the coordinates\n        new_coords = np.dot(coords, self.rm_coords[:, :2].T) + self.rm_coords[:, 2]\n        return new_coords"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        new_coords = np.column_stack((coords, np.ones(len(coords))))\n        new_coords = new_coords @ self.rm_coords.T\n        return new_coords[:, :2]"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        new_coords = np.column_stack((coords, np.ones(coords.shape[0])))  # add 1 to each coordinate\n        new_coords = np.dot(new_coords, self.rm_coords.T)  # apply rotation matrix\n        return new_coords[:, :2]  # remove the added 1 and return only (x, y) coordinates"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        new_coords = np.hstack([coords, np.ones((len(coords), 1))])\n        new_coords = np.dot(new_coords, self.rm_coords.T)\n        return new_coords[:, :2]"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        new_coords = np.column_stack((coords, np.ones(coords.shape[0])))\n        new_coords = np.dot(new_coords, self.rm_coords.T)\n        return new_coords[:, :2]"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        new_coords = np.hstack([coords, np.ones((len(coords), 1))])\n        new_coords = np.dot(new_coords, self.rm_coords.T)\n        return new_coords[:, :2]"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        new_coords = np.column_stack((coords, np.ones(len(coords))))\n        new_coords = np.dot(new_coords, self.rm_coords.T)\n        return new_coords[:, :2]"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        # Transform coordinates using the rotation matrix\n        rotation_center = np.array([self.w / 2, self.h / 2])\n        new_coords = coords - rotation_center\n        new_coords = np.hstack((new_coords, np.ones((len(new_coords), 1), dtype=new_coords.dtype)))\n        new_coords = np.dot(new_coords, self.rm_coords.T)\n        return new_coords[:, :2]"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        new_coords = np.dot(coords, self.rm_coords.T)\n        return new_coords"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        coords = np.asarray(coords)\n        coords = np.hstack((coords, np.ones((len(coords), 1), dtype=coords.dtype)))  # Convert to homogeneous coordinates\n        coords = np.dot(coords, self.rm_coords.T)  # Apply rotation matrix\n        coords = coords[:, :2]  # Convert back to non-homogeneous coordinates\n        return coords"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        new_coords = np.column_stack((coords, np.ones(coords.shape[0])))\n        new_coords = np.dot(new_coords, self.rm_coords.T)\n        return new_coords[:, :2]"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [obj[\"bbox\"] for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if \"segmentation\" in annos[0]:\n        if mask_format == \"polygon\":\n            masks = [obj[\"segmentation\"] for obj in annos]\n            masks = [polygon_to_bitmask(p, target.gt_boxes.tensor.size(1), target.gt_boxes.tensor.size(0)) for p in masks]\n            target.gt_masks = BitMasks(masks)\n        elif mask_format == \"bitmask\":\n            masks = [obj[\"segmentation\"] for obj in annos]\n            target.gt_masks = BitMasks(masks)\n\n    if \"keypoints\" in annos[0]:\n        keypoints = [obj[\"keypoints\"] for obj in annos]\n        target.gt_keypoints = Keypoints(keypoints)\n\n    return target"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [obj[\"bbox\"] for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if \"segmentation\" in annos[0]:\n        if mask_format == \"polygon\":\n            masks = [obj[\"segmentation\"] for obj in annos]\n            masks = [polygon_to_bitmask(polygon, target.gt_boxes.tensor.size(1), target.gt_boxes.tensor.size(0)) for polygon in masks]\n            target.gt_masks = BitMasks(masks)\n        elif mask_format == \"bitmask\":\n            masks = [obj[\"segmentation\"] for obj in annos]\n            target.gt_masks = BitMasks(masks)\n\n    if \"keypoints\" in annos[0]:\n        keypoints = [obj[\"keypoints\"] for obj in annos]\n        target.gt_keypoints = Keypoints(keypoints)\n\n    return target"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [obj[\"bbox\"] for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if \"segmentation\" in annos[0]:\n        if mask_format == \"polygon\":\n            masks = [obj[\"segmentation\"] for obj in annos]\n            masks = [PolygonMasks(m, *image_size) for m in masks]\n            target.gt_masks = masks\n        elif mask_format == \"bitmask\":\n            masks = [obj[\"segmentation\"] for obj in annos]\n            masks = [polygons_to_bitmask(m, *image_size) for m in masks]\n            masks = torch.as_tensor(masks, dtype=torch.uint8)\n            target.gt_masks = BitMasks(masks)\n\n    if \"keypoints\" in annos[0]:\n        keypoints = [obj[\"keypoints\"] for obj in annos]\n        keypoints = [Keypoints(k, *image_size) for k in keypoints]\n        target.gt_keypoints = keypoints\n\n    return target"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    # Initialize empty lists to store annotations\n    boxes = []\n    classes = []\n    masks = []\n    keypoints = []\n\n    # Iterate through each instance annotation\n    for anno in annos:\n        # Extract bounding box coordinates\n        bbox = anno[\"bbox\"]\n        bbox_mode = anno.get(\"bbox_mode\", BoxMode.XYXY_ABS)\n        bbox = BoxMode.convert(bbox, bbox_mode, BoxMode.XYXY_ABS)\n        boxes.append(bbox)\n\n        # Extract class label\n        classes.append(anno[\"category_id\"])\n\n        # Extract segmentation masks based on the specified mask format\n        if mask_format == \"polygon\":\n            masks.append(anno.get(\"segmentation\", []))\n        elif mask_format == \"bitmask\":\n            mask = mask_util.decode(anno[\"segmentation\"])\n            masks.append(mask)\n\n        # Extract keypoints\n        if \"keypoints\" in anno:\n            keypoints.append(anno[\"keypoints\"])\n\n    # Create an Instances object and populate it with the extracted annotations\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes)\n    target.gt_classes = torch.tensor(classes, dtype=torch.int64)\n    if masks:\n        target.gt_masks = PolygonMasks(masks) if mask_format == \"polygon\" else BitMasks(masks)\n    if keypoints:\n        target.gt_keypoints = Keypoints(keypoints)\n\n    return target"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [obj[\"bbox\"] for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if \"segmentation\" in annos[0]:\n        if mask_format == \"polygon\":\n            masks = [obj[\"segmentation\"] for obj in annos]\n            masks = [polygon_to_bitmask(p, target.image_size[0], target.image_size[1]) for p in masks]\n            target.gt_masks = BitMasks(masks)\n        elif mask_format == \"bitmask\":\n            masks = [obj[\"segmentation\"] for obj in annos]\n            target.gt_masks = BitMasks(masks)\n\n    if \"keypoints\" in annos[0]:\n        keypoints = [obj[\"keypoints\"] for obj in annos]\n        target.gt_keypoints = Keypoints(keypoints)\n\n    return target"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    # Process annotations based on the mask format\n    if mask_format == \"polygon\":\n        # Process annotations for polygon masks\n        polygons = [obj[\"segmentation\"] for obj in annos]\n        masks = [polygons_to_bitmask(p, image_size[0], image_size[1]) for p in polygons]\n        masks = BitMasks(masks, image_size[0], image_size[1])\n    elif mask_format == \"bitmask\":\n        # Process annotations for bitmask masks\n        masks = [obj[\"segmentation\"] for obj in annos]\n        masks = BitMasks(masks, image_size[0], image_size[1])\n\n    # Create an Instances object and populate it with annotations\n    target = Instances(image_size)\n    target.gt_boxes = Boxes([obj[\"bbox\"] for obj in annos])\n    target.gt_classes = torch.tensor([obj[\"category_id\"] for obj in annos], dtype=torch.int64)\n    target.gt_masks = masks\n\n    # Check for keypoints in the annotations and process them if present\n    if \"keypoints\" in annos[0]:\n        keypoints = [obj[\"keypoints\"] for obj in annos]\n        target.gt_keypoints = Keypoints(keypoints, image_size)\n\n    return target"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [obj[\"bbox\"] for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if \"segmentation\" in annos[0]:\n        if mask_format == \"polygon\":\n            masks = [obj[\"segmentation\"] for obj in annos]\n            masks = [polygons_to_bitmask(p, *image_size) for p in masks]\n            target.gt_masks = BitMasks(masks)\n        elif mask_format == \"bitmask\":\n            masks = [obj[\"segmentation\"] for obj in annos]\n            target.gt_masks = BitMasks(masks)\n\n    if \"keypoints\" in annos[0]:\n        keypoints = [obj[\"keypoints\"] for obj in annos]\n        target.gt_keypoints = Keypoints(keypoints)\n\n    return target"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [obj[\"bbox\"] for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if \"segmentation\" in annos[0]:\n        if mask_format == \"polygon\":\n            masks = [obj[\"segmentation\"] for obj in annos]\n            masks = [np.asarray(mask, dtype=np.float32).reshape(-1, 2) for mask in masks]\n            masks = [PolygonMasks([mask]) for mask in masks]\n            target.gt_masks = masks\n        elif mask_format == \"bitmask\":\n            masks = [obj[\"segmentation\"] for obj in annos]\n            masks = [mask_util.decode(mask) for mask in masks]\n            masks = [torch.as_tensor(mask, dtype=torch.uint8) for mask in masks]\n            target.gt_masks = BitMasks(masks)\n\n    if \"keypoints\" in annos[0]:\n        keypoints = [obj[\"keypoints\"] for obj in annos]\n        keypoints = [torch.as_tensor(keypoint, dtype=torch.float32) for keypoint in keypoints]\n        target.gt_keypoints = Keypoints(keypoints)\n\n    return target"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [obj[\"bbox\"] for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if \"segmentation\" in annos[0]:\n        if mask_format == \"polygon\":\n            masks = [obj[\"segmentation\"] for obj in annos]\n            masks = [polygon_to_bitmask(p, target.image_size[0], target.image_size[1]) for p in masks]\n            masks = BitMasks(masks, target.image_size[0], target.image_size[1])\n        elif mask_format == \"bitmask\":\n            masks = [obj[\"segmentation\"] for obj in annos]\n            masks = BitMasks(masks, target.image_size[0], target.image_size[1])\n        target.gt_masks = masks\n\n    if \"keypoints\" in annos[0]:\n        keypoints = [obj[\"keypoints\"] for obj in annos]\n        keypoints = Keypoints(keypoints, target.image_size)\n        target.gt_keypoints = keypoints\n\n    return target"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [obj[\"bbox\"] for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if \"segmentation\" in annos[0]:\n        segmentations = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            polygons = [list(map(float, seg)) for seg in segmentations]\n            masks = polygons_to_bitmask(polygons, *image_size)\n            target.gt_masks = BitMasks(masks)\n        elif mask_format == \"bitmask\":\n            masks = [mask_util.decode(seg) for seg in segmentations]\n            masks = [mask for mask in masks if len(mask) > 0]\n            target.gt_masks = BitMasks(masks)\n\n    if \"keypoints\" in annos[0]:\n        keypoints = [obj[\"keypoints\"] for obj in annos]\n        target.gt_keypoints = Keypoints(keypoints, image_size)\n\n    return target"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [obj[\"bbox\"] for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if \"segmentation\" in annos[0]:\n        if mask_format == \"polygon\":\n            masks = [obj[\"segmentation\"] for obj in annos]\n            masks = [np.asarray(m, dtype=np.float32).reshape(-1, 2) for m in masks]\n            masks = [PolygonMasks([m]) for m in masks]\n            target.gt_masks = masks\n        elif mask_format == \"bitmask\":\n            masks = [obj[\"segmentation\"] for obj in annos]\n            masks = [mask_util.decode(m) for m in masks]\n            masks = [torch.as_tensor(m, dtype=torch.uint8) for m in masks]\n            target.gt_masks = BitMasks(masks)\n\n    if \"keypoints\" in annos[0]:\n        keypoints = [obj[\"keypoints\"] for obj in annos]\n        keypoints = [torch.as_tensor(k, dtype=torch.float32) for k in keypoints]\n        num_keypoints = keypoints[0].shape[0] // 3\n        keypoints = [k.view(-1, 3) if k.numel() else k for k in keypoints]\n        target.gt_keypoints = Keypoints(keypoints, target.gt_boxes, num_keypoints)\n\n    return target"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [obj[\"bbox\"] for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if \"segmentation\" in annos[0]:\n        if mask_format == \"polygon\":\n            masks = [obj[\"segmentation\"] for obj in annos]\n            masks = [np.asarray(x).reshape(-1, 2) for x in masks]\n            masks = [PolygonMasks([x], *image_size) for x in masks]\n            target.gt_masks = masks\n        elif mask_format == \"bitmask\":\n            masks = [obj[\"segmentation\"] for obj in annos]\n            masks = [mask_util.decode(x) for x in masks]\n            masks = [torch.as_tensor(x, dtype=torch.uint8) for x in masks]\n            target.gt_masks = BitMasks(masks)\n\n    if \"keypoints\" in annos[0]:\n        keypoints = [obj[\"keypoints\"] for obj in annos]\n        keypoints = [torch.as_tensor(x, dtype=torch.float32) for x in keypoints]\n        target.gt_keypoints = Keypoints(keypoints, *image_size)\n\n    return target"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [obj[\"bbox\"] for obj in annos]\n    target = Instances(image_size)\n\n    # Convert bounding boxes to the Instances object\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    # Extract class labels from the annotations\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    # Process segmentation masks based on the specified format\n    if mask_format == \"polygon\":\n        # Convert segmentation polygons to bitmasks\n        segmentations = [obj[\"segmentation\"] for obj in annos]\n        masks = [np.asarray(polygons_to_bitmask(seg, *image_size)) for seg in segmentations]\n        masks = torch.as_tensor(masks)\n        target.gt_masks = BitMasks(masks)\n    elif mask_format == \"bitmask\":\n        # Convert bitmask masks directly\n        masks = [obj[\"segmentation\"] for obj in annos]\n        masks = torch.as_tensor(masks)\n        target.gt_masks = BitMasks(masks)\n\n    # Process keypoints, if available\n    if \"keypoints\" in annos[0]:\n        keypoints = [obj[\"keypoints\"] for obj in annos]\n        keypoints = torch.as_tensor(keypoints)\n        target.gt_keypoints = Keypoints(keypoints, image_size)\n\n    return target"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [obj[\"bbox\"] for obj in annos]\n    target = Instances(image_size)\n\n    # Convert bounding boxes to the RotatedBoxes format\n    boxes = target.gt_boxes = RotatedBoxes(boxes)\n    boxes.clip(image_size)\n\n    # Extract class labels from the annotations\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if mask_format == \"polygon\":\n        # Process segmentation masks as polygons\n        polygons = [obj[\"segmentation\"] for obj in annos]\n        polygons = [np.asarray(p).reshape(-1, 2) for p in polygons]\n        target.gt_masks = PolygonMasks(polygons, *image_size)\n\n    elif mask_format == \"bitmask\":\n        # Process segmentation masks as bitmasks\n        masks = [obj[\"segmentation\"] for obj in annos]\n        masks = [mask_util.decode(seg) for seg in masks]\n        masks = [transforms.apply_segmentation(mask) for mask in masks]\n        masks = [mask.astype(\"bool\") for mask in masks]\n        target.gt_masks = BitMasks(masks)\n\n    if \"keypoints\" in annos[0]:\n        # Process keypoints if available\n        keypoints = [obj[\"keypoints\"] for obj in annos]\n        keypoints = [np.asarray(k).reshape(-1, 3) for k in keypoints]\n        target.gt_keypoints = Keypoints(keypoints, *image_size)\n\n    return target"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    if mask_format == \"polygon\":\n        # Process annotations for polygon masks\n        # ... (code to process polygon masks)\n    elif mask_format == \"bitmask\":\n        # Process annotations for bitmask masks\n        # ... (code to process bitmask masks)\n    else:\n        raise ValueError(\"Unsupported mask format: {}\".format(mask_format))"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [obj[\"bbox\"] for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if \"segmentation\" in annos[0]:\n        segmentations = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = [polygon_to_bitmask(polygon, *image_size) for polygon in segmentations]\n        elif mask_format == \"bitmask\":\n            masks = [mask_util.decode(obj[\"segmentation\"]) for obj in annos]\n        else:\n            raise ValueError(\"Invalid mask format: {}\".format(mask_format))\n        masks = BitMasks(masks, *image_size)\n        target.gt_masks = masks\n\n    if \"keypoints\" in annos[0]:\n        keypoints = [obj[\"keypoints\"] for obj in annos]\n        target.gt_keypoints = Keypoints(keypoints, *image_size)\n\n    return target"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [obj[\"bbox\"] for obj in annos]\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes)\n    \n    classes = [obj[\"category_id\"] for obj in annos]\n    target.gt_classes = torch.tensor(classes, dtype=torch.int64)\n    \n    if \"segmentation\" in annos[0]:\n        if mask_format == \"polygon\":\n            masks = [obj[\"segmentation\"] for obj in annos]\n            masks = [polygon_to_bitmask(polygon, target.image_size[0], target.image_size[1]) for polygon in masks]\n            target.gt_masks = BitMasks(masks)\n        elif mask_format == \"bitmask\":\n            masks = [obj[\"segmentation\"] for obj in annos]\n            target.gt_masks = BitMasks(masks)\n    \n    if \"keypoints\" in annos[0]:\n        keypoints = [obj[\"keypoints\"] for obj in annos]\n        target.gt_keypoints = Keypoints(keypoints, target.image_size)\n    \n    return target"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [obj[\"bbox\"] for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if \"segmentation\" in annos[0]:\n        if mask_format == \"polygon\":\n            masks = [obj[\"segmentation\"] for obj in annos]\n            masks = [np.asarray(m, dtype=np.float32).reshape(-1, 2) for m in masks]\n            masks = [PolygonMasks([m]) for m in masks]\n        elif mask_format == \"bitmask\":\n            masks = [mask_util.decode(obj[\"segmentation\"]) for obj in annos]\n            masks = [BitMasks(m) for m in masks]\n        else:\n            raise ValueError(\"Invalid mask format. Supported formats are 'polygon' and 'bitmask'.\")\n        target.gt_masks = masks\n\n    if \"keypoints\" in annos[0]:\n        keypoints = [obj[\"keypoints\"] for obj in annos]\n        keypoints = [np.asarray(k, dtype=np.float32).reshape(-1, 3) for k in keypoints]\n        target.gt_keypoints = Keypoints(keypoints)\n\n    return target"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [obj[\"bbox\"] for obj in annos]\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes)\n    \n    classes = [obj[\"category_id\"] for obj in annos]\n    target.gt_classes = torch.tensor(classes, dtype=torch.int64)\n    \n    if \"segmentation\" in annos[0]:\n        if mask_format == \"polygon\":\n            masks = [obj[\"segmentation\"] for obj in annos]\n            masks = [polygons_to_bitmask(p, target.gt_boxes.tensor.size(1), target.gt_boxes.tensor.size(0)) for p in masks]\n            target.gt_masks = BitMasks(masks)\n        elif mask_format == \"bitmask\":\n            masks = [obj[\"segmentation\"] for obj in annos]\n            target.gt_masks = BitMasks(masks)\n    \n    if \"keypoints\" in annos[0]:\n        keypoints = [obj[\"keypoints\"] for obj in annos]\n        target.gt_keypoints = Keypoints(keypoints, target.gt_boxes.tensor.size(1), target.gt_boxes.tensor.size(0))\n    \n    return target"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    if mask_format == \"polygon\":\n        # Process annotations for polygon masks\n        polygons = [obj[\"segmentation\"] for obj in annos]\n        polygons = [polygons_to_bitmask(p, image_size[0], image_size[1]) for p in polygons]\n        masks = PolygonMasks(polygons, image_size[0], image_size[1])\n    elif mask_format == \"bitmask\":\n        # Process annotations for bitmask masks\n        masks = [obj[\"segmentation\"] for obj in annos]\n        masks = BitMasks(masks, image_size[0], image_size[1])\n\n    boxes = [obj[\"bbox\"] for obj in annos]\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes)\n    target.gt_classes = torch.tensor([obj[\"category_id\"] for obj in annos], dtype=torch.int64)\n    target.gt_masks = masks\n\n    if \"keypoints\" in annos[0]:\n        keypoints = [obj[\"keypoints\"] for obj in annos]\n        target.gt_keypoints = Keypoints(keypoints, image_size)\n\n    return target"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    return _wrapper_count_operators(model=model, inputs=inputs, mode=FLOPS_MODE)"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    return _wrapper_count_operators(model=model, inputs=inputs, mode=FLOPS_MODE)"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    return _wrapper_count_operators(model=model, inputs=inputs, mode=FLOPS_MODE)"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "\n    return _wrapper_count_operators(model=model, inputs=inputs, mode=FLOPS_MODE)"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    return _wrapper_count_operators(model=model, inputs=inputs, mode=FLOPS_MODE)"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    return _wrapper_count_operators(model=model, inputs=inputs, mode=FLOPS_MODE)"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    return _wrapper_count_operators(model=model, inputs=inputs, mode=FLOPS_MODE)"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    return _wrapper_count_operators(model=model, inputs=inputs, mode=FLOPS_MODE)"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    return _wrapper_count_operators(model=model, inputs=inputs, mode=FLOPS_MODE)"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    return _wrapper_count_operators(model=model, inputs=inputs, mode=FLOPS_MODE)"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    return _wrapper_count_operators(model=model, inputs=inputs, mode=FLOPS_MODE)"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    return _wrapper_count_operators(model=model, inputs=inputs, mode=FLOPS_MODE)"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    return _wrapper_count_operators(model=model, inputs=inputs, mode=FLOPS_MODE)"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    return _wrapper_count_operators(model=model, inputs=inputs, mode=FLOPS_MODE)"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    return _wrapper_count_operators(model=model, inputs=inputs, mode=FLOPS_MODE)"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    return _wrapper_count_operators(model=model, inputs=inputs, mode=FLOPS_MODE)"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    return _wrapper_count_operators(model=model, inputs=inputs, mode=FLOPS_MODE)"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    return _wrapper_count_operators(model=model, inputs=inputs, mode=FLOPS_MODE)"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    return _wrapper_count_operators(model=model, inputs=inputs, mode=FLOPS_MODE)"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    return _wrapper_count_operators(model=model, inputs=inputs, mode=FLOPS_MODE)"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        h, w = self.h, self.w\n        angle = self.angle\n        expand = self.expand\n        interp = self.interp\n\n        if len(img) == 0 or angle % 360 == 0:\n            return img\n\n        if interp is None:\n            interp = cv2.INTER_LINEAR\n\n        if expand:\n            bound_w, bound_h = np.rint([h * abs(np.sin(np.deg2rad(angle))) + w * abs(np.cos(np.deg2rad(angle))),\n                                        h * abs(np.cos(np.deg2rad(angle))) + w * abs(np.sin(np.deg2rad(angle)))]).astype(int)\n        else:\n            bound_w, bound_h = w, h\n\n        image_center = np.array((w / 2, h / 2))\n        center = self.center if self.center is not None else image_center\n\n        rm_coords = cv2.getRotationMatrix2D(tuple(center), angle, 1)\n        rm_image = cv2.getRotationMatrix2D(tuple(center), angle, 1)\n\n        if expand:\n            rot_im_center = cv2.transform(np.array([image_center]), rm_coords)[0, 0, :]\n            new_center = np.array([bound_w / 2, bound_h / 2]) - rot_im_center\n            rm_coords[:, 2] += new_center\n\n        return cv2.warpAffine(img, rm_image, (bound_w, bound_h), flags=interp)"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        h, w = self.h, self.w\n        angle = self.angle\n        expand = self.expand\n        center = self.center\n        interp = self.interp\n\n        if len(img) == 0 or angle % 360 == 0:\n            return img\n\n        if interp is None:\n            interp = cv2.INTER_LINEAR\n\n        if expand:\n            bound_w, bound_h = np.rint([h * abs(np.sin(np.deg2rad(angle))) + w * abs(np.cos(np.deg2rad(angle))),\n                                        h * abs(np.cos(np.deg2rad(angle))) + w * abs(np.sin(np.deg2rad(angle)))]).astype(int)\n        else:\n            bound_w, bound_h = w, h\n\n        image_center = np.array([w / 2, h / 2])\n        if center is None:\n            center = image_center\n\n        rm_coords = cv2.getRotationMatrix2D(tuple(center), angle, 1)\n\n        if expand:\n            rot_im_center = cv2.transform(np.array([image_center]), rm_coords)[0, 0, :]\n            new_center = np.array([bound_w / 2, bound_h / 2]) - rot_im_center\n            rm_coords[:, 2] += new_center\n\n        if len(img.shape) > 2 and img.shape[2] == 1:\n            img = img[:, :, 0]\n\n        rotated_img = cv2.warpAffine(img, rm_coords, (bound_w, bound_h), flags=interp)\n\n        if len(img.shape) > 2 and img.shape[2] == 1:\n            rotated_img = np.expand_dims(rotated_img, -1)\n\n        return rotated_img"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        h, w = self.h, self.w\n        angle = self.angle\n        expand = self.expand\n        interp = interp if interp is not None else self.interp\n\n        if len(img) == 0 or angle % 360 == 0:\n            return img\n\n        if img.dtype == np.uint8:\n            if len(img.shape) > 2 and img.shape[2] == 1:\n                pil_image = Image.fromarray(img[:, :, 0], mode=\"L\")\n            else:\n                pil_image = Image.fromarray(img)\n            pil_image = pil_image.rotate(angle, resample=interp, expand=expand, center=self.center)\n            ret = np.asarray(pil_image)\n            if len(img.shape) > 2 and img.shape[2] == 1:\n                ret = np.expand_dims(ret, -1)\n        else:\n            # PIL only supports uint8\n            if any(x < 0 for x in img.strides):\n                img = np.ascontiguousarray(img)\n            img = torch.from_numpy(img)\n            shape = list(img.shape)\n            shape_4d = shape[:2] + [1] * (4 - len(shape)) + shape[2:]\n            img = img.view(shape_4d).permute(2, 3, 0, 1)  # hw(c) -> nchw\n            mode = \"bilinear\" if interp == Image.BILINEAR else \"nearest\"\n            align_corners = None if mode == \"nearest\" else False\n            img = F.interpolate(\n                img, (self.bound_h, self.bound_w), mode=mode, align_corners=align_corners\n            )\n            shape[:2] = (self.bound_h, self.bound_w)\n            ret = img.permute(2, 3, 0, 1).view(shape).numpy()  # nchw -> hw(c)\n\n        return ret"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        h, w = self.h, self.w\n        angle = self.angle\n        expand = self.expand\n        center = self.center\n        interp = self.interp\n\n        if len(img) == 0 or angle % 360 == 0:\n            return img\n\n        if interp is None:\n            interp = cv2.INTER_LINEAR\n\n        if expand:\n            bound_w, bound_h = np.rint([h * abs(np.sin(np.deg2rad(angle))) + w * abs(np.cos(np.deg2rad(angle))),\n                                        h * abs(np.cos(np.deg2rad(angle))) + w * abs(np.sin(np.deg2rad(angle)))]).astype(int)\n        else:\n            bound_w, bound_h = w, h\n\n        image_center = np.array((w / 2, h / 2))\n        if center is None:\n            center = image_center\n\n        rm_coords = cv2.getRotationMatrix2D(tuple(center), angle, 1)\n\n        if expand:\n            rot_im_center = cv2.transform(np.array([image_center]), rm_coords)[0, 0, :]\n            new_center = np.array([bound_w / 2, bound_h / 2]) - rot_im_center\n            rm_coords[:, 2] += new_center\n\n        ret = cv2.warpAffine(img, rm_coords, (bound_w, bound_h), flags=interp)\n\n        return ret"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        h, w = self.h, self.w\n        angle = self.angle\n        expand = self.expand\n        center = self.center\n        interp = self.interp\n\n        if len(img) == 0 or angle % 360 == 0:\n            return img\n\n        if interp is None:\n            interp = cv2.INTER_LINEAR\n\n        if expand:\n            bound_w, bound_h = np.rint([h * abs(np.sin(np.deg2rad(angle))) + w * abs(np.cos(np.deg2rad(angle))), h * abs(np.cos(np.deg2rad(angle))) + w * abs(np.sin(np.deg2rad(angle)))]).astype(int)\n        else:\n            bound_w, bound_h = w, h\n\n        image_center = np.array((w / 2, h / 2))\n        if center is None:\n            center = image_center\n\n        rm_coords = cv2.getRotationMatrix2D(tuple(center), angle, 1)\n\n        if expand:\n            rot_im_center = cv2.transform(image_center[None, None, :], rm_coords)[0, 0, :]\n            new_center = np.array([bound_w / 2, bound_h / 2]) - rot_im_center\n            rm_coords[:, 2] += new_center\n\n        ret = cv2.warpAffine(img, rm_coords, (bound_w, bound_h), flags=interp)\n\n        return ret"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        h, w = self.h, self.w\n        angle = self.angle\n        if len(img) == 0 or angle % 360 == 0:\n            return img\n        if interp is None:\n            interp = self.interp\n        return cv2.warpAffine(img, self.rm_image, (self.bound_w, self.bound_h), flags=interp)"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        h, w = self.h, self.w\n        angle = self.angle\n        expand = self.expand\n        center = self.center\n        interp = self.interp\n\n        if len(img) == 0 or angle % 360 == 0:\n            return img\n\n        if interp is None:\n            interp = cv2.INTER_LINEAR\n\n        if expand:\n            bound_w, bound_h = np.rint([h * abs(np.sin(np.deg2rad(angle))) + w * abs(np.cos(np.deg2rad(angle))), h * abs(np.cos(np.deg2rad(angle))) + w * abs(np.sin(np.deg2rad(angle)))]).astype(int)\n        else:\n            bound_w, bound_h = w, h\n\n        image_center = np.array((w / 2, h / 2))\n        if center is None:\n            center = image_center\n\n        rm_coords = cv2.getRotationMatrix2D(tuple(center), angle, 1)\n        rm_image = cv2.getRotationMatrix2D(tuple(center), angle, 1)\n\n        if expand:\n            rot_im_center = cv2.transform(np.array([image_center]), rm_coords)[0, 0, :]\n            new_center = np.array([bound_w / 2, bound_h / 2]) - rot_im_center\n            rm_coords[:, 2] += new_center\n\n        return cv2.warpAffine(img, rm_image, (bound_w, bound_h), flags=interp)"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        h, w = self.h, self.w\n        angle = self.angle\n        if len(img) == 0 or angle % 360 == 0:\n            return img\n        if interp is None:\n            interp = self.interp\n        return cv2.warpAffine(img, self.rm_image, (self.bound_w, self.bound_h), flags=interp)"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        h, w = self.h, self.w\n        angle = self.angle\n        expand = self.expand\n        interp = interp if interp is not None else self.interp\n\n        if len(img) == 0 or angle % 360 == 0:\n            return img\n\n        if img.dtype == np.uint8:\n            if len(img.shape) > 2 and img.shape[2] == 1:\n                pil_image = Image.fromarray(img[:, :, 0], mode=\"L\")\n            else:\n                pil_image = Image.fromarray(img)\n            pil_image = pil_image.rotate(angle, expand=expand, resample=interp, center=self.center)\n            ret = np.asarray(pil_image)\n            if len(img.shape) > 2 and img.shape[2] == 1:\n                ret = np.expand_dims(ret, -1)\n        else:\n            # PIL only supports uint8\n            if any(x < 0 for x in img.strides):\n                img = np.ascontiguousarray(img)\n            img = torch.from_numpy(img)\n            shape = list(img.shape)\n            shape_4d = shape[:2] + [1] * (4 - len(shape)) + shape[2:]\n            img = img.view(shape_4d).permute(2, 3, 0, 1)  # hw(c) -> nchw\n            mode = \"bilinear\" if interp == Image.BILINEAR else \"nearest\"\n            align_corners = None if mode == \"nearest\" else False\n            img = F.interpolate(\n                img, (self.bound_h, self.bound_w), mode=mode, align_corners=align_corners\n            )\n            shape[:2] = (self.bound_h, self.bound_w)\n            ret = img.permute(2, 3, 0, 1).view(shape).numpy()  # nchw -> hw(c)\n\n        return ret"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "    if len(img) == 0 or self.angle % 360 == 0:\n        return img\n    interp_method = interp if interp is not None else self.interp\n    return cv2.warpAffine(img, self.rm_image, (self.bound_w, self.bound_h), flags=interp_method)"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        assert img.shape[:2] == (self.h, self.w)\n        assert len(img.shape) <= 4\n        interp_method = interp if interp is not None else self.interp\n\n        if img.dtype == np.uint8:\n            if len(img.shape) > 2 and img.shape[2] == 1:\n                pil_image = Image.fromarray(img[:, :, 0], mode=\"L\")\n            else:\n                pil_image = Image.fromarray(img)\n            pil_image = pil_image.rotate(self.angle, resample=interp_method, expand=self.expand)\n            ret = np.asarray(pil_image)\n            if len(img.shape) > 2 and img.shape[2] == 1:\n                ret = np.expand_dims(ret, -1)\n        else:\n            # OpenCV warpAffine\n            M = self.rm_image[:, :2]\n            if self.expand:\n                ret = cv2.warpAffine(img, M, (self.bound_w, self.bound_h), flags=cv2.INTER_LINEAR)\n            else:\n                ret = cv2.warpAffine(img, M, (self.w, self.h), flags=cv2.INTER_LINEAR)\n\n        return ret"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        h, w = self.h, self.w\n        angle = self.angle\n        expand = self.expand\n        center = self.center\n        interp = self.interp\n\n        if len(img) == 0 or angle % 360 == 0:\n            return img\n\n        if interp is None:\n            interp = cv2.INTER_LINEAR\n\n        if expand:\n            bound_w, bound_h = np.rint([h * abs(np.sin(np.deg2rad(angle))) + w * abs(np.cos(np.deg2rad(angle))), h * abs(np.cos(np.deg2rad(angle))) + w * abs(np.sin(np.deg2rad(angle)))]).astype(int)\n        else:\n            bound_w, bound_h = w, h\n\n        image_center = np.array((w / 2, h / 2))\n        if center is None:\n            center = image_center\n\n        rm_coords = cv2.getRotationMatrix2D(tuple(center), angle, 1)\n        if expand:\n            rot_im_center = cv2.transform(image_center[None, None, :], rm_coords)[0, 0, :]\n            new_center = np.array([bound_w / 2, bound_h / 2]) - rot_im_center\n            rm_coords[:, 2] += new_center\n\n        if len(img.shape) == 3:\n            return cv2.warpAffine(img, rm_coords, (bound_w, bound_h), flags=interp)\n        else:\n            ret = np.zeros((bound_h, bound_w, img.shape[2]), dtype=img.dtype)\n            for i in range(img.shape[2]):\n                ret[:, :, i] = cv2.warpAffine(img[:, :, i], rm_coords, (bound_w, bound_h), flags=interp)\n            return ret"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        h, w = self.h, self.w\n        angle = self.angle\n        expand = self.expand\n        center = self.center\n        interp = self.interp\n\n        if len(img) == 0 or angle % 360 == 0:\n            return img\n\n        if interp is None:\n            interp = cv2.INTER_LINEAR\n\n        if expand:\n            bound_w, bound_h = np.rint([h * abs(np.sin(np.deg2rad(angle))) + w * abs(np.cos(np.deg2rad(angle))),\n                                        h * abs(np.cos(np.deg2rad(angle))) + w * abs(np.sin(np.deg2rad(angle)))]).astype(int)\n        else:\n            bound_w, bound_h = w, h\n\n        image_center = np.array((w / 2, h / 2))\n        if center is None:\n            center = image_center\n\n        rm = cv2.getRotationMatrix2D(tuple(center), angle, 1)\n\n        if expand:\n            rot_im_center = cv2.transform(np.array([image_center]), rm)[0, 0, :]\n            new_center = np.array([bound_w / 2, bound_h / 2]) - rot_im_center\n            rm[:, 2] += new_center\n\n        ret = cv2.warpAffine(img, rm, (bound_w, bound_h), flags=interp)\n\n        return ret"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        h, w = self.h, self.w\n        angle = self.angle\n        expand = self.expand\n        center = self.center\n        interp = self.interp\n\n        if len(img) == 0 or angle % 360 == 0:\n            return img\n\n        if interp is None:\n            interp = cv2.INTER_LINEAR\n\n        if expand:\n            bound_w, bound_h = np.rint([h * abs(np.sin(np.deg2rad(angle))) + w * abs(np.cos(np.deg2rad(angle))),\n                                       h * abs(np.cos(np.deg2rad(angle))) + w * abs(np.sin(np.deg2rad(angle)))]).astype(int)\n        else:\n            bound_w, bound_h = w, h\n\n        image_center = np.array((w / 2, h / 2))\n        if center is None:\n            center = image_center\n\n        rm_coords = cv2.getRotationMatrix2D(tuple(center), angle, 1)\n        if expand:\n            rot_im_center = cv2.transform(image_center[None, None, :], rm_coords)[0, 0, :]\n            new_center = np.array([bound_w / 2, bound_h / 2]) - rot_im_center\n            rm_coords[:, 2] += new_center\n\n        if len(img.shape) == 2:\n            img = cv2.warpAffine(img, rm_coords, (bound_w, bound_h), flags=interp)\n        else:\n            img = cv2.warpAffine(img, rm_coords, (bound_w, bound_h), flags=interp, borderMode=cv2.BORDER_CONSTANT)\n\n        return img"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        h, w = self.h, self.w\n        angle = self.angle\n        expand = self.expand\n        center = self.center\n        interp = self.interp\n\n        if len(img) == 0 or angle % 360 == 0:\n            return img\n\n        if interp is None:\n            interp = cv2.INTER_LINEAR\n\n        if expand:\n            bound_w, bound_h = np.rint([h * abs(np.sin(np.deg2rad(angle))) + w * abs(np.cos(np.deg2rad(angle))),\n                                        h * abs(np.cos(np.deg2rad(angle))) + w * abs(np.sin(np.deg2rad(angle)))]).astype(int)\n        else:\n            bound_w, bound_h = w, h\n\n        image_center = np.array((w / 2, h / 2))\n        if center is None:\n            center = image_center\n\n        rm_coords = cv2.getRotationMatrix2D(tuple(center), angle, 1)\n        if expand:\n            rot_im_center = cv2.transform(image_center[None, None, :], rm_coords)[0, 0, :]\n            new_center = np.array([bound_w / 2, bound_h / 2]) - rot_im_center\n            rm_coords[:, 2] += new_center\n\n        return cv2.warpAffine(img, rm_coords, (bound_w, bound_h), flags=interp)"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        h, w = self.h, self.w\n        angle = self.angle\n        expand = self.expand\n        center = self.center\n        interp = self.interp\n\n        if len(img) == 0 or angle % 360 == 0:\n            return img\n\n        if interp is None:\n            interp = cv2.INTER_LINEAR\n\n        if expand:\n            bound_w, bound_h = np.rint([h * abs(np.sin(np.deg2rad(angle))) + w * abs(np.cos(np.deg2rad(angle))),\n                                        h * abs(np.cos(np.deg2rad(angle))) + w * abs(np.sin(np.deg2rad(angle)))]).astype(int)\n        else:\n            bound_w, bound_h = w, h\n\n        image_center = np.array((w / 2, h / 2))\n        if center is None:\n            center = image_center\n\n        rm_coords = cv2.getRotationMatrix2D(tuple(center), angle, 1)\n        rm_image = cv2.getRotationMatrix2D(tuple(center), angle, 1)\n\n        if expand:\n            rot_im_center = cv2.transform(np.array([image_center]), rm_image)[0, 0, :]\n            new_center = np.array([bound_w / 2, bound_h / 2]) - rot_im_center\n            rm_image[:, 2] += new_center\n\n        return cv2.warpAffine(img, rm_image, (bound_w, bound_h), flags=interp)"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        h, w = self.h, self.w\n        angle = self.angle\n        expand = self.expand\n        center = self.center\n        interp = self.interp\n\n        if len(img) == 0 or angle % 360 == 0:\n            return img\n\n        if interp is None:\n            interp = cv2.INTER_LINEAR\n\n        if expand:\n            bound_w, bound_h = np.rint([h * abs(np.sin(np.deg2rad(angle))) + w * abs(np.cos(np.deg2rad(angle))),\n                                        h * abs(np.cos(np.deg2rad(angle))) + w * abs(np.sin(np.deg2rad(angle)))]).astype(int)\n        else:\n            bound_w, bound_h = w, h\n\n        image_center = np.array((w / 2, h / 2))\n        if center is None:\n            center = image_center\n\n        rm_coords = cv2.getRotationMatrix2D(tuple(center), angle, 1)\n        if expand:\n            rot_im_center = cv2.transform(image_center[None, None, :], rm_coords)[0, 0, :]\n            new_center = np.array([bound_w / 2, bound_h / 2]) - rot_im_center\n            rm_coords[:, 2] += new_center\n\n        if len(img.shape) > 2 and img.shape[2] == 1:\n            img = img[:, :, 0]\n\n        rotated_img = cv2.warpAffine(img, rm_coords, (bound_w, bound_h), flags=interp)\n\n        if len(img.shape) > 2 and img.shape[2] == 1:\n            rotated_img = np.expand_dims(rotated_img, -1)\n\n        return rotated_img"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        h, w = self.h, self.w\n        angle = self.angle\n        expand = self.expand\n        center = self.center\n        interp = self.interp\n\n        if len(img) == 0 or angle % 360 == 0:\n            return img\n        else:\n            if interp is None:\n                interp = cv2.INTER_LINEAR\n\n            if expand:\n                bound_w, bound_h = np.rint([h * abs(np.sin(np.deg2rad(angle))) + w * abs(np.cos(np.deg2rad(angle))),\n                                            h * abs(np.cos(np.deg2rad(angle))) + w * abs(np.sin(np.deg2rad(angle)))]).astype(int)\n            else:\n                bound_w, bound_h = w, h\n\n            image_center = np.array((w / 2, h / 2))\n            if center is None:\n                center = image_center\n\n            rm_coords = self.create_rotation_matrix()\n            rm_image = self.create_rotation_matrix(offset=-0.5)\n\n            coords = np.asarray(coords, dtype=float)\n            if len(coords) == 0 or self.angle % 360 == 0:\n                return coords\n            coords = cv2.transform(coords[:, np.newaxis, :], rm_coords)[:, 0, :]\n\n            segmentation = self.apply_image(segmentation, interp=cv2.INTER_NEAREST)\n\n            center = (center[0] - 0.5, center[1] - 0.5)\n            rm = cv2.getRotationMatrix2D(tuple(center), angle, 1)\n            if expand:\n                rot_im_center = cv2.transform(image_center[None, None, :] - 0.5, rm)[0, 0, :]\n                new_center = np.array([bound_w / 2, bound_h / 2]) - rot_im_center\n                rm[:, 2] += new_center\n\n            return cv2.warpAffine(img, rm, (bound_w, bound_h), flags=interp)"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        h, w = self.h, self.w\n        angle = self.angle\n        if len(img) == 0 or angle % 360 == 0:\n            return img\n        if interp is None:\n            interp = self.interp\n        return cv2.warpAffine(img, self.rm_image, (self.bound_w, self.bound_h), flags=interp)"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        h, w = self.h, self.w\n        angle = self.angle\n        expand = self.expand\n        center = self.center\n        interp = self.interp\n\n        if len(img) == 0 or angle % 360 == 0:\n            return img\n\n        if interp is None:\n            interp = cv2.INTER_LINEAR\n\n        if expand:\n            bound_w, bound_h = np.rint([h * abs(np.sin(np.deg2rad(angle))) + w * abs(np.cos(np.deg2rad(angle))), h * abs(np.cos(np.deg2rad(angle))) + w * abs(np.sin(np.deg2rad(angle)))]).astype(int)\n        else:\n            bound_w, bound_h = w, h\n\n        image_center = np.array((w / 2, h / 2))\n        if center is None:\n            center = image_center\n\n        rm_coords = cv2.getRotationMatrix2D(tuple(center), angle, 1)\n\n        if expand:\n            rot_im_center = cv2.transform(np.array([image_center]), rm_coords)[0, 0, :]\n            new_center = np.array([bound_w / 2, bound_h / 2]) - rot_im_center\n            rm_coords[:, 2] += new_center\n\n        return cv2.warpAffine(img, rm_coords, (bound_w, bound_h), flags=interp)"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes.tensor if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        masks = predictions.pred_masks if predictions.has(\"pred_masks\") else None\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        labels = _create_text_labels(classes, scores, self.metadata.thing_classes)\n        assigned_colors = None\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            assigned_colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n\n        return self.overlay_instances(\n            boxes=boxes,\n            labels=labels,\n            masks=masks,\n            keypoints=keypoints,\n            assigned_colors=assigned_colors,\n        )"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        # Extract prediction data from the input\n        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        masks = predictions.pred_masks if predictions.has(\"pred_masks\") else None\n\n        # Draw the visualizations on the image\n        self.overlay_instances(boxes=boxes, labels=classes, masks=masks, scores=scores)\n\n        # Return the image with visualizations\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        if \"instances\" in predictions:\n            predictions = predictions[\"instances\"]\n        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n        if predictions.has(\"pred_masks\"):\n            masks = predictions.pred_masks\n        elif predictions.has(\"pred_masks_rle\"):\n            masks = [mask_util.decode(rle) for rle in predictions.pred_masks_rle]\n        else:\n            masks = None\n\n        return self.overlay_instances(\n            boxes=boxes,\n            labels=classes,\n            masks=masks,\n            keypoints=keypoints,\n            assigned_colors=None,\n            alpha=0.5,\n        )"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        masks = predictions.pred_masks if predictions.has(\"pred_masks\") else None\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        labels = None\n        if predictions.has(\"pred_classes\") and self.metadata.thing_classes:\n            labels = [self.metadata.thing_classes[i] for i in predictions.pred_classes]\n\n        return self.overlay_instances(\n            boxes=boxes,\n            labels=labels,\n            masks=masks,\n            keypoints=keypoints,\n            assigned_colors=None,\n            alpha=0.5,\n        )"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        masks = predictions.pred_masks if predictions.has(\"pred_masks\") else None\n\n        labels = _create_text_labels(classes, scores, self.metadata.thing_classes)\n        assigned_colors = None\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            assigned_colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n\n        self.overlay_instances(\n            boxes=boxes,\n            labels=labels,\n            masks=masks,\n            assigned_colors=assigned_colors,\n            alpha=0.5,\n        )\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        # Extract prediction data from the \"predictions\" input\n        if \"pred_boxes\" in predictions:\n            boxes = predictions.pred_boxes.tensor\n        else:\n            boxes = None\n\n        if \"pred_classes\" in predictions:\n            classes = predictions.pred_classes\n        else:\n            classes = None\n\n        if \"scores\" in predictions:\n            scores = predictions.scores\n        else:\n            scores = None\n\n        if \"pred_masks\" in predictions:\n            masks = predictions.pred_masks\n        else:\n            masks = None\n\n        if \"pred_masks_rle\" in predictions:\n            masks_rle = predictions.pred_masks_rle\n        else:\n            masks_rle = None\n\n        if \"pred_keypoints\" in predictions:\n            keypoints = predictions.pred_keypoints\n        else:\n            keypoints = None\n\n        # Draw the instance predictions using the extracted data\n        self.overlay_instances(\n            boxes=boxes,\n            labels=classes,\n            masks=masks,\n            keypoints=keypoints,\n            assigned_colors=None,\n            alpha=0.5,\n        )\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        masks = predictions.pred_masks if predictions.has(\"pred_masks\") else None\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        labels = _create_text_labels(classes, scores, self.metadata.thing_classes)\n        assigned_colors = None\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            assigned_colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n\n        self.overlay_instances(\n            boxes=boxes,\n            labels=labels,\n            masks=masks,\n            keypoints=keypoints,\n            assigned_colors=assigned_colors,\n        )\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        masks = predictions.pred_masks if predictions.has(\"pred_masks\") else None\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            if masks is not None:\n                masks = [x.to(\"cpu\").numpy() for x in masks]\n            self.output = self.overlay_instances(\n                boxes=boxes, labels=classes, masks=masks, assigned_colors=None\n            )\n        else:\n            if masks is not None:\n                masks = [x.to(\"cpu\") for x in masks]\n            if boxes is not None:\n                boxes = [x.to(\"cpu\") for x in boxes]\n            if scores is not None:\n                scores = [x.to(\"cpu\") for x in scores]\n            if classes is not None:\n                classes = [x.to(\"cpu\") for x in classes]\n            self.output = self.overlay_instances(\n                boxes=boxes, labels=classes, masks=masks, scores=scores, assigned_colors=None\n            )\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        masks = predictions.pred_masks if predictions.has(\"pred_masks\") else None\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        labels = None\n        if predictions.has(\"pred_classes\") and self.metadata.thing_classes:\n            labels = [self.metadata.thing_classes[i] for i in predictions.pred_classes]\n\n        assigned_colors = None\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.thing_colors:\n            assigned_colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]])\n                for c in predictions.pred_classes\n            ]\n\n        return self.overlay_instances(\n            boxes=boxes,\n            labels=labels,\n            masks=masks,\n            keypoints=keypoints,\n            assigned_colors=assigned_colors,\n            alpha=0.5,\n        )"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        if \"instances\" in predictions:\n            instances = predictions[\"instances\"]\n            if self._instance_mode == ColorMode.SEGMENTATION:\n                return self.draw_sem_seg(instances.pred_masks)\n            elif self._instance_mode == ColorMode.IMAGE_BW:\n                return self.draw_binary_mask(instances.pred_masks, alpha=1.0)\n            else:\n                boxes = instances.pred_boxes.tensor.numpy()\n                scores = instances.scores if instances.has(\"scores\") else None\n                classes = instances.pred_classes.numpy()\n                keypoints = instances.pred_keypoints if instances.has(\"pred_keypoints\") else None\n                if instances.has(\"pred_masks\"):\n                    masks = instances.pred_masks\n                elif instances.has(\"pred_masks_rle\"):\n                    masks = [mask_util.decode(rle) for rle in instances.pred_masks_rle]\n                else:\n                    masks = None\n                return self.overlay_instances(\n                    boxes=boxes,\n                    labels=classes,\n                    masks=masks,\n                    keypoints=keypoints,\n                    assigned_colors=None,\n                    alpha=0.5,\n                )"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        masks = predictions.pred_masks if predictions.has(\"pred_masks\") else None\n\n        num_instances = len(boxes) if boxes is not None else 0\n        if num_instances == 0:\n            return self.output\n\n        labels = _create_text_labels(classes, scores, self.metadata.thing_classes)\n        colors = None\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]])\n                for c in classes\n            ]\n\n        self.overlay_instances(boxes=boxes, labels=labels, masks=masks, assigned_colors=colors)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes.tensor if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        masks = predictions.pred_masks if predictions.has(\"pred_masks\") else None\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            # Convert the image to grayscale\n            img = self._create_grayscale_image()\n            self.output.reset_image(img)\n\n        if boxes is not None and classes is not None:\n            labels = _create_text_labels(classes, scores, self.metadata.thing_classes)\n            self.overlay_instances(boxes=boxes, labels=labels, masks=masks)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        masks = predictions.pred_masks if predictions.has(\"pred_masks\") else None\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            if masks is not None:\n                masks = [x.to(\"cpu\").numpy() for x in masks]\n                masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n                masks = [x.mask for x in masks]\n\n        labels = _create_text_labels(classes, scores, self.metadata.thing_classes)\n        assigned_colors = None\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            assigned_colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n\n        self.overlay_instances(boxes=boxes, labels=labels, masks=masks, assigned_colors=assigned_colors)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n        masks = predictions.pred_masks if predictions.has(\"pred_masks\") else None\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            # Convert the image to grayscale if the color mode is set to IMAGE_BW\n            img = self._create_grayscale_image()\n            self.output.reset_image(img)\n        if boxes is not None and scores is not None and classes is not None:\n            labels = _create_text_labels(classes, scores, self.metadata.thing_classes)\n            assigned_colors = None\n            if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n                assigned_colors = [\n                    self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n                ]\n            self.overlay_instances(boxes=boxes.tensor, labels=labels, masks=masks, keypoints=keypoints, assigned_colors=assigned_colors)\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        if \"pred_masks\" in predictions:\n            masks = predictions.pred_masks\n            if self._instance_mode == ColorMode.IMAGE_BW:\n                mask = (masks[0] > 0.5).numpy()\n                self.output.reset_image(self._create_grayscale_image(mask))\n            color = None\n            if self._instance_mode == ColorMode.SEGMENTATION:\n                color = [random_color(rgb=True, maximum=1) for _ in range(len(masks))]\n            self.overlay_instances(masks=masks, assigned_colors=color)\n        if \"pred_boxes\" in predictions:\n            boxes = predictions.pred_boxes.tensor.numpy()\n            if \"pred_classes\" in predictions:\n                classes = predictions.pred_classes.numpy()\n                class_names = self.metadata.get(\"thing_classes\", None)\n                labels = [class_names[i] for i in classes]\n            else:\n                labels = None\n            if \"scores\" in predictions:\n                scores = predictions.scores.numpy()\n            else:\n                scores = None\n            self.overlay_instances(boxes=boxes, labels=labels, scores=scores)\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        masks = predictions.pred_masks if predictions.has(\"pred_masks\") else None\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        labels = None\n        if predictions.has(\"pred_classes\") and self.metadata.thing_classes:\n            labels = [self.metadata.thing_classes[i] for i in predictions.pred_classes]\n\n        assigned_colors = None\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.thing_colors:\n            assigned_colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n\n        return self.overlay_instances(\n            boxes=boxes,\n            labels=labels,\n            masks=masks,\n            keypoints=keypoints,\n            assigned_colors=assigned_colors,\n            alpha=0.5,\n        )"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        masks = predictions.pred_masks if predictions.has(\"pred_masks\") else None\n\n        labels = _create_text_labels(classes, scores, self.metadata.thing_classes)\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n        else:\n            colors = None\n\n        self.overlay_instances(boxes=boxes, labels=labels, masks=masks, assigned_colors=colors)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        masks = predictions.pred_masks if predictions.has(\"pred_masks\") else None\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        labels = None\n        if predictions.has(\"pred_classes\") and self.metadata.thing_classes:\n            labels = [self.metadata.thing_classes[i] for i in predictions.pred_classes]\n\n        assigned_colors = None\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.thing_colors:\n            assigned_colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]])\n                for c in predictions.pred_classes\n            ]\n\n        self.overlay_instances(\n            boxes=boxes,\n            labels=labels,\n            masks=masks,\n            keypoints=keypoints,\n            assigned_colors=assigned_colors,\n        )\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        masks = predictions.pred_masks if predictions.has(\"pred_masks\") else None\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            # Convert the image to grayscale\n            img = self._create_grayscale_image()\n            self.output.reset_image(img)\n\n        if boxes is not None and classes is not None:\n            labels = _create_text_labels(classes, scores, self.metadata.thing_classes)\n            self.overlay_instances(boxes=boxes.tensor, labels=labels, masks=masks)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        masks = predictions.pred_masks if predictions.has(\"pred_masks\") else None\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            # Convert the image to grayscale\n            self.output.reset_image(self._create_grayscale_image())\n\n        if boxes is not None and classes is not None:\n            labels = _create_text_labels(classes, scores, self.metadata.thing_classes)\n            self.overlay_instances(boxes=boxes.tensor, labels=labels, masks=masks, alpha=0.5)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # Convert the RGBA image to RGB format\n        img_rgba = self.output.canvas.buffer_rgba()\n        img_rgb = np.array(img_rgba.convert(\"RGB\"))\n\n        return img_rgb"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # Convert the RGBA image to RGB format\n        rgba_image = self.canvas.buffer_rgba()\n        rgb_image = rgba_image[:, :, :3]\n\n        # Convert the image to uint8 type\n        rgb_image = (rgb_image * 255).astype(np.uint8)\n\n        return rgb_image"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # Convert the RGBA image to RGB\n        img_rgba = self.canvas.buffer_rgba()\n        img_rgb = img_rgba[:, :, :3]\n\n        # Convert the image to uint8 type\n        img_uint8 = (img_rgb * 255).astype(np.uint8)\n\n        return img_uint8"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        self.output.canvas.draw()\n        buf = self.output.canvas.buffer_rgba()\n        w, h = self.output.canvas.get_width_height()\n        return np.frombuffer(buf, np.uint8).reshape(h, w, 4)[:,:,:3]"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # Convert the RGBA image to RGB format\n        image_rgba = self.canvas.buffer_rgba()\n        image_rgb = image_rgba[:, :, :3]\n\n        # Convert the image to uint8 type\n        image_uint8 = (image_rgb * 255).astype(np.uint8)\n\n        return image_uint8"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        self.output.canvas.draw()\n        buf = self.output.canvas.buffer_rgba()\n        w, h = self.output.canvas.get_width_height()\n        return np.frombuffer(buf, np.uint8).reshape(h, w, 4)[:,:,:3]"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        self.output.canvas.draw()\n        buf = self.output.canvas.buffer_rgba()\n        w, h = self.output.canvas.get_width_height()\n        return np.frombuffer(buf, np.uint8).reshape(h, w, 4)[:,:,:3]"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        self.output.canvas.draw()\n        buf = self.output.canvas.buffer_rgba()\n        w, h = self.output.canvas.get_width_height()\n        return np.frombuffer(buf, np.uint8).reshape(h, w, 4)[..., :3]"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # Convert the RGBA image to RGB format\n        rgba_image = self.canvas.buffer_rgba()\n        rgb_image = rgba_image[:, :, :3]\n\n        # Convert the image to uint8 type and return\n        return rgb_image.astype(np.uint8)"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # Convert the RGBA image to RGB format\n        image = self.output.canvas.buffer_rgba()\n        image = np.asarray(bytearray(image), dtype=\"uint8\")\n        image = image.reshape((self.output.height, self.output.width, 4))\n        image = cv2.cvtColor(image, cv2.COLOR_RGBA2RGB)\n\n        return image"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # Convert the RGBA image to RGB format\n        image_rgba = self.output.canvas.buffer_rgba()\n        image_rgb = Image.fromarray(image_rgba).convert(\"RGB\")\n        \n        # Convert the RGB image to a numpy ndarray of uint8 type\n        image_np = np.array(image_rgb)\n        \n        return image_np"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        self.canvas.draw()\n        buf = self.canvas.buffer_rgba()\n        w, h = self.canvas.get_width_height()\n        return np.frombuffer(buf, np.uint8).reshape(h, w, 4)[:,:,:3]"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        self.canvas.draw()\n        buf = self.canvas.buffer_rgba()\n        w, h = self.canvas.get_width_height()\n        return np.frombuffer(buf, np.uint8).reshape(h, w, 4)[:,:,:3]"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        self.canvas.draw()\n        buf = self.canvas.buffer_rgba()\n        img = np.asarray(bytearray(buf), dtype=np.uint8)\n        img = img.reshape(self.output.height, self.output.width, 4)\n        img = img[:, :, :3]  # Remove the alpha channel\n        return img"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # Convert the RGBA image to RGB format\n        image_rgb = self.output.canvas.buffer_rgba()\n        image_rgb = np.asarray(bytearray(image_rgb), dtype=np.uint8)\n        image_rgb = image_rgb.reshape((self.output.height, self.output.width, 4))\n        image_rgb = image_rgb[:, :, :3]  # Remove the alpha channel\n        return image_rgb"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        self.output.canvas.draw()\n        image = np.array(self.output.canvas.renderer._renderer)\n        # Convert from RGBA to RGB\n        image = image[:, :, :3]\n        return image"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # Convert the RGBA image to RGB format\n        image_rgba = self.output.canvas.buffer_rgba()\n        image_rgb = Image.frombytes(\"RGBA\", self.output.canvas.get_width_height(), image_rgba, \"raw\")\n        image_rgb = np.array(image_rgb)\n        return image_rgb"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # Convert RGBA to RGB\n        image_rgba = self.output.canvas.buffer_rgba()\n        image_rgb = Image.fromarray(image_rgba).convert(\"RGB\")\n        image_np = np.array(image_rgb)\n        return image_np"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # Convert the RGBA image to RGB\n        img_rgba = self.output.canvas.buffer_rgba()\n        img_rgb = img_rgba[:, :, :3]\n\n        # Convert to uint8 and return\n        return img_rgb.astype(np.uint8)"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # Convert the RGBA image to RGB format\n        img_rgba = self.canvas.buffer_rgba()\n        img_rgb = img_rgba[:, :, :3]\n\n        # Convert the image to uint8 type\n        img_rgb_uint8 = img_rgb.astype(np.uint8)\n\n        return img_rgb_uint8"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # Your code to process the annotations and visualize them goes here\n        pass"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        if \"annotations\" in dic:\n            annotations = dic[\"annotations\"]\n            instances = Instances((dic[\"height\"], dic[\"width\"]))\n            instances.set(\"pred_boxes\", torch.tensor([x[\"bbox\"] for x in annotations]))\n            instances.set(\"scores\", torch.tensor([x[\"score\"] for x in annotations]))\n            instances.set(\"pred_classes\", torch.tensor([x[\"category_id\"] for x in annotations]))\n            if \"segmentation\" in annotations[0]:\n                masks = [x[\"segmentation\"] for x in annotations]\n                instances.set(\"pred_masks\", PolygonMasks(masks, dic[\"height\"], dic[\"width\"]))\n            if \"keypoints\" in annotations[0]:\n                keypoints = [x[\"keypoints\"] for x in annotations]\n                instances.set(\"pred_keypoints\", torch.tensor(keypoints))\n            return self.draw_instance_predictions(instances)\n        elif \"sem_seg\" in dic:\n            return self.draw_sem_seg(dic[\"sem_seg\"])\n        elif \"pan_seg\" in dic:\n            return self.draw_panoptic_seg(dic[\"pan_seg\"][\"panoptic_seg\"], dic[\"pan_seg\"][\"segments_info\"])\n        else:\n            raise ValueError(\"Unsupported dataset format\")"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # Implement the logic to draw the dataset annotations/segmentations on the image\n        # Use the provided annotations, semantic segmentation, and panoptic segmentation data in the input dictionary\n        # Draw the visualizations on the image using the existing methods in the Visualizer class\n        # Return the modified image object with the visualizations drawn on it"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # Extract the relevant data from the input dictionary\n        if \"annotations\" in dic:\n            annotations = dic[\"annotations\"]\n            boxes = [ann[\"bbox\"] for ann in annotations]\n            labels = [str(ann[\"category_id\"]) for ann in annotations]\n            if \"segmentation\" in annotations[0]:\n                masks = [ann[\"segmentation\"] for ann in annotations]\n            else:\n                masks = None\n            keypoints = [ann[\"keypoints\"] for ann in annotations] if \"keypoints\" in annotations[0] else None\n        else:\n            boxes, labels, masks, keypoints = None, None, None, None\n\n        if \"sem_seg\" in dic:\n            sem_seg = dic[\"sem_seg\"]\n        else:\n            sem_seg = None\n\n        if \"pan_seg\" in dic:\n            pan_seg = dic[\"pan_seg\"]\n            segments_info = dic[\"segments_info\"]\n        else:\n            pan_seg, segments_info = None, None\n\n        # Draw the visualizations based on the extracted data\n        if boxes or labels or masks or keypoints:\n            self.overlay_instances(\n                boxes=boxes,\n                labels=labels,\n                masks=masks,\n                keypoints=keypoints,\n            )\n        if sem_seg:\n            self.draw_sem_seg(sem_seg)\n        if pan_seg and segments_info:\n            self.draw_panoptic_seg(pan_seg, segments_info)\n\n        # Return the modified image object\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # Your code here\n        # Use the annotation/segmentation data in the dictionary to draw visualizations on the image\n        # Return the modified image object"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # Add your implementation here\n        # Extract the required information from the input dictionary and use the existing drawing methods to visualize the annotations/segmentations on the image.\n        # Return the modified image object with the visualizations drawn on it."}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # Add code to process the input dictionary and draw the visualizations on the image\n        # Return the modified image object\n        pass  # Placeholder for the implementation"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # Implementation of the draw_dataset_dict function goes here\n        # This function will handle the visualization of annotations/segmentations based on the input dictionary\n        # It will utilize the existing methods in the Visualizer class to draw different types of annotations on the image\n        # The modified image object with visualizations will be returned\n        pass"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # Your implementation here\n        # Use the data in the input dictionary to draw visualizations on the image\n        # Return the modified image object\n        pass"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # Implementation of the function goes here\n        # This function will process the input dictionary and draw the visualizations on the image\n        # The modified image object will then be returned\n        pass"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # Extract the necessary information from the input dictionary\n        image = dic.get(\"image\")\n        annotations = dic.get(\"annotations\")\n        sem_seg = dic.get(\"sem_seg\")\n        panoptic_seg = dic.get(\"panoptic_seg\")\n        \n        # Perform the visualizations based on the available information\n        if annotations:\n            # Draw instance-level predictions\n            predictions = self._process_annotations(annotations)\n            self.draw_instance_predictions(predictions)\n        if sem_seg:\n            # Draw semantic segmentation\n            self.draw_sem_seg(sem_seg)\n        if panoptic_seg:\n            # Draw panoptic segmentation\n            segments_info = dic.get(\"segments_info\")\n            self.draw_panoptic_seg(panoptic_seg, segments_info)\n        \n        # Return the modified image object\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        if \"annotations\" in dic:\n            return self.draw_instance_predictions(dic[\"annotations\"])\n        elif \"sem_seg\" in dic:\n            return self.draw_sem_seg(dic[\"sem_seg\"])\n        elif \"panoptic_seg\" in dic and \"segments_info\" in dic:\n            return self.draw_panoptic_seg(dic[\"panoptic_seg\"], dic[\"segments_info\"])\n        else:\n            logger.warning(\"No suitable annotations found in the input dictionary.\")\n            return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # Your implementation here\n        # Use the data in the input dictionary to draw the visualizations on the image\n        # Return the modified image object\n        pass"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # Extract the necessary data from the input dictionary\n        image = dic.get(\"image\")\n        annotations = dic.get(\"annotations\")\n        sem_seg = dic.get(\"sem_seg\")\n        panoptic_seg = dic.get(\"panoptic_seg\")\n        \n        # Perform visualization based on the available data\n        if annotations:\n            instances = annotations.get(\"instances\")\n            if instances:\n                return self.draw_instance_predictions(instances)\n        \n        if sem_seg:\n            return self.draw_sem_seg(sem_seg)\n        \n        if panoptic_seg:\n            segments_info = dic.get(\"segments_info\")\n            return self.draw_panoptic_seg(panoptic_seg, segments_info)\n        \n        # If no specific data is available, return the original image\n        return VisImage(image)"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # Your code to process the input dictionary and draw the visualizations goes here\n        # Use the existing methods in the Visualizer class to draw the visualizations\n        # Return the modified image object\n        pass  # Remove this line when you start implementing the function"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # Your implementation here\n        # Use the data in the input dictionary to draw visualizations on the image\n        # Return the modified image object"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        if \"annotations\" in dic:\n            return self.draw_instance_predictions(dic[\"annotations\"])\n        elif \"sem_seg\" in dic:\n            return self.draw_sem_seg(dic[\"sem_seg\"])\n        elif \"panoptic_seg\" in dic:\n            return self.draw_panoptic_seg(dic[\"panoptic_seg\"], dic.get(\"segments_info\"))\n        else:\n            raise ValueError(\"Unsupported visualization type in the input dictionary\")"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # Your implementation here\n        # Use the provided annotation/segmentation data to draw visualizations on the image\n        # Return the modified image object\n        pass"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # Extract the necessary information from the input dictionary\n        image = dic.get(\"image\")\n        annotations = dic.get(\"annotations\")\n        sem_seg = dic.get(\"sem_seg\")\n        panoptic_seg = dic.get(\"panoptic_seg\")\n        \n        # Perform the necessary visualizations based on the available data\n        if annotations:\n            instances = annotations.get(\"instances\")\n            if instances:\n                return self.draw_instance_predictions(instances)\n        \n        if sem_seg:\n            return self.draw_sem_seg(sem_seg)\n        \n        if panoptic_seg:\n            segments_info = dic.get(\"segments_info\")\n            return self.draw_panoptic_seg(panoptic_seg, segments_info)\n        \n        # If no relevant data is found, return the original image\n        return VisImage(image)"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # Extract the necessary information from the input dictionary\n        if \"annotations\" in dic:\n            annotations = dic[\"annotations\"]\n            boxes = [ann[\"bbox\"] for ann in annotations]\n            labels = [ann[\"category_id\"] for ann in annotations]\n        else:\n            annotations = None\n            boxes = None\n            labels = None\n\n        if \"sem_seg\" in dic:\n            sem_seg = dic[\"sem_seg\"]\n        else:\n            sem_seg = None\n\n        if \"panoptic_seg\" in dic:\n            panoptic_seg = dic[\"panoptic_seg\"]\n            segments_info = dic.get(\"segments_info\", None)\n        else:\n            panoptic_seg = None\n            segments_info = None\n\n        # Draw the visualizations based on the extracted information\n        if annotations:\n            self.draw_instance_predictions(annotations)\n        if sem_seg:\n            self.draw_sem_seg(sem_seg)\n        if panoptic_seg:\n            self.draw_panoptic_seg(panoptic_seg, segments_info)\n\n        # Return the modified image object\n        return self.output"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n    return reloaded_module"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        color = mplc.to_rgb(color)\n\n        shape2d = (binary_mask.shape[0], binary_mask.shape[1])\n        rgba = np.zeros(shape2d + (4,), dtype=\"float32\")\n        rgba[:, :, :3] = color\n        rgba[:, :, 3] = binary_mask * alpha\n        self.output.ax.imshow(rgba, extent=(0, self.output.width, self.output.height, 0))\n\n        if text is not None:\n            lighter_color = self._change_color_brightness(color, brightness_factor=0.7)\n            binary_mask = (binary_mask > 0.5).astype(\"uint8\")\n            self._draw_text_in_mask(binary_mask, text, lighter_color)\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        color = mplc.to_rgb(color)\n\n        # Create a polygon from the binary mask\n        mask_contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n        for contour in mask_contours:\n            # Draw the polygon\n            self.draw_polygon(contour.reshape(-1, 2), color, edge_color, alpha)\n\n        if text is not None:\n            # Draw text on the mask\n            lighter_color = self._change_color_brightness(color, brightness_factor=0.7)\n            self._draw_text_in_mask(binary_mask, text, lighter_color)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        color = mplc.to_rgb(color)\n\n        shape2d = (binary_mask.shape[0], binary_mask.shape[1])\n        rgba = np.zeros(shape2d + (4,), dtype=\"float32\")\n        rgba[:, :, :3] = color\n        rgba[:, :, 3] = binary_mask * alpha\n        self.output.ax.imshow(rgba, extent=(0, self.output.width, self.output.height, 0))\n\n        if text is not None:\n            lighter_color = self._change_color_brightness(color, brightness_factor=0.7)\n            binary_mask = (binary_mask > 0.5).astype(\"uint8\")\n            self._draw_text_in_mask(binary_mask, text, lighter_color)\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        color = mplc.to_rgb(color)\n\n        shape2d = (binary_mask.shape[0], binary_mask.shape[1])\n        rgba = np.zeros(shape2d + (4,), dtype=\"float32\")\n        rgba[:, :, :3] = color\n        rgba[:, :, 3] = binary_mask * alpha\n        self.output.ax.imshow(rgba, extent=(0, self.output.width, self.output.height, 0))\n\n        if text is not None:\n            lighter_color = self._change_color_brightness(color, brightness_factor=0.7)\n            binary_mask = (binary_mask > 0.5).astype(\"uint8\")\n            self._draw_text_in_mask(binary_mask, text, lighter_color)\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        color = mplc.to_rgb(color)\n\n        shape2d = (binary_mask.shape[0], binary_mask.shape[1])\n        rgba = np.zeros(shape2d + (4,), dtype=\"float32\")\n        rgba[:, :, :3] = color\n        rgba[:, :, 3] = binary_mask * alpha\n        self.output.ax.imshow(rgba, extent=(0, self.output.width, self.output.height, 0))\n\n        if text is not None:\n            lighter_color = self._change_color_brightness(color, brightness_factor=0.7)\n            self._draw_text_in_mask(binary_mask, text, lighter_color)\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        color = mplc.to_rgb(color)\n        rgba = np.zeros((binary_mask.shape[0], binary_mask.shape[1], 4), dtype=\"float32\")\n        rgba[:, :, :3] = color\n        rgba[:, :, 3] = binary_mask * alpha\n\n        self.output.ax.imshow(rgba, extent=(0, self.output.width, self.output.height, 0))\n\n        if text is not None:\n            lighter_color = self._change_color_brightness(color, brightness_factor=0.7)\n            self._draw_text_in_mask(binary_mask, text, lighter_color)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "\n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        color = mplc.to_rgb(color)\n\n        mask = (binary_mask > 0).astype(\"uint8\")\n        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n        for contour in contours:\n            area = cv2.contourArea(contour)\n            if area < area_threshold:\n                continue\n\n            if edge_color is None:\n                edge_color = color\n            edge_color = mplc.to_rgb(edge_color)\n\n            polygon = np.squeeze(contour, axis=1)\n            self.draw_polygon(polygon, color, edge_color, alpha)\n\n            if text is not None:\n                self._draw_text_in_mask(binary_mask, text, color)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "\n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        color = mplc.to_rgb(color)\n\n        if binary_mask.sum() < area_threshold:\n            return self.output\n\n        # Convert binary mask to polygons\n        mask = np.ascontiguousarray(binary_mask)\n        res = cv2.findContours(mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n        contours = res[-2]\n        for contour in contours:\n            contour = contour.flatten()\n            polygon = contour.reshape(-1, 2)\n            self.draw_polygon(polygon, color, edge_color, alpha)\n\n            if text is not None:\n                self._draw_text_in_mask(binary_mask, text, color)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        color = mplc.to_rgb(color)\n\n        shape2d = (binary_mask.shape[0], binary_mask.shape[1])\n        rgba = np.zeros(shape2d + (4,), dtype=\"float32\")\n        rgba[:, :, :3] = color\n        rgba[:, :, 3] = binary_mask * alpha\n        self.output.ax.imshow(rgba, extent=(0, self.output.width, self.output.height, 0))\n\n        if text is not None:\n            lighter_color = self._change_color_brightness(color, brightness_factor=0.7)\n            self._draw_text_in_mask(binary_mask, text, lighter_color)\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        color = mplc.to_rgb(color)\n        edge_color = mplc.to_rgb(edge_color) if edge_color is not None else color\n\n        mask = binary_mask.astype(np.uint8)\n        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n        for contour in contours:\n            area = cv2.contourArea(contour)\n            if area < area_threshold:\n                continue\n\n            polygon = contour.reshape(-1, 2)\n            self.draw_polygon(polygon, color, edge_color, alpha)\n\n            if text is not None:\n                text_pos = tuple(np.mean(polygon, axis=0).astype(int))\n                self.draw_text(text, text_pos, color=edge_color)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        color = mplc.to_rgb(color)\n\n        mask = binary_mask.astype(\"uint8\")\n        res = cv2.findContours(mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n        contours = res[-2]\n        hierarchy = res[-1]\n\n        for i, contour in enumerate(contours):\n            area = cv2.contourArea(contour)\n            if area < area_threshold:\n                continue\n\n            if edge_color is None:\n                edge_color = color\n\n            if text is not None:\n                M = cv2.moments(contour)\n                cX = int(M[\"m10\"] / M[\"m00\"])\n                cY = int(M[\"m01\"] / M[\"m00\"])\n                self.draw_text(text, (cX, cY), color=edge_color)\n\n            contour = contour.reshape(-1, 2)\n            self.draw_polygon(contour, color, edge_color, alpha)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "\n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        color = mplc.to_rgb(color)\n\n        mask = binary_mask.astype(np.uint8)\n        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n        for contour in contours:\n            area = cv2.contourArea(contour)\n            if area < area_threshold:\n                continue\n\n            if edge_color is None:\n                edge_color = color\n            edge_color = mplc.to_rgb(edge_color)\n\n            polygon = contour.reshape(-1, 2)\n            self.draw_polygon(polygon, color, edge_color, alpha)\n\n            if text is not None:\n                text_pos = np.mean(polygon, axis=0)\n                self.draw_text(text, text_pos, color=edge_color)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        color = mplc.to_rgb(color)\n\n        shape2d = (binary_mask.shape[0], binary_mask.shape[1])\n        rgba = np.zeros(shape2d + (4,), dtype=\"float32\")\n        rgba[:, :, :3] = color\n        rgba[:, :, 3] = binary_mask * alpha\n        self.output.ax.imshow(rgba, extent=(0, self.output.width, self.output.height, 0))\n\n        if text is not None:\n            lighter_color = self._change_color_brightness(color, brightness_factor=0.7)\n            binary_mask = (binary_mask > 0.5).astype(\"uint8\")\n            self._draw_text_in_mask(binary_mask, text, lighter_color)\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        color = mplc.to_rgb(color)\n\n        # Convert binary mask to polygons\n        mask_contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n        for contour in mask_contours:\n            area = cv2.contourArea(contour)\n            if area < area_threshold:\n                continue\n            contour = contour.reshape(-1, 2)\n            self.draw_polygon(contour, color, edge_color, alpha)\n\n        if text is not None:\n            lighter_color = self._change_color_brightness(color, brightness_factor=0.7)\n            self._draw_text_in_mask(binary_mask, text, lighter_color)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        color = mplc.to_rgb(color)\n\n        if edge_color is None:\n            edge_color = color\n        edge_color = mplc.to_rgb(edge_color)\n\n        mask = binary_mask.astype(np.uint8)\n        contours, _ = cv2.findContours(\n            mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE\n        )\n\n        for contour in contours:\n            if cv2.contourArea(contour) < area_threshold:\n                continue\n            polygon = contour.reshape(-1, 2)\n            self.draw_polygon(polygon, color, edge_color, alpha)\n\n        if text is not None:\n            self._draw_text_in_mask(binary_mask, text, color)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        color = mplc.to_rgb(color)\n\n        # Check if the binary mask has holes\n        contours, _ = cv2.findContours(binary_mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n        if len(contours) > 1:\n            # Mask has holes, draw it using a different approach\n            for i, contour in enumerate(contours):\n                if cv2.contourArea(contour) < area_threshold:\n                    continue\n                mask = np.zeros_like(binary_mask)\n                cv2.drawContours(mask, contours, i, 1, -1)\n                self.draw_soft_mask(mask, color, text=text, alpha=alpha)\n        else:\n            # Regular mask without holes\n            rgba = np.zeros(binary_mask.shape + (4,), dtype=\"float32\")\n            rgba[:, :, :3] = color\n            rgba[:, :, 3] = binary_mask * alpha\n            self.output.ax.imshow(rgba, extent=(0, self.output.width, self.output.height, 0))\n\n            if text is not None:\n                lighter_color = self._change_color_brightness(color, brightness_factor=0.7)\n                self._draw_text_in_mask(binary_mask, text, lighter_color)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        color = mplc.to_rgb(color)\n\n        shape2d = (binary_mask.shape[0], binary_mask.shape[1])\n        rgba = np.zeros(shape2d + (4,), dtype=\"float32\")\n        rgba[:, :, :3] = color\n        rgba[:, :, 3] = binary_mask * alpha\n        self.output.ax.imshow(rgba, extent=(0, self.output.width, self.output.height, 0))\n\n        if text is not None:\n            lighter_color = self._change_color_brightness(color, brightness_factor=0.7)\n            binary_mask = (binary_mask > 0.5).astype(\"uint8\")\n            self._draw_text_in_mask(binary_mask, text, lighter_color)\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        color = mplc.to_rgb(color)\n\n        shape2d = (binary_mask.shape[0], binary_mask.shape[1])\n        rgba = np.zeros(shape2d + (4,), dtype=\"float32\")\n        rgba[:, :, :3] = color\n        rgba[:, :, 3] = binary_mask * alpha\n        self.output.ax.imshow(rgba, extent=(0, self.output.width, self.output.height, 0))\n\n        if text is not None:\n            lighter_color = self._change_color_brightness(color, brightness_factor=0.7)\n            binary_mask = (binary_mask > 0.5).astype(\"uint8\")\n            self._draw_text_in_mask(binary_mask, text, lighter_color)\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        color = mplc.to_rgb(color)\n\n        mask = binary_mask.astype(np.uint8)\n        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n        for contour in contours:\n            area = cv2.contourArea(contour)\n            if area < area_threshold:\n                continue\n\n            if edge_color is None:\n                edge_color = color\n            edge_color = mplc.to_rgb(edge_color)\n\n            polygon = mpl.patches.Polygon(\n                contour.reshape(-1, 2),\n                fill=True,\n                facecolor=color + (alpha,),\n                edgecolor=edge_color + (1,),\n                linewidth=max(self._default_font_size // 15 * self.output.scale, 1),\n            )\n            self.output.ax.add_patch(polygon)\n\n            if text is not None:\n                text_pos = contour[0][0]  # take the first point of the contour\n                self.draw_text(text, text_pos, color=edge_color)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        color = mplc.to_rgb(color)\n\n        rgba = np.zeros((binary_mask.shape[0], binary_mask.shape[1], 4), dtype=\"float32\")\n        rgba[:, :, :3] = color\n        rgba[:, :, 3] = binary_mask * alpha\n        self.output.ax.imshow(rgba, extent=(0, self.output.width, self.output.height, 0))\n\n        if text is not None:\n            lighter_color = self._change_color_brightness(color, brightness_factor=0.7)\n            binary_mask_uint8 = binary_mask.astype(\"uint8\")\n            self._draw_text_in_mask(binary_mask_uint8, text, lighter_color)\n        return self.output"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert torch.allclose(\n            input.image_size, other.image_size, rtol=rtol\n        ), f\"{msg}Image sizes do not match: {input.image_size} vs {other.image_size}\"\n    else:\n        assert input.image_size == other.image_size, f\"{msg}Image sizes do not match: {input.image_size} vs {other.image_size}\"\n\n    for field in input.get_fields():\n        if isinstance(getattr(input, field), Boxes):\n            assert torch.allclose(\n                getattr(input, field).tensor, getattr(other, field).tensor, rtol=rtol\n            ), f\"{msg}Field {field} does not match\"\n        elif isinstance(getattr(input, field), ROIMasks):\n            assert torch.allclose(\n                getattr(input, field).mask, getattr(other, field).mask, rtol=rtol\n            ), f\"{msg}Field {field} does not match\"\n        elif isinstance(getattr(input, field), torch.Tensor):\n            assert torch.allclose(\n                getattr(input, field), getattr(other, field), rtol=rtol\n            ), f\"{msg}Field {field} does not match\"\n        else:\n            assert getattr(input, field) == getattr(other, field), f\"{msg}Field {field} does not match\""}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances), \"input must be an Instances object\"\n    assert isinstance(other, Instances), \"other must be an Instances object\"\n\n    if size_as_tensor:\n        assert torch.equal(input.image_size, other.image_size), \"image sizes are not equal\"\n    else:\n        assert input.image_size == other.image_size, \"image sizes are not equal\"\n\n    assert input._fields == other._fields, \"fields of input and other are not the same\"\n\n    for field in input._fields:\n        input_val = getattr(input, field)\n        other_val = getattr(other, field)\n\n        if isinstance(input_val, Boxes):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), f\"{field} values are not close\"\n        elif isinstance(input_val, ROIMasks):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), f\"{field} values are not close\"\n        elif isinstance(input_val, torch.Tensor):\n            assert torch.allclose(input_val, other_val, rtol=rtol), f\"{field} values are not close\"\n        else:\n            assert input_val == other_val, f\"{field} values are not equal\""}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert torch.allclose(input.image_size, other.image_size, rtol=rtol), msg\n    else:\n        assert input.image_size == other.image_size, msg\n\n    for field in input.get_fields():\n        input_val = input[field]\n        other_val = other[field]\n        if isinstance(input_val, Boxes):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), msg\n        elif isinstance(input_val, ROIMasks):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), msg\n        elif isinstance(input_val, torch.Tensor):\n            assert torch.allclose(input_val, other_val, rtol=rtol), msg\n        else:\n            assert input_val == other_val, msg"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert torch.allclose(\n            input.image_size, other.image_size, rtol=rtol\n        ), f\"{msg}Image sizes do not match: {input.image_size} vs {other.image_size}\"\n    else:\n        assert input.image_size == other.image_size, f\"{msg}Image sizes do not match: {input.image_size} vs {other.image_size}\"\n\n    for field in input.get_fields():\n        input_val = input[field]\n        other_val = other[field]\n\n        if isinstance(input_val, Boxes):\n            assert torch.allclose(\n                input_val.tensor, other_val.tensor, rtol=rtol\n            ), f\"{msg}Field {field} does not match: {input_val} vs {other_val}\"\n        elif isinstance(input_val, ROIMasks):\n            assert torch.allclose(\n                input_val.tensor, other_val.tensor, rtol=rtol\n            ), f\"{msg}Field {field} does not match: {input_val} vs {other_val}\"\n        elif isinstance(input_val, torch.Tensor):\n            assert torch.allclose(\n                input_val, other_val, rtol=rtol\n            ), f\"{msg}Field {field} does not match: {input_val} vs {other_val}\"\n        else:\n            assert input_val == other_val, f\"{msg}Field {field} does not match: {input_val} vs {other_val}\""}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert torch.allclose(\n            input.image_size, other.image_size, rtol=rtol\n        ), f\"{msg}Image sizes do not match: {input.image_size} vs {other.image_size}\"\n    else:\n        assert input.image_size == other.image_size, f\"{msg}Image sizes do not match: {input.image_size} vs {other.image_size}\"\n\n    for field in input.get_fields():\n        input_val = input[field]\n        other_val = other[field]\n        if isinstance(input_val, Boxes):\n            assert torch.allclose(\n                input_val.tensor, other_val.tensor, rtol=rtol\n            ), f\"{msg}Field {field} does not match: {input_val.tensor} vs {other_val.tensor}\"\n        elif isinstance(input_val, ROIMasks):\n            assert torch.allclose(\n                input_val.tensor, other_val.tensor, rtol=rtol\n            ), f\"{msg}Field {field} does not match: {input_val.tensor} vs {other_val.tensor}\"\n        elif isinstance(input_val, torch.Tensor):\n            assert torch.allclose(\n                input_val, other_val, rtol=rtol\n            ), f\"{msg}Field {field} does not match: {input_val} vs {other_val}\"\n        else:\n            assert input_val == other_val, f\"{msg}Field {field} does not match: {input_val} vs {other_val}\""}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert torch.allclose(input.image_size, other.image_size, rtol=rtol), msg\n    else:\n        assert input.image_size == other.image_size, msg\n\n    for field in input.get_fields():\n        input_val = input[field]\n        other_val = other[field]\n\n        if isinstance(input_val, Boxes):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), msg\n        elif isinstance(input_val, ROIMasks):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), msg\n        elif isinstance(input_val, torch.Tensor):\n            assert torch.allclose(input_val, other_val, rtol=rtol), msg\n        else:\n            assert input_val == other_val, msg"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert torch.allclose(\n            input.image_size, other.image_size, rtol=rtol\n        ), f\"{msg}Image sizes do not match: {input.image_size} vs {other.image_size}\"\n    else:\n        assert input.image_size == other.image_size, f\"{msg}Image sizes do not match: {input.image_size} vs {other.image_size}\"\n\n    for field in input.get_fields():\n        if isinstance(input[field], Boxes):\n            assert torch.allclose(\n                input[field].tensor, other[field].tensor, rtol=rtol\n            ), f\"{msg}Field {field} does not match\"\n        elif isinstance(input[field], ROIMasks):\n            assert torch.allclose(\n                input[field].mask.tensor, other[field].mask.tensor, rtol=rtol\n            ), f\"{msg}Field {field} does not match\"\n        elif isinstance(input[field], torch.Tensor):\n            assert torch.allclose(\n                input[field], other[field], rtol=rtol\n            ), f\"{msg}Field {field} does not match\"\n        else:\n            assert input[field] == other[field], f\"{msg}Field {field} does not match\""}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert torch.allclose(\n            input.image_size, other.image_size, rtol=rtol\n        ), f\"{msg}Image sizes do not match: {input.image_size} vs {other.image_size}\"\n    else:\n        assert input.image_size == other.image_size, f\"{msg}Image sizes do not match: {input.image_size} vs {other.image_size}\"\n\n    for field in input.get_fields().keys():\n        input_val = getattr(input, field)\n        other_val = getattr(other, field)\n\n        if isinstance(input_val, Boxes):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), f\"{msg}Field {field} does not match\"\n        elif isinstance(input_val, ROIMasks):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), f\"{msg}Field {field} does not match\"\n        elif isinstance(input_val, torch.Tensor):\n            assert torch.allclose(input_val, other_val, rtol=rtol), f\"{msg}Field {field} does not match\"\n        else:\n            assert input_val == other_val, f\"{msg}Field {field} does not match\""}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert torch.allclose(\n            input.image_size, other.image_size, rtol=rtol\n        ), f\"{msg}Image sizes do not match: {input.image_size} vs {other.image_size}\"\n    else:\n        assert input.image_size == other.image_size, f\"{msg}Image sizes do not match: {input.image_size} vs {other.image_size}\"\n\n    for field in input.get_fields().keys():\n        input_val = input[field]\n        other_val = other[field]\n\n        if isinstance(input_val, Boxes):\n            assert torch.allclose(\n                input_val.tensor, other_val.tensor, rtol=rtol\n            ), f\"{msg}Field {field} does not match\"\n        elif isinstance(input_val, ROIMasks):\n            assert torch.allclose(\n                input_val.tensor, other_val.tensor, rtol=rtol\n            ), f\"{msg}Field {field} does not match\"\n        elif isinstance(input_val, torch.Tensor):\n            assert torch.allclose(\n                input_val, other_val, rtol=rtol\n            ), f\"{msg}Field {field} does not match\"\n        else:\n            assert input_val == other_val, f\"{msg}Field {field} does not match\""}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert torch.allclose(input.image_size, other.image_size, rtol=rtol), f\"{msg} Image sizes do not match!\"\n    else:\n        assert input.image_size == other.image_size, f\"{msg} Image sizes do not match!\"\n\n    for field in input._field_names:\n        input_val = getattr(input, field)\n        other_val = getattr(other, field)\n\n        if isinstance(input_val, Boxes):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), f\"{msg} Boxes do not match!\"\n        elif isinstance(input_val, ROIMasks):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), f\"{msg} ROIMasks do not match!\"\n        elif isinstance(input_val, torch.Tensor):\n            assert torch.allclose(input_val, other_val, rtol=rtol), f\"{msg} Tensors do not match!\"\n        else:\n            assert input_val == other_val, f\"{msg} Fields do not match!\""}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert torch.allclose(input.image_size, other.image_size, rtol=rtol), \\\n            f\"{msg}Image sizes do not match: {input.image_size} vs {other.image_size}\"\n    else:\n        assert input.image_size == other.image_size, \\\n            f\"{msg}Image sizes do not match: {input.image_size} vs {other.image_size}\"\n\n    for field in input._field_names:\n        input_val = getattr(input, field)\n        other_val = getattr(other, field)\n\n        if isinstance(input_val, Boxes):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), \\\n                f\"{msg}Field {field} does not match\"\n        elif isinstance(input_val, ROIMasks):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), \\\n                f\"{msg}Field {field} does not match\"\n        elif isinstance(input_val, torch.Tensor):\n            assert torch.allclose(input_val, other_val, rtol=rtol), \\\n                f\"{msg}Field {field} does not match\"\n        else:\n            assert input_val == other_val, \\\n                f\"{msg}Field {field} does not match\""}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances) and isinstance(other, Instances), \"input and other must be Instances\"\n    if size_as_tensor:\n        assert torch.equal(input.image_size, other.image_size), f\"{msg}image_size do not match\"\n    else:\n        assert input.image_size == other.image_size, f\"{msg}image_size do not match\"\n\n    assert input._fields == other._fields, f\"{msg}field names do not match\"\n\n    for field in input._fields:\n        input_val = getattr(input, field)\n        other_val = getattr(other, field)\n\n        if isinstance(input_val, Boxes):\n            assert input_val.tensor.shape == other_val.tensor.shape, f\"{msg}Boxes {field} do not match in shape\"\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), f\"{msg}Boxes {field} do not match\"\n        elif isinstance(input_val, ROIMasks):\n            assert torch.equal(input_val.tensor, other_val.tensor), f\"{msg}ROIMasks {field} do not match\"\n        elif isinstance(input_val, torch.Tensor):\n            assert input_val.shape == other_val.shape, f\"{msg}Tensor {field} do not match in shape\"\n            assert torch.allclose(input_val, other_val, rtol=rtol), f\"{msg}Tensor {field} do not match\"\n        else:\n            assert input_val == other_val, f\"{msg}Field {field} do not match\""}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert torch.allclose(\n            input.image_size, other.image_size, rtol=rtol\n        ), f\"{msg}Image sizes do not match: {input.image_size} vs {other.image_size}\"\n    else:\n        assert input.image_size == other.image_size, f\"{msg}Image sizes do not match: {input.image_size} vs {other.image_size}\"\n\n    assert input._fields == other._fields, f\"{msg}Field names do not match: {input._fields} vs {other._fields}\"\n    for field in input._fields:\n        input_val = getattr(input, field)\n        other_val = getattr(other, field)\n        if isinstance(input_val, Boxes):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), f\"{msg}Field {field} does not match\"\n        elif isinstance(input_val, ROIMasks):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), f\"{msg}Field {field} does not match\"\n        elif isinstance(input_val, torch.Tensor):\n            assert torch.allclose(input_val, other_val, rtol=rtol), f\"{msg}Field {field} does not match\"\n        else:\n            assert input_val == other_val, f\"{msg}Field {field} does not match\""}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert torch.allclose(\n            input.image_size, other.image_size, rtol=rtol\n        ), f\"{msg}image_size does not match\"\n    else:\n        assert input.image_size == other.image_size, f\"{msg}image_size does not match\"\n\n    for field in input.get_fields():\n        input_val = input[field]\n        other_val = other[field]\n\n        if isinstance(input_val, Boxes):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), f\"{msg}{field} does not match\"\n        elif isinstance(input_val, ROIMasks):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), f\"{msg}{field} does not match\"\n        elif isinstance(input_val, torch.Tensor):\n            assert torch.allclose(input_val, other_val, rtol=rtol), f\"{msg}{field} does not match\"\n        else:\n            assert input_val == other_val, f\"{msg}{field} does not match\""}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert torch.allclose(input.image_size, other.image_size, rtol=rtol), msg\n    else:\n        assert input.image_size == other.image_size, msg\n\n    assert input._fields == other._fields, msg\n    for field in input._fields:\n        if isinstance(getattr(input, field), (Boxes, ROIMasks)):\n            assert_instances_allclose(\n                getattr(input, field), getattr(other, field), rtol=rtol, msg=msg, size_as_tensor=size_as_tensor\n            )\n        elif isinstance(getattr(input, field), torch.Tensor):\n            assert torch.allclose(\n                getattr(input, field), getattr(other, field), rtol=rtol\n            ), f\"{msg} Field '{field}' does not match\"\n        else:\n            assert getattr(input, field) == getattr(other, field), f\"{msg} Field '{field}' does not match\""}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert torch.allclose(input.image_size, other.image_size, rtol=rtol), msg\n    else:\n        assert input.image_size == other.image_size, msg\n\n    for field in input.get_fields():\n        if isinstance(input[field], Boxes):\n            assert torch.allclose(input[field].tensor, other[field].tensor, rtol=rtol), msg\n        elif isinstance(input[field], ROIMasks):\n            assert torch.allclose(input[field].tensor, other[field].tensor, rtol=rtol), msg\n        elif isinstance(input[field], torch.Tensor):\n            assert torch.allclose(input[field], other[field], rtol=rtol), msg\n        else:\n            assert input[field] == other[field], msg"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert torch.allclose(input.image_size, other.image_size, rtol=rtol), f\"{msg}Image sizes do not match\"\n    else:\n        assert input.image_size == other.image_size, f\"{msg}Image sizes do not match\"\n\n    for field in input.get_fields():\n        input_val = input[field]\n        other_val = other[field]\n\n        if isinstance(input_val, Boxes):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), f\"{msg}Field {field} does not match\"\n        elif isinstance(input_val, ROIMasks):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), f\"{msg}Field {field} does not match\"\n        elif isinstance(input_val, torch.Tensor):\n            assert torch.allclose(input_val, other_val, rtol=rtol), f\"{msg}Field {field} does not match\"\n        else:\n            assert input_val == other_val, f\"{msg}Field {field} does not match\""}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    # Check if image sizes are the same\n    if size_as_tensor:\n        assert torch.allclose(input.image_size, other.image_size, rtol=rtol), msg\n    else:\n        assert input.image_size == other.image_size, msg\n\n    # Check if all fields are equal or close to each other\n    for field in input.get_fields():\n        input_val = input.get(field)\n        other_val = other.get(field)\n\n        if isinstance(input_val, Boxes):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), msg\n        elif isinstance(input_val, ROIMasks):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), msg\n        elif isinstance(input_val, torch.Tensor):\n            assert torch.allclose(input_val, other_val, rtol=rtol), msg\n        else:\n            assert input_val == other_val, msg"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert torch.allclose(input.image_size, other.image_size, rtol=rtol), msg\n    else:\n        assert input.image_size == other.image_size, msg\n\n    assert input._fields == other._fields, \"Instances have different fields!\"\n\n    for field in input._fields:\n        input_val = getattr(input, field)\n        other_val = getattr(other, field)\n\n        if isinstance(input_val, Boxes):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), f\"{msg} Field '{field}' does not match!\"\n        elif isinstance(input_val, ROIMasks):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), f\"{msg} Field '{field}' does not match!\"\n        elif isinstance(input_val, torch.Tensor):\n            assert torch.allclose(input_val, other_val, rtol=rtol), f\"{msg} Field '{field}' does not match!\"\n        else:\n            assert input_val == other_val, f\"{msg} Field '{field}' does not match!\""}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert torch.allclose(\n            input.image_size, other.image_size, rtol=rtol\n        ), f\"{msg}image_size do not match\"\n\n    else:\n        assert input.image_size == other.image_size, f\"{msg}image_size do not match\"\n\n    assert input._fields == other._fields, f\"{msg}field names do not match\"\n\n    for field in input._fields:\n        input_val = getattr(input, field)\n        other_val = getattr(other, field)\n\n        if isinstance(input_val, Boxes):\n            assert torch.allclose(\n                input_val.tensor, other_val.tensor, rtol=rtol\n            ), f\"{msg}field {field} does not match\"\n\n        elif isinstance(input_val, ROIMasks):\n            assert torch.allclose(\n                input_val.tensor, other_val.tensor, rtol=rtol\n            ), f\"{msg}field {field} does not match\"\n\n        elif isinstance(input_val, torch.Tensor):\n            assert torch.allclose(\n                input_val, other_val, rtol=rtol\n            ), f\"{msg}field {field} does not match\"\n\n        else:\n            assert input_val == other_val, f\"{msg}field {field} does not match\""}
{"namespace": "detectron2.utils.registry.locate", "completion": "    obj = pydoc.locate(name)\n    if obj is not None:\n        return obj\n    else:\n        raise ImportError(f\"Could not locate object: {name}\")"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    obj = pydoc.locate(name)\n    if obj is None:\n        raise ImportError(f\"Error locating object: {name}\")\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "\n    obj = pydoc.locate(name)\n    if obj is None:\n        raise ImportError(f\"Error locating object: {name}\")\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "\n    obj = pydoc.locate(name)\n    if obj is not None:\n        return obj\n    else:\n        raise ImportError(f\"Could not locate object: {name}\")"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    obj = pydoc.locate(name)\n    if obj is None:\n        raise ImportError(f\"Error locating object: {name}\")\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "\n    try:\n        obj = pydoc.locate(name)\n        if obj is not None:\n            return obj\n    except ImportError:\n        pass\n\n    parts = name.split(\".\")\n    module_name = \".\".join(parts[:-1])\n    obj_name = parts[-1]\n\n    try:\n        module = __import__(module_name, fromlist=[obj_name])\n        obj = getattr(module, obj_name)\n        return obj\n    except (ImportError, AttributeError):\n        raise ImportError(f\"Error locating object: {name}\")"}
{"namespace": "detectron2.utils.registry.locate", "completion": "\n    obj = pydoc.locate(name)\n    if obj is None:\n        raise ImportError(f\"Error locating object: {name}\")\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "\n    obj = pydoc.locate(name)\n    if obj is None:\n        raise ImportError(f\"Error locating object: {name}\")\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    obj = pydoc.locate(name)\n    if obj is None:\n        raise ImportError(f\"Error locating object {name}\")\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "\n    obj = pydoc.locate(name)\n    if obj is None:\n        raise ImportError(f\"Error locating object {name}\")\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    obj = pydoc.locate(name)\n    if obj is None:\n        raise ImportError(f\"Error locating object: {name}\")\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    obj = pydoc.locate(name)\n    if obj is None:\n        raise ImportError(f\"Error locating object: {name}\")\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    obj = pydoc.locate(name)\n    if obj is None:\n        raise ImportError(f\"Error locating object: {name}\")\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    obj = pydoc.locate(name)\n    if obj is None:\n        raise ImportError(f\"Error locating object: {name}\")\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    obj = pydoc.locate(name)\n    if obj is None:\n        raise ImportError(f\"Error locating object: {name}\")\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    obj = pydoc.locate(name)\n    if obj is None:\n        raise ImportError(f\"Error locating object: {name}\")\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    obj = pydoc.locate(name)\n    if obj is None:\n        raise ImportError(f\"Error locating object '{name}'\")\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    obj = pydoc.locate(name)\n    if obj is None:\n        raise ImportError(f\"Error locating object: {name}\")\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    obj = pydoc.locate(name)\n    if obj is None:\n        raise ImportError(f\"Error locating object: {name}\")\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    obj = pydoc.locate(name)\n    if obj is None:\n        raise ImportError(f\"Error locating object with name {name}\")\n    return obj"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMSEG_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMSEG_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMSEG_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMSEG_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMSEG_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError(f\"Segmentor model of type {cfg['type']} is not implemented\")"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError(f\"Segmentor {cfg['type']} is not implemented yet\")"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError(f\"Segmentor model of type '{cfg['type']}' is not implemented.\")"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError(f\"Segmentor {cfg['type']} is not implemented yet\")"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError(f\"Segmentor model of type '{cfg['type']}' is not implemented in the registry.\")"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError(f\"Segmentor model of type {cfg['type']} is not implemented.\")"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError(f\"Segmentor model of type {cfg['type']} is not implemented in the registry.\")"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError(f\"Segmentor model of type '{cfg['type']}' is not implemented.\")"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError(f\"Segmentor model of type '{cfg['type']}' is not implemented.\")"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError(f\"Segmentor model of type {cfg['type']} is not implemented yet.\")"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError(f\"Segmentor {cfg['type']} is not implemented yet\")"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError(f\"Segmentor model of type {cfg['type']} is not implemented yet\")"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError(f\"Segmentor {cfg['type']} is not implemented yet\")"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError(f\"Segmentor model of type '{cfg['type']}' is not implemented yet.\")"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError(f\"Segmentor model of type '{cfg['type']}' is not implemented yet.\")"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError(f\"Segmentor model of type {cfg['type']} is not implemented yet.\")"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    return val - torch.floor(val / period + offset) * period"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    return val - torch.floor(val / period + offset) * period"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    return val - torch.floor(val / period + offset) * period"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    return val - torch.floor(val / period + offset) * period"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    return val - torch.floor(val / period + offset) * period"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    return val - torch.floor(val / period + offset) * period"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    return val - torch.floor(val / period + offset) * period"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    return val - torch.floor(val / period + offset) * period"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    return val - torch.floor(val / period + offset) * period"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    return val - torch.floor(val / period + offset) * period"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    return (val - offset * period) % period + offset * period"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    return val - torch.floor(val / period + offset) * period"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    return (val - period * offset) % period - period * offset"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    return val - torch.floor(val / period + offset) * period"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    return val - torch.floor(val / period + offset) * period"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    return val - torch.floor(val / period + offset) * period"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    return val - torch.floor(val / period + offset) * period"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    return val - torch.floor(val / period + offset) * period"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    return val - torch.floor(val / period + offset) * period"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    return val - torch.floor(val / period + offset) * period"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    pred = {}\n    gt = {}\n    for anno in gt_annos:\n        gt[anno['image_idx']] = {\n            'bbox': anno['gt_boxes'],\n            'score': np.ones(len(anno['gt_boxes']))\n        }\n    for anno in dt_annos:\n        pred[anno['image_idx']] = [\n            (box, score) for box, score, label in zip(anno['boxes_3d'],\n                                                     anno['score'],\n                                                     anno['label'])\n        ]\n    pred = {k: v for k, v in pred.items() if k in gt}\n    gt = {k: v for k, v in gt.items() if k in pred}\n    ovthresh = metric\n    ret = eval_map_recall(pred, gt, ovthresh)\n    result = {}\n    result['class-wise AP'] = {}\n    result['class-wise AR'] = {}\n    for iou_idx, thresh in enumerate(ovthresh):\n        result['class-wise AP'][thresh] = {}\n        result['class-wise AR'][thresh] = {}\n        for label, cat in label2cat.items():\n            if label in ret[0]:\n                result['class-wise AP'][thresh][cat] = ret[2][iou_idx][label][0]\n                result['class-wise AR'][thresh][cat] = ret[0][iou_idx][label][0]\n            else:\n                result['class-wise AP'][thresh][cat] = 0\n                result['class-wise AR'][thresh][cat] = 0\n    result['mAP'] = {}\n    result['mAR'] = {}\n    for iou_idx, thresh in enumerate(ovthresh):\n        result['mAP'][thresh] = np.mean(\n            [result['class-wise AP'][thresh][cat] for cat in label2cat.values()])\n        result['mAR'][thresh] = np.mean(\n            [result['class-wise AR'][thresh][cat] for cat in label2cat.values()])\n    if logger is not None:\n        if isinstance(logger, str):\n            print_log(f\"mAP and mAR at IoU threshold {ovthresh}:\", logger)\n            table_data = [['IoU Threshold', 'mAP', 'mAR']]\n            for iou_idx, thresh in enumerate(ovthresh):\n                table_data.append([thresh, result['mAP'][thresh], result['mAR'][thresh]])\n            table = AsciiTable(table_data)\n            print_log(table.table, logger)\n        else:\n            logger.info(f\"mAP and mAR at IoU threshold {ovthresh}:\")\n            table_data = [['IoU Threshold', 'mAP', 'mAR']]\n            for iou_idx, thresh in enumerate(ovthresh):\n                table_data.append([thresh, result['mAP'][thresh], result['mAR'][thresh]])\n            table = AsciiTable(table_data)\n            logger.info(table.table)\n    return result"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "\n    # Evaluation code goes here\n    # ...\n    # ...\n    # ...\n\n    return evaluation_results"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    pred = {}\n    gt = {}\n    for i in range(len(gt_annos)):\n        gt_anno = gt_annos[i]\n        dt_anno = dt_annos[i]\n        for j in range(len(gt_anno['name'])):\n            cls_name = label2cat[gt_anno['name'][j]]\n            if cls_name not in gt:\n                gt[cls_name] = {}\n                pred[cls_name] = {}\n            gt[cls_name][gt_anno['image_idx']] = gt_anno['bbox'][j]\n        for j in range(len(dt_anno['name'])):\n            cls_name = label2cat[dt_anno['name'][j]]\n            if cls_name not in pred:\n                pred[cls_name] = {}\n            pred[cls_name][dt_anno['image_idx']] = dt_anno['bbox'][j]\n\n    ovthresh = metric\n    recall, precision, ap = eval_map_recall(pred, gt, ovthresh)\n\n    # calculate mAP and mAR\n    mAP = {}\n    mAR = {}\n    for i, thresh in enumerate(ovthresh):\n        mAP[thresh] = {}\n        mAR[thresh] = {}\n        for cls in ap[i].keys():\n            mAP[thresh][cls] = np.mean(ap[i][cls])\n            mAR[thresh][cls] = np.mean(recall[i][cls])\n\n    # calculate mean mAP and mAR\n    mean_mAP = np.mean([np.mean(list(mAP[thresh].values()))\n                        for thresh in ovthresh])\n    mean_mAR = np.mean([np.mean(list(mAR[thresh].values()))\n                        for thresh in ovthresh])\n\n    # organize evaluation results into a dictionary\n    eval_results = {\n        'mAP': mAP,\n        'mAR': mAR,\n        'mean_mAP': mean_mAP,\n        'mean_mAR': mean_mAR\n    }\n\n    # print the evaluation results in a formatted table\n    if logger is not None:\n        table_data = [['IoU Threshold', 'Class', 'AP', 'AR']]\n        for i, thresh in enumerate(ovthresh):\n            for cls in ap[i].keys():\n                table_data.append([thresh, cls, mAP[thresh][cls], mAR[thresh][cls]])\n        table_data.append(['', 'Mean', mean_mAP, mean_mAR])\n        table = AsciiTable(table_data)\n        print_log(table.table, logger=logger)\n\n    return eval_results"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    pred = {}\n    gt = {}\n    for anno in dt_annos:\n        if anno['name'] not in pred:\n            pred[anno['name']] = []\n        pred[anno['name']].append((anno['bbox'], anno['score']))\n    for anno in gt_annos:\n        if anno['name'] not in gt:\n            gt[anno['name']] = []\n        gt[anno['name']].append(anno['bbox'])\n\n    ovthresh = metric\n    recall, precision, ap = eval_map_recall(pred, gt, ovthresh)\n\n    if logger is not None:\n        if isinstance(logger, str):\n            print_log(f\"Evaluating {len(gt_annos)} samples\", logger=logger)\n            table_data = [['Class', 'IoU', 'AP', 'AR']]\n            for i, ov in enumerate(ovthresh):\n                for label, cat in label2cat.items():\n                    table_data.append([cat, ov, ap[i][label][0], recall[i][label][0]])\n            table = AsciiTable(table_data)\n            print_log(table.table, logger=logger)\n\n    ret = {\n        'recall': recall,\n        'precision': precision,\n        'ap': ap\n    }\n    return ret"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    pred = {}\n    gt = {}\n\n    for i, (gt_anno, dt_anno) in enumerate(zip(gt_annos, dt_annos)):\n        if 'name' not in gt_anno:\n            gt_anno['name'] = label2cat[gt_anno['label']]\n        if 'name' not in dt_anno:\n            dt_anno['name'] = label2cat[dt_anno['label']]\n        if gt_anno['name'] not in gt:\n            gt[gt_anno['name']] = {}\n            pred[gt_anno['name']] = {}\n        if gt_anno['name'] not in pred:\n            pred[gt_anno['name']] = {}\n            gt[gt_anno['name']] = {}\n\n        if i not in gt[gt_anno['name']]:\n            gt[gt_anno['name']][i] = []\n        if i not in pred[gt_anno['name']]:\n            pred[gt_anno['name']][i] = []\n\n        gt[gt_anno['name']][i] = gt_anno\n        pred[gt_anno['name']][i] = dt_anno\n\n    ovthresh = metric\n    ret = eval_map_recall(pred, gt, ovthresh)\n\n    if logger is not None:\n        if isinstance(logger, str):\n            print_log(f'\\nEvaluation results of {len(gt_annos)} scenes\\n', logger=logger)\n            for iou_idx, thresh in enumerate(ovthresh):\n                print_log(f'IoU Thr: {thresh:.2f}', logger=logger)\n                table_data = [['class', 'ap', 'ar']]\n                for k, v in ret[2][iou_idx].items():\n                    table_data.append([k, f'{v[0]:.4f}', f'{v[1]:.4f}'])\n                table = AsciiTable(table_data)\n                print_log(table.table, logger=logger)\n        else:\n            logger.info(f'\\nEvaluation results of {len(gt_annos)} scenes\\n')\n            for iou_idx, thresh in enumerate(ovthresh):\n                logger.info(f'IoU Thr: {thresh:.2f}')\n                table_data = [['class', 'ap', 'ar']]\n                for k, v in ret[2][iou_idx].items():\n                    table_data.append([k, f'{v[0]:.4f}', f'{v[1]:.4f}'])\n                table = AsciiTable(table_data)\n                logger.info(table.table)\n\n    return ret[0], ret[1], ret[2]"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    pred = {}\n    gt = {}\n    for i in range(len(gt_annos)):\n        gt_anno = gt_annos[i]\n        dt_anno = dt_annos[i]\n        for j in range(len(gt_anno['name'])):\n            gt_boxes = gt_anno['bbox'][j]\n            name = gt_anno['name'][j]\n            if name not in gt:\n                gt[name] = {}\n                pred[name] = {}\n            gt_boxes = gt_boxes.reshape(-1, 4)\n            gt_labels = np.zeros(gt_boxes.shape[0])\n            if 'difficulty' in gt_anno:\n                difficulty = gt_anno['difficulty'][j]\n                gt_labels[difficulty == 2] = -1\n            if name not in gt[name]:\n                gt[name] = {'bbox': gt_boxes, 'det': np.zeros(gt_boxes.shape[0])}\n            else:\n                gt[name]['bbox'] = np.vstack((gt[name]['bbox'], gt_boxes))\n                gt[name]['det'] = np.hstack((gt[name]['det'], np.zeros(gt_boxes.shape[0])))\n        for j in range(len(dt_anno['name'])):\n            dt_boxes = dt_anno['bbox'][j]\n            name = dt_anno['name'][j]\n            if name not in pred:\n                pred[name] = {}\n            dt_boxes = dt_boxes.reshape(-1, 4)\n            scores = dt_anno['score'][j].reshape(-1, 1)\n            if name not in pred:\n                pred[name] = {'bbox': dt_boxes, 'score': scores}\n            else:\n                pred[name]['bbox'] = np.vstack((pred[name]['bbox'], dt_boxes))\n                pred[name]['score'] = np.vstack((pred[name]['score'], scores))\n\n    ovthresh = metric\n    ret = eval_map_recall(pred, gt, ovthresh)\n\n    if logger is not None:\n        if isinstance(logger, str):\n            logger = print_log\n\n        table_data = [['class', 'AP'] + [f'AR@{thresh}' for thresh in ovthresh]]\n        for label, ap_list, ar_list in zip(label2cat, ret[2], ret[0]):\n            row_data = [label, f'{np.mean(ap_list):.4f}']\n            for ar in ar_list:\n                row_data.append(f'{np.mean(ar):.4f}')\n            table_data.append(row_data)\n\n        table = AsciiTable(table_data)\n        logger(table.table)\n\n    ap_dict = {}\n    for label, ap_list in zip(label2cat, ret[2]):\n        ap_dict[label] = np.mean(ap_list)\n\n    ret_dict = {\n        'ap': ap_dict,\n        'map': np.mean([np.mean(ap_list) for ap_list in ret[2]]),\n        'ar': {f'ar@{thresh}': {label: np.mean(ar_list) for label, ar_list in zip(label2cat, ret[0][i])} for i, thresh in enumerate(ovthresh)}\n    }\n\n    return ret_dict"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    pred = {}\n    gt = {}\n    for anno in dt_annos:\n        image_id = anno['image_idx']\n        if image_id not in pred:\n            pred[image_id] = []\n        if 'name' in anno:\n            label = anno['name']\n        else:\n            label = anno['label']\n        bbox = anno['bbox']\n        score = anno['score']\n        pred[image_id].append((bbox, score))\n\n    for anno in gt_annos:\n        image_id = anno['image_idx']\n        if image_id not in gt:\n            gt[image_id] = []\n        if 'name' in anno:\n            label = anno['name']\n        else:\n            label = anno['label']\n        bbox = anno['bbox']\n        gt[image_id].append((bbox, label))\n\n    pred_cat = {}\n    gt_cat = {}\n    for image_id in pred:\n        if image_id not in gt:\n            gt[image_id] = []\n        if image_id not in pred_cat:\n            pred_cat[image_id] = []\n        if image_id not in gt_cat:\n            gt_cat[image_id] = []\n        for bbox, label in pred[image_id]:\n            pred_cat[image_id].append((bbox, label2cat[label]))\n        for bbox, label in gt[image_id]:\n            gt_cat[image_id].append((bbox, label2cat[label]))\n\n    ovthresh = metric\n    ret = eval_map_recall(pred_cat, gt_cat, ovthresh)\n\n    if logger is not None:\n        if isinstance(logger, str):\n            logger = print_log\n        table_data = [['class', 'AP', 'AR']]\n        for iou_idx, thresh in enumerate(ovthresh):\n            for label in ret[2][iou_idx]:\n                table_data.append(\n                    [label, ret[2][iou_idx][label], ret[0][iou_idx][label]])\n            table = AsciiTable(table_data)\n            logger(table.table)\n\n    ap = {}\n    ar = {}\n    for iou_idx, thresh in enumerate(ovthresh):\n        ap[thresh] = {}\n        ar[thresh] = {}\n        for label in ret[2][iou_idx]:\n            ap[thresh][label] = ret[2][iou_idx][label]\n            ar[thresh][label] = ret[0][iou_idx][label]\n\n    mAP = {}\n    mAR = {}\n    for iou_idx, thresh in enumerate(ovthresh):\n        mAP[thresh] = np.mean(list(ap[thresh].values()))\n        mAR[thresh] = np.mean(list(ar[thresh].values()))\n\n    return {'mAP': mAP, 'mAR': mAR, 'AP': ap, 'AR': ar}"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    pred = {}\n    gt = {}\n    for anno in gt_annos:\n        img_id = anno['image_idx']\n        if img_id not in gt:\n            gt[img_id] = []\n        gt[img_id].append(anno)\n    for anno in dt_annos:\n        img_id = anno['image_idx']\n        if img_id not in pred:\n            pred[img_id] = []\n        pred[img_id].append(anno)\n    \n    pred_mapped = {}\n    gt_mapped = {}\n    for img_id in pred:\n        pred_mapped[img_id] = []\n        for det in pred[img_id]:\n            label = det['name']\n            if label in label2cat:\n                label = label2cat[label]\n            else:\n                raise ValueError(f\"Label {label} not found in label2cat mapping\")\n            pred_mapped[img_id].append((det['bbox'], det['score'], label))\n    for img_id in gt:\n        gt_mapped[img_id] = []\n        for det in gt[img_id]:\n            label = det['name']\n            if label in label2cat:\n                label = label2cat[label]\n            else:\n                raise ValueError(f\"Label {label} not found in label2cat mapping\")\n            gt_mapped[img_id].append((det['bbox'], label))\n\n    recall, precision, ap = eval_map_recall(pred_mapped, gt_mapped, metric)\n\n    if logger is not None:\n        table_data = [['Class', 'AP'] + [f'AR@{iou}' for iou in metric]]\n        for label in ap[0].keys():\n            ap_values = [ap[i][label] for i in range(len(ap))]\n            ar_values = [recall[i][label][-1] for i in range(len(recall))]\n            table_data.append([label, np.mean(ap_values)] + ar_values)\n        table = AsciiTable(table_data)\n        print_log(table.table, logger=logger)\n\n    results = {'AP': ap, 'AR': recall}\n    return results"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    pred = {}\n    gt = {}\n    for anno in gt_annos:\n        img_id = anno['image']['image_id']\n        gt_boxes = anno['annos']\n        if len(gt_boxes) > 0:\n            gt[img_id] = []\n            for box in gt_boxes:\n                label = label2cat[box['name']]\n                gt[img_id].append({'bbox': box['bbox'], 'label': label})\n    for anno in dt_annos:\n        img_id = anno['image']['image_id']\n        dt_boxes = anno['annos']\n        if len(dt_boxes) > 0:\n            pred[img_id] = []\n            for box in dt_boxes:\n                label = label2cat[box['name']]\n                pred[img_id].append({'bbox': box['bbox'], 'label': label, 'score': box['score']})\n\n    ovthresh = metric\n    recall, precision, ap = eval_map_recall(pred, gt, ovthresh)\n\n    mAP = {}\n    mAR = {}\n    for i, thresh in enumerate(ovthresh):\n        mAP[f'mAP@{thresh}'] = np.mean([ap[i][label][0] for label in ap[i]])\n        mAR[f'mAR@{thresh}'] = np.mean([recall[i][label][0] for label in recall[i]])\n\n    results = {'mAP': mAP, 'mAR': mAR}\n\n    if logger:\n        if isinstance(logger, str):\n            print_log(f\"mAP: {mAP}\", logger=logger)\n            print_log(f\"mAR: {mAR}\", logger=logger)\n        else:\n            logger.info(f\"mAP: {mAP}\")\n            logger.info(f\"mAR: {mAR}\")\n\n    return results"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    pred = {}\n    gt = {}\n    for i in range(len(gt_annos)):\n        gt_anno = gt_annos[i]\n        dt_anno = dt_annos[i]\n        for j in range(len(gt_anno['name'])):\n            gt_name = gt_anno['name'][j]\n            dt_name = dt_anno['name'][j]\n            cat = label2cat[gt_name]\n            if cat not in gt:\n                gt[cat] = {}\n                pred[cat] = {}\n            gt[cat][i] = {'bbox': gt_anno['bbox'][j]}\n            pred[cat][i] = [(dt_anno['bbox'][j], dt_anno['score'][j])]\n    ovthresh = metric\n    recall, precision, ap = eval_map_recall(pred, gt, ovthresh)\n    ap_str = ''\n    ar_str = ''\n    table_data = [['Class', 'AP'] + [f'AR @{thresh}' for thresh in ovthresh]]\n    for i, cat in enumerate(gt.keys()):\n        ap_str += f'{label2cat[cat]} AP: {ap[0][cat][0]:.4f}\\n'\n        ar_str += f'{label2cat[cat]} AR: {recall[0][cat][0]:.4f}\\n'\n        table_data.append([label2cat[cat], f'{ap[0][cat][0]:.4f}'] +\n                          [f'{recall[j][cat][0]:.4f}' for j in range(len(ovthresh))])\n    mAP = np.mean([ap[0][cat][0] for cat in gt.keys()])\n    mAR = np.mean([recall[0][cat][0] for cat in gt.keys()])\n    ap_str += f'mAP: {mAP:.4f}\\n'\n    ar_str += f'mAR: {mAR:.4f}\\n'\n    table_data.append(['mAP', f'{mAP:.4f}'] + [f'{mAR:.4f}' for _ in range(len(ovthresh))])\n    if logger is not None:\n        if isinstance(logger, str):\n            print_log(ap_str + ar_str, logger)\n            table = AsciiTable(table_data)\n            print_log('\\n' + table.table, logger)\n        else:\n            logger.info(ap_str + ar_str)\n            table = AsciiTable(table_data)\n            logger.info('\\n' + table.table)\n    return {'mAP': mAP, 'mAR': mAR, 'AP': ap, 'AR': recall}"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    pred = {}\n    gt = {}\n    for anno in gt_annos:\n        img_id = anno['image']['image_idx']\n        if 'name' in anno['image']:\n            img_name = anno['image']['name']\n        else:\n            img_name = str(img_id)\n        gt[img_name] = []\n        for i in range(anno['gt_boxes'].shape[0]):\n            box = anno['gt_boxes'][i]\n            label = label2cat[anno['gt_names'][i]]\n            gt[img_name].append({'bbox': box, 'class': label})\n\n    for anno in dt_annos:\n        img_id = anno['image']['image_idx']\n        if 'name' in anno['image']:\n            img_name = anno['image']['name']\n        else:\n            img_name = str(img_id)\n        pred[img_name] = []\n        for i in range(anno['pred_boxes'].shape[0]):\n            box = anno['pred_boxes'][i]\n            score = anno['scores'][i]\n            label = label2cat[anno['pred_names'][i]]\n            pred[img_name].append((box, score, label))\n\n    ovthresh = metric\n    recall, precision, ap = eval_map_recall(pred, gt, ovthresh)\n\n    ret = {}\n    for iou_idx, thresh in enumerate(ovthresh):\n        ret[f'recall_{thresh}'] = recall[iou_idx]\n        ret[f'precision_{thresh}'] = precision[iou_idx]\n        ret[f'ap_{thresh}'] = ap[iou_idx]\n\n    if logger is not None:\n        mAPs = [np.mean(ap[i]) for i in range(len(ap))]\n        mARs = [np.mean(recall[i]) for i in range(len(recall))]\n        table_data = [['IoU Threshold', 'mAP', 'mAR']]\n        for i in range(len(ovthresh)):\n            table_data.append([ovthresh[i], mAPs[i], mARs[i]])\n        table = AsciiTable(table_data)\n        print_log('\\n' + table.table, logger=logger)\n\n    return ret"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    pred = {}\n    gt = {}\n    for anno in gt_annos:\n        img_id = anno['image']['image_id']\n        if 'annos' in anno:\n            gt[img_id] = anno['annos']\n        else:\n            gt[img_id] = []\n\n    for anno in dt_annos:\n        img_id = anno['image']['image_id']\n        if 'annos' in anno:\n            pred[img_id] = anno['annos']\n        else:\n            pred[img_id] = []\n\n    ovthresh = metric\n    ret = eval_map_recall(pred, gt, ovthresh)\n\n    aps = {}\n    ars = {}\n    for i, thresh in enumerate(ovthresh):\n        aps[thresh] = {}\n        ars[thresh] = {}\n        for label, cat in label2cat.items():\n            aps[thresh][cat] = ret[2][i][label][0]\n            ars[thresh][cat] = ret[0][i][label][0]\n\n    mAPs = {thresh: np.mean(list(aps[thresh].values())) for thresh in ovthresh}\n    mARs = {thresh: np.mean(list(ars[thresh].values())) for thresh in ovthresh}\n\n    if logger is not None:\n        table_data = [['IoU Threshold', 'mAP', 'mAR']]\n        for thresh in ovthresh:\n            table_data.append([str(thresh), f'{mAPs[thresh]:.4f}', f'{mARs[thresh]:.4f}'])\n        table = AsciiTable(table_data)\n        print_log(table.table, logger=logger)\n\n    return {'mAP': mAPs, 'mAR': mARs, 'APs': aps, 'ARs': ars}"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    pred = {}\n    gt = {}\n    for anno in dt_annos:\n        image_id = anno[\"image\"][\"image_id\"]\n        if image_id not in pred:\n            pred[image_id] = []\n        pred[image_id].append((anno[\"bbox\"], anno[\"score\"]))\n\n    for anno in gt_annos:\n        image_id = anno[\"image\"][\"image_id\"]\n        if image_id not in gt:\n            gt[image_id] = []\n        gt[image_id].append(anno[\"bbox\"])\n\n    ovthresh = metric\n    ret = eval_map_recall(pred, gt, ovthresh)\n\n    if logger is not None:\n        if isinstance(logger, str):\n            logger = print_log\n\n        table_data = [[\"class\", \"AP\", \"AR\"]]\n        for label, ap in ret[2].items():\n            ap_str = f\"{ap[0]:.3f}\" if not np.isnan(ap[0]) else \"NaN\"\n            ar_str = f\"{ret[0][0][label][0]:.3f}\" if not np.isnan(ret[0][0][label][0]) else \"NaN\"\n            table_data.append([label2cat[label], ap_str, ar_str])\n\n        table = AsciiTable(table_data)\n        logger(table.table)\n\n    return {\n        \"ap\": ret[2],\n        \"ar\": ret[0],\n        \"map\": np.nanmean(ret[2]),\n        \"mar\": np.nanmean(ret[0][0])\n    }"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    pred = {}\n    gt = {}\n    for i in range(len(gt_annos)):\n        if 'name' not in gt_annos[i]:\n            continue\n        if gt_annos[i]['name'] not in gt:\n            gt[gt_annos[i]['name']] = []\n            pred[gt_annos[i]['name']] = []\n        gt[gt_annos[i]['name']].append(gt_annos[i])\n    for i in range(len(dt_annos)):\n        if 'name' not in dt_annos[i]:\n            continue\n        if dt_annos[i]['name'] not in pred:\n            pred[dt_annos[i]['name']] = []\n            gt[dt_annos[i]['name']] = []\n        pred[dt_annos[i]['name']].append(dt_annos[i])\n\n    ovthresh = metric\n    ret = eval_map_recall(pred, gt, ovthresh)\n    ap_strs = []\n    ar_strs = []\n    for i, ovthresh in enumerate(metric):\n        ap_str = f'mAP@{ovthresh}'\n        ar_str = f'mAR@{ovthresh}'\n        aps = []\n        ars = []\n        for k, v in ret[2][i].items():\n            aps.append(v[0])\n            ars.append(ret[0][i][k][-1])\n        map = np.mean(aps)\n        mar = np.mean(ars)\n        ap_strs.append((ap_str, map))\n        ar_strs.append((ar_str, mar))\n\n    ap_strs.append(('mAP', np.mean([ap for _, ap in ap_strs])))\n    ar_strs.append(('mAR', np.mean([ar for _, ar in ar_strs])))\n\n    if logger is not None:\n        if isinstance(logger, str):\n            print_log(f\"Eval 3D bounding boxes\", logger=logger)\n            table_data = [['Class', 'AP', 'AR']]\n            for k, v in ret[2][0].items():\n                table_data.append([label2cat[k], v[0], ret[0][0][k][-1]])\n            table_data.append(['mAP', ap_strs[-1][1], ''])\n            table_data.append(['mAR', ar_strs[-1][1], ''])\n            table = AsciiTable(table_data)\n            print_log('\\n' + table.table, logger=logger)\n        else:\n            logger.info(f\"Eval 3D bounding boxes\")\n            table_data = [['Class', 'AP', 'AR']]\n            for k, v in ret[2][0].items():\n                table_data.append([label2cat[k], v[0], ret[0][0][k][-1]])\n            table_data.append(['mAP', ap_strs[-1][1], ''])\n            table_data.append(['mAR', ar_strs[-1][1], ''])\n            table = AsciiTable(table_data)\n            logger.info('\\n' + table.table)\n\n    return dict(ap_strs + ar_strs)"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    pred = {}\n    gt = {}\n    for anno in gt_annos:\n        img_id = anno['image']['image_idx']\n        gt[img_id] = []\n        for obj in anno['annos']:\n            if obj['name'] in label2cat:\n                cat = label2cat[obj['name']]\n                bbox = obj['bbox']\n                gt[img_id].append({'bbox': bbox, 'category_id': cat})\n\n    for anno in dt_annos:\n        img_id = anno['image']['image_idx']\n        pred[img_id] = []\n        for obj in anno['annos']:\n            if obj['name'] in label2cat:\n                cat = label2cat[obj['name']]\n                bbox = obj['bbox']\n                score = obj['score']\n                pred[img_id].append({'bbox': bbox, 'score': score, 'category_id': cat})\n\n    ovthresh = metric\n    recall, precision, ap = eval_map_recall(pred, gt, ovthresh)\n\n    ret = {}\n    for iou_idx, thresh in enumerate(ovthresh):\n        ret[f'recall@{thresh:.2f}'] = {}\n        ret[f'precision@{thresh:.2f}'] = {}\n        ret[f'AP@{thresh:.2f}'] = {}\n        for label, category in label2cat.items():\n            ret[f'recall@{thresh:.2f}'][category] = recall[iou_idx][label][0]\n            ret[f'precision@{thresh:.2f}'][category] = precision[iou_idx][label][0]\n            ret[f'AP@{thresh:.2f}'][category] = ap[iou_idx][label][0]\n\n    mAP = np.mean([ap[iou_idx][label][0] for iou_idx in range(len(ovthresh)) for label in label2cat.keys()])\n    mAR = np.mean([recall[iou_idx][label][0] for iou_idx in range(len(ovthresh)) for label in label2cat.keys()])\n\n    ret['mAP'] = mAP\n    ret['mAR'] = mAR\n\n    if logger:\n        table_data = [['Category', 'AP@0.50', 'AP@0.55', 'AP@0.60', 'AP@0.65', 'AP@0.70', 'AP@0.75']]\n        for label, category in label2cat.items():\n            ap_values = [ret[f'AP@{thresh:.2f}'][category] for thresh in ovthresh]\n            table_data.append([category] + [f'{ap:.3f}' for ap in ap_values])\n        table_data.append(['mAP'] + [f'{mAP:.3f}'])\n        table_data.append(['mAR'] + [f'{mAR:.3f}'])\n\n        table = AsciiTable(table_data)\n        print_log(table.table, logger=logger, level=logging.INFO)\n\n    return ret"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    pred = {}\n    gt = {}\n    for anno in gt_annos:\n        img_id = anno['image_idx']\n        if img_id not in gt:\n            gt[img_id] = []\n        gt[img_id].append(anno)\n\n    for anno in dt_annos:\n        img_id = anno['image_idx']\n        if img_id not in pred:\n            pred[img_id] = []\n        pred[img_id].append(anno)\n\n    pred_mapped = {}\n    gt_mapped = {}\n    for img_id in pred.keys():\n        pred_mapped[img_id] = []\n        for box in pred[img_id]:\n            pred_mapped[img_id].append((box['bbox'], box['score']))\n\n    for img_id in gt.keys():\n        gt_mapped[img_id] = []\n        for box in gt[img_id]:\n            gt_mapped[img_id].append(box)\n\n    pred_class = {}\n    gt_class = {}\n    for img_id in pred_mapped.keys():\n        for box in pred_mapped[img_id]:\n            if box['label'] not in pred_class:\n                pred_class[box['label']] = {}\n            if img_id not in pred_class[box['label']]:\n                pred_class[box['label']][img_id] = []\n            pred_class[box['label']][img_id].append(box)\n\n    for img_id in gt_mapped.keys():\n        for box in gt_mapped[img_id]:\n            if box['label'] not in gt_class:\n                gt_class[box['label']] = {}\n            if img_id not in gt_class[box['label']]:\n                gt_class[box['label']][img_id] = []\n            gt_class[box['label']][img_id].append(box)\n\n    pred_class_mapped = {}\n    gt_class_mapped = {}\n    for label in pred_class.keys():\n        pred_class_mapped[label2cat[label]] = pred_class[label]\n\n    for label in gt_class.keys():\n        gt_class_mapped[label2cat[label]] = gt_class[label]\n\n    recall, precision, ap = eval_map_recall(pred_class_mapped, gt_class_mapped, metric)\n\n    ret = {'recall': recall, 'precision': precision, 'ap': ap}\n\n    if logger is not None:\n        table_data = [['Class', 'AP']]\n        for label, ap_values in ap.items():\n            table_data.append([label, np.mean(ap_values)])\n        table_data.append(['mAP', np.mean([np.mean(ap_values) for ap_values in ap.values()])])\n        table = AsciiTable(table_data)\n        print_log('\\n' + table.table, logger=logger)\n\n    return ret"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    if logger is None:\n        logger = print_log\n    if box_type_3d is None:\n        box_type_3d = None\n    if box_mode_3d is None:\n        box_mode_3d = None\n\n    pred = {}\n    gt = {}\n    for anno in dt_annos:\n        img_id = anno[\"image\"][\"image_id\"]\n        if img_id not in pred:\n            pred[img_id] = []\n        bbox = anno[\"bbox\"]\n        label = anno[\"name\"]\n        score = anno[\"score\"]\n        pred[img_id].append((bbox, score, label))\n\n    for anno in gt_annos:\n        img_id = anno[\"image\"][\"image_id\"]\n        if img_id not in gt:\n            gt[img_id] = []\n        bbox = anno[\"bbox\"]\n        label = anno[\"name\"]\n        gt[img_id].append((bbox, label))\n\n    ovthresh = metric\n    ret = eval_map_recall(pred, gt, ovthresh)\n\n    ap_strs = []\n    ar_strs = []\n    for iou_idx, thresh in enumerate(ovthresh):\n        recall = ret[0][iou_idx]\n        precision = ret[1][iou_idx]\n        ap = ret[2][iou_idx]\n\n        # Print mAP and mAR for each IoU threshold\n        ap_str = f\"AP@{thresh:.2f}: \"\n        ar_str = f\"AR@{thresh:.2f}: \"\n        for label, category in label2cat.items():\n            if label in ap:\n                ap_str += f\"{category}: {ap[label][0]:.4f}, \"\n                ar_str += f\"{category}: {recall[label][0]:.4f}, \"\n        ap_str += f\"mAP: {np.mean(list(ap.values())):.4f}\"\n        ar_str += f\"mAR: {np.mean(list(recall.values())):.4f}\"\n        ap_strs.append(ap_str)\n        ar_strs.append(ar_str)\n\n    # Print the mAP summary\n    table_data = [[\"IoU Threshold\", \"mAP\", \"mAR\"]]\n    for i in range(len(ovthresh)):\n        table_data.append([f\"{ovthresh[i]:.2f}\", f\"{np.mean(list(ret[2][i].values())):.4f}\", f\"{np.mean(list(ret[0][i].values())):.4f}\"])\n    table = AsciiTable(table_data)\n    logger(\"\\n\".join(ap_strs))\n    logger(\"\\n\".join(ar_strs))\n    logger(table.table)\n\n    return {\n        \"ap\": ret[2],\n        \"ar\": ret[0],\n        \"mAP\": {f\"mAP@{thresh:.2f}\": np.mean(list(ret[2][i].values())) for i, thresh in enumerate(ovthresh)},\n        \"mAR\": {f\"mAR@{thresh:.2f}\": np.mean(list(ret[0][i].values())) for i, thresh in enumerate(ovthresh)}\n    }"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    pred = {}\n    gt = {}\n    for anno in gt_annos:\n        name = anno['image']['image_idx']\n        gt[name] = anno['gt_boxes_2d']\n    for anno in dt_annos:\n        name = anno['image']['image_idx']\n        pred[name] = anno['pred_boxes_2d']\n\n    recall, precision, ap = eval_map_recall(pred, gt, metric)\n\n    ret = {}\n    for iou_idx, thresh in enumerate(metric):\n        ret[f'recall@{thresh}'] = recall[iou_idx]\n        ret[f'precision@{thresh}'] = precision[iou_idx]\n        ret[f'ap@{thresh}'] = ap[iou_idx]\n\n    if logger is not None:\n        table_data = [['Class', 'AP']]\n        for label, ap_value in ret[f'ap@{metric[0]}'].items():\n            table_data.append([label2cat[label], ap_value])\n        table = AsciiTable(table_data)\n        print_log('\\n' + table.table, logger=logger)\n\n    return ret"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    gt = {}\n    dt = {}\n    for i in range(len(gt_annos)):\n        gt[i] = {'bbox': gt_annos[i]['gt_boxes'], 'det': [False] * len(metric)}\n    for i in range(len(dt_annos)):\n        dt[i] = {'bbox': dt_annos[i]['bbox'], 'det': [False] * len(metric)}\n\n    pred = {}\n    for i in range(len(dt_annos)):\n        pred[i] = {}\n        for j in range(len(dt_annos[i]['name'])):\n            label = dt_annos[i]['name'][j]\n            if label not in pred[i]:\n                pred[i][label] = []\n            pred[i][label].append((dt_annos[i]['bbox'][j], dt_annos[i]['score'][j]))\n\n    gt_dict = {}\n    for i in range(len(gt_annos)):\n        label = gt_annos[i]['name']\n        if label not in gt_dict:\n            gt_dict[label] = []\n        gt_dict[label].append(gt_annos[i]['gt_boxes'])\n\n    pred_dict = {}\n    for i in range(len(dt_annos)):\n        label = dt_annos[i]['name']\n        if label not in pred_dict:\n            pred_dict[label] = []\n        pred_dict[label].append(dt_annos[i]['bbox'])\n\n    recall, precision, ap = eval_map_recall(pred, gt, metric)\n\n    ap_dict = {}\n    ar_dict = {}\n    for i in range(len(metric)):\n        ap_dict[f'AP_{metric[i]}'] = {}\n        ar_dict[f'AR_{metric[i]}'] = {}\n        for label in gt_dict.keys():\n            ap_dict[f'AP_{metric[i]}'][label2cat[label]] = ap[i][label][0]\n            ar_dict[f'AR_{metric[i]}'][label2cat[label]] = recall[i][label][0]\n\n    mAP = np.mean([ap[i][label][0] for i in range(len(metric)) for label in gt_dict.keys()])\n    mAR = np.mean([recall[i][label][0] for i in range(len(metric)) for label in gt_dict.keys()])\n\n    results = {'mAP': mAP, 'mAR': mAR, 'AP': ap_dict, 'AR': ar_dict}\n\n    if logger is not None:\n        table_data = [['Class', 'AP'] + [f'AR_{metric[i]}' for i in range(len(metric))]]\n        for label in gt_dict.keys():\n            row = [label2cat[label], f'{ap_dict[f\"AP_{metric[0]}\"][label]:.4f}']\n            for i in range(len(metric)):\n                row.append(f'{ar_dict[f\"AR_{metric[i]}\"][label]:.4f}')\n            table_data.append(row)\n        table = AsciiTable(table_data)\n        print_log(table.table, logger=logger)\n\n    return results"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    if logger is None:\n        logger = print_log\n    elif isinstance(logger, str):\n        logger = getLogger(logger)\n\n    if not isinstance(metric, list):\n        metric = [metric]\n\n    if not isinstance(gt_annos, list):\n        raise TypeError('gt_annos should be a list')\n    if not isinstance(dt_annos, list):\n        raise TypeError('dt_annos should be a list')\n\n    gt = {}\n    dt = {}\n    for anno in gt_annos:\n        if anno['name'] not in gt:\n            gt[anno['name']] = []\n        gt[anno['name']].append(anno)\n    for anno in dt_annos:\n        if anno['name'] not in dt:\n            dt[anno['name']] = []\n        dt[anno['name']].append(anno)\n\n    pred = {}\n    for class_name in dt.keys():\n        pred[label2cat[class_name]] = {}\n        for iou_thr in metric:\n            pred[label2cat[class_name]][iou_thr] = []\n        for anno in dt[class_name]:\n            if anno['score'] is None:\n                raise ValueError('The score of detection cannot be None')\n            pred[label2cat[class_name]][metric[0]].append(\n                (anno['bbox'], anno['score']))\n\n    gts = {}\n    for class_name in gt.keys():\n        gts[label2cat[class_name]] = {}\n        for anno in gt[class_name]:\n            gts[label2cat[class_name]][anno['name']] = anno\n\n    ret = eval_map_recall(pred, gts, metric)\n\n    # organize the evaluation results into a dictionary\n    eval_results = {}\n    for i, iou_thr in enumerate(metric):\n        eval_results['AP@IoU={}'.format(iou_thr)] = {}\n        eval_results['AR@IoU={}'.format(iou_thr)] = {}\n        for class_name in ret[0][i].keys():\n            eval_results['AP@IoU={}'.format(iou_thr)][class_name] = ret[2][i][class_name]\n            eval_results['AR@IoU={}'.format(iou_thr)][class_name] = ret[0][i][class_name]\n\n    # calculate the overall mAP and mAR\n    mAP = np.mean([np.mean(ret[2][i][class_name]) for i, iou_thr in enumerate(metric) for class_name in ret[2][i].keys()])\n    mAR = np.mean([np.mean(ret[0][i][class_name]) for i, iou_thr in enumerate(metric) for class_name in ret[0][i].keys()])\n\n    eval_results['mAP'] = mAP\n    eval_results['mAR'] = mAR\n\n    # format the evaluation results into a table for logging\n    table_data = [['Class', 'AP@IoU=0.5', 'AR@IoU=0.5', 'AP@IoU=0.7', 'AR@IoU=0.7']]\n    for class_name in ret[0][0].keys():\n        ap_05 = eval_results['AP@IoU=0.5'][class_name]\n        ar_05 = eval_results['AR@IoU=0.5'][class_name]\n        ap_07 = eval_results['AP@IoU=0.7'][class_name]\n        ar_07 = eval_results['AR@IoU=0.7'][class_name]\n        table_data.append([class_name, ap_05, ar_05, ap_07, ar_07])\n\n    table = AsciiTable(table_data)\n    logger(table.table)\n\n    return eval_results"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    box_type = box_type.upper()\n    if box_type == \"LIDAR\":\n        return LidarInstance3DBoxes, \"LiDAR\"\n    elif box_type == \"CAMERA\":\n        return CameraInstance3DBoxes, \"Camera\"\n    elif box_type == \"DEPTH\":\n        return DepthInstance3DBoxes, \"Depth\"\n    else:\n        raise ValueError(f\"Unrecognized box type: {box_type}. Please use one of 'LiDAR', 'Camera', or 'Depth'.\")"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    box_type = box_type.upper()\n    if box_type == \"LIDAR\":\n        return LidarInstance3DBoxes, \"LiDAR\"\n    elif box_type == \"CAMERA\":\n        return CameraInstance3DBoxes, \"Camera\"\n    elif box_type == \"DEPTH\":\n        return DepthInstance3DBoxes, \"Depth\"\n    else:\n        raise ValueError(f\"Unrecognized box type: {box_type}. Please use one of 'LiDAR', 'Camera', or 'Depth'.\")"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "            from . import DepthInstance3DBoxes\n            from . import CameraInstance3DBoxes\n            from . import LiDARInstance3DBoxes\n    box_type = box_type.upper()\n    if box_type == 'LIDAR':\n        from . import LiDARInstance3DBoxes\n        return LiDARInstance3DBoxes, 'LiDAR'\n    elif box_type == 'CAMERA':\n        from . import CameraInstance3DBoxes\n        return CameraInstance3DBoxes, 'Camera'\n    elif box_type == 'DEPTH':\n        from . import DepthInstance3DBoxes\n        return DepthInstance3DBoxes, 'Depth'\n    else:\n        raise ValueError(f'Unrecognized box type: {box_type}. '\n                         f'Box type should be one of \"LiDAR\", \"Camera\", or \"Depth\".')"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "            from . import DepthInstance3DBoxes\n            from . import CameraInstance3DBoxes\n            from . import LiDARInstance3DBoxes\n    box_type = box_type.upper()\n    if box_type == 'LIDAR':\n        from . import LiDARInstance3DBoxes\n        return LiDARInstance3DBoxes, 'LiDAR'\n    elif box_type == 'CAMERA':\n        from . import CameraInstance3DBoxes\n        return CameraInstance3DBoxes, 'Camera'\n    elif box_type == 'DEPTH':\n        from . import DepthInstance3DBoxes\n        return DepthInstance3DBoxes, 'Depth'\n    else:\n        raise ValueError(f'Unrecognized box type: {box_type}. '\n                         f'Box type should be one of \"LiDAR\", \"Camera\", or \"Depth\".')"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    box_type = box_type.upper()\n    if box_type == 'LIDAR':\n        return LidarInstance3DBoxes, 'lidar'\n    elif box_type == 'CAMERA':\n        return CameraInstance3DBoxes, 'camera'\n    elif box_type == 'DEPTH':\n        return DepthInstance3DBoxes, 'depth'\n    else:\n        raise ValueError(f'Unrecognized box type: {box_type}. Box type should be one of \"LiDAR\", \"Camera\", or \"Depth\".')"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    box_type = box_type.upper()\n    if box_type == 'LIDAR':\n        return LidarInstance3DBoxes, 'LiDAR'\n    elif box_type == 'CAMERA':\n        return CameraInstance3DBoxes, 'Camera'\n    elif box_type == 'DEPTH':\n        return DepthInstance3DBoxes, 'Depth'\n    else:\n        raise ValueError(f\"Unrecognized box type: {box_type}. Please use one of 'LiDAR', 'Camera', or 'Depth'.\")"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    box_type = box_type.upper()\n    if box_type == 'LIDAR':\n        return LidarInstance3DBoxes, 'lidar'\n    elif box_type == 'CAMERA':\n        return CameraInstance3DBoxes, 'camera'\n    elif box_type == 'DEPTH':\n        return DepthInstance3DBoxes, 'depth'\n    else:\n        raise ValueError(f'Unrecognized box type: {box_type}. '\n                         f'Box type should be one of \"LiDAR\", \"Camera\", or \"Depth\".')"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "\n    box_type = box_type.upper()\n    mapping = {'LIDAR': ('LiDARInstance3DBoxes', 'LiDAR'),\n               'DEPTH': ('DepthInstance3DBoxes', 'Depth'),\n               'CAMERA': ('CameraInstance3DBoxes', 'Camera')}\n\n    if box_type in mapping:\n        return mapping[box_type]\n    else:\n        raise ValueError(f'Unrecognized box type: {box_type}. '\n                         f'Box type should be one of \"LiDAR\", \"Camera\", or \"Depth\".')"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "\n    box_type = box_type.upper()\n    if box_type == 'LIDAR':\n        return LidarInstance3DBoxes, 'LiDAR'\n    elif box_type == 'CAMERA':\n        return CameraInstance3DBoxes, 'Camera'\n    elif box_type == 'DEPTH':\n        return DepthInstance3DBoxes, 'Depth'\n    else:\n        raise ValueError(f\"Unrecognized box type: {box_type}. Please use one of 'LiDAR', 'Camera', or 'Depth'.\")"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    box_type = box_type.upper()\n    if box_type == 'LIDAR':\n        return LidarInstance3DBoxes, 'lidar'\n    elif box_type == 'CAMERA':\n        return CameraInstance3DBoxes, 'camera'\n    elif box_type == 'DEPTH':\n        return DepthInstance3DBoxes, 'depth'\n    else:\n        raise ValueError(f\"Unrecognized box type: {box_type}. Please use one of 'LiDAR', 'Camera', or 'Depth'.\")"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    box_type = box_type.upper()\n    if box_type == \"LIDAR\":\n        return LidarInstance3DBoxes, \"lidar\"\n    elif box_type == \"CAMERA\":\n        return CameraInstance3DBoxes, \"camera\"\n    elif box_type == \"DEPTH\":\n        return DepthInstance3DBoxes, \"depth\"\n    else:\n        raise ValueError(f\"Unrecognized box type: {box_type}. Please use one of 'LiDAR', 'Camera', or 'Depth'.\")"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    box_type = box_type.upper()\n    if box_type == 'LIDAR':\n        return LidarInstance3DBoxes, 'LiDAR'\n    elif box_type == 'CAMERA':\n        return CameraInstance3DBoxes, 'Camera'\n    elif box_type == 'DEPTH':\n        return DepthInstance3DBoxes, 'Depth'\n    else:\n        raise ValueError(f\"Unrecognized box type: {box_type}. Supported types are 'LiDAR', 'Camera', or 'Depth'.\")"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    box_type = box_type.upper()\n    if box_type == 'LIDAR':\n        return LidarInstance3DBoxes, 'LiDAR'\n    elif box_type == 'CAMERA':\n        return CameraInstance3DBoxes, 'Camera'\n    elif box_type == 'DEPTH':\n        return DepthInstance3DBoxes, 'Depth'\n    else:\n        raise ValueError(f'Unrecognized box type: {box_type}. Box type should be one of \"LiDAR\", \"Camera\", or \"Depth\".')"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "            from . import DepthInstance3DBoxes\n            from . import CameraInstance3DBoxes\n            from . import LiDARInstance3DBoxes\n    box_type = box_type.upper()\n    if box_type == 'LIDAR':\n        from . import LiDARInstance3DBoxes\n        return LiDARInstance3DBoxes, 'LiDAR'\n    elif box_type == 'CAMERA':\n        from . import CameraInstance3DBoxes\n        return CameraInstance3DBoxes, 'Camera'\n    elif box_type == 'DEPTH':\n        from . import DepthInstance3DBoxes\n        return DepthInstance3DBoxes, 'Depth'\n    else:\n        raise ValueError(\"Unrecognized box type. Supported types are 'LiDAR', 'Camera', or 'Depth'.\")"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "            from . import DepthInstance3DBoxes\n            from . import CameraInstance3DBoxes\n            from . import LiDARInstance3DBoxes\n    box_type = box_type.upper()\n    if box_type == 'LIDAR':\n        from . import LiDARInstance3DBoxes\n        return LiDARInstance3DBoxes, 'LiDAR'\n    elif box_type == 'CAMERA':\n        from . import CameraInstance3DBoxes\n        return CameraInstance3DBoxes, 'Camera'\n    elif box_type == 'DEPTH':\n        from . import DepthInstance3DBoxes\n        return DepthInstance3DBoxes, 'Depth'\n    else:\n        raise ValueError(f\"Unrecognized box type: {box_type}. Please use one of 'LiDAR', 'Camera', or 'Depth'.\")"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    box_type = box_type.upper()\n    if box_type == \"LIDAR\":\n        return LidarInstance3DBoxes, \"LiDAR\"\n    elif box_type == \"CAMERA\":\n        return CameraInstance3DBoxes, \"Camera\"\n    elif box_type == \"DEPTH\":\n        return DepthInstance3DBoxes, \"Depth\"\n    else:\n        raise ValueError(f\"Unrecognized box type: {box_type}. Please use one of 'LiDAR', 'Camera', or 'Depth'.\")"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    box_type = box_type.upper()\n    mapping = {'LIDAR': ('LiDARInstance3DBoxes', 'lidar'),\n               'CAMERA': ('CameraInstance3DBoxes', 'camera'),\n               'DEPTH': ('DepthInstance3DBoxes', 'depth')}\n    if box_type in mapping:\n        return mapping[box_type]\n    else:\n        raise ValueError(f\"Unrecognized box type: {box_type}. Box type should be one of 'LiDAR', 'Camera', or 'Depth'.\")"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    box_type = box_type.upper()\n    mapping = {'LIDAR': 'LidarInstance3DBoxes', 'DEPTH': 'DepthInstance3DBoxes', 'CAMERA': 'CameraInstance3DBoxes'}\n    assert box_type in mapping.keys(), f'box_type should be one of \"LiDAR\", \"Camera\", or \"Depth\", got {box_type}'\n    return mapping[box_type], box_type"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    box_type = box_type.upper()\n    if box_type == 'LIDAR':\n        return LidarInstance3DBoxes, 'lidar'\n    elif box_type == 'CAMERA':\n        return CameraInstance3DBoxes, 'camera'\n    elif box_type == 'DEPTH':\n        return DepthInstance3DBoxes, 'depth'\n    else:\n        raise ValueError(f\"Unrecognized box type: {box_type}. Supported types are 'LiDAR', 'Camera', or 'Depth'.\")"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    box_type = box_type.upper()\n    box_classes = {\n        'LIDAR': (LidarInstance3DBoxes, 'lidar'),\n        'CAMERA': (CameraInstance3DBoxes, 'camera'),\n        'DEPTH': (DepthInstance3DBoxes, 'depth')\n    }\n    if box_type not in box_classes:\n        raise ValueError(f'Unsupported box type {box_type}. Supported box types are {\", \".join(box_classes.keys())}')\n    return box_classes[box_type]"}
{"namespace": "ollama._client.Client.chat", "completion": "  if not model:\n    raise RequestError('must provide a model')\n\n  for message in messages or []:\n    if not isinstance(message, dict):\n      raise TypeError('messages must be a list of strings')\n    if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n      raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n    if not message.get('content'):\n      raise RequestError('messages must contain content')\n    if images := message.get('images'):\n      message['images'] = [_encode_image(image) for image in images]\n\n  return self._request_stream(\n    'POST',\n    '/api/chat',\n    json={\n      'model': model,\n      'messages': messages,\n      'stream': stream,\n      'format': format,\n      'options': options or {},\n      'keep_alive': keep_alive,\n    },\n    stream=stream,\n  )"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.generate", "completion": "\n    if not model:\n      raise RequestError('must provide a model')\n\n    return self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.generate", "completion": "\n    if not model:\n      raise RequestError('must provide a model')\n\n    return self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.generate", "completion": "\n    if not model:\n      raise RequestError('must provide a model')\n\n    return self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.generate", "completion": "\n    if not model:\n      raise RequestError('must provide a model')\n\n    return self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.generate", "completion": "\n    if not model:\n      raise RequestError('must provide a model')\n\n    return self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.generate", "completion": "\n    if not model:\n      raise RequestError('must provide a model')\n\n    return self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.generate", "completion": "\n    if not model:\n      raise RequestError('must provide a model')\n\n    return self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.generate", "completion": "\n    if not model:\n      raise RequestError('must provide a model')\n\n    return self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "\n    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "\n    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "\n    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "\n    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "\n    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "\n    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "\n    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "\n    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "\n    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "\n    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "\n    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n        while True:\n            chunk = r.read(32 * 1024)\n            if not chunk:\n                break\n            sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n        self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n        if e.status_code != 404:\n            raise\n\n        def upload_bytes():\n            with open(path, 'rb') as r:\n                while True:\n                    chunk = r.read(32 * 1024)\n                    if not chunk:\n                        break\n                    yield chunk\n\n        self._request('POST', f'/api/blobs/{digest}', content=upload_bytes())\n\n    return digest"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      def upload_bytes():\n        with open(path, 'rb') as r:\n          while True:\n            chunk = r.read(32 * 1024)\n            if not chunk:\n              break\n            yield chunk\n\n      self._request('POST', f'/api/blobs/{digest}', content=upload_bytes())\n\n    return digest"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      async def upload_bytes():\n        with open(path, 'rb') as r:\n          while True:\n            chunk = r.read(32 * 1024)\n            if not chunk:\n              break\n            yield chunk\n\n      await self._request('POST', f'/api/blobs/{digest}', content=upload_bytes())\n\n    return digest"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      def upload_bytes():\n        with open(path, 'rb') as r:\n          while True:\n            chunk = r.read(32 * 1024)\n            if not chunk:\n              break\n            yield chunk\n\n      self._request('POST', f'/api/blobs/{digest}', content=upload_bytes())\n\n    return digest"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    sha256sum = sha256()\n    async with aiofiles.open(path, 'rb') as f:\n        while True:\n            chunk = await f.read(32 * 1024)\n            if not chunk:\n                break\n            sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n        await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n        if e.status_code != 404:\n            raise\n\n        async def upload_bytes():\n            async with aiofiles.open(path, 'rb') as f:\n                while True:\n                    chunk = await f.read(32 * 1024)\n                    if not chunk:\n                        break\n                    yield chunk\n\n        await self._request('POST', f'/api/blobs/{digest}', content=upload_bytes())\n\n    return digest"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      def upload_bytes():\n        with open(path, 'rb') as r:\n          while True:\n            chunk = r.read(32 * 1024)\n            if not chunk:\n              break\n            yield chunk\n\n      self._request('POST', f'/api/blobs/{digest}', content=upload_bytes())\n\n    return digest"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    sha256sum = sha256()\n    async with aiofiles.open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      async def upload_bytes():\n        async with aiofiles.open(path, 'rb') as r:\n          while True:\n            chunk = await r.read(32 * 1024)\n            if not chunk:\n              break\n            yield chunk\n\n      await self._request('POST', f'/api/blobs/{digest}', content=upload_bytes())\n\n    return digest"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      def upload_bytes():\n        with open(path, 'rb') as r:\n          while True:\n            chunk = r.read(32 * 1024)\n            if not chunk:\n              break\n            yield chunk\n\n      self._request('POST', f'/api/blobs/{digest}', content=upload_bytes())\n\n    return digest"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      def upload_bytes():\n        with open(path, 'rb') as r:\n          while True:\n            chunk = r.read(32 * 1024)\n            if not chunk:\n              break\n            yield chunk\n\n      self._request('POST', f'/api/blobs/{digest}', content=upload_bytes())\n\n    return digest"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    sha256sum = sha256()\n    async with aiofiles.open(path, 'rb') as f:\n      chunk = await f.read(32 * 1024)\n      while chunk:\n        sha256sum.update(chunk)\n        chunk = await f.read(32 * 1024)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      async def upload_bytes():\n        async with aiofiles.open(path, 'rb') as f:\n          chunk = await f.read(32 * 1024)\n          while chunk:\n            yield chunk\n            chunk = await f.read(32 * 1024)\n\n      await self._request('POST', f'/api/blobs/{digest}', content=upload_bytes())\n\n    return digest"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    sha256sum = sha256()\n    async with aiofiles.open(path, 'rb') as f:\n      while True:\n        chunk = await f.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      async def upload_bytes():\n        async with aiofiles.open(path, 'rb') as f:\n          while True:\n            chunk = await f.read(32 * 1024)\n            if not chunk:\n              break\n            yield chunk\n\n      await self._request('POST', f'/api/blobs/{digest}', content=upload_bytes())\n\n    return digest"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    sha256sum = sha256()\n    async with open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      async def upload_bytes():\n        async with open(path, 'rb') as r:\n          while True:\n            chunk = await r.read(32 * 1024)\n            if not chunk:\n              break\n            yield chunk\n\n      await self._request('POST', f'/api/blobs/{digest}', content=upload_bytes())\n\n    return digest"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    sha256sum = sha256()\n    async with aiofiles.open(path, 'rb') as file:\n      chunk = await file.read(32 * 1024)\n      while chunk:\n        sha256sum.update(chunk)\n        chunk = await file.read(32 * 1024)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      async def upload_bytes():\n        async with aiofiles.open(path, 'rb') as file:\n          chunk = await file.read(32 * 1024)\n          while chunk:\n            yield chunk\n            chunk = await file.read(32 * 1024)\n\n      await self._request('POST', f'/api/blobs/{digest}', content=upload_bytes())\n\n    return digest"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      def upload_bytes():\n        with open(path, 'rb') as r:\n          while True:\n            chunk = r.read(32 * 1024)\n            if not chunk:\n              break\n            yield chunk\n\n      self._request('POST', f'/api/blobs/{digest}', content=upload_bytes())\n\n    return digest"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    sha256sum = sha256()\n    async with aiofiles.open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      async def upload_bytes():\n        async with aiofiles.open(path, 'rb') as r:\n          while True:\n            chunk = await r.read(32 * 1024)\n            if not chunk:\n              break\n            yield chunk\n\n      await self._request('POST', f'/api/blobs/{digest}', content=upload_bytes())\n\n    return digest"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    sha256sum = sha256()\n    async with aiofiles.open(path, 'rb') as f:\n      while True:\n        chunk = await f.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      async def upload_bytes():\n        async with aiofiles.open(path, 'rb') as f:\n          while True:\n            chunk = await f.read(32 * 1024)\n            if not chunk:\n              break\n            yield chunk\n\n      await self._request('POST', f'/api/blobs/{digest}', content=upload_bytes())\n\n    return digest"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    sha256sum = sha256()\n    async with open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      async def upload_bytes():\n        async with open(path, 'rb') as r:\n          while True:\n            chunk = await r.read(32 * 1024)\n            if not chunk:\n              break\n            yield chunk\n\n      await self._request('POST', f'/api/blobs/{digest}', content=upload_bytes())\n\n    return digest"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    sha256sum = sha256()\n    async with aiofiles.open(path, 'rb') as f:\n      while True:\n        chunk = await f.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      async def upload_bytes():\n        async with aiofiles.open(path, 'rb') as f:\n          while True:\n            chunk = await f.read(32 * 1024)\n            if not chunk:\n              break\n            yield chunk\n\n      await self._request('POST', f'/api/blobs/{digest}', content=upload_bytes())\n\n    return digest"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      async def upload_bytes():\n        with open(path, 'rb') as r:\n          while True:\n            chunk = r.read(32 * 1024)\n            if not chunk:\n              break\n            yield chunk\n\n      await self._request('POST', f'/api/blobs/{digest}', content=upload_bytes())\n\n    return digest"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    sha256sum = sha256()\n    async with open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      async def upload_bytes():\n        async with open(path, 'rb') as r:\n          while True:\n            chunk = await r.read(32 * 1024)\n            if not chunk:\n              break\n            yield chunk\n\n      await self._request('POST', f'/api/blobs/{digest}', content=upload_bytes())\n\n    return digest"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "\n        self._state_dict = state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "\n        self._state_dict = state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "\n        self._state_dict = state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "\n        # Load the state dictionary into the StreamingDataset instance\n        self._state_dict = state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "\n        self._state_dict = state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "\n        self._state_dict = state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "\n        # Load the state dictionary into the StreamingDataset instance\n        self._state_dict = state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "\n        # Restore the state of the StreamingDataset based on the provided state dictionary\n        self._state_dict = state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "\n        self._state_dict = state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict\n        self.set_shuffle(state_dict[\"shuffle\"])\n        self.set_epoch(state_dict[\"current_epoch\"])"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "\n        self._state_dict = state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "\n        self._state_dict = state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "\n        # Load the state dictionary into the StreamingDataset instance\n        self._state_dict = state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "\n        self._state_dict = state_dict\n        self._validate_state_dict()"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "\n        self._state_dict = state_dict\n        self.current_epoch = state_dict[\"current_epoch\"]"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "\n        self._state_dict = state_dict\n        self._validate_state_dict()"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "\n        self._state_dict = state_dict\n        self.set_shuffle(state_dict[\"shuffle\"])\n        self.set_epoch(state_dict[\"current_epoch\"])"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "\n        self._state_dict = state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict is None:\n            return\n\n        state: Dict[str, Any] = self._state_dict\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\"Mismatch in shuffle parameter between state dictionary and current state\")\n\n        if state[\"num_workers\"] != self.worker_env.world_size:\n            raise ValueError(\"Mismatch in num_workers parameter between state dictionary and current state\")\n\n        if state[\"input_dir_path\"] != self.input_dir.path or state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\"Mismatch in input directory path/URL between state dictionary and current state\")\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\"Mismatch in seed parameter between state dictionary and current state\")\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\"Mismatch in drop_last parameter between state dictionary and current state\")\n\n        if state[\"item_loader\"] is not None and self.item_loader is not None:\n            if state[\"item_loader\"] != self.item_loader.state_dict():\n                raise ValueError(\"Mismatch in item_loader state between state dictionary and current state\")\n        elif state[\"item_loader\"] is not None or self.item_loader is not None:\n            raise ValueError(\"Mismatch in item_loader state between state dictionary and current state\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict is None:\n            return\n\n        state: Dict[str, Any] = self._state_dict\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\"Shuffle parameter in state dictionary does not match current state\")\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\"Drop_last parameter in state dictionary does not match current state\")\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\"Seed parameter in state dictionary does not match current state\")\n\n        if state[\"num_workers\"] != self.worker_env.world_size:\n            raise ValueError(\"Num_workers parameter in state dictionary does not match current state\")\n\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\"Input directory path in state dictionary does not match current state\")\n\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\"Input directory URL in state dictionary does not match current state\")\n\n        if state[\"item_loader\"]:\n            if not self.item_loader:\n                raise ValueError(\"Item loader in state dictionary is not None but current state is None\")\n            if state[\"item_loader\"] != self.item_loader.state_dict():\n                raise ValueError(\"Item loader state in state dictionary does not match current state\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict:\n            state: Dict[str, Any] = self._state_dict\n            if state[\"shuffle\"] != self.shuffle:\n                raise ValueError(\"Mismatch in shuffle parameter between state dictionary and current state\")\n            if state[\"num_workers\"] != self.worker_env.world_size:\n                raise ValueError(\"Mismatch in num_workers between state dictionary and current state\")\n            if state[\"input_dir_path\"] != self.input_dir.path or state[\"input_dir_url\"] != self.input_dir.url:\n                raise ValueError(\"Mismatch in input directory path or URL between state dictionary and current state\")\n            if state[\"seed\"] != self.seed:\n                raise ValueError(\"Mismatch in seed between state dictionary and current state\")\n            if state[\"item_loader\"]:\n                item_loader_state = state[\"item_loader\"]\n                if not self.item_loader or self.item_loader.state_dict() != item_loader_state:\n                    raise ValueError(\"Mismatch in item_loader state between state dictionary and current state\")\n            if state[\"drop_last\"] != self.drop_last:\n                raise ValueError(\"Mismatch in drop_last flag between state dictionary and current state\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict:\n            state: Dict[str, Any] = self._state_dict\n            if state[\"shuffle\"] != self.shuffle:\n                raise ValueError(\"Mismatch in shuffle parameter between state dictionary and current state.\")\n            if state[\"num_workers\"] != self.worker_env.world_size:\n                raise ValueError(\"Mismatch in num_workers parameter between state dictionary and current state.\")\n            if state[\"input_dir_path\"] != self.input_dir.path:\n                raise ValueError(\"Mismatch in input directory path between state dictionary and current state.\")\n            if state[\"input_dir_url\"] != self.input_dir.url:\n                raise ValueError(\"Mismatch in input directory URL between state dictionary and current state.\")\n            if state[\"item_loader\"]:\n                if not self.item_loader or state[\"item_loader\"] != self.item_loader.state_dict():\n                    raise ValueError(\"Mismatch in item_loader state between state dictionary and current state.\")\n            if state[\"drop_last\"] != self.drop_last:\n                raise ValueError(\"Mismatch in drop_last flag between state dictionary and current state.\")\n            if state[\"seed\"] != self.seed:\n                raise ValueError(\"Mismatch in seed parameter between state dictionary and current state.\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict:\n            state: Dict[str, Any] = self._state_dict\n            if state[\"shuffle\"] != self.shuffle:\n                raise ValueError(\"Shuffle parameter in state dictionary does not match the current state.\")\n            if state[\"world_size\"] != self.distributed_env.world_size:\n                raise ValueError(\"World size in state dictionary does not match the current state.\")\n            if state[\"input_dir_path\"] != self.input_dir.path:\n                raise ValueError(\"Input directory path in state dictionary does not match the current state.\")\n            if state[\"input_dir_url\"] != self.input_dir.url:\n                raise ValueError(\"Input directory URL in state dictionary does not match the current state.\")\n            if state[\"seed\"] != self.seed:\n                raise ValueError(\"Seed in state dictionary does not match the current state.\")\n            if state[\"item_loader\"] != (self.item_loader.state_dict() if self.item_loader else None):\n                raise ValueError(\"Item loader state in state dictionary does not match the current state.\")\n            if state[\"drop_last\"] != self.drop_last:\n                raise ValueError(\"Drop last flag in state dictionary does not match the current state.\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict:\n            state: Dict[str, Any] = self._state_dict\n            if state[\"shuffle\"] != self.shuffle:\n                raise ValueError(\"Mismatch in shuffle parameter between state dictionary and current state\")\n            if state[\"num_workers\"] != self.worker_env.world_size:\n                raise ValueError(\"Mismatch in num_workers between state dictionary and current state\")\n            if state[\"input_dir_path\"] != self.input_dir.path:\n                raise ValueError(\"Mismatch in input directory path between state dictionary and current state\")\n            if state[\"input_dir_url\"] != self.input_dir.url:\n                raise ValueError(\"Mismatch in input directory URL between state dictionary and current state\")\n            if state[\"seed\"] != self.seed:\n                raise ValueError(\"Mismatch in seed parameter between state dictionary and current state\")\n            if state[\"drop_last\"] != self.drop_last:\n                raise ValueError(\"Mismatch in drop_last flag between state dictionary and current state\")\n            if state[\"item_loader\"] != (self.item_loader.state_dict() if self.item_loader else None):\n                raise ValueError(\"Mismatch in item_loader state between state dictionary and current state\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict:\n            state: Dict[str, Any] = self._state_dict\n            if state[\"shuffle\"] != self.shuffle:\n                raise ValueError(\"Mismatch: 'shuffle' in state_dict does not match current state.\")\n            if state[\"num_workers\"] != self.worker_env.world_size:\n                raise ValueError(\"Mismatch: 'num_workers' in state_dict does not match current state.\")\n            if state[\"input_dir_path\"] != self.input_dir.path:\n                raise ValueError(\"Mismatch: 'input_dir_path' in state_dict does not match current state.\")\n            if state[\"input_dir_url\"] != self.input_dir.url:\n                raise ValueError(\"Mismatch: 'input_dir_url' in state_dict does not match current state.\")\n            if state[\"seed\"] != self.seed:\n                raise ValueError(\"Mismatch: 'seed' in state_dict does not match current state.\")\n            if state[\"item_loader\"] and self.item_loader:\n                if state[\"item_loader\"] != self.item_loader.state_dict():\n                    raise ValueError(\"Mismatch: 'item_loader' in state_dict does not match current state.\")\n            if state[\"drop_last\"] != self.drop_last:\n                raise ValueError(\"Mismatch: 'drop_last' in state_dict does not match current state.\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict is None:\n            return\n\n        state: Dict[str, Any] = self._state_dict\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\"Mismatch in shuffle parameter between state_dict and current state\")\n\n        if state[\"num_workers\"] != self.worker_env.world_size:\n            raise ValueError(\"Mismatch in num_workers parameter between state_dict and current state\")\n\n        if state[\"input_dir_path\"] != self.input_dir.path or state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\"Mismatch in input directory path or URL between state_dict and current state\")\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\"Mismatch in seed parameter between state_dict and current state\")\n\n        if state[\"item_loader\"] is not None:\n            if self.item_loader is None or state[\"item_loader\"] != self.item_loader.state_dict():\n                raise ValueError(\"Mismatch in item_loader state between state_dict and current state\")\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\"Mismatch in drop_last parameter between state_dict and current state\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict:\n            state: Dict[str, Any] = self._state_dict\n            if state[\"shuffle\"] != self.shuffle:\n                raise ValueError(\"Mismatch in shuffle parameter between state dictionary and current state\")\n            if state[\"num_workers\"] != self.worker_env.world_size:\n                raise ValueError(\"Mismatch in num_workers parameter between state dictionary and current state\")\n            if state[\"input_dir_path\"] != self.input_dir.path:\n                raise ValueError(\"Mismatch in input directory path between state dictionary and current state\")\n            if state[\"input_dir_url\"] != self.input_dir.url:\n                raise ValueError(\"Mismatch in input directory URL between state dictionary and current state\")\n            if state[\"seed\"] != self.seed:\n                raise ValueError(\"Mismatch in seed parameter between state dictionary and current state\")\n            if state[\"item_loader\"] != self.item_loader.state_dict() if self.item_loader else None:\n                raise ValueError(\"Mismatch in item_loader state between state dictionary and current state\")\n            if state[\"drop_last\"] != self.drop_last:\n                raise ValueError(\"Mismatch in drop_last flag between state dictionary and current state\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict:\n            state: Dict[str, Any] = self._state_dict\n            if state[\"shuffle\"] != self.shuffle:\n                raise ValueError(\"Shuffle parameter mismatch between state dictionary and current state\")\n            if state[\"num_workers\"] != self.worker_env.world_size:\n                raise ValueError(\"Num workers parameter mismatch between state dictionary and current state\")\n            if state[\"input_dir_path\"] != self.input_dir.path:\n                raise ValueError(\"Input directory path mismatch between state dictionary and current state\")\n            if state[\"input_dir_url\"] != self.input_dir.url:\n                raise ValueError(\"Input directory URL mismatch between state dictionary and current state\")\n            if state[\"seed\"] != self.seed:\n                raise ValueError(\"Seed parameter mismatch between state dictionary and current state\")\n            if state[\"drop_last\"] != self.drop_last:\n                raise ValueError(\"Drop last parameter mismatch between state dictionary and current state\")\n            if state[\"item_loader\"]:\n                if not self.item_loader:\n                    raise ValueError(\"Item loader mismatch between state dictionary and current state\")\n                if state[\"item_loader\"] != self.item_loader.state_dict():\n                    raise ValueError(\"Item loader state mismatch between state dictionary and current state\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict:\n            state: Dict[str, Any] = self._state_dict\n            if (\n                state[\"shuffle\"] != self.shuffle\n                or state[\"num_workers\"] != self.worker_env.world_size\n                or state[\"input_dir_path\"] != self.input_dir.path\n                or state[\"input_dir_url\"] != self.input_dir.url\n                or state[\"seed\"] != self.seed\n                or state[\"item_loader\"] != self.item_loader.state_dict() if self.item_loader else None\n                or state[\"drop_last\"] != self.drop_last\n            ):\n                raise ValueError(\"State dictionary does not match the current state of the StreamingDataset instance.\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict:\n            state: Dict[str, Any] = self._state_dict\n            if state[\"shuffle\"] != self.shuffle:\n                raise ValueError(\"Mismatch in shuffle parameter between state dictionary and current state\")\n            if state[\"num_workers\"] != self.worker_env.world_size:\n                raise ValueError(\"Mismatch in num_workers parameter between state dictionary and current state\")\n            if state[\"input_dir_path\"] != self.input_dir.path:\n                raise ValueError(\"Mismatch in input directory path between state dictionary and current state\")\n            if state[\"input_dir_url\"] != self.input_dir.url:\n                raise ValueError(\"Mismatch in input directory URL between state dictionary and current state\")\n            if state[\"seed\"] != self.seed:\n                raise ValueError(\"Mismatch in seed parameter between state dictionary and current state\")\n            if state[\"drop_last\"] != self.drop_last:\n                raise ValueError(\"Mismatch in drop_last parameter between state dictionary and current state\")\n            if state[\"item_loader\"]:\n                if not self.item_loader or state[\"item_loader\"] != self.item_loader.state_dict():\n                    raise ValueError(\"Mismatch in item_loader state between state dictionary and current state\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict:\n            state: Dict[str, Any] = self._state_dict\n            if state[\"shuffle\"] != self.shuffle:\n                raise ValueError(\"Mismatch in shuffle parameter between state dictionary and current state.\")\n            if state[\"num_workers\"] != self.worker_env.world_size:\n                raise ValueError(\"Mismatch in num_workers parameter between state dictionary and current state.\")\n            if state[\"input_dir_path\"] != self.input_dir.path or state[\"input_dir_url\"] != self.input_dir.url:\n                raise ValueError(\"Mismatch in input directory path or URL between state dictionary and current state.\")\n            if state[\"seed\"] != self.seed:\n                raise ValueError(\"Mismatch in seed parameter between state dictionary and current state.\")\n            if state[\"drop_last\"] != self.drop_last:\n                raise ValueError(\"Mismatch in drop_last parameter between state dictionary and current state.\")\n            if state[\"item_loader\"] and self.item_loader:\n                if state[\"item_loader\"] != self.item_loader.state_dict():\n                    raise ValueError(\"Mismatch in item_loader state between state dictionary and current state.\")\n            elif (state[\"item_loader\"] and not self.item_loader) or (not state[\"item_loader\"] and self.item_loader):\n                raise ValueError(\"Mismatch in item_loader presence between state dictionary and current state.\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict is None:\n            return\n\n        state: Dict[str, Any] = self._state_dict\n\n        if state.get(\"shuffle\") != self.shuffle:\n            raise ValueError(\"Mismatch in 'shuffle' parameter between state dictionary and current state\")\n\n        if state.get(\"num_workers\") != self.worker_env.world_size:\n            raise ValueError(\"Mismatch in 'num_workers' parameter between state dictionary and current state\")\n\n        if state.get(\"input_dir_path\") != self.input_dir.path or state.get(\"input_dir_url\") != self.input_dir.url:\n            raise ValueError(\"Mismatch in input directory path or URL between state dictionary and current state\")\n\n        if state.get(\"seed\") != self.seed:\n            raise ValueError(\"Mismatch in 'seed' parameter between state dictionary and current state\")\n\n        if state.get(\"item_loader\") != (self.item_loader.state_dict() if self.item_loader else None):\n            raise ValueError(\"Mismatch in 'item_loader' state between state dictionary and current state\")\n\n        if state.get(\"drop_last\") != self.drop_last:\n            raise ValueError(\"Mismatch in 'drop_last' parameter between state dictionary and current state\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict:\n            state: Dict[str, Any] = self._state_dict\n            if state[\"shuffle\"] != self.shuffle:\n                raise ValueError(\"Mismatch in shuffle parameter between state dictionary and current state\")\n            if state[\"num_workers\"] != self.worker_env.world_size:\n                raise ValueError(\"Mismatch in num_workers parameter between state dictionary and current state\")\n            if state[\"input_dir_path\"] != self.input_dir.path:\n                raise ValueError(\"Mismatch in input directory path between state dictionary and current state\")\n            if state[\"input_dir_url\"] != self.input_dir.url:\n                raise ValueError(\"Mismatch in input directory URL between state dictionary and current state\")\n            if state[\"seed\"] != self.seed:\n                raise ValueError(\"Mismatch in seed parameter between state dictionary and current state\")\n            if state[\"item_loader\"] and self.item_loader:\n                if state[\"item_loader\"] != self.item_loader.state_dict():\n                    raise ValueError(\"Mismatch in item_loader state between state dictionary and current state\")\n            if state[\"drop_last\"] != self.drop_last:\n                raise ValueError(\"Mismatch in drop_last flag between state dictionary and current state\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict:\n            state: Dict[str, Any] = self._state_dict\n            if state[\"shuffle\"] != self.shuffle:\n                raise ValueError(\"Mismatch in shuffle parameter between state dictionary and current state\")\n            if state[\"num_workers\"] != self.worker_env.world_size:\n                raise ValueError(\"Mismatch in num_workers between state dictionary and current state\")\n            if state[\"input_dir_path\"] != self.input_dir.path or state[\"input_dir_url\"] != self.input_dir.url:\n                raise ValueError(\"Mismatch in input directory path or URL between state dictionary and current state\")\n            if state[\"seed\"] != self.seed:\n                raise ValueError(\"Mismatch in seed between state dictionary and current state\")\n            if state[\"drop_last\"] != self.drop_last:\n                raise ValueError(\"Mismatch in drop_last flag between state dictionary and current state\")\n            if state[\"item_loader\"]:\n                if not self.item_loader or state[\"item_loader\"] != self.item_loader.state_dict():\n                    raise ValueError(\"Mismatch in item_loader state between state dictionary and current state\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict is None:\n            return  # No state dict to validate\n\n        state: Dict[str, Any] = self._state_dict\n\n        # Validate shuffle\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\"Shuffle parameter mismatch between state dictionary and current state\")\n\n        # Validate num_workers\n        if state[\"world_size\"] != self.distributed_env.world_size:\n            raise ValueError(\"Number of workers mismatch between state dictionary and current state\")\n\n        # Validate input directory path and URL\n        if state[\"input_dir_path\"] != self.input_dir.path or state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\"Input directory path or URL mismatch between state dictionary and current state\")\n\n        # Validate seed\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\"Seed parameter mismatch between state dictionary and current state\")\n\n        # Validate item_loader state\n        if state[\"item_loader\"] and self.item_loader:\n            if state[\"item_loader\"] != self.item_loader.state_dict():\n                raise ValueError(\"Item loader state mismatch between state dictionary and current state\")\n\n        # Validate drop_last flag\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\"Drop last parameter mismatch between state dictionary and current state\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict:\n            state: Dict[str, Any] = self._state_dict\n            if state[\"shuffle\"] != self.shuffle:\n                raise ValueError(\"Mismatch: shuffle parameter in state dictionary does not match current state\")\n            if state[\"num_workers\"] != self.worker_env.world_size:\n                raise ValueError(\"Mismatch: num_workers parameter in state dictionary does not match current state\")\n            if state[\"input_dir_path\"] != self.input_dir.path:\n                raise ValueError(\"Mismatch: input directory path in state dictionary does not match current state\")\n            if state[\"input_dir_url\"] != self.input_dir.url:\n                raise ValueError(\"Mismatch: input directory URL in state dictionary does not match current state\")\n            if state[\"seed\"] != self.seed:\n                raise ValueError(\"Mismatch: seed parameter in state dictionary does not match current state\")\n            if state[\"item_loader\"] != (self.item_loader.state_dict() if self.item_loader else None):\n                raise ValueError(\"Mismatch: item_loader state in state dictionary does not match current state\")\n            if state[\"drop_last\"] != self.drop_last:\n                raise ValueError(\"Mismatch: drop_last parameter in state dictionary does not match current state\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict is None:\n            return\n\n        state: Dict[str, Any] = self._state_dict\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\"Mismatch in shuffle parameter between state dictionary and current state\")\n\n        if state[\"num_workers\"] != self.worker_env.world_size:\n            raise ValueError(\"Mismatch in num_workers parameter between state dictionary and current state\")\n\n        if state[\"input_dir_path\"] != self.input_dir.path or state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\"Mismatch in input directory path or URL between state dictionary and current state\")\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\"Mismatch in seed parameter between state dictionary and current state\")\n\n        if state[\"item_loader\"] != (self.item_loader.state_dict() if self.item_loader else None):\n            raise ValueError(\"Mismatch in item_loader state between state dictionary and current state\")\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\"Mismatch in drop_last flag between state dictionary and current state\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict:\n            state: Dict[str, Any] = self._state_dict\n            if state[\"shuffle\"] != self.shuffle:\n                raise ValueError(\"Mismatch in shuffle parameter between state dictionary and current state\")\n            if state[\"num_workers\"] != self.worker_env.world_size:\n                raise ValueError(\"Mismatch in num_workers parameter between state dictionary and current state\")\n            if state[\"input_dir_path\"] != self.input_dir.path:\n                raise ValueError(\"Mismatch in input directory path between state dictionary and current state\")\n            if state[\"input_dir_url\"] != self.input_dir.url:\n                raise ValueError(\"Mismatch in input directory URL between state dictionary and current state\")\n            if state[\"seed\"] != self.seed:\n                raise ValueError(\"Mismatch in seed parameter between state dictionary and current state\")\n            if state[\"item_loader\"] != self.item_loader.state_dict() if self.item_loader else None:\n                raise ValueError(\"Mismatch in item_loader state between state dictionary and current state\")\n            if state[\"drop_last\"] != self.drop_last:\n                raise ValueError(\"Mismatch in drop_last flag between state dictionary and current state\")"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"XAgent Command Line Interface\")\n    parser.add_argument(\"--task\", type=str, required=True, help=\"The task description, specifying what task should be performed.\")\n    parser.add_argument(\"--upload-files\", nargs='+', type=str, help=\"List of files to upload, allowing multiple files to be specified.\")\n    parser.add_argument(\"--model\", type=str, help=\"Model identifier for the task, specifying which model to use.\")\n    parser.add_argument(\"--record-dir\", type=str, help=\"Directory to record task execution logs, specifying where to save the logs.\")\n    parser.add_argument(\"--mode\", type=str, default=\"auto\", help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\")\n    parser.add_argument(\"--quiet\", action=\"store_true\", help=\"If set, the program runs in quiet mode with minimal output.\")\n    parser.add_argument(\"--max-subtask-chain-length\", type=int, help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\")\n    parser.add_argument(\"--enable-ask-human-for-help\", action=\"store_true\", help=\"Flag to enable asking for human assistance during task execution.\")\n    parser.add_argument(\"--max-plan-refine-chain-length\", type=int, help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\")\n    parser.add_argument(\"--max-plan-tree-depth\", type=int, help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\")\n    parser.add_argument(\"--max-plan-tree-width\", type=int, help=\"Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.\")\n    parser.add_argument(\"--max-retry-times\", type=int, help=\"Maximum number of retry attempts, specifying how many times a task can be retried upon failure.\")\n    parser.add_argument(\"--config-file\", type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help=\"Path to the configuration file, specifying where to find the configuration settings.\")\n\n    return parser.parse_args()"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='Description of your program')\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', nargs='+', type=str, help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', help='Operational mode, which can be \"auto\" or \"manual\", specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file, specifying where to find the configuration settings.')\n\n    return parser.parse_args()"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"XAgent Command Line Interface\")\n    parser.add_argument(\"--task\", type=str, required=True, help=\"The task description, specifying what task should be performed.\")\n    parser.add_argument(\"--upload-files\", nargs='+', type=str, help=\"List of files to upload, allowing multiple files to be specified.\")\n    parser.add_argument(\"--model\", type=str, help=\"Model identifier for the task, specifying which model to use.\")\n    parser.add_argument(\"--record-dir\", type=str, help=\"Directory to record task execution logs, specifying where to save the logs.\")\n    parser.add_argument(\"--mode\", type=str, default=\"auto\", help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\")\n    parser.add_argument(\"--quiet\", action=\"store_true\", help=\"If set, the program runs in quiet mode with minimal output.\")\n    parser.add_argument(\"--max-subtask-chain-length\", type=int, help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\")\n    parser.add_argument(\"--enable-ask-human-for-help\", action=\"store_true\", help=\"Flag to enable asking for human assistance during task execution.\")\n    parser.add_argument(\"--max-plan-refine-chain-length\", type=int, help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\")\n    parser.add_argument(\"--max-plan-tree-depth\", type=int, help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\")\n    parser.add_argument(\"--max-plan-tree-width\", type=int, help=\"Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.\")\n    parser.add_argument(\"--max-retry-times\", type=int, help=\"Maximum number of retry attempts, specifying how many times a task can be retried upon failure.\")\n    parser.add_argument(\"--config-file\", type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help=\"Path to the configuration file, specifying where to find the configuration settings.\")\n\n    return parser.parse_args()"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"Process command line arguments\")\n    parser.add_argument(\"--task\", type=str, required=True, help=\"The task description, specifying what task should be performed.\")\n    parser.add_argument(\"--upload-files\", nargs=\"+\", type=str, help=\"List of files to upload, allowing multiple files to be specified.\")\n    parser.add_argument(\"--model\", type=str, help=\"Model identifier for the task, specifying which model to use.\")\n    parser.add_argument(\"--record-dir\", type=str, help=\"Directory to record task execution logs, specifying where to save the logs.\")\n    parser.add_argument(\"--mode\", type=str, default=\"auto\", help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\")\n    parser.add_argument(\"--quiet\", action=\"store_true\", help=\"If set, the program runs in quiet mode with minimal output.\")\n    parser.add_argument(\"--max-subtask-chain-length\", type=int, help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\")\n    parser.add_argument(\"--enable-ask-human-for-help\", action=\"store_true\", help=\"Flag to enable asking for human assistance during task execution.\")\n    parser.add_argument(\"--max-plan-refine-chain-length\", type=int, help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\")\n    parser.add_argument(\"--max-plan-tree-depth\", type=int, help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\")\n    parser.add_argument(\"--max-plan-tree-width\", type=int, help=\"Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.\")\n    parser.add_argument(\"--max-retry-times\", type=int, help=\"Maximum number of retry attempts, specifying how many times a task can be retried upon failure.\")\n    parser.add_argument(\"--config-file\", type=str, default=os.environ.get('CONFIG_FILE', 'assets/config.yml'), help=\"Path to the configuration file, specifying where to find the configuration settings.\")\n\n    return parser.parse_args()"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"Parse command line arguments\")\n    parser.add_argument(\"--task\", type=str, required=True, help=\"The task description, specifying what task should be performed.\")\n    parser.add_argument(\"--upload-files\", type=str, nargs='+', help=\"List of files to upload, allowing multiple files to be specified.\")\n    parser.add_argument(\"--model\", type=str, help=\"Model identifier for the task, specifying which model to use.\")\n    parser.add_argument(\"--record-dir\", type=str, help=\"Directory to record task execution logs, specifying where to save the logs.\")\n    parser.add_argument(\"--mode\", type=str, default=\"auto\", help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\")\n    parser.add_argument(\"--quiet\", action=\"store_true\", help=\"If set, the program runs in quiet mode with minimal output.\")\n    parser.add_argument(\"--max-subtask-chain-length\", type=int, help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\")\n    parser.add_argument(\"--enable-ask-human-for-help\", action=\"store_true\", help=\"Flag to enable asking for human assistance during task execution.\")\n    parser.add_argument(\"--max-plan-refine-chain-length\", type=int, help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\")\n    parser.add_argument(\"--max-plan-tree-depth\", type=int, help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\")\n    parser.add_argument(\"--max-plan-tree-width\", type=int, help=\"Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.\")\n    parser.add_argument(\"--max-retry-times\", type=int, help=\"Maximum number of retry attempts, specifying how many times a task can be retried upon failure.\")\n    parser.add_argument(\"--config-file\", type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help=\"Path to the configuration file, specifying where to find the configuration settings.\")\n\n    return parser.parse_args()"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"Parse command line arguments\")\n    parser.add_argument(\"--task\", type=str, required=True, help=\"The task description, specifying what task should be performed.\")\n    parser.add_argument(\"--upload-files\", nargs=\"+\", type=str, help=\"List of files to upload, allowing multiple files to be specified.\")\n    parser.add_argument(\"--model\", type=str, help=\"Model identifier for the task, specifying which model to use.\")\n    parser.add_argument(\"--record-dir\", type=str, help=\"Directory to record task execution logs, specifying where to save the logs.\")\n    parser.add_argument(\"--mode\", type=str, default=\"auto\", help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\")\n    parser.add_argument(\"--quiet\", action=\"store_true\", help=\"If set, the program runs in quiet mode with minimal output.\")\n    parser.add_argument(\"--max-subtask-chain-length\", type=int, help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\")\n    parser.add_argument(\"--enable-ask-human-for-help\", action=\"store_true\", help=\"Flag to enable asking for human assistance during task execution.\")\n    parser.add_argument(\"--max-plan-refine-chain-length\", type=int, help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\")\n    parser.add_argument(\"--max-plan-tree-depth\", type=int, help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\")\n    parser.add_argument(\"--max-plan-tree-width\", type=int, help=\"Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.\")\n    parser.add_argument(\"--max-retry-times\", type=int, help=\"Maximum number of retry attempts, specifying how many times a task can be retried upon failure.\")\n    parser.add_argument(\"--config-file\", type=str, default=os.getenv(\"CONFIG_FILE\", \"assets/config.yml\"), help=\"Path to the configuration file, specifying where to find the configuration settings.\")\n\n    return parser.parse_args()"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"Process command line arguments\")\n    parser.add_argument(\"--task\", type=str, required=True, help=\"The task description, specifying what task should be performed.\")\n    parser.add_argument(\"--upload-files\", nargs='+', type=str, help=\"List of files to upload, allowing multiple files to be specified.\")\n    parser.add_argument(\"--model\", type=str, help=\"Model identifier for the task, specifying which model to use.\")\n    parser.add_argument(\"--record-dir\", type=str, help=\"Directory to record task execution logs, specifying where to save the logs.\")\n    parser.add_argument(\"--mode\", type=str, default=\"auto\", help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\")\n    parser.add_argument(\"--quiet\", action=\"store_true\", help=\"If set, the program runs in quiet mode with minimal output.\")\n    parser.add_argument(\"--max-subtask-chain-length\", type=int, help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\")\n    parser.add_argument(\"--enable-ask-human-for-help\", action=\"store_true\", help=\"Flag to enable asking for human assistance during task execution.\")\n    parser.add_argument(\"--max-plan-refine-chain-length\", type=int, help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\")\n    parser.add_argument(\"--max-plan-tree-depth\", type=int, help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\")\n    parser.add_argument(\"--max-plan-tree-width\", type=int, help=\"Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.\")\n    parser.add_argument(\"--max-retry-times\", type=int, help=\"Maximum number of retry attempts, specifying how many times a task can be retried upon failure.\")\n    parser.add_argument(\"--config-file\", type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help=\"Path to the configuration file, specifying where to find the configuration settings.\")\n\n    return parser.parse_args()"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"Parse command line arguments\")\n    parser.add_argument(\"--task\", type=str, required=True, help=\"The task description, specifying what task should be performed.\")\n    parser.add_argument(\"--upload-files\", type=str, nargs='+', help=\"List of files to upload, allowing multiple files to be specified.\")\n    parser.add_argument(\"--model\", type=str, help=\"Model identifier for the task, specifying which model to use.\")\n    parser.add_argument(\"--record-dir\", type=str, help=\"Directory to record task execution logs, specifying where to save the logs.\")\n    parser.add_argument(\"--mode\", type=str, default=\"auto\", help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\")\n    parser.add_argument(\"--quiet\", action=\"store_true\", help=\"If set, the program runs in quiet mode with minimal output.\")\n    parser.add_argument(\"--max-subtask-chain-length\", type=int, help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\")\n    parser.add_argument(\"--enable-ask-human-for-help\", action=\"store_true\", help=\"Flag to enable asking for human assistance during task execution.\")\n    parser.add_argument(\"--max-plan-refine-chain-length\", type=int, help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\")\n    parser.add_argument(\"--max-plan-tree-depth\", type=int, help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\")\n    parser.add_argument(\"--max-plan-tree-width\", type=int, help=\"Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.\")\n    parser.add_argument(\"--max-retry-times\", type=int, help=\"Maximum number of retry attempts, specifying how many times a task can be retried upon failure.\")\n    parser.add_argument(\"--config-file\", type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help=\"Path to the configuration file, specifying where to find the configuration settings.\")\n\n    return parser.parse_args()"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='Process command line arguments')\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', nargs='+', type=str, help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', choices=['auto', 'manual'], help='Operational mode, which can be \"auto\" or \"manual\", specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file, specifying where to find the configuration settings.')\n\n    return parser.parse_args()"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"Parse command line arguments\")\n    parser.add_argument(\"--task\", type=str, required=True, help=\"The task description, specifying what task should be performed.\")\n    parser.add_argument(\"--upload-files\", nargs='+', type=str, help=\"List of files to upload, allowing multiple files to be specified.\")\n    parser.add_argument(\"--model\", type=str, help=\"Model identifier for the task, specifying which model to use.\")\n    parser.add_argument(\"--record-dir\", type=str, help=\"Directory to record task execution logs, specifying where to save the logs.\")\n    parser.add_argument(\"--mode\", type=str, default=\"auto\", help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\")\n    parser.add_argument(\"--quiet\", action=\"store_true\", help=\"If set, the program runs in quiet mode with minimal output.\")\n    parser.add_argument(\"--max-subtask-chain-length\", type=int, help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\")\n    parser.add_argument(\"--enable-ask-human-for-help\", action=\"store_true\", help=\"Flag to enable asking for human assistance during task execution.\")\n    parser.add_argument(\"--max-plan-refine-chain-length\", type=int, help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\")\n    parser.add_argument(\"--max-plan-tree-depth\", type=int, help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\")\n    parser.add_argument(\"--max-plan-tree-width\", type=int, help=\"Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.\")\n    parser.add_argument(\"--max-retry-times\", type=int, help=\"Maximum number of retry attempts, specifying how many times a task can be retried upon failure.\")\n    parser.add_argument(\"--config-file\", type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help=\"Path to the configuration file, specifying where to find the configuration settings.\")\n\n    return parser.parse_args()"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"Parse command line arguments\")\n    parser.add_argument(\"--task\", type=str, required=True, help=\"The task description, specifying what task should be performed.\")\n    parser.add_argument(\"--upload-files\", nargs='+', type=str, help=\"List of files to upload, allowing multiple files to be specified.\")\n    parser.add_argument(\"--model\", type=str, help=\"Model identifier for the task, specifying which model to use.\")\n    parser.add_argument(\"--record-dir\", type=str, help=\"Directory to record task execution logs, specifying where to save the logs.\")\n    parser.add_argument(\"--mode\", type=str, default=\"auto\", help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\")\n    parser.add_argument(\"--quiet\", action=\"store_true\", help=\"If set, the program runs in quiet mode with minimal output.\")\n    parser.add_argument(\"--max-subtask-chain-length\", type=int, help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\")\n    parser.add_argument(\"--enable-ask-human-for-help\", action=\"store_true\", help=\"Flag to enable asking for human assistance during task execution.\")\n    parser.add_argument(\"--max-plan-refine-chain-length\", type=int, help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\")\n    parser.add_argument(\"--max-plan-tree-depth\", type=int, help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\")\n    parser.add_argument(\"--max-plan-tree-width\", type=int, help=\"Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.\")\n    parser.add_argument(\"--max-retry-times\", type=int, help=\"Maximum number of retry attempts, specifying how many times a task can be retried upon failure.\")\n    parser.add_argument(\"--config-file\", type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help=\"Path to the configuration file, specifying where to find the configuration settings.\")\n\n    return parser.parse_args()"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='Process command line arguments')\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', nargs='+', help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\")\n    parser.add_argument('--quiet', action='store_true', default=False, help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file, specifying where to find the configuration settings.')\n\n    return parser.parse_args()"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"Command line arguments for XAgent\")\n\n    parser.add_argument(\"--task\", type=str, required=True, help=\"The task description, specifying what task should be performed.\")\n    parser.add_argument(\"--upload-files\", nargs='+', type=str, help=\"List of files to upload, allowing multiple files to be specified.\")\n    parser.add_argument(\"--model\", type=str, help=\"Model identifier for the task, specifying which model to use.\")\n    parser.add_argument(\"--record-dir\", type=str, help=\"Directory to record task execution logs, specifying where to save the logs.\")\n    parser.add_argument(\"--mode\", type=str, default=\"auto\", choices=[\"auto\", \"manual\"], help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\")\n    parser.add_argument(\"--quiet\", action=\"store_true\", help=\"If set, the program runs in quiet mode with minimal output.\")\n    parser.add_argument(\"--max-subtask-chain-length\", type=int, help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\")\n    parser.add_argument(\"--enable-ask-human-for-help\", action=\"store_true\", help=\"Flag to enable asking for human assistance during task execution.\")\n    parser.add_argument(\"--max-plan-refine-chain-length\", type=int, help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\")\n    parser.add_argument(\"--max-plan-tree-depth\", type=int, help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\")\n    parser.add_argument(\"--max-plan-tree-width\", type=int, help=\"Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.\")\n    parser.add_argument(\"--max-retry-times\", type=int, help=\"Maximum number of retry attempts, specifying how many times a task can be retried upon failure.\")\n    parser.add_argument(\"--config-file\", type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help=\"Path to the configuration file, specifying where to find the configuration settings.\")\n\n    return parser.parse_args()"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='Process command line arguments')\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', type=str, nargs='+', help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', help='Operational mode, which can be \"auto\" or \"manual\", specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file, specifying where to find the configuration settings.')\n\n    return parser.parse_args()"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"XAgent Command Line Interface\")\n    parser.add_argument(\"--task\", type=str, required=True, help=\"The task description, specifying what task should be performed.\")\n    parser.add_argument(\"--upload-files\", nargs='+', type=str, help=\"List of files to upload, allowing multiple files to be specified.\")\n    parser.add_argument(\"--model\", type=str, help=\"Model identifier for the task, specifying which model to use.\")\n    parser.add_argument(\"--record-dir\", type=str, help=\"Directory to record task execution logs, specifying where to save the logs.\")\n    parser.add_argument(\"--mode\", type=str, default=\"auto\", help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\")\n    parser.add_argument(\"--quiet\", action=\"store_true\", help=\"If set, the program runs in quiet mode with minimal output.\")\n    parser.add_argument(\"--max-subtask-chain-length\", type=int, help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\")\n    parser.add_argument(\"--enable-ask-human-for-help\", action=\"store_true\", help=\"Flag to enable asking for human assistance during task execution.\")\n    parser.add_argument(\"--max-plan-refine-chain-length\", type=int, help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\")\n    parser.add_argument(\"--max-plan-tree-depth\", type=int, help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\")\n    parser.add_argument(\"--max-plan-tree-width\", type=int, help=\"Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.\")\n    parser.add_argument(\"--max-retry-times\", type=int, help=\"Maximum number of retry attempts, specifying how many times a task can be retried upon failure.\")\n    parser.add_argument(\"--config-file\", type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help=\"Path to the configuration file, specifying where to find the configuration settings.\")\n\n    return parser.parse_args()"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"XAgent Command Line Interface\")\n    parser.add_argument(\"--task\", type=str, required=True, help=\"The task description, specifying what task should be performed.\")\n    parser.add_argument(\"--upload-files\", nargs=\"+\", type=str, help=\"List of files to upload, allowing multiple files to be specified.\")\n    parser.add_argument(\"--model\", type=str, help=\"Model identifier for the task, specifying which model to use.\")\n    parser.add_argument(\"--record-dir\", type=str, help=\"Directory to record task execution logs, specifying where to save the logs.\")\n    parser.add_argument(\"--mode\", type=str, default=\"auto\", help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\")\n    parser.add_argument(\"--quiet\", action=\"store_true\", help=\"If set, the program runs in quiet mode with minimal output.\")\n    parser.add_argument(\"--max-subtask-chain-length\", type=int, help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\")\n    parser.add_argument(\"--enable-ask-human-for-help\", action=\"store_true\", help=\"Flag to enable asking for human assistance during task execution.\")\n    parser.add_argument(\"--max-plan-refine-chain-length\", type=int, help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\")\n    parser.add_argument(\"--max-plan-tree-depth\", type=int, help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\")\n    parser.add_argument(\"--max-plan-tree-width\", type=int, help=\"Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.\")\n    parser.add_argument(\"--max-retry-times\", type=int, help=\"Maximum number of retry attempts, specifying how many times a task can be retried upon failure.\")\n    parser.add_argument(\"--config-file\", type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help=\"Path to the configuration file, specifying where to find the configuration settings.\")\n\n    return parser.parse_args()"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='Process command line arguments')\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', nargs='+', type=str, help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', help='Operational mode, which can be \"auto\" or \"manual\", specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file, specifying where to find the configuration settings.')\n\n    return parser.parse_args()"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='Process command line arguments')\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', nargs='+', type=str, help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\")\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help=\"Path to the configuration file, specifying where to find the configuration settings.\")\n    return parser.parse_args()"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='Process command line arguments')\n    parser.add_argument('--task', type=str, help='The task description, specifying what task should be performed', required=True)\n    parser.add_argument('--upload-files', nargs='+', type=str, help='List of files to upload, allowing multiple files to be specified')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs')\n    parser.add_argument('--mode', type=str, default='auto', help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed\")\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure')\n    parser.add_argument('--config-file', type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help=\"Path to the configuration file, specifying where to find the configuration settings\")\n\n    return parser.parse_args()"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"Parse command line arguments\")\n    parser.add_argument(\"--task\", type=str, required=True, help=\"The task description, specifying what task should be performed.\")\n    parser.add_argument(\"--upload-files\", nargs='+', type=str, help=\"List of files to upload, allowing multiple files to be specified.\")\n    parser.add_argument(\"--model\", type=str, help=\"Model identifier for the task, specifying which model to use.\")\n    parser.add_argument(\"--record-dir\", type=str, help=\"Directory to record task execution logs, specifying where to save the logs.\")\n    parser.add_argument(\"--mode\", type=str, default=\"auto\", help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\")\n    parser.add_argument(\"--quiet\", action=\"store_true\", help=\"If set, the program runs in quiet mode with minimal output.\")\n    parser.add_argument(\"--max-subtask-chain-length\", type=int, help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\")\n    parser.add_argument(\"--enable-ask-human-for-help\", action=\"store_true\", help=\"Flag to enable asking for human assistance during task execution.\")\n    parser.add_argument(\"--max-plan-refine-chain-length\", type=int, help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\")\n    parser.add_argument(\"--max-plan-tree-depth\", type=int, help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\")\n    parser.add_argument(\"--max-plan-tree-width\", type=int, help=\"Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.\")\n    parser.add_argument(\"--max-retry-times\", type=int, help=\"Maximum number of retry attempts, specifying how many times a task can be retried upon failure.\")\n    parser.add_argument(\"--config-file\", type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help=\"Path to the configuration file, specifying where to find the configuration settings.\")\n\n    return parser.parse_args()"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir:\n        dir_hash = hashlib.md5(input_dir.encode()).hexdigest()\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, dir_hash)\n        try:\n            os.makedirs(cache_dir, exist_ok=True)\n            return cache_dir\n        except Exception as e:\n            logger.error(f\"Error creating cache directory: {e}\")\n            return None\n    else:\n        logger.error(\"Input directory is None. Cache directory cannot be created.\")\n        return None"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.md5(input_dir.encode()).hexdigest())\n        try:\n            os.makedirs(cache_dir, exist_ok=True)\n            return cache_dir\n        except Exception as e:\n            logger.error(f\"Error creating cache directory: {e}\")\n            return None\n    else:\n        logger.error(\"Input directory is None. Cannot create cache directory.\")\n        return None"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.md5(input_dir.encode(\"utf-8\")).hexdigest())\n        try:\n            os.makedirs(cache_dir, exist_ok=True)\n            return cache_dir\n        except Exception as e:\n            logger.warning(f\"Failed to create cache directory: {e}\")\n            return None\n    else:\n        logger.warning(\"Input directory is None. Cannot create cache directory.\")\n        return None"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.md5(input_dir.encode()).hexdigest())\n    else:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.md5(\"\".encode()).hexdigest())\n\n    try:\n        os.makedirs(cache_dir, exist_ok=True)\n        return cache_dir\n    except Exception as e:\n        logger.error(f\"Error creating cache directory: {e}\")\n        return None"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir:\n        cache_dir = hashlib.md5(input_dir.encode()).hexdigest()\n    else:\n        cache_dir = hashlib.md5(\"\".encode()).hexdigest()\n\n    try:\n        if \"CACHE_DIR\" in os.environ:\n            cache_path = os.path.join(os.environ[\"CACHE_DIR\"], cache_dir)\n        else:\n            cache_path = os.path.join(_DEFAULT_CACHE_DIR, cache_dir)\n\n        os.makedirs(cache_path, exist_ok=True)\n        return cache_path\n    except Exception as e:\n        logger.error(f\"Error creating cache directory: {e}\")\n        return None"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Generate a unique directory name by hashing the input directory\n    cache_dir_name = hashlib.md5(input_dir.encode()).hexdigest()\n\n    # Check if the environment variables are set\n    if \"DATA_OPTIMIZER_GLOBAL_RANK\" in os.environ and \"DATA_OPTIMIZER_LOCAL_RANK\" in os.environ:\n        cache_dir = os.path.join(os.environ.get(\"DATA_OPTIMIZER_GLOBAL_RANK\"), cache_dir_name)\n    else:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, cache_dir_name)\n\n    # Attempt to create the cache directory\n    try:\n        os.makedirs(cache_dir, exist_ok=True)\n        return cache_dir\n    except Exception:\n        return None"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Generate a unique directory name by hashing the input directory\n    cache_dir_name = hashlib.md5(input_dir.encode()).hexdigest()\n\n    # Check if environment variables are set for cache directory location\n    if \"CACHE_DIR\" in os.environ:\n        cache_dir = os.path.join(os.environ[\"CACHE_DIR\"], cache_dir_name)\n    else:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, cache_dir_name)\n\n    # Attempt to create the cache directory\n    try:\n        os.makedirs(cache_dir, exist_ok=True)\n        return cache_dir\n    except Exception as e:\n        logger.error(f\"Failed to create cache directory: {cache_dir}. Error: {e}\")\n        return None"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir:\n        # Generate a unique directory name by hashing the input directory\n        cache_dir_name = hashlib.md5(input_dir.encode()).hexdigest()\n    else:\n        cache_dir_name = hashlib.md5(\"\".encode()).hexdigest()\n\n    # Check if environment variables are set for cache directory location\n    if \"DATA_OPTIMIZER_CACHE_DIR\" in os.environ:\n        cache_dir = os.path.join(os.environ[\"DATA_OPTIMIZER_CACHE_DIR\"], cache_dir_name)\n    elif \"TEAMSPACE_CACHE_DIR\" in os.environ:\n        cache_dir = os.path.join(os.environ[\"TEAMSPACE_CACHE_DIR\"], cache_dir_name)\n    else:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, cache_dir_name)\n\n    # Attempt to create the cache directory\n    try:\n        os.makedirs(cache_dir, exist_ok=True)\n        return cache_dir\n    except Exception:\n        return None"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.md5(input_dir.encode()).hexdigest())\n        try:\n            os.makedirs(cache_dir, exist_ok=True)\n            return cache_dir\n        except Exception as e:\n            logger.error(f\"Error creating cache directory: {e}\")\n            return None\n    else:\n        return None"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.md5(input_dir.encode(\"utf-8\")).hexdigest())\n    else:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.md5(\"\".encode(\"utf-8\")).hexdigest())\n\n    try:\n        os.makedirs(cache_dir, exist_ok=True)\n        return cache_dir\n    except Exception as e:\n        logger.error(f\"Failed to create cache directory: {e}\")\n        return None"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir:\n        cache_name = hashlib.md5(input_dir.encode()).hexdigest()\n        cache_path = os.path.join(_DEFAULT_CACHE_DIR, cache_name)\n        try:\n            os.makedirs(cache_path, exist_ok=True)\n            return cache_path\n        except Exception as e:\n            logger.error(f\"Failed to create cache directory: {cache_path}. Error: {e}\")\n            return None\n    else:\n        logger.error(\"Input directory is None. Cannot create cache directory.\")\n        return None"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir:\n        cache_dir = hashlib.md5(input_dir.encode()).hexdigest()\n    else:\n        cache_dir = hashlib.md5(\"\".encode()).hexdigest()\n\n    default_cache_dir = os.path.join(_DEFAULT_CACHE_DIR, cache_dir)\n    specified_cache_dir = os.getenv(\"SPECIFIED_CACHE_DIR\")\n\n    if specified_cache_dir:\n        cache_path = os.path.join(specified_cache_dir, cache_dir)\n    else:\n        cache_path = default_cache_dir\n\n    try:\n        os.makedirs(cache_path, exist_ok=True)\n        return cache_path\n    except Exception as e:\n        logger.error(f\"Error creating cache directory: {e}\")\n        return None"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is not None:\n        input_dir_hash = hashlib.md5(input_dir.encode()).hexdigest()\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, input_dir_hash)\n        try:\n            os.makedirs(cache_dir, exist_ok=True)\n            return cache_dir\n        except Exception as e:\n            logger.error(f\"Error creating cache directory: {e}\")\n            return None\n    else:\n        logger.error(\"Input directory is None. Cannot create cache directory.\")\n        return None"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.md5(input_dir.encode()).hexdigest())\n    else:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.md5(\"\".encode()).hexdigest())\n\n    try:\n        os.makedirs(cache_dir, exist_ok=True)\n        return cache_dir\n    except Exception as e:\n        logger.error(f\"Error creating cache directory: {e}\")\n        return None"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.md5(input_dir.encode()).hexdigest())\n    else:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.md5(\"\".encode()).hexdigest())\n\n    try:\n        os.makedirs(cache_dir, exist_ok=True)\n        return cache_dir\n    except Exception as e:\n        logger.error(f\"Error creating cache directory: {e}\")\n        return None"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Generate a unique directory name by hashing the input directory\n    cache_dir_name = hashlib.md5(input_dir.encode()).hexdigest()\n\n    # Check if the environment variables are set\n    if \"TEAMSPACE_DATASETS\" in os.environ and \"TEAMSPACE_CACHE_DIR\" in os.environ:\n        cache_dir = os.path.join(os.environ[\"TEAMSPACE_CACHE_DIR\"], cache_dir_name)\n    else:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, cache_dir_name)\n\n    # Attempt to create the cache directory\n    try:\n        os.makedirs(cache_dir, exist_ok=True)\n        return cache_dir\n    except Exception as e:\n        logger.error(f\"Failed to create cache directory: {cache_dir}. Error: {e}\")\n        return None"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.md5(input_dir.encode(\"utf-8\")).hexdigest())\n    else:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.md5(\"\".encode(\"utf-8\")).hexdigest())\n\n    try:\n        os.makedirs(cache_dir, exist_ok=True)\n        return cache_dir\n    except Exception as e:\n        logger.error(f\"Error creating cache directory: {e}\")\n        return None"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.md5(input_dir.encode(\"utf-8\")).hexdigest())\n\n    if not os.path.exists(cache_dir):\n        try:\n            os.makedirs(cache_dir, exist_ok=True)\n            return cache_dir\n        except Exception as e:\n            logger.warning(f\"Failed to create cache directory: {e}\")\n            return None\n    else:\n        return cache_dir"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Generate a unique directory name by hashing the input directory\n    unique_dir_name = hashlib.md5(input_dir.encode()).hexdigest()\n\n    # Check if environment variables are set\n    if \"CACHE_DIR\" in os.environ and \"TEAMSPACE\" in os.environ:\n        cache_dir = os.path.join(os.environ[\"CACHE_DIR\"], unique_dir_name)\n    else:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, unique_dir_name)\n\n    # Attempt to create the cache directory\n    try:\n        os.makedirs(cache_dir, exist_ok=True)\n        return cache_dir\n    except Exception as e:\n        logger.error(f\"Error creating cache directory: {e}\")\n        return None"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Generate a unique directory name by hashing the input directory\n    cache_dir_name = hashlib.md5(input_dir.encode()).hexdigest()\n\n    # Check if environment variables are set to determine the location of the cache directory\n    if os.getenv(\"CACHE_DIR\"):\n        cache_dir = os.path.join(os.getenv(\"CACHE_DIR\"), cache_dir_name)\n    else:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, cache_dir_name)\n\n    # Attempt to create the cache directory\n    try:\n        os.makedirs(cache_dir, exist_ok=True)\n        return cache_dir\n    except Exception as e:\n        logger.error(f\"Error creating cache directory: {e}\")\n        return None"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\" or path.startswith(\"/cache\") or path.startswith(_DEFAULT_CACHE_DIR):\n        return True\n    else:\n        return False"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if not path or path.startswith(\"/cache\") or path.startswith(\"gs://\"):\n        return True\n    return False"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\" or path.startswith(\"/cache\") or path.startswith(_DEFAULT_CACHE_DIR):\n        return True\n    else:\n        return False"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    return path is None or path == \"\" or path.startswith(\"/cache\") or path.startswith(\"gs://\")"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    return path is None or path == \"\" or path.startswith(\"/cache\") or path.startswith(\"gs://\") or path.startswith(\"s3://\")"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    return path is None or path == \"\" or path.startswith(\"/cache\") or path.startswith(\"gs://\")"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\" or path.startswith(\"/cache\") or path.startswith(\"s3://\"):\n        return True\n    else:\n        return False"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if not path or path.startswith(\"/cache\") or path.startswith(_DEFAULT_CACHE_DIR):\n        return True\n    return False"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    return path is None or path == \"\" or path.startswith(\"/cache\") or path.startswith(\"gs://\")"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\" or path.startswith(\"/cache\") or path.startswith(_DEFAULT_CACHE_DIR):\n        return True\n    else:\n        return False"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    return path is None or path == \"\" or path.startswith((\"/special_prefix1\", \"/special_prefix2\"))"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\" or path.startswith(\"/cache\") or path.startswith(_DEFAULT_CACHE_DIR):\n        return True\n    else:\n        return False"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\" or path.startswith((\"/cache\", \"gs://\", \"s3://\")):\n        return True\n    else:\n        return False"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\" or path.startswith(\"/cache\") or path.startswith(_DEFAULT_CACHE_DIR):\n        return True\n    return False"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\" or path.startswith((\"/cache\", \"http://\", \"https://\")):\n        return True\n    else:\n        return False"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    return path is None or path == \"\" or path.startswith(\"/cache\") or path.startswith(\"gs://\")"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\" or path.startswith(\"/cache\") or path.startswith(_DEFAULT_CACHE_DIR):\n        return True\n    else:\n        return False"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if not path or path.startswith(\"/cache\") or path.startswith(\"gs://\"):\n        return True\n    return False"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\" or path.startswith(\"/cache\") or path.startswith(_DEFAULT_CACHE_DIR):\n        return True\n    else:\n        return False"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\" or path.startswith(\"/cache\"):\n        return True\n    else:\n        return False"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    samples_per_worker = num_samples_yielded // batch_size // num_workers\n    remaining_samples = num_samples_yielded // batch_size % num_workers\n\n    samples_distribution = {i: samples_per_worker for i in range(num_workers)}\n    for i in range(remaining_samples):\n        samples_distribution[i] += 1\n\n    return samples_distribution"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples each worker should have processed\n    num_samples_per_worker = num_samples_yielded // num_workers\n    remaining_samples = num_samples_yielded % num_workers\n\n    # Initialize the dictionary to store the number of samples processed by each worker\n    samples_processed = {}\n\n    # Distribute the remaining samples among the workers\n    for i in range(num_workers):\n        if i < remaining_samples:\n            samples_processed[i] = num_samples_per_worker + 1\n        else:\n            samples_processed[i] = num_samples_per_worker\n\n    return samples_processed"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    samples_per_worker = num_samples_yielded // batch_size // num_workers\n    remaining_samples = num_samples_yielded // batch_size % num_workers\n\n    samples = {i: samples_per_worker for i in range(num_workers)}\n\n    for i in range(remaining_samples):\n        samples[i] += 1\n\n    return samples"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples each worker should have processed based on the total number of samples yielded\n    samples_per_worker = num_samples_yielded // num_workers\n    remaining_samples = num_samples_yielded % num_workers\n\n    # Initialize a dictionary to store the number of samples processed by each worker\n    samples_processed = {}\n\n    # Distribute the samples evenly among the workers\n    for i in range(num_workers):\n        samples_processed[i] = samples_per_worker\n\n    # Distribute any remaining samples among the workers\n    for i in range(remaining_samples):\n        samples_processed[i] += 1\n\n    return samples_processed"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    samples_per_worker = num_samples_yielded // batch_size // num_workers\n    remaining_samples = num_samples_yielded // batch_size % num_workers\n\n    samples_per_worker_dict = {i: samples_per_worker for i in range(num_workers)}\n    for i in range(remaining_samples):\n        samples_per_worker_dict[i] += 1\n\n    return samples_per_worker_dict"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    total_samples_per_worker = num_samples_yielded // num_workers\n    remaining_samples = num_samples_yielded % num_workers\n\n    samples_per_worker = {i: total_samples_per_worker for i in range(num_workers)}\n    for i in range(remaining_samples):\n        samples_per_worker[i] += 1\n\n    return samples_per_worker"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    samples_per_worker = num_samples_yielded // batch_size // num_workers\n    remaining_samples = num_samples_yielded // batch_size % num_workers\n\n    samples_per_worker_dict = {i: samples_per_worker for i in range(num_workers)}\n\n    for i in range(remaining_samples):\n        samples_per_worker_dict[i] += 1\n\n    return samples_per_worker_dict"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    samples_per_worker = num_samples_yielded // num_workers\n    remaining_samples = num_samples_yielded % num_workers\n\n    samples_processed = {i: samples_per_worker for i in range(num_workers)}\n\n    for i in range(remaining_samples):\n        samples_processed[i] += 1\n\n    return samples_processed"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    samples_per_worker = num_samples_yielded // num_workers\n    remaining_samples = num_samples_yielded % num_workers\n\n    samples_distribution = {i: samples_per_worker for i in range(num_workers)}\n    for i in range(remaining_samples):\n        samples_distribution[i] += 1\n\n    return samples_distribution"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    samples_per_worker = num_samples_yielded // num_workers\n    remaining_samples = num_samples_yielded % num_workers\n\n    samples_distribution = {i: samples_per_worker for i in range(num_workers)}\n\n    for i in range(remaining_samples):\n        samples_distribution[i] += 1\n\n    return samples_distribution"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the base number of samples each worker should have processed\n    base_samples_per_worker = num_samples_yielded // num_workers\n\n    # Calculate the remaining samples after evenly distributing among workers\n    remaining_samples = num_samples_yielded % num_workers\n\n    # Initialize the dictionary to store the number of samples processed by each worker\n    samples_per_worker = {}\n\n    # Distribute the base number of samples to each worker\n    for i in range(num_workers):\n        samples_per_worker[i] = base_samples_per_worker\n\n    # Distribute the remaining samples among workers\n    for i in range(remaining_samples):\n        samples_per_worker[i] += 1\n\n    return samples_per_worker"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    num_samples_per_worker = num_samples_yielded // num_workers\n    remaining_samples = num_samples_yielded % num_workers\n\n    samples_processed = {}\n    for i in range(num_workers):\n        samples_processed[i] = num_samples_per_worker\n\n    for i in range(remaining_samples):\n        samples_processed[i] += 1\n\n    return samples_processed"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples each worker should have processed based on the total number of samples yielded\n    # and the batch size\n    samples_per_worker = num_samples_yielded // num_workers\n    remaining_samples = num_samples_yielded % num_workers\n\n    # Create a dictionary to store the number of samples processed by each worker\n    worker_samples = {}\n\n    # Distribute the samples evenly among the workers\n    for i in range(num_workers):\n        if i < remaining_samples:\n            worker_samples[i] = samples_per_worker + 1\n        else:\n            worker_samples[i] = samples_per_worker\n\n    return worker_samples"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples processed per worker\n    samples_per_worker = num_samples_yielded // batch_size // num_workers\n    remainder = num_samples_yielded % (batch_size * num_workers)\n\n    # Initialize the dictionary to store the number of samples processed per worker\n    samples_processed = {}\n\n    # Distribute the samples evenly among workers\n    for i in range(num_workers):\n        samples_processed[i] = samples_per_worker\n\n    # Distribute any remaining samples\n    for i in range(remainder):\n        samples_processed[i] += 1\n\n    return samples_processed"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples processed by each worker\n    samples_per_worker = num_samples_yielded // batch_size // num_workers\n    remaining_samples = num_samples_yielded // batch_size % num_workers\n\n    # Create a dictionary to store the number of samples processed by each worker\n    samples_processed = {}\n\n    # Distribute the samples evenly among the workers\n    for i in range(num_workers):\n        samples_processed[i] = samples_per_worker\n\n    # Distribute any remaining samples among the workers\n    for i in range(remaining_samples):\n        samples_processed[i] += 1\n\n    return samples_processed"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    samples_per_worker = num_samples_yielded // batch_size // num_workers\n    remaining_samples = num_samples_yielded // batch_size % num_workers\n\n    samples_per_worker_dict = {i: samples_per_worker for i in range(num_workers)}\n\n    for i in range(remaining_samples):\n        samples_per_worker_dict[i] += 1\n\n    return samples_per_worker_dict"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    samples_per_worker = num_samples_yielded // num_workers\n    remaining_samples = num_samples_yielded % num_workers\n\n    samples_distribution = {i: samples_per_worker for i in range(num_workers)}\n    for i in range(remaining_samples):\n        samples_distribution[i] += 1\n\n    return samples_distribution"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples each worker should have processed\n    samples_per_worker = num_samples_yielded // num_workers\n    remaining_samples = num_samples_yielded % num_workers\n\n    # Initialize the dictionary to store the number of samples processed by each worker\n    samples_processed = {}\n\n    # Distribute the samples evenly among the workers\n    for i in range(num_workers):\n        samples_processed[i] = samples_per_worker\n\n    # Distribute any remaining samples\n    for i in range(remaining_samples):\n        samples_processed[i] += 1\n\n    return samples_processed"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    samples_per_worker = {}\n    samples_per_batch = batch_size * num_workers\n    num_full_batches = num_samples_yielded // samples_per_batch\n    remaining_samples = num_samples_yielded % samples_per_batch\n\n    for i in range(num_workers):\n        samples_per_worker[i] = num_full_batches * batch_size\n        if i < remaining_samples:\n            samples_per_worker[i] += batch_size\n        elif i == remaining_samples:\n            samples_per_worker[i] += remaining_samples\n\n    return samples_per_worker"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    samples_per_worker = num_samples_yielded // (batch_size * num_workers)\n    remaining_samples = num_samples_yielded % (batch_size * num_workers)\n\n    samples_distribution = {i: samples_per_worker for i in range(num_workers)}\n    for i in range(remaining_samples):\n        samples_distribution[i] += 1\n\n    return samples_distribution"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_remote_filepath = parse.urlparse(remote_filepath)\n        if parsed_remote_filepath.scheme != \"s3\":\n            raise ValueError(\"The remote file path must use the 's3' scheme\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        lock_filepath = local_filepath + \".lock\"\n        with FileLock(lock_filepath, timeout=60):\n            if self._s5cmd_available:\n                subprocess.run([\"s5cmd\", \"cp\", remote_filepath, local_filepath], check=True)\n            else:\n                self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if not remote_filepath.startswith(\"s3://\"):\n            raise ValueError(\"The remote file path must use the 's3' scheme\")\n\n        if os.path.exists(local_filepath):\n            return  # File already exists, no need to download\n\n        with FileLock(local_filepath + \".lock\", timeout=10):\n            if self._s5cmd_available:\n                subprocess.run([\"s5cmd\", \"cp\", remote_filepath, local_filepath], check=True)\n            else:\n                self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(\"The remote file path must use the 's3' scheme\")\n\n        if not os.path.exists(local_filepath):\n            with FileLock(local_filepath + \".lock\", timeout=10):\n                if self._s5cmd_available:\n                    subprocess.run([\"s5cmd\", \"cp\", remote_filepath, local_filepath])\n                else:\n                    self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != 's3':\n            raise ValueError(\"The remote file path does not use the 's3' scheme\")\n\n        if not os.path.exists(local_filepath):\n            with FileLock(local_filepath + '.lock', timeout=60):\n                if self._s5cmd_available:\n                    subprocess.run(['s5cmd', 'cp', remote_filepath, local_filepath])\n                else:\n                    self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != 's3':\n            raise ValueError(\"The remote file path must use the 's3' scheme\")\n\n        if not os.path.exists(local_filepath):\n            lock_filepath = local_filepath + '.lock'\n            with FileLock(lock_filepath, timeout=60):\n                if self._s5cmd_available:\n                    subprocess.run([\"s5cmd\", \"cp\", remote_filepath, local_filepath], check=True)\n                else:\n                    self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(\"The remote file path must use the 's3' scheme\")\n\n        if not os.path.exists(local_filepath):\n            lock_file = local_filepath + \".lock\"\n            with FileLock(lock_file, timeout=10):\n                if self._s5cmd_available:\n                    subprocess.run([\"s5cmd\", \"cp\", remote_filepath, local_filepath])\n                else:\n                    self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != 's3':\n            raise ValueError(\"The remote file path must use the 's3' scheme\")\n\n        if not os.path.exists(local_filepath):\n            with FileLock(local_filepath + '.lock', timeout=10):\n                if self._s5cmd_available:\n                    subprocess.run(['s5cmd', 'cp', remote_filepath, local_filepath])\n                else:\n                    self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(\"The provided remote file path is not an S3 URL.\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        with FileLock(local_filepath + \".lock\", timeout=10):\n            if self._s5cmd_available:\n                subprocess.run([\"s5cmd\", \"cp\", remote_filepath, local_filepath], check=True)\n            else:\n                self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(\"The remote file path must use the 's3' scheme\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        lock_filepath = local_filepath + \".lock\"\n        with FileLock(lock_filepath, timeout=60):\n            if self._s5cmd_available:\n                subprocess.run([\"s5cmd\", \"cp\", remote_filepath, local_filepath])\n            else:\n                self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if not remote_filepath.startswith(\"s3://\"):\n            raise ValueError(\"The remote file path must use the 's3' scheme\")\n\n        if os.path.exists(local_filepath):\n            return  # Local file already exists\n\n        lock_filepath = local_filepath + \".lock\"\n        with FileLock(lock_filepath, timeout=30):\n            if self._s5cmd_available:\n                subprocess.run([\"s5cmd\", \"cp\", remote_filepath, local_filepath])\n            else:\n                self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(\"The provided remote_filepath is not an S3 URL.\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        lock_path = local_filepath + \".lock\"\n        with FileLock(lock_path, timeout=60):\n            if self._s5cmd_available:\n                subprocess.run([\"s5cmd\", \"cp\", remote_filepath, local_filepath], check=True)\n            else:\n                self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(\"The provided remote file path is not an S3 URL.\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        lock_filepath = f\"{local_filepath}.lock\"\n        with FileLock(lock_filepath, timeout=60):\n            if self._s5cmd_available:\n                subprocess.run([\"s5cmd\", \"cp\", remote_filepath, local_filepath])\n            else:\n                self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(\"The provided remote file path is not an S3 URL.\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        lock_filepath = local_filepath + \".lock\"\n        with FileLock(lock_filepath, timeout=10):\n            if self._s5cmd_available:\n                subprocess.run([\"s5cmd\", \"cp\", remote_filepath, local_filepath], check=True)\n            else:\n                self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if not os.path.exists(local_filepath):\n            parsed_remote_filepath = parse.urlparse(remote_filepath)\n            if parsed_remote_filepath.scheme != \"s3\":\n                raise ValueError(\"The remote file path must use the 's3' scheme.\")\n\n            lock_filepath = f\"{local_filepath}.lock\"\n            with FileLock(lock_filepath, timeout=60):\n                if not os.path.exists(local_filepath):\n                    if self._s5cmd_available:\n                        subprocess.run([\"s5cmd\", \"cp\", remote_filepath, local_filepath])\n                    else:\n                        self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_remote_filepath = parse.urlparse(remote_filepath)\n        if parsed_remote_filepath.scheme != 's3':\n            raise ValueError(\"The remote file path must use the 's3' scheme\")\n\n        if not os.path.exists(local_filepath):\n            with FileLock(local_filepath + '.lock', timeout=10):\n                if self._s5cmd_available:\n                    subprocess.run(['s5cmd', 'cp', remote_filepath, local_filepath], check=True)\n                else:\n                    self._client.download_file(parsed_remote_filepath.netloc, parsed_remote_filepath.path.lstrip('/'), local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(\"The remote file path must use the 's3' scheme\")\n\n        if not os.path.exists(local_filepath):\n            with FileLock(local_filepath + \".lock\", timeout=10):\n                if self._s5cmd_available:\n                    subprocess.run([\"s5cmd\", \"cp\", remote_filepath, local_filepath], check=True)\n                else:\n                    self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(\"The remote file path must use the 's3' scheme.\")\n\n        if not os.path.exists(local_filepath):\n            with FileLock(local_filepath + \".lock\", timeout=10):\n                if self._s5cmd_available:\n                    subprocess.run([\"s5cmd\", \"cp\", remote_filepath, local_filepath], check=True)\n                else:\n                    self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(\"The remote file path must be an S3 URL.\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        lock_path = local_filepath + \".lock\"\n        with FileLock(lock_path, timeout=60):\n            if self._s5cmd_available:\n                subprocess.run([\"s5cmd\", \"cp\", remote_filepath, local_filepath], check=True)\n            else:\n                self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(\"The remote file path must use the 's3' scheme\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        lock_filepath = local_filepath + \".lock\"\n        with FileLock(lock_filepath, timeout=60):\n            if self._s5cmd_available:\n                subprocess.run([\"s5cmd\", \"cp\", remote_filepath, local_filepath], check=True)\n            else:\n                self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(\"The remote file path must use the 's3' scheme.\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        lock_filepath = local_filepath + \".lock\"\n        with FileLock(lock_filepath, timeout=60):\n            if self._s5cmd_available:\n                subprocess.run([\"s5cmd\", \"cp\", remote_filepath, local_filepath], check=True)\n            else:\n                self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    workers_chunks = {}\n    workers_intervals = {}\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        worker_idx = i % worker_env.world_size\n        if worker_idx not in workers_chunks:\n            workers_chunks[worker_idx] = []\n            workers_intervals[worker_idx] = []\n        workers_chunks[worker_idx].append(chunk_index)\n        workers_intervals[worker_idx].append(chunk_interval)\n    return workers_chunks, workers_intervals"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # Calculate the total number of chunks and intervals\n    total_chunks = len(chunks_replica)\n    total_intervals = len(intervals_replica)\n\n    # Calculate the number of chunks and intervals to be assigned to each worker\n    chunks_per_worker = total_chunks // num_workers\n    intervals_per_worker = total_intervals // num_workers\n\n    # Calculate the remaining chunks and intervals after evenly distributing among workers\n    remaining_chunks = total_chunks % num_workers\n    remaining_intervals = total_intervals % num_workers\n\n    # Initialize dictionaries to store the assigned chunks and intervals for each worker\n    workers_chunks = {}\n    workers_intervals = {}\n\n    # Assign chunks and intervals to each worker based on their index and world size\n    for worker_idx in range(num_workers):\n        # Calculate the start and end indices for chunks and intervals based on worker index\n        start_chunk_idx = worker_idx * chunks_per_worker + min(worker_idx, remaining_chunks)\n        end_chunk_idx = start_chunk_idx + chunks_per_worker + (1 if worker_idx < remaining_chunks else 0)\n\n        start_interval_idx = worker_idx * intervals_per_worker + min(worker_idx, remaining_intervals)\n        end_interval_idx = start_interval_idx + intervals_per_worker + (1 if worker_idx < remaining_intervals else 0)\n\n        # Assign chunks and intervals to the current worker\n        workers_chunks[worker_idx] = chunks_replica[start_chunk_idx:end_chunk_idx]\n        workers_intervals[worker_idx] = intervals_replica[start_interval_idx:end_interval_idx]\n\n    return workers_chunks, workers_intervals"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    chunks_per_replica = {}\n    intervals_per_replica = {}\n\n    for worker_idx in range(num_workers):\n        chunks_per_replica[worker_idx] = []\n        intervals_per_replica[worker_idx] = []\n\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        if i % worker_env.world_size != worker_env.rank:\n            continue\n        worker_idx = i % num_workers\n        chunks_per_replica[worker_idx].append(chunk_index)\n        intervals_per_replica[worker_idx].append(chunk_interval)\n\n    return chunks_per_replica, intervals_per_replica"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    chunks_per_replica = chunks_replica\n    intervals_per_replica = intervals_replica\n\n    # Distribute chunks and intervals to workers based on their index and total world size\n    workers_chunks = {}\n    workers_intervals = {}\n\n    for worker_idx in range(worker_env.world_size):\n        workers_chunks[worker_idx] = []\n        workers_intervals[worker_idx] = []\n\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_per_replica, intervals_per_replica)):\n        if i % worker_env.world_size != worker_env.rank:\n            continue\n        worker_idx = i % worker_env.world_size\n        workers_chunks[worker_idx].append(chunk_index)\n        workers_intervals[worker_idx].append(chunk_interval)\n\n    return workers_chunks, workers_intervals"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # Calculate the number of chunks per worker\n    chunks_per_worker = len(chunks_replica) // worker_env.world_size\n    remainder = len(chunks_replica) % worker_env.world_size\n\n    # Distribute the chunks and intervals to workers\n    workers_chunks = {}\n    workers_intervals = {}\n    start = 0\n    for i in range(worker_env.world_size):\n        num_chunks = chunks_per_worker + (1 if i < remainder else 0)\n        end = start + num_chunks\n\n        worker_idx = (i + worker_env.rank) % worker_env.world_size\n        workers_chunks[worker_idx] = chunks_replica[start:end]\n        workers_intervals[worker_idx] = intervals_replica[start:end]\n\n        start = end\n\n    return workers_chunks, workers_intervals"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    chunks_per_replica = {}\n    intervals_per_replica = {}\n\n    for i in range(num_workers):\n        chunks_per_replica[i] = []\n        intervals_per_replica[i] = []\n\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        worker_idx = i % worker_env.world_size\n        chunks_per_replica[worker_idx].append(chunk_index)\n        intervals_per_replica[worker_idx].append(chunk_interval)\n\n    return chunks_per_replica, intervals_per_replica"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    workers_chunks = {}\n    workers_intervals = {}\n\n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        if i % worker_env.world_size != worker_env.rank:\n            continue\n        worker_idx = i % num_workers\n        workers_chunks[worker_idx].append(chunk_index)\n        workers_intervals[worker_idx].append(chunk_interval)\n\n    return workers_chunks, workers_intervals"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    chunk_interval_size = len(chunks_replica) // num_workers\n    chunks_per_worker = {i: [] for i in range(num_workers)}\n    intervals_per_worker = {i: [] for i in range(num_workers)}\n\n    for i, (chunk, interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        worker_idx = i % num_workers\n        chunks_per_worker[worker_idx].append(chunk)\n        intervals_per_worker[worker_idx].append(interval)\n\n    return chunks_per_worker, intervals_per_worker"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # Calculate the number of chunks and intervals to be distributed to each worker\n    chunks_per_worker = len(chunks_replica) // worker_env.world_size\n    intervals_per_worker = len(intervals_replica) // worker_env.world_size\n\n    # Distribute the chunks and intervals to each worker based on their index\n    workers_chunks = {}\n    workers_intervals = {}\n    for i in range(worker_env.world_size):\n        start_chunk = i * chunks_per_worker\n        end_chunk = (i + 1) * chunks_per_worker\n        workers_chunks[i] = chunks_replica[start_chunk:end_chunk]\n\n        start_interval = i * intervals_per_worker\n        end_interval = (i + 1) * intervals_per_worker\n        workers_intervals[i] = intervals_replica[start_interval:end_interval]\n\n    return workers_chunks, workers_intervals"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    chunks_per_replica = {i: [] for i in range(num_workers)}\n    intervals_per_replica = {i: [] for i in range(num_workers)}\n\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        worker_idx = i % worker_env.world_size\n        chunks_per_replica[worker_idx].append(chunk_index)\n        intervals_per_replica[worker_idx].append(chunk_interval)\n\n    return chunks_per_replica, intervals_per_replica"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # Calculate the total number of chunks and intervals\n    total_chunks = len(chunks_replica)\n    total_intervals = len(intervals_replica)\n\n    # Calculate the chunks and intervals per worker\n    chunks_per_worker = total_chunks // num_workers\n    intervals_per_worker = total_intervals // num_workers\n\n    # Initialize dictionaries to store chunks and intervals assigned to each worker\n    workers_chunks = {}\n    workers_intervals = {}\n\n    # Distribute chunks and intervals to each worker\n    for i in range(num_workers):\n        start_chunk = i * chunks_per_worker\n        end_chunk = (i + 1) * chunks_per_worker\n        workers_chunks[i] = chunks_replica[start_chunk:end_chunk]\n\n        start_interval = i * intervals_per_worker\n        end_interval = (i + 1) * intervals_per_worker\n        workers_intervals[i] = intervals_replica[start_interval:end_interval]\n\n    return workers_chunks, workers_intervals"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # Calculate the number of chunks per worker\n    chunks_per_worker = len(chunks_replica) // worker_env.world_size\n    remainder = len(chunks_replica) % worker_env.world_size\n\n    # Distribute the chunks and intervals to the workers\n    workers_chunks = {}\n    workers_intervals = {}\n\n    start = 0\n    for i in range(worker_env.world_size):\n        num_chunks = chunks_per_worker + (1 if i < remainder else 0)\n        end = start + num_chunks\n\n        workers_chunks[i] = chunks_replica[start:end]\n        workers_intervals[i] = intervals_replica[start:end]\n\n        start = end\n\n    return workers_chunks, workers_intervals"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    chunk_per_worker = len(chunks_replica) // num_workers\n    intervals_per_worker = len(intervals_replica) // num_workers\n\n    workers_chunks = {i: [] for i in range(num_workers)}\n    workers_intervals = {i: [] for i in range(num_workers)}\n\n    for i, (chunk, interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        worker_idx = i % num_workers\n        workers_chunks[worker_idx].append(chunk)\n        workers_intervals[worker_idx].append(interval)\n\n    return workers_chunks, workers_intervals"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    chunks_per_replica = {}\n    intervals_per_replica = {}\n\n    for worker_idx in range(num_workers):\n        chunks_per_replica[worker_idx] = []\n        intervals_per_replica[worker_idx] = []\n\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        if i % worker_env.world_size != worker_env.rank:\n            continue\n        worker_idx = i % num_workers\n        chunks_per_replica[worker_idx].append(chunk_index)\n        intervals_per_replica[worker_idx].append(chunk_interval)\n\n    return chunks_per_replica, intervals_per_replica"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    workers_chunks = {}\n    workers_intervals = {}\n\n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        worker_idx = i % worker_env.world_size\n        workers_chunks[worker_idx].append(chunk_index)\n        workers_intervals[worker_idx].append(chunk_interval)\n\n    return workers_chunks, workers_intervals"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    worker_chunks = {}\n    worker_intervals = {}\n\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        if i % worker_env.world_size != worker_env.rank:\n            continue\n        worker_idx = i % num_workers\n        if worker_idx not in worker_chunks:\n            worker_chunks[worker_idx] = []\n            worker_intervals[worker_idx] = []\n        worker_chunks[worker_idx].append(chunk_index)\n        worker_intervals[worker_idx].append(chunk_interval)\n\n    return worker_chunks, worker_intervals"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    workers_chunks = {}\n    workers_intervals = {}\n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        if i % worker_env.world_size != worker_env.rank:\n            continue\n        worker_idx = i % num_workers\n        workers_chunks[worker_idx].append(chunk_index)\n        workers_intervals[worker_idx].append(chunk_interval)\n\n    return workers_chunks, workers_intervals"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    chunks_per_replica = chunks_replica\n    intervals_per_replica = intervals_replica\n\n    workers_chunks = {}\n    workers_intervals = {}\n\n    for worker_idx in range(num_workers):\n        workers_chunks[worker_idx] = []\n        workers_intervals[worker_idx] = []\n\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_per_replica, intervals_per_replica)):\n        if i % worker_env.world_size != worker_env.rank:\n            continue\n        worker_idx = i % num_workers\n        workers_chunks[worker_idx].append(chunk_index)\n        workers_intervals[worker_idx].append(chunk_interval)\n\n    return workers_chunks, workers_intervals"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    chunks_per_replica = {}\n    intervals_per_replica = {}\n\n    for worker_idx in range(num_workers):\n        chunks_per_replica[worker_idx] = []\n        intervals_per_replica[worker_idx] = []\n\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        if i % worker_env.world_size != worker_env.rank:\n            continue\n        worker_idx = i % num_workers\n        chunks_per_replica[worker_idx].append(chunk_index)\n        intervals_per_replica[worker_idx].append(chunk_interval)\n\n    return chunks_per_replica, intervals_per_replica"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    chunks_per_replica = len(chunks_replica)\n    workers_chunks = {i: [] for i in range(num_workers)}\n    workers_intervals = {i: [] for i in range(num_workers)}\n\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        worker_idx = i % num_workers\n        workers_chunks[worker_idx].append(chunk_index)\n        workers_intervals[worker_idx].append(chunk_interval)\n\n    return workers_chunks, workers_intervals"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        remote_filepath = remote_filepath.replace(\"local:\", \"\")\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\", 1)\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        remote_filepath = remote_filepath.replace(\"local:\", \"\")\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\", 1)\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\")\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        remote_filepath = remote_filepath.replace(\"local:\", \"\")\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\", 1)\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\")\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        remote_filepath = remote_filepath.replace(\"local:\", \"\")\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\", 1)\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        remote_filepath = remote_filepath.replace(\"local:\", \"\")\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\", 1)\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        remote_filepath = remote_filepath.replace(\"local:\", \"\")\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\", 1)\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        remote_filepath = remote_filepath.replace(\"local:\", \"\")\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\")\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        remote_filepath = remote_filepath.replace(\"local:\", \"\")\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        chunk_index = 0\n        for interval in intervals:\n            interval_size = interval[1] - interval[0]\n            if indexes[worker_idx] < interval_size:\n                chunk_index = intervals.index(interval)\n                break\n            else:\n                indexes[worker_idx] -= interval_size\n\n        chunks_index[worker_idx] = chunk_index\n        updated_indexes[worker_idx] = indexes[worker_idx]\n\n    return chunks_index, updated_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        chunk_index = 0\n        current_index = indexes[worker_idx]\n\n        for interval in intervals:\n            interval_size = interval[1] - interval[0]\n            if current_index < interval_size:\n                chunk_index = intervals.index(interval)\n                break\n            else:\n                current_index -= interval_size\n\n        chunks_index[worker_idx] = chunk_index\n        updated_indexes[worker_idx] = current_index\n\n    return chunks_index, updated_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        total_interval_size = sum([interval[-1] - interval[0] for interval in intervals])\n        if total_interval_size == 0:\n            chunks_index[worker_idx] = 0\n            updated_indexes[worker_idx] = indexes[worker_idx]\n        else:\n            num_intervals = len(intervals)\n            total_indexes = indexes[worker_idx]\n            chunk_index = 0\n            for i in range(num_intervals):\n                interval = intervals[i]\n                interval_size = interval[-1] - interval[0]\n                if total_indexes < interval_size:\n                    chunk_index = i\n                    break\n                total_indexes -= interval_size\n            chunks_index[worker_idx] = chunk_index\n            updated_indexes[worker_idx] = total_indexes\n\n    return chunks_index, updated_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        chunk_index = 0\n        for interval in intervals:\n            interval_size = interval[1] - interval[0]\n            if indexes[worker_idx] < interval_size:\n                break\n            indexes[worker_idx] -= interval_size\n            chunk_index += 1\n\n        chunks_index[worker_idx] = chunk_index\n        updated_indexes[worker_idx] = indexes[worker_idx]\n\n    return chunks_index, updated_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        current_index = indexes[worker_idx]\n        chunk_index = 0\n\n        for interval in intervals:\n            interval_size = interval[1] - interval[0]\n            if current_index < interval_size:\n                break\n            current_index -= interval_size\n            chunk_index += 1\n\n        chunks_index[worker_idx] = chunk_index\n        updated_indexes[worker_idx] = current_index\n\n    return chunks_index, updated_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        num_intervals = len(intervals)\n        current_interval_index = indexes[worker_idx] // num_intervals\n        current_interval_remainder = indexes[worker_idx] % num_intervals\n\n        # Update chunk index\n        chunks_index[worker_idx] = current_interval_index\n\n        # Update indexes within chunks\n        updated_indexes[worker_idx] = current_interval_remainder\n\n    return chunks_index, updated_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        current_index = indexes[worker_idx]\n        chunk_index = 0\n\n        for interval in intervals:\n            interval_size = interval[1] - interval[0]\n            if current_index < interval_size:\n                break\n            else:\n                current_index -= interval_size\n                chunk_index += 1\n\n        chunks_index[worker_idx] = chunk_index\n        updated_indexes[worker_idx] = current_index\n\n    return chunks_index, updated_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        current_index = indexes[worker_idx]\n        chunk_index = 0\n\n        for interval in intervals:\n            interval_size = interval[1] - interval[0]\n            if current_index < interval_size:\n                chunk_index = intervals.index(interval)\n                break\n            else:\n                current_index -= interval_size\n\n        chunks_index[worker_idx] = chunk_index\n        updated_indexes[worker_idx] = current_index\n\n    return chunks_index, updated_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        current_index = indexes[worker_idx]\n        chunk_index = 0\n        for interval in intervals:\n            interval_size = interval[1] - interval[0]\n            if current_index < interval_size:\n                break\n            current_index -= interval_size\n            chunk_index += 1\n        chunks_index[worker_idx] = chunk_index\n        updated_indexes[worker_idx] = current_index\n\n    return chunks_index, updated_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        chunk_index = 0\n        current_index = indexes[worker_idx]\n\n        for interval in intervals:\n            interval_size = interval[1] - interval[0]\n            if current_index < interval_size:\n                chunk_index = intervals.index(interval)\n                break\n            else:\n                current_index -= interval_size\n\n        chunks_index[worker_idx] = chunk_index\n        updated_indexes[worker_idx] = current_index\n\n    return chunks_index, updated_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        chunk_index = 0\n        for interval in intervals:\n            interval_size = interval[1] - interval[0]\n            if indexes[worker_idx] < interval_size:\n                chunk_index = intervals.index(interval)\n                break\n            else:\n                indexes[worker_idx] -= interval_size\n\n        chunks_index[worker_idx] = chunk_index\n        updated_indexes[worker_idx] = indexes[worker_idx]\n\n    return chunks_index, updated_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    new_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        # Calculate the total size of intervals for the worker\n        total_size = sum(interval[1] - interval[0] for interval in intervals)\n\n        # Calculate the number of times the data has been replayed\n        num_replays = indexes[worker_idx] // total_size\n\n        # Calculate the remaining index after replaying complete intervals\n        remaining_index = indexes[worker_idx] % total_size\n\n        # Find the chunk index to replay based on the remaining index\n        chunk_index = 0\n        running_total = 0\n        for i, interval in enumerate(intervals):\n            interval_size = interval[1] - interval[0]\n            running_total += interval_size\n            if remaining_index < running_total:\n                chunk_index = i\n                break\n\n        # Update the chunk index and remaining index\n        chunks_index[worker_idx] = chunk_index\n        new_indexes[worker_idx] = remaining_index\n\n    return chunks_index, new_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        current_index = indexes[worker_idx]\n        chunk_index = 0\n\n        for i, interval in enumerate(intervals):\n            interval_size = interval[1] - interval[0]\n            if current_index < interval_size:\n                chunk_index = i\n                break\n            else:\n                current_index -= interval_size\n\n        chunks_index[worker_idx] = chunk_index\n        updated_indexes[worker_idx] = current_index\n\n    return chunks_index, updated_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        current_index = indexes[worker_idx]\n        chunk_index = 0\n        for interval in intervals:\n            interval_size = interval[1] - interval[0]\n            if current_index < interval_size:\n                break\n            current_index -= interval_size\n            chunk_index += 1\n\n        chunks_index[worker_idx] = chunk_index\n        updated_indexes[worker_idx] = current_index\n\n    return chunks_index, updated_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        current_index = indexes[worker_idx]\n        chunk_index = 0\n\n        for interval in intervals:\n            interval_size = interval[1] - interval[0]\n            if current_index < interval_size:\n                break\n            current_index -= interval_size\n            chunk_index += 1\n\n        chunks_index[worker_idx] = chunk_index\n        updated_indexes[worker_idx] = current_index\n\n    return chunks_index, updated_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        current_index = indexes[worker_idx]\n        chunk_index = 0\n        for interval in intervals:\n            interval_size = interval[1] - interval[0]\n            if current_index < interval_size:\n                break\n            current_index -= interval_size\n            chunk_index += 1\n\n        chunks_index[worker_idx] = chunk_index\n        updated_indexes[worker_idx] = current_index\n\n    return chunks_index, updated_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        current_index = indexes[worker_idx]\n        chunk_index = 0\n\n        for interval in intervals:\n            interval_size = interval[1] - interval[0]\n            if current_index < interval_size:\n                break\n            current_index -= interval_size\n            chunk_index += 1\n\n        chunks_index[worker_idx] = chunk_index\n        updated_indexes[worker_idx] = current_index\n\n    return chunks_index, updated_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        chunk_index = 0\n        current_index = indexes[worker_idx]\n\n        for interval in intervals:\n            interval_size = interval[1] - interval[0]\n            if current_index < interval_size:\n                break\n            current_index -= interval_size\n            chunk_index += 1\n\n        chunks_index[worker_idx] = chunk_index\n        updated_indexes[worker_idx] = current_index\n\n    return chunks_index, updated_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        chunk_index = 0\n        for interval in intervals:\n            interval_size = interval[1] - interval[0]\n            if indexes[worker_idx] < interval_size:\n                updated_indexes[worker_idx] = indexes[worker_idx]\n                chunks_index[worker_idx] = chunk_index\n                break\n            else:\n                indexes[worker_idx] -= interval_size\n                chunk_index += 1\n\n    return chunks_index, updated_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        chunk_index = 0\n        current_index = indexes[worker_idx]\n\n        for interval in intervals:\n            interval_size = interval[1] - interval[0]\n            if current_index < interval_size:\n                break\n            current_index -= interval_size\n            chunk_index += 1\n\n        chunks_index[worker_idx] = chunk_index\n        updated_indexes[worker_idx] = current_index\n\n    return chunks_index, updated_indexes"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        size_bytes = np.array([item.width, item.height, len(item.mode)], dtype=np.uint32).tobytes()\n        mode_bytes = item.mode.encode(\"utf-8\")\n        data_bytes = item.tobytes()\n        return size_bytes + mode_bytes + data_bytes, None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        size = item.size\n        mode = item.mode\n        mode_bytes = mode.encode(\"utf-8\")\n        mode_length = len(mode_bytes).to_bytes(4, byteorder=\"big\")\n        width = size[0].to_bytes(4, byteorder=\"big\")\n        height = size[1].to_bytes(4, byteorder=\"big\")\n        raw = item.tobytes()\n\n        serialized_data = width + height + mode_length + mode_bytes + raw\n        return serialized_data, None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        size = item.size\n        mode = item.mode\n        mode_bytes = mode.encode(\"utf-8\")\n        mode_length = len(mode_bytes).to_bytes(4, byteorder=\"big\")\n        size_bytes = b\"\".join([size[0].to_bytes(4, byteorder=\"big\"), size[1].to_bytes(4, byteorder=\"big\")])\n        return size_bytes + mode_length + mode_bytes + item.tobytes(), None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        size = item.size\n        mode = item.mode\n        mode_bytes = mode.encode(\"utf-8\")\n        mode_length = len(mode_bytes).to_bytes(4, byteorder=\"big\")\n        width_bytes = size[0].to_bytes(4, byteorder=\"big\")\n        height_bytes = size[1].to_bytes(4, byteorder=\"big\")\n        raw_data = item.tobytes()\n\n        serialized_data = width_bytes + height_bytes + mode_length + mode_bytes + raw_data\n        return serialized_data, None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        size = item.size\n        mode = item.mode\n        mode_bytes = mode.encode(\"utf-8\")\n        mode_length = len(mode_bytes).to_bytes(4, byteorder=\"big\")\n        size_bytes = b\"\".join([s.to_bytes(4, byteorder=\"big\") for s in size])\n        return size_bytes + mode_length + mode_bytes + item.tobytes(), None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        size = item.size\n        mode = item.mode.encode(\"utf-8\")\n        data = size[0].to_bytes(4, byteorder=\"big\") + size[1].to_bytes(4, byteorder=\"big\") + len(mode).to_bytes(4, byteorder=\"big\") + mode + item.tobytes()\n        return data, None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        size = item.size\n        mode = item.mode\n        mode_bytes = mode.encode(\"utf-8\")\n        mode_length = len(mode_bytes).to_bytes(4, byteorder=\"big\")\n        size_bytes = b\"\".join([s.to_bytes(4, byteorder=\"big\") for s in size])\n        return size_bytes + mode_length + mode_bytes + item.tobytes(), None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        size = item.size\n        mode = item.mode\n        mode_bytes = mode.encode(\"utf-8\")\n        mode_length = len(mode_bytes).to_bytes(4, byteorder=\"big\")\n        width = size[0].to_bytes(4, byteorder=\"big\")\n        height = size[1].to_bytes(4, byteorder=\"big\")\n        data = mode_length + width + height + mode_bytes + item.tobytes()\n        return data, None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        size = item.size\n        mode = item.mode\n        mode_bytes = mode.encode(\"utf-8\")\n        mode_length = len(mode_bytes).to_bytes(4, byteorder=\"big\")\n        width_bytes = size[0].to_bytes(4, byteorder=\"big\")\n        height_bytes = size[1].to_bytes(4, byteorder=\"big\")\n        raw_data = item.tobytes()\n\n        serialized_data = width_bytes + height_bytes + mode_length + mode_bytes + raw_data\n        return serialized_data, None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        size = item.size\n        mode = item.mode\n        mode_bytes = mode.encode(\"utf-8\")\n        mode_size = len(mode_bytes).to_bytes(4, byteorder=\"big\")\n        width = size[0].to_bytes(4, byteorder=\"big\")\n        height = size[1].to_bytes(4, byteorder=\"big\")\n        serialized_data = width + height + mode_size + mode_bytes + item.tobytes()\n        return serialized_data, None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        size = item.size\n        mode = item.mode\n        mode_bytes = mode.encode(\"utf-8\")\n        mode_length = len(mode_bytes).to_bytes(4, byteorder=\"big\")\n        width_bytes = size[0].to_bytes(4, byteorder=\"big\")\n        height_bytes = size[1].to_bytes(4, byteorder=\"big\")\n        raw_data = item.tobytes()\n\n        serialized_data = width_bytes + height_bytes + mode_length + mode_bytes + raw_data\n        return serialized_data, None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        size_bytes = np.array([item.width, item.height, len(item.mode)], dtype=np.uint32).tobytes()\n        mode_bytes = item.mode.encode(\"utf-8\")\n        raw_bytes = item.tobytes()\n        return size_bytes + mode_bytes + raw_bytes, None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        width, height = item.size\n        mode = item.mode.encode(\"utf-8\")\n        mode_size = len(mode)\n        data = [\n            np.uint32(width).tobytes(),\n            np.uint32(height).tobytes(),\n            np.uint32(mode_size).tobytes(),\n            mode,\n            item.tobytes(),\n        ]\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        size = item.size\n        mode = item.mode\n        mode_bytes = mode.encode(\"utf-8\")\n        mode_length = len(mode_bytes).to_bytes(4, byteorder=\"big\")\n        size_bytes = b\"\".join([s.to_bytes(4, byteorder=\"big\") for s in size])\n        return size_bytes + mode_length + mode_bytes + item.tobytes(), None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        size = item.size\n        mode = item.mode\n        mode_bytes = mode.encode(\"utf-8\")\n        mode_length = len(mode_bytes).to_bytes(4, byteorder=\"big\")\n        size_bytes = b\"\".join([s.to_bytes(4, byteorder=\"big\") for s in size])\n        return size_bytes + mode_length + mode_bytes + item.tobytes(), None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        size = item.size\n        mode = item.mode\n        mode_bytes = mode.encode(\"utf-8\")\n        mode_size = len(mode_bytes).to_bytes(4, byteorder=\"big\")\n        data = size[0].to_bytes(4, byteorder=\"big\") + size[1].to_bytes(4, byteorder=\"big\") + mode_size + mode_bytes + item.tobytes()\n        return data, None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        size = item.size\n        mode = item.mode\n        mode_bytes = mode.encode(\"utf-8\")\n        mode_length = len(mode_bytes).to_bytes(4, byteorder=\"big\")\n        size_bytes = b\"\".join([s.to_bytes(4, byteorder=\"big\") for s in size])\n        data = size_bytes + mode_length + mode_bytes + item.tobytes()\n        return data, None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        width, height = item.size\n        mode = item.mode.encode(\"utf-8\")\n        mode_size = len(mode)\n        data = [\n            np.uint32(width).tobytes(),\n            np.uint32(height).tobytes(),\n            np.uint32(mode_size).tobytes(),\n            mode,\n            item.tobytes(),\n        ]\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        size = item.size\n        mode = item.mode.encode(\"utf-8\")\n        data = size[0].to_bytes(4, byteorder=\"big\") + size[1].to_bytes(4, byteorder=\"big\") + len(mode).to_bytes(4, byteorder=\"big\") + mode + item.tobytes()\n        return data, None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        size_bytes = np.array([item.width, item.height, len(item.mode)], dtype=np.uint32).tobytes()\n        mode_bytes = item.mode.encode(\"utf-8\")\n        raw_bytes = item.tobytes()\n        return size_bytes + mode_bytes + raw_bytes, None"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile) and hasattr(item, \"filename\") and os.path.isfile(item.filename):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        elif _PIL_AVAILABLE:\n            if isinstance(item, Image.Image):\n                buffer = io.BytesIO()\n                item.save(buffer, format=\"JPEG\")\n                return buffer.getvalue(), None\n            else:\n                raise TypeError(\"Unsupported image type. Expected PIL Image or JpegImageFile.\")\n        else:\n            raise ModuleNotFoundError(\"PIL is required. Run `pip install pillow`\")"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile) and hasattr(item, \"filename\") and os.path.exists(item.filename):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        elif _PIL_AVAILABLE:\n            if isinstance(item, Image.Image):\n                return item.tobytes(), None\n            else:\n                raise TypeError(\"Unsupported image type. Expected PIL Image or its subclasses.\")\n        else:\n            raise ModuleNotFoundError(\"PIL is required. Run `pip install pillow` if you want to use PILSerializer.\")"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile) and hasattr(item, \"filename\") and os.path.exists(item.filename):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        else:\n            return item.tobytes(), None"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        mode = item.mode.encode(\"utf-8\")\n        width, height = item.size\n        raw = item.tobytes()\n        ints = np.array([width, height, len(mode)], np.uint32)\n        return ints.tobytes() + mode + raw, None"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile) and hasattr(item, \"filename\") and os.path.isfile(item.filename):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        elif isinstance(item, JpegImageFile):\n            with io.BytesIO() as output:\n                item.save(output, format=\"JPEG\")\n                return output.getvalue(), None\n        else:\n            raise TypeError(\"Unsupported image type for JPEG serialization\")"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile) and hasattr(item, \"filename\") and os.path.exists(item.filename):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        else:\n            return item.tobytes(), None"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile) and hasattr(item, \"filename\") and os.path.isfile(item.filename):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        elif _PIL_AVAILABLE:\n            if isinstance(item, Image.Image):\n                with io.BytesIO() as output:\n                    item.save(output, format=\"JPEG\")\n                    return output.getvalue(), None\n        raise TypeError(\"Unsupported image type for JPEG serialization\")"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile) and hasattr(item, \"filename\") and os.path.exists(item.filename):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        elif isinstance(item, Image.Image):\n            with io.BytesIO() as output:\n                item.save(output, format=\"JPEG\")\n                return output.getvalue(), None\n        else:\n            raise TypeError(\"Unsupported image type for JPEG serialization\")"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile) and hasattr(item, \"filename\") and os.path.isfile(item.filename):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        elif _PIL_AVAILABLE and isinstance(item, Image.Image):\n            with io.BytesIO() as output:\n                item.save(output, format=\"JPEG\")\n                return output.getvalue(), None\n        else:\n            raise TypeError(\"Unsupported image type for JPEG serialization\")"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile) and hasattr(item, \"filename\") and os.path.isfile(item.filename):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        else:\n            if not _PIL_AVAILABLE:\n                raise ModuleNotFoundError(\"PIL is required. Run `pip install pillow`\")\n\n            if not isinstance(item, Image.Image):\n                raise TypeError(\"Unsupported image type. The item should be an instance of Image class or its subclasses.\")\n\n            with io.BytesIO() as output:\n                item.save(output, format=\"JPEG\")\n                return output.getvalue(), None"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile) and hasattr(item, \"filename\") and os.path.isfile(item.filename):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        elif isinstance(item, JpegImageFile):\n            with io.BytesIO() as output:\n                item.save(output, format=\"JPEG\")\n                return output.getvalue(), None\n        else:\n            raise TypeError(\"Unsupported image type for serialization. Supported types: JpegImageFile\")"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile) and hasattr(item, \"filename\") and os.path.exists(item.filename):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        elif _PIL_AVAILABLE and isinstance(item, Image.Image):\n            with io.BytesIO() as output:\n                item.save(output, format=\"JPEG\")\n                return output.getvalue(), None\n        else:\n            raise TypeError(\"Item is not a supported image type for JPEG serialization\")"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            # Read the file directly if it's a JPEG and has a defined filename\n            if item.filename and os.path.exists(item.filename):\n                with open(item.filename, \"rb\") as f:\n                    return f.read(), None\n            else:\n                raise ValueError(\"The JPEG item does not have a defined filename or the file does not exist.\")\n        elif isinstance(item, Image.Image):\n            # Convert the item into JPEG format in memory\n            with io.BytesIO() as output:\n                item.save(output, format=\"JPEG\")\n                return output.getvalue(), None\n        else:\n            raise TypeError(\"Unsupported image type. Expected an instance of Image class or its subclasses.\")"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        elif _PIL_AVAILABLE and isinstance(item, Image.Image):\n            with io.BytesIO() as output:\n                item.save(output, format=\"JPEG\")\n                return output.getvalue(), None\n        else:\n            raise TypeError(\"Unsupported image type for JPEG serialization\")"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        mode = item.mode.encode(\"utf-8\")\n        width, height = item.size\n        raw = item.tobytes()\n        ints = np.array([width, height, len(mode)], np.uint32)\n        return ints.tobytes() + mode + raw, None"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        else:\n            with io.BytesIO() as output:\n                item.save(output, format=\"JPEG\")\n                return output.getvalue(), None"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile) and hasattr(item, \"filename\") and os.path.exists(item.filename):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        elif _PIL_AVAILABLE and isinstance(item, Image.Image):\n            output = io.BytesIO()\n            item.save(output, format=\"JPEG\")\n            return output.getvalue(), None\n        else:\n            raise TypeError(\"Unsupported image type for JPEG serialization\")"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile) and hasattr(item, \"filename\") and os.path.isfile(item.filename):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        elif isinstance(item, Image.Image):\n            with io.BytesIO() as output:\n                item.save(output, format=\"JPEG\")\n                return output.getvalue(), None\n        else:\n            raise TypeError(\"Unsupported image type for JPEG serialization\")"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            filename = item.filename\n            if filename and os.path.exists(filename):\n                with open(filename, \"rb\") as f:\n                    return f.read(), None\n            else:\n                raise ValueError(\"Item is a JPEG but does not have a valid filename\")\n\n        if isinstance(item, Image.Image):\n            with io.BytesIO() as output:\n                item.save(output, format=\"JPEG\")\n                return output.getvalue(), None\n\n        raise TypeError(\"Unsupported image type for JPEG serialization\")"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            if item.filename and os.path.exists(item.filename):\n                with open(item.filename, \"rb\") as file:\n                    return file.read(), None\n            else:\n                raise ValueError(\"Item is a JPEG but does not have a valid filename\")\n        elif _PIL_AVAILABLE and isinstance(item, Image.Image):\n            with io.BytesIO() as output:\n                item.save(output, format=\"JPEG\")\n                return output.getvalue(), None\n        else:\n            raise TypeError(\"Item is not a supported image type\")"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_length = ints\n        mode = data[12:12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length:]\n        img = Image.frombytes(mode, (width, height), raw)\n        return img"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_length = ints\n        mode = data[12:12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length:]\n        image = Image.frombytes(mode, (width, height), raw)\n        return image"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_length = ints\n        mode = data[12:12+mode_length].decode(\"utf-8\")\n        image_data = data[12+mode_length:]\n        return Image.frombytes(mode, (width, height), image_data)"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_length = ints\n        mode = data[12:12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length:]\n        return Image.frombytes(mode, (width, height), raw)"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_length = ints\n        mode = data[12:12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length:]\n        return Image.frombytes(mode, (width, height), raw)"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_length = ints\n        mode = data[12:12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length:]\n        image = Image.frombytes(mode, (width, height), raw)\n        return image"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_length = ints\n        mode = data[12:12 + mode_length].decode(\"utf-8\")\n        raw_data = data[12 + mode_length:]\n        return Image.frombytes(mode, (width, height), raw_data)"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_length = ints\n        mode = data[12:12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length:]\n        img = Image.frombytes(mode, (width, height), raw)\n        return img"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_length = ints\n        mode = data[12:12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length:]\n        return Image.frombytes(mode, (width, height), raw)"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_length = ints\n        mode = data[12:12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length:]\n        return Image.frombytes(mode, (width, height), raw)"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_length = ints\n        mode = data[12:12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length:]\n        return Image.frombytes(mode, (width, height), raw)"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_length = ints\n        mode = data[12:12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length:]\n        img = Image.frombytes(mode, (width, height), raw)\n        return img"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_size = ints\n        mode = data[12:12 + mode_size].decode(\"utf-8\")\n        raw = data[12 + mode_size:]\n        return Image.frombytes(mode, (width, height), raw)"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_length = ints\n        mode = data[12:12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length:]\n        return Image.frombytes(mode, (width, height), raw)"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_length = ints\n        mode = data[12:12+mode_length].decode(\"utf-8\")\n        raw = data[12+mode_length:]\n        return Image.frombytes(mode, (width, height), raw)"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_length = ints\n        mode = data[12:12 + mode_length].decode(\"utf-8\")\n        raw_data = data[12 + mode_length:]\n        return Image.frombytes(mode, (width, height), raw_data)"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_length = ints\n        mode = data[12:12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length:]\n        return Image.frombytes(mode, (width, height), raw)"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_length = ints\n        mode = data[12:12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length:]\n        img = Image.frombytes(mode, (width, height), raw)\n        return img"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_length = ints\n        mode = data[12:12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length:]\n        image = Image.frombytes(mode, (width, height), raw)\n        return image"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_length = ints\n        mode = data[12:12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length:]\n        return Image.frombytes(mode, (width, height), raw)"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[:4], np.uint32).item()\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = tuple(np.frombuffer(data[8:8 + shape_size * 4], np.uint32))\n        tensor_data = np.frombuffer(data[8 + shape_size * 4:], dtype=dtype)\n        return torch.from_numpy(tensor_data).view(shape)"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        # Deserialize the shape header\n        # Note: The start position of the shape value: 8 (dtype + shape length) + 4 * shape_idx\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx: 8 + 4 * (shape_idx + 1)], np.uint32).item())\n\n        # Deserialize the tensor's raw data\n        tensor = np.frombuffer(data[8 + 4 * (shape_idx + 1): len(data)], dtype=dtype)\n        tensor = torch.from_numpy(tensor)\n        tensor = tensor.view(*shape)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        # deserialize the shape header\n        # Note: The start position of the shape value: 8 (dtype + shape length) + 4 * shape_idx\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n\n        # deserialize the tensor raw data\n        tensor_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        tensor = torch.from_numpy(tensor_data).reshape(shape)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        # deserialize the shape header\n        # Note: The start position of the shape value: 8 (dtype + shape length) + 4 * shape_idx\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n\n        # deserialize the tensor data\n        tensor_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        tensor = torch.from_numpy(tensor_data)\n        tensor = tensor.view(*shape)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        # deserialize the shape header\n        # Note: The start position of the shape value: 8 (dtype + shape length) + 4 * shape_idx\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n\n        # deserialize the tensor's raw data\n        tensor_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n\n        # reconstruct the tensor from the deserialized information\n        tensor = torch.from_numpy(tensor_data)\n        tensor = tensor.view(*shape)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        # deserialize the shape header\n        # Note: The start position of the shape value: 8 (dtype + shape length) + 4 * shape_idx\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n\n        # deserialize the tensor data\n        tensor_data = np.frombuffer(data[8 + 4 * shape_size:], dtype=dtype)\n        tensor = torch.from_numpy(tensor_data)\n        tensor = tensor.view(*shape)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        # deserialize the shape header\n        # Note: The start position of the shape value: 8 (dtype + shape length) + 4 * shape_idx\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n\n        # deserialize the tensor data\n        tensor_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n\n        # reconstruct the tensor\n        tensor = torch.from_numpy(tensor_data)\n        tensor = tensor.reshape(shape)\n\n        return tensor"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        # deserialize the shape header\n        # Note: The start position of the shape value: 8 (dtype + shape length) + 4 * shape_idx\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n\n        # deserialize the tensor data\n        tensor_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        tensor = torch.from_numpy(tensor_data)\n        tensor = tensor.view(*shape)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        # deserialize the shape header\n        # Note: The start position of the shape value: 8 (dtype + shape length) + 4 * shape_idx\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n\n        # deserialize the tensor data\n        tensor_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        tensor = torch.from_numpy(tensor_data)\n        tensor = tensor.view(*shape)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        # deserialize the shape header\n        # Note: The start position of the shape value: 8 (dtype + shape length) + 4 * shape_idx\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n\n        # deserialize the tensor data\n        tensor_data = np.frombuffer(data[8 + 4 * shape_size:], dtype=dtype)\n\n        # reconstruct the tensor\n        tensor = torch.from_numpy(tensor_data)\n        tensor = tensor.reshape(shape)\n\n        return tensor"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        # deserialize the shape header\n        # Note: The start position of the shape value: 8 (dtype + shape length) + 4 * shape_idx\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n\n        # deserialize the tensor raw data\n        tensor_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        tensor = torch.from_numpy(tensor_data)\n        tensor = tensor.view(*shape)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        # deserialize the shape header\n        # Note: The start position of the shape value: 8 (dtype + shape length) + 4 * shape_idx\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n\n        # deserialize the tensor data\n        tensor_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n\n        # reconstruct the tensor\n        tensor = torch.from_numpy(tensor_data)\n        tensor = tensor.reshape(shape)\n\n        return tensor"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        # deserialize the shape header\n        # Note: The start position of the shape value: 8 (dtype + shape length) + 4 * shape_idx\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n\n        # deserialize the tensor raw data\n        tensor_data = np.frombuffer(data[8 + 4 * shape_size:], dtype=dtype)\n\n        # reconstruct the tensor\n        tensor = torch.from_numpy(tensor_data)\n        tensor = tensor.reshape(shape)\n\n        return tensor"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        # deserialize the shape header\n        # Note: The start position of the shape value: 8 (dtype + shape length) + 4 * shape_idx\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n\n        # deserialize the tensor data\n        tensor_data = np.frombuffer(data[8 + 4 * shape_size:], dtype=dtype)\n\n        # reconstruct the tensor\n        tensor = torch.from_numpy(tensor_data)\n        tensor = tensor.reshape(shape)\n\n        return tensor"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        # deserialize the shape header\n        # Note: The start position of the shape value: 8 (dtype + shape length) + 4 * shape_idx\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n\n        # deserialize the tensor raw data\n        tensor_data = np.frombuffer(data[8 + 4 * shape_size:], dtype=dtype)\n        tensor = torch.from_numpy(tensor_data)\n        tensor = tensor.reshape(shape)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        # deserialize the shape header\n        # Note: The start position of the shape value: 8 (dtype + shape length) + 4 * shape_idx\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n\n        # deserialize the tensor data\n        tensor_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n\n        # reconstruct the tensor\n        tensor = torch.from_numpy(tensor_data)\n        tensor = tensor.reshape(shape)\n\n        return tensor"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        # deserialize the shape header\n        # Note: The start position of the shape value: 8 (dtype + shape length) + 4 * shape_idx\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n\n        # deserialize the tensor raw data\n        tensor_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        tensor = torch.from_numpy(tensor_data)\n        tensor = tensor.view(shape)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        # deserialize the shape header\n        # Note: The start position of the shape value: 8 (dtype + shape length) + 4 * shape_idx\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n\n        # deserialize the tensor raw data\n        tensor_data = np.frombuffer(data[8 + 4 * shape_size:], dtype=dtype)\n\n        # reshape the tensor using the extracted shape\n        tensor = torch.from_numpy(tensor_data)\n        tensor = tensor.view(*shape)\n\n        return tensor"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        # deserialize the shape header\n        # Note: The start position of the shape value: 8 (dtype + shape length) + 4 * shape_idx\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n\n        # deserialize the tensor's raw data\n        tensor = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        tensor = tensor.reshape(shape)\n        return torch.from_numpy(tensor)"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        # deserialize the shape header\n        # Note: The start position of the shape value: 8 (dtype + shape length) + 4 * shape_idx\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n\n        # deserialize the tensor's raw data\n        tensor_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        tensor = torch.from_numpy(tensor_data)\n        tensor = tensor.view(*shape)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        dtype_bytes = np.uint32(dtype_indice).tobytes()\n        shape_bytes = np.uint32(len(item.shape)).tobytes()\n        shape_data = [np.uint32(dim).tobytes() for dim in item.shape]\n        raw_data = item.tobytes()\n        serialized_data = b\"\".join([dtype_bytes, shape_bytes] + shape_data + [raw_data])\n        return serialized_data, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_indice = _TORCH_DTYPES_MAPPING[item.dtype]\n        dtype_bytes = np.array([dtype_indice], np.uint32).tobytes()\n        shape_bytes = np.array(item.shape, np.uint32).tobytes()\n        raw_bytes = item.tobytes()\n        return dtype_bytes + shape_bytes + raw_bytes, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_indice = np.uint32(self._dtype_to_indices[item.dtype]).tobytes()\n        shape = np.array(item.shape, dtype=np.uint32)\n        shape_size = np.uint32(len(shape)).tobytes()\n        tensor_bytes = item.tobytes()\n        return dtype_indice + shape_size + shape.tobytes() + tensor_bytes, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_indice = np.uint32(self._dtype_to_indices[item.dtype]).tobytes()\n        shape = np.array(item.shape, dtype=np.uint32)\n        shape_size = np.uint32(len(shape)).tobytes()\n        raw_data = item.numpy().tobytes(order=\"C\")\n        return dtype_indice + shape_size + shape.tobytes() + raw_data, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_indice = np.uint32(self._dtype_to_indices[item.dtype]).tobytes()\n        shape = np.uint32(len(item.shape)).tobytes()\n        shape_data = b\"\".join([np.uint32(dim).tobytes() for dim in item.shape])\n        tensor_data = item.numpy().tobytes(order=\"C\")\n        return dtype_indice + shape + shape_data + tensor_data, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        dtype_bytes = np.array([dtype_indice], dtype=np.uint32).tobytes()\n        shape_bytes = np.array(item.shape, dtype=np.uint32).tobytes()\n        data_bytes = item.numpy().tobytes(order=\"C\")\n        return dtype_bytes + shape_bytes + data_bytes, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_indice = np.uint32(self._dtype_to_indices[item.dtype]).tobytes()\n        shape = np.uint32(len(item.shape)).tobytes()\n        shape_data = b\"\".join([np.uint32(dim).tobytes() for dim in item.shape])\n        tensor_data = item.numpy().tobytes(order=\"C\")\n        return dtype_indice + shape + shape_data + tensor_data, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        dtype_bytes = np.uint32(dtype_indice).tobytes()\n        shape_bytes = np.uint32(len(item.shape)).tobytes()\n        shape_data = b\"\".join([np.uint32(dim).tobytes() for dim in item.shape])\n        tensor_bytes = item.numpy().tobytes(order=\"C\")\n        serialized_data = dtype_bytes + shape_bytes + shape_data + tensor_bytes\n        return serialized_data, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        dtype_bytes = np.uint32(dtype_indice).tobytes()\n        shape_bytes = np.uint32(len(item.shape)).tobytes()\n        shape_data = b\"\".join([np.uint32(dim).tobytes() for dim in item.shape])\n        tensor_bytes = item.numpy().tobytes(order=\"C\")\n        return dtype_bytes + shape_bytes + shape_data + tensor_bytes, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_indice = _TORCH_DTYPES_MAPPING[item.dtype]\n        dtype_bytes = np.uint32(dtype_indice).tobytes()\n        shape_bytes = np.uint32(len(item.shape)).tobytes()\n        shape_data = [np.uint32(dim).tobytes() for dim in item.shape]\n        raw_data = item.numpy().tobytes(order=\"C\")\n        serialized_tensor = dtype_bytes + shape_bytes + b\"\".join(shape_data) + raw_data\n        return serialized_tensor, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_indice = np.array([self._dtype_to_indices[item.dtype]], np.uint32).tobytes()\n        shape_size = np.array([len(item.shape)], np.uint32).tobytes()\n        shape = np.array(item.shape, np.uint32).tobytes()\n        raw_data = item.numpy().tobytes(order=\"C\")\n        return dtype_indice + shape_size + shape + raw_data, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_indice = np.uint32(self._dtype_to_indices[item.dtype]).tobytes()\n        shape = np.uint32(len(item.shape)).tobytes()\n        shape_data = b\"\".join([np.uint32(dim).tobytes() for dim in item.shape])\n        tensor_data = item.numpy().tobytes(order=\"C\")\n        return dtype_indice + shape + shape_data + tensor_data, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_indice = np.uint32(self._dtype_to_indices[item.dtype]).tobytes()\n        shape = np.array(item.shape, dtype=np.uint32)\n        shape_size = np.uint32(len(shape)).tobytes()\n        tensor_bytes = item.numpy().tobytes(order=\"C\")\n        return dtype_indice + shape_size + shape.tobytes() + tensor_bytes, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_indice = np.uint32(self._dtype_to_indices[item.dtype]).tobytes()\n        shape = np.uint32(len(item.shape)).tobytes()\n        shape_data = b\"\".join([np.uint32(dim).tobytes() for dim in item.shape])\n        tensor_data = item.numpy().tobytes(order=\"C\")\n        return dtype_indice + shape + shape_data + tensor_data, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_indice = np.uint32(self._dtype_to_indices[item.dtype]).tobytes()\n        shape = np.uint32(len(item.shape)).tobytes()\n        shape_data = b\"\".join([np.uint32(dim).tobytes() for dim in item.shape])\n        tensor_data = item.tobytes()\n        return dtype_indice + shape + shape_data + tensor_data, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_indice = np.uint32(self._dtype_to_indices[item.dtype]).tobytes()\n        shape = np.array(item.shape, dtype=np.uint32)\n        shape_size = np.uint32(len(shape)).tobytes()\n        tensor_data = item.numpy().tobytes(order=\"C\")\n        return dtype_indice + shape_size + shape.tobytes() + tensor_data, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        tensor = torch.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = torch.Size(shape)\n        if tensor.shape == shape:\n            return tensor\n        return torch.reshape(tensor, shape)"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        dtype_bytes = np.uint32(dtype_indice).tobytes()\n        shape_bytes = np.uint32(len(item.shape)).tobytes()\n        shape_data = b\"\".join([np.uint32(dim).tobytes() for dim in item.shape])\n        tensor_bytes = item.tobytes()\n        return dtype_bytes + shape_bytes + shape_data + tensor_bytes, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_indice = np.uint32(self._dtype_to_indices[item.dtype]).tobytes()\n        shape = np.uint32(len(item.shape)).tobytes()\n        shape_data = b\"\".join([np.uint32(dim).tobytes() for dim in item.shape])\n        tensor_data = item.numpy().tobytes(order=\"C\")\n        return dtype_indice + shape + shape_data + tensor_data, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        tensor = torch.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = torch.Size(shape)\n        if tensor.shape == shape:\n            return tensor\n        return torch.reshape(tensor, shape)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 12.92\n  linear1 = xnp.maximum(eps, ((srgb + 0.055) / 1.055) ** 2.4)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 12.92\n  linear1 = xnp.power((srgb + 0.055) / 1.055, 2.4)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 12.92\n  linear1 = xnp.power((srgb + 0.055) / 1.055, 2.4)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 12.92\n  linear1 = xnp.power((srgb + 0.055) / 1.055, 2.4)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear = xnp.where(srgb <= 0.04045, srgb / 12.92, ((srgb + 0.055) / 1.055) ** 2.4)\n  return linear"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 12.92\n  linear1 = xnp.power((srgb + 0.055) / 1.055, 2.4)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 12.92\n  linear1 = xnp.power((srgb + 0.055) / 1.055, 2.4)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 12.92\n  linear1 = xnp.power((srgb + 0.055) / 1.055, 2.4)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 12.92\n  linear1 = xnp.power((srgb + 0.055) / 1.055, 2.4)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 12.92\n  linear1 = xnp.power((srgb + 0.055) / 1.055, 2.4)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 12.92\n  linear1 = xnp.power((srgb + 0.055) / 1.055, 2.4)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 12.92\n  linear1 = xnp.maximum(eps, ((srgb + 0.055) / 1.055) ** 2.4)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 12.92\n  linear1 = xnp.power((srgb + 0.055) / 1.055, 2.4)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 12.92\n  linear1 = xnp.power((srgb + 0.055) / 1.055, 2.4)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  \"\"\"\n  Converts sRGB color values to linear color space values. It uses a piecewise function as defined in the sRGB color space specification to perform the conversion, ensuring accurate color representation in linear space.\n\n  Input-Output Arguments\n  :param srgb: Array-like. The sRGB color values expected to be in the range [0, 1]. These values are converted to linear space.\n  :param eps: Float, optional. A small epsilon value to avoid division by zero or logarithm of zero in calculations. If not provided, it defaults to the machine epsilon for float32 data type.\n  :param xnp: Module, optional. The numerical processing module used for calculations (e.g., NumPy, JAX NumPy). It defaults to JAX NumPy (jnp) if not specified.\n  :return: Array-like. The converted color values in linear space.\n  \"\"\"\n  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear = xnp.where(\n      srgb <= 0.04045,\n      srgb / 12.92,\n      xnp.power((srgb + 0.055) / 1.055, 2.4)\n  )\n  return linear"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 12.92\n  linear1 = xnp.power((srgb + 0.055) / 1.055, 2.4)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 12.92\n  linear1 = xnp.power((srgb + 0.055) / 1.055, 2.4)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 12.92\n  linear1 = xnp.power((srgb + 0.055) / 1.055, 2.4)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 12.92\n  linear1 = ((srgb + 0.055) / 1.055) ** 2.4\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 12.92\n  linear1 = ((srgb + 0.055) / 1.055) ** 2.4\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    # Round the locations to the nearest integer\n    rounded_locations = jnp.round(locations).astype(jnp.int32)\n    # Gather the data at the rounded locations\n    resampled_data = gather_volume(data, rounded_locations, coordinate_order)\n  elif method == 'TRILINEAR':\n    if half_pixel_center:\n        # Adjust the locations for half-pixel centering\n        locations -= 0.5\n    # Extract the integer and fractional parts of the locations\n    int_locations = jnp.floor(locations).astype(jnp.int32)\n    fractional = locations - int_locations\n    # Get the 8 corner coordinates for trilinear interpolation\n    corner_locations = get_corner_locations(int_locations, fractional)\n    # Gather the data at the corner locations\n    corner_data = gather_volume(data, corner_locations, coordinate_order)\n    # Perform trilinear interpolation\n    resampled_data = trilinear_interpolation(corner_data, fractional)\n  else:\n    raise ValueError(\"Invalid method. Method must be either 'NEAREST' or 'TRILINEAR'.\")\n\n  if edge_behavior == 'CONSTANT_OUTSIDE':\n    # Mask the locations outside the volume and replace with constant values\n    outside_mask = get_outside_mask(locations, data.shape, half_pixel_center)\n    resampled_data = jnp.where(outside_mask, constant_values, resampled_data)\n  elif edge_behavior == 'CLAMP':\n    # Clamp the locations to the volume boundaries\n    resampled_data = clamp_to_edge(locations, data, resampled_data)\n  else:\n    raise ValueError(\"Invalid edge_behavior. Edge behavior must be either 'CONSTANT_OUTSIDE' or 'CLAMP'.\")\n\n  return resampled_data"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'TRILINEAR':\n    if edge_behavior == 'CONSTANT_OUTSIDE':\n      if half_pixel_center:\n        locations -= 0.5\n      else:\n        locations = jnp.floor(locations)\n\n      if coordinate_order == 'xyz':\n        x = locations[..., 0]\n        y = locations[..., 1]\n        z = locations[..., 2]\n      elif coordinate_order == 'zyx':\n        z = locations[..., 0]\n        y = locations[..., 1]\n        x = locations[..., 2]\n\n      D, H, W, C = data.shape\n      x = jnp.clip(x, 0, W - 1)\n      y = jnp.clip(y, 0, H - 1)\n      z = jnp.clip(z, 0, D - 1)\n\n      x0 = jnp.clip(jnp.floor(x), 0, W - 1).astype(jnp.int32)\n      x1 = jnp.clip(x0 + 1, 0, W - 1)\n      y0 = jnp.clip(jnp.floor(y), 0, H - 1).astype(jnp.int32)\n      y1 = jnp.clip(y0 + 1, 0, H - 1)\n      z0 = jnp.clip(jnp.floor(z), 0, D - 1).astype(jnp.int32)\n      z1 = jnp.clip(z0 + 1, 0, D - 1)\n\n      xd = x - x0\n      yd = y - y0\n      zd = z - z0\n\n      c000 = gather_volume(data, jnp.stack([z0, y0, x0], axis=-1), coordinate_order)\n      c001 = gather_volume(data, jnp.stack([z0, y0, x1], axis=-1), coordinate_order)\n      c010 = gather_volume(data, jnp.stack([z0, y1, x0], axis=-1), coordinate_order)\n      c011 = gather_volume(data, jnp.stack([z0, y1, x1], axis=-1), coordinate_order)\n      c100 = gather_volume(data, jnp.stack([z1, y0, x0], axis=-1), coordinate_order)\n      c101 = gather_volume(data, jnp.stack([z1, y0, x1], axis=-1), coordinate_order)\n      c110 = gather_volume(data, jnp.stack([z1, y1, x0], axis=-1), coordinate_order)\n      c111 = gather_volume(data, jnp.stack([z1, y1, x1], axis=-1), coordinate_order)\n\n      c00 = c000 * (1 - xd) + c001 * xd\n      c01 = c010 * (1 - xd) + c011 * xd\n      c10 = c100 * (1 - xd) + c101 * xd\n      c11 = c110 * (1 - xd) + c111 * xd\n\n      c0 = c00 * (1 - yd) + c01 * yd\n      c1 = c10 * (1 - yd) + c11 * yd\n\n      c = c0 * (1 - zd) + c1 * zd\n\n      return c\n\n    elif edge_behavior == 'CLAMP':\n      # Implement clamp behavior\n      pass\n\n    else:\n      raise ValueError(\"Invalid edge_behavior. Must be 'CONSTANT_OUTSIDE' or 'CLAMP'.\")\n\n  elif method == 'NEAREST':\n    # Implement nearest neighbor interpolation\n    pass\n\n  else:\n    raise ValueError(\"Invalid method. Must be 'TRILINEAR' or 'NEAREST'.\")"}
{"namespace": "resample.resample_3d", "completion": "  # Convert locations to float32 for consistency.\n  locations = jnp.asarray(locations, dtype=jnp.float32)\n\n  # Adjust for half-pixel centering if needed.\n  if half_pixel_center:\n    locations -= 0.5\n\n  # Handle edge behavior based on the specified method.\n  if edge_behavior == 'CONSTANT_OUTSIDE':\n    if method == 'TRILINEAR':\n      # Pad the input volume with constant values.\n      data = jnp.pad(data, ((1, 1), (1, 1), (1, 1), (0, 0)), mode='constant', constant_values=constant_values)\n    elif method == 'NEAREST':\n      # No padding needed for nearest neighbor interpolation.\n      pass\n    else:\n      raise ValueError(\"Invalid method. Supported methods are 'TRILINEAR' and 'NEAREST'.\")\n\n  elif edge_behavior == 'CLAMP':\n    # Clamp sample points to the volume boundaries.\n    locations = jnp.clip(locations, 0, jnp.array(data.shape[:-1]) - 1)\n\n  else:\n    raise ValueError(\"Invalid edge_behavior. Supported edge behaviors are 'CONSTANT_OUTSIDE' and 'CLAMP'.\")\n\n  # Perform trilinear interpolation or nearest neighbor interpolation based on the specified method.\n  if method == 'TRILINEAR':\n    # Compute the floor coordinates for trilinear interpolation.\n    floor_locations = jnp.floor(locations).astype(jnp.int32)\n\n    # Compute the fractional part for trilinear interpolation.\n    delta = locations - floor_locations\n\n    # Compute the weights for trilinear interpolation.\n    weights = [\n        (1 - delta[..., 0]) * (1 - delta[..., 1]) * (1 - delta[..., 2]),\n        (1 - delta[..., 0]) * (1 - delta[..., 1]) * delta[..., 2],\n        (1 - delta[..., 0]) * delta[..., 1] * (1 - delta[..., 2]),\n        (1 - delta[..., 0]) * delta[..., 1] * delta[..., 2],\n        delta[..., 0] * (1 - delta[..., 1]) * (1 - delta[..., 2]),\n        delta[..., 0] * (1 - delta[..., 1]) * delta[..., 2],\n        delta[..., 0] * delta[..., 1] * (1 - delta[..., 2]),\n        delta[..., 0] * delta[..., 1] * delta[..., 2],\n    ]\n\n    # Gather the 8 corner values for trilinear interpolation.\n    corner_values = jnp.array([\n        gather_volume(data, floor_locations + offset, coordinate_order) for offset in [\n            (0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1),\n            (1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1)\n        ]\n    ])\n\n    # Compute the interpolated values using trilinear interpolation.\n    interpolated_values = jnp.sum(corner_values * jnp.array(weights).T[..., jnp.newaxis], axis=-2)\n\n  elif method == 'NEAREST':\n    # Round the locations to the nearest integer for nearest neighbor interpolation.\n    rounded_locations = jnp.round(locations).astype(jnp.int32)\n\n    # Gather the nearest neighbor values for each location.\n    interpolated_values = gather_volume(data, rounded_locations, coordinate_order)\n\n  else:\n    raise ValueError(\"Invalid method. Supported methods are 'TRILINEAR' and 'NEAREST'.\")\n\n  return interpolated_values"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    if half_pixel_center:\n      locations = locations + 0.5\n    locations = jnp.round(locations).astype(jnp.int32)\n    return gather_volume(data, locations, coordinate_order)\n\n  if method == 'TRILINEAR':\n    if half_pixel_center:\n      locations = locations + 0.5\n    z = locations[..., 0]\n    y = locations[..., 1]\n    x = locations[..., 2]\n\n    z0 = jnp.floor(z).astype(jnp.int32)\n    z1 = z0 + 1\n    y0 = jnp.floor(y).astype(jnp.int32)\n    y1 = y0 + 1\n    x0 = jnp.floor(x).astype(jnp.int32)\n    x1 = x0 + 1\n\n    # Clip coordinates based on edge behavior\n    if edge_behavior == 'CONSTANT_OUTSIDE':\n      z0 = jnp.clip(z0, 0, data.shape[0] - 1)\n      z1 = jnp.clip(z1, 0, data.shape[0] - 1)\n      y0 = jnp.clip(y0, 0, data.shape[1] - 1)\n      y1 = jnp.clip(y1, 0, data.shape[1] - 1)\n      x0 = jnp.clip(x0, 0, data.shape[2] - 1)\n      x1 = jnp.clip(x1, 0, data.shape[2] - 1)\n    elif edge_behavior == 'CLAMP':\n      z0 = jnp.clip(z0, 0, data.shape[0] - 1)\n      z1 = jnp.clip(z1, 0, data.shape[0] - 1)\n      y0 = jnp.clip(y0, 0, data.shape[1] - 1)\n      y1 = jnp.clip(y1, 0, data.shape[1] - 1)\n      x0 = jnp.clip(x0, 0, data.shape[2] - 1)\n      x1 = jnp.clip(x1, 0, data.shape[2] - 1)\n\n    # Calculate the weights for trilinear interpolation\n    dz0 = z1 - z\n    dz1 = z - z0\n    dy0 = y1 - y\n    dy1 = y - y0\n    dx0 = x1 - x\n    dx1 = x - x0\n\n    # Gather the 8 corner values for trilinear interpolation\n    c000 = gather_volume(data, jnp.stack([z0, y0, x0], axis=-1), coordinate_order)\n    c001 = gather_volume(data, jnp.stack([z0, y0, x1], axis=-1), coordinate_order)\n    c010 = gather_volume(data, jnp.stack([z0, y1, x0], axis=-1), coordinate_order)\n    c011 = gather_volume(data, jnp.stack([z0, y1, x1], axis=-1), coordinate_order)\n    c100 = gather_volume(data, jnp.stack([z1, y0, x0], axis=-1), coordinate_order)\n    c101 = gather_volume(data, jnp.stack([z1, y0, x1], axis=-1), coordinate_order)\n    c110 = gather_volume(data, jnp.stack([z1, y1, x0], axis=-1), coordinate_order)\n    c111 = gather_volume(data, jnp.stack([z1, y1, x1], axis=-1), coordinate_order)\n\n    # Perform trilinear interpolation\n    output = (\n        c000 * dz0 * dy0 * dx0\n        + c001 * dz0 * dy0 * dx1\n        + c010 * dz0 * dy1 * dx0\n        + c011 * dz0 * dy1 * dx1\n        + c100 * dz1 * dy0 * dx0\n        + c101 * dz1 * dy0 * dx1\n        + c110 * dz1 * dy1 * dx0\n        + c111 * dz1 * dy1 * dx1\n    )\n    return output"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    if half_pixel_center:\n      locations = locations + 0.5\n    locations = jnp.round(locations).astype(jnp.int32)\n    if edge_behavior == 'CONSTANT_OUTSIDE':\n      data = jnp.pad(data, 1, constant_values=constant_values)\n    return gather_volume(data, locations, coordinate_order)\n  elif method == 'TRILINEAR':\n    if half_pixel_center:\n      locations = locations + 0.5\n    z = locations[..., 0]\n    y = locations[..., 1]\n    x = locations[..., 2]\n    z0 = jnp.floor(z).astype(jnp.int32)\n    z1 = z0 + 1\n    y0 = jnp.floor(y).astype(jnp.int32)\n    y1 = y0 + 1\n    x0 = jnp.floor(x).astype(jnp.int32)\n    x1 = x0 + 1\n    if edge_behavior == 'CONSTANT_OUTSIDE':\n      data = jnp.pad(data, 1, constant_values=constant_values)\n      z0 = jnp.clip(z0, 0, data.shape[0] - 1)\n      z1 = jnp.clip(z1, 0, data.shape[0] - 1)\n      y0 = jnp.clip(y0, 0, data.shape[1] - 1)\n      y1 = jnp.clip(y1, 0, data.shape[1] - 1)\n      x0 = jnp.clip(x0, 0, data.shape[2] - 1)\n      x1 = jnp.clip(x1, 0, data.shape[2] - 1)\n    iz0 = gather_volume(data, jnp.stack([z0, y0, x0], axis=-1), coordinate_order)\n    iz1 = gather_volume(data, jnp.stack([z1, y0, x0], axis=-1), coordinate_order)\n    iy0 = gather_volume(data, jnp.stack([z0, y1, x0], axis=-1), coordinate_order)\n    iy1 = gather_volume(data, jnp.stack([z1, y1, x0], axis=-1), coordinate_order)\n    ix0 = gather_volume(data, jnp.stack([z0, y0, x1], axis=-1), coordinate_order)\n    ix1 = gather_volume(data, jnp.stack([z1, y0, x1], axis=-1), coordinate_order)\n    iz0y0 = iz0 * (z1 - z) + iz1 * (z - z0)\n    iz1y1 = iy0 * (z1 - z) + iy1 * (z - z0)\n    iz0y1 = ix0 * (z1 - z) + ix1 * (z - z0)\n    iz1y0 = ix0 * (z1 - z) + ix1 * (z - z0)\n    iy = iz0y0 * (y1 - y) + iz1y1 * (y - y0)\n    ix = iz0y1 * (y1 - y) + iz1y0 * (y - y0)\n    return iy * (x1 - x) + ix * (x - x0)\n  else:\n    raise ValueError(\"Invalid method. Method must be 'NEAREST' or 'TRILINEAR'.\")"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'TRILINEAR':\n    if half_pixel_center:\n      locations = locations + 0.5\n    if edge_behavior == 'CONSTANT_OUTSIDE':\n      data = jnp.pad(data, ((1, 1), (1, 1), (1, 1), (0, 0)), mode='constant', constant_values=constant_values)\n      locations = jnp.clip(locations, 0, (data.shape[0] - 1, data.shape[1] - 1, data.shape[2] - 1))\n    elif edge_behavior == 'CLAMP':\n      locations = jnp.clip(locations, 0, (data.shape[0] - 1, data.shape[1] - 1, data.shape[2] - 1))\n\n    # Compute the integer and fractional parts of the sample locations\n    int_locations = jnp.floor(locations).astype(jnp.int32)\n    delta = locations - int_locations\n\n    # Gather the 8 corner values around the sample locations\n    c000 = gather_volume(data, int_locations, coordinate_order)\n    c100 = gather_volume(data, int_locations + (1, 0, 0), coordinate_order)\n    c010 = gather_volume(data, int_locations + (0, 1, 0), coordinate_order)\n    c110 = gather_volume(data, int_locations + (1, 1, 0), coordinate_order)\n    c001 = gather_volume(data, int_locations + (0, 0, 1), coordinate_order)\n    c101 = gather_volume(data, int_locations + (1, 0, 1), coordinate_order)\n    c011 = gather_volume(data, int_locations + (0, 1, 1), coordinate_order)\n    c111 = gather_volume(data, int_locations + (1, 1, 1), coordinate_order)\n\n    # Trilinear interpolation\n    c00 = c000 * (1 - delta[..., 0]) + c100 * delta[..., 0]\n    c01 = c001 * (1 - delta[..., 0]) + c101 * delta[..., 0]\n    c10 = c010 * (1 - delta[..., 0]) + c110 * delta[..., 0]\n    c11 = c011 * (1 - delta[..., 0]) + c111 * delta[..., 0]\n    c0 = c00 * (1 - delta[..., 1]) + c10 * delta[..., 1]\n    c1 = c01 * (1 - delta[..., 1]) + c11 * delta[..., 1]\n    resampled_data = c0 * (1 - delta[..., 2]) + c1 * delta[..., 2]\n\n  elif method == 'NEAREST':\n    if half_pixel_center:\n      locations = jnp.round(locations)\n    else:\n      locations = jnp.floor(locations + 0.5)\n    if edge_behavior == 'CONSTANT_OUTSIDE':\n      data = jnp.pad(data, ((1, 1), (1, 1), (1, 1), (0, 0)), mode='constant', constant_values=constant_values)\n      locations = jnp.clip(locations, 0, (data.shape[0] - 1, data.shape[1] - 1, data.shape[2] - 1))\n    elif edge_behavior == 'CLAMP':\n      locations = jnp.clip(locations, 0, (data.shape[0] - 1, data.shape[1] - 1, data.shape[2] - 1))\n    resampled_data = gather_volume(data, locations, coordinate_order)\n\n  return resampled_data"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    # Round the locations to the nearest integer\n    locations = jnp.round(locations).astype(jnp.int32)\n    # Gather from data at rounded locations\n    resampled_data = gather_volume(data, locations, coordinate_order)\n  elif method == 'TRILINEAR':\n    # If half pixel centering is used, adjust the locations\n    if half_pixel_center:\n      locations -= 0.5\n    # Extract the integer and fractional parts of the locations\n    int_locations = jnp.floor(locations).astype(jnp.int32)\n    frac_locations = locations - int_locations\n    # Handle edge behavior based on the specified method\n    if edge_behavior == 'CONSTANT_OUTSIDE':\n      # Pad the data with constant values\n      padded_data = jnp.pad(data, 1, constant_values=constant_values)\n      # Gather from data at integer locations\n      gathered_data = gather_volume(padded_data, int_locations, coordinate_order)\n    elif edge_behavior == 'CLAMP':\n      # Clamp the integer locations to the valid range\n      int_locations = jnp.clip(int_locations, 0, jnp.array(data.shape) - 1)\n      # Gather from data at integer locations\n      gathered_data = gather_volume(data, int_locations, coordinate_order)\n    else:\n      raise ValueError(\"Invalid edge behavior specified. Supported options are 'CONSTANT_OUTSIDE' and 'CLAMP'.\")\n    # Calculate the trilinear interpolation weights\n    weights = jnp.prod(1 - frac_locations, axis=-1, keepdims=True)\n    # Interpolate along the x-axis\n    interp_x0 = gathered_data * (1 - frac_locations[..., 0:1]) + gather_volume(data, int_locations + 1, coordinate_order) * frac_locations[..., 0:1]\n    interp_x1 = gathered_data * (1 - frac_locations[..., 0:1]) + gather_volume(data, int_locations + 1, coordinate_order) * frac_locations[..., 0:1]\n    interp_x = interp_x0 * (1 - frac_locations[..., 1:2]) + interp_x1 * frac_locations[..., 1:2]\n    # Interpolate along the y-axis\n    interp_y0 = interp_x * (1 - frac_locations[..., 1:2]) + interp_x * frac_locations[..., 1:2]\n    interp_y1 = interp_x * (1 - frac_locations[..., 1:2]) + interp_x * frac_locations[..., 1:2]\n    interp_y = interp_y0 * (1 - frac_locations[..., 2:]) + interp_y1 * frac_locations[..., 2:]\n    # Assign the interpolated values to the resampled data\n    resampled_data = interp_y\n  else:\n    raise ValueError(\"Invalid method specified. Supported options are 'TRILINEAR' and 'NEAREST'.\")\n\n  return resampled_data"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    # Round the locations to the nearest integer\n    if half_pixel_center:\n      locations = locations - 0.5\n    locations = jnp.round(locations).astype(jnp.int32)\n\n    # Clamp the locations to the volume boundaries if edge behavior is set to 'CLAMP'\n    if edge_behavior == 'CLAMP':\n      locations = jnp.clip(locations, 0, jnp.array(data.shape[:3]) - 1)\n\n    # Gather from data at the rounded locations\n    resampled_data = gather_volume(data, locations, coordinate_order)\n\n  elif method == 'TRILINEAR':\n    # Calculate the fractional part of the locations\n    if half_pixel_center:\n      locations = locations - 0.5\n    int_locations = jnp.floor(locations).astype(jnp.int32)\n    fractional = locations - int_locations\n\n    # Clamp the locations to the volume boundaries if edge behavior is set to 'CLAMP'\n    if edge_behavior == 'CLAMP':\n      int_locations = jnp.clip(int_locations, 0, jnp.array(data.shape[:3]) - 1)\n\n    # Gather the 8 corners of the cube around the locations\n    corners = []\n    for z_off in [0, 1]:\n      for y_off in [0, 1]:\n        for x_off in [0, 1]:\n          corner_locations = int_locations + jnp.array([z_off, y_off, x_off])\n          corner_data = gather_volume(data, corner_locations, coordinate_order)\n          corners.append(corner_data)\n\n    # Perform trilinear interpolation\n    x_weights = jnp.stack([1 - fractional[..., 2], fractional[..., 2]])\n    y_weights = jnp.stack([1 - fractional[..., 1], fractional[..., 1]])\n    z_weights = jnp.stack([1 - fractional[..., 0], fractional[..., 0])\n    resampled_data = jnp.tensordot(\n        jnp.tensordot(\n            jnp.tensordot(corners[0], x_weights[0], axes=0) +\n            jnp.tensordot(corners[1], x_weights[1], axes=0),\n            y_weights[0], axes=0) +\n        jnp.tensordot(\n            jnp.tensordot(corners[2], x_weights[0], axes=0) +\n            jnp.tensordot(corners[3], x_weights[1], axes=0),\n            y_weights[1], axes=0),\n        z_weights[0], axes=0) +\n    jnp.tensordot(\n        jnp.tensordot(\n            jnp.tensordot(corners[4], x_weights[0], axes=0) +\n            jnp.tensordot(corners[5], x_weights[1], axes=0),\n            y_weights[0], axes=0) +\n        jnp.tensordot(\n            jnp.tensordot(corners[6], x_weights[0], axes=0) +\n            jnp.tensordot(corners[7], x_weights[1], axes=0),\n            y_weights[1], axes=0),\n        z_weights[1], axes=0)\n\n  return resampled_data"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    # Round locations to the nearest integer\n    locations = jnp.round(locations).astype(jnp.int32)\n    # Gather from data at the rounded locations\n    resampled_data = gather_volume(data, locations, coordinate_order)\n  elif method == 'TRILINEAR':\n    # If half-pixel centering is used, adjust the locations\n    if half_pixel_center:\n      locations -= 0.5\n    # Get the floor and ceil coordinates\n    floor_locations = jnp.floor(locations).astype(jnp.int32)\n    ceil_locations = jnp.ceil(locations).astype(jnp.int32)\n    # Calculate the alpha values for interpolation\n    alpha = locations - floor_locations\n    # Handle edge behavior\n    if edge_behavior == 'CONSTANT_OUTSIDE':\n      # Pad the data with constant values\n      data = jnp.pad(data, ((1, 1), (1, 1), (1, 1), (0, 0)), mode='constant', constant_values=constant_values)\n      # Clamp the floor and ceil locations\n      floor_locations = jnp.clip(floor_locations, 0, jnp.array(data.shape) - 1)\n      ceil_locations = jnp.clip(ceil_locations, 0, jnp.array(data.shape) - 1)\n    elif edge_behavior == 'CLAMP':\n      # Clamp the floor and ceil locations\n      floor_locations = jnp.clip(floor_locations, 0, jnp.array(data.shape) - 1)\n      ceil_locations = jnp.clip(ceil_locations, 0, jnp.array(data.shape) - 1)\n    # Gather the data at floor and ceil locations\n    data_floor = gather_volume(data, floor_locations, coordinate_order)\n    data_ceil = gather_volume(data, ceil_locations, coordinate_order)\n    # Perform trilinear interpolation\n    resampled_data = (1 - alpha) * data_floor + alpha * data_ceil\n  return resampled_data"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    return gather_volume(data, jnp.floor(locations + 0.5).astype(jnp.int32), coordinate_order)\n  elif method == 'TRILINEAR':\n    if half_pixel_center:\n      locations -= 0.5\n    z = locations[..., 0]\n    y = locations[..., 1]\n    x = locations[..., 2]\n    z0 = jnp.floor(z).astype(jnp.int32)\n    z1 = z0 + 1\n    y0 = jnp.floor(y).astype(jnp.int32)\n    y1 = y0 + 1\n    x0 = jnp.floor(x).astype(jnp.int32)\n    x1 = x0 + 1\n    z0 = jnp.clip(z0, 0, data.shape[0] - 1)\n    z1 = jnp.clip(z1, 0, data.shape[0] - 1)\n    y0 = jnp.clip(y0, 0, data.shape[1] - 1)\n    y1 = jnp.clip(y1, 0, data.shape[1] - 1)\n    x0 = jnp.clip(x0, 0, data.shape[2] - 1)\n    x1 = jnp.clip(x1, 0, data.shape[2] - 1)\n\n    iz0 = z0.astype(jnp.int32)\n    iz1 = z1.astype(jnp.int32)\n    iy0 = y0.astype(jnp.int32)\n    iy1 = y1.astype(jnp.int32)\n    ix0 = x0.astype(jnp.int32)\n    ix1 = x1.astype(jnp.int32)\n\n    dz = z - z0\n    dy = y - y0\n    dx = x - x0\n\n    w000 = (1 - dz) * (1 - dy) * (1 - dx)\n    w001 = (1 - dz) * (1 - dy) * dx\n    w010 = (1 - dz) * dy * (1 - dx)\n    w011 = (1 - dz) * dy * dx\n    w100 = dz * (1 - dy) * (1 - dx)\n    w101 = dz * (1 - dy) * dx\n    w110 = dz * dy * (1 - dx)\n    w111 = dz * dy * dx\n\n    c000 = gather_volume(data, jnp.stack([iz0, iy0, ix0], axis=-1), coordinate_order)\n    c001 = gather_volume(data, jnp.stack([iz0, iy0, ix1], axis=-1), coordinate_order)\n    c010 = gather_volume(data, jnp.stack([iz0, iy1, ix0], axis=-1), coordinate_order)\n    c011 = gather_volume(data, jnp.stack([iz0, iy1, ix1], axis=-1), coordinate_order)\n    c100 = gather_volume(data, jnp.stack([iz1, iy0, ix0], axis=-1), coordinate_order)\n    c101 = gather_volume(data, jnp.stack([iz1, iy0, ix1], axis=-1), coordinate_order)\n    c110 = gather_volume(data, jnp.stack([iz1, iy1, ix0], axis=-1), coordinate_order)\n    c111 = gather_volume(data, jnp.stack([iz1, iy1, ix1], axis=-1), coordinate_order)\n\n    return (\n        w000 * c000 + w001 * c001 + w010 * c010 + w011 * c011 +\n        w100 * c100 + w101 * c101 + w110 * c110 + w111 * c111\n    )\n  else:\n    raise ValueError(\"Invalid method argument. Must be 'NEAREST' or 'TRILINEAR'.\")"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    # Round the locations to the nearest integer\n    rounded_locations = jnp.round(locations).astype(jnp.int32)\n\n    if edge_behavior == 'CONSTANT_OUTSIDE':\n      # Pad the input data with constant values\n      padded_data = jnp.pad(data, 1, constant_values=constant_values)\n\n      # Clamp the rounded locations to the bounds of the padded data\n      clamped_locations = jnp.clip(rounded_locations, 0, jnp.array(data.shape) - 1)\n\n      # Gather the nearest neighbor values from the padded data\n      resampled_data = gather_volume(padded_data, clamped_locations, coordinate_order)\n\n    elif edge_behavior == 'CLAMP':\n      # Clamp the rounded locations to the bounds of the input data\n      clamped_locations = jnp.clip(rounded_locations, 0, jnp.array(data.shape) - 1)\n\n      # Gather the nearest neighbor values from the input data\n      resampled_data = gather_volume(data, clamped_locations, coordinate_order)\n\n  elif method == 'TRILINEAR':\n    # Implement trilinear interpolation\n    # ...\n    # (Add trilinear interpolation implementation here)\n\n  return resampled_data"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    # Round the locations to the nearest integer\n    rounded_locations = jnp.round(locations).astype(jnp.int32)\n\n    # Clamp the rounded locations if edge behavior is set to 'CLAMP'\n    if edge_behavior == 'CLAMP':\n      rounded_locations = jnp.clip(rounded_locations, 0, jnp.array(data.shape[:-1]) - 1)\n\n    # Gather from data at the rounded locations\n    resampled_data = gather_volume(data, rounded_locations, coordinate_order)\n\n  elif method == 'TRILINEAR':\n    # If half-pixel centering is used, adjust the locations\n    if half_pixel_center:\n      locations -= 0.5\n\n    # Extract the integer and fractional parts of the locations\n    int_locations = jnp.floor(locations).astype(jnp.int32)\n    frac_locations = locations - int_locations\n\n    # Clamp the integer locations if edge behavior is set to 'CLAMP'\n    if edge_behavior == 'CLAMP':\n      int_locations = jnp.clip(int_locations, 0, jnp.array(data.shape[:-1]) - 1)\n\n    # Gather from data at the integer locations\n    c000 = gather_volume(data, int_locations, coordinate_order)\n    c100 = gather_volume(data, int_locations + jnp.array([1, 0, 0]), coordinate_order)\n    c010 = gather_volume(data, int_locations + jnp.array([0, 1, 0]), coordinate_order)\n    c001 = gather_volume(data, int_locations + jnp.array([0, 0, 1]), coordinate_order)\n    c110 = gather_volume(data, int_locations + jnp.array([1, 1, 0]), coordinate_order)\n    c101 = gather_volume(data, int_locations + jnp.array([1, 0, 1]), coordinate_order)\n    c011 = gather_volume(data, int_locations + jnp.array([0, 1, 1]), coordinate_order)\n    c111 = gather_volume(data, int_locations + jnp.array([1, 1, 1]), coordinate_order)\n\n    # Trilinear interpolation\n    resampled_data = (\n        (1 - frac_locations[..., 0]) * (1 - frac_locations[..., 1]) * (1 - frac_locations[..., 2]) * c000 +\n        frac_locations[..., 0] * (1 - frac_locations[..., 1]) * (1 - frac_locations[..., 2]) * c100 +\n        (1 - frac_locations[..., 0]) * frac_locations[..., 1] * (1 - frac_locations[..., 2]) * c010 +\n        (1 - frac_locations[..., 0]) * (1 - frac_locations[..., 1]) * frac_locations[..., 2] * c001 +\n        frac_locations[..., 0] * frac_locations[..., 1] * (1 - frac_locations[..., 2]) * c110 +\n        frac_locations[..., 0] * (1 - frac_locations[..., 1]) * frac_locations[..., 2] * c101 +\n        (1 - frac_locations[..., 0]) * frac_locations[..., 1] * frac_locations[..., 2] * c011 +\n        frac_locations[..., 0] * frac_locations[..., 1] * frac_locations[..., 2] * c111\n    )\n\n  else:\n    raise ValueError(\"Invalid method. Method must be 'TRILINEAR' or 'NEAREST'.\")\n\n  return resampled_data"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'TRILINEAR':\n    if half_pixel_center:\n      locations -= 0.5\n    z = locations[..., 0]\n    y = locations[..., 1]\n    x = locations[..., 2]\n\n    # Handle edge behavior\n    if edge_behavior == 'CONSTANT_OUTSIDE':\n      data = jnp.pad(data, ((1, 1), (1, 1), (1, 1), (0, 0)), constant_values=constant_values)\n      z = jnp.clip(z, 0, data.shape[0] - 1)\n      y = jnp.clip(y, 0, data.shape[1] - 1)\n      x = jnp.clip(x, 0, data.shape[2] - 1)\n    elif edge_behavior == 'CLAMP':\n      z = jnp.clip(z, 0, data.shape[0] - 1)\n      y = jnp.clip(y, 0, data.shape[1] - 1)\n      x = jnp.clip(x, 0, data.shape[2] - 1)\n\n    # Compute the integer coordinates for the 8 corners of the cube\n    z0 = jnp.floor(z).astype(jnp.int32)\n    z1 = z0 + 1\n    y0 = jnp.floor(y).astype(jnp.int32)\n    y1 = y0 + 1\n    x0 = jnp.floor(x).astype(jnp.int32)\n    x1 = x0 + 1\n\n    # Compute the weights for trilinear interpolation\n    dz = z - z0\n    dy = y - y0\n    dx = x - x0\n    wz0 = (1 - dz) * (1 - dy) * (1 - dx)\n    wz1 = (1 - dz) * (1 - dy) * dx\n    wz2 = (1 - dz) * dy * (1 - dx)\n    wz3 = (1 - dz) * dy * dx\n    wz4 = dz * (1 - dy) * (1 - dx)\n    wz5 = dz * (1 - dy) * dx\n    wz6 = dz * dy * (1 - dx)\n    wz7 = dz * dy * dx\n\n    # Gather the values from the 8 corners of the cube\n    c000 = gather_volume(data, jnp.stack([z0, y0, x0], axis=-1), coordinate_order)\n    c001 = gather_volume(data, jnp.stack([z0, y0, x1], axis=-1), coordinate_order)\n    c010 = gather_volume(data, jnp.stack([z0, y1, x0], axis=-1), coordinate_order)\n    c011 = gather_volume(data, jnp.stack([z0, y1, x1], axis=-1), coordinate_order)\n    c100 = gather_volume(data, jnp.stack([z1, y0, x0], axis=-1), coordinate_order)\n    c101 = gather_volume(data, jnp.stack([z1, y0, x1], axis=-1), coordinate_order)\n    c110 = gather_volume(data, jnp.stack([z1, y1, x0], axis=-1), coordinate_order)\n    c111 = gather_volume(data, jnp.stack([z1, y1, x1], axis=-1), coordinate_order)\n\n    # Perform trilinear interpolation\n    result = wz0 * c000 + wz1 * c001 + wz2 * c010 + wz3 * c011 + wz4 * c100 + wz5 * c101 + wz6 * c110 + wz7 * c111\n  elif method == 'NEAREST':\n    if half_pixel_center:\n      locations = jnp.round(locations)\n    result = gather_volume(data, locations.astype(jnp.int32), coordinate_order)\n  else:\n    raise ValueError(\"Invalid method. Method must be 'TRILINEAR' or 'NEAREST'.\")\n\n  return result"}
{"namespace": "resample.resample_3d", "completion": "  # Use Advanced indexing to gather data data.\n  if method == 'NEAREST':\n    if coordinate_order == 'xyz':\n      locations = jnp.round(locations).astype(int)\n    elif coordinate_order == 'zyx':\n      locations = jnp.round(locations[..., ::-1]).astype(int)\n    else:\n      raise ValueError(\"Invalid coordinate_order. Must be 'xyz' or 'zyx'.\")\n\n    if edge_behavior == 'CONSTANT_OUTSIDE':\n      data = jnp.pad(data, 1, constant_values=constant_values)\n      gathered = gather_volume(data, locations, coordinate_order)\n    elif edge_behavior == 'CLAMP':\n      gathered = gather_volume(data, jnp.clip(locations, 0, jnp.array(data.shape[:-1]) - 1), coordinate_order)\n    else:\n      raise ValueError(\"Invalid edge_behavior. Must be 'CONSTANT_OUTSIDE' or 'CLAMP'.\")\n\n  elif method == 'TRILINEAR':\n    # Your code for trilinear interpolation\n    pass\n  else:\n    raise ValueError(\"Invalid method. Must be 'NEAREST' or 'TRILINEAR'.\")\n\n  return gathered"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    # Round the locations to the nearest integer\n    locations = jnp.round(locations).astype(jnp.int32)\n    # Gather the data at the rounded locations\n    resampled_data = gather_volume(data, locations, coordinate_order)\n  elif method == 'TRILINEAR':\n    if half_pixel_center:\n      # Adjust locations for half-pixel centering\n      locations -= 0.5\n    # Extract the integer and fractional parts of the locations\n    int_locations = jnp.floor(locations).astype(jnp.int32)\n    fractional = locations - int_locations\n    # Clamp the integer locations to the valid range\n    int_locations = jnp.clip(int_locations, 0, jnp.array(data.shape[:3]) - 1)\n    # Gather the data at the integer locations\n    gathered_data = gather_volume(data, int_locations, coordinate_order)\n    # Interpolate along the x-axis\n    x0 = gathered_data\n    x1 = jnp.roll(gathered_data, shift=-1, axis=2)\n    x = x0 * (1 - fractional[Ellipsis, 0]) + x1 * fractional[Ellipsis, 0]\n    # Interpolate along the y-axis\n    y0 = x\n    y1 = jnp.roll(x, shift=-1, axis=1)\n    y = y0 * (1 - fractional[Ellipsis, 1]) + y1 * fractional[Ellipsis, 1]\n    # Interpolate along the z-axis\n    z0 = y\n    z1 = jnp.roll(y, shift=-1, axis=0)\n    resampled_data = z0 * (1 - fractional[Ellipsis, 2]) + z1 * fractional[Ellipsis, 2]\n  else:\n    raise ValueError(\"Invalid method. Method must be either 'NEAREST' or 'TRILINEAR'.\")\n\n  if edge_behavior == 'CONSTANT_OUTSIDE':\n    # Mask values outside the valid range and replace with constant_values\n    mask = (int_locations < 0) | (int_locations >= jnp.array(data.shape[:3])[None, ...])\n    resampled_data = jnp.where(mask.any(axis=-1, keepdims=True), constant_values, resampled_data)\n  elif edge_behavior == 'CLAMP':\n    # Clamp values outside the valid range to the nearest valid value\n    resampled_data = jnp.clip(resampled_data, 0, jnp.array(data.shape[:3]) - 1)\n  else:\n    raise ValueError(\"Invalid edge_behavior. Edge behavior must be either 'CONSTANT_OUTSIDE' or 'CLAMP'.\")\n\n  return resampled_data"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    # Round the locations to the nearest integer\n    rounded_locations = jnp.round(locations).astype(jnp.int32)\n    # Gather from data at the rounded locations\n    resampled_data = gather_volume(data, rounded_locations, coordinate_order)\n  elif method == 'TRILINEAR':\n    # If half pixel centering is used, shift the locations by 0.5\n    if half_pixel_center:\n      locations = locations + 0.5\n    # Extract the integer and fractional parts of the locations\n    int_locations = jnp.floor(locations).astype(jnp.int32)\n    fractional_part = locations - int_locations\n    # Handle edge behavior\n    if edge_behavior == 'CONSTANT_OUTSIDE':\n      # Pad the data with constant values\n      padded_data = jnp.pad(data, 1, constant_values=constant_values)\n      # Gather the data at the integer locations\n      gathered_data = gather_volume(padded_data, int_locations, coordinate_order)\n    elif edge_behavior == 'CLAMP':\n      # Clamp the integer locations to the valid range\n      clamped_locations = jnp.clip(int_locations, 0, jnp.array(data.shape) - 1)\n      # Gather the data at the clamped locations\n      gathered_data = gather_volume(data, clamped_locations, coordinate_order)\n    # Calculate the weights for trilinear interpolation\n    weights = jnp.array([[(1 - fractional_part[0]) * (1 - fractional_part[1]),\n                          (1 - fractional_part[0]) * fractional_part[1]],\n                         [fractional_part[0] * (1 - fractional_part[1]),\n                          fractional_part[0] * fractional_part[1]]])\n    # Perform trilinear interpolation\n    resampled_data = jnp.sum(gathered_data * weights, axis=(2, 3))\n  return resampled_data"}
{"namespace": "resample.resample_3d", "completion": "  # Convert the locations to match the coordinate order\n  if coordinate_order == 'xyz':\n    locations = locations\n  elif coordinate_order == 'zyx':\n    locations = jnp.flip(locations, axis=-1)\n\n  # Handle edge behavior\n  if edge_behavior == 'CONSTANT_OUTSIDE':\n    data = jnp.pad(data, ((1, 1), (1, 1), (1, 1), (0, 0)), mode='constant', constant_values=constant_values)\n    locations = jnp.clip(locations, 0, (jnp.array(data.shape[:3]) - 1).astype(jnp.float32))\n  elif edge_behavior == 'CLAMP':\n    locations = jnp.clip(locations, 0, (jnp.array(data.shape[:3]) - 1).astype(jnp.float32))\n\n  # Perform trilinear interpolation\n  if method == 'TRILINEAR':\n    if half_pixel_center:\n      locations -= 0.5\n    floor_locations = jnp.floor(locations).astype(jnp.int32)\n    ceil_locations = jnp.minimum(floor_locations + 1, jnp.array(data.shape[:3]) - 1)\n    alpha = locations - floor_locations.astype(jnp.float32)\n    inv_alpha = 1.0 - alpha\n    data000 = gather_volume(data, floor_locations, coordinate_order)\n    data001 = gather_volume(data, jnp.stack([floor_locations[..., 0], floor_locations[..., 1], ceil_locations[..., 2]], axis=-1), coordinate_order)\n    data010 = gather_volume(data, jnp.stack([floor_locations[..., 0], ceil_locations[..., 1], floor_locations[..., 2]], axis=-1), coordinate_order)\n    data011 = gather_volume(data, jnp.stack([floor_locations[..., 0], ceil_locations[..., 1], ceil_locations[..., 2]], axis=-1), coordinate_order)\n    data100 = gather_volume(data, jnp.stack([ceil_locations[..., 0], floor_locations[..., 1], floor_locations[..., 2]], axis=-1), coordinate_order)\n    data101 = gather_volume(data, jnp.stack([ceil_locations[..., 0], floor_locations[..., 1], ceil_locations[..., 2]], axis=-1), coordinate_order)\n    data110 = gather_volume(data, jnp.stack([ceil_locations[..., 0], ceil_locations[..., 1], floor_locations[..., 2]], axis=-1), coordinate_order)\n    data111 = gather_volume(data, ceil_locations, coordinate_order)\n    resampled_values = (\n        data000 * inv_alpha[..., 0] * inv_alpha[..., 1] * inv_alpha[..., 2] +\n        data001 * inv_alpha[..., 0] * inv_alpha[..., 1] * alpha[..., 2] +\n        data010 * inv_alpha[..., 0] * alpha[..., 1] * inv_alpha[..., 2] +\n        data011 * inv_alpha[..., 0] * alpha[..., 1] * alpha[..., 2] +\n        data100 * alpha[..., 0] * inv_alpha[..., 1] * inv_alpha[..., 2] +\n        data101 * alpha[..., 0] * inv_alpha[..., 1] * alpha[..., 2] +\n        data110 * alpha[..., 0] * alpha[..., 1] * inv_alpha[..., 2] +\n        data111 * alpha[..., 0] * alpha[..., 1] * alpha[..., 2]\n    )\n\n  # Perform nearest neighbor interpolation\n  elif method == 'NEAREST':\n    if half_pixel_center:\n      locations = jnp.round(locations)\n    else:\n      locations = jnp.floor(locations + 0.5)\n    resampled_values = gather_volume(data, locations.astype(jnp.int32), coordinate_order)\n\n  return resampled_values"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    # Nearest neighbor interpolation\n    if half_pixel_center:\n      locations = locations - 0.5\n    locations = jnp.round(locations).astype(jnp.int32)\n    if edge_behavior == 'CONSTANT_OUTSIDE':\n      data = jnp.pad(data, 1, mode='constant', constant_values=constant_values)\n    elif edge_behavior == 'CLAMP':\n      locations = jnp.clip(locations, 0, jnp.array(data.shape) - 1)\n    return gather_volume(data, locations, coordinate_order)\n  elif method == 'TRILINEAR':\n    # Trilinear interpolation\n    if half_pixel_center:\n      locations = locations - 0.5\n    floor_locations = jnp.floor(locations).astype(jnp.int32)\n    ceil_locations = jnp.ceil(locations).astype(jnp.int32)\n    if edge_behavior == 'CONSTANT_OUTSIDE':\n      data = jnp.pad(data, 1, mode='constant', constant_values=constant_values)\n      floor_locations = jnp.clip(floor_locations, 0, jnp.array(data.shape) - 1)\n      ceil_locations = jnp.clip(ceil_locations, 0, jnp.array(data.shape) - 1)\n    elif edge_behavior == 'CLAMP':\n      floor_locations = jnp.clip(floor_locations, 0, jnp.array(data.shape) - 1)\n      ceil_locations = jnp.clip(ceil_locations, 0, jnp.array(data.shape) - 1)\n\n    alpha = locations - floor_locations\n    inv_alpha = 1.0 - alpha\n\n    # Gather the 8 corner values\n    c000 = gather_volume(data, floor_locations, coordinate_order)\n    c001 = gather_volume(data, jnp.stack([ceil_locations[..., 0], floor_locations[..., 1], floor_locations[..., 2]], axis=-1), coordinate_order)\n    c010 = gather_volume(data, jnp.stack([floor_locations[..., 0], ceil_locations[..., 1], floor_locations[..., 2]], axis=-1), coordinate_order)\n    c011 = gather_volume(data, jnp.stack([ceil_locations[..., 0], ceil_locations[..., 1], floor_locations[..., 2]], axis=-1), coordinate_order)\n    c100 = gather_volume(data, jnp.stack([floor_locations[..., 0], floor_locations[..., 1], ceil_locations[..., 2]], axis=-1), coordinate_order)\n    c101 = gather_volume(data, jnp.stack([ceil_locations[..., 0], floor_locations[..., 1], ceil_locations[..., 2]], axis=-1), coordinate_order)\n    c110 = gather_volume(data, jnp.stack([floor_locations[..., 0], ceil_locations[..., 1], ceil_locations[..., 2]], axis=-1), coordinate_order)\n    c111 = gather_volume(data, ceil_locations, coordinate_order)\n\n    # Perform trilinear interpolation\n    result = (\n        c000 * inv_alpha[..., 0] * inv_alpha[..., 1] * inv_alpha[..., 2] +\n        c001 * inv_alpha[..., 0] * inv_alpha[..., 1] * alpha[..., 2] +\n        c010 * inv_alpha[..., 0] * alpha[..., 1] * inv_alpha[..., 2] +\n        c011 * inv_alpha[..., 0] * alpha[..., 1] * alpha[..., 2] +\n        c100 * alpha[..., 0] * inv_alpha[..., 1] * inv_alpha[..., 2] +\n        c101 * alpha[..., 0] * inv_alpha[..., 1] * alpha[..., 2] +\n        c110 * alpha[..., 0] * alpha[..., 1] * inv_alpha[..., 2] +\n        c111 * alpha[..., 0] * alpha[..., 1] * alpha[..., 2]\n    )\n    return result\n  else:\n    raise ValueError(\"Unknown resampling method: {}\".format(method))"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    # Nearest neighbor interpolation\n    if half_pixel_center:\n      locations = locations - 0.5\n    rounded_locations = jnp.round(locations).astype(jnp.int32)\n    if edge_behavior == 'CONSTANT_OUTSIDE':\n      rounded_locations = jnp.clip(rounded_locations, 0, jnp.array(data.shape) - 1)\n      resampled_data = gather_volume(data, rounded_locations, coordinate_order)\n      return resampled_data\n    elif edge_behavior == 'CLAMP':\n      rounded_locations = jnp.clip(rounded_locations, 0, jnp.array(data.shape) - 1)\n      resampled_data = gather_volume(data, rounded_locations, coordinate_order)\n      return resampled_data\n  elif method == 'TRILINEAR':\n    # Trilinear interpolation\n    if half_pixel_center:\n      locations = locations - 0.5\n    floor_locations = jnp.floor(locations).astype(jnp.int32)\n    ceil_locations = jnp.ceil(locations).astype(jnp.int32)\n    if edge_behavior == 'CONSTANT_OUTSIDE':\n      floor_locations = jnp.clip(floor_locations, 0, jnp.array(data.shape) - 1)\n      ceil_locations = jnp.clip(ceil_locations, 0, jnp.array(data.shape) - 1)\n      alpha = locations - floor_locations\n      resampled_data = (\n          (1 - alpha) * gather_volume(data, floor_locations, coordinate_order)\n          + alpha * gather_volume(data, ceil_locations, coordinate_order)\n      )\n      return resampled_data\n    elif edge_behavior == 'CLAMP':\n      floor_locations = jnp.clip(floor_locations, 0, jnp.array(data.shape) - 1)\n      ceil_locations = jnp.clip(ceil_locations, 0, jnp.array(data.shape) - 1)\n      alpha = locations - floor_locations\n      resampled_data = (\n          (1 - alpha) * gather_volume(data, floor_locations, coordinate_order)\n          + alpha * gather_volume(data, ceil_locations, coordinate_order)\n      )\n      return resampled_data\n  else:\n    raise ValueError(\"Invalid method. Method must be 'TRILINEAR' or 'NEAREST'.\")"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    # Round the locations to the nearest integer\n    locations = jnp.round(locations).astype(jnp.int32)\n    return gather_volume(data, locations, coordinate_order)\n\n  if method == 'TRILINEAR':\n    if half_pixel_center:\n      # Adjust the locations for half-pixel centering\n      locations -= 0.5\n\n    # Extract the integer and fractional parts of the locations\n    int_locations = jnp.floor(locations).astype(jnp.int32)\n    frac_locations = locations - int_locations\n\n    # Handle edge behavior based on the specified method\n    if edge_behavior == 'CONSTANT_OUTSIDE':\n      # Pad the input volume with constant values\n      data = jnp.pad(data, 1, mode='constant', constant_values=constant_values)\n      int_locations += 1  # Adjust the integer locations for the padding\n\n    # Gather the 8 neighboring voxels for trilinear interpolation\n    c000 = gather_volume(data, int_locations, coordinate_order)\n    c100 = gather_volume(data, int_locations + [1, 0, 0], coordinate_order)\n    c010 = gather_volume(data, int_locations + [0, 1, 0], coordinate_order)\n    c001 = gather_volume(data, int_locations + [0, 0, 1], coordinate_order)\n    c110 = gather_volume(data, int_locations + [1, 1, 0], coordinate_order)\n    c101 = gather_volume(data, int_locations + [1, 0, 1], coordinate_order)\n    c011 = gather_volume(data, int_locations + [0, 1, 1], coordinate_order)\n    c111 = gather_volume(data, int_locations + [1, 1, 1], coordinate_order)\n\n    # Perform trilinear interpolation\n    x0 = lerp(c000, c100, frac_locations[..., 0])\n    x1 = lerp(c010, c110, frac_locations[..., 0])\n    y0 = lerp(x0, x1, frac_locations[..., 1])\n    x0 = lerp(c001, c101, frac_locations[..., 0])\n    x1 = lerp(c011, c111, frac_locations[..., 0])\n    y1 = lerp(x0, x1, frac_locations[..., 1])\n    return lerp(y0, y1, frac_locations[..., 2])"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  dt = jnp.diff(t)\n  integral = jnp.sum((w[Ellipsis, :-1] + w[Ellipsis, 1:]) * dt, axis=-1) / 2\n  return integral"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  dt = jnp.diff(t)\n  integral = jnp.sum((w[Ellipsis, :-1] + w[Ellipsis, 1:]) * dt, axis=-1) / 2\n  return integral"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  dt = jnp.diff(t)\n  integral = jnp.sum((w[Ellipsis, :-1] + w[Ellipsis, 1:]) * dt / 2, axis=-1)\n  return integral"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  dt = jnp.diff(t)\n  integral = jnp.sum(0.5 * (w[Ellipsis, :-1] + w[Ellipsis, 1:]) * dt)\n  return integral"}
{"namespace": "linspline.integrate", "completion": "  dt = jnp.diff(t)\n  return jnp.sum((w[Ellipsis, :-1] + w[Ellipsis, 1:]) * dt) / 2"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  dt = jnp.diff(t)\n  integral = 0.5 * jnp.sum(dt * (w[Ellipsis, :-1] + w[Ellipsis, 1:]))\n  return integral"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  dt = jnp.diff(t)\n  dw = jnp.diff(w)\n  return jnp.sum(0.5 * (w[Ellipsis, :-1] + w[Ellipsis, 1:]) * dt)"}
{"namespace": "linspline.integrate", "completion": "  dt = jnp.diff(t)\n  integral = jnp.sum((w[Ellipsis, :-1] + w[Ellipsis, 1:]) * dt, axis=-1) / 2\n  return integral"}
{"namespace": "linspline.integrate", "completion": "  dt = jnp.diff(t)\n  integral = jnp.sum((w[Ellipsis, :-1] + w[Ellipsis, 1:]) * dt / 2)\n  return integral"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  dt = jnp.diff(t)\n  dw = jnp.diff(w)\n  return jnp.sum((w[Ellipsis, :-1] + w[Ellipsis, 1:]) * dt) / 2"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  dt = jnp.diff(t)\n  integral = jnp.sum((w[Ellipsis, :-1] + w[Ellipsis, 1:]) * dt, axis=-1) / 2\n  return integral"}
{"namespace": "linspline.integrate", "completion": "  dt = jnp.diff(t)\n  return jnp.sum(0.5 * (w[Ellipsis, :-1] + w[Ellipsis, 1:]) * dt)"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  dt = jnp.diff(t)\n  integral = jnp.sum((w[Ellipsis, :-1] + w[Ellipsis, 1:]) * dt, axis=-1) / 2\n  return integral"}
{"namespace": "linspline.integrate", "completion": "  dt = jnp.diff(t)\n  return jnp.sum((w[Ellipsis, :-1] + w[Ellipsis, 1:]) * dt / 2, axis=-1)"}
{"namespace": "linspline.integrate", "completion": "  dt = jnp.diff(t)\n  return jnp.sum(0.5 * (w[Ellipsis, :-1] + w[Ellipsis, 1:]) * dt)"}
{"namespace": "linspline.integrate", "completion": "  dt = jnp.diff(t)\n  integral = jnp.sum((w[Ellipsis, :-1] + w[Ellipsis, 1:]) * dt, axis=-1) / 2\n  return integral"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  dt = jnp.diff(t)\n  integral = jnp.sum(0.5 * dt * (w[Ellipsis, :-1] + w[Ellipsis, 1:]))\n  return integral"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  dt = jnp.diff(t)\n  integral = jnp.sum((w[Ellipsis, :-1] + w[Ellipsis, 1:]) * dt, axis=-1) / 2\n  return integral"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  dt = jnp.diff(t)\n  return jnp.sum(0.5 * dt * (w[Ellipsis, :-1] + w[Ellipsis, 1:]), axis=-1)"}
{"namespace": "linspline.integrate", "completion": "  dt = jnp.diff(t)\n  return jnp.sum((w[Ellipsis, :-1] + w[Ellipsis, 1:]) * dt / 2)"}
{"namespace": "linspline.query", "completion": "  utils.assert_valid_linspline(t, v)\n  idx0, idx1 = sorted_lookup(tq, t)\n  t0 = jnp.take_along_axis(t, idx0, axis=-1)\n  t1 = jnp.take_along_axis(t, idx1, axis=-1)\n  v0 = jnp.take_along_axis(v, idx0, axis=-1)\n  v1 = jnp.take_along_axis(v, idx1, axis=-1)\n  slope = (v1 - v0) / (t1 - t0)\n  interpolated_values = v0 + slope * (tq - t0)\n  return jnp.where((tq < t[0]) | (tq > t[-1]), 0, interpolated_values)"}
{"namespace": "linspline.query", "completion": "  utils.assert_valid_linspline(t, v)\n\n  # Clip to valid inputs (assumes repeating boundaries).\n  tq = jnp.clip(tq, t[Ellipsis, :1], math.minus_eps(t[Ellipsis, -1:]))\n\n  # Lookup the values corresponding to each input query.\n  idx0, idx1 = sorted_lookup(tq, t)\n  t0 = jnp.take_along_axis(t, idx0, axis=-1)\n  t1 = jnp.take_along_axis(t, idx1, axis=-1)\n  v0 = jnp.take_along_axis(v, idx0, axis=-1)\n  v1 = jnp.take_along_axis(v, idx1, axis=-1)\n\n  # Linearly interpolate between the values at t0 and t1.\n  slope = (v1 - v0) / (t1 - t0)\n  interpolated_values = v0 + slope * (tq - t0)\n  return jnp.where((tq < t[Ellipsis, 0]) | (tq > t[Ellipsis, -1]), 0, interpolated_values)"}
{"namespace": "linspline.query", "completion": "  utils.assert_valid_linspline(t, v)\n  idx0, idx1 = sorted_lookup(tq, t)\n  t0 = jnp.take_along_axis(t, idx0, axis=-1)\n  t1 = jnp.take_along_axis(t, idx1, axis=-1)\n  v0 = jnp.take_along_axis(v, idx0, axis=-1)\n  v1 = jnp.take_along_axis(v, idx1, axis=-1)\n  slope = (v1 - v0) / (t1 - t0)\n  result = v0 + slope * (tq - t0)\n  result = jnp.where(tq < t0, 0, jnp.where(tq > t1, 0, result))\n  return result"}
{"namespace": "linspline.query", "completion": "  utils.assert_valid_linspline(t, v)\n  idx0, idx1 = sorted_lookup(tq, t)\n  t0 = jnp.take_along_axis(t, idx0, axis=-1)\n  t1 = jnp.take_along_axis(t, idx1, axis=-1)\n  v0 = jnp.take_along_axis(v, idx0, axis=-1)\n  v1 = jnp.take_along_axis(v, idx1, axis=-1)\n  slope = (v1 - v0) / (t1 - t0)\n  return v0 + slope * (tq - t0)"}
{"namespace": "linspline.query", "completion": "  utils.assert_valid_linspline(t, v)\n  idx0, idx1 = sorted_lookup(tq, t)\n  t0 = jnp.take_along_axis(t, idx0, axis=-1)\n  t1 = jnp.take_along_axis(t, idx1, axis=-1)\n  v0 = jnp.take_along_axis(v, idx0, axis=-1)\n  v1 = jnp.take_along_axis(v, idx1, axis=-1)\n  slope = (v1 - v0) / (t1 - t0)\n  interpolated_values = v0 + slope * (tq - t0)\n  return jnp.where((tq < t[0]) | (tq > t[-1]), 0, interpolated_values)"}
{"namespace": "linspline.query", "completion": "  utils.assert_valid_linspline(t, v)\n  idx0, idx1 = sorted_lookup(tq, t)\n  t0 = jnp.take_along_axis(t, idx0, axis=-1)\n  t1 = jnp.take_along_axis(t, idx1, axis=-1)\n  v0 = jnp.take_along_axis(v, idx0, axis=-1)\n  v1 = jnp.take_along_axis(v, idx1, axis=-1)\n  slope = (v1 - v0) / (t1 - t0)\n  interpolated_values = v0 + slope * (tq - t0)\n  return jnp.where((tq < t[0]) | (tq > t[-1]), 0, interpolated_values)"}
{"namespace": "linspline.query", "completion": "  utils.assert_valid_linspline(t, v)\n\n  # Clip to valid inputs (assumes repeating boundaries).\n  tq = jnp.clip(tq, t[Ellipsis, :1], math.minus_eps(t[Ellipsis, -1:]))\n\n  # Lookup the spline values corresponding to each input query.\n  idx0, idx1 = sorted_lookup(tq, t)\n  t0 = jnp.take_along_axis(t, idx0, axis=-1)\n  t1 = jnp.take_along_axis(t, idx1, axis=-1)\n  v0 = jnp.take_along_axis(v, idx0, axis=-1)\n  v1 = jnp.take_along_axis(v, idx1, axis=-1)\n\n  # Linearly interpolate between the nearest knot points.\n  slope = (v1 - v0) / (t1 - t0)\n  interpolated_values = v0 + slope * (tq - t0)\n  return jnp.where((tq < t[Ellipsis, :1]) | (tq > t[Ellipsis, -1]), 0, interpolated_values)"}
{"namespace": "linspline.query", "completion": "  utils.assert_valid_linspline(t, v)\n  idx0, idx1 = sorted_lookup(tq, t)\n  t0 = jnp.take_along_axis(t, idx0, axis=-1)\n  t1 = jnp.take_along_axis(t, idx1, axis=-1)\n  v0 = jnp.take_along_axis(v, idx0, axis=-1)\n  v1 = jnp.take_along_axis(v, idx1, axis=-1)\n  slope = (v1 - v0) / (t1 - t0)\n  interpolated_values = v0 + slope * (tq - t0)\n  return jnp.where((tq < t[0]) | (tq > t[-1]), 0, interpolated_values)"}
{"namespace": "linspline.query", "completion": "  utils.assert_valid_linspline(t, v)\n  # Clip to valid inputs (assumes repeating boundaries).\n  tq = jnp.clip(tq, t[Ellipsis, :1], math.minus_eps(t[Ellipsis, -1:]))\n  idx0, idx1 = sorted_lookup(tq, t)\n  t0 = jnp.take_along_axis(t, idx0, axis=-1)\n  t1 = jnp.take_along_axis(t, idx1, axis=-1)\n  v0 = jnp.take_along_axis(v, idx0, axis=-1)\n  v1 = jnp.take_along_axis(v, idx1, axis=-1)\n  slope = (v1 - v0) / (t1 - t0)\n  value = v0 + slope * (tq - t0)\n  return jnp.where((tq < t[Ellipsis, 0]) | (tq > t[Ellipsis, -1]), 0, value)"}
{"namespace": "linspline.query", "completion": "  utils.assert_valid_linspline(t, v)\n  idx0, idx1 = sorted_lookup(tq, t)\n  t0 = jnp.take_along_axis(t, idx0, axis=-1)\n  t1 = jnp.take_along_axis(t, idx1, axis=-1)\n  v0 = jnp.take_along_axis(v, idx0, axis=-1)\n  v1 = jnp.take_along_axis(v, idx1, axis=-1)\n  slope = (v1 - v0) / (t1 - t0)\n  return v0 + slope * (tq - t0)"}
{"namespace": "linspline.query", "completion": "  utils.assert_valid_linspline(t, v)\n  idx0, idx1 = sorted_lookup(tq, t)\n  t0 = jnp.take_along_axis(t, idx0, axis=-1)\n  t1 = jnp.take_along_axis(t, idx1, axis=-1)\n  v0 = jnp.take_along_axis(v, idx0, axis=-1)\n  v1 = jnp.take_along_axis(v, idx1, axis=-1)\n  slope = (v1 - v0) / (t1 - t0)\n  interpolated_values = v0 + slope * (tq - t0)\n  return jnp.where((tq < t[0]) | (tq > t[-1]), 0, interpolated_values)"}
{"namespace": "linspline.query", "completion": "  utils.assert_valid_linspline(t, v)\n  idx0, idx1 = sorted_lookup(tq, t)\n  t0 = jnp.take_along_axis(t, idx0, axis=-1)\n  t1 = jnp.take_along_axis(t, idx1, axis=-1)\n  v0 = jnp.take_along_axis(v, idx0, axis=-1)\n  v1 = jnp.take_along_axis(v, idx1, axis=-1)\n  slope = (v1 - v0) / (t1 - t0)\n  interpolated_values = v0 + slope * (tq - t0)\n  return jnp.where((tq < t[0]) | (tq > t[-1]), 0, interpolated_values)"}
{"namespace": "linspline.query", "completion": "  utils.assert_valid_linspline(t, v)\n\n  # Clip to valid inputs (assumes repeating boundaries).\n  tq = jnp.clip(tq, t[Ellipsis, :1], math.minus_eps(t[Ellipsis, -1:]))\n\n  # Lookup the linear coefficients corresponding to each input query.\n  idx0, idx1 = sorted_lookup(tq, t)\n  t0 = jnp.take_along_axis(t, idx0, axis=-1)\n  t1 = jnp.take_along_axis(t, idx1, axis=-1)\n  v0 = jnp.take_along_axis(v, idx0, axis=-1)\n  v1 = jnp.take_along_axis(v, idx1, axis=-1)\n\n  # Linear interpolation between the two nearest time points.\n  w = (t1 - tq) / (t1 - t0)\n  return w * v0 + (1 - w) * v1"}
{"namespace": "linspline.query", "completion": "  utils.assert_valid_linspline(t, v)\n  idx0, idx1 = sorted_lookup(tq, t)\n  t0 = jnp.take_along_axis(t, idx0, axis=-1)\n  t1 = jnp.take_along_axis(t, idx1, axis=-1)\n  v0 = jnp.take_along_axis(v, idx0, axis=-1)\n  v1 = jnp.take_along_axis(v, idx1, axis=-1)\n  slope = (v1 - v0) / jnp.maximum(math.plus_eps(t1 - t0), jnp.finfo(jnp.float32).eps)\n  return v0 + slope * (tq - t0)"}
{"namespace": "linspline.query", "completion": "  utils.assert_valid_linspline(t, v)\n\n  # Clip to valid inputs (assumes repeating boundaries).\n  tq = jnp.clip(tq, t[Ellipsis, :1], math.minus_eps(t[Ellipsis, -1:]))\n\n  # Lookup the spline values corresponding to each input query.\n  idx0, idx1 = sorted_lookup(tq, t)\n  t0 = jnp.take_along_axis(t, idx0, axis=-1)\n  t1 = jnp.take_along_axis(t, idx1, axis=-1)\n  v0 = jnp.take_along_axis(v, idx0, axis=-1)\n  v1 = jnp.take_along_axis(v, idx1, axis=-1)\n\n  # Linearly interpolate between the spline values.\n  slope = (v1 - v0) / (t1 - t0)\n  interpolated_values = v0 + slope * (tq - t0)\n\n  # Set extrapolated values to 0 outside the original range.\n  extrapolated_values = jnp.where((tq < t[Ellipsis, 0]) | (tq > t[Ellipsis, -1]), 0, interpolated_values)\n\n  return extrapolated_values"}
{"namespace": "linspline.query", "completion": "  utils.assert_valid_linspline(t, v)\n  idx0, idx1 = sorted_lookup(tq, t)\n  t0 = jnp.take_along_axis(t, idx0, axis=-1)\n  t1 = jnp.take_along_axis(t, idx1, axis=-1)\n  v0 = jnp.take_along_axis(v, idx0, axis=-1)\n  v1 = jnp.take_along_axis(v, idx1, axis=-1)\n  slope = (v1 - v0) / (t1 - t0)\n  interpolated_values = v0 + slope * (tq - t0)\n  return jnp.where((tq < t[0]) | (tq > t[-1]), 0, interpolated_values)"}
{"namespace": "linspline.query", "completion": "  utils.assert_valid_linspline(t, v)\n  # Clip to valid inputs (assumes repeating boundaries).\n  tq = jnp.clip(tq, t[Ellipsis, :1], math.minus_eps(t[Ellipsis, -1:]))\n  # Lookup the values corresponding to each input query.\n  idx0, idx1 = sorted_lookup(tq, t)\n  v0 = jnp.take_along_axis(v, idx0, axis=-1)\n  v1 = jnp.take_along_axis(v, idx1, axis=-1)\n  # Linearly interpolate between the values.\n  t0 = jnp.take_along_axis(t, idx0, axis=-1)\n  t1 = jnp.take_along_axis(t, idx1, axis=-1)\n  vt = v0 + (v1 - v0) * (tq - t0) / (t1 - t0)\n  return vt"}
{"namespace": "linspline.query", "completion": "  utils.assert_valid_linspline(t, v)\n\n  # Clip to valid inputs (assumes repeating boundaries).\n  tq = jnp.clip(tq, t[Ellipsis, :1], math.minus_eps(t[Ellipsis, -1:]))\n\n  # Lookup the values corresponding to each input query.\n  idx0, idx1 = sorted_lookup(tq, t)\n  t0 = jnp.take_along_axis(t, idx0, axis=-1)\n  t1 = jnp.take_along_axis(t, idx1, axis=-1)\n  v0 = jnp.take_along_axis(v, idx0, axis=-1)\n  v1 = jnp.take_along_axis(v, idx1, axis=-1)\n\n  # Linear interpolation between the values at t0 and t1.\n  slope = (v1 - v0) / (t1 - t0)\n  interpolated_values = v0 + slope * (tq - t0)\n  return interpolated_values"}
{"namespace": "linspline.query", "completion": "  utils.assert_valid_linspline(t, v)\n\n  # Clip to valid inputs (assumes repeating boundaries).\n  tq = jnp.clip(tq, t[Ellipsis, :1], math.minus_eps(t[Ellipsis, -1:]))\n\n  # Lookup the spline values corresponding to each input query.\n  idx0, idx1 = sorted_lookup(tq, t)\n  t0 = jnp.take_along_axis(t, idx0, axis=-1)\n  t1 = jnp.take_along_axis(t, idx1, axis=-1)\n  v0 = jnp.take_along_axis(v, idx0, axis=-1)\n  v1 = jnp.take_along_axis(v, idx1, axis=-1)\n\n  # Linearly interpolate between the nearest knot values.\n  t_diff = t1 - t0\n  v_diff = v1 - v0\n  slope = v_diff / jnp.maximum(eps, t_diff)\n  interpolated_values = v0 + slope * (tq - t0)\n  return jnp.where((tq < t[Ellipsis, 0]) | (tq > t[Ellipsis, -1]), 0, interpolated_values)"}
{"namespace": "linspline.query", "completion": "  utils.assert_valid_linspline(t, v)\n\n  # Clip to valid inputs (assumes repeating boundaries).\n  tq = jnp.clip(tq, t[Ellipsis, :1], math.minus_eps(t[Ellipsis, -1:]))\n\n  # Lookup the values corresponding to each input query.\n  idx0, _ = sorted_lookup(tq, t)\n  v0 = jnp.take_along_axis(v, idx0, axis=-1)\n  v1 = jnp.take_along_axis(v, idx0 + 1, axis=-1)\n\n  # Linear interpolation between the values at the two nearest time points.\n  t0 = jnp.take_along_axis(t, idx0, axis=-1)\n  t1 = jnp.take_along_axis(t, idx0 + 1, axis=-1)\n  w1 = (tq - t0) / (t1 - t0)\n  w0 = 1.0 - w1\n  return w0 * v0 + w1 * v1"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-10  # Small epsilon to account for numerical precision\n  normalized_dir1 = spin_math.normalize(dir1)  # Normalize the direction vector of the first line\n  normalized_dir2 = spin_math.normalize(dir2)  # Normalize the direction vector of the second line\n  dot_product = jnp.dot(normalized_dir1, normalized_dir2)  # Compute the dot product of the normalized direction vectors\n  return jnp.abs(dot_product - 1) < epsilon  # Return True if the absolute difference between the dot product and 1 is less than epsilon, indicating parallel lines"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-6  # Small epsilon to account for numerical precision issues\n  normalized_dir1 = spin_math.normalize(dir1)  # Normalize the direction vector of the first line\n  normalized_dir2 = spin_math.normalize(dir2)  # Normalize the direction vector of the second line\n  dot_product = jnp.dot(normalized_dir1, normalized_dir2)  # Calculate the dot product of the normalized direction vectors\n  return jnp.abs(dot_product - 1) < epsilon  # Return True if the dot product is close to 1 (considering numerical precision), otherwise False"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-6  # Small epsilon to account for numerical precision issues\n  dir1_normalized = spin_math.normalize(dir1)  # Normalize the direction vector of the first line\n  dir2_normalized = spin_math.normalize(dir2)  # Normalize the direction vector of the second line\n  dot_product = jnp.dot(dir1_normalized, dir2_normalized)  # Compute the dot product of the normalized direction vectors\n  return jnp.abs(dot_product - 1) < epsilon  # Return True if the dot product is close to 1, indicating parallel lines, otherwise False"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-6  # Small epsilon to account for numerical precision\n  normalized_dir1 = spin_math.normalize(dir1)\n  normalized_dir2 = spin_math.normalize(dir2)\n  dot_product = jnp.dot(normalized_dir1, normalized_dir2)\n  return jnp.abs(dot_product - 1) < epsilon"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-6  # Small epsilon to account for numerical precision issues\n  dir1_normalized = spin_math.normalize(dir1)  # Normalize the direction vector of the first line\n  dir2_normalized = spin_math.normalize(dir2)  # Normalize the direction vector of the second line\n  dot_product = jnp.dot(dir1_normalized, dir2_normalized)  # Calculate the dot product of the normalized direction vectors\n  return jnp.abs(dot_product - 1) < epsilon  # Return True if the dot product is close to 1 (considering numerical precision), otherwise False"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-6  # Small epsilon to account for numerical precision\n  dir1 = spin_math.normalize(dir1)  # Normalize the direction vector of the first line\n  dir2 = spin_math.normalize(dir2)  # Normalize the direction vector of the second line\n  dot_product = jnp.dot(dir1, dir2)  # Calculate the dot product of the normalized direction vectors\n  return jnp.abs(dot_product - 1) < epsilon  # Return True if the dot product is close to 1 (considering epsilon), indicating parallel lines, otherwise False"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-6  # Small epsilon to account for numerical precision issues\n  dir1_normalized = spin_math.normalize(dir1)  # Normalize the direction vector of the first line\n  dir2_normalized = spin_math.normalize(dir2)  # Normalize the direction vector of the second line\n  dot_product = jnp.dot(dir1_normalized, dir2_normalized)  # Calculate the dot product of the normalized direction vectors\n  return jnp.abs(dot_product - 1) < epsilon  # Return True if the dot product is close to 1, indicating parallel lines, otherwise False"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-6  # Small epsilon to account for numerical precision\n  dir1 = spin_math.normalize(dir1)  # Normalize the direction vector of the first line\n  dir2 = spin_math.normalize(dir2)  # Normalize the direction vector of the second line\n  dot_product = jnp.dot(dir1, dir2)  # Compute the dot product of the normalized direction vectors\n  return jnp.abs(dot_product - 1) < epsilon  # Check if the absolute difference from 1 is less than epsilon"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-6  # Small epsilon to account for numerical precision\n  normalized_dir1 = spin_math.normalize(dir1)  # Normalize the direction vector of the first line\n  normalized_dir2 = spin_math.normalize(dir2)  # Normalize the direction vector of the second line\n  dot_product = jnp.dot(normalized_dir1, normalized_dir2)  # Compute the dot product of the normalized direction vectors\n  return jnp.abs(dot_product - 1) < epsilon  # Return True if the dot product is close to 1, indicating parallel lines, otherwise False"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-10  # Small epsilon to account for numerical precision issues\n  normalized_dir1 = spin_math.normalize(dir1)\n  normalized_dir2 = spin_math.normalize(dir2)\n  dot_product = jnp.dot(normalized_dir1, normalized_dir2)\n  return jnp.abs(dot_product - 1) < epsilon  # Return True if the dot product is close to 1, indicating parallel lines"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-6  # Small epsilon to account for numerical precision\n  normalized_dir1 = spin_math.normalize(dir1)\n  normalized_dir2 = spin_math.normalize(dir2)\n  dot_product = jnp.dot(normalized_dir1, normalized_dir2)\n  return jnp.abs(dot_product - 1) < epsilon  # Lines are considered parallel if dot product is close to 1"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-6  # Small epsilon to account for numerical precision\n  dir1_normalized = spin_math.normalize(dir1)  # Normalize the direction vector of the first line\n  dir2_normalized = spin_math.normalize(dir2)  # Normalize the direction vector of the second line\n  dot_product = jnp.dot(dir1_normalized, dir2_normalized)  # Compute the dot product of the normalized direction vectors\n  return jnp.abs(dot_product - 1) < epsilon  # Return True if the absolute difference is less than epsilon, indicating parallel lines"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-6  # Small epsilon to account for numerical precision issues\n  normalized_dir1 = spin_math.normalize(dir1)\n  normalized_dir2 = spin_math.normalize(dir2)\n  dot_product = jnp.dot(normalized_dir1, normalized_dir2)\n  return jnp.abs(dot_product - 1) < epsilon  # Check if the dot product is close to 1 within the epsilon"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-6  # Small epsilon to account for numerical precision issues\n  dir1 = spin_math.normalize(dir1)  # Normalize the direction vector of the first line\n  dir2 = spin_math.normalize(dir2)  # Normalize the direction vector of the second line\n  dot_product = jnp.dot(dir1, dir2)  # Calculate the dot product of the normalized direction vectors\n  return jnp.abs(dot_product - 1) < epsilon  # Return True if the dot product is close to 1, indicating parallel lines, otherwise False"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-8  # Small epsilon to account for numerical precision\n  normalized_dir1 = spin_math.normalize(dir1)\n  normalized_dir2 = spin_math.normalize(dir2)\n  dot_product = jnp.dot(normalized_dir1, normalized_dir2)\n  return jnp.abs(dot_product - 1) < epsilon  # Lines are parallel if dot product is close to 1"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-6  # Small epsilon to account for numerical precision\n  dir1_normalized = spin_math.normalize(dir1)  # Normalize the direction vector of the first line\n  dir2_normalized = spin_math.normalize(dir2)  # Normalize the direction vector of the second line\n  dot_product = jnp.dot(dir1_normalized, dir2_normalized)  # Compute the dot product of the normalized direction vectors\n  return jnp.abs(dot_product - 1) < epsilon  # Return True if the dot product is close to 1, indicating parallel lines, otherwise False"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-8\n  normalized_dir1 = spin_math.normalize(dir1)\n  normalized_dir2 = spin_math.normalize(dir2)\n  dot_product = jnp.dot(normalized_dir1, normalized_dir2)\n  return jnp.abs(dot_product - 1) < epsilon"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-10  # Small epsilon to account for numerical precision\n  dir1_normalized = spin_math.normalize(dir1)  # Normalize the direction vector of the first line\n  dir2_normalized = spin_math.normalize(dir2)  # Normalize the direction vector of the second line\n  dot_product = jnp.dot(dir1_normalized, dir2_normalized)  # Compute the dot product of the normalized direction vectors\n  return jnp.abs(dot_product - 1) < epsilon  # Check if the absolute difference between the dot product and 1 is less than epsilon"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-6  # Small epsilon to account for numerical precision\n  dir1_normalized = spin_math.normalize(dir1)\n  dir2_normalized = spin_math.normalize(dir2)\n  dot_product = jnp.dot(dir1_normalized, dir2_normalized)\n  return jnp.abs(dot_product - 1) < epsilon  # Check if the dot product is close to 1 within the epsilon"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-8  # Small epsilon to account for numerical precision\n  dir1 = spin_math.normalize(dir1)  # Normalize the direction vector of the first line\n  dir2 = spin_math.normalize(dir2)  # Normalize the direction vector of the second line\n  dot_product = jnp.dot(dir1, dir2)  # Compute the dot product of the normalized direction vectors\n  return jnp.abs(dot_product - 1) < epsilon  # Return True if the dot product is close to 1, indicating parallel lines, otherwise False"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)  # pytype: disable=bad-return-type  # jax-ndarray"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)  # pytype: disable=wrong-arg-types  # jax-ndarray"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack((x, y, z), axis=-1)"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)  # pytype: disable=bad-return-type  # jax-ndarray"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)  # pytype: disable=bad-return-type  # jax-ndarray"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack((x, y, z), axis=-1)"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)  # pytype: disable=bad-return-type  # jax-ndarray"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)  # pytype: disable=bad-return-type  # jax-ndarray"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)  # pytype: disable=bad-return-type  # jax-ndarray"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)  # pytype: disable=bad-return-type  # jax-ndarray"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)  # pytype: disable=bad-return-type  # jax-ndarray"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)  # pytype: disable=wrong-arg-types  # jax-ndarray"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)  # pytype: disable=bad-return-type  # jax-ndarray"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)  # pytype: disable=wrong-arg-types  # jax-ndarray"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if v < 1:\n    raise ValueError(f'Tessellation factor v must be >= 1, got {v}')\n  if v == 1:\n    return np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n\n  # Generate integer weights for each vertex of the triangle.\n  weights = np.array([[v - i, i] for i in range(v + 1)])\n\n  # Normalize the weights to get the barycentric coordinates.\n  weights = weights / v\n\n  return weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if v < 1:\n    raise ValueError(f'Tessellation factor v must be >= 1, got {v}')\n  if v == 1:\n    return np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n\n  tri_weights = []\n  for i in range(v + 1):\n    for j in range(v + 1 - i):\n      tri_weights.append([i, j, v - i - j])\n  tri_weights = np.array(tri_weights, dtype=float)\n  tri_weights /= v\n\n  return tri_weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if v < 1:\n    raise ValueError(f'Tessellation factor v must be >= 1, got {v}')\n  if v == 1:\n    return np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n\n  weights = []\n  for i in range(v + 1):\n    for j in range(v - i + 1):\n      weights.append([i, j, v - i - j])\n  weights = np.array(weights)\n  weights = weights / v\n\n  return weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if not isinstance(v, int) or v < 1:\n    raise ValueError(f'v {v} must be an integer greater than or equal to 1')\n\n  if v == 1:\n    return np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n\n  weights = []\n  for i in range(v + 1):\n    for j in range(v + 1 - i):\n      weights.append([i, j, v - i - j])\n  weights = np.array(weights) / v\n\n  return weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if v < 1:\n    raise ValueError(f'Tessellation factor v={v} must be >= 1')\n  if v == 1:\n    return np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n\n  # Generate integer weights for each vertex of the triangle.\n  weights = np.array([[v - i, i, 0] for i in range(v + 1)])\n\n  # Normalize the weights to get the barycentric coordinates.\n  weights = weights / v\n\n  return weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if v < 1:\n    raise ValueError(f'Tessellation factor v must be >= 1, got {v}')\n\n  # Generate all the integer weights for the triangle.\n  weights = np.array([[i, j, v - i - j] for i in range(v + 1) for j in range(v + 1 - i)])\n\n  # Normalize the weights to get the barycentric coordinates.\n  weights = weights / v\n\n  return weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if not isinstance(v, int) or v < 1:\n    raise ValueError(f'v {v} must be an integer greater than or equal to 1')\n\n  weights = []\n  for i in range(v + 1):\n    for j in range(v - i + 1):\n      weights.append([i, j, v - i - j])\n  weights = np.array(weights) / v\n\n  return weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if v < 1:\n    raise ValueError(f'Tessellation factor v must be greater than or equal to 1, got {v}')\n  \n  weights = []\n  for i in range(v + 1):\n    for j in range(v - i + 1):\n      weights.append([i, j, v - i - j])\n  \n  weights = np.array(weights)\n  weights = weights / v\n  \n  return weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if v < 1:\n    raise ValueError(\"Tessellation factor must be greater than or equal to 1\")\n  \n  # Generate the integer weights for each vertex of the triangle\n  weights = np.array([[v - i, i, j] for i in range(v+1) for j in range(v-i+1)])\n  \n  # Normalize the weights to get the barycentric coordinates\n  weights = weights / v\n  \n  return weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if v < 1:\n    raise ValueError(f'Tessellation factor v must be >= 1, got {v}')\n\n  weights = []\n  for i in range(v + 1):\n    for j in range(v - i + 1):\n      weights.append([i, j, v - i - j])\n  weights = np.array(weights) / v\n\n  return weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if not isinstance(v, int) or v < 1:\n    raise ValueError(f'v {v} must be an integer greater than or equal to 1')\n\n  # Generate all combinations of integers i, j, k such that i + j + k = v\n  weights = np.array([[i, j, v - i - j] for i in range(v + 1) for j in range(v - i + 1)])\n\n  # Normalize the weights to get the barycentric coordinates\n  weights = weights / v\n\n  return weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if not isinstance(v, int) or v < 1:\n    raise ValueError(f'v {v} must be an integer greater than or equal to 1')\n\n  weights = []\n  for i in range(v + 1):\n    for j in range(v - i + 1):\n      weights.append([i, j, v - i - j])\n  weights = np.array(weights) / v\n\n  return weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if v < 1:\n    raise ValueError(f'Tessellation factor v must be >= 1, got {v}')\n  if v == 1:\n    return np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n\n  weights = []\n  for i in range(v + 1):\n    for j in range(v + 1 - i):\n      weights.append([i, j, v - i - j])\n  weights = np.array(weights)\n  weights = weights / v\n\n  return weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if not isinstance(v, int) or v < 1:\n    raise ValueError(f'v {v} must be an integer greater than or equal to 1')\n\n  # Create the weights for tessellating the vertices of a triangle\n  weights = []\n  for i in range(v + 1):\n    for j in range(v - i + 1):\n      weights.append([i, j, v - i - j])\n\n  # Normalize the weights to get the barycentric coordinates\n  weights = np.array(weights, dtype=float)\n  weights /= v\n\n  return weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if v < 1:\n    raise ValueError(f'Tessellation factor v {v} must be greater than or equal to 1')\n  \n  # Generate all combinations of weights for the tessellation factor v\n  weights = np.array([[i, j, v - i - j] for i in range(v + 1) for j in range(v - i + 1)])\n  \n  # Normalize the weights to get the barycentric coordinates\n  tri_weights = weights / v\n  \n  return tri_weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if not isinstance(v, int) or v < 1:\n    raise ValueError(f'v {v} must be an integer greater than or equal to 1')\n\n  # Generate all combinations of integer weights that sum to v\n  weights = np.array([[i, j, v - i - j] for i in range(v + 1) for j in range(v - i + 1)])\n\n  # Normalize the weights to get the barycentric coordinates\n  weights = weights / v\n\n  return weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if v < 1:\n    raise ValueError(f'Tessellation factor v must be >= 1, got {v}')\n  if v == 1:\n    return np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n\n  # Generate all combinations of weights for the tessellation factor v\n  weights = np.array([[i, j, v - i - j] for i in range(v + 1) for j in range(v - i + 1)])\n\n  # Normalize the weights to get the barycentric coordinates\n  weights = weights / v\n\n  return weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if v < 1:\n    raise ValueError(f'Tessellation factor v must be greater than or equal to 1, got {v}')\n  \n  weights = []\n  for i in range(v + 1):\n    for j in range(v - i + 1):\n      weights.append([i, j, v - i - j])\n  \n  weights = np.array(weights)\n  weights = weights / v\n\n  return weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if not isinstance(v, int) or v < 1:\n    raise ValueError(f'v {v} must be an integer greater than or equal to 1')\n\n  if v == 1:\n    return np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n\n  weights = []\n  for i in range(v + 1):\n    for j in range(v - i + 1):\n      weights.append([i, j, v - i - j])\n  weights = np.array(weights)\n\n  return weights / v"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if not isinstance(v, int) or v < 1:\n    raise ValueError(f'v {v} must be an integer greater than or equal to 1')\n\n  if v == 1:\n    return np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n\n  # Generate all combinations of weights for the tessellation factor v\n  weights = np.array([[i, j, v - i - j] for i in range(v + 1) for j in range(v - i + 1)])\n\n  # Normalize the weights to get the barycentric coordinates\n  weights = weights / v\n\n  return weights"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n  r = jnp.sqrt(x**2 + y**2 + z**2)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n  r = jnp.sqrt(x**2 + y**2 + z**2)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n  r = jnp.sqrt(x**2 + y**2 + z**2)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n\n  r = jnp.sqrt(x**2 + y**2 + z**2)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n  r = jnp.sqrt(x**2 + y**2 + z**2)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n  r = jnp.sqrt(x**2 + y**2 + z**2)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n  r = jnp.sqrt(x**2 + y**2 + z**2)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n  r = jnp.sqrt(x**2 + y**2 + z**2)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  \"\"\"\n  Converts cartesian coordinates to spherical coordinates using a right-handed coordinate system. It calculates the radius, inclination (theta), and azimuth (phi) of a point given its cartesian coordinates (x, y, z).\n\n  Input-Output Arguments\n  :param cartesian_vector: Array-like, the cartesian coordinates of a point or set of points, expected to have a shape of (..., 3) where the last dimension represents the x, y, and z coordinates.\n  :param eps: Float, a small epsilon value used to prevent division by zero in the calculation of the inclination angle (theta). It defaults to the smallest positive float32 value.\n  :return: Tuple of arrays. The spherical coordinates as a tuple consisting of radius (r), inclination (theta), and azimuth (phi). Each element in the tuple is an array with the same shape as the input array's leading dimensions.\n  \"\"\"\n  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n  r = jnp.sqrt(x**2 + y**2 + z**2)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  \n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  \"\"\"\n  Converts cartesian coordinates to spherical coordinates using a right-handed coordinate system. It calculates the radius, inclination (theta), and azimuth (phi) of a point given its cartesian coordinates (x, y, z).\n\n  Input-Output Arguments\n  :param cartesian_vector: Array-like, the cartesian coordinates of a point or set of points, expected to have a shape of (..., 3) where the last dimension represents the x, y, and z coordinates.\n  :param eps: Float, a small epsilon value used to prevent division by zero in the calculation of the inclination angle (theta). It defaults to the smallest positive float32 value.\n  :return: Tuple of arrays. The spherical coordinates as a tuple consisting of radius (r), inclination (theta), and azimuth (phi). Each element in the tuple is an array with the same shape as the input array's leading dimensions.\n  \"\"\"\n  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n  r = jnp.sqrt(x**2 + y**2 + z**2)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    sq_dist = np.sum(mat0**2, axis=0, keepdims=True) - 2 * np.matmul(mat0.T, mat0)\n    sq_dist = np.maximum(sq_dist, 0)\n  else:\n    sq_dist = np.sum(mat0**2, axis=0, keepdims=True).T - 2 * np.matmul(mat0.T, mat1) + np.sum(mat1**2, axis=0, keepdims=True)\n    sq_dist = np.maximum(sq_dist, 0)\n  return sq_dist"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    sq_dist = np.sum(mat0**2, axis=0, keepdims=True) - 2 * np.matmul(mat0.T, mat0)\n    sq_dist = np.maximum(sq_dist, 0)\n  else:\n    sq_dist = np.sum(mat0**2, axis=0, keepdims=True) - 2 * np.matmul(mat0.T, mat1)\n    sq_dist += np.sum(mat1**2, axis=0, keepdims=True)\n    sq_dist = np.maximum(sq_dist, 0)\n  return sq_dist"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    # Compute pairwise distances within mat0\n    diff = mat0[:, :, np.newaxis] - mat0[:, np.newaxis, :]\n    sq_dist = np.sum(diff ** 2, axis=0)\n  else:\n    # Compute pairwise distances between mat0 and mat1\n    diff = mat0[:, :, np.newaxis] - mat1[:, np.newaxis, :]\n    sq_dist = np.sum(diff ** 2, axis=0)\n\n  # Set negative distances to zero due to numerical errors\n  sq_dist[sq_dist < 0] = 0\n\n  return sq_dist"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    sq_dists = np.sum(mat0**2, axis=0, keepdims=True) - 2 * mat0.T @ mat0\n    sq_dists = np.maximum(sq_dists, 0)\n  else:\n    sq_dists = np.sum(mat0**2, axis=0, keepdims=True).T + np.sum(mat1**2, axis=0, keepdims=True) - 2 * mat0.T @ mat1\n    sq_dists = np.maximum(sq_dists, 0)\n  return sq_dists"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  norm0 = np.sum(mat0**2, axis=0, keepdims=True)\n  norm1 = np.sum(mat1**2, axis=0, keepdims=True)\n  sq_dist = norm0.T + norm1 - 2 * np.dot(mat0.T, mat1)\n  sq_dist = np.maximum(sq_dist, 0)\n  return sq_dist"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  norms0 = np.sum(mat0**2, axis=0, keepdims=True)\n  norms1 = np.sum(mat1**2, axis=0, keepdims=True)\n  sq_dist = norms0.T + norms1 - 2 * np.dot(mat0.T, mat1)\n  sq_dist[sq_dist < 0] = 0\n  return sq_dist"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    sq_dist = np.sum(mat0**2, 0, keepdims=True) - 2 * np.matmul(mat0.T, mat0)\n    sq_dist[sq_dist < 0] = 0  # Ensure compatibility with numerical errors.\n  else:\n    sq_dist = np.sum(mat0**2, 0, keepdims=True) - 2 * np.matmul(mat0.T, mat1)\n    sq_dist += np.sum(mat1**2, 0, keepdims=True)\n    sq_dist[sq_dist < 0] = 0  # Ensure compatibility with numerical errors.\n  return sq_dist"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    sq_diff = np.square(mat0[:, :, np.newaxis] - mat0[:, np.newaxis, :])\n  else:\n    sq_diff = np.square(mat0[:, :, np.newaxis] - mat1[:, np.newaxis, :])\n  sq_dist = np.sum(sq_diff, axis=0)\n  np.maximum(sq_dist, 0, out=sq_dist)  # Set negative distances to zero\n  return sq_dist"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    # Compute pairwise distances within mat0\n    n = mat0.shape[1]\n    sq_dist = np.zeros((n, n))\n    for i in range(n):\n      diff = mat0 - mat0[:, i:i+1]\n      sq_dist[:, i] = np.sum(diff**2, axis=0)\n  else:\n    # Compute pairwise distances between mat0 and mat1\n    n = mat0.shape[1]\n    m = mat1.shape[1]\n    sq_dist = np.zeros((n, m))\n    for i in range(m):\n      diff = mat0 - mat1[:, i:i+1]\n      sq_dist[:, i] = np.sum(diff**2, axis=0)\n\n  # Set negative distances to zero due to numerical errors\n  sq_dist = np.maximum(sq_dist, 0)\n\n  return sq_dist"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    sq_dists = np.sum(mat0**2, axis=0, keepdims=True) - 2 * np.matmul(mat0.T, mat0) + np.sum(mat0**2, axis=0, keepdims=True).T\n    sq_dists[sq_dists < 0] = 0  # Set negative distances to zero\n  else:\n    sq_dists = np.sum(mat0**2, axis=0, keepdims=True).T - 2 * np.matmul(mat0.T, mat1) + np.sum(mat1**2, axis=0, keepdims=True)\n    sq_dists[sq_dists < 0] = 0  # Set negative distances to zero\n  return sq_dists"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    sq_norms = np.sum(mat0**2, axis=0, keepdims=True)\n    sq_dist = sq_norms.T - 2 * np.dot(mat0.T, mat0) + sq_norms\n    sq_dist = np.maximum(sq_dist, 0)\n  else:\n    sq_norms0 = np.sum(mat0**2, axis=0, keepdims=True)\n    sq_norms1 = np.sum(mat1**2, axis=0, keepdims=True)\n    sq_dist = sq_norms0.T - 2 * np.dot(mat0.T, mat1) + sq_norms1\n    sq_dist = np.maximum(sq_dist, 0)\n  return sq_dist"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  norms0 = np.sum(mat0**2, axis=0, keepdims=True)\n  norms1 = np.sum(mat1**2, axis=0, keepdims=True)\n  sq_dist = norms0.T + norms1 - 2 * np.dot(mat0.T, mat1)\n  sq_dist[sq_dist < 0] = 0\n  return sq_dist"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    dist = np.sum(mat0**2, axis=0, keepdims=True) - 2 * np.matmul(mat0.T, mat0)\n    dist = np.maximum(dist, 0)\n  else:\n    dist = np.sum(mat0**2, axis=0, keepdims=True).T - 2 * np.matmul(mat0.T, mat1)\n    dist += np.sum(mat1**2, axis=0, keepdims=True)\n    dist = np.maximum(dist, 0)\n  return dist"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    sq_dists = np.sum(mat0**2, axis=0, keepdims=True) - 2 * np.dot(mat0.T, mat0)\n    sq_dists = np.maximum(sq_dists, 0)\n  else:\n    sq_dists = np.sum(mat0**2, axis=0, keepdims=True).T - 2 * np.dot(mat0.T, mat1) + np.sum(mat1**2, axis=0, keepdims=True)\n    sq_dists = np.maximum(sq_dists, 0)\n  return sq_dists"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    sq_dists = np.sum(mat0**2, axis=0, keepdims=True) - 2 * mat0.T @ mat0\n    sq_dists = np.maximum(sq_dists, 0)  # Set negative distances to zero\n  else:\n    sq_dists = np.sum(mat0**2, axis=0, keepdims=True).T + np.sum(mat1**2, axis=0, keepdims=True) - 2 * mat0.T @ mat1\n    sq_dists = np.maximum(sq_dists, 0)  # Set negative distances to zero\n  return sq_dists"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    sq_dist = np.sum(mat0**2, axis=0, keepdims=True) - 2 * mat0.T @ mat0\n    sq_dist = np.maximum(sq_dist, 0)\n  else:\n    sq_dist = np.sum(mat0**2, axis=0, keepdims=True).T - 2 * mat0.T @ mat1 + np.sum(mat1**2, axis=0, keepdims=True)\n    sq_dist = np.maximum(sq_dist, 0)\n  return sq_dist"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  return np.maximum(\n      np.sum(mat0**2, 0)[:, None] + np.sum(mat1**2, 0)[None, :] - 2 * np.dot(mat0.T, mat1), 0\n  )"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n      mat1 = mat0\n  return np.sum(mat0**2, axis=0, keepdims=True).T + np.sum(mat1**2, axis=0, keepdims=True) - 2 * np.dot(mat0.T, mat1)"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  norms0 = np.sum(mat0**2, axis=0, keepdims=True)\n  norms1 = np.sum(mat1**2, axis=0, keepdims=True)\n  sq_dist = norms0.T + norms1 - 2 * np.dot(mat0.T, mat1)\n  sq_dist[sq_dist < 0] = 0\n  return sq_dist"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    # Compute pairwise distances within mat0\n    diff = mat0[:, :, None] - mat0[:, :, None].T\n    sq_dist = np.sum(diff**2, 1)\n    np.fill_diagonal(sq_dist, 0)\n  else:\n    # Compute pairwise distances between mat0 and mat1\n    diff = mat0[:, :, None] - mat1[:, :, None].T\n    sq_dist = np.sum(diff**2, 1)\n\n  # Ensure compatibility with numerical errors\n  sq_dist[sq_dist < 0] = 0\n  return sq_dist"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(jnp.float32(x), jnp.inf)\n  )"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(jnp.float32(x), jnp.inf)\n  )"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(jnp.float32(x), jnp.inf)\n  )"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(jnp.float32(x), jnp.inf)\n  )"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(jnp.float32(x), jnp.inf))"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(jnp.float32(x), jnp.inf)\n  )"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(jnp.float32(x), jnp.inf)\n  )"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(jnp.float32(x), jnp.inf)\n  )"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(jnp.float32(x), jnp.inf)\n  )"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(jnp.float32(x), jnp.inf)\n  )"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(jnp.float32(x), jnp.inf)\n  )"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(jnp.float32(x), jnp.inf)\n  )"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(jnp.float32(x), jnp.inf)\n  )"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(jnp.float32(x), jnp.inf)\n  )"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(jnp.float32(x), jnp.inf)\n  )"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(jnp.float32(x), jnp.inf)\n  )"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(x < tiny_val, tiny_val, jnp.nextafter(jnp.float32(x), jnp.inf))"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(jnp.float32(x), jnp.inf)\n  )"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(x < tiny_val, tiny_val, jnp.nextafter(jnp.float32(x), jnp.inf))"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(jnp.float32(x), jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, np.nextafter(np.log1p(max_val), np.float32(0))),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, np.nextafter(np.log(max_val), np.float32(0))),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, np.nextafter(np.log1p(max_val), np.float32(0))),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, np.nextafter(np.log(max_val), np.float32(0))),\n  )(x)"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                tensor = decode_jpeg(data)\n                return tensor\n            except RuntimeError:\n                pass\n\n        # Fallback to PIL\n        pil_image = Image.open(io.BytesIO(data))\n        return pil_image"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                tensor = decode_jpeg(data)\n                return tensor\n            except RuntimeError:\n                pass\n        if _PIL_AVAILABLE:\n            pil_image = Image.open(io.BytesIO(data))\n            return pil_image"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        try:\n            if _TORCH_VISION_AVAILABLE:\n                # Try decoding the data as a JPEG using torchvision\n                return decode_jpeg(data)\n        except RuntimeError:\n            pass\n\n        # If decoding using torchvision fails, fall back to using PIL to deserialize the data\n        pil_image = Image.open(io.BytesIO(data))\n\n        if _TORCH_VISION_AVAILABLE:\n            # If torchvision is available, convert the PIL image to a PyTorch tensor before returning\n            return pil_to_tensor(pil_image)\n\n        return pil_image"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                tensor = decode_jpeg(data)\n                return tensor\n            except RuntimeError:\n                pass\n\n        # Fallback to using PIL to deserialize the data\n        pil_image = Image.open(io.BytesIO(data))\n\n        if _TORCH_VISION_AVAILABLE:\n            # Convert PIL image to PyTorch tensor\n            tensor = pil_to_tensor(pil_image)\n            return tensor\n        else:\n            return pil_image"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                tensor = decode_jpeg(data)\n                return tensor\n            except RuntimeError:\n                pass\n\n        # Fallback to using PIL to deserialize the data\n        pil_image = Image.open(io.BytesIO(data))\n        if _TORCH_VISION_AVAILABLE:\n            tensor = pil_to_tensor(pil_image)\n            return tensor\n        else:\n            return pil_image"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        try:\n            if _TORCH_VISION_AVAILABLE:\n                # Try to decode the data as a JPEG using torchvision\n                decoded_image = decode_jpeg(data)\n                return pil_to_tensor(decoded_image)\n        except RuntimeError:\n            pass\n\n        # Fallback to using PIL to deserialize the data\n        pil_image = Image.open(io.BytesIO(data))\n\n        if _TORCH_VISION_AVAILABLE:\n            # Convert the PIL image to a PyTorch tensor\n            return pil_to_tensor(pil_image)\n        else:\n            return pil_image"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                # Attempt to decode the data as a JPEG using torchvision\n                tensor = decode_jpeg(data)\n                return tensor\n            except RuntimeError:\n                pass\n\n        # Fallback to using PIL to deserialize the data\n        pil_image = Image.open(io.BytesIO(data))\n\n        if _TORCH_VISION_AVAILABLE:\n            # Convert the PIL image to a PyTorch tensor\n            tensor = pil_to_tensor(pil_image)\n            return tensor\n        else:\n            return pil_image"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                tensor = decode_jpeg(data)\n                return pil_to_tensor(Image.open(io.BytesIO(data))) if tensor is None else tensor\n            except RuntimeError:\n                return pil_to_tensor(Image.open(io.BytesIO(data)))\n        else:\n            return pil_to_tensor(Image.open(io.BytesIO(data)))"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        try:\n            if _TORCH_VISION_AVAILABLE:\n                # Attempt to decode the data as a JPEG using torchvision\n                jpeg_tensor, _ = decode_jpeg(data)\n                return jpeg_tensor\n        except RuntimeError:\n            pass\n\n        # If decoding using torchvision fails, fall back to using PIL to deserialize the data\n        pil_image = Image.open(io.BytesIO(data))\n\n        if _TORCH_VISION_AVAILABLE:\n            # Convert the PIL image to a PyTorch tensor\n            return pil_to_tensor(pil_image)\n\n        # If torchvision is not available, return the deserialized PIL image\n        return pil_image"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                tensor = decode_jpeg(data)\n                return tensor\n            except RuntimeError:\n                pass\n\n        # Fallback to using PIL to deserialize the data\n        img = Image.open(io.BytesIO(data))\n\n        if _TORCH_VISION_AVAILABLE:\n            return pil_to_tensor(img)\n        else:\n            return img"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                tensor = decode_jpeg(data)\n                return tensor\n            except RuntimeError:\n                # If decoding fails, fall back to using PIL to deserialize the data\n                pass\n        # If torchvision is available, convert the PIL image to a PyTorch tensor before returning\n        if _PIL_AVAILABLE:\n            pil_image = Image.open(io.BytesIO(data))\n            if _TORCH_VISION_AVAILABLE:\n                return pil_to_tensor(pil_image)\n            else:\n                return pil_image\n        else:\n            raise ModuleNotFoundError(\"PIL is required. Run `pip install pillow`\")"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                # Try to decode the data as a JPEG using torchvision\n                image = decode_jpeg(data)\n                return pil_to_tensor(image)\n            except RuntimeError:\n                pass\n\n        # Fallback to using PIL to deserialize the data\n        pil_image = Image.open(io.BytesIO(data))\n\n        if _TORCH_VISION_AVAILABLE:\n            # Convert the PIL image to a PyTorch tensor\n            return pil_to_tensor(pil_image)\n        else:\n            return pil_image"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                # Try to decode the data as a JPEG using torchvision\n                tensor = decode_jpeg(data)\n                return tensor\n            except RuntimeError:\n                pass\n\n        # Fallback to using PIL to deserialize the data\n        pil_image = Image.open(io.BytesIO(data))\n\n        if _TORCH_VISION_AVAILABLE:\n            # Convert the PIL image to a PyTorch tensor\n            tensor = pil_to_tensor(pil_image)\n            return tensor\n        else:\n            return pil_image"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                tensor = decode_jpeg(data)\n                return tensor\n            except RuntimeError:\n                pass\n\n        pil_image = Image.open(io.BytesIO(data))\n        if _TORCH_VISION_AVAILABLE:\n            return pil_to_tensor(pil_image)\n\n        return pil_image"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                # Attempt to decode the data as a JPEG using torchvision\n                tensor = decode_jpeg(data)\n                return tensor\n            except RuntimeError:\n                # If decoding fails, fall back to using PIL to deserialize the data\n                pil_image = Image.open(io.BytesIO(data))\n                return pil_image\n        else:\n            # If torchvision is not available, use PIL to deserialize the data\n            pil_image = Image.open(io.BytesIO(data))\n            return pil_image"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                tensor = decode_jpeg(data)\n                return tensor\n            except RuntimeError:\n                pass\n        if _PIL_AVAILABLE:\n            return PILSerializer.deserialize(data)\n        raise ValueError(\"Unable to deserialize the given data into a JPEG image.\")"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                tensor = decode_jpeg(data)\n                return pil_to_tensor(Image.open(io.BytesIO(data))) if tensor is None else tensor\n            except RuntimeError:\n                return pil_to_tensor(Image.open(io.BytesIO(data)))\n        else:\n            return pil_to_tensor(Image.open(io.BytesIO(data))) if _PIL_AVAILABLE else None"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                # Attempt to decode the data as a JPEG using torchvision\n                tensor = decode_jpeg(data)\n                return tensor\n            except RuntimeError:\n                # If decoding fails, fall back to using PIL to deserialize the data\n                pil_image = Image.open(io.BytesIO(data))\n                return pil_image\n        else:\n            # If torchvision is not available, use PIL to deserialize the data\n            pil_image = Image.open(io.BytesIO(data))\n            return pil_image"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                # Attempt to decode the data as a JPEG using torchvision\n                tensor = decode_jpeg(data)\n                return pil_to_tensor(tensor)\n            except RuntimeError:\n                # If decoding fails, fall back to using PIL to deserialize the data\n                image = Image.open(io.BytesIO(data))\n                return image\n        else:\n            # If torchvision is not available, use PIL to deserialize the data\n            image = Image.open(io.BytesIO(data))\n            return image"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "\n        if _TORCH_VISION_AVAILABLE:\n            try:\n                # Try to decode the data using torchvision\n                decoded_image = decode_jpeg(data)\n                return pil_to_tensor(decoded_image)\n            except RuntimeError:\n                # If decoding fails, fall back to using PIL to deserialize the data\n                return PILSerializer.deserialize(data)\n        else:\n            # If torchvision is not available, use PIL to deserialize the data\n            return PILSerializer.deserialize(data)"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_tensor:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        data = item.numpy().tobytes(order=\"C\")\n        dtype_index = _TORCH_DTYPES_MAPPING[item.dtype]\n        data_type_str = f\"no_header_tensor:{dtype_index}\"\n        return data, data_type_str"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_tensor:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.numpy().tobytes(order=\"C\"), f\"no_header_tensor:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        data = item.numpy().tobytes(order=\"C\")\n        dtype_index = _TORCH_DTYPES_MAPPING[item.dtype]\n        return data, f\"no_header_tensor:{dtype_index}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_tensor:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "    dtype_indice = self._dtype_to_indices[item.dtype]\n    data = [np.uint32(dtype_indice).tobytes()]\n    data.append(np.uint32(len(item.shape)).tobytes())\n    for dim in item.shape:\n        data.append(np.uint32(dim).tobytes())\n    data.append(item.numpy().tobytes(order=\"C\"))\n    return b\"\".join(data), f\"no_header_tensor:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "    pass\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_tensor:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_tensor:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        data = item.numpy().tobytes(order=\"C\")\n        dtype_index = _TORCH_DTYPES_MAPPING[item.dtype]\n        return data, f\"no_header_tensor:{dtype_index}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        data = item.numpy().tobytes(order=\"C\")\n        dtype_index = _TORCH_DTYPES_MAPPING[item.dtype]\n        data_type_string = f\"no_header_tensor:{dtype_index}\"\n        return data, data_type_string"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.numpy().tobytes(order=\"C\"), f\"no_header_tensor:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_tensor:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_tensor:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.numpy().tobytes(order=\"C\"), f\"no_header_tensor:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_tensor:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.numpy().tobytes(order=\"C\"), f\"no_header_tensor:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_tensor:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        data = item.numpy().tobytes(order=\"C\")\n        dtype_index = _TORCH_DTYPES_MAPPING[item.dtype]\n        return data, f\"no_header_tensor:{dtype_index}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        array = np.frombuffer(data, dtype=self._dtype)\n        return torch.from_numpy(array)"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        array = np.frombuffer(data, dtype=self._dtype)\n        return torch.from_numpy(array)"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        array = np.frombuffer(data, dtype=self._dtype)\n        return torch.as_tensor(array)"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        array = np.frombuffer(data, dtype=self._dtype)\n        return torch.from_numpy(array)"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        array = np.frombuffer(data, dtype=self._dtype)\n        return torch.as_tensor(array)"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        array = np.frombuffer(data, dtype=self._dtype)\n        return torch.tensor(array)"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        tensor = torch.frombuffer(data, dtype=self._dtype)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        tensor = torch.frombuffer(data, dtype=self._dtype)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        array = np.frombuffer(data, dtype=self._dtype)\n        return torch.from_numpy(array)"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        array = np.frombuffer(data, dtype=self._dtype)\n        return torch.from_numpy(array)"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        array = np.frombuffer(data, dtype=self._dtype)\n        return torch.from_numpy(array)"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        tensor = torch.frombuffer(data, dtype=self._dtype)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        tensor = torch.frombuffer(data, dtype=self._dtype)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        array = np.frombuffer(data, dtype=self._dtype)\n        return torch.from_numpy(array)"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        dtype = self._dtype\n        return torch.frombuffer(data, dtype=dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        array = torch.frombuffer(data, dtype=self._dtype)\n        return array"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        array = np.frombuffer(data, dtype=self._dtype)\n        return torch.as_tensor(array)"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        array = torch.frombuffer(data, dtype=self._dtype)\n        return array"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        tensor = torch.frombuffer(data, dtype=self._dtype)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        tensor = torch.frombuffer(data, dtype=self._dtype)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        array = np.reshape(array_data, shape)\n        return array"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        return array_data.reshape(shape)"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        return array_data.reshape(shape)"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        return array_data.reshape(shape)"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        array = np.reshape(array_data, shape)\n        return array"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        array = np.reshape(array_data, tuple(shape))\n        return array"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        return array_data.reshape(shape)"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        array = array_data.reshape(shape)\n        return array"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        return array_data.reshape(shape)"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        array = np.reshape(array_data, shape)\n        return array"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array_data = np.frombuffer(data[8 + 4 * shape_size:], dtype=dtype)\n        array = np.reshape(array_data, shape)\n        return array"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        array = np.reshape(array_data, shape)\n        return array"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        array = array_data.reshape(shape)\n        return array"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        return array_data.reshape(shape)"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        return array_data.reshape(tuple(shape))"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        return array_data.reshape(shape)"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        return array_data.reshape(shape)"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        arr_start_idx = 8 + 4 * shape_size\n        arr_end_idx = arr_start_idx + dtype.itemsize * np.prod(shape)\n        arr_data = np.frombuffer(data[arr_start_idx:arr_end_idx], dtype=dtype)\n        return arr_data.reshape(shape)"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        return array_data.reshape(shape)"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        return array_data.reshape(shape)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        dtype = self._dtype\n        return np.frombuffer(data, dtype=dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        dtype = self._dtype\n        return np.frombuffer(data, dtype=dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        dtype = self._dtype\n        return np.frombuffer(data, dtype=dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        dtype = self._dtype\n        return np.frombuffer(data, dtype=dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        dtype = self._dtype\n        return np.frombuffer(data, dtype=dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        dtype = self._dtype\n        return np.frombuffer(data, dtype=dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        dtype = self._dtype\n        return np.frombuffer(data, dtype=dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        dtype = self._dtype\n        return np.frombuffer(data, dtype=dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        dtype = self._dtype\n        return np.frombuffer(data, dtype=dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        dtype = self._dtype\n        return np.frombuffer(data, dtype=dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        dtype = self._dtype\n        return np.frombuffer(data, dtype=dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        dtype = self._dtype\n        return np.frombuffer(data, dtype=dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        dtype = self._dtype\n        return np.frombuffer(data, dtype=dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        dtype = self._dtype\n        return np.frombuffer(data, dtype=dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        dtype = self._dtype\n        return np.frombuffer(data, dtype=dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        dtype: np.dtype = self._dtype\n        return np.frombuffer(data, dtype=dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = _NUMPY_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = _NUMPY_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice: int = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = np.uint32(_NUMPY_DTYPES_MAPPING[item.dtype]).tobytes()\n        shape = np.uint32(len(item.shape)).tobytes()\n        shape_data = b\"\".join([np.uint32(dim).tobytes() for dim in item.shape])\n        array_data = item.tobytes(order=\"C\")\n        return dtype_indice + shape + shape_data + array_data, None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice: int = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = _NUMPY_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = _NUMPY_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice: int = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice: int = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = _NUMPY_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = _NUMPY_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = _NUMPY_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice: int = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = _NUMPY_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = _NUMPY_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = _NUMPY_DTYPES_MAPPING[item.dtype]\n        shape = np.array(item.shape, dtype=np.uint32)\n        serialized_data = dtype_indice.tobytes() + shape.tobytes() + item.tobytes(order=\"C\")\n        return serialized_data, None"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"current_epoch\": self.current_epoch,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"num_samples_yielded\"] = self._num_samples_yielded_streaming\n        else:\n            state[\"num_samples_yielded\"] = self._num_samples_yielded_combined\n\n        if isinstance(self.dataset, CombinedStreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        elif isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        else:\n            raise RuntimeError(\"The provided dataset should be a `StreamingDataset` or a `CombinedStreamingDataset`.\")\n\n        return state"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": self._num_samples_yielded_streaming\n            if isinstance(self.dataset, StreamingDataset)\n            else self._num_samples_yielded_combined,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n\n        if isinstance(self.dataset, CombinedStreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        elif isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n\n        return state"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": self._num_samples_yielded_streaming\n            if isinstance(self.dataset, StreamingDataset)\n            else self._num_samples_yielded_combined,\n            \"latest_worker_idx\": self._latest_worker_idx - 1,\n        }\n\n        if isinstance(self.dataset, CombinedStreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n\n        return state"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"current_epoch\": self.current_epoch,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"num_samples_yielded\"] = self._num_samples_yielded_streaming\n        else:\n            state[\"num_samples_yielded\"] = self._num_samples_yielded_combined\n\n        if isinstance(self.dataset, CombinedStreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        elif isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        else:\n            raise RuntimeError(\"The provided dataset should be a `StreamingDataset` or a `CombinedStreamingDataset`.\")\n\n        return state"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": self._num_samples_yielded_streaming\n            if isinstance(self.dataset, StreamingDataset)\n            else self._num_samples_yielded_combined,\n            \"latest_worker_idx\": self._latest_worker_idx - 1,\n        }\n\n        if isinstance(self.dataset, CombinedStreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n\n        return state"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"current_epoch\": self.current_epoch,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"num_samples_yielded\"] = self._num_samples_yielded_streaming\n        else:\n            state[\"num_samples_yielded\"] = self._num_samples_yielded_combined\n\n        if isinstance(self.dataset, CombinedStreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        elif isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        else:\n            raise RuntimeError(\"The provided dataset should be a `StreamingDataset` or a `CombinedStreamingDataset`.\")\n\n        return state"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"current_epoch\": self.current_epoch,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"num_samples_yielded\"] = self._num_samples_yielded_streaming\n        else:\n            state[\"num_samples_yielded\"] = self._num_samples_yielded_combined\n\n        if isinstance(self.dataset, CombinedStreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        elif isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        else:\n            raise RuntimeError(\"The provided dataset should be a `StreamingDataset` or a `CombinedStreamingDataset`.\")\n\n        return state"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"current_epoch\": self.current_epoch,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"num_samples_yielded\"] = self._num_samples_yielded_streaming\n        else:\n            state[\"num_samples_yielded\"] = self._num_samples_yielded_combined\n\n        if isinstance(self.dataset, CombinedStreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        elif isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        else:\n            raise RuntimeError(\"The provided dataset should be a `StreamingDataset` or a `CombinedStreamingDataset`.\")\n\n        return state"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "\n        state = {\n            \"current_epoch\": self.current_epoch,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"num_samples_yielded\"] = self._num_samples_yielded_streaming\n            state[\"dataset\"] = self.dataset.state_dict()\n        else:\n            state[\"num_samples_yielded\"] = self._num_samples_yielded_combined\n\n        return state"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"current_epoch\": self.current_epoch,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"num_samples_yielded\"] = self._num_samples_yielded_streaming\n        else:\n            state[\"num_samples_yielded\"] = self._num_samples_yielded_combined\n\n        if isinstance(self.dataset, CombinedStreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        elif isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        else:\n            raise RuntimeError(\"The provided dataset should be a `StreamingDataset` or a `CombinedStreamingDataset`.\")\n\n        return state"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": self._num_samples_yielded_streaming\n            if isinstance(self.dataset, StreamingDataset)\n            else self._num_samples_yielded_combined,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n\n        if isinstance(self.dataset, CombinedStreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n\n        return state"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": (\n                self._num_samples_yielded_streaming\n                if isinstance(self.dataset, StreamingDataset)\n                else self._num_samples_yielded_combined\n            ),\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n\n        if isinstance(self.dataset, CombinedStreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        elif isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n\n        return state"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "\n        state_dict = {\n            \"current_epoch\": self.current_epoch,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n\n        if isinstance(self.dataset, StreamingDataset):\n            state_dict[\"num_samples_yielded\"] = self._num_samples_yielded_streaming\n            state_dict[\"dataset\"] = self.dataset.state_dict()\n        else:\n            state_dict[\"num_samples_yielded\"] = self._num_samples_yielded_combined\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": self._num_samples_yielded_streaming\n            if isinstance(self.dataset, StreamingDataset)\n            else self._num_samples_yielded_combined,\n            \"latest_worker_idx\": self._latest_worker_idx - 1,\n        }\n\n        if isinstance(self.dataset, CombinedStreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n\n        return state"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"current_epoch\": self.current_epoch,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"num_samples_yielded\"] = self._num_samples_yielded_streaming\n        else:\n            state[\"num_samples_yielded\"] = self._num_samples_yielded_combined\n\n        if isinstance(self.dataset, CombinedStreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        elif isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        else:\n            raise RuntimeError(\"The provided dataset should be a `StreamingDataset` or a `CombinedStreamingDataset`.\")\n\n        return state"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state_dict = {\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": self._num_samples_yielded_streaming\n            if isinstance(self.dataset, StreamingDataset)\n            else self._num_samples_yielded_combined,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n\n        if isinstance(self.dataset, CombinedStreamingDataset):\n            state_dict[\"dataset\"] = self.dataset.state_dict()\n        elif isinstance(self.dataset, StreamingDataset):\n            state_dict[\"dataset\"] = self.dataset.state_dict()\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"current_epoch\": self.current_epoch,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"num_samples_yielded\"] = self._num_samples_yielded_streaming\n        else:\n            state[\"num_samples_yielded\"] = self._num_samples_yielded_combined\n\n        if isinstance(self.dataset, CombinedStreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        elif isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        else:\n            raise RuntimeError(\"The provided dataset should be a `StreamingDataset` or a `CombinedStreamingDataset`.\")\n\n        return state"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": self._num_samples_yielded_streaming\n            if isinstance(self.dataset, StreamingDataset)\n            else self._num_samples_yielded_combined,\n            \"latest_worker_idx\": self._latest_worker_idx - 1,\n        }\n\n        if isinstance(self.dataset, CombinedStreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        elif isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n\n        return state"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state_dict = {\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": self._num_samples_yielded_streaming\n            if isinstance(self.dataset, StreamingDataset)\n            else self._num_samples_yielded_combined,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n\n        if isinstance(self.dataset, CombinedStreamingDataset):\n            state_dict[\"dataset\"] = self.dataset.state_dict()\n        elif isinstance(self.dataset, StreamingDataset):\n            state_dict[\"dataset\"] = self.dataset.state_dict()\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"current_epoch\": self.current_epoch,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"num_samples_yielded\"] = self._num_samples_yielded_streaming\n        else:\n            state[\"num_samples_yielded\"] = self._num_samples_yielded_combined\n\n        if isinstance(self.dataset, CombinedStreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        elif isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        else:\n            raise RuntimeError(\"The provided dataset should be a `StreamingDataset` or a `CombinedStreamingDataset`.\")\n\n        return state"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE or not _AV_AVAILABLE:\n            raise Exception(\"Required libraries torchvision and av are not installed.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n            temp_file.write(data)\n            temp_file_path = temp_file.name\n\n        try:\n            video, audio, info = torchvision.io.read_video(temp_file_path)\n            return video\n        finally:\n            os.unlink(temp_file_path)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE or not _AV_AVAILABLE:\n            raise Exception(\"torchvision and av libraries are required for deserializing video data.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n            temp_file.write(data)\n            temp_file_path = temp_file.name\n\n        try:\n            video, audio, info = torchvision.io.read_video(temp_file_path, pts_unit=\"sec\")\n            return video\n        finally:\n            os.unlink(temp_file_path)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE or not _AV_AVAILABLE:\n            raise Exception(\"torchvision and av libraries are required for deserializing video data.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n            temp_file.write(data)\n            temp_file_path = temp_file.name\n\n        try:\n            video, audio, info = torchvision.io.read_video(temp_file_path, pts_unit=\"sec\")\n            return video\n        finally:\n            os.unlink(temp_file_path)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE or not _AV_AVAILABLE:\n            raise Exception(\"torchvision and av libraries are required for deserializing video data.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n            temp_file.write(data)\n            temp_file_path = temp_file.name\n\n        try:\n            video, audio, info = torchvision.io.read_video(temp_file_path)\n            return video\n        finally:\n            os.unlink(temp_file_path)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE or not _AV_AVAILABLE:\n            raise Exception(\"torchvision and av libraries are required for deserializing video. Please install them.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n            temp_file.write(data)\n            temp_file_path = temp_file.name\n\n        try:\n            video, audio, info = torchvision.io.read_video(temp_file_path, pts_unit=\"sec\")\n            return video\n        finally:\n            os.remove(temp_file_path)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE or not _AV_AVAILABLE:\n            raise Exception(\"Required libraries torchvision and av are not installed.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n            temp_file.write(data)\n            temp_file_path = temp_file.name\n\n        try:\n            video, audio, info = torchvision.io.read_video(temp_file_path)\n            return video\n        finally:\n            os.unlink(temp_file_path)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE or not _AV_AVAILABLE:\n            raise Exception(\"Torchvision and av libraries are required for deserializing video data.\")\n        \n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_video_file:\n            temp_video_file.write(data)\n            temp_video_file_path = temp_video_file.name\n        \n        try:\n            video_tensor, audio_tensor, info = torchvision.io.read_video(temp_video_file_path)\n            return (video_tensor, audio_tensor, info)\n        finally:\n            os.unlink(temp_video_file_path)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE or not _AV_AVAILABLE:\n            raise Exception(\"torchvision and av libraries are required for deserializing video data.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n            temp_file.write(data)\n            temp_file_path = temp_file.name\n\n        try:\n            video, audio, info = torchvision.io.read_video(temp_file_path)\n            return video\n        finally:\n            os.unlink(temp_file_path)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE or not _AV_AVAILABLE:\n            raise Exception(\"torchvision and av libraries are required for deserializing video data.\")\n        \n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n            temp_file.write(data)\n            temp_file_path = temp_file.name\n\n        try:\n            video, audio, info = torchvision.io.read_video(temp_file_path, pts_unit=\"sec\")\n            return video\n        finally:\n            os.unlink(temp_file_path)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE or not _AV_AVAILABLE:\n            raise Exception(\"torchvision and av libraries are required for deserializing video data.\")\n        \n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n            temp_file.write(data)\n            temp_file_path = temp_file.name\n\n        try:\n            video, audio, info = torchvision.io.read_video(temp_file_path, pts_unit=\"sec\")\n            return video\n        finally:\n            os.unlink(temp_file_path)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE or not _TORCH_VISION_AVAILABLE:\n            raise Exception(\"Required libraries (torchvision and av) are not installed.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n            temp_file.write(data)\n            temp_file_path = temp_file.name\n\n        try:\n            video, audio, info = torchvision.io.read_video(temp_file_path, pts_unit=\"sec\")\n            return video\n        finally:\n            os.unlink(temp_file_path)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE or not _AV_AVAILABLE:\n            raise Exception(\"Torchvision and av libraries are required for deserializing video data.\")\n        \n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n            temp_file.write(data)\n            temp_file_path = temp_file.name\n\n        try:\n            video, audio, info = torchvision.io.read_video(temp_file_path)\n            return video\n        finally:\n            os.unlink(temp_file_path)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE or not _AV_AVAILABLE:\n            raise Exception(\"Torchvision and av libraries are required for deserializing video. Please install them.\")\n        \n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n            temp_file.write(data)\n            temp_file_path = temp_file.name\n\n        try:\n            video, audio, info = torchvision.io.read_video(temp_file_path)\n            return video\n        finally:\n            os.unlink(temp_file_path)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE or not _AV_AVAILABLE:\n            raise Exception(\"Required libraries (torchvision and av) are not installed.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n            temp_file.write(data)\n            temp_file_path = temp_file.name\n\n        try:\n            video, audio, info = torchvision.io.read_video(temp_file_path)\n            return video\n        finally:\n            os.unlink(temp_file_path)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE or not _TORCH_VISION_AVAILABLE:\n            raise Exception(\"Required libraries (torchvision and av) are not installed\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n            temp_file.write(data)\n            temp_file_path = temp_file.name\n\n        try:\n            return torchvision.io.read_video(temp_file_path)\n        finally:\n            os.unlink(temp_file_path)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE or not _TORCH_VISION_AVAILABLE:\n            raise Exception(\"Required libraries (torchvision and av) are not installed.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n            temp_file.write(data)\n            temp_file_path = temp_file.name\n\n        try:\n            video, audio, info = torchvision.io.read_video(temp_file_path)\n            return video\n        finally:\n            os.unlink(temp_file_path)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE or not _AV_AVAILABLE:\n            raise Exception(\"Required libraries torchvision and av are not installed\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n            temp_file.write(data)\n            temp_file_path = temp_file.name\n\n        try:\n            video, audio, info = torchvision.io.read_video(temp_file_path, pts_unit=\"sec\")\n            return video\n        finally:\n            os.unlink(temp_file_path)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE or not _AV_AVAILABLE:\n            raise Exception(\"Required libraries (torchvision and av) are not installed.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n            temp_file.write(data)\n            temp_file_path = temp_file.name\n\n        try:\n            video, audio, info = torchvision.io.read_video(temp_file_path)\n            return video\n        finally:\n            os.unlink(temp_file_path)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE or not _AV_AVAILABLE:\n            raise Exception(\"Required libraries (torchvision and av) are not installed.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n            temp_file.write(data)\n            temp_file_path = temp_file.name\n\n        try:\n            video, audio, info = torchvision.io.read_video(temp_file_path, pts_unit=\"sec\")\n            return video\n        finally:\n            os.unlink(temp_file_path)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise Exception(\"The 'av' library is required for deserializing video data. Please install it using 'pip install av'.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n            temp_file.write(data)\n            temp_file_path = temp_file.name\n\n        video, audio, info = torchvision.io.read_video(temp_file_path)\n\n        os.remove(temp_file_path)\n\n        return video"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while not self.filled:\n            if self._should_write():\n                self.write_chunk()\n        return [self.write_chunks_index()]"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while not self.filled:\n            if self._should_write():\n                self.write_chunk()\n        return [self.write_chunks_index()]\n        self._is_done = True"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while not self.filled:\n            self.write_chunk()\n        file_paths = [self.write_chunks_index()]\n        self._is_done = True\n        return file_paths"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        written_chunks = []\n        while not self.filled:\n            written_chunks.append(self.write_chunk())\n        written_chunks.append(self.write_chunks_index())\n        self._is_done = True\n        return written_chunks"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        written_chunks = []\n        while not self.filled:\n            if self._should_write():\n                written_chunks.append(self.write_chunk())\n        index_file_path = self.write_chunks_index()\n        if index_file_path:\n            written_chunks.append(index_file_path)\n        self._is_done = True\n        return written_chunks"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while not self.filled:\n            self.write_chunk()\n        return [self.write_chunks_index()]"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while not self.filled:\n            if self._should_write():\n                self.write_chunk()\n        return [self.write_chunks_index()]"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        written_chunks = []\n        while not self.filled:\n            if self._should_write():\n                written_chunks.append(self.write_chunk())\n        index_file = self.write_chunks_index()\n        if index_file:\n            written_chunks.append(index_file)\n        self._is_done = True\n        return written_chunks"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while not self.filled:\n            if self._should_write():\n                self.write_chunk()\n        return [self.write_chunks_index()]\n        self._is_done = True"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        file_paths = []\n        while not self.filled:\n            file_paths.append(self.write_chunk())\n        file_paths.append(self.write_chunks_index())\n        self._is_done = True\n        return file_paths"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while not self.filled:\n            if self._should_write():\n                self.write_chunk()\n        return [self.write_chunks_index()]\n        self._is_done = True"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while not self.filled:\n            self.write_chunk()\n        index_file = self.write_chunks_index()\n        self._is_done = True\n        return [index_file]"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        paths = []\n        while not self.filled:\n            if self._should_write():\n                paths.append(self.write_chunk())\n            else:\n                break\n        paths.append(self.write_chunks_index())\n        self._is_done = True\n        return paths"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while not self.filled:\n            if self._should_write():\n                self.write_chunk()\n        return [self.write_chunks_index()]"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "\n        written_chunks = []\n        while not self.filled:\n            if self._should_write():\n                written_chunks.append(self.write_chunk())\n            sleep(0.01)\n\n        if not self._is_done:\n            written_chunks.append(self.write_chunk(on_done=True))\n            written_chunks.append(self.write_chunks_index())\n            self._is_done = True\n\n        return written_chunks"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while not self.filled:\n            if self._should_write():\n                self.write_chunk()\n        return [self.write_chunks_index()]"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while not self.filled:\n            if self._should_write():\n                self.write_chunk()\n        return [self.write_chunks_index()]"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while not self.filled:\n            if self._should_write():\n                self.write_chunk()\n        return [self.write_chunks_index()]"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while not self.filled:\n            if self._should_write():\n                self.write_chunk()\n        file_paths = [self.write_chunks_index()]\n        self._is_done = True\n        return file_paths"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while not self.filled:\n            if self._should_write():\n                self.write_chunk()\n        return [self.write_chunks_index()]"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj['dataset'])\n            self.current_epoch = obj['current_epoch']\n            self._num_samples_yielded_streaming = obj['num_samples_yielded']\n            self._latest_worker_idx = obj['latest_worker_idx']\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj['dataset'])\n            self.current_epoch = obj['current_epoch']\n            self._num_samples_yielded_combined = obj['num_samples_yielded']\n            self._latest_worker_idx = obj['latest_worker_idx']\n        else:\n            raise RuntimeError(\"The dataset associated with the StreamingDataLoader must be either a StreamingDataset or a CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        else:\n            raise RuntimeError(\"The dataset associated with the StreamingDataLoader must be either a StreamingDataset or a CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            for worker_idx, num_samples_yielded in obj[\"num_samples_yielded\"].items():\n                self.dataset.datasets[worker_idx].load_state_dict(\n                    {\n                        \"dataset\": obj[\"dataset\"],\n                        \"current_epoch\": obj[\"current_epoch\"],\n                        \"num_samples_yielded\": num_samples_yielded,\n                        \"latest_worker_idx\": obj[\"latest_worker_idx\"],\n                    }\n                )\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        else:\n            raise RuntimeError(\"The dataset associated with the StreamingDataLoader must be either a StreamingDataset or a CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        else:\n            raise RuntimeError(\"The dataset associated with the StreamingDataLoader must be a StreamingDataset or CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        else:\n            raise RuntimeError(\"The dataset associated with the StreamingDataLoader should be either a StreamingDataset or a CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.restore = True\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.restore = True\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        else:\n            raise RuntimeError(\"The dataset associated with the StreamingDataLoader must be either a StreamingDataset or a CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            for worker_idx, num_samples_yielded in obj[\"num_samples_yielded\"].items():\n                self.dataset.datasets[worker_idx].load_state_dict(\n                    {\n                        \"dataset\": obj[\"dataset\"],\n                        \"current_epoch\": obj[\"current_epoch\"],\n                        \"num_samples_yielded\": num_samples_yielded,\n                        \"latest_worker_idx\": obj[\"latest_worker_idx\"],\n                    }\n                )\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        else:\n            raise RuntimeError(\"The dataset associated with the StreamingDataLoader must be either a StreamingDataset or a CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj['dataset'])\n            self.current_epoch = obj['current_epoch']\n            self._num_samples_yielded_streaming = obj['num_samples_yielded']\n            self._latest_worker_idx = obj['latest_worker_idx']\n            self.restore = True\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj['dataset'])\n            self.current_epoch = obj['current_epoch']\n            self._num_samples_yielded_combined = obj['num_samples_yielded']\n            self._latest_worker_idx = obj['latest_worker_idx']\n            self.restore = True\n        else:\n            raise RuntimeError(\"The dataset associated with the StreamingDataLoader must be either a StreamingDataset or a CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        else:\n            raise RuntimeError(\"Dataset associated with StreamingDataLoader must be either StreamingDataset or CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        else:\n            raise RuntimeError(\"The dataset associated with the StreamingDataLoader is neither a StreamingDataset nor a CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        else:\n            raise RuntimeError(\"Dataset must be either a StreamingDataset or a CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        else:\n            raise RuntimeError(\"Dataset must be either a StreamingDataset or a CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        else:\n            raise RuntimeError(\"The dataset associated with the StreamingDataLoader must be either a StreamingDataset or a CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            for worker_idx in obj[\"num_samples_yielded\"]:\n                self.dataset.datasets[worker_idx].load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        else:\n            raise RuntimeError(\"The dataset associated with the StreamingDataLoader must be either a StreamingDataset or a CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        else:\n            raise RuntimeError(\"Dataset associated with StreamingDataLoader must be a StreamingDataset or CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.restore = True\n            self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n            self._worker_idx_iter = iter(self._worker_idx)\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.current_epoch = obj[\"current_epoch\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.restore = True\n            self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n            self._worker_idx_iter = iter(self._worker_idx)\n            for worker_idx in obj[\"num_samples_yielded\"]:\n                self._num_samples_yielded_combined[worker_idx] = obj[\"num_samples_yielded\"][worker_idx]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        else:\n            raise RuntimeError(\"The dataset associated with the StreamingDataLoader must be either a StreamingDataset or a CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        else:\n            raise RuntimeError(\"Dataset should be either StreamingDataset or CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        else:\n            raise RuntimeError(\"The dataset associated with the StreamingDataLoader must be either a StreamingDataset or a CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        else:\n            raise RuntimeError(\"The dataset associated with the StreamingDataLoader must be either a StreamingDataset or a CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        else:\n            raise RuntimeError(\"The dataset associated with the StreamingDataLoader must be either a StreamingDataset or a CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if self._iterator is not None:\n            return self._iterator.state_dict(num_workers, batch_size)\n\n        return _state_dict(self._datasets, num_samples_yielded, num_workers, batch_size)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "\n        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if self._iterator is not None:\n            return self._iterator.state_dict(num_workers, batch_size)\n\n        return _state_dict(self._datasets, num_samples_yielded, num_workers, batch_size)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "\n        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if self._iterator is not None:\n            return self._iterator.state_dict(num_workers, batch_size)\n\n        return _state_dict(self._datasets, num_samples_yielded, num_workers, batch_size)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if self._iterator is not None:\n            return self._iterator.state_dict(num_workers, batch_size)\n\n        return _state_dict(self._datasets, num_samples_yielded, num_workers, batch_size)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "\n        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if self._iterator is not None:\n            return self._iterator.state_dict(num_workers, batch_size)\n\n        return _state_dict(self._datasets, num_samples_yielded, num_workers, batch_size)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if self._iterator is not None:\n            return self._iterator.state_dict(num_workers, batch_size)\n\n        return _state_dict(self._datasets, num_samples_yielded, num_workers, batch_size)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "\n        if self._iterator is None and num_samples_yielded is None:\n            return {}\n        elif self._iterator is None:\n            return _state_dict(self._datasets, num_samples_yielded, num_workers, batch_size)\n        else:\n            return self._iterator.state_dict(num_workers, batch_size)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if self._iterator is not None:\n            return self._iterator.state_dict(num_workers, batch_size)\n\n        return _state_dict(self._datasets, num_samples_yielded, num_workers, batch_size)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if self._iterator is not None:\n            return self._iterator.state_dict(num_workers, batch_size)\n\n        return _state_dict(self._datasets, num_samples_yielded, num_workers, batch_size)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if self._iterator is not None:\n            return self._iterator.state_dict(num_workers, batch_size)\n\n        return _state_dict(self._datasets, num_samples_yielded, num_workers, batch_size)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "\n        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if self._iterator is not None:\n            return self._iterator.state_dict(num_workers, batch_size)\n\n        return _state_dict(self._datasets, num_samples_yielded, num_workers, batch_size)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "\n        if self._iterator is None and num_samples_yielded is None:\n            return {}\n        elif self._iterator is None:\n            return _state_dict(self._datasets, num_samples_yielded, num_workers, batch_size)\n        else:\n            return self._iterator.state_dict(num_workers, batch_size)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "\n        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if self._iterator is not None:\n            return self._iterator.state_dict(num_workers, batch_size)\n\n        return _state_dict(self._datasets, num_samples_yielded, num_workers, batch_size)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "\n        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if self._iterator is not None:\n            return self._iterator.state_dict(num_workers, batch_size)\n\n        return _state_dict(self._datasets, num_samples_yielded, num_workers, batch_size)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "\n        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if self._iterator is not None:\n            return self._iterator.state_dict(num_workers, batch_size)\n\n        return _state_dict(self._datasets, num_samples_yielded, num_workers, batch_size)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "\n        if self._iterator is None and num_samples_yielded is None:\n            return {}\n        elif self._iterator is not None:\n            return self._iterator.state_dict(num_workers, batch_size)\n        else:\n            return _state_dict(self._datasets, num_samples_yielded, num_workers, batch_size)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "\n        if self._iterator is None and num_samples_yielded is None:\n            return {}\n        elif self._iterator is not None:\n            return self._iterator.state_dict(num_workers, batch_size)\n        else:\n            return _state_dict(self._datasets, num_samples_yielded, num_workers, batch_size)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n        elif self._iterator is not None:\n            return self._iterator.state_dict(num_workers, batch_size)\n        else:\n            return _state_dict(self._datasets, num_samples_yielded, num_workers, batch_size)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if self._iterator is not None:\n            return self._iterator.state_dict(num_workers, batch_size)\n\n        return _state_dict(self._datasets, num_samples_yielded, num_workers, batch_size)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        return _state_dict(self._datasets, self._num_samples_yielded, num_workers, batch_size)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if not isinstance(state_dict, dict):\n            raise TypeError(\"State_dict should be a dictionary.\")\n\n        for dataset_idx, dataset in enumerate(self._datasets):\n            if str(dataset_idx) in state_dict:\n                dataset.load_state_dict(state_dict[str(dataset_idx)])"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        self._num_samples_yielded = state_dict.get(\"__NUM_SAMPLES_YIELDED__\")\n        if self._iterator is not None:\n            self._iterator._num_samples_yielded = self._num_samples_yielded\n        for dataset, dataset_state in zip(self._datasets, state_dict.values()):\n            dataset.load_state_dict(dataset_state)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            return\n        for dataset_idx, dataset_state in state_dict.items():\n            self._datasets[int(dataset_idx)].load_state_dict(dataset_state)\n        self._num_samples_yielded = [dataset_state[\"num_samples_yielded\"] for dataset_state in state_dict.values()]"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            return\n\n        num_workers = len(self._iterator._datasets)\n        batch_size = 1\n        if state_dict:\n            for dataset_idx, dataset_state in state_dict.items():\n                self._iterator._datasets[int(dataset_idx)].load_state_dict(dataset_state)\n                batch_size = dataset_state[\"batch_size\"]\n                num_samples_yielded = dataset_state[\"num_samples_yielded\"]\n                self._iterator._num_samples_yielded[int(dataset_idx)] = num_samples_yielded\n\n        self._iterator._num_samples_yielded = [0 for _ in range(len(self._iterator._datasets))]"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is not None:\n            num_workers = len(state_dict)\n            batch_size = state_dict[\"0\"][\"batch_size\"]  # Assuming all datasets have the same batch size\n            num_samples_yielded = [state_dict[str(i)][\"num_samples_yielded\"] for i in range(len(state_dict))]\n            self._iterator.load_state_dict(num_workers, batch_size, num_samples_yielded)\n        else:\n            self._num_samples_yielded = [state_dict[str(i)][\"num_samples_yielded\"] for i in range(len(state_dict))]"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        for dataset_idx, dataset_state in state_dict.items():\n            self._datasets[int(dataset_idx)].load_state_dict(dataset_state)\n        if __NUM_SAMPLES_YIELDED_KEY__ in state_dict:\n            self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "\n        self._num_samples_yielded = [state_dict[str(i)] for i in range(len(self._datasets))]"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        for dataset_idx, dataset_state in state_dict.items():\n            self._datasets[int(dataset_idx)].load_state_dict(dataset_state)\n        if __NUM_SAMPLES_YIELDED_KEY__ in state_dict:\n            self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is not None:\n            num_samples_yielded = state_dict.get(__NUM_SAMPLES_YIELDED_KEY__)\n            if num_samples_yielded:\n                self._num_samples_yielded = num_samples_yielded"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is not None:\n            num_workers = len(state_dict)\n            batch_size = len(list(state_dict.values())[0]['samples'])\n            num_samples_yielded = [state_dict[str(i)]['num_samples_yielded'] for i in range(len(state_dict))]\n\n            self._iterator.load_state_dict(num_workers, batch_size, num_samples_yielded)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            return\n\n        num_workers = len(state_dict)\n        batch_size = state_dict[\"0\"][\"batch_size\"]  # Assuming all datasets have the same batch size\n\n        for dataset_idx, dataset in enumerate(self._datasets):\n            dataset_state_dict = state_dict[str(dataset_idx)]\n            num_samples_yielded = dataset_state_dict[\"num_samples_yielded\"]\n            dataset.load_state_dict(dataset_state_dict)\n            self._num_samples_yielded[dataset_idx] = num_samples_yielded"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        for dataset_idx, dataset_state in state_dict.items():\n            dataset_idx = int(dataset_idx)\n            self._datasets[dataset_idx].load_state_dict(dataset_state)\n        if __NUM_SAMPLES_YIELDED_KEY__ in state_dict:\n            self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is not None:\n            num_workers = len(state_dict)\n            batch_size = state_dict[\"0\"][\"batch_size\"]  # Assuming all datasets have the same batch size\n            num_samples_yielded = [state_dict[str(i)][\"num_samples_yielded\"] for i in range(len(state_dict))]\n            self._iterator.load_state_dict(num_workers, batch_size, num_samples_yielded)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            return\n        for dataset_idx, dataset_state in state_dict.items():\n            self._datasets[int(dataset_idx)].load_state_dict(dataset_state)\n        self._num_samples_yielded = [dataset_state[\"num_samples_yielded\"] for dataset_state in state_dict.values()]"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is not None:\n            num_workers = len(state_dict)  # Assuming the number of workers is equal to the length of the state_dict\n            batch_size = len(state_dict[\"0\"][\"__SAMPLES__\"])  # Assuming the batch size is equal to the length of the samples in the first dataset\n            num_samples_yielded = [len(state_dict[str(i)][\"__NUM_SAMPLES_YIELDED__\"]) for i in range(len(state_dict))]\n            self._iterator.load_state_dict(state_dict, num_workers, batch_size, num_samples_yielded)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is not None:\n            num_workers = len(state_dict)\n            batch_size = state_dict[\"0\"][\"batch_size\"]  # Assuming all datasets have the same batch size\n            num_samples_yielded = [state_dict[str(i)][\"num_samples_yielded\"] for i in range(len(state_dict))]\n            self._iterator.load_state_dict(num_workers, batch_size, num_samples_yielded)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        for dataset_idx, dataset_state in state_dict.items():\n            dataset_idx = int(dataset_idx)\n            self._datasets[dataset_idx].load_state_dict(dataset_state)\n        if __NUM_SAMPLES_YIELDED_KEY__ in state_dict:\n            self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        for dataset_idx, dataset_state in state_dict.items():\n            self._datasets[int(dataset_idx)].load_state_dict(dataset_state)\n        if __NUM_SAMPLES_YIELDED_KEY__ in state_dict:\n            self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        for dataset_idx, dataset_state in state_dict.items():\n            self._datasets[int(dataset_idx)].load_state_dict(dataset_state)\n        if __NUM_SAMPLES_YIELDED_KEY__ in state_dict:\n            self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        for dataset_idx, dataset_state in state_dict.items():\n            dataset_idx = int(dataset_idx)\n            self._datasets[dataset_idx].load_state_dict(dataset_state)\n            if self._num_samples_yielded is not None:\n                self._num_samples_yielded[dataset_idx] = dataset_state[__NUM_SAMPLES_YIELDED_KEY__]"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if dir_path.startswith(\"s3://\"):\n        return _resolve_s3_connections(dir_path)\n\n    if dir_path.startswith(\"projects/\"):\n        return _resolve_studio(dir_path, None, None)\n\n    if dir_path.startswith(\"datasets/\"):\n        return _resolve_datasets(dir_path)\n\n    return Dir(path=dir_path)"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path.startswith(\"s3://\"):\n        return _resolve_studio(dir_path, None, None)\n\n    if dir_path.startswith(\"data-connections/\"):\n        return _resolve_s3_connections(dir_path)\n\n    if dir_path.startswith(\"datasets/\"):\n        return _resolve_datasets(dir_path)\n\n    return Dir(path=dir_path)"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path.startswith(\"s3://\"):\n        return _resolve_s3_connections(dir_path)\n    elif dir_path.startswith(\"/\"):\n        return Dir(path=dir_path)\n    elif dir_path.startswith(\"projects/\"):\n        return _resolve_studio(dir_path, None, None)\n    elif dir_path.startswith(\"data_connections/\"):\n        return _resolve_s3_connections(dir_path)\n    elif dir_path.startswith(\"datasets/\"):\n        return _resolve_datasets(dir_path)\n    else:\n        raise ValueError(f\"Unsupported directory path format: {dir_path}\")"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if dir_path.startswith(\"s3://\"):\n        return _resolve_s3_connections(dir_path)\n    elif dir_path.startswith(\"/\"):\n        return Dir(path=dir_path)\n    elif dir_path.startswith(\"projects/\"):\n        return _resolve_studio(dir_path, None, None)\n    elif dir_path.startswith(\"datasets/\"):\n        return _resolve_datasets(dir_path)\n    else:\n        raise ValueError(f\"Unsupported directory path format: {dir_path}\")"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n    elif dir_path.startswith(\"s3://\"):\n        return _resolve_s3_connections(dir_path)\n    elif dir_path.startswith(\"/\"):\n        return Dir(path=dir_path)\n    else:\n        raise ValueError(\"Unsupported directory path format.\")"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path.startswith(\"s3://\"):\n        return _resolve_studio(dir_path, None, None)\n    elif dir_path.startswith(\"data-connections/\"):\n        return _resolve_s3_connections(dir_path)\n    elif dir_path.startswith(\"datasets/\"):\n        return _resolve_datasets(dir_path)\n    else:\n        return Dir(path=dir_path)"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path.startswith(\"s3://\"):\n        return _resolve_s3_connections(dir_path)\n    elif dir_path.startswith(\"/\"):\n        return Dir(path=dir_path)\n    elif dir_path.startswith(\"projects/\"):\n        return _resolve_studio(dir_path, None, None)\n    else:\n        return Dir(path=dir_path)"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path.startswith(\"s3://\"):\n        return _resolve_studio(dir_path, None, None)\n\n    if dir_path.startswith(\"data-connection://\"):\n        return _resolve_s3_connections(dir_path)\n\n    if dir_path.startswith(\"dataset://\"):\n        return _resolve_datasets(dir_path)\n\n    return Dir(path=dir_path)"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if dir_path.startswith(\"s3://\"):\n        return _resolve_s3_connections(dir_path)\n\n    if dir_path.startswith(\"projects/\"):\n        return _resolve_studio(dir_path, None, None)\n\n    if dir_path.startswith(\"data-connections/\"):\n        return _resolve_s3_connections(dir_path)\n\n    if dir_path.startswith(\"datasets/\"):\n        return _resolve_datasets(dir_path)\n\n    return Dir(path=dir_path)"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if dir_path.startswith(\"s3://\"):\n        return _resolve_s3_connections(dir_path)\n\n    if \"projects\" in dir_path:\n        return _resolve_studio(dir_path, None, None)\n\n    if \"datasets\" in dir_path:\n        return _resolve_datasets(dir_path)\n\n    return Dir(path=dir_path)"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if dir_path.startswith(\"s3://\"):\n        return _resolve_s3_connections(dir_path)\n\n    if dir_path.startswith(\"projects/\"):\n        return _resolve_studio(dir_path, None, None)\n\n    if dir_path.startswith(\"datasets/\"):\n        return _resolve_datasets(dir_path)\n\n    return Dir(path=dir_path)"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "\n    if isinstance(dir_path, Dir):\n        return dir_path\n    elif dir_path is None:\n        return Dir()\n\n    if dir_path.startswith(\"s3://\"):\n        return _resolve_studio(dir_path, None, None)\n    elif dir_path.startswith(\"data_connection://\"):\n        return _resolve_s3_connections(dir_path)\n    elif dir_path.startswith(\"dataset://\"):\n        return _resolve_datasets(dir_path)\n    else:\n        return Dir(path=dir_path)"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(path=dir_path, url=dir_path)\n\n    if dir_path.startswith(\"projects/\") or dir_path.startswith(\"datasets/\") or dir_path.startswith(\"cloudspaces/\"):\n        return Dir(path=dir_path, url=f\"{_get_lightning_cloud_url()}/{dir_path}\")\n\n    return Dir(path=dir_path)"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if dir_path.startswith(\"s3://\"):\n        return _resolve_s3_connections(dir_path)\n\n    if dir_path.startswith(\"projects/\"):\n        return _resolve_studio(dir_path, None, None)\n\n    if dir_path.startswith(\"datasets/\"):\n        return _resolve_datasets(dir_path)\n\n    return Dir(path=dir_path)"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(path=dir_path, url=dir_path)\n\n    if dir_path.startswith(\"/\"):\n        return Dir(path=dir_path)\n\n    return Dir(path=dir_path)"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if dir_path.startswith(\"s3://\"):\n        return _resolve_s3_connections(dir_path)\n\n    if dir_path.startswith(\"projects/\"):\n        return _resolve_studio(dir_path, None, None)\n\n    if dir_path.startswith(\"datasets/\"):\n        return _resolve_datasets(dir_path)\n\n    return Dir(path=dir_path)"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if dir_path.startswith(\"s3://\"):\n        return _resolve_s3_connections(dir_path)\n\n    if dir_path.startswith(\"/\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"projects/\") or dir_path.startswith(\"cloudspaces/\") or dir_path.startswith(\"datasets/\"):\n        return _resolve_datasets(dir_path)\n\n    if dir_path.startswith(\"studios/\") or dir_path.startswith(\"cloudspaces/\"):\n        return _resolve_studio(dir_path, None, None)\n\n    raise ValueError(f\"The provided directory path `{dir_path}` couldn't be resolved.\")"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if dir_path.startswith(\"s3://\"):\n        return _resolve_s3_connections(dir_path)\n\n    if dir_path.startswith(\"projects/\") or dir_path.startswith(\"cloudspaces/\") or dir_path.startswith(\"datasets/\"):\n        return _resolve_studio(dir_path, None, None)\n\n    if dir_path.startswith(\"data_connections/\"):\n        return _resolve_s3_connections(dir_path)\n\n    if dir_path.startswith(\"s3://\"):\n        return _resolve_s3_connections(dir_path)\n\n    return Dir(path=dir_path)"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if dir_path.startswith(\"s3://\"):\n        return _resolve_s3_connections(dir_path)\n\n    if dir_path.startswith(\"/\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"projects/\"):\n        return _resolve_studio(dir_path, None, None)\n\n    if dir_path.startswith(\"datasets/\"):\n        return _resolve_datasets(dir_path)\n\n    return Dir(path=dir_path)"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if dir_path.startswith(\"s3://\"):\n        return _resolve_s3_connections(dir_path)\n\n    if dir_path.startswith(\"/\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"projects/\") or dir_path.startswith(\"datasets/\"):\n        return _resolve_datasets(dir_path)\n\n    return _resolve_studio(dir_path, None, None)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    class OptimizeDNSContext:\n        def __init__(self, enable: bool):\n            self.enable = enable\n            self.original_state = None\n\n        def __enter__(self):\n            self.original_state = _IS_IN_STUDIO\n            optimize_dns(self.enable)\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            optimize_dns(False)\n\n    return OptimizeDNSContext(enable)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "\n    class _OptimizeDNSContext:\n        def __init__(self, enable: bool):\n            self.enable = enable\n\n        def __enter__(self):\n            _optimize_dns(self.enable)\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            _optimize_dns(False)\n\n    return _OptimizeDNSContext(enable)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    class OptimizeDNSContext:\n        def __init__(self, enable: bool):\n            self.enable = enable\n            self.original_state = None\n\n        def __enter__(self):\n            self.original_state = _is_dns_optimization_enabled()\n            if self.enable != self.original_state:\n                _optimize_dns(self.enable)\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            if self.enable != self.original_state:\n                _optimize_dns(self.original_state)\n\n    return OptimizeDNSContext(enable)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "\n    class OptimizeDNSContext:\n        def __init__(self, enable: bool):\n            self.enable = enable\n\n        def __enter__(self):\n            _optimize_dns(self.enable)\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            _optimize_dns(False)\n\n    return OptimizeDNSContext(enable)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "\n    class OptimizeDNSContext:\n        def __init__(self, enable: bool):\n            self.enable = enable\n\n        def __enter__(self):\n            _optimize_dns(self.enable)\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            _optimize_dns(False)\n\n    return OptimizeDNSContext(enable)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "\n    class OptimizeDNSContext:\n        def __init__(self, enable: bool):\n            self.enable = enable\n\n        def __enter__(self):\n            _optimize_dns(self.enable)\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            _optimize_dns(False)\n\n    return OptimizeDNSContext(enable)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "\n    class _OptimizeDnsContext:\n        def __init__(self, enable: bool):\n            self.enable = enable\n            self.original_state = None\n\n        def __enter__(self):\n            self.original_state = _is_dns_optimized()\n            optimize_dns(self.enable)\n\n        def __exit__(self, exc_type, exc_val, exc_tb):\n            optimize_dns(self.original_state)\n\n    return _OptimizeDnsContext(enable)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "\n    class _OptimizeDNSContext:\n        def __init__(self, enable: bool):\n            self.enable = enable\n\n        def __enter__(self):\n            _optimize_dns(self.enable)\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            _optimize_dns(False)\n\n    return _OptimizeDNSContext(enable)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "\n    class _OptimizeDnsContext:\n        def __init__(self, enable: bool):\n            self.enable = enable\n\n        def __enter__(self):\n            _optimize_dns(self.enable)\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            _optimize_dns(False)\n\n    return _OptimizeDnsContext(enable)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "\n    class OptimizeDNSContext:\n        def __init__(self, enable: bool):\n            self.enable = enable\n\n        def __enter__(self):\n            _optimize_dns(self.enable)\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            _optimize_dns(False)\n\n    return OptimizeDNSContext(enable)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "\n    class OptimizeDNSContext:\n        def __init__(self, enable: bool):\n            self.enable = enable\n\n        def __enter__(self):\n            _optimize_dns(self.enable)\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            _optimize_dns(False)\n\n    return OptimizeDNSContext(enable)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    class _OptimizeDNSContext:\n        def __init__(self, enable: bool):\n            self.enable = enable\n            self.original_state = None\n\n        def __enter__(self):\n            self.original_state = _is_dns_optimized()\n            if self.enable != self.original_state:\n                _optimize_dns(self.enable)\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            if self.original_state is not None and self.original_state != _is_dns_optimized():\n                _optimize_dns(self.original_state)\n\n    return _OptimizeDNSContext(enable)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    class OptimizeDNSContext:\n        def __init__(self, enable: bool):\n            self.enable = enable\n\n        def __enter__(self):\n            _optimize_dns(self.enable)\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            _optimize_dns(False)\n\n    return OptimizeDNSContext(enable)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "\n    class _OptimizeDnsContext:\n        def __init__(self, enable: bool):\n            self.enable = enable\n\n        def __enter__(self):\n            _optimize_dns(self.enable)\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            _optimize_dns(False)\n\n    return _OptimizeDnsContext(enable)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    class OptimizeDNSContext:\n        def __init__(self, enable: bool):\n            self.enable = enable\n\n        def __enter__(self):\n            _optimize_dns(self.enable)\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            _optimize_dns(False)\n\n    return OptimizeDNSContext(enable)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "\n    class OptimizeDNSContext:\n        def __init__(self, enable: bool):\n            self.enable = enable\n            self.original_state = None\n\n        def __enter__(self):\n            self.original_state = _IS_IN_STUDIO\n            optimize_dns(self.enable)\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            optimize_dns(False)\n\n    return OptimizeDNSContext(enable)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "\n    class OptimizeDNSContext:\n        def __init__(self, enable: bool):\n            self.enable = enable\n\n        def __enter__(self):\n            _optimize_dns(self.enable)\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            _optimize_dns(False)\n\n    return OptimizeDNSContext(enable)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "\n    class OptimizeDNSContext:\n        def __init__(self, enable: bool):\n            self.enable = enable\n\n        def __enter__(self):\n            _optimize_dns(self.enable)\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            _optimize_dns(False)\n\n    return OptimizeDNSContext(enable)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "\n    class OptimizeDNSContext:\n        def __init__(self, enable: bool):\n            self.enable = enable\n            self.original_state = None\n\n        def __enter__(self):\n            self.original_state = _is_dns_optimization_enabled()\n            if self.original_state != self.enable:\n                _optimize_dns(self.enable)\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            if self.original_state != self.enable:\n                _optimize_dns(self.original_state)\n\n    return OptimizeDNSContext(enable)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "\n    class _OptimizeDNSContext:\n        def __init__(self, enable: bool):\n            self.enable = enable\n            self.original_state = None\n\n        def __enter__(self):\n            self.original_state = _optimize_dns(self.enable)\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            _optimize_dns(False)\n\n    return _OptimizeDNSContext(enable)"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # Calculate the number of items each rank should process\n    total_items = len(indexes)\n    items_per_rank = total_items // distributed_env.world_size\n    remainder = total_items % distributed_env.world_size\n\n    # Adjust items per rank if drop_last is True\n    if drop_last and remainder > 0:\n        items_per_rank -= 1\n        remainder -= 1\n\n    # Distribute chunks and intervals to ranks\n    chunks_per_ranks = []\n    intervals_per_ranks = []\n\n    start_index = 0\n    for rank in range(distributed_env.world_size):\n        end_index = start_index + items_per_rank\n        if remainder > 0:\n            end_index += 1\n            remainder -= 1\n\n        chunks_per_ranks.append(indexes[start_index:end_index])\n        intervals_per_ranks.append(chunk_intervals[start_index:end_index])\n\n        start_index = end_index\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_chunks = len(indexes)\n    chunks_per_rank = total_chunks // distributed_env.world_size\n    remainder = total_chunks % distributed_env.world_size\n\n    chunks_per_ranks = []\n    start = 0\n    for rank in range(distributed_env.world_size):\n        num_chunks = chunks_per_rank + (1 if rank < remainder else 0)\n        end = start + num_chunks\n        chunks_per_ranks.append(indexes[start:end])\n        start = end\n\n    if drop_last and remainder > 0:\n        chunks_per_ranks[-1] = chunks_per_ranks[-1][:-1]\n\n    intervals_per_ranks = []\n    for chunks in chunks_per_ranks:\n        intervals = [chunk_intervals[i] for i in chunks]\n        intervals_per_ranks.append(intervals)\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_chunks = len(indexes)\n    chunks_per_rank = total_chunks // distributed_env.world_size\n    remainder = total_chunks % distributed_env.world_size\n\n    chunks_per_ranks = []\n    start = 0\n    for rank in range(distributed_env.world_size):\n        num_chunks = chunks_per_rank + (1 if rank < remainder else 0)\n        end = start + num_chunks\n        chunks_per_ranks.append(indexes[start:end])\n        start = end\n\n    if drop_last and remainder > 0:\n        chunks_per_ranks[-1] = chunks_per_ranks[-1][:-1]\n\n    intervals_per_ranks = []\n    for chunks in chunks_per_ranks:\n        intervals = [chunk_intervals[i] for i in chunks]\n        intervals_per_ranks.append(intervals)\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_chunks = len(indexes)\n    chunks_per_rank = total_chunks // distributed_env.world_size\n    remainder = total_chunks % distributed_env.world_size\n\n    chunks_per_ranks = []\n    start = 0\n    for i in range(distributed_env.world_size):\n        num_chunks = chunks_per_rank + (1 if i < remainder else 0)\n        end = start + num_chunks\n        chunks_per_ranks.append(indexes[start:end])\n        start = end\n\n    intervals_per_ranks = []\n    start = 0\n    for chunks in chunks_per_ranks:\n        intervals = []\n        for chunk_index in chunks:\n            intervals.append(chunk_intervals[chunk_index])\n        intervals_per_ranks.append(intervals)\n\n    if drop_last and remainder > 0:\n        chunks_per_ranks[-1] = chunks_per_ranks[-1][:-1]\n        intervals_per_ranks[-1] = intervals_per_ranks[-1][:-1]\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_items = len(indexes)\n    items_per_rank = total_items // distributed_env.world_size\n    remainder = total_items % distributed_env.world_size\n\n    # Calculate the number of items each rank should process\n    items_per_rank_list = [items_per_rank] * distributed_env.world_size\n    if remainder > 0:\n        if not drop_last:\n            for i in range(remainder):\n                items_per_rank_list[i] += 1\n        else:\n            for i in range(remainder):\n                items_per_rank_list[-(i + 1)] -= 1\n\n    # Assign chunks and their intervals to each rank\n    chunks_per_ranks = []\n    intervals_per_ranks = []\n    start = 0\n    for rank in range(distributed_env.world_size):\n        end = start + items_per_rank_list[rank]\n        chunks_per_ranks.append(indexes[start:end])\n        intervals_per_rank = [chunk_intervals[i] for i in range(start, end)]\n        intervals_per_ranks.append(intervals_per_rank)\n        start = end\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_chunks = len(indexes)\n    chunks_per_rank = total_chunks // distributed_env.world_size\n    remainder = total_chunks % distributed_env.world_size\n\n    chunks_per_ranks = []\n    start = 0\n    for rank in range(distributed_env.world_size):\n        num_chunks = chunks_per_rank + (1 if rank < remainder else 0)\n        end = start + num_chunks\n        chunks_per_ranks.append(indexes[start:end])\n        start = end\n\n    intervals_per_ranks = []\n    start = 0\n    for rank_chunks in chunks_per_ranks:\n        rank_intervals = []\n        for chunk_index in rank_chunks:\n            rank_intervals.append(chunk_intervals[chunk_index])\n        intervals_per_ranks.append(rank_intervals)\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_items = len(indexes)\n    items_per_rank = total_items // distributed_env.world_size\n    remainder = total_items % distributed_env.world_size\n\n    chunks_per_ranks = []\n    intervals_per_ranks = []\n\n    start = 0\n    for rank in range(distributed_env.world_size):\n        num_items = items_per_rank + (1 if rank < remainder else 0)\n        end = start + num_items\n        chunk_indexes = indexes[start:end]\n        chunk_intervals = chunk_intervals[start:end]\n        chunks_per_ranks.append(chunk_indexes)\n        intervals_per_ranks.append(chunk_intervals)\n        start = end\n\n    if drop_last and remainder > 0:\n        chunks_per_ranks[-1].extend(chunks_per_ranks.pop())\n        intervals_per_ranks[-1].extend(intervals_per_ranks.pop())\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_chunks = len(indexes)\n    chunks_per_rank = total_chunks // distributed_env.world_size\n    remainder = total_chunks % distributed_env.world_size\n\n    chunks_per_ranks = []\n    start = 0\n    for i in range(distributed_env.world_size):\n        chunk_count = chunks_per_rank + 1 if i < remainder else chunks_per_rank\n        end = start + chunk_count\n        chunks_per_ranks.append(indexes[start:end])\n        start = end\n\n    if drop_last and remainder > 0:\n        chunks_per_ranks[-1] = chunks_per_ranks[-1][:-1]\n\n    intervals_per_ranks = []\n    for chunks in chunks_per_ranks:\n        intervals = [chunk_intervals[i] for i in chunks]\n        intervals_per_ranks.append(intervals)\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_items = len(indexes)\n    items_per_rank = total_items // distributed_env.world_size\n    remainder = total_items % distributed_env.world_size\n\n    chunks_per_ranks = []\n    intervals_per_ranks = []\n\n    start = 0\n    for rank in range(distributed_env.world_size):\n        num_items = items_per_rank + (1 if rank < remainder else 0)\n        end = start + num_items\n        chunk_indexes = indexes[start:end]\n        chunk_intervals_per_rank = chunk_intervals[start:end]\n\n        if not drop_last and rank >= remainder:\n            end += 1\n            chunk_indexes.append(indexes[end - 1])\n            chunk_intervals_per_rank.append(chunk_intervals[end - 1])\n\n        chunks_per_ranks.append(chunk_indexes)\n        intervals_per_ranks.append(chunk_intervals_per_rank)\n\n        start = end\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_chunks = len(indexes)\n    chunks_per_rank = total_chunks // distributed_env.world_size\n    remainder = total_chunks % distributed_env.world_size\n\n    chunks_per_ranks = []\n    start = 0\n    for rank in range(distributed_env.world_size):\n        num_chunks = chunks_per_rank + (1 if rank < remainder else 0)\n        end = start + num_chunks\n        chunks_per_ranks.append(indexes[start:end])\n        start = end\n\n    intervals_per_ranks = []\n    start = 0\n    for rank in range(distributed_env.world_size):\n        num_chunks = len(chunks_per_ranks[rank])\n        intervals_per_ranks.append(chunk_intervals[start : start + num_chunks])\n        start += num_chunks\n\n    if drop_last and remainder > 0:\n        chunks_per_ranks[-1] = []\n        intervals_per_ranks[-1] = []\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_items = len(indexes)\n    items_per_rank = total_items // distributed_env.world_size\n    remainder = total_items % distributed_env.world_size\n\n    chunks_per_ranks = []\n    intervals_per_ranks = []\n\n    start = 0\n    for rank in range(distributed_env.world_size):\n        num_items = items_per_rank + (1 if rank < remainder else 0)\n        end = start + num_items\n        chunks_per_ranks.append(indexes[start:end])\n        intervals_per_ranks.append(chunk_intervals[start:end])\n        start = end\n\n    if drop_last and remainder > 0:\n        chunks_per_ranks[-1] = chunks_per_ranks[-1][:-1]\n        intervals_per_ranks[-1] = intervals_per_ranks[-1][:-1]\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_items = len(indexes)\n    items_per_rank = total_items // distributed_env.world_size\n    remainder = total_items % distributed_env.world_size\n\n    chunks_per_ranks = []\n    intervals_per_ranks = []\n\n    start = 0\n    for rank in range(distributed_env.world_size):\n        num_items = items_per_rank + (1 if rank < remainder else 0)\n        end = start + num_items\n        chunk_indexes = indexes[start:end]\n        chunk_intervals = chunk_intervals[start:end]\n\n        chunks_per_ranks.append(chunk_indexes)\n        intervals_per_ranks.append(chunk_intervals)\n\n        start = end\n\n    if drop_last and remainder > 0:\n        chunks_per_ranks[-1].extend(chunks_per_ranks[-2][-remainder:])\n        intervals_per_ranks[-1].extend(intervals_per_ranks[-2][-remainder:])\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    num_items = len(indexes)\n    items_per_rank = num_items // distributed_env.world_size\n    remainder = num_items % distributed_env.world_size\n\n    # Calculate the number of items each rank should process\n    items_per_rank_list = [items_per_rank + 1] * remainder + [items_per_rank] * (distributed_env.world_size - remainder)\n\n    # Assign chunks and their intervals to each rank\n    chunks_per_ranks = []\n    intervals_per_ranks = []\n\n    start = 0\n    for rank in range(distributed_env.world_size):\n        end = start + items_per_rank_list[rank]\n        chunks_per_ranks.append(indexes[start:end])\n        intervals_per_ranks.append(chunk_intervals[start:end])\n        start = end\n\n    if drop_last:\n        chunks_per_ranks = chunks_per_ranks[:-1]\n        intervals_per_ranks = intervals_per_ranks[:-1]\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_items = len(indexes)\n    items_per_rank = total_items // distributed_env.world_size\n    remainder = total_items % distributed_env.world_size\n\n    # Calculate the number of items each rank should process\n    items_per_rank_list = [items_per_rank + 1] * remainder + [items_per_rank] * (distributed_env.world_size - remainder)\n\n    # Assign chunks and their intervals to each rank\n    chunks_per_ranks = []\n    intervals_per_ranks = []\n\n    start = 0\n    for i in range(distributed_env.world_size):\n        end = start + items_per_rank_list[i]\n        chunk_indexes = indexes[start:end]\n        chunk_intervals_assigned = chunk_intervals[start:end]\n        chunks_per_ranks.append(chunk_indexes)\n        intervals_per_ranks.append(chunk_intervals_assigned)\n        start = end\n\n    # Drop the last items if specified\n    if drop_last and remainder > 0:\n        chunks_per_ranks[-1] = chunks_per_ranks[-1][:-1]\n        intervals_per_ranks[-1] = intervals_per_ranks[-1][:-1]\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    num_chunks = len(indexes)\n    chunks_per_rank = num_chunks // distributed_env.world_size\n    if not drop_last:\n        remainder = num_chunks % distributed_env.world_size\n        chunks_per_ranks = [\n            chunks_per_rank + 1 if i < remainder else chunks_per_rank for i in range(distributed_env.world_size)\n        ]\n    else:\n        chunks_per_ranks = [chunks_per_rank for _ in range(distributed_env.world_size)]\n\n    # Assign chunks to ranks\n    start = 0\n    chunk_indexes_per_ranks = []\n    for num_chunks in chunks_per_ranks:\n        end = start + num_chunks\n        chunk_indexes_per_ranks.append(indexes[start:end])\n        start = end\n\n    # Assign chunk intervals to ranks\n    chunk_intervals_per_ranks = []\n    for chunk_indexes in chunk_indexes_per_ranks:\n        intervals = [chunk_intervals[i] for i in chunk_indexes]\n        chunk_intervals_per_ranks.append(intervals)\n\n    return chunk_indexes_per_ranks, chunk_intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_items = len(indexes)\n    items_per_rank = total_items // distributed_env.world_size\n    remainder = total_items % distributed_env.world_size\n\n    # Calculate the number of items each rank should process\n    items_per_rank_list = [items_per_rank + 1 if i < remainder else items_per_rank for i in range(distributed_env.world_size)]\n\n    # Assign chunks and their intervals to each rank\n    chunks_per_ranks = []\n    intervals_per_ranks = []\n\n    start = 0\n    for i in range(distributed_env.world_size):\n        end = start + items_per_rank_list[i]\n        if i < remainder:\n            end += 1\n        chunks_per_ranks.append(indexes[start:end])\n        intervals_per_ranks.append(chunk_intervals[start:end])\n        start = end\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_items = len(indexes)\n    items_per_rank = total_items // distributed_env.world_size\n    remainder = total_items % distributed_env.world_size\n\n    if drop_last and remainder > 0:\n        items_per_rank -= 1\n\n    chunks_per_ranks = []\n    intervals_per_ranks = []\n\n    start = 0\n    for rank in range(distributed_env.world_size):\n        num_items = items_per_rank + (1 if rank < remainder else 0)\n\n        end = start + num_items\n        chunk_indexes = indexes[start:end]\n        chunk_intervals = chunk_intervals[start:end]\n\n        chunks_per_ranks.append(chunk_indexes)\n        intervals_per_ranks.append(chunk_intervals)\n\n        start = end\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_chunks = len(indexes)\n    chunks_per_rank = total_chunks // distributed_env.world_size\n    remainder = total_chunks % distributed_env.world_size\n\n    chunks_per_ranks = []\n    start = 0\n    for rank in range(distributed_env.world_size):\n        num_chunks = chunks_per_rank + int(rank < remainder)\n        end = start + num_chunks\n        chunks_per_ranks.append(indexes[start:end])\n        start = end\n\n    if drop_last and remainder > 0:\n        chunks_per_ranks[-1] = chunks_per_ranks[-1][:-1]\n\n    # Associate chunk intervals to ranks\n    chunk_intervals_per_ranks = []\n    start = 0\n    for rank in range(distributed_env.world_size):\n        num_chunks = len(chunks_per_ranks[rank])\n        end = start + num_chunks\n        chunk_intervals_per_ranks.append(chunk_intervals[start:end])\n        start = end\n\n    return chunks_per_ranks, chunk_intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    num_chunks = len(indexes)\n    chunks_per_rank = num_chunks // distributed_env.world_size\n    remainder = num_chunks % distributed_env.world_size\n\n    chunks_per_ranks = [\n        chunks_per_rank + 1 if i < remainder else chunks_per_rank for i in range(distributed_env.world_size)\n    ]\n\n    if drop_last:\n        chunks_per_ranks = [min(chunk, num_chunks) for chunk in chunks_per_ranks]\n\n    chunk_indexes_per_ranks = []\n    start = 0\n    for chunk_count in chunks_per_ranks:\n        end = start + chunk_count\n        chunk_indexes_per_ranks.append(list(range(start, end)))\n        start = end\n\n    chunk_intervals_per_ranks = [\n        [chunk_intervals[index] for index in chunk_indexes] for chunk_indexes in chunk_indexes_per_ranks\n    ]\n\n    return chunk_indexes_per_ranks, chunk_intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_chunks = len(indexes)\n    chunks_per_rank = total_chunks // distributed_env.world_size\n    remainder = total_chunks % distributed_env.world_size\n\n    chunks_per_ranks = []\n    start = 0\n    for rank in range(distributed_env.world_size):\n        num_chunks = chunks_per_rank + (1 if rank < remainder else 0)\n        end = start + num_chunks\n        chunks_per_ranks.append(indexes[start:end])\n        start = end\n\n    intervals_per_ranks = []\n    start = 0\n    for rank in range(distributed_env.world_size):\n        num_chunks = len(chunks_per_ranks[rank])\n        end = start + num_chunks\n        intervals_per_ranks.append(chunk_intervals[start:end])\n        start = end\n\n    if drop_last and remainder > 0:\n        chunks_per_ranks[-1] = []\n        intervals_per_ranks[-1] = []\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {\"output_dir\": output_dir}\n        if self._contains_device:\n            self._find_device()\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, **kwargs)"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._contains_device:\n            self._find_device()\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {\"output_dir\": output_dir}\n        if self._contains_device:\n            self._find_device()\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        if isinstance(self._fn, partial):\n            self._fn(item_metadata, **kwargs)\n        elif isinstance(self._fn, FunctionType):\n            self._fn(item_metadata, **kwargs)\n        elif callable(self._fn):\n            self._fn.__call__(item_metadata, **kwargs)\n        else:\n            raise ValueError(f\"The provided {self._fn} isn't supported.\")"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_device:\n            self._find_device()\n\n        if self._contains_is_last:\n            self._fn(item_metadata, output_dir, device=self._device, is_last=is_last)\n        else:\n            self._fn(item_metadata, output_dir, device=self._device)"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {\"device\": self._device} if self._contains_device else {}\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        if isinstance(self._fn, partial):\n            self._fn(item_metadata, output_dir, **kwargs)\n        elif isinstance(self._fn, FunctionType):\n            self._fn(item_metadata, output_dir, **kwargs)\n        elif callable(self._fn):\n            self._fn.__call__(item_metadata, output_dir, **kwargs)\n        else:\n            raise ValueError(f\"The provided {self._fn} isn't supported.\")"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {\"device\": self._device} if self._contains_device else {}\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n        self._fn(item_metadata, output_dir, **kwargs)"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._contains_device:\n            self._find_device()\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n        self._fn(item_metadata, output_dir, **kwargs)"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {\"output_dir\": output_dir}\n        if self._contains_device:\n            self._find_device()\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        if isinstance(self._fn, partial):\n            self._fn(item_metadata, **kwargs)\n        elif isinstance(self._fn, FunctionType):\n            self._fn(item_metadata, **kwargs)\n        elif callable(self._fn):\n            self._fn.__call__(item_metadata, **kwargs)\n        else:\n            raise ValueError(f\"The provided {self._fn} isn't supported.\")"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._contains_device:\n            self._find_device()\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {\"output_dir\": output_dir}\n        if self._contains_device:\n            self._find_device()\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        if isinstance(self._fn, partial):\n            self._fn(item_metadata, **kwargs)\n        elif isinstance(self._fn, FunctionType):\n            self._fn(item_metadata, **kwargs)\n        elif callable(self._fn):\n            self._fn.__call__(item_metadata, **kwargs)\n        else:\n            raise ValueError(f\"The provided {self._fn} isn't supported.\")"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {\"output_dir\": output_dir}\n        if self._contains_device:\n            self._find_device()\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        if isinstance(self._fn, partial):\n            self._fn(item_metadata, **kwargs)\n\n        elif isinstance(self._fn, FunctionType):\n            self._fn(item_metadata, **kwargs)\n\n        elif callable(self._fn):\n            self._fn(item_metadata, **kwargs)\n\n        else:\n            raise ValueError(f\"The provided {self._fn} isn't supported.\")"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {\"output_dir\": output_dir}\n        if self._contains_device:\n            self._find_device()\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        if isinstance(self._fn, partial):\n            self._fn(item_metadata, **kwargs)\n        elif isinstance(self._fn, FunctionType):\n            self._fn(item_metadata, **kwargs)\n        elif callable(self._fn):\n            self._fn.__call__(item_metadata, **kwargs)\n        else:\n            raise ValueError(f\"The provided {self._fn} isn't supported.\")"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        args = [item_metadata, output_dir]\n        kwargs = {}\n        if self._contains_device:\n            self._find_device()\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n        self._fn(*args, **kwargs)"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {\"device\": self._device} if self._contains_device else {}\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n        self._fn(item_metadata, output_dir, **kwargs)"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._contains_device:\n            self._find_device()\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {\"output_dir\": output_dir}\n        if self._contains_device:\n            self._find_device()\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n        self._fn(item_metadata, **kwargs)"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_device:\n            self._find_device()\n\n        if self._contains_is_last:\n            self._fn(item_metadata, output_dir, device=self._device, is_last=is_last)\n        else:\n            self._fn(item_metadata, output_dir, device=self._device)"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._contains_device:\n            self._find_device()\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        if isinstance(self._fn, partial):\n            self._fn(item_metadata, output_dir, **kwargs)\n        elif isinstance(self._fn, FunctionType):\n            self._fn(item_metadata, output_dir, **kwargs)\n        elif callable(self._fn):\n            self._fn.__call__(item_metadata, output_dir, **kwargs)\n        else:\n            raise ValueError(f\"The provided {self._fn} isn't supported.\")"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {\"output_dir\": output_dir}\n        if self._contains_device:\n            self._find_device()\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        if isinstance(self._fn, partial):\n            self._fn(item_metadata, **kwargs)\n        elif isinstance(self._fn, FunctionType):\n            self._fn(item_metadata, **kwargs)\n        elif callable(self._fn):\n            self._fn.__call__(item_metadata, **kwargs)\n        else:\n            raise ValueError(f\"The provided {self._fn} isn't supported.\")"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {\"device\": self._device} if self._contains_device else {}\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        if isinstance(self._fn, partial):\n            self._fn(item_metadata, output_dir, **kwargs)\n        elif isinstance(self._fn, FunctionType):\n            self._fn(item_metadata, output_dir, **kwargs)\n        elif callable(self._fn):\n            self._fn.__call__(item_metadata, output_dir, **kwargs)\n        else:\n            raise ValueError(f\"The provided {self._fn} isn't supported.\")"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.client.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            error_code = e.response[\"Error\"][\"Code\"]\n            if error_code == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.client.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            error_code = e.response[\"Error\"][\"Code\"]\n            if error_code == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.client.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            error_code = e.response[\"Error\"][\"Code\"]\n            if error_code == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.client.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            error_code = e.response[\"Error\"][\"Code\"]\n            if error_code == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "\n    while True:\n        try:\n            response = s3.client.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            error_code = e.response[\"Error\"][\"Code\"]\n            if error_code == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.client.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            error_code = e.response[\"Error\"][\"Code\"]\n            if error_code == \"404\":\n                time.sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.client.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            error_code = e.response[\"Error\"][\"Code\"]\n            if error_code == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.client.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            error_code = e.response[\"Error\"][\"Code\"]\n            if error_code == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.client.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            error_code = e.response[\"Error\"][\"Code\"]\n            if error_code == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.client.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            error_code = e.response[\"Error\"][\"Code\"]\n            if error_code == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "\n    while True:\n        try:\n            response = s3.client.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            error_code = e.response[\"Error\"][\"Code\"]\n            if error_code == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.client.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            error_code = e.response[\"Error\"][\"Code\"]\n            if error_code == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.client.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            error_code = e.response[\"Error\"][\"Code\"]\n            if error_code == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.client.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            error_code = e.response[\"Error\"][\"Code\"]\n            if error_code == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.client.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            error_code = e.response[\"Error\"][\"Code\"]\n            if error_code == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.client.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            error_code = e.response[\"Error\"][\"Code\"]\n            if error_code == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.client.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            error_code = e.response[\"Error\"][\"Code\"]\n            if error_code == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.client.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            error_code = e.response[\"Error\"][\"Code\"]\n            if error_code == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "\n    while True:\n        try:\n            response = s3.client.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            error_code = e.response[\"Error\"][\"Code\"]\n            if error_code == \"404\":\n                time.sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.client.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            error_code = e.response[\"Error\"][\"Code\"]\n            if error_code == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "        import psutil\n        import shutil\n    import shutil\n    import psutil\n\n    while True:\n        disk_usage = shutil.disk_usage(input_dir)\n        free_space_gb = disk_usage.free / (2**30)  # Convert bytes to gigabytes\n        if free_space_gb < threshold_in_gb:\n            break\n        else:\n            time.sleep(sleep_time)"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        free_gb = free / (2**30)  # Convert bytes to gigabytes\n        if free_gb < threshold_in_gb:\n            sleep(sleep_time)\n        else:\n            break"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "        import psutil\n    import psutil\n\n    while True:\n        disk_usage = psutil.disk_usage(input_dir)\n        free_space_gb = disk_usage.free / (2**30)  # convert to gigabytes\n        if free_space_gb <= threshold_in_gb:\n            break\n        else:\n            sleep(sleep_time)"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "        import psutil\n    import psutil\n    while True:\n        disk_usage = psutil.disk_usage(input_dir)\n        free_space_gb = disk_usage.free / (2**30)  # Convert bytes to gigabytes\n        if free_space_gb <= threshold_in_gb:\n            break\n        else:\n            sleep(sleep_time)"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        free_gb = free / (2**30)  # Convert bytes to gigabytes\n        if free_gb <= threshold_in_gb:\n            break\n        else:\n            sleep(sleep_time)"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "        import psutil\n    import psutil\n    while True:\n        disk_usage = psutil.disk_usage(input_dir)\n        free_space_gb = disk_usage.free / (2**30)  # Convert bytes to gigabytes\n        if free_space_gb <= threshold_in_gb:\n            break\n        else:\n            sleep(sleep_time)"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        free_gb = free / (2**30)  # Convert bytes to gigabytes\n        if free_gb < threshold_in_gb:\n            sleep(sleep_time)\n        else:\n            break"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "        import psutil\n    import psutil\n    disk_usage = psutil.disk_usage(input_dir)\n    free_space_gb = disk_usage.free / (2**30)  # Convert bytes to gigabytes\n    while free_space_gb > threshold_in_gb:\n        disk_usage = psutil.disk_usage(input_dir)\n        free_space_gb = disk_usage.free / (2**30)  # Convert bytes to gigabytes\n        time.sleep(sleep_time)"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        free_gb = free / (2**30)  # convert bytes to gigabytes\n        if free_gb <= threshold_in_gb:\n            break\n        else:\n            sleep(sleep_time)"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "        import psutil\n    import psutil\n\n    while True:\n        disk_usage = psutil.disk_usage(input_dir)\n        free_space_gb = disk_usage.free / (2**30)  # Convert bytes to gigabytes\n        if free_space_gb <= threshold_in_gb:\n            break\n        else:\n            sleep(sleep_time)"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "        import shutil\n        import psutil\n    import psutil\n    import shutil\n\n    while True:\n        disk_usage = shutil.disk_usage(input_dir)\n        free_space_gb = disk_usage.free / (2**30)  # Convert bytes to gigabytes\n        if free_space_gb < threshold_in_gb:\n            break\n        else:\n            time.sleep(sleep_time)"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        free_gb = free / (2**30)  # Convert bytes to gigabytes\n        if free_gb < threshold_in_gb:\n            sleep(sleep_time)\n        else:\n            break"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "        import psutil\n    import psutil\n\n    while True:\n        disk_usage = psutil.disk_usage(input_dir)\n        free_space_gb = disk_usage.free / (2**30)  # Convert bytes to gigabytes\n        if free_space_gb <= threshold_in_gb:\n            break\n        else:\n            sleep(sleep_time)"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "        import psutil\n    import psutil\n    disk_usage = psutil.disk_usage(input_dir)\n    free_space_gb = disk_usage.free / (2**30)  # Convert bytes to gigabytes\n    while free_space_gb > threshold_in_gb:\n        disk_usage = psutil.disk_usage(input_dir)\n        free_space_gb = disk_usage.free / (2**30)  # Convert bytes to gigabytes\n        time.sleep(sleep_time)"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        free_gb = free / (2**30)  # Convert bytes to gigabytes\n        if free_gb < threshold_in_gb:\n            sleep(sleep_time)\n        else:\n            break"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "\n    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        free_gb = free / (2**30)  # Convert bytes to gigabytes\n        if free_gb < threshold_in_gb:\n            sleep(sleep_time)\n        else:\n            break"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "        import psutil\n    import psutil\n\n    while True:\n        disk_usage = psutil.disk_usage(input_dir)\n        free_space_gb = disk_usage.free / (2**30)  # Convert bytes to gigabytes\n        if free_space_gb < threshold_in_gb:\n            break\n        else:\n            sleep(sleep_time)"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        free_gb = free / (2**30)  # convert bytes to gigabytes\n        if free_gb < threshold_in_gb:\n            sleep(sleep_time)\n        else:\n            break"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        free_gb = free / (2**30)  # Convert bytes to gigabytes\n        if free_gb <= threshold_in_gb:\n            break\n        else:\n            sleep(sleep_time)"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "        import psutil\n    import psutil\n\n    while True:\n        disk_usage = psutil.disk_usage(input_dir)\n        free_space_gb = disk_usage.free / (2**30)  # Convert bytes to gigabytes\n        if free_space_gb < threshold_in_gb:\n            break\n        else:\n            sleep(sleep_time)"}
{"namespace": "litdata.processing.functions.optimize", "completion": "\n    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,\n            reader=reader,\n        )\n        with optimize_dns_context(True):\n            return data_processor.run(LambdaDataTransformRecipe(fn, inputs))\n    return _execute(\n        f\"data-prep-map-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,\n            reader=reader,\n        )\n        with optimize_dns_context(True):\n            return data_processor.run(LambdaDataTransformRecipe(fn, inputs))\n    return _execute(\n        f\"data-prep-map-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "\n    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,\n            reader=reader,\n        )\n        with optimize_dns_context(True):\n            return data_processor.run(LambdaDataTransformRecipe(fn, inputs))\n    return _execute(\n        f\"data-prep-map-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "\n    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,\n            reader=reader,\n        )\n        with optimize_dns_context(True):\n            return data_processor.run(LambdaDataTransformRecipe(fn, inputs))\n    return _execute(\n        f\"data-prep-map-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "\n    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,\n            reader=reader,\n        )\n        with optimize_dns_context(True):\n            return data_processor.run(LambdaDataChunkRecipe(fn, inputs, chunk_size, chunk_bytes, compression))\n    return _execute(\n        f\"data-prep-optimize-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "\n    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,\n            reader=reader,\n        )\n        with optimize_dns_context(True):\n            return data_processor.run(LambdaDataTransformRecipe(fn, inputs))\n    return _execute(\n        f\"data-prep-optimize-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,\n            reader=reader,\n        )\n        with optimize_dns_context(True):\n            return data_processor.run(LambdaDataChunkRecipe(fn, inputs, chunk_size, chunk_bytes, compression))\n    return _execute(\n        f\"data-prep-optimize-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "\n    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,\n            reader=reader,\n        )\n        with optimize_dns_context(True):\n            return data_processor.run(LambdaDataTransformRecipe(fn, inputs))\n    return _execute(\n        f\"data-prep-map-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "\n    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,\n            reader=reader,\n        )\n        with optimize_dns_context(True):\n            return data_processor.run(LambdaDataTransformRecipe(fn, inputs))\n    return _execute(\n        f\"data-prep-map-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "\n    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,\n            reader=reader,\n        )\n        with optimize_dns_context(True):\n            return data_processor.run(LambdaDataTransformRecipe(fn, inputs))\n    return _execute(\n        f\"data-prep-map-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "\n    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,\n            reader=reader,\n        )\n        with optimize_dns_context(True):\n            return data_processor.run(LambdaDataChunkRecipe(fn, inputs, chunk_size, chunk_bytes, compression))\n    return _execute(\n        f\"data-prep-optimize-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "\n    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,\n            reader=reader,\n        )\n        with optimize_dns_context(True):\n            return data_processor.run(LambdaDataTransformRecipe(fn, inputs))\n    return _execute(\n        f\"data-prep-map-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,\n            reader=reader,\n        )\n        with optimize_dns_context(True):\n            return data_processor.run(LambdaDataChunkRecipe(fn, inputs, chunk_size, chunk_bytes, compression))\n    return _execute(\n        f\"data-prep-optimize-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "\n    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,\n            reader=reader,\n        )\n        with optimize_dns_context(True):\n            return data_processor.run(LambdaDataChunkRecipe(fn, inputs, chunk_size, chunk_bytes, compression))\n    return _execute(\n        f\"data-prep-optimize-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "\n    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,\n            reader=reader,\n        )\n        with optimize_dns_context(True):\n            return data_processor.run(LambdaDataChunkRecipe(fn, inputs, chunk_size, chunk_bytes, compression))\n    return _execute(\n        f\"data-prep-optimize-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "\n    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,\n            reader=reader,\n        )\n        with optimize_dns_context(True):\n            return data_processor.run(LambdaDataTransformRecipe(fn, inputs))\n    return _execute(\n        f\"data-prep-map-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "\n    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,\n            reader=reader,\n        )\n        with optimize_dns_context(True):\n            return data_processor.run(LambdaDataChunkRecipe(fn, inputs, chunk_size, chunk_bytes, compression))\n    return _execute(\n        f\"data-prep-optimize-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "\n    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,\n            reader=reader,\n        )\n        with optimize_dns_context(True):\n            return data_processor.run(LambdaDataTransformRecipe(fn, inputs))\n    return _execute(\n        f\"data-prep-map-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,\n            reader=reader,\n        )\n        with optimize_dns_context(True):\n            return data_processor.run(LambdaDataChunkRecipe(fn, inputs, chunk_size, chunk_bytes, compression))\n    return _execute(\n        f\"data-prep-optimize-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,\n            reader=reader,\n        )\n        with optimize_dns_context(True):\n            return data_processor.run(LambdaDataTransformRecipe(fn, inputs))\n    return _execute(\n        f\"data-prep-map-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.map", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if isinstance(output_dir, str) and error_when_not_empty and os.path.exists(output_dir) and os.listdir(output_dir):\n        raise ValueError(f\"The output directory {output_dir} is not empty.\")\n\n    if isinstance(output_dir, Dir) and error_when_not_empty and output_dir.exists() and output_dir.list():\n        raise ValueError(f\"The output directory {output_dir.path} is not empty.\")\n\n    if not isinstance(output_dir, (str, Dir)):\n        raise ValueError(f\"The output_dir should be a string path or a Dir object. Found {output_dir}.\")\n\n    if not isinstance(output_dir, Dir):\n        output_dir = Dir(output_dir)\n\n    if chunk_size is None and chunk_bytes is None and batch_size is None:\n        raise ValueError(\"Either `chunk_size`, `chunk_bytes`, or `batch_size` needs to be defined.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \"Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to optimize your data faster \"\n            \"using multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url is not None and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            reader=reader,\n        )\n\n        with optimize_dns_context(True):\n            data_processor.run(\n                LambdaDataTransformRecipe(\n                    fn,\n                    inputs,\n                )\n            )\n        return None\n    return _execute(\n        f\"data-prep-map-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.map", "completion": "\n    if error_when_not_empty and os.path.exists(output_dir) and len(os.listdir(output_dir)) > 0:\n        raise ValueError(f\"The output directory {output_dir} is not empty.\")\n\n    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \"Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to optimize your data faster \"\n            \"using multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url is not None and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            reader=reader,\n        )\n\n        with optimize_dns_context(True):\n            data_processor.run(\n                LambdaDataTransformRecipe(\n                    fn,\n                    inputs,\n                )\n            )\n        return None\n    return _execute(\n        f\"data-prep-optimize-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.map", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not isinstance(output_dir, Dir) and not isinstance(output_dir, str):\n        raise ValueError(\"The output_dir should be either a string path or a Dir object.\")\n\n    if error_when_not_empty and os.path.exists(output_dir):\n        if len(os.listdir(output_dir)) > 0:\n            raise ValueError(f\"The output directory {output_dir} is not empty.\")\n\n    if not isinstance(output_dir, Dir):\n        output_dir = Dir(output_dir)\n\n    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The output_dir should be either a string path or a Dir object.\")\n\n    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The output_dir should be either a string path or a Dir object.\")\n\n    if chunk_size is None and chunk_bytes is None:\n        raise ValueError(\"Either `chunk_size` or `chunk_bytes` needs to be defined.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \"Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to optimize your data faster \"\n            \"using multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url is not None and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            reader=reader,\n        )\n\n        with optimize_dns_context(True):\n            data_processor.run(\n                LambdaDataChunkRecipe(\n                    fn,\n                    inputs,\n                    chunk_size=chunk_size,\n                    chunk_bytes=chunk_bytes,\n                    compression=compression,\n                )\n            )\n        return None\n    return _execute(\n        f\"data-prep-optimize-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.map", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not isinstance(output_dir, str) and not isinstance(output_dir, Dir):\n        raise ValueError(\"The output_dir should be either a string path or a Dir object.\")\n\n    if isinstance(output_dir, str) and error_when_not_empty and os.path.exists(output_dir) and os.listdir(output_dir):\n        raise ValueError(\"The output directory is not empty and error_when_not_empty is set to True.\")\n\n    if not isinstance(output_dir, str) and error_when_not_empty and output_dir.exists() and list(output_dir.iterdir()):\n        raise ValueError(\"The output directory is not empty and error_when_not_empty is set to True.\")\n\n    if chunk_size is None and chunk_bytes is None:\n        raise ValueError(\"Either `chunk_size` or `chunk_bytes` needs to be defined.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \"Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to optimize your data faster \"\n            \"using multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url is not None and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            reader=reader,\n        )\n\n        with optimize_dns_context(True):\n            data_processor.run(\n                LambdaDataChunkRecipe(\n                    fn,\n                    inputs,\n                    chunk_size=chunk_size,\n                    chunk_bytes=chunk_bytes,\n                    compression=compression,\n                )\n            )\n        return None\n    return _execute(\n        f\"data-prep-optimize-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.map", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not isinstance(output_dir, (str, Dir)):\n        raise ValueError(f\"The provided output_dir should be a string path or a Dir object. Found {output_dir}.\")\n\n    if error_when_not_empty and os.path.exists(output_dir):\n        if len(os.listdir(output_dir)) > 0:\n            raise ValueError(f\"The output directory {output_dir} is not empty.\")\n\n    if not isinstance(output_dir, Dir) and not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to map your data faster \"\n            \"using multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url is not None and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            reader=reader,\n        )\n\n        with optimize_dns_context(True):\n            data_processor.run(\n                LambdaDataTransformRecipe(\n                    fn,\n                    inputs,\n                )\n            )\n        return None\n    return _execute(\n        f\"data-prep-map-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.map", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not isinstance(output_dir, (str, Dir)):\n        raise ValueError(f\"The provided output_dir should be a string path or a Dir object. Found {output_dir}.\")\n\n    if isinstance(output_dir, str) and error_when_not_empty and os.path.isdir(output_dir) and os.listdir(output_dir):\n        raise ValueError(f\"The provided output directory {output_dir} is not empty.\")\n\n    if not isinstance(output_dir, str) and error_when_not_empty and output_dir.exists() and list(output_dir):\n        raise ValueError(f\"The provided output directory {output_dir} is not empty.\")\n\n    if not isinstance(output_dir, str) and not output_dir.exists():\n        output_dir.mkdir(parents=True, exist_ok=True)\n\n    if not isinstance(output_dir, str) and not output_dir.is_dir():\n        raise ValueError(f\"The provided output directory {output_dir} is not a valid directory.\")\n\n    if isinstance(output_dir, str):\n        output_dir = Dir(output_dir)\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if chunk_size is None and chunk_bytes is None:\n        raise ValueError(\"Either `chunk_size` or `chunk_bytes` needs to be defined.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \"Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to optimize your data faster \"\n            \"using multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url is not None and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers,\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            reader=reader,\n        )\n\n        with optimize_dns_context(True):\n            data_processor.run(\n                LambdaDataChunkRecipe(\n                    fn,\n                    inputs,\n                    chunk_size=chunk_size,\n                    chunk_bytes=chunk_bytes,\n                    compression=compression,\n                )\n            )\n        return None\n    return _execute(\n        f\"data-prep-optimize-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.map", "completion": "\n    if error_when_not_empty and os.path.isdir(output_dir) and os.listdir(output_dir):\n        raise ValueError(\"The output directory is not empty.\")\n\n    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \"Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to optimize your data faster \"\n            \"using multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url is not None and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            reader=reader,\n        )\n\n        with optimize_dns_context(True):\n            data_processor.run(\n                LambdaDataTransformRecipe(\n                    fn,\n                    inputs,\n                )\n            )\n        return None\n    return _execute(\n        f\"data-prep-optimize-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.map", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not isinstance(output_dir, Dir) and error_when_not_empty and os.path.exists(output_dir):\n        raise ValueError(f\"The output directory {output_dir} is not empty.\")\n\n    if not isinstance(output_dir, Dir) and not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    if not isinstance(output_dir, Dir) and not os.path.isdir(output_dir):\n        raise ValueError(f\"The output directory {output_dir} is not a valid directory.\")\n\n    if not isinstance(output_dir, Dir) and not os.access(output_dir, os.W_OK):\n        raise ValueError(f\"The output directory {output_dir} is not writable.\")\n\n    if not isinstance(output_dir, Dir):\n        _output_dir: Dir = _resolve_dir(output_dir)\n    else:\n        _output_dir = output_dir\n\n    if chunk_size is None and chunk_bytes is None:\n        raise ValueError(\"Either `chunk_size` or `chunk_bytes` needs to be defined.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \"Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to optimize your data faster \"\n            \"using multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            reader=reader,\n        )\n\n        with optimize_dns_context(True):\n            data_processor.run(\n                LambdaDataTransformRecipe(\n                    fn,\n                    inputs,\n                )\n            )\n        return None\n    return _execute(\n        f\"data-prep-optimize-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.map", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not isinstance(output_dir, Dir) and not isinstance(output_dir, str):\n        raise ValueError(\"The output_dir should be either a Dir object or a string path.\")\n\n    if error_when_not_empty and os.path.exists(output_dir) and os.listdir(output_dir):\n        raise ValueError(\"The output directory is not empty and error_when_not_empty is set to True.\")\n\n    if not isinstance(output_dir, Dir):\n        output_dir = _resolve_dir(output_dir)\n\n    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The resolved output_dir should be a Dir object.\")\n\n    if chunk_size is None and chunk_bytes is None:\n        raise ValueError(\"Either `chunk_size` or `chunk_bytes` needs to be defined.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \"Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to optimize your data faster \"\n            \"using multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url is not None and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            reader=reader,\n        )\n\n        with optimize_dns_context(True):\n            data_processor.run(\n                LambdaDataChunkRecipe(\n                    fn,\n                    inputs,\n                    chunk_size=chunk_size,\n                    chunk_bytes=chunk_bytes,\n                    compression=compression,\n                )\n            )\n        return None\n    return _execute(\n        f\"data-prep-optimize-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.map", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not isinstance(output_dir, (str, Dir)):\n        raise ValueError(f\"The output_dir should be a string path or a Dir object. Found {output_dir}.\")\n\n    if isinstance(output_dir, Dir) and error_when_not_empty and len(list(output_dir.iterdir())) > 0:\n        raise ValueError(f\"The output directory {output_dir} is not empty and error_when_not_empty is set to True.\")\n\n    if not isinstance(output_dir, Dir) and error_when_not_empty and len(os.listdir(output_dir)) > 0:\n        raise ValueError(f\"The output directory {output_dir} is not empty and error_when_not_empty is set to True.\")\n\n    if isinstance(output_dir, StreamingDataLoader):\n        raise ValueError(\"The output_dir cannot be a StreamingDataLoader.\")\n\n    if num_workers is not None and num_workers < 1:\n        raise ValueError(\"num_workers should be a positive integer.\")\n\n    if isinstance(output_dir, Dir):\n        output_dir = output_dir.path\n\n    if batch_size is not None and isinstance(inputs, StreamingDataLoader):\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if batch_size is not None and batch_size < 1:\n        raise ValueError(\"batch_size should be a positive integer.\")\n\n    if chunk_size is None and chunk_bytes is None:\n        raise ValueError(\"Either `chunk_size` or `chunk_bytes` needs to be defined.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \"Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to optimize your data faster \"\n            \"using multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url is not None and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            reader=reader,\n        )\n\n        with optimize_dns_context(True):\n            data_processor.run(\n                LambdaDataChunkRecipe(\n                    fn,\n                    inputs,\n                    chunk_size=chunk_size,\n                    chunk_bytes=chunk_bytes,\n                    compression=compression,\n                )\n            )\n        return None\n    return _execute(\n        f\"data-prep-optimize-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.map", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if isinstance(output_dir, str) and error_when_not_empty and os.path.exists(output_dir) and len(os.listdir(output_dir)) > 0:\n        raise ValueError(\"The output directory is not empty and error_when_not_empty is set to True.\")\n\n    if isinstance(output_dir, Dir) and error_when_not_empty and output_dir.url is not None and len(list(walk(output_dir.path))) > 0:\n        raise ValueError(\"The output directory is not empty and error_when_not_empty is set to True.\")\n\n    if not isinstance(output_dir, (str, Dir)):\n        raise ValueError(f\"The output_dir should be a string or a Dir object. Found {output_dir}.\")\n\n    if isinstance(output_dir, str):\n        _output_dir = output_dir\n    else:\n        _output_dir = output_dir.path\n\n    if num_workers is not None and num_workers < 1:\n        raise ValueError(\"num_workers should be a positive integer.\")\n\n    if isinstance(output_dir, str) and not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine. \"\n            \"Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to optimize your data faster \"\n            \"using multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir = _resolve_dir(_output_dir)\n\n        if isinstance(inputs, StreamingDataLoader):\n            input_dir = Dir()\n        else:\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            reader=reader,\n        )\n\n        with optimize_dns_context(True):\n            data_processor.run(\n                LambdaDataTransformRecipe(\n                    fn,\n                    inputs,\n                )\n            )\n        return None\n    return _execute(\n        f\"data-prep-map-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.map", "completion": "\n    if error_when_not_empty and os.path.exists(output_dir) and os.listdir(output_dir):\n        raise ValueError(f\"The output directory {output_dir} is not empty.\")\n\n    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \"Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to optimize your data faster \"\n            \"using multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url is not None and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            reader=reader,\n        )\n\n        with optimize_dns_context(True):\n            data_processor.run(\n                LambdaDataTransformRecipe(\n                    fn,\n                    inputs,\n                )\n            )\n        return None\n    return _execute(\n        f\"data-prep-map-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.map", "completion": "\n    if error_when_not_empty and os.path.isdir(output_dir) and os.listdir(output_dir):\n        raise ValueError(f\"The output directory {output_dir} is not empty.\")\n\n    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \"Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to optimize your data faster \"\n            \"using multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url is not None and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            reader=reader,\n        )\n\n        with optimize_dns_context(True):\n            data_processor.run(\n                LambdaDataTransformRecipe(\n                    fn,\n                    inputs,\n                )\n            )\n        return None\n    return _execute(\n        f\"data-prep-optimize-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.map", "completion": "\n    if error_when_not_empty and os.path.exists(output_dir) and os.listdir(output_dir):\n        raise ValueError(f\"The output directory {output_dir} is not empty.\")\n\n    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \"Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to optimize your data faster \"\n            \"using multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url is not None and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            reader=reader,\n        )\n\n        with optimize_dns_context(True):\n            data_processor.run(\n                LambdaDataTransformRecipe(\n                    fn,\n                    inputs,\n                )\n            )\n        return None\n    return _execute(\n        f\"data-prep-map-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.map", "completion": "\n    if error_when_not_empty and os.path.isdir(output_dir) and os.listdir(output_dir):\n        raise ValueError(f\"The output directory {output_dir} is not empty.\")\n\n    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \"Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to optimize your data faster \"\n            \"using multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url is not None and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            reader=reader,\n        )\n\n        with optimize_dns_context(True):\n            data_processor.run(\n                LambdaDataTransformRecipe(\n                    fn,\n                    inputs,\n                )\n            )\n        return None\n    return _execute(\n        f\"data-prep-optimize-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.map", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not isinstance(output_dir, str) and not isinstance(output_dir, Dir):\n        raise ValueError(\"The output_dir should be either a string path or a Dir object.\")\n\n    if error_when_not_empty and os.path.exists(output_dir):\n        if len(os.listdir(output_dir)) > 0:\n            raise ValueError(\"The output directory is not empty.\")\n\n    if not isinstance(output_dir, str):\n        output_dir = output_dir.path\n\n    if not isinstance(output_dir, str):\n        raise ValueError(\"The output_dir should be a string path.\")\n\n    if not isinstance(output_dir, str):\n        raise ValueError(\"The output_dir should be a string path.\")\n\n    if chunk_size is None and chunk_bytes is None:\n        raise ValueError(\"Either `chunk_size` or `chunk_bytes` needs to be defined.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \"Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to optimize your data faster \"\n            \"using multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url is not None and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            reader=reader,\n        )\n\n        with optimize_dns_context(True):\n            data_processor.run(\n                LambdaDataChunkRecipe(\n                    fn,\n                    inputs,\n                    chunk_size=chunk_size,\n                    chunk_bytes=chunk_bytes,\n                    compression=compression,\n                )\n            )\n        return None\n    return _execute(\n        f\"data-prep-optimize-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.map", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not isinstance(output_dir, Dir) and not isinstance(output_dir, str):\n        raise ValueError(f\"The provided output_dir should be a string path or a Dir object. Found {output_dir}.\")\n\n    if error_when_not_empty and os.path.exists(output_dir):\n        if len(os.listdir(output_dir)) > 0:\n            raise ValueError(f\"The output directory {output_dir} is not empty.\")\n\n    if not isinstance(output_dir, Dir):\n        output_dir = _resolve_dir(output_dir)\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if chunk_size is None and chunk_bytes is None:\n        raise ValueError(\"Either `chunk_size` or `chunk_bytes` needs to be defined.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \"Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to optimize your data faster \"\n            \"using multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url is not None and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers,\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            reader=reader,\n        )\n\n        with optimize_dns_context(True):\n            data_processor.run(\n                LambdaDataChunkRecipe(\n                    fn,\n                    inputs,\n                    chunk_size=chunk_size,\n                    chunk_bytes=chunk_bytes,\n                    compression=compression,\n                )\n            )\n        return None\n    return _execute(\n        f\"data-prep-optimize-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.map", "completion": "\n    if error_when_not_empty and os.path.exists(output_dir) and os.listdir(output_dir):\n        raise ValueError(\"The output directory is not empty.\")\n\n    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \"Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to optimize your data faster \"\n            \"using multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url is not None and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            reader=reader,\n        )\n\n        with optimize_dns_context(True):\n            data_processor.run(\n                LambdaDataTransformRecipe(\n                    fn,\n                    inputs,\n                )\n            )\n        return None\n    return _execute(\n        f\"data-prep-optimize-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.map", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not isinstance(output_dir, str) and not isinstance(output_dir, Dir):\n        raise ValueError(f\"The output_dir should be a string path or a Dir object. Found {output_dir}.\")\n\n    if error_when_not_empty and os.path.exists(output_dir):\n        if len(os.listdir(output_dir)) > 0:\n            raise ValueError(f\"The output directory {output_dir} is not empty.\")\n\n    if not isinstance(output_dir, Dir) and not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to optimize your data faster \"\n            \"using multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url is not None and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            reader=reader,\n        )\n\n        with optimize_dns_context(True):\n            data_processor.run(\n                LambdaDataTransformRecipe(\n                    fn,\n                    inputs,\n                )\n            )\n        return None\n    return _execute(\n        f\"data-prep-map-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.map", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not isinstance(output_dir, str) and not isinstance(output_dir, Dir):\n        raise ValueError(\"The output_dir should be either a string path or a Dir object.\")\n\n    if isinstance(output_dir, str) and error_when_not_empty and os.path.exists(output_dir) and os.listdir(output_dir):\n        raise ValueError(\"The output directory is not empty and error_when_not_empty is set to True.\")\n\n    if isinstance(output_dir, Dir) and error_when_not_empty and output_dir.url is not None and output_dir.list():\n        raise ValueError(\"The output directory is not empty and error_when_not_empty is set to True.\")\n\n    if isinstance(output_dir, Dir) and output_dir.url is not None and \"cloudspaces\" in output_dir.url:\n        raise ValueError(\n            f\"The provided `output_dir` isn't valid. Found {output_dir.path}.\"\n            \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n        )\n\n    if chunk_size is None and chunk_bytes is None:\n        raise ValueError(\"Either `chunk_size` or `chunk_bytes` needs to be defined.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \"Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to optimize your data faster \"\n            \"using multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            reader=reader,\n        )\n\n        with optimize_dns_context(True):\n            data_processor.run(\n                LambdaDataChunkRecipe(\n                    fn,\n                    inputs,\n                    chunk_size=chunk_size,\n                    chunk_bytes=chunk_bytes,\n                    compression=compression,\n                )\n            )\n        return None\n    return _execute(\n        f\"data-prep-optimize-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        task = queue_in.get()\n        if task is None:\n            return\n\n        index, file_paths = task\n        downloaded_files = []\n\n        for file_path in file_paths:\n            local_file_path = os.path.join(cache_dir, os.path.basename(file_path))\n            if not os.path.exists(local_file_path):\n                # Download the file from the remote directory to the local cache directory\n                # Replace this with the actual download logic based on the source path or URL\n                # Example: download_file_from_remote(input_dir, file_path, local_file_path)\n                print(f\"Downloading {file_path} to {local_file_path}\")\n                # Simulate the download process by copying the file\n                shutil.copy(file_path, local_file_path)\n            downloaded_files.append(local_file_path)\n\n        # Signal completion by putting the task index into the output queue\n        queue_out.put(index)"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "\n    while True:\n        task = queue_in.get()\n        \n        if task is None:\n            return\n\n        index, file_paths = task\n\n        # Check if the files are already downloaded\n        all_files_exist = all([os.path.exists(os.path.join(cache_dir, file_path)) for file_path in file_paths])\n\n        if all_files_exist:\n            queue_out.put(index)  # Signal completion by putting the task index into the output queue\n        else:\n            # Download missing files\n            for file_path in file_paths:\n                source_path = os.path.join(input_dir.path, file_path) if input_dir.path else file_path\n                destination_path = os.path.join(cache_dir, file_path)\n                \n                # Perform the actual download\n                # Example: shutil.copyfile(source_path, destination_path)\n                # Replace the above line with the appropriate download logic\n                \n            queue_out.put(index)  # Signal completion by putting the task index into the output queue"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        # Fetch download tasks from the input queue\n        task = queue_in.get()\n\n        # Terminate the function if None is received, indicating the end of the download tasks\n        if task is None:\n            return\n\n        # Extract the index and file paths from the task\n        index, file_paths = task\n\n        # Download missing files to the local cache directory\n        for file_path in file_paths:\n            local_file_path = os.path.join(cache_dir, os.path.basename(file_path))\n            if not os.path.exists(local_file_path):\n                # Perform the download operation here (code not provided)\n                # Example: download_file(file_path, local_file_path)\n                pass\n\n        # Signal completion by putting the task index into the output queue\n        queue_out.put(index)"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        task = queue_in.get()\n        if task is None:\n            # Terminate the process if we received a termination signal\n            return\n\n        index, file_paths = task\n\n        # Download missing files\n        for file_path in file_paths:\n            local_file_path = os.path.join(cache_dir, os.path.basename(file_path))\n            if not os.path.exists(local_file_path):\n                # Download the file\n                # Add code here to download the file from input_dir to cache_dir\n                pass\n\n        # Signal completion by putting the task index into the output queue\n        queue_out.put(index)"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        # Get the task from the input queue\n        task = queue_in.get()\n\n        # Terminate the process if we received a termination signal\n        if task is None:\n            return\n\n        # Extract the index and file paths from the task\n        index, file_paths = task\n\n        # Download the missing files\n        for file_path in file_paths:\n            local_file_path = os.path.join(cache_dir, os.path.basename(file_path))\n            if not os.path.exists(local_file_path):\n                # Download the file from the source directory to the cache directory\n                # Add code here to download the file from the source directory to the cache directory\n                # For example:\n                # download_file(file_path, local_file_path)\n                pass\n\n        # Signal completion by putting the index into the output queue\n        queue_out.put(index)"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        # Fetch download tasks from the input queue\n        task = queue_in.get()\n        \n        # Terminate the process if we received a termination signal\n        if task is None:\n            return\n        \n        # Extract the index and file paths from the task\n        index, file_paths = task\n        \n        # Download missing files to the local cache directory\n        for file_path in file_paths:\n            local_path = os.path.join(cache_dir, os.path.basename(file_path))\n            if not os.path.exists(local_path):\n                # Perform the download operation\n                # Replace this with the actual download operation\n                # Example: download_file_from_remote(file_path, local_path)\n                print(f\"Downloading {file_path} to {local_path}\")\n        \n        # Signal completion by putting the task index into the output queue\n        queue_out.put(index)"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        task = queue_in.get()\n        if task is None:\n            # Terminate the process if we received a termination signal\n            return\n        index, file_paths = task\n        downloaded_files = []\n        for file_path in file_paths:\n            local_file_path = os.path.join(cache_dir, os.path.basename(file_path))\n            if not os.path.exists(local_file_path):\n                # Download the file if it doesn't already exist in the cache directory\n                # Add code here to download the file from input_dir to cache_dir\n                downloaded_files.append(local_file_path)\n        # Signal completion by putting the task index into the output queue\n        queue_out.put(index)"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        task = queue_in.get()\n        if task is None:\n            return\n\n        index, file_paths = task\n\n        # Check if the files are already downloaded\n        downloaded_files = []\n        for file_path in file_paths:\n            local_file_path = os.path.join(cache_dir, os.path.basename(file_path))\n            if os.path.exists(local_file_path):\n                downloaded_files.append(local_file_path)\n            else:\n                downloaded_files.append(None)\n\n        # Download missing files\n        for i, file_path in enumerate(file_paths):\n            if downloaded_files[i] is None:\n                # Perform the download operation here\n                # Example: download_file(input_dir, file_path, cache_dir)\n                # Replace the download_file function with the actual download operation\n\n                # Simulating the download operation\n                print(f\"Downloading {file_path} to {cache_dir}...\")\n                # Download code goes here\n\n                # Once downloaded, update the downloaded_files list\n                downloaded_files[i] = os.path.join(cache_dir, os.path.basename(file_path))\n\n        # Signal completion by putting the task index into the output queue\n        queue_out.put(index)"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        task = queue_in.get()\n        if task is None:\n            # Terminate the process if we received a termination signal\n            return\n        index, file_paths = task\n        downloaded_files = []\n        for file_path in file_paths:\n            local_file_path = os.path.join(cache_dir, os.path.basename(file_path))\n            if not os.path.exists(local_file_path):\n                # File is not downloaded, download it\n                # Add code to download the file from input_dir to cache_dir\n                # For example:\n                # download_file(input_dir, file_path, cache_dir)\n                downloaded_files.append(local_file_path)\n            else:\n                downloaded_files.append(local_file_path)\n        queue_out.put(index)  # Signal completion by putting the task index into the output queue"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        # Fetch download tasks from the input queue\n        task = queue_in.get()\n\n        # Terminate the process if we received a termination signal\n        if task is None:\n            return\n\n        # Extract the index and file paths from the task\n        index, file_paths = task\n\n        # Download missing files to the local cache directory\n        for file_path in file_paths:\n            local_file_path = os.path.join(cache_dir, os.path.relpath(file_path, input_dir.path))\n            if not os.path.exists(local_file_path):\n                # Download the file from the source directory to the local cache directory\n                download_file(file_path, local_file_path)\n\n        # Signal completion by putting the index into the output queue\n        queue_out.put(index)"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        # Fetch download tasks from the input queue\n        task = queue_in.get()\n\n        # Terminate the process if we received a termination signal\n        if task is None:\n            return\n\n        # Extract the index and file paths from the task\n        index, file_paths = task\n\n        # Check if the files are already downloaded\n        all_files_exist = all(os.path.exists(os.path.join(cache_dir, file_path)) for file_path in file_paths)\n\n        if all_files_exist:\n            # If all files are already downloaded, signal completion by putting the index into the output queue\n            queue_out.put(index)\n        else:\n            # If files are missing, download the missing files\n            for file_path in file_paths:\n                source_path = os.path.join(input_dir.path, file_path) if input_dir.path else file_path\n                destination_path = os.path.join(cache_dir, file_path)\n\n                # Download the file from the source path to the destination path\n                # (Code for downloading the file is not provided and should be added here)\n\n            # Signal completion by putting the index into the output queue\n            queue_out.put(index)"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "\n    while True:\n        task = queue_in.get()\n        if task is None:\n            return\n\n        index, file_paths = task\n        completed = []\n\n        for file_path in file_paths:\n            local_file_path = os.path.join(cache_dir, os.path.basename(file_path))\n            if not os.path.exists(local_file_path):\n                # Download the file\n                # Replace this with actual download code\n                # Example: download_file_from_remote(file_path, local_file_path)\n                print(f\"Downloading {file_path} to {local_file_path}\")\n\n            completed.append(file_path)\n\n        queue_out.put(index)"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        # Fetch download tasks from the input queue\n        task = queue_in.get()\n        \n        # Terminate the process if we received a termination signal\n        if task is None:\n            return\n        \n        # Extract the index and file paths from the task\n        index, file_paths = task\n        \n        # Download missing files\n        for file_path in file_paths:\n            local_file_path = os.path.join(cache_dir, os.path.relpath(file_path, input_dir.path))\n            if not os.path.exists(local_file_path):\n                # Download the file from the remote directory to the local cache directory\n                download_file(file_path, local_file_path)\n        \n        # Signal completion by putting the task index into the output queue\n        queue_out.put(index)"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        # Fetch download tasks from the input queue\n        task = queue_in.get()\n\n        # Terminate the process if we received a termination signal\n        if task is None:\n            return\n\n        # Extract the index and file paths from the task\n        index, file_paths = task\n\n        # Download missing files and check if files are already downloaded\n        downloaded_files = []\n        for file_path in file_paths:\n            # Check if the file is already downloaded\n            if not os.path.exists(os.path.join(cache_dir, file_path)):\n                # Download the missing file\n                # Replace the source path with the cache directory in the file path\n                source_path = os.path.join(input_dir.path, file_path)\n                destination_path = os.path.join(cache_dir, file_path)\n                # Perform the download operation (e.g., using urllib or other appropriate library)\n                # Example: urllib.request.urlretrieve(source_path, destination_path)\n                # After downloading, add the file to the list of downloaded files\n                downloaded_files.append(file_path)\n\n        # Put the index of the completed download task into the output queue\n        queue_out.put(index)"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        task = queue_in.get()\n        if task is None:\n            return\n\n        index, files = task\n        downloaded_files = []\n\n        for file in files:\n            destination = os.path.join(cache_dir, file)\n            if not os.path.exists(destination):\n                if input_dir.url:\n                    # Download file from remote source to local cache directory\n                    # Example code for downloading file from remote source to local cache directory\n                    # download_file(input_dir.url, file, destination)\n                    pass\n                else:\n                    # Copy file from source directory to local cache directory\n                    # Example code for copying file from source directory to local cache directory\n                    # shutil.copyfile(os.path.join(input_dir.path, file), destination)\n                    pass\n            downloaded_files.append(destination)\n\n        queue_out.put(index)"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        task = queue_in.get()\n        if task is None:\n            return\n        index, file_paths = task\n        downloaded_files = []\n        for file_path in file_paths:\n            destination_path = os.path.join(cache_dir, os.path.basename(file_path))\n            if not os.path.exists(destination_path):\n                # Download the file from the source directory to the cache directory\n                # Code to download the file goes here\n                # For example:\n                # download_file(input_dir, file_path, destination_path)\n                downloaded_files.append(destination_path)\n        queue_out.put(index)"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "\n    while True:\n        task = queue_in.get()\n\n        if task is None:\n            queue_out.put(None)\n            return\n\n        index, file_paths = task\n\n        # Download missing files\n        for file_path in file_paths:\n            destination_path = os.path.join(cache_dir, file_path)\n            if not os.path.exists(destination_path):\n                # Perform the download operation here\n                # Example: download_file(input_dir, file_path, destination_path)\n\n        queue_out.put(index)"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        task = queue_in.get()\n        if task is None:\n            return  # Terminate the function if a termination signal is received\n\n        index, file_paths = task\n        completed = []\n\n        for file_path in file_paths:\n            destination_path = os.path.join(cache_dir, os.path.basename(file_path))\n            if not os.path.exists(destination_path):\n                # File is not downloaded, download it\n                if input_dir.url:\n                    # Download from remote source\n                    # Add code to download the file from the remote source to the local cache directory\n                    # Example:\n                    # download_file(input_dir.url + file_path, destination_path)\n                    pass\n                else:\n                    # Copy from local source\n                    shutil.copyfile(file_path, destination_path)\n            completed.append(file_path)\n\n        queue_out.put(index)  # Signal completion by putting the task index into the output queue"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        task = queue_in.get()\n        if task is None:\n            return\n\n        index, file_paths = task\n        downloaded_files = []\n\n        for file_path in file_paths:\n            destination_path = os.path.join(cache_dir, os.path.basename(file_path))\n\n            if os.path.exists(destination_path):\n                downloaded_files.append(file_path)\n            else:\n                # Download the file from the input_dir to the cache_dir\n                # Add the downloaded file to the list of downloaded_files\n                downloaded_files.append(file_path)\n\n        # Signal completion by putting the task index into the output queue\n        queue_out.put(index)"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        task = queue_in.get()\n        if task is None:\n            return\n\n        index, file_paths = task\n        downloaded_files = []\n\n        for file_path in file_paths:\n            destination_path = os.path.join(cache_dir, os.path.basename(file_path))\n            if not os.path.exists(destination_path):\n                # Download the file\n                # Replace the following line with the code to download the file from input_dir to cache_dir\n                # Example: download_file(input_dir, file_path, cache_dir)\n                downloaded_files.append(destination_path)\n\n        queue_out.put(index)"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "\n    while True:\n        # 1. Fetch from the queue\n        data = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if data is None:\n            return\n\n        # 3. Upload the data to the output directory\n        if isinstance(data, tuple):\n            temp_dir, file_path = data\n            if output_dir.url:\n                # Upload to S3\n                # Implement the S3 upload logic here\n                pass\n            else:\n                # Move file within the local filesystem\n                # Implement the local file move logic here\n                pass\n            # Add file path to remove_queue for removal after successful upload\n            remove_queue.put(file_path)\n\n        else:\n            if output_dir.url:\n                # Upload to S3\n                # Implement the S3 upload logic here\n                pass\n            else:\n                # Move file within the local filesystem\n                # Implement the local file move logic here\n                pass\n            # Add file path to remove_queue for removal after successful upload\n            remove_queue.put(data)"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "\n    while True:\n        # 1. Get the item from the upload queue\n        item = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if item is None:\n            return\n\n        # 3. Upload the item to the output directory\n        if isinstance(item, str):\n            if output_dir.url:\n                # Upload to S3\n                # Implement S3 upload logic here\n                pass\n            else:\n                # Move file within the local filesystem\n                # Implement local file move logic here\n                pass\n        elif isinstance(item, tuple):\n            temp_dir, file_path = item\n            if output_dir.url:\n                # Upload to S3\n                # Implement S3 upload logic here\n                pass\n            else:\n                # Move file within the local filesystem\n                # Implement local file move logic here\n                pass\n\n        # 4. Send the file path to the remove queue for removal after successful upload\n        remove_queue.put(item)"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    while True:\n        item = upload_queue.get()\n        if item is None:\n            # Terminate the process if we received a termination signal\n            return\n        if isinstance(item, str):\n            # Upload the file to the output directory\n            if output_dir.url:\n                # Upload to S3 if the output directory is an S3 bucket\n                s3 = S3Client()\n                s3.client.upload_file(item, output_dir.bucket, output_dir.key)\n            else:\n                # Move the file within the local filesystem\n                shutil.move(item, output_dir.path)\n            # Send the file path to the remove queue for removal\n            remove_queue.put(item)\n        elif isinstance(item, tuple) and len(item) == 2:\n            # Upload the file from the temporary directory to the output directory\n            temp_dir, file_path = item\n            if output_dir.url:\n                # Upload to S3 if the output directory is an S3 bucket\n                s3 = S3Client()\n                s3.client.upload_file(file_path, output_dir.bucket, output_dir.key)\n            else:\n                # Move the file within the local filesystem\n                shutil.move(file_path, output_dir.path)\n            # Send the file path to the remove queue for removal\n            remove_queue.put(file_path)\n            # Remove the temporary directory\n            shutil.rmtree(temp_dir)"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    while True:\n        item = upload_queue.get()\n        if item is None:\n            # Terminate the function if a termination signal is received\n            return\n        if isinstance(item, tuple):\n            # If the item is a tuple, it contains a temporary directory and a file path\n            temp_dir, file_path = item\n            if output_dir.url:\n                # If the output directory is an S3 bucket, upload the file to the bucket\n                s3 = S3Client()\n                s3.client.upload_file(file_path, output_dir.url, file_path.replace(temp_dir, \"\"))\n            else:\n                # If the output directory is a local directory, move the file to the directory\n                shutil.move(file_path, output_dir.path)\n            # Send the file path to the remove queue for removal after successful upload\n            remove_queue.put(file_path)\n        else:\n            # If the item is a file path, check the output directory scheme and perform the corresponding action\n            if output_dir.url:\n                # If the output directory is an S3 bucket, upload the file to the bucket\n                s3 = S3Client()\n                s3.client.upload_file(item, output_dir.url, item.replace(cache_dir, \"\"))\n            else:\n                # If the output directory is a local directory, move the file to the directory\n                shutil.move(item, output_dir.path)\n            # Send the file path to the remove queue for removal after successful upload\n            remove_queue.put(item)"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "\n    while True:\n        data = upload_queue.get()\n        if data is None:\n            break\n\n        if isinstance(data, tuple):\n            temp_dir, file_path = data\n            output_path = os.path.join(output_dir.path, os.path.relpath(file_path, temp_dir))\n            shutil.move(file_path, output_path)\n            shutil.rmtree(temp_dir, ignore_errors=True)\n        else:\n            output_path = os.path.join(output_dir.path, os.path.relpath(data, cache_dir))\n            if output_dir.url:\n                # Upload to S3\n                s3 = S3Client()\n                s3.client.upload_file(data, output_dir.netloc, output_path.lstrip(\"/\"))\n            else:\n                # Move within the local filesystem\n                shutil.move(data, output_path)\n\n        remove_queue.put(output_path)"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "\n    while True:\n        # 1. Fetch from the queue\n        data = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if data is None:\n            return\n\n        # 3. Upload the data to the output directory\n        if isinstance(data, str):\n            # Handle file path\n            if output_dir.url:\n                # Upload to S3\n                # Implement S3 upload logic here\n                pass\n            else:\n                # Move file within the local filesystem\n                # Implement local file move logic here\n                pass\n        elif isinstance(data, tuple) and len(data) == 2:\n            temp_dir, file_path = data\n            if output_dir.url:\n                # Upload to S3\n                # Implement S3 upload logic here\n                pass\n            else:\n                # Move file within the local filesystem\n                # Implement local file move logic here\n                pass\n\n        # 4. Send the file path to the remove queue for removal after successful upload\n        remove_queue.put(data)"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "\n    while True:\n        item = upload_queue.get()\n        if item is None:\n            break  # Terminate the function if a termination signal is received\n\n        if isinstance(item, str):\n            file_path = item\n            if output_dir.url:  # Check if the output directory is an S3 bucket\n                # Upload the file to the S3 bucket\n                s3_client = S3Client()\n                s3_client.upload_file(file_path, output_dir.url, os.path.relpath(file_path, cache_dir))\n            else:\n                # Move the file within the local filesystem\n                shutil.move(file_path, os.path.join(output_dir.path, os.path.basename(file_path)))\n            remove_queue.put(file_path)  # Send the file path to the remove_queue for removal\n        elif isinstance(item, tuple):\n            temp_dir, file_path = item\n            if output_dir.url:  # Check if the output directory is an S3 bucket\n                # Upload the file to the S3 bucket\n                s3_client = S3Client()\n                s3_client.upload_file(file_path, output_dir.url, os.path.relpath(file_path, cache_dir))\n            else:\n                # Move the file within the local filesystem\n                shutil.move(file_path, os.path.join(output_dir.path, os.path.basename(file_path)))\n            remove_queue.put(temp_dir)  # Send the temporary directory to the remove_queue for removal"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    while True:\n        item = upload_queue.get()\n        if item is None:\n            # Termination signal received\n            return\n\n        if isinstance(item, tuple):\n            # Item is a tuple containing a temporary directory and a file path\n            temp_dir, file_path = item\n            if output_dir.url:\n                # Upload to S3 bucket\n                s3 = S3Client()\n                s3.client.upload_file(file_path, output_dir.url, file_path.replace(temp_dir, \"\").lstrip(\"/\"))\n            else:\n                # Move file within the local filesystem\n                shutil.move(file_path, file_path.replace(temp_dir, output_dir.path, 1))\n            remove_queue.put(file_path)  # Send file path for removal after successful upload\n        else:\n            if output_dir.url:\n                # Upload to S3 bucket\n                s3 = S3Client()\n                s3.client.upload_file(item, output_dir.url, item.replace(cache_dir, \"\").lstrip(\"/\"))\n            else:\n                # Move file within the local filesystem\n                shutil.move(item, item.replace(cache_dir, output_dir.path, 1))\n            remove_queue.put(item)  # Send file path for removal after successful upload"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    while True:\n        # Get the item from the upload queue\n        item = upload_queue.get()\n\n        # Check for termination signal\n        if item is None:\n            break\n\n        # Upload the item to the output directory\n        if isinstance(item, str):\n            # If the item is a file path, upload it to the output directory\n            if output_dir.url:\n                # Upload to S3 if the output directory is an S3 bucket\n                s3 = S3Client()\n                s3.upload_file(item, output_dir.url, remove_original=True)\n            else:\n                # Move the file within the local filesystem\n                shutil.move(item, output_dir.path)\n        elif isinstance(item, tuple) and len(item) == 2:\n            # If the item is a tuple containing a temporary directory and a file path, upload the file to the output directory\n            temp_dir, file_path = item\n            if output_dir.url:\n                # Upload to S3 if the output directory is an S3 bucket\n                s3 = S3Client()\n                s3.upload_file(file_path, output_dir.url, remove_original=True)\n            else:\n                # Move the file within the local filesystem\n                shutil.move(file_path, output_dir.path)\n\n        # Send the file path to the remove queue for removal\n        remove_queue.put(item)"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "\n    while True:\n        # 1. Fetch from the queue\n        data = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if data is None:\n            return\n\n        # 3. Upload the file to the output directory\n        if isinstance(data, str):\n            file_path = data\n            if output_dir.url:\n                # Upload to S3\n                # Implement S3 upload logic here\n                pass\n            else:\n                # Move within the local filesystem\n                # Implement local filesystem move logic here\n                pass\n        elif isinstance(data, tuple) and len(data) == 2:\n            temp_dir, file_path = data\n            if output_dir.url:\n                # Upload to S3\n                # Implement S3 upload logic here\n                pass\n            else:\n                # Move within the local filesystem\n                # Implement local filesystem move logic here\n                pass\n\n        # 4. Send the file path to the remove queue for removal after successful upload\n        remove_queue.put(file_path)"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "\n    while True:\n        item = upload_queue.get()\n        if item is None:\n            break  # Terminate the function if a termination signal is received\n\n        if isinstance(item, tuple):\n            temp_dir, file_path = item\n            output_path = os.path.join(output_dir.path, os.path.relpath(file_path, temp_dir))\n            os.makedirs(os.path.dirname(output_path), exist_ok=True)\n            shutil.move(file_path, output_path)\n        else:\n            output_path = os.path.join(output_dir.path, os.path.relpath(item, cache_dir))\n            os.makedirs(os.path.dirname(output_path), exist_ok=True)\n            shutil.move(item, output_path)\n\n        remove_queue.put(output_path)  # Send the file path to the remove queue for removal after successful upload"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    while True:\n        item = upload_queue.get()\n        if item is None:\n            break\n        if isinstance(item, tuple):\n            temp_dir, file_path = item\n            if output_dir.url:\n                # Upload to S3\n                s3 = S3Client()\n                s3.client.upload_file(file_path, output_dir.url, file_path.replace(temp_dir, \"\"))\n            else:\n                # Move within the local filesystem\n                shutil.move(file_path, file_path.replace(temp_dir, output_dir.path))\n            remove_queue.put(file_path)\n        else:\n            if output_dir.url:\n                # Upload to S3\n                s3 = S3Client()\n                s3.client.upload_file(item, output_dir.url, item.replace(cache_dir, \"\"))\n            else:\n                # Move within the local filesystem\n                shutil.move(item, item.replace(cache_dir, output_dir.path))\n            remove_queue.put(item)"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "\n    while True:\n        item = upload_queue.get()\n        if item is None:\n            break  # Terminate the function if a termination signal is received\n\n        if isinstance(item, tuple):\n            temp_dir, file_path = item\n            if output_dir.url:\n                # Upload to S3\n                s3_client = S3Client()\n                s3_client.upload_file(file_path, output_dir.url, file_path.replace(temp_dir, \"\"))\n            else:\n                # Move within the local filesystem\n                shutil.move(file_path, file_path.replace(temp_dir, output_dir.path))\n        else:\n            if output_dir.url:\n                # Upload to S3\n                s3_client = S3Client()\n                s3_client.upload_file(item, output_dir.url, item.replace(cache_dir, \"\"))\n            else:\n                # Move within the local filesystem\n                shutil.move(item, item.replace(cache_dir, output_dir.path))\n\n        # Send the file path to the remove_queue for removal after successful upload\n        remove_queue.put(item)"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    while True:\n        item = upload_queue.get()\n        if item is None:\n            return  # Terminate the function\n\n        if isinstance(item, tuple):\n            temp_dir, file_path = item\n            if output_dir.url:\n                # Upload to S3\n                s3 = S3Client()\n                s3.client.upload_file(file_path, output_dir.url, file_path.replace(temp_dir, \"\"))\n            else:\n                # Move file within the local filesystem\n                shutil.move(file_path, file_path.replace(temp_dir, output_dir.path))\n        else:\n            if output_dir.url:\n                # Upload to S3\n                s3 = S3Client()\n                s3.client.upload_file(item, output_dir.url, item.replace(cache_dir, \"\"))\n            else:\n                # Move file within the local filesystem\n                shutil.move(item, item.replace(cache_dir, output_dir.path))\n\n        remove_queue.put(item)  # Signal that the file can be removed from the cache"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    while True:\n        item = upload_queue.get()\n        if item is None:\n            break  # Terminate the function if a termination signal is received\n\n        # Upload the item to the output directory\n        if isinstance(item, tuple):\n            # If the item is a tuple containing a temporary directory and a file path\n            temp_dir, file_path = item\n            if output_dir.url:\n                # If the output directory is an S3 bucket\n                s3_client = S3Client()\n                s3_client.upload_file(file_path, output_dir.url, os.path.relpath(file_path, temp_dir))\n            else:\n                # If the output directory is a local directory\n                shutil.move(file_path, os.path.join(output_dir.path, os.path.basename(file_path)))\n        else:\n            # If the item is a file path\n            if output_dir.url:\n                # If the output directory is an S3 bucket\n                s3_client = S3Client()\n                s3_client.upload_file(item, output_dir.url, os.path.basename(item))\n            else:\n                # If the output directory is a local directory\n                shutil.move(item, os.path.join(output_dir.path, os.path.basename(item)))\n\n        # Send the file path to the remove queue for removal after successful upload\n        remove_queue.put(item)"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "\n    while True:\n        data = upload_queue.get()\n        if data is None:\n            break  # Terminate the function if a termination signal is received\n\n        if isinstance(data, tuple):\n            temp_dir, file_path = data\n            if output_dir.url:\n                # Upload to S3\n                s3_client = S3Client()\n                s3_client.upload_file(file_path, output_dir.url, Path(file_path).name)\n            else:\n                # Move the file within the local filesystem\n                shutil.move(file_path, output_dir.path)\n            remove_queue.put(temp_dir)  # Send the temporary directory for removal\n        else:\n            if output_dir.url:\n                # Upload to S3\n                s3_client = S3Client()\n                s3_client.upload_file(data, output_dir.url, Path(data).name)\n            else:\n                # Move the file within the local filesystem\n                shutil.move(data, output_dir.path)\n            remove_queue.put(data)  # Send the file path for removal"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    while True:\n        # 1. Fetch from the queue\n        data = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if data is None:\n            return\n\n        # 3. Upload the data to the output directory\n        if isinstance(data, str):\n            # Single file upload\n            if output_dir.url:\n                # Upload to S3\n                s3 = S3Client()\n                s3.client.upload_file(data, output_dir.netloc, output_dir.path.lstrip(\"/\"))\n            else:\n                # Move file within the local filesystem\n                shutil.move(data, output_dir.path)\n        elif isinstance(data, tuple) and len(data) == 2:\n            # Temporary directory and file path upload\n            temp_dir, file_path = data\n            if output_dir.url:\n                # Upload to S3\n                s3 = S3Client()\n                s3.client.upload_file(file_path, output_dir.netloc, output_dir.path.lstrip(\"/\"))\n            else:\n                # Move file within the local filesystem\n                shutil.move(file_path, output_dir.path)\n\n            # Cleanup the temporary directory\n            shutil.rmtree(temp_dir, ignore_errors=True)\n\n        # 4. Inform the remove queue that the file has been successfully uploaded\n        remove_queue.put(data)"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        data = upload_queue.get()\n        if data is None:\n            return\n\n        if isinstance(data, tuple):\n            temp_dir, file_path = data\n            if output_dir.url:\n                s3.client.upload_file(file_path, output_dir.url, file_path.replace(temp_dir, \"\"))\n            else:\n                shutil.move(file_path, file_path.replace(temp_dir, output_dir.path))\n            remove_queue.put(file_path)\n        else:\n            if output_dir.url:\n                s3.client.upload_file(data, output_dir.url, os.path.basename(data))\n            else:\n                shutil.move(data, os.path.join(output_dir.path, os.path.basename(data)))\n            remove_queue.put(data)"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    while True:\n        # 1. Fetch from the queue\n        data = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if data is None:\n            return\n\n        # 3. Upload the data to the output directory\n        if isinstance(data, tuple):\n            temp_dir, file_path = data\n            if output_dir.url:\n                # Upload to S3\n                s3 = S3Client()\n                s3.client.upload_file(file_path, output_dir.netloc, output_dir.path.lstrip(\"/\"))\n            else:\n                # Move within the local filesystem\n                shutil.move(file_path, output_dir.path)\n            # Send the file path to remove_queue for removal\n            remove_queue.put(file_path)\n            # Clean up the temporary directory\n            shutil.rmtree(temp_dir, ignore_errors=True)\n        else:\n            if output_dir.url:\n                # Upload to S3\n                s3 = S3Client()\n                s3.client.upload_file(data, output_dir.netloc, output_dir.path.lstrip(\"/\"))\n            else:\n                # Move within the local filesystem\n                shutil.move(data, output_dir.path)\n            # Send the file path to remove_queue for removal\n            remove_queue.put(data)"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    while True:\n        # 1. Fetch from the queue\n        data = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if data is None:\n            return\n\n        # 3. Upload the data to the output directory\n        if isinstance(data, tuple):\n            temp_dir, file_path = data\n            if output_dir.url:\n                # Upload to S3\n                s3 = S3Client()\n                s3.upload_file(file_path, output_dir.url, os.path.relpath(file_path, temp_dir))\n            else:\n                # Move file within the local filesystem\n                shutil.move(file_path, os.path.join(output_dir.path, os.path.basename(file_path)))\n        else:\n            if output_dir.url:\n                # Upload to S3\n                s3 = S3Client()\n                s3.upload_file(data, output_dir.url, os.path.basename(data))\n            else:\n                # Move file within the local filesystem\n                shutil.move(data, os.path.join(output_dir.path, os.path.basename(data)))\n\n        # 4. Inform the remove queue that the file has been successfully uploaded\n        remove_queue.put(data)"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "\n    # Calculate the total weight\n    total_weight = sum(weights) if weights else len(user_items)\n\n    # Calculate the number of nodes\n    num_nodes = _get_num_nodes()\n\n    # Calculate the world size\n    world_size = num_nodes * num_workers\n\n    # Calculate the number of items per worker\n    num_items_per_worker = [int((w / total_weight) * len(user_items)) for w in weights] if weights else [len(user_items) // world_size] * world_size\n\n    # Distribute the remaining items to the workers\n    remainder = len(user_items) % world_size\n    for i in range(remainder):\n        num_items_per_worker[i] += 1\n\n    # Create a list to store the items for each worker\n    items_per_worker = []\n\n    # Initialize the start index for slicing the user_items list\n    start_index = 0\n\n    # Distribute the items to the workers\n    for i in range(world_size):\n        end_index = start_index + num_items_per_worker[i]\n        items_per_worker.append(user_items[start_index:end_index])\n        start_index = end_index\n\n    # Shuffle the items for each worker\n    for i in range(world_size):\n        random.shuffle(items_per_worker[i])\n\n    return items_per_worker"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "\n    total_workers = _get_num_nodes() * num_workers\n\n    if weights is None:\n        weights = [1] * len(user_items)\n\n    total_weight = sum(weights)\n\n    items_per_worker = [0] * total_workers\n    items_assigned = [0] * total_workers\n\n    for idx, weight in enumerate(weights):\n        items_per_worker[idx % total_workers] += weight\n\n    if file_size:\n        print(\"Distribution of items per worker based on file sizes (in MB):\")\n        for i in range(total_workers):\n            print(f\"Worker {i}: {items_per_worker[i] / (1024 * 1024):.2f} MB\")\n    else:\n        print(\"Distribution of items per worker based on weights:\")\n        for i in range(total_workers):\n            print(f\"Worker {i}: {items_per_worker[i]}\")\n\n    shuffled_user_items = random.sample(user_items, len(user_items))\n\n    workers_user_items = [[] for _ in range(total_workers)]\n\n    for item in shuffled_user_items:\n        min_worker = items_assigned.index(min(items_assigned))\n        workers_user_items[min_worker].append(item)\n        items_assigned[min_worker] += weights[shuffled_user_items.index(item)]\n\n    return workers_user_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "\n    # Calculate the total weight\n    total_weight = sum(weights) if weights else len(user_items)\n\n    # Calculate the weight per worker\n    weight_per_worker = total_weight / num_workers\n\n    # Initialize variables to track the weight assigned to each worker\n    current_weight = 0\n    worker_weights = [0] * num_workers\n\n    # Create a list to hold the items assigned to each worker\n    worker_items = [[] for _ in range(num_workers)]\n\n    # Iterate through the items and assign them to workers based on their weights\n    for i, item in enumerate(user_items):\n        if weights:\n            current_weight += weights[i]\n        else:\n            current_weight += 1\n\n        # Find the worker to assign the item to\n        worker_index = int(current_weight // weight_per_worker)\n\n        # Ensure the worker index is within the valid range\n        worker_index = min(worker_index, num_workers - 1)\n\n        # Assign the item to the corresponding worker\n        worker_items[worker_index].append(item)\n\n        # Update the weight assigned to the worker\n        worker_weights[worker_index] += weights[i] if weights else 1\n\n    # Print the distribution details\n    print(\"Worker distribution details:\")\n    for i in range(num_workers):\n        if file_size:\n            print(f\"Worker {i + 1}: {len(worker_items[i])} items, total weight: {worker_weights[i]}\")\n        else:\n            print(f\"Worker {i + 1}: {len(worker_items[i])} items, total weight: {worker_weights[i]}\")\n\n    # Shuffle the items for each worker\n    for i in range(num_workers):\n        random.shuffle(worker_items[i])\n\n    return worker_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "\n    # Calculate the total weight\n    total_weight = sum(weights) if weights else len(user_items)\n\n    # Calculate the weight per worker\n    weight_per_worker = total_weight / (num_workers)\n\n    # Initialize variables to keep track of the assigned weight and items\n    assigned_weight = 0\n    assigned_items = []\n    workers_items = []\n\n    # Iterate through the user_items and distribute them to workers based on weights\n    for item, weight in zip(user_items, weights):\n        # If the assigned weight exceeds the weight per worker, start a new worker\n        if assigned_weight >= weight_per_worker:\n            workers_items.append(assigned_items)\n            assigned_items = []\n            assigned_weight = 0\n\n        assigned_items.append(item)\n        assigned_weight += weight\n\n    # Add the remaining items to the last worker\n    workers_items.append(assigned_items)\n\n    # Shuffle the items within each worker\n    for items in workers_items:\n        random.shuffle(items)\n\n    return workers_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    if weights is None:\n        weights = [1] * len(user_items)\n\n    total_weight = sum(weights)\n    cumulative_weights = [sum(weights[:i + 1]) for i in range(len(weights))]\n    total_workers = num_workers * _get_num_nodes()\n\n    worker_items = [[] for _ in range(total_workers)]\n\n    for idx, item in enumerate(user_items):\n        weight = weights[idx]\n        num_assigned_workers = int(weight / total_weight * total_workers)\n        if num_assigned_workers == 0:\n            num_assigned_workers = 1\n        for _ in range(num_assigned_workers):\n            worker_idx = random.choice(range(total_workers))\n            worker_items[worker_idx].append(item)\n\n    for items in worker_items:\n        random.shuffle(items)\n\n    return worker_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "\n    total_workers = _get_num_nodes() * num_workers\n\n    if weights is None:\n        weights = [1] * len(user_items)\n\n    total_weight = sum(weights)\n    items_per_worker = [int(weight / total_weight * len(user_items)) for weight in weights]\n\n    remainder = len(user_items) - sum(items_per_worker)\n    if remainder > 0:\n        # Distribute the remainder items to the workers based on the weights\n        remaining_weights = [(weights[i], i) for i in range(len(user_items))]\n        remaining_weights.sort(reverse=True)\n\n        for i in range(remainder):\n            items_per_worker[remaining_weights[i][1]] += 1\n\n    items_assigned = 0\n    worker_items = []\n\n    for i in range(total_workers):\n        start_index = items_assigned\n        end_index = min(items_assigned + items_per_worker[i], len(user_items))\n        worker_items.append(user_items[start_index:end_index])\n        items_assigned += items_per_worker[i]\n\n    for i in range(total_workers):\n        random.shuffle(worker_items[i])\n\n    return worker_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "\n    # Calculate the total weight\n    total_weight = sum(weights) if weights else len(user_items)\n\n    # Calculate the weight per worker\n    weight_per_worker = total_weight / (num_workers)\n\n    # Initialize variables to track the distribution\n    current_weight = 0\n    worker_items = [[] for _ in range(num_workers)]\n\n    # Distribute the items to workers based on weights\n    for index, item in enumerate(user_items):\n        if weights:\n            current_weight += weights[index]\n        else:\n            current_weight += 1\n\n        # Find the worker to assign the item to\n        worker_index = min(int(current_weight // weight_per_worker), num_workers - 1)\n\n        # Add the item to the corresponding worker's list\n        worker_items[worker_index].append(item)\n\n    # Shuffle the items in each worker's list\n    for items in worker_items:\n        random.shuffle(items)\n\n    return worker_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "\n    # Calculate the total weight of all items\n    total_weight = sum(weights) if weights else len(user_items)\n\n    # Calculate the weight per worker\n    weight_per_worker = total_weight / (num_workers * _get_num_nodes())\n\n    # Create a list to store the items assigned to each worker\n    assigned_items = [[] for _ in range(num_workers)]\n\n    # Assign items to workers based on their weights\n    cumulative_weight = 0\n    worker_index = 0\n    for i, item in enumerate(user_items):\n        # Calculate the cumulative weight\n        cumulative_weight += weights[i] if weights else 1\n\n        # Assign the item to the current worker\n        assigned_items[worker_index].append(item)\n\n        # If the cumulative weight exceeds the target weight per worker, move to the next worker\n        if cumulative_weight >= weight_per_worker:\n            worker_index = (worker_index + 1) % num_workers\n            cumulative_weight = 0\n\n    # Shuffle the assigned items for each worker\n    for items in assigned_items:\n        random.shuffle(items)\n\n    return assigned_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "\n    # Calculate total weight\n    total_weight = sum(weights) if weights else len(user_items)\n\n    # Calculate the number of items per worker based on weights\n    items_per_worker = [int((w / total_weight) * len(user_items)) if weights else len(user_items) // num_workers for w in weights]\n\n    # Calculate the remainder for distribution\n    remainder = len(user_items) % num_workers\n\n    # Distribute items to workers based on weights\n    distributed_items = []\n    start = 0\n    for i in range(num_workers):\n        end = start + items_per_worker[i]\n        if remainder > 0:\n            end += 1\n            remainder -= 1\n        distributed_items.append(user_items[start:end])\n        start = end\n\n    # Shuffle the items within each worker's list\n    for items in distributed_items:\n        random.shuffle(items)\n\n    return distributed_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    if weights is None:\n        weights = [1] * len(user_items)\n\n    total_weight = sum(weights)\n    total_workers = num_workers * _get_num_nodes()\n    items_per_worker = [0] * total_workers\n\n    for i, item in enumerate(user_items):\n        worker_index = i % total_workers\n        items_per_worker[worker_index] += weights[i]\n\n    avg_items_per_worker = total_weight / total_workers\n\n    if file_size:\n        print(\"Items distribution per worker (in MB):\")\n        for i in range(total_workers):\n            print(f\"Worker {i}: {items_per_worker[i] / (1024 * 1024):.2f} MB\")\n    else:\n        print(\"Items distribution per worker (weighted):\")\n        for i in range(total_workers):\n            print(f\"Worker {i}: {items_per_worker[i]}\")\n\n    # Shuffle the items and distribute them to workers\n    items_with_index = list(enumerate(user_items))\n    random.shuffle(items_with_index)\n\n    workers_items = [[] for _ in range(total_workers)]\n\n    for index, item in items_with_index:\n        worker_index = index % total_workers\n        workers_items[worker_index].append(item)\n\n    return workers_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "\n    # Calculate the total weight of items\n    total_weight = sum(weights) if weights else len(user_items)\n\n    # Calculate the weight per worker\n    weight_per_worker = total_weight // (num_workers * _get_num_nodes())\n\n    # Initialize the lists to store items for each worker\n    workers_items = [[] for _ in range(num_workers)]\n\n    # Assign items to workers based on weights\n    for i, item in enumerate(user_items):\n        if weights:\n            item_weight = weights[i]\n        else:\n            item_weight = 1\n\n        # Distribute the item to workers based on its weight\n        for j in range(num_workers):\n            if item_weight >= weight_per_worker:\n                workers_items[j].append(item)\n                item_weight -= weight_per_worker\n            else:\n                break\n\n    # Shuffle the items for each worker\n    for i in range(num_workers):\n        random.shuffle(workers_items[i])\n\n    # Print the distribution details\n    if file_size:\n        print(f\"Total size of items: {total_weight} MB\")\n        print(f\"Size per worker: {weight_per_worker} MB\")\n    else:\n        print(f\"Total weight of items: {total_weight}\")\n        print(f\"Weight per worker: {weight_per_worker}\")\n\n    return workers_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "\n    num_nodes = _get_num_nodes()\n    world_size = num_nodes * num_workers\n\n    if weights is None:\n        weights = [1] * len(user_items)\n\n    total_weight = sum(weights)\n    items_per_worker = [0] * world_size\n\n    for i, weight in enumerate(weights):\n        items_per_worker[i % world_size] += weight\n\n    if file_size:\n        print(\"Distribution of items to workers based on file sizes (in MB):\")\n        for i in range(world_size):\n            print(f\"Worker {i}: {items_per_worker[i]} items, {items_per_worker[i] / (1024 * 1024)} MB\")\n    else:\n        print(\"Distribution of items to workers based on weights:\")\n        for i in range(world_size):\n            print(f\"Worker {i}: {items_per_worker[i]} items, {items_per_worker[i] / total_weight * 100}%\")\n\n    # Shuffle the items for each worker\n    items_assigned = [[] for _ in range(world_size)]\n    for i, item in enumerate(user_items):\n        items_assigned[i % world_size].append(item)\n\n    for i in range(world_size):\n        random.shuffle(items_assigned[i])\n\n    return items_assigned"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "\n    # Calculate the total weight of items\n    total_weight = sum(weights) if weights else len(user_items)\n\n    # Calculate the weight per worker\n    weight_per_worker = total_weight // (num_workers)\n\n    # Create a list to store items for each worker\n    workers_items = [[] for _ in range(num_workers)]\n\n    # Assign items to workers based on weights\n    current_worker = 0\n    current_weight = 0\n    for i, item in enumerate(user_items):\n        if weights:\n            current_weight += weights[i]\n        else:\n            current_weight += 1\n\n        # If the current weight exceeds the weight per worker, move to the next worker\n        if current_weight > weight_per_worker and current_worker < num_workers - 1:\n            current_worker += 1\n            current_weight = 0\n\n        # Add the item to the list of items for the current worker\n        workers_items[current_worker].append(item)\n\n    # Shuffle the items for each worker\n    for items in workers_items:\n        random.shuffle(items)\n\n    # Print the distribution details\n    print(\"Distribution of items to workers:\")\n    for i, items in enumerate(workers_items):\n        if file_size:\n            total_size = sum(weights[j] for j in items) if weights else len(items)\n            print(f\"Worker {i + 1}: {len(items)} items, total size: {total_size} MB\")\n        else:\n            print(f\"Worker {i + 1}: {len(items)} items\")\n\n    return workers_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "\n    # Calculate the total weight of items\n    total_weight = sum(weights) if weights else len(user_items)\n\n    # Calculate the weight per worker\n    weight_per_worker = total_weight / (num_workers)\n\n    # Initialize the lists to store items for each worker\n    items_per_worker = [[] for _ in range(num_workers)]\n\n    # Iterate through the items and distribute them to workers based on weights\n    cumulative_weight = 0\n    worker_index = 0\n    for i, item in enumerate(user_items):\n        if weights:\n            cumulative_weight += weights[i]\n        else:\n            cumulative_weight += 1\n\n        # Distribute the item to the current worker\n        items_per_worker[worker_index].append(item)\n\n        # If the cumulative weight exceeds the weight per worker, move to the next worker\n        if cumulative_weight >= weight_per_worker and worker_index < num_workers - 1:\n            cumulative_weight = 0\n            worker_index += 1\n\n    # Shuffle the items for each worker\n    for i in range(num_workers):\n        random.shuffle(items_per_worker[i])\n\n    return items_per_worker"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "\n    # Calculate the total weight of items\n    total_weight = sum(weights) if weights else len(user_items)\n\n    # Calculate the weight per worker\n    weight_per_worker = total_weight / (num_workers * _get_num_nodes())\n\n    # Initialize variables to track the distribution\n    worker_items = [[] for _ in range(num_workers)]\n    current_worker = 0\n    current_weight = 0\n\n    # Iterate through the items and distribute them to workers based on weights\n    for i, item in enumerate(user_items):\n        if weights:\n            current_weight += weights[i]\n        else:\n            current_weight += 1\n\n        # Check if the current worker's weight limit has been reached\n        if current_weight > weight_per_worker:\n            current_worker = (current_worker + 1) % num_workers\n            current_weight = 0\n\n        # Add the item to the current worker's list\n        worker_items[current_worker].append(item)\n\n    # Shuffle the items in each worker's list\n    for items in worker_items:\n        random.shuffle(items)\n\n    # Print the distribution details\n    if file_size:\n        print(f\"Total file size: {total_weight} MB\")\n        print(f\"File size per worker: {weight_per_worker} MB\")\n    else:\n        print(f\"Total weight: {total_weight}\")\n        print(f\"Weight per worker: {weight_per_worker}\")\n\n    return worker_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "\n    # Calculate the total weight\n    total_weight = sum(weights) if weights else len(user_items)\n\n    # Calculate the number of items per worker based on weights\n    items_per_worker = [int((w / total_weight) * len(user_items)) if weights else len(user_items) // num_workers for w in weights]\n\n    # Distribute the items to workers\n    distributed_items = []\n    start = 0\n    for count in items_per_worker:\n        distributed_items.append(user_items[start:start+count])\n        start += count\n\n    # Shuffle the items in each worker's list\n    for items in distributed_items:\n        random.shuffle(items)\n\n    return distributed_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "\n    total_workers = _get_num_nodes() * num_workers\n    if weights is None:\n        weights = [1] * len(user_items)\n\n    total_weight = sum(weights)\n    items_per_worker = [0] * total_workers\n\n    for i in range(len(user_items)):\n        worker_index = i % total_workers\n        items_per_worker[worker_index] += weights[i]\n\n    if file_size:\n        items_per_worker = [round(w / (1024 * 1024), 2) for w in items_per_worker]\n        total_weight = round(total_weight / (1024 * 1024), 2)\n\n    print(f\"Total weight: {total_weight} MB\" if file_size else f\"Total weight: {total_weight}\")\n    for i in range(total_workers):\n        print(f\"Worker {i}: {items_per_worker[i]} MB\" if file_size else f\"Worker {i}: {items_per_worker[i]}\")\n\n    items_workers = [[] for _ in range(total_workers)]\n    for i, item in enumerate(user_items):\n        worker_index = i % total_workers\n        items_workers[worker_index].append(item)\n\n    for items in items_workers:\n        random.shuffle(items)\n\n    return items_workers"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    if weights is None:\n        weights = [1] * len(user_items)\n\n    total_weights = sum(weights)\n\n    num_nodes = _get_num_nodes()\n    world_size = num_nodes * num_workers\n\n    weighted_items = []\n    for item, weight in zip(user_items, weights):\n        weighted_items.extend([item] * (weight * world_size // total_weights))\n\n    random.shuffle(weighted_items)\n\n    items_per_worker = len(weighted_items) // world_size\n    remaining_items = len(weighted_items) % world_size\n\n    items_per_worker_list = [items_per_worker] * world_size\n    for i in range(remaining_items):\n        items_per_worker_list[i] += 1\n\n    items_assigned = []\n    for i in range(num_workers):\n        start = i * num_nodes\n        end = start + num_nodes\n        items_assigned.append(weighted_items[start:end])\n\n    return items_assigned"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "\n    # Calculate the total weight\n    total_weight = sum(weights) if weights else len(user_items)\n\n    # Calculate the weight per worker\n    weight_per_worker = total_weight / (num_workers)\n\n    # Initialize the lists to store items for each worker\n    worker_items = [[] for _ in range(num_workers)]\n\n    # Iterate through the user_items and distribute them to workers based on weights\n    for idx, item in enumerate(user_items):\n        if weights:\n            # Calculate the cumulative weight for the current item\n            cumulative_weight = sum(weights[:idx + 1])\n            # Find the worker index based on the cumulative weight\n            worker_idx = int(cumulative_weight / weight_per_worker)\n        else:\n            # If weights are not provided, distribute items evenly\n            worker_idx = idx % num_workers\n\n        # Add the item to the corresponding worker's list\n        worker_items[worker_idx].append(item)\n\n    # Shuffle the items within each worker's list\n    for items in worker_items:\n        random.shuffle(items)\n\n    # Print the distribution details\n    if file_size:\n        print(f\"Distributed {total_weight} items with file sizes among {num_workers} workers:\")\n    else:\n        print(f\"Distributed {total_weight} items among {num_workers} workers:\")\n\n    for i, items in enumerate(worker_items):\n        if file_size:\n            total_size = sum(weights[:idx + 1]) if weights else len(items)\n            print(f\"Worker {i + 1}: {len(items)} items, total size: {total_size} MB\")\n        else:\n            print(f\"Worker {i + 1}: {len(items)} items\")\n\n    return worker_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "\n    if weights is None:\n        weights = [1] * len(user_items)\n\n    total_weight = sum(weights)\n    total_workers = num_workers * _get_num_nodes()\n\n    items_per_worker = [0] * total_workers\n    cumulative_weights = [0] * (len(user_items) + 1)\n\n    for i in range(1, len(user_items) + 1):\n        cumulative_weights[i] = cumulative_weights[i - 1] + weights[i - 1]\n\n    for i in range(total_workers):\n        start = (i * total_weight) // total_workers\n        end = ((i + 1) * total_weight) // total_workers\n        items_per_worker[i] = sum(1 for weight in cumulative_weights if start < weight <= end)\n\n    worker_items = [[] for _ in range(total_workers)]\n\n    for i, item in enumerate(user_items):\n        for j in range(total_workers):\n            if (cumulative_weights[i] * total_workers) // total_weight == j:\n                worker_items[j].append(item)\n\n    for items in worker_items:\n        random.shuffle(items)\n\n    return worker_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    total_items = len(user_items)\n    total_workers = _get_num_nodes() * num_workers\n    items_per_worker = total_items // total_workers\n    remainder = total_items % total_workers\n\n    worker_items = []\n    start_index = 0\n    for i in range(total_workers):\n        end_index = start_index + items_per_worker\n        if i < remainder:\n            end_index += 1\n        worker_items.append(user_items[start_index:end_index])\n        start_index = end_index\n\n    if len(worker_items) != num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers.\")\n\n    return worker_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "\n    total_items = len(user_items)\n    total_workers = _get_num_nodes() * num_workers\n    items_per_worker = total_items // total_workers\n    remainder = total_items % total_workers\n\n    start = 0\n    end = 0\n    items_assigned = []\n\n    for i in range(total_workers):\n        extra = 1 if i < remainder else 0\n        start = end\n        end = start + items_per_worker + extra\n        items_assigned.append(user_items[start:end])\n\n    if len(items_assigned) != total_workers:\n        raise RuntimeError(\"Improper assignment of items to workers.\")\n\n    return items_assigned"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    total_workers = _get_num_nodes() * num_workers\n    num_items = len(user_items)\n    items_per_worker = num_items // total_workers\n    remainder = num_items % total_workers\n\n    start_idx = 0\n    workers_user_items = []\n\n    for i in range(total_workers):\n        end_idx = start_idx + items_per_worker\n        if i < remainder:\n            end_idx += 1\n\n        worker_items = user_items[start_idx:end_idx]\n        workers_user_items.append(worker_items)\n        start_idx = end_idx\n\n    if len(workers_user_items) != total_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return workers_user_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    total_items = len(user_items)\n    total_workers = _get_num_nodes() * num_workers\n    items_per_worker = total_items // total_workers\n    remaining_items = total_items % total_workers\n\n    start_indices = [i * items_per_worker + min(i, remaining_items) for i in range(total_workers)]\n    end_indices = [(i + 1) * items_per_worker + min(i + 1, remaining_items) for i in range(total_workers)]\n\n    distributed_items = [user_items[start:end] for start, end in zip(start_indices, end_indices)]\n\n    if len(distributed_items) != num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return distributed_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # Calculate the total number of workers across all nodes\n    total_workers = _get_num_nodes() * num_workers\n\n    # Calculate the number of items each worker should process\n    items_per_worker = len(user_items) // total_workers\n    remainder = len(user_items) % total_workers\n\n    # Distribute items to workers\n    start = 0\n    distributed_items = []\n    for i in range(total_workers):\n        end = start + items_per_worker + (1 if i < remainder else 0)\n        distributed_items.append(user_items[start:end])\n        start = end\n\n    # Check for proper assignment\n    if len(distributed_items) != total_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return distributed_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # Calculate the total number of workers across all nodes\n    total_workers = _get_num_nodes() * num_workers\n    \n    # Calculate the number of items each worker should process\n    items_per_worker = len(user_items) // total_workers\n    remainder = len(user_items) % total_workers\n    \n    # Distribute the items to the workers\n    distributed_items = []\n    start = 0\n    for i in range(num_workers):\n        # Adjust for any remainder by adding extra items to the last workers\n        extra = 1 if i < remainder else 0\n        end = start + items_per_worker + extra\n        distributed_items.append(user_items[start:end])\n        start = end\n    \n    # Ensure the output list has a length equal to the number of workers\n    if len(distributed_items) != num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers.\")\n    \n    return distributed_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    total_items = len(user_items)\n    total_workers = _get_num_nodes() * num_workers\n    items_per_worker = total_items // total_workers\n    remainder = total_items % total_workers\n\n    start_idx = 0\n    end_idx = 0\n    items_assigned = []\n\n    for i in range(total_workers):\n        end_idx += items_per_worker + (1 if i < remainder else 0)\n        items_assigned.append(user_items[start_idx:end_idx])\n        start_idx = end_idx\n\n    if len(items_assigned) != total_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return items_assigned"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    total_items = len(user_items)\n    total_workers = _get_num_nodes() * num_workers\n    items_per_worker = total_items // total_workers\n    remainder = total_items % total_workers\n\n    start = 0\n    end = 0\n    worker_items = []\n\n    for i in range(total_workers):\n        extra = 1 if i < remainder else 0\n        start = end\n        end = start + items_per_worker + extra\n        worker_items.append(user_items[start:end])\n\n    if len(worker_items) != total_workers:\n        raise RuntimeError(\"Improper assignment of items to workers.\")\n\n    return worker_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "\n    total_items = len(user_items)\n    total_workers = _get_num_nodes() * num_workers\n    items_per_worker = total_items // total_workers\n    remainder = total_items % total_workers\n\n    start_idx = 0\n    workers_user_items = []\n\n    for i in range(total_workers):\n        end_idx = start_idx + items_per_worker\n        if i < remainder:\n            end_idx += 1\n\n        worker_items = user_items[start_idx:end_idx]\n        workers_user_items.append(worker_items)\n        start_idx = end_idx\n\n    if len(workers_user_items) != num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return workers_user_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    total_items = len(user_items)\n    total_workers = _get_num_nodes() * num_workers\n    items_per_worker = total_items // total_workers\n    remainder = total_items % total_workers\n\n    start_idx = 0\n    end_idx = 0\n    worker_items = []\n\n    for i in range(total_workers):\n        extra = 1 if i < remainder else 0\n        start_idx = end_idx\n        end_idx = start_idx + items_per_worker + extra\n        worker_items.append(user_items[start_idx:end_idx])\n\n    if len(worker_items) != num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers.\")\n\n    return worker_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    total_items = len(user_items)\n    total_workers = _get_num_nodes() * num_workers\n    items_per_worker = total_items // total_workers\n    remainder = total_items % total_workers\n\n    start = 0\n    end = 0\n    workers_user_items = []\n\n    for i in range(total_workers):\n        extra = 1 if i < remainder else 0\n        start = end\n        end = start + items_per_worker + extra\n        workers_user_items.append(user_items[start:end])\n\n    if len(workers_user_items) != num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return workers_user_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    total_workers = _get_num_nodes() * num_workers\n    items_per_worker = len(user_items) // total_workers\n    remainder = len(user_items) % total_workers\n\n    start_indices = [i * items_per_worker + min(i, remainder) for i in range(total_workers)]\n    end_indices = [(i + 1) * items_per_worker + min(i + 1, remainder) for i in range(total_workers)]\n\n    if len(start_indices) != num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers.\")\n\n    return [user_items[start:end] for start, end in zip(start_indices, end_indices)]"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "\n    # Calculate the total number of workers across all nodes\n    total_workers = _get_num_nodes() * num_workers\n\n    # Calculate the number of items each worker should process\n    items_per_worker = len(user_items) // total_workers\n    remainder = len(user_items) % total_workers\n\n    # Distribute the items among the workers\n    distributed_items = []\n    start = 0\n    for i in range(num_workers):\n        # Calculate the end index for each worker\n        end = start + items_per_worker\n        if i < remainder:\n            end += 1  # Distribute the remainder items to the first few workers\n\n        # Assign the items to the current worker\n        distributed_items.append(user_items[start:end])\n        start = end  # Update the start index for the next worker\n\n    # Ensure proper assignment of items\n    if len(distributed_items) != num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return distributed_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "\n    total_items = len(user_items)\n    total_workers = _get_num_nodes() * num_workers\n    items_per_worker = total_items // total_workers\n    remainder = total_items % total_workers\n\n    worker_items = []\n    start_index = 0\n\n    for i in range(num_workers):\n        extra = 1 if i < remainder else 0\n        worker_start = start_index + (items_per_worker * i) + min(i, remainder)\n        worker_end = worker_start + items_per_worker + extra\n        worker_items.append(user_items[worker_start:worker_end])\n        start_index = worker_end\n\n    if len(worker_items) != num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers.\")\n\n    return worker_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    total_workers = _get_num_nodes() * num_workers\n    total_items = len(user_items)\n    items_per_worker = total_items // total_workers\n    remainder = total_items % total_workers\n\n    start = 0\n    end = 0\n    worker_items = []\n\n    for i in range(total_workers):\n        end += items_per_worker + 1 if i < remainder else items_per_worker\n        worker_items.append(user_items[start:end])\n        start = end\n\n    if len(worker_items) != num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return worker_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    total_items = len(user_items)\n    total_workers = _get_num_nodes() * num_workers\n    items_per_worker = total_items // total_workers\n    remainder = total_items % total_workers\n\n    start_idx = 0\n    end_idx = 0\n    items_assigned = []\n\n    for worker in range(total_workers):\n        if worker < remainder:\n            end_idx += items_per_worker + 1\n        else:\n            end_idx += items_per_worker\n\n        items_assigned.append(user_items[start_idx:end_idx])\n        start_idx = end_idx\n\n    if len(items_assigned) != num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return items_assigned"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "\n    total_items = len(user_items)\n    total_workers = _get_num_nodes() * num_workers\n    items_per_worker = total_items // total_workers\n    remainder = total_items % total_workers\n\n    worker_items = []\n    start = 0\n    for i in range(total_workers):\n        end = start + items_per_worker\n        if i < remainder:\n            end += 1\n        worker_items.append(user_items[start:end])\n        start = end\n\n    if len(worker_items) != total_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return worker_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "\n    total_items = len(user_items)\n    total_workers = _get_num_nodes() * num_workers\n    items_per_worker = total_items // total_workers\n    remainder = total_items % total_workers\n\n    start = 0\n    end = 0\n    items_assigned = []\n\n    for i in range(total_workers):\n        if i < remainder:\n            end = start + items_per_worker + 1\n        else:\n            end = start + items_per_worker\n\n        if start < total_items:\n            items_assigned.append(user_items[start:end])\n            start = end\n\n    if len(items_assigned) != total_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return items_assigned"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    total_items = len(user_items)\n    total_workers = _get_num_nodes() * num_workers\n    items_per_worker = total_items // total_workers\n    remainder = total_items % total_workers\n\n    start = 0\n    end = 0\n    items_assigned = []\n\n    for worker_id in range(total_workers):\n        end += items_per_worker + (1 if worker_id < remainder else 0)\n        items_assigned.append(user_items[start:end])\n        start = end\n\n    if len(items_assigned) != total_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return items_assigned"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "\n    # Calculate the total number of workers across all nodes\n    total_workers = _get_num_nodes() * num_workers\n\n    # Calculate the number of items each worker should process\n    items_per_worker = len(user_items) // total_workers\n    remainder = len(user_items) % total_workers\n\n    # Distribute the items among the workers\n    distributed_items = []\n    start = 0\n    for i in range(num_workers):\n        extra = 1 if i < remainder else 0\n        end = start + items_per_worker + extra\n        distributed_items.append(user_items[start:end])\n        start = end\n\n    # Check for proper assignment\n    if len(distributed_items) != num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return distributed_items"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        if self.input_dir and self.input_dir.path:\n            cache_dir = _get_cache_dir()\n            if os.path.exists(cache_dir):\n                shutil.rmtree(cache_dir)\n            os.makedirs(cache_dir, exist_ok=True)\n\n        if self.output_dir and self.output_dir.path:\n            data_cache_dir = _get_cache_data_dir()\n            if os.path.exists(data_cache_dir):\n                shutil.rmtree(data_cache_dir)\n            os.makedirs(data_cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dirs = [_get_cache_dir(), _get_cache_data_dir()]\n        for cache_dir in cache_dirs:\n            if os.path.exists(cache_dir):\n                shutil.rmtree(cache_dir)\n            os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_data_dir = _get_cache_data_dir()\n        cache_chunks_dir = _get_cache_dir()\n\n        if os.path.exists(cache_data_dir):\n            shutil.rmtree(cache_data_dir)\n        os.makedirs(cache_data_dir, exist_ok=True)\n\n        if os.path.exists(cache_chunks_dir):\n            shutil.rmtree(cache_chunks_dir)\n        os.makedirs(cache_chunks_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        if self.input_dir and self.input_dir.path:\n            cache_dir = _get_cache_dir()\n            if os.path.exists(cache_dir):\n                shutil.rmtree(cache_dir)\n            os.makedirs(cache_dir, exist_ok=True)\n\n        if self.output_dir and self.output_dir.path:\n            cache_data_dir = _get_cache_data_dir()\n            if os.path.exists(cache_data_dir):\n                shutil.rmtree(cache_data_dir)\n            os.makedirs(cache_data_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dirs = [_get_cache_dir(), _get_cache_data_dir()]\n        for cache_dir in cache_dirs:\n            if os.path.exists(cache_dir):\n                shutil.rmtree(cache_dir)\n            os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dir = _get_cache_dir()\n        cache_data_dir = _get_cache_data_dir()\n\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir)\n        os.makedirs(cache_dir, exist_ok=True)\n\n        if os.path.exists(cache_data_dir):\n            shutil.rmtree(cache_data_dir)\n        os.makedirs(cache_data_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "\n        if self.input_dir and self.input_dir.path and os.path.exists(self.input_dir.path):\n            shutil.rmtree(self.input_dir.path)\n\n        if self.output_dir and self.output_dir.path and os.path.exists(self.output_dir.path):\n            shutil.rmtree(self.output_dir.path)\n\n        if self.input_dir and self.input_dir.url and os.path.exists(self.input_dir.url):\n            shutil.rmtree(self.input_dir.url)\n\n        if self.output_dir and self.output_dir.url and os.path.exists(self.output_dir.url):\n            shutil.rmtree(self.output_dir.url)\n\n        if self.input_dir and self.input_dir.path:\n            os.makedirs(self.input_dir.path)\n\n        if self.output_dir and self.output_dir.path:\n            os.makedirs(self.output_dir.path)\n\n        if self.input_dir and self.input_dir.url:\n            os.makedirs(self.input_dir.url)\n\n        if self.output_dir and self.output_dir.url:\n            os.makedirs(self.output_dir.url)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_data_dir = _get_cache_data_dir()\n        cache_chunks_dir = _get_cache_dir()\n\n        if os.path.exists(cache_data_dir):\n            shutil.rmtree(cache_data_dir)\n\n        if os.path.exists(cache_chunks_dir):\n            shutil.rmtree(cache_chunks_dir)\n\n        os.makedirs(cache_data_dir, exist_ok=True)\n        os.makedirs(cache_chunks_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dirs = [_get_cache_data_dir(), _get_cache_dir()]\n        for dir in cache_dirs:\n            if os.path.exists(dir):\n                shutil.rmtree(dir)\n            os.makedirs(dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        if self.input_dir and self.input_dir.path:\n            cache_dir = _get_cache_dir()\n            if os.path.exists(cache_dir):\n                shutil.rmtree(cache_dir)\n            os.makedirs(cache_dir, exist_ok=True)\n\n        if self.output_dir and self.output_dir.path:\n            data_cache_dir = _get_cache_data_dir()\n            if os.path.exists(data_cache_dir):\n                shutil.rmtree(data_cache_dir)\n            os.makedirs(data_cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        if self.input_dir:\n            cache_dir = _get_cache_dir()\n            if os.path.exists(cache_dir):\n                shutil.rmtree(cache_dir)\n            os.makedirs(cache_dir, exist_ok=True)\n\n        if self.output_dir and self.output_dir.url:\n            output_cache_dir = _get_cache_dir(name=self.output_dir.url)\n            if os.path.exists(output_cache_dir):\n                shutil.rmtree(output_cache_dir)\n            os.makedirs(output_cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dir = _get_cache_dir()\n        cache_data_dir = _get_cache_data_dir()\n\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir)\n        os.makedirs(cache_dir, exist_ok=True)\n\n        if os.path.exists(cache_data_dir):\n            shutil.rmtree(cache_data_dir)\n        os.makedirs(cache_data_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dirs = [_get_cache_dir(), _get_cache_data_dir()]\n        for dir in cache_dirs:\n            if os.path.exists(dir):\n                shutil.rmtree(dir)\n            os.makedirs(dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dir = _get_cache_dir()\n        cache_data_dir = _get_cache_data_dir()\n\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir)\n        os.makedirs(cache_dir, exist_ok=True)\n\n        if os.path.exists(cache_data_dir):\n            shutil.rmtree(cache_data_dir)\n        os.makedirs(cache_data_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dirs = [_get_cache_dir(), _get_cache_data_dir()]\n        for cache_dir in cache_dirs:\n            if os.path.exists(cache_dir):\n                shutil.rmtree(cache_dir)\n            os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dir = _get_cache_dir()\n        cache_data_dir = _get_cache_data_dir()\n\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir)\n        os.makedirs(cache_dir, exist_ok=True)\n\n        if os.path.exists(cache_data_dir):\n            shutil.rmtree(cache_data_dir)\n        os.makedirs(cache_data_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dirs = [_get_cache_dir(), _get_cache_data_dir()]\n        for cache_dir in cache_dirs:\n            if os.path.exists(cache_dir):\n                shutil.rmtree(cache_dir)\n            os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dirs = [_get_cache_dir(), _get_cache_data_dir()]\n        for cache_dir in cache_dirs:\n            if os.path.exists(cache_dir):\n                shutil.rmtree(cache_dir)\n            os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dirs = [_get_cache_dir(), _get_cache_data_dir()]\n        \n        for cache_dir in cache_dirs:\n            if os.path.exists(cache_dir):\n                shutil.rmtree(cache_dir)\n            os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dir = _get_cache_dir()\n        cache_data_dir = _get_cache_data_dir()\n\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir)\n        os.makedirs(cache_dir, exist_ok=True)\n\n        if os.path.exists(cache_data_dir):\n            shutil.rmtree(cache_data_dir)\n        os.makedirs(cache_data_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "        import os\n        import concurrent.futures\n    import concurrent.futures\n    import os\n\n    def get_file_size(item):\n        if base_path:\n            file_path = os.path.join(base_path, item)\n        else:\n            file_path = item\n        return os.path.getsize(file_path)\n\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        file_sizes = list(executor.map(get_file_size, items))\n\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "        import os\n        import concurrent.futures\n    import concurrent.futures\n    import os\n\n    def get_file_size(item):\n        if base_path:\n            file_path = os.path.join(base_path, item)\n        else:\n            file_path = item\n        return os.path.getsize(file_path)\n\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        file_sizes = list(executor.map(get_file_size, items))\n\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "        import os\n        import concurrent.futures\n    import concurrent.futures\n    import os\n\n    def get_file_size(item):\n        path = os.path.join(base_path, item)\n        return os.path.getsize(path)\n\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        file_sizes = list(executor.map(get_file_size, items))\n\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    file_sizes = []\n    with concurrent.futures.ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n        futures = [executor.submit(_get_num_bytes, item, base_path) for item in items]\n        for future in concurrent.futures.as_completed(futures):\n            file_sizes.append(future.result())\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "\n    # Your implementation here\n    file_sizes = []\n    for item in items:\n        file_path = os.path.join(base_path, str(item))\n        if os.path.exists(file_path):\n            file_sizes.append(os.path.getsize(file_path))\n        else:\n            file_sizes.append(0)  # If the file doesn't exist, add 0 to the file sizes list\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "\n    # Your code to compute file sizes goes here\n\n    file_sizes = []\n\n    for item in items:\n        # Compute the file size for each item and append it to the file_sizes list\n        size = _get_num_bytes(item, base_path)\n        file_sizes.append(size)\n\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "        import os\n        import concurrent.futures\n    import concurrent.futures\n    import os\n\n    def get_file_size(item):\n        if base_path:\n            file_path = os.path.join(base_path, item)\n        else:\n            file_path = item\n        return os.path.getsize(file_path)\n\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        file_sizes = list(executor.map(get_file_size, items))\n\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "        import os\n        import concurrent.futures\n    import concurrent.futures\n    import os\n\n    def get_file_size(item):\n        if base_path:\n            item_path = os.path.join(base_path, item)\n        else:\n            item_path = item\n        return os.path.getsize(item_path)\n\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        file_sizes = list(executor.map(get_file_size, items))\n\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "\n    # Your code here\n\n    file_sizes = []\n    with concurrent.futures.ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n        futures = [executor.submit(_get_num_bytes, item, base_path) for item in items]\n        for future in concurrent.futures.as_completed(futures):\n            file_size = future.result()\n            file_sizes.append(file_size)\n\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "        import os\n        import concurrent.futures\n\n    import concurrent.futures\n    import os\n\n    def get_file_size(item):\n        if base_path:\n            file_path = os.path.join(base_path, item)\n        else:\n            file_path = item\n        return os.path.getsize(file_path)\n\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        file_sizes = list(executor.map(get_file_size, items))\n\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "        import os\n        import concurrent.futures\n    import concurrent.futures\n    import os\n\n    def get_file_size(item):\n        if base_path:\n            file_path = os.path.join(base_path, item)\n        else:\n            file_path = item\n        return os.path.getsize(file_path)\n\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        file_sizes = list(executor.map(get_file_size, items))\n\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "        import os\n        import concurrent.futures\n\n    import concurrent.futures\n    import os\n\n    def get_file_size(item):\n        if base_path:\n            file_path = os.path.join(base_path, item)\n        else:\n            file_path = item\n        return os.path.getsize(file_path)\n\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        file_sizes = list(executor.map(get_file_size, items))\n\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "\n    # Implement the logic to compute file sizes for each item in the given list\n    file_sizes = []\n    for item in items:\n        file_path = os.path.join(base_path, str(item))\n        if os.path.isfile(file_path):\n            size = os.path.getsize(file_path)\n            file_sizes.append(size)\n        else:\n            file_sizes.append(0)  # If the item is not a file, add 0 as the size\n\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "        import os\n        import concurrent.futures\n    import concurrent.futures\n    import os\n\n    def get_file_size(item):\n        if base_path:\n            file_path = os.path.join(base_path, item)\n        else:\n            file_path = item\n        return os.path.getsize(file_path)\n\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        file_sizes = list(executor.map(get_file_size, items))\n\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "        import os\n        import concurrent.futures\n    import concurrent.futures\n    import os\n\n    def get_file_size(item):\n        if base_path:\n            file_path = os.path.join(base_path, item)\n        else:\n            file_path = item\n        return os.path.getsize(file_path)\n\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        file_sizes = list(executor.map(get_file_size, items))\n\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "        import os\n        import concurrent.futures\n    import concurrent.futures\n    import os\n\n    def get_file_size(item):\n        if base_path:\n            file_path = os.path.join(base_path, item)\n        else:\n            file_path = item\n        return os.path.getsize(file_path)\n\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        file_sizes = list(executor.map(get_file_size, items))\n\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "        import os\n        import concurrent.futures\n    import concurrent.futures\n    import os\n\n    def get_file_size(item):\n        if base_path:\n            item_path = os.path.join(base_path, item)\n        else:\n            item_path = item\n        return os.path.getsize(item_path)\n\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        file_sizes = list(executor.map(get_file_size, items))\n\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "        import os\n        import concurrent.futures\n    import concurrent.futures\n    import os\n\n    def get_file_size(item):\n        if base_path:\n            file_path = os.path.join(base_path, item)\n        else:\n            file_path = item\n        return os.path.getsize(file_path)\n\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        file_sizes = list(executor.map(get_file_size, items))\n\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "\n    # Your implementation here\n    file_sizes = []\n\n    # Parallelize the file size retrieval process\n    with concurrent.futures.ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n        # Submit file size retrieval tasks to the executor\n        future_to_item = {executor.submit(_get_num_bytes, item, base_path): item for item in items}\n        # Retrieve the file sizes as the tasks complete\n        for future in concurrent.futures.as_completed(future_to_item):\n            item = future_to_item[future]\n            try:\n                file_size = future.result()\n                file_sizes.append(file_size)\n            except Exception as e:\n                # Handle any exceptions that occurred during file size retrieval\n                logging.error(f\"Exception occurred while retrieving file size for item {item}: {e}\")\n                file_sizes.append(0)  # Add a placeholder value for the file size\n\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "\n    # Function to compute file size for a single item\n    def get_file_size(item: Any) -> int:\n        # Logic to compute file size for the item\n        # Example: \n        # file_size = os.path.getsize(os.path.join(base_path, item))\n        # return file_size\n        pass\n\n    # Using ThreadPoolExecutor to parallelize file size retrieval\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        file_sizes = list(executor.map(get_file_size, items))\n\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        path = Path(element)\n        if input_dir:\n            return str(path).startswith(input_dir) and path.exists()\n        else:\n            return path.exists()\n    else:\n        return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        element = str(element)\n        if input_dir:\n            if os.path.isabs(element):\n                return element.startswith(input_dir)\n            else:\n                return os.path.exists(os.path.join(input_dir, element))\n        else:\n            return os.path.exists(element)\n    else:\n        return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        element = str(Path(element).resolve())\n        if input_dir:\n            input_dir = str(Path(input_dir).resolve())\n            if element.startswith(input_dir):\n                return True\n        return os.path.exists(element)\n    return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        path = element\n        if not os.path.isabs(path) and input_dir:\n            path = os.path.join(input_dir, element)\n        return os.path.exists(path)\n    else:\n        return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        path = str(element)\n        if os.path.isabs(path):\n            return os.path.exists(path)\n        elif input_dir:\n            return os.path.exists(os.path.join(input_dir, path))\n        else:\n            return False\n    else:\n        return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        path = Path(element)\n        if input_dir:\n            input_path = Path(input_dir)\n            if path.is_absolute():\n                return str(path).startswith(str(input_path))\n            else:\n                return (input_path / path).exists()\n        else:\n            return path.exists()\n    else:\n        return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        # Convert to absolute path if it's a relative path\n        element = os.path.abspath(element)\n\n        if input_dir:\n            # Check if the element starts with the input directory\n            return element.startswith(input_dir) or os.path.exists(element)\n        else:\n            # If no input directory is provided, simply check if the path exists\n            return os.path.exists(element)\n    else:\n        return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        element = Path(element)\n        if input_dir:\n            input_dir = Path(input_dir)\n            return element.is_absolute() or str(element).startswith(str(input_dir)) or element.exists()\n        else:\n            return element.exists()\n    else:\n        return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        path = Path(element)\n        if input_dir:\n            input_path = Path(input_dir)\n            if path.is_absolute():\n                return path.parts[:len(input_path.parts)] == input_path.parts\n            else:\n                return (input_path / path).exists()\n        else:\n            return path.exists()\n    else:\n        return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        element = Path(element)\n        if input_dir:\n            input_dir = Path(input_dir)\n            if element.is_absolute():\n                return element.is_file() or element.is_dir()\n            else:\n                return (input_dir / element).is_file() or (input_dir / element).is_dir()\n        else:\n            return element.is_file() or element.is_dir()\n    else:\n        return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        path = Path(element)\n        if input_dir:\n            input_path = Path(input_dir)\n            if path.is_absolute():\n                return path.parts[:len(input_path.parts)] == input_path.parts\n            else:\n                return (input_path / path).exists()\n        else:\n            return path.exists()\n    else:\n        return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        element = str(Path(element).resolve())\n        if input_dir and element.startswith(input_dir):\n            return True\n        return os.path.exists(element)\n    return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        path = Path(element)\n        if input_dir:\n            input_path = Path(input_dir)\n            if path.is_absolute():\n                return str(path).startswith(str(input_path))\n            else:\n                return (input_path / path).exists()\n        else:\n            return path.exists()\n    else:\n        return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        path = Path(element)\n        if input_dir:\n            input_path = Path(input_dir)\n            if path.is_absolute():\n                return str(path).startswith(str(input_path))\n            else:\n                return (input_path / path).exists()\n        else:\n            return path.exists()\n    else:\n        return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        if os.path.isabs(element):\n            return os.path.exists(element)\n        elif input_dir and os.path.exists(os.path.join(input_dir, element)):\n            return True\n        else:\n            return os.path.exists(element)\n    else:\n        return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        element = Path(element)\n        if input_dir is not None:\n            input_dir = Path(input_dir)\n            if element.is_absolute():\n                return str(element).startswith(str(input_dir))\n            else:\n                return (input_dir / element).exists()\n        else:\n            return element.exists()\n    else:\n        return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        path = Path(element)\n        if input_dir:\n            input_path = Path(input_dir)\n            return path.is_absolute() or str(path).startswith(str(input_path))\n        else:\n            return path.exists()\n    else:\n        return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        element_path = Path(element)\n        if input_dir:\n            input_path = Path(input_dir)\n            return element_path.is_absolute() or (input_path / element_path).resolve().is_file()\n        else:\n            return element_path.is_absolute() or element_path.is_file()\n    else:\n        return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        path = str(element)\n        if input_dir and not path.startswith(\"/\") and not os.path.isabs(path):\n            path = os.path.join(input_dir, path)\n        return os.path.exists(path)\n    else:\n        return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        path = Path(element)\n        if input_dir:\n            input_path = Path(input_dir)\n            return path.is_absolute() or str(path).startswith(str(input_path)) or path.exists()\n        else:\n            return path.is_absolute() or path.exists()\n    else:\n        return False"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = spin_math.safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n  W = skew(w)\n  V = jnp.outer(w, v)\n  R = exp_so3(w * theta, eps)\n  t = (jnp.eye(3) * theta + (1 - jnp.cos(theta)) * W + (theta - jnp.sin(theta)) * V) @ v\n  T = jnp.block([[R, t[:, jnp.newaxis]], [jnp.zeros((1, 3)), 1]])\n  return T"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = spin_math.safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  v = screw_axis[3:] / theta\n  w = screw_axis[:3]\n\n  W = skew(w)\n  V = skew(v)\n\n  R = exp_so3(w, eps)\n  G_inv1 = jnp.eye(3)\n  G_inv2 = (1 - jnp.cos(theta)) * W\n  G_inv3 = (theta - jnp.sin(theta)) * spin_math.matmul(W, W)\n  G_inv4 = (jnp.eye(3) - R) @ V\n  G_inv = G_inv1 + G_inv2 + G_inv3 + G_inv4\n\n  p = spin_math.matmul(G_inv, v)\n  X = rp_to_se3(R, p)\n\n  return X"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = spin_math.safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  v = screw_axis[3:]\n  w = screw_axis[:3] / theta\n\n  W = skew(w)\n  V = jnp.eye(3) * theta + (1 - jnp.cos(theta)) * W + (theta - jnp.sin(theta)) * spin_math.matmul(W, W)\n\n  T = jnp.eye(3) * theta + (1 - jnp.cos(theta)) * W + (theta - jnp.sin(theta)) * spin_math.matmul(W, W)\n  top = jnp.concatenate((T, spin_math.matmul(V, v)[:, jnp.newaxis]), axis=1)\n  bottom = jnp.array([[0, 0, 0, 1]])\n  T = jnp.concatenate((top, bottom), axis=0)\n\n  return T"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = spin_math.safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n  W = skew(w)\n  V = jnp.outer(w, v)\n  R = exp_so3(w * theta)\n  t = (jnp.eye(3) * theta + (1 - jnp.cos(theta)) * W + (theta - jnp.sin(theta)) * V) @ v\n  T = jnp.block([[R, t[:, jnp.newaxis]], [jnp.array([[0.0, 0.0, 0.0, 1.0]])]])\n  return T"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = spin_math.safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n  W = skew(w)\n  G_inv1 = jnp.eye(3)\n  G_inv2 = (jnp.eye(3) - exp_so3(W, eps)) / jnp.dot(w, w)\n  G_inv3 = (\n      jnp.eye(3) * theta\n      + (1 - jnp.cos(theta)) * W\n      + (theta - jnp.sin(theta)) * spin_math.matmul(W, W)\n  ) / jnp.dot(w, w)\n  G_inv = G_inv1 + G_inv2 + G_inv3\n  p = spin_math.matmul(G_inv, v[Ellipsis, jnp.newaxis]).squeeze(-1)\n  X = rp_to_se3(exp_so3(W, eps), p)\n  return X"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = spin_math.safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n  W = skew(w)\n  V = jnp.outer(w, v)\n  R = exp_so3(w * theta, eps)\n  t = (jnp.eye(3) * theta + (1 - jnp.cos(theta)) * W + (theta - jnp.sin(theta)) * V) @ v\n  return jnp.block([[R, t[:, jnp.newaxis]], [jnp.array([0, 0, 0, 1])]])"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = spin_math.safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n\n  W = skew(w)\n  V = jnp.outer(w, v)\n\n  R = exp_so3(w * theta, eps)\n  t = ((jnp.eye(3) * theta) + (1 - jnp.cos(theta)) * W + (theta - jnp.sin(theta)) * spin_math.matmul(W, W)).dot(v)\n\n  T = jnp.block([[R, t[:, jnp.newaxis]], [jnp.zeros((1, 3)), jnp.array([[1.0]])]])\n\n  return T"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta_squared = jnp.sum(screw_axis[:3]**2, axis=-1)\n  theta = spin_math.safe_sqrt(theta_squared)\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  X_taylor = jnp.eye(4) + skew(screw_axis) + (1 - jnp.cos(theta)) * (skew(screw_axis) @ skew(screw_axis)) / (theta_squared + eps**2)\n\n  # Prevent bad gradients from propagating back when theta is small.\n  screw_axis_safe = jnp.where(theta_squared > eps**2, screw_axis, 0.0)\n  theta_safe = jnp.where(theta_squared > eps**2, theta, 1.0)\n  w = screw_axis_safe[:3] / theta_safe\n  v = screw_axis_safe[3:] / theta_safe\n  W = skew(w)\n  R = exp_so3(w, eps)\n\n  G_inv1 = jnp.eye(3)\n  G_inv2 = (jnp.eye(3) - R) @ W + jnp.outer(w, v)\n  G_inv3 = jnp.outer(w, w)\n  G_inv = G_inv1 + theta_safe / 2.0 * G_inv2 + (1 - theta_safe / jnp.tan(theta_safe / 2.0)) * G_inv3\n\n  p = G_inv @ v\n  X = jnp.eye(4)\n  X = X.at[:3, :3].set(R)\n  X = X.at[:3, 3].set(p)\n\n  return jnp.where(theta_squared > eps**2, X, X_taylor)"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = spin_math.safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n\n  W = skew(w)\n  V = jnp.outer(w, v)\n\n  R = exp_so3(w * theta)\n  G_inv1 = jnp.eye(3)\n  G_inv2 = (jnp.eye(3) - R) @ W + w[:, jnp.newaxis] @ w[jnp.newaxis, :]\n  G_inv3 = jnp.dot(w, v)[:, jnp.newaxis] @ w[jnp.newaxis, :]\n  G_inv = G_inv1 + theta / 2 * G_inv2 + (1 - theta / jnp.tan(theta / 2)) * G_inv3\n\n  t = G_inv @ v\n\n  X = jnp.eye(4)\n  X = X.at[:3, :3].set(R)\n  X = X.at[:3, 3].set(t)\n\n  return X"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = spin_math.safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  v = screw_axis[3:]\n  w = screw_axis[:3]\n\n  if theta < eps:\n    return rp_to_se3(jnp.eye(3), v)\n  else:\n    W = skew(w)\n    V = jnp.eye(3) + ((1 - jnp.cos(theta)) / (theta**2)) * W + ((theta - jnp.sin(theta)) / (theta**3)) * spin_math.matmul(W, W)\n    R = exp_so3(w, eps)\n    p = spin_math.matmul(V, v)\n    return rp_to_se3(R, p)"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = spin_math.safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n  W = skew(w)\n  V = jnp.outer(w, v)\n\n  R = exp_so3(w[None] * theta, eps)\n  G_inv1 = jnp.eye(3)\n  G_inv2 = (jnp.eye(3) * theta - W + (1 - jnp.cos(theta)) * V + (theta - jnp.sin(theta)) * spin_math.matmul(W, V)) / (theta**2)\n  G_inv = G_inv1 + G_inv2\n\n  p = spin_math.matmul(G_inv, v[:, jnp.newaxis]).squeeze(-1)\n  X = jnp.block([[R, p[:, jnp.newaxis]], [jnp.array([0, 0, 0, 1])]])\n  return X"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = spin_math.safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n\n  W = skew(w)\n  V = jnp.outer(w, v)\n\n  R = exp_so3(w * theta)\n  t = (jnp.eye(3) * theta + (1 - jnp.cos(theta)) * W + (theta - jnp.sin(theta)) * V) @ v\n\n  T = jnp.block([[R, t[:, jnp.newaxis]], [jnp.array([0.0, 0.0, 0.0, 1.0])]])\n  return T"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = spin_math.safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n  W = skew(w)\n  V = jnp.outer(w, v)\n  R = exp_so3(w * theta)\n  t = (jnp.eye(3) * theta + (1 - jnp.cos(theta)) * W + (theta - jnp.sin(theta)) * V) @ v\n  T = jnp.block([[R, t[:, jnp.newaxis]], [jnp.zeros((1, 3)), jnp.array([[1]])]])\n  return T"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = spin_math.safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n  W = skew(w)\n  G_inv1 = jnp.eye(3)\n  G_inv2 = (1 - jnp.cos(theta)) * W\n  G_inv3 = (theta - jnp.sin(theta)) * spin_math.matmul(W, W)\n  G_inv = G_inv1 + G_inv2 + G_inv3\n  p = spin_math.matmul(G_inv, v[Ellipsis, jnp.newaxis]).squeeze(-1)\n  R = exp_so3(w * theta)\n  X = rp_to_se3(R, p)\n  return X"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = spin_math.safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n\n  W = skew(w)\n  V = jnp.dot((jnp.eye(3) - exp_so3(W, eps)), v) / theta\n  zero = jnp.zeros(3)\n\n  T = jnp.block([[exp_so3(W, eps), jnp.dot(V, theta)],\n                 [zero, 1.0]])\n\n  return T"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = spin_math.safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n\n  W = skew(w)\n  V = jnp.outer(w, v)\n\n  R = exp_so3(w * theta, eps)\n  t = jnp.eye(3) * theta + (1 - jnp.cos(theta)) * W + (theta - jnp.sin(theta)) * spin_math.matmul(W, W)\n  t_inv = jnp.linalg.inv(t)\n\n  p = spin_math.matmul(t_inv, v)\n\n  T = jnp.block([[R, spin_math.matmul(t_inv, V)], [jnp.zeros((1, 3)), 1]])\n\n  return T"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = spin_math.safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  v = screw_axis[3:] / theta\n  w = screw_axis[:3]\n\n  W = skew(w)\n  V = jnp.eye(3) - 0.5 * W + (1 - (1 + jnp.cos(theta)) / (theta * jnp.sin(theta))) * spin_math.matmul(W, W)\n  R = exp_so3(w, eps)\n\n  G_inv1 = jnp.block([[R, jnp.zeros((3, 1))], [jnp.zeros((1, 3)), jnp.array([[1.0]])]])\n  G_inv2 = jnp.block([[V, spin_math.matmul(W, v)[:, jnp.newaxis]], [jnp.zeros((1, 3)), jnp.array([[1.0]])]])\n  G_inv = spin_math.matmul(G_inv2, G_inv1)\n\n  return G_inv"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = spin_math.safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n\n  W = skew(w)\n  V = jnp.outer(w, v)\n\n  R = exp_so3(w * theta)\n  t = (jnp.eye(3) * theta + (1 - jnp.cos(theta)) * W + (theta - jnp.sin(theta)) * V) @ v\n\n  T = jnp.block([[R, t[:, jnp.newaxis]], [jnp.array([0, 0, 0, 1])]])\n  return T"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = spin_math.safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n  W = skew(w)\n  V = jnp.outer(w, v)\n  R = exp_so3(w * theta, eps)\n  t = (jnp.eye(3) * theta + (1 - jnp.cos(theta)) * W + (theta - jnp.sin(theta)) * V) @ v\n  return jnp.block([[R, t[:, jnp.newaxis]], [jnp.array([0, 0, 0, 1])]])"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = spin_math.safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n  W = skew(w)\n  V = jnp.outer(w, v)\n\n  R = exp_so3(w * theta, eps)\n  t = (jnp.eye(3) * theta + (1 - jnp.cos(theta)) * W + (theta - jnp.sin(theta)) * V) @ v\n\n  T = jnp.block([[R, t[:, jnp.newaxis]], [jnp.array([0, 0, 0, 1])]])\n  return T"}
{"namespace": "rigid_body.exp_so3", "completion": "  \"\"\"\n  This function computes the exponential map from the Lie algebra so3 to the Lie group SO3, using Rodrigues' formula. It translates a 3D axis-angle representation of a rotation into a 3x3 rotation matrix. The function includes a numerical stability mechanism for small angles of rotation.\n\n  Input-Output Arguments\n  :param axis_angle: A 3-vector (numpy array). Represents the axis of rotation and the magnitude of rotation. It is used to compute the rotation matrix.\n  :param eps: Float. A small epsilon value for numerical stability, used to avoid division by zero or very small values that could lead to numerical instability. Defaults to the machine epsilon for float32.\n  :return: A (3, 3) numpy array. An orthonormal rotation matrix representing the same rotation as the input axis-angle representation.\n  \"\"\"\n  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n      return jnp.eye(3) + skew(axis_angle)\n  else:\n      K = skew(axis_angle / theta)\n      return jnp.eye(3) + jnp.sin(theta) * K + (1 - jnp.cos(theta)) * spin_math.matmul(K, K)"}
{"namespace": "rigid_body.exp_so3", "completion": "  \"\"\"\n  This function computes the exponential map from the Lie algebra so3 to the Lie group SO3, using Rodrigues' formula. It translates a 3D axis-angle representation of a rotation into a 3x3 rotation matrix. The function includes a numerical stability mechanism for small angles of rotation.\n\n  Input-Output Arguments\n  :param axis_angle: A 3-vector (numpy array). Represents the axis of rotation and the magnitude of rotation. It is used to compute the rotation matrix.\n  :param eps: Float. A small epsilon value for numerical stability, used to avoid division by zero or very small values that could lead to numerical instability. Defaults to the machine epsilon for float32.\n  :return: A (3, 3) numpy array. An orthonormal rotation matrix representing the same rotation as the input axis-angle representation.\n  \"\"\"\n  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n      return jnp.eye(3) + skew(axis_angle)\n  else:\n      K = skew(axis_angle / theta)\n      return jnp.eye(3) + jnp.sin(theta) * K + (1 - jnp.cos(theta)) * K @ K"}
{"namespace": "rigid_body.exp_so3", "completion": "  \"\"\"\n  This function computes the exponential map from the Lie algebra so3 to the Lie group SO3, using Rodrigues' formula. It translates a 3D axis-angle representation of a rotation into a 3x3 rotation matrix. The function includes a numerical stability mechanism for small angles of rotation.\n\n  Input-Output Arguments\n  :param axis_angle: A 3-vector (numpy array). Represents the axis of rotation and the magnitude of rotation. It is used to compute the rotation matrix.\n  :param eps: Float. A small epsilon value for numerical stability, used to avoid division by zero or very small values that could lead to numerical instability. Defaults to the machine epsilon for float32.\n  :return: A (3, 3) numpy array. An orthonormal rotation matrix representing the same rotation as the input axis-angle representation.\n  \"\"\"\n  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n      return jnp.eye(3) + skew(axis_angle)\n  else:\n      K = skew(axis_angle / theta)\n      return jnp.eye(3) + jnp.sin(theta) * K + (1 - jnp.cos(theta)) * K @ K"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n    return jnp.eye(3) + skew(axis_angle)\n  else:\n    w = axis_angle / theta\n    W = skew(w)\n    return jnp.eye(3) + jnp.sin(theta) * W + (1 - jnp.cos(theta)) * W @ W"}
{"namespace": "rigid_body.exp_so3", "completion": "  \"\"\"\n  This function computes the exponential map from the Lie algebra so3 to the Lie group SO3, using Rodrigues' formula. It translates a 3D axis-angle representation of a rotation into a 3x3 rotation matrix. The function includes a numerical stability mechanism for small angles of rotation.\n\n  Input-Output Arguments\n  :param axis_angle: A 3-vector (numpy array). Represents the axis of rotation and the magnitude of rotation. It is used to compute the rotation matrix.\n  :param eps: Float. A small epsilon value for numerical stability, used to avoid division by zero or very small values that could lead to numerical instability. Defaults to the machine epsilon for float32.\n  :return: A (3, 3) numpy array. An orthonormal rotation matrix representing the same rotation as the input axis-angle representation.\n  \"\"\"\n  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n      return jnp.eye(3) + skew(axis_angle)\n  else:\n      k = axis_angle / theta\n      K = skew(k)\n      return jnp.eye(3) + jnp.sin(theta) * K + (1 - jnp.cos(theta)) * K @ K"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n    return jnp.eye(3) + skew(axis_angle)\n  else:\n    W = skew(axis_angle / theta)\n    return jnp.eye(3) + jnp.sin(theta) * W + (1 - jnp.cos(theta)) * spin_math.matmul(W, W)"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n    return jnp.eye(3) + skew(axis_angle)\n  else:\n    w = axis_angle / theta\n    W = skew(w)\n    return jnp.eye(3) + jnp.sin(theta) * W + (1 - jnp.cos(theta)) * W @ W"}
{"namespace": "rigid_body.exp_so3", "completion": "  \"\"\"\n  This function computes the exponential map from the Lie algebra so3 to the Lie group SO3, using Rodrigues' formula. It translates a 3D axis-angle representation of a rotation into a 3x3 rotation matrix. The function includes a numerical stability mechanism for small angles of rotation.\n\n  Input-Output Arguments\n  :param axis_angle: A 3-vector (numpy array). Represents the axis of rotation and the magnitude of rotation. It is used to compute the rotation matrix.\n  :param eps: Float. A small epsilon value for numerical stability, used to avoid division by zero or very small values that could lead to numerical instability. Defaults to the machine epsilon for float32.\n  :return: A (3, 3) numpy array. An orthonormal rotation matrix representing the same rotation as the input axis-angle representation.\n  \"\"\"\n  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n      return jnp.eye(3) + skew(axis_angle)\n  else:\n      W = skew(axis_angle / theta)\n      return jnp.eye(3) + jnp.sin(theta) * W + (1 - jnp.cos(theta)) * spin_math.matmul(W, W)"}
{"namespace": "rigid_body.exp_so3", "completion": "  \"\"\"\n  This function computes the exponential map from the Lie algebra so3 to the Lie group SO3, using Rodrigues' formula. It translates a 3D axis-angle representation of a rotation into a 3x3 rotation matrix. The function includes a numerical stability mechanism for small angles of rotation.\n\n  Input-Output Arguments\n  :param axis_angle: A 3-vector (numpy array). Represents the axis of rotation and the magnitude of rotation. It is used to compute the rotation matrix.\n  :param eps: Float. A small epsilon value for numerical stability, used to avoid division by zero or very small values that could lead to numerical instability. Defaults to the machine epsilon for float32.\n  :return: A (3, 3) numpy array. An orthonormal rotation matrix representing the same rotation as the input axis-angle representation.\n  \"\"\"\n  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n      return jnp.eye(3) + skew(axis_angle)\n  else:\n      K = skew(axis_angle / theta)\n      return jnp.eye(3) + jnp.sin(theta) * K + (1 - jnp.cos(theta)) * K @ K"}
{"namespace": "rigid_body.exp_so3", "completion": "  \"\"\"\n  This function computes the exponential map from the Lie algebra so3 to the Lie group SO3, using Rodrigues' formula. It translates a 3D axis-angle representation of a rotation into a 3x3 rotation matrix. The function includes a numerical stability mechanism for small angles of rotation.\n\n  Input-Output Arguments\n  :param axis_angle: A 3-vector (numpy array). Represents the axis of rotation and the magnitude of rotation. It is used to compute the rotation matrix.\n  :param eps: Float. A small epsilon value for numerical stability, used to avoid division by zero or very small values that could lead to numerical instability. Defaults to the machine epsilon for float32.\n  :return: A (3, 3) numpy array. An orthonormal rotation matrix representing the same rotation as the input axis-angle representation.\n  \"\"\"\n  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n      return jnp.eye(3) + skew(axis_angle)\n  else:\n      K = skew(axis_angle / theta)\n      return jnp.eye(3) + jnp.sin(theta) * K + (1 - jnp.cos(theta)) * K @ K"}
{"namespace": "rigid_body.exp_so3", "completion": "  \"\"\"\n  This function computes the exponential map from the Lie algebra so3 to the Lie group SO3, using Rodrigues' formula. It translates a 3D axis-angle representation of a rotation into a 3x3 rotation matrix. The function includes a numerical stability mechanism for small angles of rotation.\n\n  Input-Output Arguments\n  :param axis_angle: A 3-vector (numpy array). Represents the axis of rotation and the magnitude of rotation. It is used to compute the rotation matrix.\n  :param eps: Float. A small epsilon value for numerical stability, used to avoid division by zero or very small values that could lead to numerical instability. Defaults to the machine epsilon for float32.\n  :return: A (3, 3) numpy array. An orthonormal rotation matrix representing the same rotation as the input axis-angle representation.\n  \"\"\"\n  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n      return jnp.eye(3) + skew(axis_angle)\n  else:\n      K = skew(axis_angle / theta)\n      return jnp.eye(3) + jnp.sin(theta) * K + (1 - jnp.cos(theta)) * K @ K"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n      return jnp.eye(3) + skew(axis_angle)\n  else:\n      w = axis_angle / theta\n      W = skew(w)\n      return jnp.eye(3) + jnp.sin(theta) * W + (1 - jnp.cos(theta)) * spin_math.matmul(W, W)"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n    return jnp.eye(3) + skew(axis_angle)\n  else:\n    W = skew(axis_angle / theta)\n    return jnp.eye(3) + jnp.sin(theta) * W + (1 - jnp.cos(theta)) * spin_math.matmul(W, W)"}
{"namespace": "rigid_body.exp_so3", "completion": "  \"\"\"\n  This function computes the exponential map from the Lie algebra so3 to the Lie group SO3, using Rodrigues' formula. It translates a 3D axis-angle representation of a rotation into a 3x3 rotation matrix. The function includes a numerical stability mechanism for small angles of rotation.\n\n  Input-Output Arguments\n  :param axis_angle: A 3-vector (numpy array). Represents the axis of rotation and the magnitude of rotation. It is used to compute the rotation matrix.\n  :param eps: Float. A small epsilon value for numerical stability, used to avoid division by zero or very small values that could lead to numerical instability. Defaults to the machine epsilon for float32.\n  :return: A (3, 3) numpy array. An orthonormal rotation matrix representing the same rotation as the input axis-angle representation.\n  \"\"\"\n  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n      return jnp.eye(3) + skew(axis_angle)\n  else:\n      K = skew(axis_angle / theta)\n      return jnp.eye(3) + jnp.sin(theta) * K + (1 - jnp.cos(theta)) * spin_math.matmul(K, K)"}
{"namespace": "rigid_body.exp_so3", "completion": "  \"\"\"\n  This function computes the exponential map from the Lie algebra so3 to the Lie group SO3, using Rodrigues' formula. It translates a 3D axis-angle representation of a rotation into a 3x3 rotation matrix. The function includes a numerical stability mechanism for small angles of rotation.\n\n  Input-Output Arguments\n  :param axis_angle: A 3-vector (numpy array). Represents the axis of rotation and the magnitude of rotation. It is used to compute the rotation matrix.\n  :param eps: Float. A small epsilon value for numerical stability, used to avoid division by zero or very small values that could lead to numerical instability. Defaults to the machine epsilon for float32.\n  :return: A (3, 3) numpy array. An orthonormal rotation matrix representing the same rotation as the input axis-angle representation.\n  \"\"\"\n  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n      return jnp.eye(3) + skew(axis_angle)\n  else:\n      K = skew(axis_angle / theta)\n      return jnp.eye(3) + jnp.sin(theta) * K + (1 - jnp.cos(theta)) * K @ K"}
{"namespace": "rigid_body.exp_so3", "completion": "  \"\"\"\n  This function computes the exponential map from the Lie algebra so3 to the Lie group SO3, using Rodrigues' formula. It translates a 3D axis-angle representation of a rotation into a 3x3 rotation matrix. The function includes a numerical stability mechanism for small angles of rotation.\n\n  Input-Output Arguments\n  :param axis_angle: A 3-vector (numpy array). Represents the axis of rotation and the magnitude of rotation. It is used to compute the rotation matrix.\n  :param eps: Float. A small epsilon value for numerical stability, used to avoid division by zero or very small values that could lead to numerical instability. Defaults to the machine epsilon for float32.\n  :return: A (3, 3) numpy array. An orthonormal rotation matrix representing the same rotation as the input axis-angle representation.\n  \"\"\"\n  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n      return jnp.eye(3) + skew(axis_angle)\n  else:\n      K = skew(axis_angle / theta)\n      return jnp.eye(3) + jnp.sin(theta) * K + (1 - jnp.cos(theta)) * K @ K"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n    return jnp.eye(3) + skew(axis_angle)\n  else:\n    w = axis_angle / theta\n    W = skew(w)\n    return jnp.eye(3) + jnp.sin(theta) * W + (1 - jnp.cos(theta)) * spin_math.matmul(W, W)"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n    return jnp.eye(3) + skew(axis_angle)\n  else:\n    W = skew(axis_angle / theta)\n    return jnp.eye(3) + jnp.sin(theta) * W + (1 - jnp.cos(theta)) * spin_math.matmul(W, W)"}
{"namespace": "rigid_body.exp_so3", "completion": "  \"\"\"\n  This function computes the exponential map from the Lie algebra so3 to the Lie group SO3, using Rodrigues' formula. It translates a 3D axis-angle representation of a rotation into a 3x3 rotation matrix. The function includes a numerical stability mechanism for small angles of rotation.\n\n  Input-Output Arguments\n  :param axis_angle: A 3-vector (numpy array). Represents the axis of rotation and the magnitude of rotation. It is used to compute the rotation matrix.\n  :param eps: Float. A small epsilon value for numerical stability, used to avoid division by zero or very small values that could lead to numerical instability. Defaults to the machine epsilon for float32.\n  :return: A (3, 3) numpy array. An orthonormal rotation matrix representing the same rotation as the input axis-angle representation.\n  \"\"\"\n  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n      return jnp.eye(3) + skew(axis_angle)\n  else:\n      w = axis_angle / theta\n      W = skew(w)\n      return jnp.eye(3) + jnp.sin(theta) * W + (1 - jnp.cos(theta)) * spin_math.matmul(W, W)"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n    return jnp.eye(3) + skew(axis_angle)\n  else:\n    K = skew(axis_angle / theta)\n    return jnp.eye(3) + jnp.sin(theta) * K + (1 - jnp.cos(theta)) * spin_math.matmul(K, K)"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  radius = base_radius * (t0 + t1) / 2\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  radius = base_radius * (t0 + t1) / 2\n  return lift_gaussian(d, t_mean, t_var, r_var, radius, diag)"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  radius = base_radius * t_mean\n  return cylinder_to_gaussian(d, t0, t1, radius, diag)"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  radius = base_radius * (t0 + t1) / 2\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1, base_radius)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  radius = base_radius * (t0 + t1) / 2\n  return cylinder_to_gaussian(d, t0, t1, radius, diag)"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1, base_radius)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  radius = base_radius * (t0 + t1) / 2\n  return cylinder_to_gaussian(d, t0, t1, radius, diag)"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var = r_var * base_radius**2\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var = r_var * base_radius**2\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1, base_radius)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1, base_radius)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  radius = base_radius * (t0 + t1) / 2\n  return cylinder_to_gaussian(d, t0, t1, radius, diag)"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1, base_radius)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  d_mag_sq = jnp.maximum(1e-10, jnp.sum(d**2, axis=-1, keepdims=True))\n  d_normalized = d / jnp.sqrt(d_mag_sq)\n  mean = d_normalized * t_mean[Ellipsis, None]\n  if diag:\n    cov_diag = jnp.diag(t_var + r_var * (1 - d_normalized**2))\n    return mean, cov_diag\n  else:\n    d_outer = d_normalized[Ellipsis, :, None] * d_normalized[Ellipsis, None, :]\n    eye = jnp.eye(d_normalized.shape[-1])\n    null_outer = eye - d_outer\n    cov = t_var[Ellipsis, None, None] * d_outer[Ellipsis, None, :, :] + r_var[Ellipsis, None, None] * null_outer[Ellipsis, None, :, :]\n    return mean, cov"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var = r_var * base_radius**2\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  d_mag_sq = jnp.maximum(1e-10, jnp.sum(d**2, axis=-1, keepdims=True))\n  base_radius_sq = base_radius**2\n\n  mean = d[Ellipsis, None, :] * t_mean[Ellipsis, None]\n\n  if diag:\n    d_outer_diag = d**2\n    null_outer_diag = 1 - d_outer_diag / d_mag_sq\n    t_cov_diag = t_var[Ellipsis, None] * d_outer_diag[Ellipsis, None, :]\n    xy_cov_diag = r_var[Ellipsis, None] * null_outer_diag[Ellipsis, None, :]\n    cov_diag = t_cov_diag + xy_cov_diag\n    return mean, cov_diag\n  else:\n    d_outer = d[Ellipsis, :, None] * d[Ellipsis, None, :]\n    eye = jnp.eye(d.shape[-1])\n    null_outer = eye - d[Ellipsis, :, None] * (d / d_mag_sq)[Ellipsis, None, :]\n    t_cov = t_var[Ellipsis, None, None] * d_outer[Ellipsis, None, :, :]\n    xy_cov = r_var[Ellipsis, None, None] * null_outer[Ellipsis, None, :, :]\n    cov = t_cov + xy_cov\n    return mean, cov"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1, base_radius)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean = (t0 + t1) / 2\n  t_var = (t1 - t0)**2 / 12\n  r_var = radius**2 / 4\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  # Calculate the mean, variance, and radius variance for the Gaussian approximation\n  t_mean = (t0 + t1) / 2\n  t_var = (t1 - t0)**2 / 12\n  r_var = radius**2 / 2\n\n  # Use the lift_gaussian function to convert the mean, variance, and radius variance into a Gaussian distribution\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  \n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Shift pixel coordinates to NDC space.\n  if pixtocam_ndc is not None:\n    pix_x_ndc, pix_y_ndc = pix_x_int, pix_y_int\n    pix_x_int = (2 * pix_x_int / (pix_x_int.shape[-1] - 1)) - 1\n    pix_y_int = (2 * pix_y_int / (pix_y_int.shape[-2] - 1)) - 1\n\n  # Convert pixel coordinates to camera coordinates.\n  pix_coords = xnp.stack([pix_x_int, pix_y_int, xnp.ones_like(pix_x_int)], -1)\n  cam_coords = xnp.einsum('...ij,...j->...i', pixtocams, pix_coords)\n\n  # Convert camera coordinates to world coordinates.\n  origins = xnp.einsum('...ij,...j->...i', camtoworlds[..., :3, :3], cam_coords)\n  directions = xnp.einsum('...ij,...j->...i', camtoworlds[..., :3, :3], cam_coords) - camtoworlds[..., :3, 3]\n\n  # Normalize directions to get view directions.\n  viewdirs = xnp.linalg.norm(directions, axis=-1, keepdims=True)\n  viewdirs = directions / viewdirs\n\n  # Compute differential radii for mip-NeRF cones.\n  radii = xnp.linalg.norm(cam_coords[..., :2], axis=-1, keepdims=True)\n\n  # Apply distortion correction if distortion parameters are provided.\n  if distortion_params is not None:\n    x, y = _radial_and_tangential_distort(\n        cam_coords[..., 0], cam_coords[..., 1], **distortion_params\n    )\n    cam_coords = xnp.stack([x, y, cam_coords[..., 2]], -1)\n\n  # Project ray origins and directions to NDC space if pixtocam_ndc is provided.\n  if pixtocam_ndc is not None:\n    origins_ndc, directions_ndc = convert_to_ndc(\n        origins, directions, pixtocam_ndc, xnp=xnp\n    )\n    origins, directions = origins_ndc, directions_ndc\n\n  # Convert pixel coordinates to image plane in world space.\n  imageplane = pix_coords[..., :2]\n\n  return origins, directions, viewdirs, radii, imageplane"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Shift pixel coordinates to NDC space.\n  if pixtocam_ndc is not None:\n    pix_x_ndc, pix_y_ndc = pix_x_int, pix_y_int\n    pix_x_int, pix_y_int = 2.0 * pix_x_int / pix_x_int.shape[-1] - 1.0, 2.0 * pix_y_int / pix_y_int.shape[-1] - 1.0\n\n  # Convert pixel coordinates to camera space.\n  origins, directions = convert_to_ndc(\n      origins=xnp.stack([pix_x_int, pix_y_int, xnp.ones_like(pix_x_int)], axis=-1),\n      directions=xnp.stack([pix_x_int, pix_y_int, xnp.zeros_like(pix_x_int)], axis=-1),\n      pixtocam=pixtocams,\n      xnp=xnp,\n  )\n\n  # Convert camera space to world space.\n  origins = jax.vmap(spin_math.matmul)(camtoworlds, origins)\n  directions = jax.vmap(spin_math.matmul)(camtoworlds[..., :3, :3], directions)\n\n  # Normalize direction vectors.\n  viewdirs = math.normalize(directions)\n\n  # Compute ray differential radii.\n  radii = None\n  if camtype == ProjectionType.PERSPECTIVE:\n    radii = jnp.sqrt(jnp.sum(origins**2, axis=-1))\n\n  # Correct for distortion.\n  if distortion_params is not None:\n    x, y = _radial_and_tangential_distort(\n        pix_x_ndc, pix_y_ndc, **distortion_params\n    )\n    imageplane = xnp.stack([x, y], axis=-1)\n  else:\n    imageplane = xnp.stack([pix_x_ndc, pix_y_ndc], axis=-1)\n\n  return origins, directions, viewdirs, radii, imageplane"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Convert pixel coordinates to NDC space if pixtocam_ndc is provided.\n  if pixtocam_ndc is not None:\n    pixtocams = pixtocam_ndc\n\n  # Convert pixel coordinates to camera coordinates.\n  camera_dirs = xnp.stack(\n      [\n          (pix_x_int - pixtocams[0, 2]) / pixtocams[0, 0],\n          (pix_y_int - pixtocams[1, 2]) / pixtocams[1, 1],\n          xnp.ones_like(pix_x_int),\n      ],\n      axis=-1,\n  )\n\n  if camtype == ProjectionType.PERSPECTIVE:\n    # Convert camera coordinates to world space.\n    origins = xnp.einsum('...ij,...j->...i', camtoworlds[:, :3, :3], camera_dirs)\n    directions = xnp.einsum('...ij,...j->...i', camtoworlds[:, :3, :3], camera_dirs) - camtoworlds[:, :3, 3]\n\n    # Normalize the directions to get viewdirs.\n    viewdirs = xnp.linalg.norm(directions, axis=-1, keepdims=True)\n    viewdirs = directions / viewdirs\n\n    # Compute differential radii.\n    radii = xnp.ones_like(pix_x_int)\n\n    # Compute image plane coordinates.\n    imageplane = xnp.stack([pix_x_int, pix_y_int], axis=-1)\n\n  elif camtype == ProjectionType.FISHEYE:\n    # Convert camera coordinates to world space.\n    ray_dirs = camera_dirs\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs, -1, 0)\n    ray_dirs = xnp.moveaxis(ray_dirs"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Shift pixel coordinates to NDC space.\n  if pixtocam_ndc is not None:\n    pix_x_int, pix_y_int = pix_x_int.astype(float), pix_y_int.astype(float)\n    pix_x_ndc = (pix_x_int + 0.5) / xnp.array(pix_x_int.shape[-1])\n    pix_y_ndc = (pix_y_int + 0.5) / xnp.array(pix_y_int.shape[-2])\n    pix_x_ndc = 2 * pix_x_ndc - 1\n    pix_y_ndc = 1 - 2 * pix_y_ndc\n    pix_x_ndc, pix_y_ndc = pix_x_ndc[..., None], pix_y_ndc[..., None]\n    pix_x_ndc, pix_y_ndc = xnp.broadcast_arrays(pix_x_ndc, pix_y_ndc)\n    pix_x_int, pix_y_int = pix_x_ndc, pix_y_ndc\n\n  # Shift ray origins to near plane, such that oz = -near.\n  # This makes the new near bound equal to 0.\n  t = -(near + origins[Ellipsis, 2]) / directions[Ellipsis, 2]\n  origins = origins + t[Ellipsis, None] * directions\n\n  dx, dy, dz = xnp.moveaxis(directions, -1, 0)\n  ox, oy, oz = xnp.moveaxis(origins, -1, 0)\n\n  xmult = 1.0 / pixtocams[0, 2]  # Equal to -2. * focal / cx\n  ymult = 1.0 / pixtocams[1, 2]  # Equal to -2. * focal / cy\n\n  # Perspective projection into NDC for the t = 0 near points\n  #     origins + 0 * directions\n  origins_ndc = xnp.stack(\n      [xmult * ox / oz, ymult * oy / oz, -xnp.ones_like(oz)], axis=-1\n  )\n\n  # Perspective projection into NDC for the t = infinity far points\n  #     origins + infinity * directions\n  infinity_ndc = xnp.stack(\n      [xmult * dx / dz, ymult * dy / dz, xnp.ones_like(oz)], axis=-1\n  )\n\n  # directions_ndc points from origins_ndc to infinity_ndc\n  directions_ndc = infinity_ndc - origins_ndc\n\n  return origins_ndc, directions_ndc, directions, directions, infinity_ndc"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Shift pixel coordinates to NDC space if necessary.\n  if pixtocam_ndc is not None:\n    pix_x_ndc = (pix_x_int + 0.5) / xnp.array(pix_x_int.shape[-1])\n    pix_y_ndc = (pix_y_int + 0.5) / xnp.array(pix_y_int.shape[-2])\n    pix_x_ndc = 2.0 * pix_x_ndc - 1.0\n    pix_y_ndc = 1.0 - 2.0 * pix_y_ndc\n    pix_x_ndc = xnp.broadcast_to(pix_x_ndc, pixtocams.shape[:-2] + pix_x_ndc.shape)\n    pix_y_ndc = xnp.broadcast_to(pix_y_ndc, pixtocams.shape[:-2] + pix_y_ndc.shape)\n    pixtocams = pixtocam_ndc\n\n  # Apply the inverse intrinsics to get the camera coordinates.\n  cam_x = (pix_x_int - pixtocams[..., 0, 2]) / pixtocams[..., 0, 0]\n  cam_y = (pix_y_int - pixtocams[..., 1, 2]) / pixtocams[..., 1, 1]\n  cam_z = xnp.ones_like(cam_x)\n  if distortion_params is not None:\n    cam_x, cam_y = _radial_and_tangential_distort(\n        cam_x, cam_y, **distortion_params\n    )\n\n  # Convert to camera coordinates.\n  cam_coords = xnp.stack([cam_x, cam_y, cam_z], axis=-1)\n\n  # Convert to world coordinates.\n  cam_coords = xnp.broadcast_to(cam_coords, camtoworlds.shape[:-2] + cam_coords.shape)\n  origins = spin_math.matmul(camtoworlds, cam_coords)\n\n  # Compute ray directions.\n  directions = origins - camtoworlds[..., :3, 3]\n  directions = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n\n  # Compute normalized view directions.\n  viewdirs = -directions\n\n  # Compute differential radii.\n  radii = xnp.ones_like(pix_x_int)\n\n  # Compute image plane coordinates.\n  imageplane = xnp.stack([pix_x_int, pix_y_int], axis=-1)\n\n  return origins, directions, viewdirs, radii, imageplane"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Shift pixel coordinates to NDC space for perspective projection.\n  if camtype == ProjectionType.PERSPECTIVE and pixtocam_ndc is not None:\n    pix_x_ndc, pix_y_ndc = pix_x_int, pix_y_int\n    pix_x_int, pix_y_int = pix_x_int / pix_x_int.max(), pix_y_int / pix_y_int.max()\n\n  # Convert pixel coordinates to camera coordinates using inverse intrinsics.\n  pix_homogeneous = xnp.stack([pix_x_int, pix_y_int, xnp.ones_like(pix_x_int)], axis=-1)\n  pix_cam = xnp.einsum('...ij,...j->...i', pixtocams, pix_homogeneous)\n\n  # Convert camera coordinates to world coordinates using extrinsics.\n  origins = xnp.einsum('...ij,...j->...i', camtoworlds[..., :3, :3], pix_cam) + camtoworlds[..., :3, 3]\n\n  # Compute ray directions using normalized camera coordinates.\n  if camtype == ProjectionType.PERSPECTIVE:\n    directions = xnp.linalg.norm(origins, axis=-1, keepdims=True)\n  else:\n    directions = xnp.ones_like(origins)\n\n  # Normalize ray directions to unit vectors.\n  directions = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n\n  # Normalize view directions to unit vectors.\n  viewdirs = -directions\n\n  # Compute ray differential radii.\n  radii = xnp.linalg.norm(xnp.cross(pix_cam[..., :2] + 1, directions), axis=-1)\n\n  # Compute image plane coordinates.\n  imageplane = xnp.stack([pix_x_int, pix_y_int], axis=-1)\n\n  return origins, directions, viewdirs, radii, imageplane"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Shift pixel coordinates to the center of the pixel.\n  pix_x = pix_x_int + 0.5\n  pix_y = pix_y_int + 0.5\n\n  # Convert to NDC.\n  if camtype == ProjectionType.PERSPECTIVE:\n    origins_ndc, directions_ndc = convert_to_ndc(\n        origins=pixtocams[Ellipsis, :3, :3],\n        directions=pixtocams[Ellipsis, :3, :3],\n        pixtocam=pixtocam_ndc,\n        xnp=xnp,\n    )\n  else:\n    raise ValueError(f'Camera type {camtype} not supported.')\n\n  # Set ray origins to the camera position.\n  origins = camtoworlds[Ellipsis, :3, -1]\n\n  # Compute ray directions.\n  dx, dy, dz = xnp.moveaxis(directions_ndc, -1, 0)\n  ox, oy, oz = xnp.moveaxis(origins_ndc, -1, 0)\n  ray_dirs = xnp.stack([dx / dz, dy / dz, -xnp.ones_like(dz)], axis=-1)\n\n  # Compute view directions.\n  viewdirs = -ray_dirs\n\n  # Compute differential radii.\n  radii = xnp.zeros_like(ox)\n\n  # Compute image plane coordinates.\n  imageplane = xnp.stack([pix_x / xnp.array(pixtocams.shape[-2], dtype=xnp.float32), pix_y / xnp.array(pixtocams.shape[-3], dtype=xnp.float32)], axis=-1)\n\n  return origins, ray_dirs, viewdirs, radii, imageplane"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Shift ray origins to near plane, such that oz = -near.\n  # This makes the new near bound equal to 0.\n  t = -(near + origins[Ellipsis, 2]) / directions[Ellipsis, 2]\n  origins = origins + t[Ellipsis, None] * directions\n\n  dx, dy, dz = xnp.moveaxis(directions, -1, 0)\n  ox, oy, oz = xnp.moveaxis(origins, -1, 0)\n\n  xmult = 1.0 / pixtocams[0, 2]  # Equal to -2. * focal / cx\n  ymult = 1.0 / pixtocams[1, 2]  # Equal to -2. * focal / cy\n\n  # Perspective projection into NDC for the t = 0 near points\n  #     origins + 0 * directions\n  origins_ndc = xnp.stack(\n      [xmult * ox / oz, ymult * oy / oz, -xnp.ones_like(oz)], axis=-1\n  )\n\n  # Perspective projection into NDC for the t = infinity far points\n  #     origins + infinity * directions\n  infinity_ndc = xnp.stack(\n      [xmult * dx / dz, ymult * dy / dz, xnp.ones_like(oz)], axis=-1\n  )\n\n  # directions_ndc points from origins_ndc to infinity_ndc\n  directions_ndc = infinity_ndc - origins_ndc\n\n  return origins_ndc, directions_ndc"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Shift pixel coordinates to NDC space if pixtocam_ndc is provided.\n  if pixtocam_ndc is not None:\n    pix_x_ndc, pix_y_ndc = (pix_x_int - pixtocam_ndc[0, 2]) / pixtocam_ndc[0, 0], (pix_y_int - pixtocam_ndc[1, 2]) / pixtocam_ndc[1, 1]\n  else:\n    pix_x_ndc, pix_y_ndc = pix_x_int, pix_y_int\n\n  # Convert pixel coordinates to camera coordinates.\n  cam_x, cam_y = (pix_x_ndc - pixtocams[0, 2]) / pixtocams[0, 0], (pix_y_ndc - pixtocams[1, 2]) / pixtocams[1, 1]\n\n  # Compute ray directions in camera coordinates.\n  if camtype == ProjectionType.PERSPECTIVE:\n    ray_dir_cam = xnp.stack([cam_x, cam_y, -xnp.ones_like(cam_x)], axis=-1)\n  else:\n    ray_dir_cam = xnp.stack([cam_x, cam_y, xnp.ones_like(cam_x)], axis=-1)\n    ray_dir_cam = xnp.linalg.norm(ray_dir_cam, axis=-1, keepdims=True)\n\n  # Convert ray directions to world coordinates.\n  ray_dir_world = xnp.matmul(camtoworlds[..., :3, :3], ray_dir_cam[..., None])[..., 0]\n\n  # Compute ray origins in world coordinates.\n  ray_orig_world = camtoworlds[..., :3, -1]\n\n  # Compute normalized view directions.\n  view_dirs = xnp.linalg.norm(ray_dir_world, axis=-1, keepdims=True)\n  view_dirs = ray_dir_world / view_dirs\n\n  # Compute ray differential radii.\n  radii = xnp.linalg.norm(ray_dir_cam, axis=-1, keepdims=True)\n\n  # Compute image plane coordinates.\n  image_plane = xnp.stack([pix_x_ndc, pix_y_ndc], axis=-1)\n\n  return ray_orig_world, ray_dir_world, view_dirs, radii, image_plane"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Shift ray origins to near plane, such that oz = -near.\n  # This makes the new near bound equal to 0.\n  t = -(near + origins[Ellipsis, 2]) / directions[Ellipsis, 2]\n  origins = origins + t[Ellipsis, None] * directions\n\n  dx, dy, dz = xnp.moveaxis(directions, -1, 0)\n  ox, oy, oz = xnp.moveaxis(origins, -1, 0)\n\n  xmult = 1.0 / pixtocams[0, 2]  # Equal to -2. * focal / cx\n  ymult = 1.0 / pixtocams[1, 2]  # Equal to -2. * focal / cy\n\n  # Perspective projection into NDC for the t = 0 near points\n  #     origins + 0 * directions\n  origins_ndc = xnp.stack(\n      [xmult * ox / oz, ymult * oy / oz, -xnp.ones_like(oz)], axis=-1\n  )\n\n  # Perspective projection into NDC for the t = infinity far points\n  #     origins + infinity * directions\n  infinity_ndc = xnp.stack(\n      [xmult * dx / dz, ymult * dy / dz, xnp.ones_like(oz)], axis=-1\n  )\n\n  # directions_ndc points from origins_ndc to infinity_ndc\n  directions_ndc = infinity_ndc - origins_ndc\n\n  return origins_ndc, directions_ndc"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  t = -(near + origins[Ellipsis, 2]) / directions[Ellipsis, 2]\n  origins = origins + t[Ellipsis, None] * directions\n\n  dx, dy, dz = xnp.moveaxis(directions, -1, 0)\n  ox, oy, oz = xnp.moveaxis(origins, -1, 0)\n\n  xmult = 1.0 / pixtocam[0, 2]  # Equal to -2. * focal / cx\n  ymult = 1.0 / pixtocam[1, 2]  # Equal to -2. * focal / cy\n\n  # Perspective projection into NDC for the t = 0 near points\n  #     origins + 0 * directions\n  origins_ndc = xnp.stack(\n      [xmult * ox / oz, ymult * oy / oz, -xnp.ones_like(oz)], axis=-1\n  )\n\n  # Perspective projection into NDC for the t = infinity far points\n  #     origins + infinity * directions\n  infinity_ndc = xnp.stack(\n      [xmult * dx / dz, ymult * dy / dz, xnp.ones_like(oz)], axis=-1\n  )\n\n  # directions_ndc points from origins_ndc to infinity_ndc\n  directions_ndc = infinity_ndc - origins_ndc\n\n  return origins_ndc, directions_ndc"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Shift pixel coordinates to NDC if provided.\n  if pixtocam_ndc is not None:\n    pix_x_int, pix_y_int = pix_x_int.astype(float), pix_y_int.astype(float)\n    pix_x_int = (pix_x_int + 0.5) / xnp.array(pix_x_int.shape[-1]) - 0.5\n    pix_y_int = (pix_y_int + 0.5) / xnp.array(pix_y_int.shape[-2]) - 0.5\n\n  # Normalize pixel coordinates to [-1, 1] if using NDC.\n  if camtype == ProjectionType.PERSPECTIVE and pixtocam_ndc is not None:\n    pix_x_int = 2.0 * pix_x_int - 1.0\n    pix_y_int = 2.0 * pix_y_int - 1.0\n\n  # Convert pixel coordinates to camera space.\n  pixcoords = xnp.stack([pix_x_int, pix_y_int, xnp.ones_like(pix_x_int)], -1)\n  camcoords = xnp.einsum('...ij,...j->...i', pixtocams, pixcoords)\n\n  # Apply distortion correction if provided.\n  if distortion_params is not None:\n    if camtype == ProjectionType.PERSPECTIVE:\n      # Correct for distortion.\n      x, y = _radial_and_tangential_distort(\n          camcoords[Ellipsis, 0],\n          camcoords[Ellipsis, 1],\n          **distortion_params,\n      )\n      camcoords = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  # Convert camera space to world space.\n  origins = xnp.einsum('...ij,...j->...i', camtoworlds[Ellipsis, :3, :3], camcoords)\n  directions = xnp.einsum('...ij,...j->...i', camtoworlds[Ellipsis, :3, :3], xnp.ones_like(camcoords))\n\n  # Normalize directions.\n  directions = xnp.moveaxis(directions, -1, 0)\n  directions = xnp.moveaxis(directions / xnp.linalg.norm(directions, axis=0), 0, -1)\n\n  # Compute normalized view directions.\n  viewdirs = -directions\n\n  # Compute ray differential radii.\n  radii = xnp.linalg.norm(camcoords[..., :2], axis=-1)\n\n  # Compute image plane coordinates.\n  imageplane = camcoords[..., :2]\n\n  return origins, directions, viewdirs, radii, imageplane"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  origins = None\n  directions = None\n  viewdirs = None\n  radii = None\n  imageplane = None\n\n  # Implementation of the function\n\n  return origins, directions, viewdirs, radii, imageplane"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Shift pixel coordinates to the center of the pixels.\n  pix_x = pix_x_int + 0.5\n  pix_y = pix_y_int + 0.5\n\n  # Convert pixel coordinates to NDC space.\n  if pixtocam_ndc is not None:\n    pix_x, pix_y = pix_x - pixtocam_ndc[0, 2], pix_y - pixtocam_ndc[1, 2]\n    pix_x, pix_y = pix_x / pixtocam_ndc[0, 0], pix_y / pixtocam_ndc[1, 1]\n\n  # Convert pixel coordinates to camera coordinates.\n  cam_x = pix_x * pixtocams[Ellipsis, 0, 0] + pixtocams[Ellipsis, 0, 2]\n  cam_y = pix_y * pixtocams[Ellipsis, 1, 1] + pixtocams[Ellipsis, 1, 2]\n\n  # Compute ray directions in camera coordinates.\n  if camtype == ProjectionType.PERSPECTIVE:\n    ray_dirs_cam = xnp.stack([cam_x, cam_y, -xnp.ones_like(cam_x)], axis=-1)\n  else:\n    raise ValueError(f'Camera projection type {camtype} is not supported.')\n\n  # Apply distortion correction if available.\n  if distortion_params is not None:\n    cam_x, cam_y = _radial_and_tangential_undistort(\n        cam_x, cam_y, **distortion_params\n    )\n    ray_dirs_cam = xnp.stack([cam_x, cam_y, -xnp.ones_like(cam_x)], axis=-1)\n\n  # Convert ray directions to world coordinates.\n  ray_dirs_world = mat_vec_mul(camtoworlds[Ellipsis, :3, :3], ray_dirs_cam)\n\n  # Compute ray origins in world coordinates.\n  ray_origins_world = camtoworlds[Ellipsis, :3, -1]\n\n  # Compute view directions.\n  view_dirs_world = -ray_dirs_world\n\n  # Compute differential radii.\n  radii = xnp.sqrt(xnp.sum(ray_dirs_world ** 2, axis=-1))\n\n  # Compute image plane coordinates.\n  image_plane = xnp.stack([cam_x, cam_y], axis=-1)\n\n  return ray_origins_world, ray_dirs_world, view_dirs_world, radii, image_plane"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Shift pixel coordinates to NDC space for perspective projection.\n  if camtype == ProjectionType.PERSPECTIVE and pixtocam_ndc is not None:\n    pix_x_ndc, pix_y_ndc = pix_x_int, pix_y_int\n    pix_x_int, pix_y_int = pix_x_int - 0.5, pix_y_int - 0.5\n    pix_x_int, pix_y_int = 2.0 * pix_x_int / pix_x_int.shape[-1], 2.0 * pix_y_int / pix_y_int.shape[-2]\n    pix_x_int, pix_y_int = pix_x_int[..., None], pix_y_int[..., None]\n\n  # Convert pixel coordinates to camera coordinates.\n  cam_x = pix_x_int * pixtocams[Ellipsis, 0, 0] + pixtocams[Ellipsis, 0, 2]\n  cam_y = pix_y_int * pixtocams[Ellipsis, 1, 1] + pixtocams[Ellipsis, 1, 2]\n\n  # Apply distortion correction if provided.\n  if distortion_params is not None:\n    cam_x, cam_y = _radial_and_tangential_distort(cam_x, cam_y, **distortion_params)\n\n  # Map pixel coordinates to rays in camera space.\n  ray_origins = xnp.stack([cam_x, cam_y, -xnp.ones_like(cam_x)], axis=-1)\n  ray_directions = xnp.stack([cam_x, cam_y, -xnp.ones_like(cam_x)], axis=-1)\n\n  # Convert rays from camera to world space.\n  world_ray_origins = mat_vec_mul(camtoworlds, ray_origins)\n  world_ray_directions = mat_vec_mul(camtoworlds, ray_directions)\n\n  # Normalize ray directions to get view directions.\n  view_directions = xnp.linalg.norm(world_ray_directions, axis=-1, keepdims=True)\n  view_directions = world_ray_directions / view_directions\n\n  # Compute differential radii for mip-NeRF cones.\n  radii = xnp.linalg.norm(ray_directions, axis=-1, keepdims=True)\n\n  # If in NDC space, convert ray origins and directions to NDC.\n  if camtype == ProjectionType.PERSPECTIVE and pixtocam_ndc is not None:\n    world_ray_origins = mat_vec_mul(pixtocam_ndc, world_ray_origins)\n    world_ray_directions = mat_vec_mul(pixtocam_ndc, world_ray_directions)\n\n  # Compute image plane coordinates for the projection of pixel coordinates in world space.\n  image_plane = xnp.stack([cam_x, cam_y], axis=-1)\n\n  return world_ray_origins, world_ray_directions, view_directions, radii, image_plane"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Shift pixel coordinates to NDC space if using NDC projection.\n  if pixtocam_ndc is not None:\n    pix_x_int, pix_y_int = pix_x_int / pix_x_int.max(), pix_y_int / pix_y_int.max()\n    pix_x_ndc = 2.0 * pix_x_int - 1.0\n    pix_y_ndc = 1.0 - 2.0 * pix_y_int\n    pix_x_ndc, pix_y_ndc = pix_x_ndc * pixtocam_ndc[0, 0], pix_y_ndc * pixtocam_ndc[1, 1]\n\n  # Convert pixel coordinates to camera coordinates.\n  pix_coords = xnp.stack([pix_x_int, pix_y_int, xnp.ones_like(pix_x_int)], axis=-1)\n  cam_coords = xnp.einsum('...ij,...j->...i', pixtocams, pix_coords)\n\n  # Apply distortion correction if distortion parameters are provided.\n  if distortion_params is not None:\n    pix_x_dist, pix_y_dist = _radial_and_tangential_distort(\n        cam_coords[Ellipsis, 0],\n        cam_coords[Ellipsis, 1],\n        **distortion_params,\n    )\n    cam_coords = xnp.stack([pix_x_dist, pix_y_dist, xnp.ones_like(pix_x_dist)], axis=-1)\n\n  # Convert camera coordinates to world coordinates.\n  origins = cam_coords\n  directions = origins - camtoworlds[Ellipsis, :3, 3]\n\n  # Normalize the directions to get view directions.\n  viewdirs = xnp.linalg.norm(directions, axis=-1, keepdims=True)\n  directions = directions / viewdirs\n\n  # Compute differential radii for mip-NeRF cones.\n  radii = viewdirs / xnp.sqrt(xnp.array([3.0], dtype=viewdirs.dtype))\n\n  # Compute image plane coordinates.\n  if pixtocam_ndc is not None:\n    imageplane = xnp.stack([pix_x_ndc, pix_y_ndc], axis=-1)\n  else:\n    imageplane = None\n\n  return origins, directions, viewdirs, radii, imageplane"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Shift pixel coordinates to NDC space.\n  if pixtocam_ndc is not None:\n    pix_x_ndc = (pix_x_int + 0.5) / xnp.array(pix_x_int.shape[-1])\n    pix_y_ndc = (pix_y_int + 0.5) / xnp.array(pix_y_int.shape[-2])\n    pix_x_ndc = 2.0 * pix_x_ndc - 1.0\n    pix_y_ndc = 2.0 * pix_y_ndc - 1.0\n    pix_x_int, pix_y_int = pix_x_ndc, pix_y_ndc\n\n  # Convert pixel coordinates to camera coordinates.\n  ray_o = xnp.stack([pix_x_int, pix_y_int, xnp.ones_like(pix_x_int)], -1)\n  ray_o = xnp.moveaxis(ray_o, -1, 0)\n  ray_o = xnp.moveaxis(ray_o, -1, 0)\n  ray_o = xnp.broadcast_to(ray_o, pixtocams.shape[:-2] + ray_o.shape)\n\n  # Compute ray directions in camera space.\n  ray_d = xnp.moveaxis(pixtocams @ ray_o, -1, 0)\n  ray_d = xnp.moveaxis(ray_d, -1, 0)\n\n  # Convert ray origins and directions to world space.\n  ray_o = xnp.moveaxis(ray_o, -1, 0)\n  ray_d = xnp.moveaxis(ray_d, -1, 0)\n  ray_o = xnp.moveaxis(ray_o, -1, 0)\n  ray_d = xnp.moveaxis(ray_d, -1, 0)\n  ray_o = xnp.moveaxis(ray_o, -1, 0)\n  ray_d = xnp.moveaxis(ray_d, -1, 0)\n  ray_o = xnp.moveaxis(ray_o, -1, 0)\n  ray_d = xnp.moveaxis(ray_d, -1, 0)\n\n  # Normalize ray directions.\n  viewdirs = xnp.moveaxis(xnp.moveaxis(ray_d, -1, 0), -1, 0)\n  ray_d = xnp.moveaxis(ray_d, -1, 0)\n  ray_d = xnp.moveaxis(ray_d, -1, 0)\n  ray_d = xnp.moveaxis(ray_d, -1, 0)\n  ray_d = xnp.moveaxis(ray_d, -1, 0)\n  ray_d = xnp.moveaxis(ray_d, -1, 0)\n  ray_d = xnp.moveaxis(ray_d, -1, 0)\n  ray_d = xnp.moveaxis(ray_d, -1, 0)\n  ray_d = xnp.moveaxis(ray_d, -1, 0)\n  ray_d = xnp.moveaxis(ray_d, -1, 0)\n  ray_d = xnp.moveaxis(ray_d, -1, 0)\n  ray_d = xnp.moveaxis(ray_d, -1, 0)\n  ray_d = xnp.moveaxis(ray_d, -1, 0)\n\n  # Compute differential radii.\n  radii = xnp.ones_like(pix_x_int)\n\n  # Compute image plane coordinates.\n  imageplane = xnp.stack([pix_x_int, pix_y_int], -1)\n\n  return ray_o, ray_d, viewdirs, radii, imageplane"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Shift pixel coordinates to near plane in NDC space.\n  near = 1.0\n  origins_ndc, directions_ndc = convert_to_ndc(\n      origins=0.0,\n      directions=1.0,\n      pixtocam=pixtocam_ndc,\n      near=near,\n      xnp=xnp,\n  )\n\n  # Shift pixel coordinates to near plane in camera space.\n  origins, directions = convert_to_ndc(\n      origins=pix_x_int,\n      directions=pix_y_int,\n      pixtocam=pixtocams,\n      near=near,\n      xnp=xnp,\n  )\n\n  # Apply distortion correction if provided.\n  if distortion_params is not None:\n      # Correct for distortion.\n      x, y = _radial_and_tangential_distort(\n          origins[Ellipsis, 0],\n          origins[Ellipsis, 1],\n          **distortion_params,\n      )\n      origins = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  # Compute ray origins and directions in world space.\n  origins = mat_vec_mul(camtoworlds, origins)\n  directions = mat_vec_mul(camtoworlds[Ellipsis, :3, :3], directions)\n\n  # Compute normalized view directions.\n  viewdirs = xnp.linalg.norm(-directions, axis=-1)\n\n  # Compute ray differential radii.\n  radii = xnp.zeros_like(viewdirs)\n\n  # Compute image plane coordinates.\n  imageplane = xnp.stack([pix_x_int, pix_y_int], axis=-1)\n\n  return origins, directions, viewdirs, radii, imageplane"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Shift ray origins to near plane, such that oz = -near.\n  # This makes the new near bound equal to 0.\n  t = -(near + origins[Ellipsis, 2]) / directions[Ellipsis, 2]\n  origins = origins + t[Ellipsis, None] * directions\n\n  dx, dy, dz = xnp.moveaxis(directions, -1, 0)\n  ox, oy, oz = xnp.moveaxis(origins, -1, 0)\n\n  xmult = 1.0 / pixtocams[0, 2]  # Equal to -2. * focal / cx\n  ymult = 1.0 / pixtocams[1, 2]  # Equal to -2. * focal / cy\n\n  # Perspective projection into NDC for the t = 0 near points\n  #     origins + 0 * directions\n  origins_ndc = xnp.stack(\n      [xmult * ox / oz, ymult * oy / oz, -xnp.ones_like(oz)], axis=-1\n  )\n\n  # Perspective projection into NDC for the t = infinity far points\n  #     origins + infinity * directions\n  infinity_ndc = xnp.stack(\n      [xmult * dx / dz, ymult * dy / dz, xnp.ones_like(oz)], axis=-1\n  )\n\n  # directions_ndc points from origins_ndc to infinity_ndc\n  directions_ndc = infinity_ndc - origins_ndc\n\n  return origins_ndc, directions_ndc"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Shift pixel coordinates to NDC space.\n  if pixtocam_ndc is not None:\n    pix_x_ndc, pix_y_ndc = pix_x_int, pix_y_int\n    pix_x_int, pix_y_int = pix_x_int - 0.5, pix_y_int - 0.5\n    pix_x_int, pix_y_int = pix_x_int / (pixtocam_ndc[0, 0] * 2), pix_y_int / (pixtocam_ndc[1, 1] * 2)\n\n  # Convert pixel coordinates to camera coordinates.\n  pix_coords = xnp.stack([pix_x_int, pix_y_int, xnp.ones_like(pix_x_int)], axis=-1)\n  cam_coords = xnp.einsum('...ij,...j->...i', pixtocams, pix_coords)\n\n  # Convert camera coordinates to world coordinates.\n  origins = cam_coords\n  directions = origins - camtoworlds[Ellipsis, :3, 3]\n\n  # Normalize the ray directions.\n  viewdirs = xnp.linalg.norm(directions, axis=-1, keepdims=True)\n  directions = directions / viewdirs\n\n  # Compute ray differential radii.\n  radii = xnp.sqrt((pix_x_int[Ellipsis, None] - pix_x_int[Ellipsis, None])**2 + (pix_y_int[Ellipsis, None] - pix_y_int[Ellipsis, None])**2)\n\n  # Compute image plane coordinates.\n  imageplane = xnp.stack([pix_x_int, pix_y_int], axis=-1)\n\n  return origins, directions, viewdirs, radii, imageplane"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / jnp.diff(t)"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / jnp.diff(t)"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / jnp.diff(t)"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / jnp.diff(t)"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / jnp.diff(t)"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / jnp.diff(t)"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / jnp.diff(t)"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / jnp.diff(t)"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / jnp.diff(t)"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / jnp.diff(t)"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / jnp.diff(t)"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / jnp.diff(t)"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / jnp.diff(t)"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / jnp.diff(t)"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / jnp.diff(t)"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / jnp.diff(t)"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / jnp.diff(t)"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / jnp.diff(t)"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / jnp.diff(t)"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / jnp.diff(t)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * jnp.linalg.norm(dirs, axis=-1) * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * jnp.linalg.norm(dirs, axis=-1) * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist / jnp.linalg.norm(dirs, axis=-1, keepdims=True)\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * jnp.linalg.norm(dirs, axis=-1) * tdist[..., 1:]\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * jnp.linalg.norm(dirs, axis=-1) * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * jnp.linalg.norm(dirs, axis=-1) * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * jnp.linalg.norm(dirs, axis=-1) * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "\n  density_delta = density * jnp.linalg.norm(dirs, axis=-1) * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * jnp.linalg.norm(dirs, axis=-1) * tdist[..., 1:]\n  weights = compute_alpha_weights_helper(density_delta, **kwargs)\n  return weights"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * jnp.linalg.norm(dirs, axis=-1) * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * jnp.linalg.norm(dirs, axis=-1) * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist\n  weights = compute_alpha_weights_helper(density_delta, **kwargs)\n  return weights"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * jnp.linalg.norm(dirs, axis=-1) * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * jnp.linalg.norm(dirs, axis=-1) * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * jnp.linalg.norm(dirs, axis=-1) * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * jnp.linalg.norm(dirs, axis=-1) * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * jnp.linalg.norm(dirs, axis=-1) * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * (tdist[Ellipsis, 1:] - tdist[Ellipsis, :-1])\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return p * td"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return p * td"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  tp = jnp.concatenate([t[..., :1], t], axis=-1)\n  wp = jnp.diff(tp) * p\n  w = math.safe_div(wp, jnp.sum(wp, axis=-1, keepdims=True))\n  return w"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  w = p * td\n  w = w / jnp.sum(w)\n  return w"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  w = p * td\n  w = w / jnp.sum(w)\n  return w"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, p * td)"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  w = p * td\n  w = w / jnp.sum(w)\n  return w"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return p * td"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  w = p * td\n  w = w / jnp.sum(w)\n  return w"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  w = p * td\n  return w / jnp.sum(w)"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, p * td)"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return p * td"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, p * td)"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  w = p * td\n  w = w / jnp.sum(w)\n  return w"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  w = p * td\n  w = w / jnp.sum(w)\n  return w"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  w = p * td\n  w = w / jnp.sum(w)\n  return w"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  w = p * td\n  return w / jnp.sum(w)"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  w = p * td\n  w = w / jnp.sum(w)\n  return w"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  w = p * td\n  return w / jnp.sum(w)"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return p * td"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  if num_samples <= 1:\n    raise ValueError(f'num_samples must be > 1, is {num_samples}.')\n\n  if rng is None:\n    return jnp.linspace(t[..., 0], t[..., -1], num_samples)\n\n  # Sample a set of points from the step function.\n  centers = invert_cdf(jax.random.uniform(rng, (num_samples,) + t.shape[:-1]), t, w_logits)\n\n  if deterministic_center:\n    # The intervals we return will span the midpoints of each adjacent sample.\n    mid = (centers[Ellipsis, 1:] + centers[Ellipsis, :-1]) / 2\n    first = 2 * centers[Ellipsis, :1] - mid[Ellipsis, :1]\n    last = 2 * centers[Ellipsis, -1:] - mid[Ellipsis, -1:]\n    samples = jnp.concatenate([first, mid, last], axis=-1)\n  else:\n    samples = centers\n\n  # Jitter the samples if single_jitter is False.\n  if not single_jitter:\n    jitter = jax.random.uniform(rng, samples.shape) * eps\n    samples += jitter\n\n  return samples"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  if num_samples <= 1:\n    raise ValueError(f'num_samples must be > 1, is {num_samples}.')\n\n  if rng is not None:\n    u = jax.random.uniform(rng, shape=(num_samples, *t.shape[:-1]), minval=eps, maxval=1.0 - eps)\n  else:\n    u = jnp.linspace(eps, 1.0 - eps, num_samples)\n\n  t_samples = invert_cdf(u, t, w_logits)\n\n  if deterministic_center:\n    t_samples = (t_samples[..., 1:] + t_samples[..., :-1]) / 2\n\n  if single_jitter and rng is not None:\n    jitter = jax.random.uniform(rng, shape=t_samples.shape, minval=-eps, maxval=eps)\n    t_samples += jitter\n\n  return t_samples"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  if num_samples <= 1:\n    raise ValueError(f'num_samples must be > 1, is {num_samples}.')\n\n  # Sample a set of points from the step function.\n  if rng is not None:\n      u = jax.random.uniform(rng, shape=(num_samples, *t.shape[:-1]), minval=eps, maxval=1.0 - eps)\n      centers = invert_cdf(u, t, w_logits)\n  else:\n      centers = linspline.linspace(t, num_samples)\n\n  if deterministic_center:\n      return centers\n\n  # Jitter the samples if single_jitter is False.\n  if not single_jitter:\n      jitter = jax.random.uniform(rng, shape=centers.shape, minval=-eps, maxval=eps)\n      centers = centers + jitter\n\n  return centers"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  if num_samples <= 1:\n    raise ValueError(f'num_samples must be > 1, is {num_samples}.')\n\n  if rng is None:\n    # Deterministic sampling based on linspace.\n    return jnp.linspace(t[..., 0], t[..., -1], num_samples)\n\n  # Random sampling method using the given random number generator.\n  u = jax.random.uniform(rng, shape=(num_samples,) + t.shape[:-1], minval=eps, maxval=1 - eps)\n\n  # Invert the CDF to get the samples.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  if single_jitter:\n    # Apply single jitter to all samples along each ray.\n    jitter = (t[..., 1:] - t[..., :-1]) / 2\n    t_samples += jitter * (2 * jax.random.uniform(rng, shape=t_samples.shape) - 1)\n\n  if deterministic_center:\n    # Center the samples in each interval.\n    t_samples = (t_samples[..., 1:] + t_samples[..., :-1]) / 2\n\n  return t_samples"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  if num_samples <= 1:\n    raise ValueError(f'num_samples must be > 1, is {num_samples}.')\n\n  if rng is None:\n    # Deterministic sampling based on linspace.\n    centers = jnp.linspace(t[..., 0], t[..., -1], num_samples + 1)[..., 1:-1]\n  else:\n    # Random sampling using the provided random number generator.\n    u = jax.random.uniform(rng, shape=(num_samples, *t.shape[:-1]), dtype=jnp.float32, minval=0, maxval=1 - eps)\n    centers = invert_cdf(u, t, w_logits)\n\n    if single_jitter:\n      # Jitter each sample along each ray by the same amount in the inverse CDF.\n      jitter = jax.random.uniform(rng, shape=(num_samples, *t.shape[:-1]), dtype=jnp.float32, minval=-eps, maxval=eps)\n      centers += jitter\n\n  if deterministic_center:\n    # Center the samples in each interval of the PDF.\n    widths = jnp.diff(t)\n    centers = t[..., :-1] + (centers * widths)\n\n  return centers"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  if num_samples <= 1:\n    raise ValueError(f'num_samples must be > 1, is {num_samples}.')\n\n  if rng is None:\n    return linspline.linspace(t, num_samples, deterministic_center)\n\n  # Sample a set of points from the step function.\n  centers = invert_cdf(jax.random.uniform(rng, (num_samples,) + w_logits.shape[:-1]), t, w_logits)\n\n  if single_jitter:\n    jitter = jax.random.uniform(rng, (num_samples,) + w_logits.shape[:-1]) * eps\n    samples = centers + jitter\n  else:\n    jitter = jax.random.uniform(rng, (num_samples, 2) + w_logits.shape[:-1]) * eps\n    samples = jnp.sort(jnp.concatenate([centers - jitter[:, :1], centers + jitter[:, 1:]], axis=1), axis=1)\n\n  return samples"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  if num_samples <= 1:\n    raise ValueError(f'num_samples must be > 1, is {num_samples}.')\n\n  if rng is None:\n    # Deterministic sampling based on linspace.\n    centers = jnp.linspace(t[..., 0], t[..., -1], num_samples + 1)[..., 1:-1]\n  else:\n    # Random sampling based on uniform distribution.\n    u = jax.random.uniform(rng, shape=(num_samples,) + t.shape[:-1], minval=eps, maxval=1.0 - eps)\n    centers = invert_cdf(u, t, w_logits)\n\n    if single_jitter:\n      # Jitter each sample along each ray by the same amount in the inverse CDF.\n      jitter = jnp.diff(t)\n      centers += jitter * (jax.random.uniform(rng, shape=centers.shape, minval=-0.5, maxval=0.5) - 0.5)\n\n  if deterministic_center:\n    # Center the samples in each interval of the PDF.\n    centers = (centers[Ellipsis, 1:] + centers[Ellipsis, :-1]) / 2\n\n  return centers"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  if num_samples <= 1:\n    raise ValueError(f'num_samples must be > 1, is {num_samples}.')\n\n  # Sample a set of points from the step function.\n  if rng is None:\n    centers = linspline.linspace(t, num_samples)\n  else:\n    u = jax.random.uniform(rng, (num_samples,) + t.shape[:-1] + (1,), minval=eps, maxval=1.0 - eps)\n    centers = invert_cdf(u, t, w_logits)\n\n  if deterministic_center:\n    # The intervals we return will span the midpoints of each adjacent sample.\n    mid = (centers[Ellipsis, 1:] + centers[Ellipsis, :-1]) / 2\n\n    # Each first/last fencepost is the reflection of the first/last midpoint\n    # around the first/last sampled center.\n    first = 2 * centers[Ellipsis, :1] - mid[Ellipsis, :1]\n    last = 2 * centers[Ellipsis, -1:] - mid[Ellipsis, -1:]\n    samples = jnp.concatenate([first, mid, last], axis=-1)\n  else:\n    samples = centers\n\n  return samples"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  if num_samples <= 1:\n    raise ValueError(f'num_samples must be > 1, is {num_samples}.')\n\n  if rng is not None:\n    # Random sampling\n    u = jax.random.uniform(rng, shape=(num_samples,) + t.shape[:-1] + (1,), dtype=t.dtype)\n    t_samples = invert_cdf(u, t, w_logits)\n  else:\n    # Deterministic sampling based on linspace\n    t_samples = jnp.linspace(t[..., 0], t[..., -1], num_samples)\n\n  if single_jitter:\n    jitter = (2 * jax.random.bernoulli(rng, 0.5, shape=(num_samples,) + t.shape[:-1] + (1,)) - 1) * eps\n    t_samples += jitter\n\n  if deterministic_center:\n    t_samples = (t_samples[..., 1:] + t_samples[..., :-1]) / 2\n\n  return t_samples"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  if num_samples <= 1:\n    raise ValueError(f'num_samples must be > 1, is {num_samples}.')\n\n  if rng is None:\n    return linspline.linspace(t, num_samples, deterministic_center)\n\n  # Sample a set of points from the step function.\n  centers = invert_cdf(jax.random.uniform(rng, (num_samples,)), t, w_logits)\n\n  if single_jitter:\n    jitter = eps * jax.random.uniform(rng, (num_samples,))\n    samples = centers + jitter\n  else:\n    jitter = eps * jax.random.uniform(rng, (num_samples,))\n    samples = centers + jitter\n\n  return samples"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  if num_samples <= 1:\n    raise ValueError(f'num_samples must be > 1, is {num_samples}.')\n\n  if rng is None:\n    # Deterministic sampling based on linspace.\n    centers = (t[Ellipsis, 1:] + t[Ellipsis, :-1]) / 2\n  else:\n    # Random sampling based on uniform distribution.\n    u = jax.random.uniform(rng, shape=(num_samples,) + t.shape[:-1], minval=0, maxval=1 - eps)\n    centers = invert_cdf(u, t, w_logits)\n\n    if single_jitter:\n      # Apply single jitter to all samples along each ray.\n      jitter = jax.random.uniform(rng, shape=t.shape[:-1], minval=-eps, maxval=eps)\n      centers += jitter[..., jnp.newaxis]\n\n  if deterministic_center:\n    # Centers the samples within each interval.\n    samples = centers\n  else:\n    # Samples span the entire PDF.\n    first = 2 * t[Ellipsis, :1] - centers[Ellipsis, :1]\n    last = 2 * t[Ellipsis, -1:] - centers[Ellipsis, -1:]\n    samples = jnp.concatenate([first, centers, last], axis=-1)\n\n  return samples"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  if num_samples <= 1:\n    raise ValueError(f'num_samples must be > 1, is {num_samples}.')\n\n  if rng is not None:\n    # Random sampling based on the inverse CDF.\n    u = jax.random.uniform(rng, shape=(num_samples,) + t.shape[:-1] + (1,), dtype=t.dtype)\n    t_samples = invert_cdf(u, t, w_logits)\n  else:\n    # Deterministic sampling based on linspace.\n    t_samples = jnp.linspace(t[..., 0], t[..., -1], num_samples + 1)[..., :-1]\n\n  if deterministic_center:\n    # Center the samples within each interval.\n    t_diff = jnp.diff(t, axis=-1)\n    t_samples = t_samples + 0.5 * t_diff\n\n  if single_jitter:\n    # Jitter all samples along each ray by the same amount in the inverse CDF.\n    jitter = jax.random.uniform(rng, shape=t_samples.shape, dtype=t_samples.dtype) * eps\n    t_samples = t_samples + jitter\n\n  return t_samples"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  if num_samples <= 1:\n    raise ValueError(f'num_samples must be > 1, is {num_samples}.')\n\n  if rng is None:\n    # Deterministic sampling based on linspace.\n    centers = (t[Ellipsis, 1:] + t[Ellipsis, :-1]) / 2\n  else:\n    # Random sampling.\n    u = jax.random.uniform(rng, (num_samples,) + t.shape[:-1] + (1,), minval=eps, maxval=1 - eps)\n    centers = invert_cdf(u, t, w_logits)\n\n    if single_jitter:\n      # Jitter each sample along each ray by the same amount in the inverse CDF.\n      jitter = (t[Ellipsis, 1:] - t[Ellipsis, :-1]) / 2\n      centers += jitter * (2 * jax.random.bernoulli(rng, 0.5, (num_samples,) + t.shape[:-1] + (1,)) - 1)\n\n  if deterministic_center:\n    # Centers are centered in each interval of the PDF.\n    samples = jnp.concatenate([t[Ellipsis, :1], centers, t[Ellipsis, -1:]], axis=-1)\n  else:\n    # Centers span the entire PDF.\n    samples = jnp.concatenate([centers, t[Ellipsis, -1:]], axis=-1)\n\n  return samples"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  if num_samples <= 1:\n    raise ValueError(f'num_samples must be > 1, is {num_samples}.')\n\n  if rng is None:\n    # Deterministic sampling based on linspace.\n    return jnp.linspace(t[..., 0], t[..., -1], num_samples)\n\n  # Random sampling method\n  u = jax.random.uniform(rng, shape=(num_samples,) + t.shape[:-1], minval=eps, maxval=1.0 - eps)\n  t_samples = invert_cdf(u, t, w_logits)\n\n  if single_jitter:\n    # Jitter each sample along each ray by the same amount in the inverse CDF.\n    jitter = (t[..., 1:] - t[..., :-1]) / 2\n    t_samples += jitter * (2 * jax.random.uniform(rng, shape=(num_samples,) + t.shape[:-1]) - 1)\n\n  if deterministic_center:\n    # Center the samples in each interval of the PDF.\n    t_samples = (t_samples[..., 1:] + t_samples[..., :-1]) / 2\n\n  return t_samples"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  if num_samples <= 1:\n    raise ValueError(f'num_samples must be > 1, is {num_samples}.')\n\n  if rng is None:\n    return linspline.linspace(t, num_samples)\n\n  # Sample a set of points from the step function.\n  centers = invert_cdf(jax.random.uniform(rng, (num_samples,) + w_logits.shape[:-1]), t, w_logits)\n\n  if single_jitter:\n    # Jitter every sample along each ray by the same amount in the inverse CDF.\n    jitter = (2 * jax.random.bernoulli(rng, 0.5, (num_samples,) + w_logits.shape[:-1]) - 1) * eps\n    samples = centers + jitter\n  else:\n    # Jitter each sample independently.\n    jitter = jax.random.uniform(rng, (num_samples,) + w_logits.shape[:-1]) * eps\n    samples = centers + jitter\n\n  if deterministic_center:\n    # Centers the samples in each interval of the PDF.\n    samples = (samples[..., 1:] + samples[..., :-1]) / 2\n\n  return samples"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  if num_samples <= 1:\n    raise ValueError(f'num_samples must be > 1, is {num_samples}.')\n\n  if rng is None:\n    return jnp.linspace(t[..., 0], t[..., -1], num_samples)\n\n  # Sample a set of points from the step function.\n  centers = invert_cdf(jax.random.uniform(rng, (num_samples,) + t.shape[:-1]), t, w_logits)\n\n  if deterministic_center:\n    # The intervals we return will span the midpoints of each adjacent sample.\n    mid = (centers[Ellipsis, 1:] + centers[Ellipsis, :-1]) / 2\n\n    # Each first/last fencepost is the reflection of the first/last midpoint\n    # around the first/last sampled center.\n    first = 2 * centers[Ellipsis, :1] - mid[Ellipsis, :1]\n    last = 2 * centers[Ellipsis, -1:] - mid[Ellipsis, -1:]\n    samples = jnp.concatenate([first, mid, last], axis=-1)\n  else:\n    samples = centers\n\n  return samples"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  if num_samples <= 1:\n    raise ValueError(f'num_samples must be > 1, is {num_samples}.')\n\n  if rng is None:\n    # Deterministic sampling based on linspace.\n    samples = jnp.linspace(t[..., 0], t[..., -1], num_samples)\n    return samples\n\n  # Sample uniform values and invert the CDF to obtain samples.\n  u = jax.random.uniform(rng, shape=(num_samples,) + t.shape[:-1], minval=eps, maxval=1.0 - eps)\n  t_samples = invert_cdf(u, t, w_logits)\n\n  if single_jitter:\n    # Jitter each sample along each ray by the same amount in the inverse CDF.\n    jitter = jax.random.uniform(rng, shape=(num_samples,) + t.shape[:-1], minval=-eps, maxval=eps)\n    t_samples += jitter\n  elif not deterministic_center:\n    # Jitter each sample independently.\n    jitter = jax.random.uniform(rng, shape=(num_samples,) + t.shape[:-1], minval=-eps, maxval=eps)\n    t_samples += jitter * jnp.diff(t)[..., None]\n\n  return t_samples"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  if num_samples <= 1:\n    raise ValueError(f'num_samples must be > 1, is {num_samples}.')\n\n  if rng is not None:\n    # Random sampling\n    u = jax.random.uniform(rng, shape=(num_samples,) + t.shape[:-1], dtype=jnp.float32)\n    t_samples = invert_cdf(u, t, w_logits)\n    if not single_jitter:\n      # Add independent jitter to each sample\n      jitter = jax.random.uniform(rng, shape=(num_samples,) + t.shape[:-1], dtype=jnp.float32)\n      t_samples = t_samples + (jnp.diff(t) * (jitter - 0.5))\n  else:\n    # Deterministic sampling based on linspace\n    t_samples = jnp.linspace(t[..., 0], t[..., -1], num_samples + 1)[..., 1:-1]\n    if deterministic_center:\n      # Center the samples in each interval\n      t_samples = (t_samples[Ellipsis, 1:] + t_samples[Ellipsis, :-1]) / 2\n\n  return t_samples"}
{"namespace": "stepfun.sample", "completion": "  if rng is None:\n    return jnp.linspace(t[..., 0], t[..., -1], num_samples)\n\n  utils.assert_valid_stepfun(t, w_logits)\n\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  # Generate random samples from the uniform distribution.\n  u = jax.random.uniform(rng, shape=(num_samples,) + t.shape[:-1], minval=0, maxval=1 - eps)\n\n  if deterministic_center:\n    # Use the inverse CDF to sample from the center of each interval.\n    t_samples = invert_cdf(0.5, t, w_logits)\n  else:\n    # Use the inverse CDF to sample from the entire PDF.\n    t_samples = invert_cdf(u, t, w_logits)\n\n  if single_jitter:\n    # Jitter every sample along each ray by the same amount in the inverse CDF.\n    jitter = jax.random.uniform(rng, shape=t_samples.shape, minval=-eps, maxval=eps)\n    t_samples = t_samples + jitter\n\n  return t_samples"}
{"namespace": "stepfun.sample", "completion": "  if rng is not None:\n    # Random sampling\n    u = jax.random.uniform(rng, shape=(num_samples,) + t.shape[:-1], dtype=jnp.float32)\n    t_samples = invert_cdf(u, t, w_logits)\n\n    if not single_jitter:\n      # Independent jittering\n      jitter = jax.random.uniform(rng, shape=(num_samples,) + t.shape[:-1], dtype=jnp.float32)\n      t_samples += (2 * jitter - 1) * eps * jnp.diff(t)\n\n  else:\n    # Deterministic sampling based on linspace\n    t_samples = jnp.linspace(t[..., 0], t[..., -1], num_samples + 1)\n    t_samples = (t_samples[..., 1:] + t_samples[..., :-1]) / 2\n\n  return t_samples"}
{"namespace": "stepfun.sample_intervals", "completion": "  t_samples = sample(rng, t, w_logits, num_samples, single_jitter=single_jitter)\n\n  # Calculate midpoints between adjacent samples\n  t_midpoints = (t_samples[..., :-1] + t_samples[..., 1:]) / 2\n\n  # Adjust the first and last intervals to ensure they are within the specified domain\n  t_samples = jnp.clip(t_samples, domain[0], domain[1])\n\n  return t_samples, t_midpoints"}
{"namespace": "stepfun.sample_intervals", "completion": "  t_samples = sample(rng, t, w_logits, num_samples, single_jitter=single_jitter)\n\n  # Calculate midpoints between adjacent samples\n  t_midpoints = (t_samples[..., :-1] + t_samples[..., 1:]) / 2\n\n  # Adjust the first and last intervals to fit within the specified domain\n  t_samples = jnp.clip(t_samples, domain[0], domain[1])\n\n  return t_samples"}
{"namespace": "stepfun.sample_intervals", "completion": "  t_samples = sample(rng, t, w_logits, num_samples, single_jitter=single_jitter)\n\n  # Calculate midpoints between adjacent samples\n  t_midpoints = (t_samples[..., :-1] + t_samples[..., 1:]) / 2\n\n  # Adjust the first and last intervals to fit within the specified domain\n  t_samples = jnp.clip(t_samples, domain[0], domain[1])\n\n  return t_samples"}
{"namespace": "stepfun.sample_intervals", "completion": "  t_samples = sample(rng, t, w_logits, num_samples, single_jitter)\n  midpoints = (t_samples[:, :-1] + t_samples[:, 1:]) / 2\n  midpoints = jnp.clip(midpoints, domain[0], domain[1])\n  t_samples = jnp.concatenate([t_samples[:, :1], midpoints, t_samples[:, -1:]], axis=1)\n  return t_samples"}
{"namespace": "stepfun.sample_intervals", "completion": "  t_samples = sample(rng, t, w_logits, num_samples, single_jitter=single_jitter)\n\n  # Calculate midpoints between adjacent samples\n  t_midpoints = (t_samples[..., :-1] + t_samples[..., 1:]) / 2\n\n  # Adjust the first and last intervals to fit within the specified domain\n  t_samples = jnp.clip(t_samples, domain[0], domain[1])\n\n  return t_samples"}
{"namespace": "stepfun.sample_intervals", "completion": "  t_samples = sample(rng, t, w_logits, num_samples, single_jitter=single_jitter)\n\n  # Calculate midpoints between adjacent samples\n  t_midpoints = (t_samples[..., :-1] + t_samples[..., 1:]) / 2\n\n  # Adjust the first and last intervals to fit within the specified domain\n  t_samples = jnp.clip(t_samples, domain[0], domain[1])\n\n  return t_samples"}
{"namespace": "stepfun.sample_intervals", "completion": "  t_samples = sample(rng, t, w_logits, num_samples, single_jitter)\n  midpoints = (t_samples[..., :-1] + t_samples[..., 1:]) / 2\n  midpoints = jnp.clip(midpoints, domain[0], domain[1])\n  t_samples = jnp.concatenate([t_samples[..., :1], midpoints, t_samples[..., -1:]], axis=-1)\n  return t_samples"}
{"namespace": "stepfun.sample_intervals", "completion": "  t_samples = sample(rng, t, w_logits, num_samples, single_jitter=single_jitter)\n\n  # Calculate midpoints between adjacent samples\n  t_midpoints = (t_samples[..., :-1] + t_samples[..., 1:]) / 2\n\n  # Adjust the first and last intervals to fit within the specified domain\n  t_samples = jnp.clip(t_samples, domain[0], domain[1])\n\n  return t_samples, t_midpoints"}
{"namespace": "stepfun.sample_intervals", "completion": "  t_samples = sample(rng, t, w_logits, num_samples, single_jitter)\n  midpoints = (t_samples[..., :-1] + t_samples[..., 1:]) / 2\n  midpoints = jnp.clip(midpoints, domain[0], domain[1])\n  t_samples = jnp.concatenate([t_samples[..., :1], midpoints, t_samples[..., -1:]], axis=-1)\n  return t_samples"}
{"namespace": "stepfun.sample_intervals", "completion": "  t_samples = sample(rng, t, w_logits, num_samples, single_jitter)\n  \n  # Calculate midpoints between adjacent samples\n  midpoints = (t_samples[:, 1:] + t_samples[:, :-1]) / 2\n  \n  # Adjust the first and last intervals to ensure they are within the specified domain\n  midpoints = jnp.clip(midpoints, domain[0], domain[1])\n  \n  return midpoints"}
{"namespace": "stepfun.sample_intervals", "completion": "  t_samples = sample(rng, t, w_logits, num_samples, single_jitter=single_jitter)\n\n  # Calculate midpoints between adjacent samples\n  t_midpoints = (t_samples[:, :-1] + t_samples[:, 1:]) / 2\n\n  # Adjust the first and last intervals to fit within the specified domain\n  t_midpoints = jnp.clip(t_midpoints, domain[0], domain[1])\n\n  return t_midpoints"}
{"namespace": "stepfun.sample_intervals", "completion": "  t_samples = sample(rng, t, w_logits, num_samples, single_jitter)\n  \n  # Calculate midpoints between adjacent samples\n  midpoints = (t_samples[..., :-1] + t_samples[..., 1:]) / 2\n  \n  # Adjust the first and last intervals to fit within the specified domain\n  midpoints = jnp.clip(midpoints, domain[0], domain[1])\n  \n  return midpoints"}
{"namespace": "stepfun.sample_intervals", "completion": "  t_samples = sample(rng, t, w_logits, num_samples, single_jitter)\n  midpoints = (t_samples[:, :-1] + t_samples[:, 1:]) / 2\n  midpoints = jnp.clip(midpoints, domain[0], domain[1])\n  t_samples = jnp.concatenate([t_samples[:, :1], midpoints, t_samples[:, -1:]], axis=1)\n  return t_samples"}
{"namespace": "stepfun.sample_intervals", "completion": "  t_samples = sample(rng, t, w_logits, num_samples, single_jitter=single_jitter)\n\n  # Calculate midpoints between adjacent samples\n  t_midpoints = (t_samples[..., :-1] + t_samples[..., 1:]) / 2\n\n  # Adjust the first and last intervals to ensure they are within the specified domain\n  t_samples = jnp.clip(t_samples, domain[0], domain[1])\n\n  return t_samples"}
{"namespace": "stepfun.sample_intervals", "completion": "  t_samples = sample(rng, t, w_logits, num_samples, single_jitter=single_jitter)\n\n  # Calculate midpoints between adjacent samples\n  t_midpoints = (t_samples[:, :-1] + t_samples[:, 1:]) / 2\n\n  # Adjust the first and last intervals to fit within the specified domain\n  t_samples = jnp.clip(t_samples, domain[0], domain[1])\n\n  return t_samples"}
{"namespace": "stepfun.sample_intervals", "completion": "  t_samples = sample(rng, t, w_logits, num_samples, single_jitter=single_jitter)\n\n  # Calculate midpoints between adjacent samples\n  t_midpoints = (t_samples[..., :-1] + t_samples[..., 1:]) / 2\n\n  # Adjust the first and last intervals to ensure they are within the specified domain\n  t_samples = jnp.clip(t_samples, domain[0], domain[1])\n\n  return t_samples"}
{"namespace": "stepfun.sample_intervals", "completion": "  t_samples = sample(rng, t, w_logits, num_samples, single_jitter)\n  midpoints = (t_samples[:, :-1] + t_samples[:, 1:]) / 2\n  midpoints = jnp.clip(midpoints, domain[0], domain[1])\n  t_samples = jnp.concatenate([t_samples[:, :1], midpoints, t_samples[:, -1:]], axis=1)\n  return t_samples"}
{"namespace": "stepfun.sample_intervals", "completion": "  t_samples = sample(rng, t, w_logits, num_samples, single_jitter=single_jitter)\n  midpoints = (t_samples[..., :-1] + t_samples[..., 1:]) / 2\n  midpoints = jnp.clip(midpoints, domain[0], domain[1])\n  t_samples = jnp.concatenate([t_samples[..., :1], midpoints, t_samples[..., -1:]], axis=-1)\n  return t_samples"}
{"namespace": "stepfun.sample_intervals", "completion": "  t_samples = sample(rng, t, w_logits, num_samples, single_jitter)\n  \n  # Calculate midpoints between adjacent samples\n  midpoints = (t_samples[..., :-1] + t_samples[..., 1:]) / 2\n  \n  # Adjust the first and last intervals to fit within the specified domain\n  midpoints = jnp.clip(midpoints, domain[0], domain[1])\n  \n  return midpoints"}
{"namespace": "stepfun.sample_intervals", "completion": "  t_samples = sample(rng, t, w_logits, num_samples, single_jitter)\n  midpoints = (t_samples[:, :-1] + t_samples[:, 1:]) / 2\n  midpoints = jnp.clip(midpoints, domain[0], domain[1])\n  t_samples = jnp.concatenate([t_samples[:, :1], midpoints, t_samples[:, -1:]], axis=1)\n  return t_samples"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  cw = integrate_weights(w)\n  return math.sorted_interp(ps / 100.0, cw, t, utils.device_is_tpu())"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Ensure that the weights sum to 1\n  w = jnp.clip(w, 0, 1)\n  w = w / jnp.sum(w)\n\n  # Compute the cumulative sum of the weights\n  cw = integrate_weights(w)\n\n  # Interpolate into the inverse CDF to find the x-values corresponding to the percentiles\n  t_percentiles = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n  return t_percentiles"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Ensure that the weights sum to 1\n  w = jnp.clip(w, 0, 1)  # Clip to ensure non-negative values\n  w = w / jnp.sum(w)  # Normalize the weights to ensure they sum to 1\n\n  # Compute the cumulative sum of the weights\n  cw = integrate_weights(w)\n\n  # Interpolate into the inverse CDF to find the percentiles\n  percentiles = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n  return percentiles"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Ensure that the weights sum to 1\n  w = jnp.clip(w, 0, 1)\n  w = w / jnp.sum(w)\n\n  # Integrate the weights\n  cw = integrate_weights(w)\n\n  # Interpolate into the integrated weights to find the percentiles\n  percentiles = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n  return percentiles"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Ensure that the weights sum to 1\n  w_sum = jnp.sum(w, axis=-1)\n  if not jnp.isclose(w_sum, 1):\n    raise ValueError(\"Weights must sum to 1.\")\n\n  # Compute the cumulative sum of the weights\n  cw = integrate_weights(w)\n\n  # Interpolate into the inverse CDF to find the x-values corresponding to the percentiles\n  t_percentiles = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n  return t_percentiles"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  cw = integrate_weights(w)\n  return math.sorted_interp(ps / 100.0, cw, t, utils.device_is_tpu())"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Ensure that the weights sum to 1\n  w = jnp.clip(w, 0, 1)\n  w = w / jnp.sum(w)\n\n  # Compute the cumulative sum of the weights\n  cw = jnp.cumsum(w)\n\n  # Interpolate into the integrated weights to find the percentiles\n  percentiles = jnp.interp(ps / 100, cw, t)\n\n  return percentiles"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Ensure that the weights sum to 1\n  w = jnp.clip(w, 0, 1)  # Ensure that the weights are within the valid range\n  w = w / jnp.sum(w)  # Normalize the weights to ensure they sum to 1\n\n  # Compute the cumulative sum of the weights\n  cw = integrate_weights(w)\n\n  # Interpolate into the inverse CDF to find the percentiles\n  percentiles = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n  return percentiles"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Ensure that the weights sum to 1\n  w_sum = jnp.sum(w, axis=-1)\n  if not jnp.allclose(w_sum, 1):\n    raise ValueError(\"Weights must sum to 1.\")\n\n  # Compute the cumulative sum of the weights\n  cw = integrate_weights(w)\n\n  # Interpolate into the inverse CDF to find the percentiles\n  percentiles = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n  return percentiles"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  \n  # Ensure that the weights sum to 1\n  w_sum = jnp.sum(w, axis=-1)\n  if not jnp.allclose(w_sum, 1):\n      raise ValueError(\"The weights must sum to 1.\")\n\n  # Compute the integrated weights\n  cw = integrate_weights(w)\n\n  # Interpolate into the integrated weights to find the percentiles\n  percentiles = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n  return percentiles"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  cw = integrate_weights(w)  # Compute the cumulative sum of w, ensuring it sums to 1\n  return math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())  # Interpolate into the integrated weights to find the corresponding x-values"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Ensure that the weights sum to 1\n  w_sum = jnp.sum(w, axis=-1)\n  if not jnp.allclose(w_sum, 1):\n    raise ValueError(\"Weights must sum to 1\")\n\n  # Compute the cumulative sum of the weights\n  cw = integrate_weights(w)\n\n  # Interpolate into the inverse CDF to find the percentiles\n  percentiles = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n  return percentiles"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  cw = integrate_weights(w)\n  return math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Ensure weights sum to 1\n  w = jnp.clip(w, 0, 1)  # Clip to ensure non-negative values\n  w = w / jnp.sum(w)  # Normalize to ensure sum of weights is 1\n\n  # Compute the cumulative sum of the weights\n  cw = jnp.cumsum(w)\n\n  # Interpolate into the integrated weights to find the percentiles\n  percentiles = jnp.interp(ps / 100, cw, t)\n\n  return percentiles"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Ensure that the weights sum to 1\n  w_sum = jnp.sum(w, axis=-1)\n  if not jnp.allclose(w_sum, 1):\n    raise ValueError(\"Weights must sum to 1.\")\n\n  # Compute the cumulative sum of the weights\n  cw = integrate_weights(w)\n\n  # Interpolate into the cumulative weights to find the percentiles\n  percentiles = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n  return percentiles"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Ensure that the weights sum to 1\n  w = jnp.clip(w, 0, 1)\n  w = w / jnp.sum(w, axis=-1, keepdims=True)\n\n  # Compute the cumulative sum of the weights\n  cw = integrate_weights(w)\n\n  # Interpolate into the inverse CDF to find the x-values corresponding to the percentiles\n  t_percentiles = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n  return t_percentiles"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  \n  # Ensure that the weights sum to 1\n  w = jnp.clip(w, 0, 1)  # Clip the weights to be between 0 and 1\n  w = w / jnp.sum(w)  # Normalize the weights to ensure they sum to 1\n  \n  # Compute the cumulative sum of the weights\n  cw = integrate_weights(w)\n  \n  # Interpolate into the integrated weights to find the percentiles\n  percentiles = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n  \n  return percentiles"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Ensure that the weights sum to 1\n  w = jnp.clip(w, 0, 1)  # Clip the weights to be between 0 and 1\n  w = w / jnp.sum(w)  # Normalize the weights to ensure they sum to 1\n\n  # Compute the cumulative sum of the weights\n  cw = integrate_weights(w)\n\n  # Interpolate into the integrated weights to find the percentiles\n  percentiles = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n  return percentiles"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Ensure weights sum to 1\n  w = jnp.clip(w, 0, 1)\n  w = w / jnp.sum(w, axis=-1, keepdims=True)\n\n  # Compute the cumulative sum of the integrated weights\n  cw = integrate_weights(w)\n\n  # Interpolate into the inverse CDF to find the x-values for the given percentiles\n  t_percentile = math.sorted_interp(ps / 100.0, cw, t, utils.device_is_tpu())\n\n  return t_percentile"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  cw = integrate_weights(w)\n  return math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to PDF\n  p = weight_to_pdf(t, w)\n  \n  # Blur the PDF\n  blurred_p = linspline.gaussian_filter1d(p, blur_halfwidth)\n  \n  # Resample the blurred PDF to match the new time points\n  resampled_w = pdf_to_weight(tq, resample(tq, t, blurred_p))\n  \n  return resampled_w"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to a probability density function (PDF)\n  p = weight_to_pdf(t, w)\n  \n  # Blur the PDF\n  blurred_p = linspline.blur(p, blur_halfwidth)\n  \n  # Convert the blurred PDF back to weights\n  w_resampled = pdf_to_weight(tq, blurred_p)\n  \n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to a probability density function (PDF)\n  p = weight_to_pdf(t, w)\n  \n  # Blur the PDF using a Gaussian filter\n  blurred_p = linspline.gaussian_filter1d(p, blur_halfwidth)\n  \n  # Convert the blurred PDF back to weights\n  w_resampled = pdf_to_weight(tq, blurred_p)\n  \n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to PDF\n  p = weight_to_pdf(t, w)\n  \n  # Blur the PDF\n  blurred_p = linspline.blur(p, blur_halfwidth)\n  \n  # Convert blurred PDF back to weights\n  w_resampled = pdf_to_weight(tq, blurred_p)\n  \n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to a probability density function (PDF)\n  p = weight_to_pdf(t, w)\n  \n  # Blur the PDF using a Gaussian kernel\n  blurred_p = linspline.gaussian_filter1d(p, blur_halfwidth)\n  \n  # Convert the blurred PDF back to weights\n  w_blurred = pdf_to_weight(t, blurred_p)\n  \n  # Resample the blurred weights to match the new time points\n  w_resampled = resample(tq, t, w_blurred)\n  \n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to PDF\n  p = weight_to_pdf(t, w)\n  \n  # Blur the PDF\n  blurred_p = linspline.blur(p, blur_halfwidth)\n  \n  # Resample the blurred PDF to match the new time points\n  resampled_w = pdf_to_weight(tq, blurred_p)\n  \n  return resampled_w"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to a probability density function (PDF)\n  p = weight_to_pdf(t, w)\n  \n  # Blur the PDF using a Gaussian filter\n  blurred_p = linspline.gaussian_filter1d(p, blur_halfwidth)\n  \n  # Convert the blurred PDF back to weights\n  w_blurred = pdf_to_weight(t, blurred_p)\n  \n  # Resample the blurred weights to match the new time points\n  w_resampled = resample(tq, t, w_blurred)\n  \n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to a probability density function (PDF)\n  p = weight_to_pdf(t, w)\n  \n  # Blur the PDF using a Gaussian filter\n  blurred_p = linspline.gaussian_filter1d(p, blur_halfwidth)\n  \n  # Resample the blurred PDF to match the new time points\n  resampled_w = pdf_to_weight(tq, resample(tq, t, blurred_p))\n  \n  return resampled_w"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to a probability density function (PDF)\n  p = weight_to_pdf(t, w)\n  \n  # Blur the PDF using a Gaussian filter\n  blurred_p = linspline.gaussian_filter1d(p, blur_halfwidth)\n  \n  # Resample the blurred PDF to match the new time points\n  resampled_w = pdf_to_weight(tq, resample(tq, t, blurred_p))\n  \n  return resampled_w"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to a probability density function (PDF)\n  p = weight_to_pdf(t, w)\n  \n  # Blur the PDF using a Gaussian filter\n  blurred_p = linspline.gaussian_filter1d(p, blur_halfwidth)\n  \n  # Convert the blurred PDF back to weights\n  w_resampled = pdf_to_weight(tq, blurred_p)\n  \n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to a probability density function (PDF)\n  p = weight_to_pdf(t, w)\n\n  # Blur the PDF using a Gaussian filter\n  blurred_p = linspline.gaussian_filter1d(p, blur_halfwidth)\n\n  # Convert the blurred PDF back to weights\n  w_resampled = pdf_to_weight(tq, blurred_p)\n\n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to a probability density function (PDF)\n  p = weight_to_pdf(t, w)\n  \n  # Blur the PDF using a Gaussian filter\n  blurred_p = linspline.gaussian_filter1d(p, blur_halfwidth)\n  \n  # Convert the blurred PDF back to weights\n  w_blurred = pdf_to_weight(t, blurred_p)\n  \n  # Resample the blurred weights to match the new time points\n  w_resampled = resample(tq, t, w_blurred)\n  \n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to PDF\n  p = weight_to_pdf(t, w)\n\n  # Blur the PDF\n  blurred_p = linspline.blur(p, blur_halfwidth)\n\n  # Resample the blurred PDF to match the new time points\n  resampled_w = pdf_to_weight(tq, blurred_p)\n\n  return resampled_w"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to PDF\n  p = weight_to_pdf(t, w)\n  \n  # Blur the PDF\n  blurred_p = linspline.convolve_with_gaussian(p, blur_halfwidth)\n  \n  # Resample the blurred PDF to match the new time points\n  resampled_w = pdf_to_weight(tq, resample(tq, t, blurred_p))\n  \n  return resampled_w"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to a probability density function (PDF)\n  p = weight_to_pdf(t, w)\n\n  # Blur the PDF\n  blurred_p = linspline.blur(p, blur_halfwidth)\n\n  # Resample the blurred PDF to match the new time points\n  resampled_w = pdf_to_weight(tq, blurred_p)\n\n  return resampled_w"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to PDF\n  p = weight_to_pdf(t, w)\n\n  # Blur the PDF\n  blurred_p = linspline.blur(p, blur_halfwidth)\n\n  # Resample the blurred PDF to match the new time points\n  resampled_w = pdf_to_weight(tq, resample(tq, t, blurred_p))\n\n  return resampled_w"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to a probability density function (PDF)\n  p = weight_to_pdf(t, w)\n  \n  # Blur the PDF using a Gaussian blur\n  blurred_p = linspline.gaussian_blur(p, blur_halfwidth)\n  \n  # Resample the blurred PDF to match the new time points\n  resampled_w = pdf_to_weight(tq, resample(tq, t, blurred_p))\n  \n  return resampled_w"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to a PDF\n  p = weight_to_pdf(t, w)\n  \n  # Blur the PDF\n  blurred_p = linspline.blur(p, blur_halfwidth)\n  \n  # Convert the blurred PDF back to weights\n  blurred_w = pdf_to_weight(t, blurred_p)\n  \n  # Resample the weights based on the new time points\n  resampled_weights = resample(tq, t, blurred_w)\n  \n  return resampled_weights"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to a probability density function (PDF)\n  p = weight_to_pdf(t, w)\n  \n  # Blur the PDF using a Gaussian kernel\n  blurred_p = linspline.gaussian_blur_1d(p, blur_halfwidth)\n  \n  # Convert the blurred PDF back to weights\n  w_resampled = pdf_to_weight(tq, blurred_p)\n  \n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to a PDF\n  p = weight_to_pdf(t, w)\n  \n  # Apply Gaussian blur to the PDF\n  blurred_p = linspline.gaussian_blur(p, blur_halfwidth)\n  \n  # Resample the blurred PDF to match the new time points\n  resampled_w = pdf_to_weight(tq, resample(tq, t, blurred_p))\n  \n  return resampled_w"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of strings')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    async with aiofiles.open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      async with aiofiles.open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n        while True:\n            chunk = r.read(32 * 1024)\n            if not chunk:\n                break\n            sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n        await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n        if e.status_code != 404:\n            raise\n\n        with open(path, 'rb') as r:\n            await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n        while True:\n            chunk = r.read(32 * 1024)\n            if not chunk:\n                break\n            sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'  # Calculate the SHA256 checksum\n\n    try:\n        await self._request('HEAD', f'/api/blobs/{digest}')  # Check if the blob already exists\n    except ResponseError as e:\n        if e.status_code != 404:  # If the blob does not exist\n            raise\n\n        with open(path, 'rb') as r:\n            await self._request('POST', f'/api/blobs/{digest}', content=r)  # Upload the file in chunks\n\n    return digest  # Return the digest of the file"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    async with open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      async with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create temporary files for user code and test code\n        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as user_file, \\\n                tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as test_file:\n            user_file.write(user_code)\n            test_file.write(test_code)\n\n        # Run Pyright to perform type checking\n        process = subprocess.Popen([\"pyright\", \"--outputjson\", user_file.name, test_file.name], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        stdout, stderr = process.communicate()\n\n        # Parse the output of Pyright to identify type errors\n        error_messages = []\n        for line in stderr.decode(\"utf-8\").splitlines():\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                line_no, error_msg = match.groups()\n                error_messages.append(f\"Line {line_no}: {error_msg}\")\n\n        # Determine if the type check passed or failed\n        passed = len(error_messages) == 0\n        message = \"Type check passed\" if passed else \"Type check failed\"\n\n        # Return the result of the type check\n        return TypeCheckResult(message, passed, {\"error_messages\": error_messages})"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Your implementation here\n        pass"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary file to store the combined user code and test code\n        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as temp_file:\n            temp_file.write(user_code + test_code)\n\n        # Run Pyright to perform the type check\n        pyright_output = subprocess.run(\n            [\"pyright\", \"--outputjson\", temp_file.name],\n            capture_output=True,\n            text=True,\n        )\n\n        # Parse the Pyright output to identify type errors\n        error_messages = []\n        for line in pyright_output.stdout.splitlines():\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                line_number, error_message = match.groups()\n                error_messages.append(f\"Line {line_number}: {error_message}\")\n\n        # Determine if the type check passed or failed\n        passed = len(error_messages) == 0\n\n        # Create a TypeCheckResult object to store the outcome of the type check\n        result = TypeCheckResult(\n            message=\"Type check passed\" if passed else \"Type check failed\",\n            passed=passed,\n            debug_info={\"pyright_output\": pyright_output.stdout, \"error_messages\": error_messages},\n        )\n\n        # Delete the temporary file\n        Path(temp_file.name).unlink()\n\n        return result"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Code to be completed goes here\n        pass  # Placeholder for the implementation"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        result = subprocess.run(\n            [\"pyright\", \"--outputjson\", \"-\"],\n            input=(user_code + test_code).encode(\"utf-8\"),\n            capture_output=True,\n            text=True,\n        )\n        if result.returncode != 0:\n            return TypeCheckResult(\n                message=\"Type check failed\",\n                passed=False,\n                debug_info={\"error_output\": result.stderr},\n            )\n\n        error_lines = []\n        for line in result.stdout.splitlines():\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                error_lines.append(int(match.group(1)))\n\n        if any(cls.EXPECT_ERROR_COMMENT in line for line in (user_code + test_code).splitlines()):\n            if error_lines:\n                return TypeCheckResult(\n                    message=\"Expected type error not found\",\n                    passed=False,\n                    debug_info={\"error_lines\": error_lines},\n                )\n            else:\n                return TypeCheckResult(\n                    message=\"Expected type error found\",\n                    passed=True,\n                )\n\n        if error_lines:\n            return TypeCheckResult(\n                message=\"Type check failed\",\n                passed=False,\n                debug_info={\"error_lines\": error_lines},\n            )\n        else:\n            return TypeCheckResult(\n                message=\"Type check passed\",\n                passed=True,\n            )"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Your implementation of the type check with Pyright goes here\n        pass  # Placeholder, replace with actual implementation"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create temporary files to store the user code and test code\n        with tempfile.TemporaryDirectory() as tmpdir:\n            user_code_file = Path(tmpdir) / \"user_code.py\"\n            test_code_file = Path(tmpdir) / \"test_code.py\"\n\n            # Write the user code and test code to the temporary files\n            user_code_file.write_text(user_code, encoding=\"utf-8\")\n            test_code_file.write_text(test_code, encoding=\"utf-8\")\n\n            # Run Pyright to perform the type check\n            pyright_cmd = [\"npx\", \"pyright\", \"--outputjson\", str(user_code_file), str(test_code_file)]\n            result = subprocess.run(pyright_cmd, capture_output=True, text=True)\n\n            # Parse the output of Pyright to identify type errors\n            error_messages = []\n            for line in result.stdout.splitlines():\n                match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n                if match:\n                    line_no, error_message = match.groups()\n                    error_messages.append(f\"Line {line_no}: {error_message}\")\n\n            # Determine if the type check passed or failed\n            passed = len(error_messages) == 0\n            message = \"Type check passed\" if passed else \"Type check failed\"\n\n            # Create a TypeCheckResult object to store the type check result\n            type_check_result = TypeCheckResult(message, passed, {\"error_messages\": error_messages})\n\n            return type_check_result"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Perform type check using Pyright\n        pyright_output = subprocess.run(\n            [\"npx\", \"pyright\", \"--outputjson\", \"-\"],\n            input=(user_code + test_code).encode(\"utf-8\"),\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n        )\n\n        # Parse Pyright output and identify lines with expected type errors\n        error_lines = []\n        for line in pyright_output.stderr.split(\"\\n\"):\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                error_lines.append(int(match.group(1)))\n\n        # Determine if the type check passed or failed\n        passed = len(error_lines) == 0\n        message = \"Type check passed\" if passed else \"Type check failed\"\n\n        return TypeCheckResult(message, passed, {\"error_lines\": error_lines})"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create temporary files for user code and test code\n        with tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as user_file, tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as test_file:\n            user_file.write(user_code)\n            test_file.write(test_code)\n\n        # Run Pyright to perform type checking\n        pyright_output = subprocess.run(\n            [\"pyright\", user_file.name, test_file.name],\n            capture_output=True,\n            text=True,\n        )\n\n        # Parse the Pyright output to identify type errors\n        error_messages = []\n        for line in pyright_output.stdout.splitlines():\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                line_number, error_message = match.groups()\n                error_messages.append(f\"Line {line_number}: {error_message}\")\n\n        # Determine if the type check passed or failed\n        passed = len(error_messages) == 0\n        message = \"Type check passed\" if passed else \"Type check failed\"\n\n        # Return the result of the type check\n        return TypeCheckResult(message, passed, {\"error_messages\": error_messages})"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create temporary files for user code and test code\n        with tempfile.TemporaryDirectory() as temp_dir:\n            user_code_file = Path(temp_dir) / \"user_code.py\"\n            test_code_file = Path(temp_dir) / \"test_code.py\"\n\n            # Write user code and test code to temporary files\n            user_code_file.write_text(user_code, encoding=\"utf-8\")\n            test_code_file.write_text(test_code, encoding=\"utf-8\")\n\n            # Run Pyright to perform type checking\n            result = subprocess.run(\n                [\"npx\", \"pyright\", \"--outputjson\", str(user_code_file)],\n                capture_output=True,\n                text=True,\n            )\n\n            # Parse the output of Pyright and identify type errors\n            error_messages = []\n            for line in result.stdout.splitlines():\n                match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n                if match:\n                    line_number, error_message = match.groups()\n                    error_messages.append(f\"Line {line_number}: {error_message}\")\n\n            # Determine if the type check passed or failed\n            passed = len(error_messages) == 0\n\n            # Create a TypeCheckResult object with the outcome and error messages\n            type_check_result = TypeCheckResult(\n                message=\"\\n\".join(error_messages) if error_messages else \"Type check passed\",\n                passed=passed,\n            )\n\n            return type_check_result"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "\n        # Perform type check using Pyright\n        process = subprocess.Popen(\n            [\"npx\", \"pyright\", \"--outputjson\", \"-\"],\n            stdin=subprocess.PIPE,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n        )\n        combined_code = user_code + \"\\n\" + test_code\n        stdout, stderr = process.communicate(input=combined_code)\n\n        # Parse Pyright output to identify type errors\n        error_messages = []\n        for line in stderr.splitlines():\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                line_no, error_message = match.groups()\n                error_messages.append(f\"Line {line_no}: {error_message}\")\n\n        # Determine if type check passed or failed\n        passed = len(error_messages) == 0\n        message = \"Type check passed\" if passed else \"Type check failed\"\n\n        return TypeCheckResult(message, passed, {\"error_messages\": error_messages})"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        process = subprocess.Popen(\n            [\"pyright\", \"--outputjson\", \"-\"],\n            stdin=subprocess.PIPE,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n        )\n        combined_code = f\"{user_code}\\n{test_code}\"\n        stdout, stderr = process.communicate(combined_code)\n        if process.returncode != 0:\n            return TypeCheckResult(\n                message=f\"Type check failed: {stderr}\", passed=False\n            )\n\n        # Parse the JSON output from Pyright\n        try:\n            pyright_output = json.loads(stdout)\n        except json.JSONDecodeError:\n            return TypeCheckResult(\n                message=\"Failed to parse Pyright output\", passed=False\n            )\n\n        # Check for expected type errors\n        error_messages = []\n        for diagnostic in pyright_output[\"diagnostics\"]:\n            if diagnostic[\"message\"].startswith(cls.EXPECT_ERROR_COMMENT):\n                error_messages.append(diagnostic[\"message\"])\n\n        if error_messages:\n            return TypeCheckResult(\n                message=\"\\n\".join(error_messages), passed=False\n            )\n        else:\n            return TypeCheckResult(message=\"Type check passed\", passed=True)"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create temporary files to store the user code and test code\n        with tempfile.TemporaryDirectory() as temp_dir:\n            user_code_file = Path(temp_dir) / \"user_code.py\"\n            test_code_file = Path(temp_dir) / \"test_code.py\"\n\n            # Write the user code and test code to the temporary files\n            user_code_file.write_text(user_code, encoding=\"utf-8\")\n            test_code_file.write_text(test_code, encoding=\"utf-8\")\n\n            # Run Pyright to perform the type check\n            pyright_output = subprocess.run(\n                [\"pyright\", \"--outputjson\", str(user_code_file)],\n                capture_output=True,\n                text=True,\n            )\n\n            # Process the Pyright output to identify type errors\n            errors = []\n            for line in pyright_output.stdout.splitlines():\n                match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n                if match:\n                    line_no, error_message = match.groups()\n                    errors.append((int(line_no), error_message))\n\n            # Check if the type check passed or failed\n            passed = not any(cls.EXPECT_ERROR_COMMENT in line for line in test_code.splitlines())\n\n            # Create a TypeCheckResult object with the outcome of the type check\n            result = TypeCheckResult(\n                message=\"Type check passed\" if passed else \"Type check failed\",\n                passed=passed,\n                debug_info={\"errors\": errors},\n            )\n\n            return result"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Implement the type check using Pyright here\n        # ...\n        pass  # Placeholder, replace with actual implementation"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        process = subprocess.Popen(\n            [\"pyright\", \"--outputjson\", \"-\"],\n            stdin=subprocess.PIPE,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n        )\n        combined_code = f\"{test_code}\\n{user_code}\"\n        stdout, stderr = process.communicate(combined_code)\n\n        if process.returncode != 0:\n            return TypeCheckResult(\n                message=\"Failed to run Pyright for type checking\",\n                passed=False,\n                debug_info={\"stderr\": stderr},\n            )\n\n        error_messages = []\n        for line in stderr.splitlines():\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                line_no, error_message = match.groups()\n                error_messages.append(f\"Line {line_no}: {error_message}\")\n\n        if error_messages:\n            return TypeCheckResult(\n                message=\"\\n\".join(error_messages),\n                passed=False,\n                debug_info={\"stderr\": stderr},\n            )\n        else:\n            return TypeCheckResult(\n                message=\"Type check passed\",\n                passed=True,\n            )"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        process = subprocess.Popen(\n            [\"pyright\", \"--outputjson\", \"-\"],\n            stdin=subprocess.PIPE,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n        )\n        combined_code = f\"{user_code}\\n{test_code}\"\n        stdout, stderr = process.communicate(combined_code)\n        exit_code = process.wait()\n        if exit_code != 0:\n            return TypeCheckResult(\n                message=f\"Type check failed with exit code {exit_code}\",\n                passed=False,\n                debug_info={\"stdout\": stdout, \"stderr\": stderr},\n            )\n\n        errors = []\n        for match in re.finditer(cls.PYRIGHT_MESSAGE_REGEX, stderr, re.MULTILINE):\n            line_no, error_message = match.groups()\n            errors.append((int(line_no), error_message))\n\n        if errors:\n            return TypeCheckResult(\n                message=\"Type check failed with errors\",\n                passed=False,\n                debug_info={\"errors\": errors},\n            )\n        else:\n            return TypeCheckResult(message=\"Type check passed\", passed=True)"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create temporary files for user code and test code\n        with tempfile.TemporaryDirectory() as temp_dir:\n            user_code_file = Path(temp_dir) / \"user_code.py\"\n            test_code_file = Path(temp_dir) / \"test_code.py\"\n\n            user_code_file.write_text(user_code, encoding=\"utf-8\")\n            test_code_file.write_text(test_code, encoding=\"utf-8\")\n\n            # Run Pyright to perform type checking\n            pyright_output = subprocess.run(\n                [\"pyright\", \"--outputjson\", str(user_code_file), str(test_code_file)],\n                capture_output=True,\n                text=True,\n            )\n\n            # Parse the Pyright output to identify type errors\n            error_lines = []\n            for line in pyright_output.stdout.splitlines():\n                match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n                if match:\n                    line_no, error_message = match.groups()\n                    error_lines.append(f\"Line {line_no}: {error_message}\")\n\n            # Determine if the type check passed or failed\n            passed = len(error_lines) == 0\n            message = \"Type check passed\" if passed else \"Type check failed\"\n\n            # Create TypeCheckResult object\n            result = TypeCheckResult(message, passed, {\"error_lines\": error_lines})\n\n            return result"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Perform type check using Pyright\n        process = subprocess.Popen(\n            [\"pyright\", \"--outputjson\", \"-\"],\n            stdin=subprocess.PIPE,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n        )\n        input_code = f\"{user_code}\\n{test_code}\"\n        stdout, stderr = process.communicate(input=input_code)\n\n        # Parse Pyright output and identify type errors\n        error_lines = []\n        for line in stderr.split(\"\\n\"):\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                error_lines.append(int(match.group(1)))\n\n        # Determine if type check passed or failed\n        passed = len(error_lines) == 0\n        message = \"Type check passed\" if passed else \"Type check failed\"\n\n        return TypeCheckResult(message, passed, {\"error_lines\": error_lines})"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Perform type check using Pyright\n        process = subprocess.Popen(\n            [\"pyright\", \"--outputjson\", \"-\"],\n            stdin=subprocess.PIPE,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n        )\n        input_code = user_code + \"\\n\" + test_code\n        stdout, stderr = process.communicate(input_code)\n\n        # Parse Pyright output to identify errors\n        error_lines = []\n        for line in stderr.split(\"\\n\"):\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                error_lines.append(int(match.group(1)))\n\n        # Determine type check result\n        if error_lines:\n            message = f\"Type check failed. Errors found in lines: {', '.join(map(str, error_lines))}\"\n            passed = False\n        else:\n            message = \"Type check passed. No errors found.\"\n            passed = True\n\n        return TypeCheckResult(message, passed, {\"pyright_output\": stdout, \"error_lines\": error_lines})"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create temporary file to write the combined code\n        with tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as temp_file:\n            temp_file.write(user_code + test_code)\n\n        # Run Pyright to perform type checking\n        pyright_output = subprocess.run(\n            [\"pyright\", \"--outputjson\", temp_file.name], capture_output=True, text=True\n        )\n\n        # Parse Pyright output to identify type errors\n        error_messages = []\n        for line in pyright_output.stdout.splitlines():\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                line_no, error_message = match.groups()\n                error_messages.append(f\"Line {line_no}: {error_message}\")\n\n        # Determine if the type check passed or failed\n        passed = len(error_messages) == 0\n        message = \"Type check passed\" if passed else \"Type check failed\"\n\n        # Return the result of the type check\n        return TypeCheckResult(message, passed, {\"error_messages\": error_messages})"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = await self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = await self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = await self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = await self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = await self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = await self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = await self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = await self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = await self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = await self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = await self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = await self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = await self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = await self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = await self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = await self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = await self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = await self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = await self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = await self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = await self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = await self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = await self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = await self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = await self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = await self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = await self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = await self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = await self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = await self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = await self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = await self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = await self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = await self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = await self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = await self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = await self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = await self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = await self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = await self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            compiled_module = aot_module(fn, get_compiler_fn(\"Forward graph\"))\n            return compiled_module\n    else:\n        with no_fake_tensor():\n            compiled_function = aot_function(fn, get_compiler_fn(\"Forward graph\"))\n            return compiled_function"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            compiled_module = aot_module(fn, get_compiler_fn(\"Forward and Backward Graph for AOT Compilation\"))\n        return compiled_module\n    else:\n        with no_fake_tensor():\n            compiled_function = aot_function(fn, get_compiler_fn(\"Forward and Backward Graph for AOT Compilation\"))\n        return compiled_function"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "\n    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            compiled_module = aot_module(fn, get_compiler_fn())\n        return compiled_module\n    else:\n        with no_fake_tensor():\n            compiled_function = aot_function(fn, get_compiler_fn())\n        return compiled_function"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            compiled_module = aot_module(fn, get_compiler_fn(\"Forward Graph\"), get_compiler_fn(\"Backward Graph\"))\n        return compiled_module\n    else:\n        with no_fake_tensor():\n            compiled_function = aot_function(fn, get_compiler_fn(\"Forward Graph\"), get_compiler_fn(\"Backward Graph\"))\n        return compiled_function"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            if packaging.version.parse(torch.__version__) >= packaging.version.parse(\"2.0.0\"):\n                compiled_module = aot_module(fn, get_compiler_fn())\n            else:\n                compiled_module = aot_module(fn, get_compiler_fn())\n            return compiled_module\n    else:\n        with no_fake_tensor():\n            if packaging.version.parse(torch.__version__) >= packaging.version.parse(\"2.0.0\"):\n                compiled_function = aot_function(fn, get_compiler_fn())\n            else:\n                compiled_function = aot_function(fn, get_compiler_fn())\n            return compiled_function"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            compiled_module = aot_module(fn, get_compiler_fn(\"Forward Graph\"))\n            return compiled_module\n    else:\n        with no_fake_tensor():\n            compiled_function = aot_function(fn, get_compiler_fn(\"Forward Graph\"))\n            return compiled_function"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            compiled_module = aot_module(fn, get_compiler_fn(\"Forward Graph\"))\n            return compiled_module\n    else:\n        with no_fake_tensor():\n            compiled_function = aot_function(fn, get_compiler_fn(\"Forward Graph\"))\n            return compiled_function"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            compiled_module = aot_module(fn, get_compiler_fn())\n        return compiled_module\n    else:\n        with no_fake_tensor():\n            compiled_function = aot_function(fn, get_compiler_fn())\n        return compiled_function"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "\n    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            return aot_module(fn, get_compiler_fn())\n    else:\n        return aot_function(fn, get_compiler_fn())"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            compiled_module = aot_module(fn, get_compiler_fn(\"Forward Graph\"), get_compiler_fn(\"Backward Graph\"))\n        return compiled_module\n    else:\n        with no_fake_tensor():\n            compiled_function = aot_function(fn, get_compiler_fn(\"Forward Graph\"), get_compiler_fn(\"Backward Graph\"))\n        return compiled_function"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "\n    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            return aot_module(fn, get_compiler_fn())\n    else:\n        with no_fake_tensor():\n            return aot_function(fn, get_compiler_fn())"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            with torch.no_grad():\n                compiled_module = aot_module(fn, get_compiler_fn())\n        return compiled_module\n    else:\n        with no_fake_tensor():\n            with torch.no_grad():\n                compiled_function = aot_function(fn, get_compiler_fn())\n        return compiled_function"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            compiled_module = aot_module(fn, get_compiler_fn())\n        return compiled_module\n    else:\n        with no_fake_tensor():\n            compiled_function = aot_function(fn, get_compiler_fn())\n        return compiled_function"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            compiled_fn = aot_module(fn, get_compiler_fn(\"Forward Graph\"))\n    else:\n        with no_fake_tensor():\n            compiled_fn = aot_function(fn, get_compiler_fn(\"Function Graph\"))\n    \n    return compiled_fn"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            compiled_module = aot_module(fn, get_compiler_fn(\"Forward Graph\"), get_compiler_fn(\"Backward Graph\"))\n        return compiled_module\n    else:\n        with no_fake_tensor():\n            compiled_function = aot_function(fn, get_compiler_fn(\"Forward Graph\"), get_compiler_fn(\"Backward Graph\"))\n        return compiled_function"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            compiled_module = aot_module(fn, get_compiler_fn(\"Forward Module\"))\n        return compiled_module\n    else:\n        with no_fake_tensor():\n            compiled_function = aot_function(fn, get_compiler_fn(\"Forward Function\"))\n        return compiled_function"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"Forward Graph\"), get_compiler_fn(\"Backward Graph\"))\n    else:\n        return aot_function(fn, get_compiler_fn(\"Forward Graph\"), get_compiler_fn(\"Backward Graph\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            compiled_module = aot_module(fn, get_compiler_fn(\"Forward Graph\"), get_compiler_fn(\"Backward Graph\"))\n        return compiled_module\n    else:\n        with no_fake_tensor():\n            compiled_function = aot_function(fn, get_compiler_fn(\"Forward Graph\"), get_compiler_fn(\"Backward Graph\"))\n        return compiled_function"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            compiled_fn = aot_module(fn, get_compiler_fn(\"Forward Graph\"))\n    else:\n        with no_fake_tensor():\n            compiled_fn = aot_function(fn, get_compiler_fn(\"Forward Graph\"))\n    \n    return compiled_fn"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"Forward Graph\"), get_compiler_fn(\"Backward Graph\"))\n    else:\n        return aot_function(fn, get_compiler_fn(\"Forward Graph\"), get_compiler_fn(\"Backward Graph\"))"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_file_path = os.path.join(trial_path, \"summary.csv\")\n    config_file_path = os.path.join(trial_path, \"config.yaml\")\n\n    summary_df = load_summary_file(summary_file_path)\n    with open(config_file_path, 'r') as f:\n        config_dict = yaml.safe_load(f)\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        if not output_path.endswith(('.yaml', '.yml')):\n            raise ValueError(\"Output file path must have .yaml or .yml extension\")\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config, f)\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_file_path = os.path.join(trial_path, 'summary.csv')\n    config_file_path = os.path.join(trial_path, 'config.yaml')\n\n    summary_df = load_summary_file(summary_file_path)\n    with open(config_file_path, 'r') as f:\n        config_dict = yaml.safe_load(f)\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        if not output_path.endswith(('.yaml', '.yml')):\n            raise ValueError(\"Output file path must have .yaml or .yml extension\")\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config, f)\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_file = os.path.join(trial_path, 'summary.csv')\n    config_file = os.path.join(trial_path, 'config.yaml')\n\n    if not os.path.exists(summary_file):\n        raise FileNotFoundError(f\"summary.csv not found in {trial_path}\")\n\n    if not os.path.exists(config_file):\n        raise FileNotFoundError(f\"config.yaml not found in {trial_path}\")\n\n    summary_df = load_summary_file(summary_file)\n    with open(config_file, 'r') as f:\n        config_dict = yaml.safe_load(f)\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        if not output_path.endswith(('.yaml', '.yml')):\n            raise ValueError(\"Output file must have .yaml or .yml extension\")\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config, f)\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_file_path = os.path.join(trial_path, \"summary.csv\")\n    config_file_path = os.path.join(trial_path, \"config.yaml\")\n\n    summary_df = load_summary_file(summary_file_path)\n    with open(config_file_path, 'r') as f:\n        config_dict = yaml.safe_load(f)\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        with open(output_path, 'w') as file:\n            yaml.dump(best_config, file, default_flow_style=False)\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_file_path = os.path.join(trial_path, \"summary.csv\")\n    config_file_path = os.path.join(trial_path, \"config.yaml\")\n\n    summary_df = load_summary_file(summary_file_path)\n    with open(config_file_path, 'r') as f:\n        config_dict = yaml.safe_load(f)\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        if not output_path.endswith(('.yaml', '.yml')):\n            raise ValueError(\"Output file path must have a .yaml or .yml extension\")\n        with open(output_path, 'w') as file:\n            yaml.dump(best_config, file)\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_file_path = os.path.join(trial_path, \"summary.csv\")\n    config_file_path = os.path.join(trial_path, \"config.yaml\")\n\n    summary_df = load_summary_file(summary_file_path)\n    with open(config_file_path, 'r') as f:\n        config_dict = yaml.safe_load(f)\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        if not output_path.endswith(('.yaml', '.yml')):\n            raise ValueError(\"Output file path must have .yaml or .yml extension\")\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config, f)\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_file_path = os.path.join(trial_path, 'summary.csv')\n    config_file_path = os.path.join(trial_path, 'config.yaml')\n\n    summary_df = load_summary_file(summary_file_path)\n    with open(config_file_path, 'r') as f:\n        config_dict = yaml.safe_load(f)\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        if not output_path.endswith(('.yaml', '.yml')):\n            raise ValueError(\"Output file path must have a .yaml or .yml extension\")\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config, f)\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_file_path = os.path.join(trial_path, \"summary.csv\")\n    config_file_path = os.path.join(trial_path, \"config.yaml\")\n\n    summary_df = load_summary_file(summary_file_path)\n    with open(config_file_path, 'r') as f:\n        config_dict = yaml.safe_load(f)\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        with open(output_path, 'w') as file:\n            yaml.dump(best_config, file, default_flow_style=False)\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_file_path = os.path.join(trial_path, \"summary.csv\")\n    config_file_path = os.path.join(trial_path, \"config.yaml\")\n\n    if not os.path.exists(summary_file_path):\n        raise FileNotFoundError(f\"summary.csv not found in {trial_path}\")\n\n    summary_df = load_summary_file(summary_file_path)\n    with open(config_file_path, 'r') as f:\n        config_dict = yaml.safe_load(f)\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        if not output_path.endswith(('.yaml', '.yml')):\n            raise ValueError(\"Output file path must have a .yaml or .yml extension\")\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config, f)\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_file_path = os.path.join(trial_path, \"summary.csv\")\n    config_file_path = os.path.join(trial_path, \"config.yaml\")\n\n    if not os.path.exists(summary_file_path):\n        raise FileNotFoundError(f\"Summary file not found at {summary_file_path}\")\n\n    if not os.path.exists(config_file_path):\n        raise FileNotFoundError(f\"Config file not found at {config_file_path}\")\n\n    summary_df = load_summary_file(summary_file_path)\n    with open(config_file_path, 'r') as f:\n        config_dict = yaml.safe_load(f)\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        if not output_path.endswith(('.yaml', '.yml')):\n            raise ValueError(\"Output file path must have .yaml or .yml extension\")\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config, f)\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_file_path = os.path.join(trial_path, 'summary.csv')\n    config_file_path = os.path.join(trial_path, 'config.yaml')\n\n    summary_df = load_summary_file(summary_file_path)\n    with open(config_file_path, 'r') as f:\n        config_dict = yaml.safe_load(f)\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        with open(output_path, 'w') as file:\n            documents = yaml.dump(best_config, file)\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_file_path = os.path.join(trial_path, \"summary.csv\")\n    config_file_path = os.path.join(trial_path, \"config.yaml\")\n\n    if not os.path.exists(summary_file_path):\n        raise FileNotFoundError(f\"summary.csv not found in {trial_path}\")\n\n    if not os.path.exists(config_file_path):\n        raise FileNotFoundError(f\"config.yaml not found in {trial_path}\")\n\n    summary_df = load_summary_file(summary_file_path)\n    with open(config_file_path, 'r') as f:\n        config_dict = yaml.safe_load(f)\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        if not output_path.endswith(('.yaml', '.yml')):\n            raise ValueError(\"Output file must have .yaml or .yml extension\")\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config, f)\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_path = os.path.join(trial_path, 'summary.csv')\n    config_path = os.path.join(trial_path, 'config.yaml')\n\n    if not os.path.exists(summary_path):\n        raise FileNotFoundError(f\"summary.csv not found in {trial_path}\")\n\n    if not os.path.exists(config_path):\n        raise FileNotFoundError(f\"config.yaml not found in {trial_path}\")\n\n    summary_df = load_summary_file(summary_path)\n    with open(config_path, 'r') as f:\n        config_dict = yaml.safe_load(f)\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        if not output_path.endswith('.yaml') and not output_path.endswith('.yml'):\n            raise ValueError(\"Output file path must have .yaml or .yml extension\")\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config, f)\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_file_path = os.path.join(trial_path, \"summary.csv\")\n    config_file_path = os.path.join(trial_path, \"config.yaml\")\n\n    if not os.path.exists(summary_file_path) or not os.path.exists(config_file_path):\n        raise FileNotFoundError(\"summary.csv or config.yaml not found in the trial directory\")\n\n    summary_df = load_summary_file(summary_file_path)\n    with open(config_file_path, 'r') as f:\n        config_dict = yaml.safe_load(f)\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        if not output_path.endswith(('.yaml', '.yml')):\n            raise ValueError(\"Output file path must have .yaml or .yml extension\")\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config, f)\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_file_path = os.path.join(trial_path, 'summary.csv')\n    config_file_path = os.path.join(trial_path, 'config.yaml')\n\n    summary_df = load_summary_file(summary_file_path)\n    with open(config_file_path, 'r') as f:\n        config_dict = yaml.safe_load(f)\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config, f)\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_file_path = os.path.join(trial_path, 'summary.csv')\n    config_file_path = os.path.join(trial_path, 'config.yaml')\n\n    summary_df = load_summary_file(summary_file_path)\n    with open(config_file_path, 'r') as f:\n        config_dict = yaml.safe_load(f)\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config, f)\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_file_path = os.path.join(trial_path, \"summary.csv\")\n    config_file_path = os.path.join(trial_path, \"config.yaml\")\n\n    summary_df = load_summary_file(summary_file_path)\n    with open(config_file_path, 'r') as f:\n        config_dict = yaml.safe_load(f)\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        if not output_path.endswith(('.yaml', '.yml')):\n            raise ValueError(\"Output file must have .yaml or .yml extension\")\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config, f)\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "\n    summary_file = os.path.join(trial_path, 'summary.csv')\n    config_file = os.path.join(trial_path, 'config.yaml')\n\n    if not os.path.exists(summary_file) or not os.path.exists(config_file):\n        raise FileNotFoundError(\"Summary.csv or config.yaml not found in the specified trial directory.\")\n\n    summary_df = load_summary_file(summary_file)\n    with open(config_file, 'r') as f:\n        config_dict = yaml.safe_load(f)\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        if not output_path.endswith(('.yaml', '.yml')):\n            raise ValueError(\"Output file path must have .yaml or .yml extension.\")\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config, f)\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "\n    summary_file_path = os.path.join(trial_path, \"summary.csv\")\n    config_file_path = os.path.join(trial_path, \"config.yaml\")\n\n    summary_df = load_summary_file(summary_file_path)\n    with open(config_file_path, 'r') as f:\n        config_dict = yaml.safe_load(f)\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        with open(output_path, 'w') as file:\n            yaml.dump(best_config, file)\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_path = os.path.join(trial_path, 'summary.csv')\n    config_path = os.path.join(trial_path, 'config.yaml')\n\n    summary_df = load_summary_file(summary_path)\n    with open(config_path, 'r') as f:\n        config_dict = yaml.safe_load(f)\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        if not output_path.endswith('.yaml') and not output_path.endswith('.yml'):\n            raise ValueError(\"Output file path must have .yaml or .yml extension\")\n        with open(output_path, 'w') as file:\n            yaml.dump(best_config, file)\n\n    return best_config"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    global _lazy_trace_cache\n    if \"_lazy_trace_cache\" not in globals():\n        _lazy_trace_cache = {}\n\n    def wrapped(*args, **kwargs):\n        inputs = (args, kwargs)\n        key = (func, hash_arg(inputs), hash_arg(kwargs_))\n        if key in _lazy_trace_cache:\n            return _lazy_trace_cache[key](*args, **kwargs)\n        else:\n            traced_func = AutoTraceCompiler(ts_compiler=ts_compiler,\n                                           **kwargs_).compile(func, *args, **kwargs)\n            _lazy_trace_cache[key] = traced_func\n            return traced_func(*args, **kwargs)\n\n    return wrapped"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    cache = {}\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        inputs_key = hash_arg(args) + hash_arg(kwargs)\n        if inputs_key not in cache:\n            with threading.Lock():\n                if inputs_key not in cache:\n                    traced_func = trace_with_kwargs(func, *args, **kwargs_, ts_compiler=ts_compiler)\n                    cache[inputs_key] = traced_func\n        return cache[inputs_key](*args, **kwargs)\n\n    return wrapper"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    cache = {}\n\n    def wrapped(*args, **kwargs):\n        inputs_key = hash_arg(args), hash_arg(kwargs)\n        if inputs_key not in cache:\n            with threading.Lock():\n                if inputs_key not in cache:\n                    traced_func = trace_with_kwargs(func, example_inputs=args, example_kwarg_inputs=kwargs, ts_compiler=ts_compiler, **kwargs_)\n                    cache[inputs_key] = traced_func\n        return cache[inputs_key](*args, **kwargs)\n\n    return wrapped"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "        lock = threading.Lock()\n\n        @functools.wraps(func)\n        def wrapped_func(*args, **kwargs):\n            key = (func, args, kwargs)\n            with lock:\n                if key not in cache:\n                    traced_module, call_helper = trace_with_kwargs(func, *args, **kwargs_)\n                    if ts_compiler is not None:\n                        if 'call_helper' in inspect.signature(ts_compiler).parameters:\n                            traced_module = ts_compiler(traced_module, call_helper, *args, **kwargs_)\n                        else:\n                            converted_args = call_helper(traced_module).convert_inputs(*args, **kwargs_)\n                            traced_module = ts_compiler(traced_module, converted_args)\n                    traced_module = call_helper(traced_module)\n                    cache[key] = traced_module\n                return cache[key](*args, **kwargs)\n\n        return wrapped_func"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    cache = {}\n\n    def wrapper(*args, **kwargs):\n        key = (func, args, kwargs)\n        if key not in cache:\n            with threading.Lock():\n                if key not in cache:\n                    traced = trace_with_kwargs(func, *args, **kwargs_, ts_compiler=ts_compiler)\n                    cache[key] = traced\n        return cache[key]\n\n    return wrapper"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    cache = {}\n\n    @functools.wraps(func)\n    def lazy_trace_wrapper(*args, **kwargs):\n        inputs_key = hash_arg(args) if args else hash_arg(kwargs)\n        outputs_key = None\n        if inputs_key in cache:\n            traced_module, call_helper = cache[inputs_key]\n        else:\n            traced_module, call_helper = apply_auto_trace_compiler(\n                func, filter_func=None, recursive=True, ts_compiler=ts_compiler,\n                **kwargs_)\n            cache[inputs_key] = traced_module, call_helper\n\n        return traced_module(*args, **kwargs)\n\n    return lazy_trace_wrapper"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "\n        cache = {}\n        lock = threading.Lock()\n\n        def wrapper(*args, **kwargs):\n            key = (func, args, hash_arg(kwargs), ts_compiler, kwargs_)\n            with lock:\n                if key not in cache:\n                    traced_func = trace_with_kwargs(func, *args, **kwargs_, ts_compiler=ts_compiler)\n                    cache[key] = traced_func\n            return cache[key](*args, **kwargs)\n\n        return wrapper"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "\n        lock = threading.Lock()\n\n        @functools.wraps(func)\n        def wrapped(*args, **kwargs):\n            key = (func, args, tuple(kwargs.items()))\n            with lock:\n                if key not in cache:\n                    if isinstance(func, torch.nn.Module):\n                        traced_module, call_helper = trace_with_kwargs(\n                            func, *args, **kwargs_, ts_compiler=ts_compiler)\n                        traced_module = call_helper(traced_module)\n                    else:\n                        traced_func, call_helper = better_trace(\n                            func, *args, **kwargs_, ts_compiler=ts_compiler)\n                        traced_module = to_module(traced_func)\n\n                    cache[key] = traced_module\n\n                return cache[key](*args, **kwargs)\n\n        return wrapped"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "\n        lock = threading.Lock()\n\n        def wrapper(*args, **kwargs):\n            key = (func, args, frozenset(kwargs.items()))\n            with lock:\n                if key not in cache:\n                    traced_module, call_helper = trace_with_kwargs(\n                        to_module(func), *args, **kwargs_, ts_compiler=ts_compiler)\n                    cache[key] = traced_module, call_helper\n                else:\n                    traced_module, call_helper = cache[key]\n            return traced_module(*args, **kwargs)\n\n        return wrapper"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "        def wrapper(*args, **kwargs):\n            key = (func, args, frozenset(kwargs.items()))\n            if key in cache:\n                return cache[key]\n            else:\n                traced_func = trace_with_kwargs(func, *args, **kwargs_)\n                if ts_compiler:\n                    traced_func = ts_compiler(traced_func)\n                cache[key] = traced_func\n                return traced_func\n        return wrapper"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    cache = {}\n\n    def wrapper(*args, **kwargs):\n        key = (func, args, kwargs)\n        if key not in cache:\n            with threading.Lock():\n                if key not in cache:\n                    traced = trace_with_kwargs(func, *args, **kwargs_)\n                    cache[key] = traced\n        return cache[key]\n\n    return wrapper"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "        cache = {}\n\n        def wrapper(*args, **kwargs):\n            key = (func, args, frozenset(kwargs.items()))\n            if key not in cache:\n                with threading.Lock():\n                    if key not in cache:\n                        cache[key] = trace_with_kwargs(func, *args, **kwargs_, ts_compiler=ts_compiler)\n            return cache[key]\n\n        return wrapper"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    cache = {}\n\n    def wrapped(*args, **kwargs):\n        inputs = args, kwargs\n        key = (func, hash_arg(inputs), hash_arg(kwargs_))\n        if key in cache:\n            return cache[key](*args, **kwargs)\n        with threading.Lock():\n            if key in cache:\n                return cache[key](*args, **kwargs)\n            traced = AutoTraceCompiler(ts_compiler=ts_compiler, **kwargs_).compile(\n                func, *args, **kwargs)\n            cache[key] = traced\n            return traced(*args, **kwargs)\n\n    return wrapped"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    cache = {}\n\n    def wrapped(*args, **kwargs):\n        inputs = (args, kwargs)\n        key = (func, ts_compiler, kwargs_, inputs)\n        if key not in cache:\n            with threading.Lock():\n                if key not in cache:\n                    traced = trace_with_kwargs(func, *inputs, ts_compiler=ts_compiler, **kwargs_)\n                    cache[key] = traced\n        return cache[key](*args, **kwargs)\n\n    return wrapped"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "        traced_cache = {}\n\n        def trace_with_kwargs(func, example_inputs=None, example_kwarg_inputs=None, **kwargs):\n            if example_inputs is None:\n                example_inputs = tuple()\n            if example_kwarg_inputs is None:\n                example_kwarg_inputs = {}\n            pos_args = flat_tensors.flattern(\n                (tree_copy(example_inputs,\n                           detach=True), tree_copy(example_kwarg_inputs, detach=True)))\n            traced_module = better_trace(TraceablePosArgOnlyModuleWrapper(func),\n                                         pos_args, **kwargs)\n            training = getattr(func, 'training', False) if isinstance(\n                func, torch.nn.Module) else None\n            return traced_module, lambda m: TracedPosArgOnlyModuleWrapper(\n                m, training=training)\n\n        def get_traced_module(func, inputs, kwargs):\n            inputs_key = hash_arg(inputs)\n            kwargs_key = hash_arg(kwargs)\n            if (func, inputs_key, kwargs_key) in traced_cache:\n                return traced_cache[(func, inputs_key, kwargs_key)]\n            traced_module, call_helper = trace_with_kwargs(func, inputs, kwargs, **kwargs_)\n            traced_cache[(func, inputs_key, kwargs_key)] = (traced_module, call_helper)\n            return traced_module, call_helper\n\n        def wrapped_func(*args, **kwargs):\n            inputs = args\n            if kwargs:\n                inputs = (args, kwargs)\n            traced_module, call_helper = get_traced_module(func, *inputs)\n            return traced_module(*args, **kwargs)\n\n        return wrapped_func"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    _trace_cache = {}\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        inputs_key = hash_arg(args), hash_arg(kwargs)\n        if inputs_key not in _trace_cache:\n            _trace_cache[inputs_key] = AutoTraceCompiler(ts_compiler=ts_compiler, **kwargs_).compile(func, args, kwargs)\n        return _trace_cache[inputs_key](*args, **kwargs)\n\n    return wrapper"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    cache = {}\n\n    def wrapper(*args, **kwargs):\n        inputs = (args, kwargs)\n        key = (func, hash_arg(inputs), hash_arg(kwargs_.items()))\n        if key in cache:\n            return cache[key](*args, **kwargs)\n        else:\n            with threading.Lock():\n                if key in cache:\n                    return cache[key](*args, **kwargs)\n                traced_func = trace_with_kwargs(func, *args, **kwargs_, ts_compiler=ts_compiler)\n                cache[key] = traced_func\n                return traced_func(*args, **kwargs)\n\n    return wrapper"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    global _lazy_trace_cache\n    if not hasattr(lazy_trace, '_lazy_trace_cache'):\n        lazy_trace._lazy_trace_cache = {}\n\n    def wrapper(*args, **kwargs):\n        inputs = flat_tensors.flattern(args, kwargs)\n        inputs_key = hash_arg(inputs)\n        if inputs_key in _lazy_trace_cache:\n            return _lazy_trace_cache[inputs_key](*args, **kwargs)\n\n        if isinstance(func, torch.nn.Module):\n            module_to_be_traced = to_module(func)\n            traced_m, call_helper = trace_with_kwargs(module_to_be_traced, *args, **kwargs_)\n        else:\n            traced_m, call_helper = trace_with_kwargs(func, *args, **kwargs_)\n\n        if ts_compiler is not None:\n            if 'call_helper' in inspect.signature(ts_compiler).parameters:\n                traced_m = ts_compiler(traced_m, call_helper, *args, **kwargs_)\n            else:\n                converted_args = call_helper(traced_m).convert_inputs(*args, **kwargs_)\n                traced_m = ts_compiler(traced_m, converted_args)\n\n        traced_module = call_helper(traced_m)\n\n        @functools.wraps(func)\n        def functionalized(*args, **kwargs):\n            return traced_module(*args, **kwargs)\n\n        _lazy_trace_cache[inputs_key] = functionalized\n        return functionalized(*args, **kwargs)\n\n    return wrapper"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    cache = {}\n\n    def wrapper(*args, **kwargs):\n        key = (func, args, kwargs)\n        if key not in cache:\n            with threading.Lock():\n                if key not in cache:\n                    traced = trace_with_kwargs(func, *args, **kwargs_)\n                    cache[key] = traced\n        return cache[key]\n\n    return wrapper"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    cache = {}\n\n    def wrapper(*args, **kwargs):\n        key = (func, args, tuple(kwargs.items()))\n        if key not in cache:\n            cache[key] = AutoTraceCompiler(ts_compiler=ts_compiler, **kwargs_).compile(func, args, kwargs)\n        return cache[key](*args, **kwargs)\n\n    return wrapper"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        output_path = os.path.join(trial_path, 'best_config.yaml')\n        yaml_dict = extract_best_config(trial_path, output_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls.from_yaml(output_path, project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        output_path = os.path.join(trial_path, 'best_config.yaml')\n        yaml_dict = extract_best_config(trial_path, output_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls.from_yaml(output_path, project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config_yaml_path = os.path.join(trial_path, 'best_config.yaml')\n        if not os.path.exists(config_yaml_path):\n            raise ValueError(f\"best_config.yaml does not exist in {trial_path}.\")\n        return cls.from_yaml(config_yaml_path, project_dir=os.path.dirname(trial_path))"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config = extract_best_config(trial_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls(config, project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        output_path = os.path.join(trial_path, 'best_config.yaml')\n        yaml_dict = extract_best_config(trial_path, output_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls.from_yaml(output_path, project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        output_path = os.path.join(trial_path, 'best_config.yaml')\n        yaml_dict = extract_best_config(trial_path, output_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls(yaml_dict, project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config = extract_best_config(trial_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls(config, project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        output_path = os.path.join(trial_path, 'best_config.yaml')\n        config_dict = extract_best_config(trial_path, output_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls(config_dict, project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        output_path = os.path.join(trial_path, 'best_config.yaml')\n        yaml_dict = extract_best_config(trial_path, output_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls.from_yaml(output_path, project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        output_path = os.path.join(trial_path, 'best_config.yaml')\n        yaml_dict = extract_best_config(trial_path, output_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls.from_yaml(output_path, project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config_path = os.path.join(trial_path, 'config.yaml')\n        if not os.path.exists(config_path):\n            raise ValueError(f\"config.yaml does not exist in {trial_path}.\")\n        with open(config_path, 'r') as f:\n            config = yaml.safe_load(f)\n        project_dir = os.path.dirname(trial_path)\n        return cls(config, project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        output_path = os.path.join(trial_path, 'best_config.yaml')\n        yaml_dict = extract_best_config(trial_path, output_path)\n        return cls.from_yaml(output_path, project_dir=os.path.dirname(trial_path))"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        output_path = os.path.join(trial_path, 'best_config.yaml')\n        yaml_dict = extract_best_config(trial_path, output_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls.from_yaml(output_path, project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        output_path = os.path.join(trial_path, 'best_config.yaml')\n        config_dict = extract_best_config(trial_path, output_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls(config_dict, project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        output_path = os.path.join(trial_path, \"best_config.yaml\")\n        yaml_dict = extract_best_config(trial_path, output_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls(yaml_dict, project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config = extract_best_config(trial_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls(config, project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        output_path = os.path.join(trial_path, 'config.yaml')\n        config = extract_best_config(trial_path, output_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls(config, project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config_yaml_path = os.path.join(trial_path, 'best_config.yaml')\n        runner = cls.from_yaml(config_yaml_path, project_dir=os.path.dirname(trial_path))\n        return runner"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        output_path = os.path.join(trial_path, 'best_config.yaml')\n        yaml_dict = extract_best_config(trial_path, output_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls.from_yaml(output_path, project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config_yaml_path = os.path.join(trial_path, 'best_config.yaml')\n        if not os.path.exists(config_yaml_path):\n            raise ValueError(f\"best_config.yaml does not exist in {trial_path}.\")\n        return cls.from_yaml(config_yaml_path, project_dir=os.path.dirname(trial_path))"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "\n    filtered_results = [result for result, val in zip(results, value) if val <= threshold]\n    filtered_metadatas = [metadata for metadata, val in zip(metadatas, value) if val <= threshold] if metadatas else []\n\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "\n    filtered_results = [result for result, val in zip(results, value) if val <= threshold]\n    filtered_metadatas = [metadata for metadata, val in zip(metadatas, value) if val <= threshold] if metadatas else []\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "\n    filtered_results = [result for i, result in enumerate(results) if value[i] <= threshold]\n    filtered_metadatas = [metadata for i, metadata in enumerate(metadatas) if value[i] <= threshold] if metadatas else []\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "\n    filtered_results = [result for i, result in enumerate(results) if value[i] <= threshold]\n    filtered_metadatas = [metadata for i, metadata in enumerate(metadatas) if value[i] <= threshold] if metadatas else []\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "\n    filtered_results = [result for result, val in zip(results, value) if val <= threshold]\n    filtered_metadatas = [metadata for metadata, val in zip(metadatas, value) if val <= threshold] if metadatas else []\n\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "\n    filtered_results = [result for result, val in zip(results, value) if val <= threshold]\n    filtered_metadatas = [metadata for metadata, val in zip(metadatas, value) if val <= threshold] if metadatas else []\n\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "\n    filtered_results = [result for result, val in zip(results, value) if val <= threshold]\n    filtered_metadatas = [metadata for metadata, val in zip(metadatas, value) if val <= threshold] if metadatas else []\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    filtered_results = [result for result, val in zip(results, value) if val <= threshold]\n    filtered_metadatas = [metadata for metadata, val in zip(metadatas, value) if val <= threshold]\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "\n    filtered_results = [result for result, val in zip(results, value) if val <= threshold]\n    filtered_metadatas = [metadata for metadata, val in zip(metadatas, value) if val <= threshold] if metadatas else []\n\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    filtered_results = [result for result, val in zip(results, value) if val <= threshold]\n    filtered_metadatas = [metadata for metadata, val in zip(metadatas or [None] * len(results), value) if val <= threshold]\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "\n    filtered_results = [result for result, val in zip(results, value) if val <= threshold]\n    filtered_metadatas = [metadata for metadata, val in zip(metadatas, value) if val <= threshold] if metadatas else []\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    filtered_results = [result for result, val in zip(results, value) if val <= threshold]\n    filtered_metadatas = [metadata for metadata, val in zip(metadatas, value) if val <= threshold]\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "\n    filtered_results = [result for result, val in zip(results, value) if val <= threshold]\n    filtered_metadatas = [metadata for metadata, val in zip(metadatas, value) if val <= threshold] if metadatas else []\n\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "\n    filtered_results = [result for result, val in zip(results, value) if val <= threshold]\n    filtered_metadatas = [metadata for metadata, val in zip(metadatas, value) if val <= threshold] if metadatas else []\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "\n    filtered_results = [result for result, val in zip(results, value) if val <= threshold]\n    filtered_metadatas = [metadata for metadata, val in zip(metadatas, value) if val <= threshold] if metadatas else []\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "\n    filtered_results = [result for result, val in zip(results, value) if val <= threshold]\n    filtered_metadatas = [metadata for metadata, val in zip(metadatas, value) if val <= threshold] if metadatas else []\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n    assert len(results) == len(metadatas) == len(value), \"results, value, and metadatas must have the same length.\"\n    \n    filtered_results = [result for result, val in zip(results, value) if val <= threshold]\n    filtered_metadatas = [metadata for result, val, metadata in zip(results, value, metadatas) if val <= threshold]\n    \n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    filtered_results = [result for result, val in zip(results, value) if val <= threshold]\n    filtered_metadatas = [metadata for metadata, val in zip(metadatas, value) if val <= threshold] if metadatas else []\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "\n    filtered_results = [result for result, val in zip(results, value) if val <= threshold]\n    filtered_metadatas = [metadata for metadata, val in zip(metadatas, value) if val <= threshold] if metadatas else []\n    \n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "\n    filtered_results = [result for result, val in zip(results, value) if val <= threshold]\n    filtered_metadatas = [metadata for metadata, val in zip(metadatas, value) if val <= threshold] if metadatas else []\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    results = []\n    execution_times = []\n    for module, params in zip(modules, module_params):\n        result, time = measure_speed(module, params)\n        results.append(result)\n        execution_times.append(time)\n\n    result_df = pd.concat(results, axis=1)\n    result_df.columns = [f\"retrieved_{i}\" for i in range(len(results))]\n\n    result_df = filter_by_threshold(result_df, strategies.get('speed_threshold', None))\n\n    best_result = select_best_average(result_df)\n\n    best_result.to_parquet(os.path.join(node_line_dir, \"best_result.parquet\"))\n\n    summary_df = pd.DataFrame({\n        'filename': [\"best_result.parquet\"],\n        'module_name': [\"retrieval\"],\n        'module_params': [module_params],\n        'execution_time': [sum(execution_times)]\n    })\n\n    summary_df.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    return pd.concat([previous_result, best_result], axis=1)"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Run each retrieval module with given parameters\n    result_dfs = []\n    execution_times = []\n    for module, params in zip(modules, module_params):\n        result_df, execution_time = module(previous_result, **params)\n        result_dfs.append(result_df)\n        execution_times.append(execution_time)\n\n    # Measure execution times\n    total_execution_time = sum(execution_times)\n    logger.info(f\"Total execution time for retrieval node: {total_execution_time}\")\n\n    # Apply specified strategies\n    result_df = pd.concat(result_dfs, axis=1)\n    result_df = measure_speed(result_df, execution_times)\n    result_df = filter_by_threshold(result_df, strategies['speed_threshold'])\n    result_df = select_best_average(result_df)\n\n    # Save results and summary of execution times and evaluation metrics to disk\n    result_df.to_parquet(os.path.join(node_line_dir, \"result.parquet\"))\n    summary_df = pd.DataFrame({\n        'filename': [\"result.parquet\"],\n        'module_name': [\"retrieval_node\"],\n        'module_params': [module_params],\n        'execution_time': [total_execution_time]\n    })\n    summary_df.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    return result_df"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    result_dfs = []\n    execution_times = []\n    for module, params in zip(modules, module_params):\n        result_df, execution_time = measure_speed(module, params, previous_result)\n        result_dfs.append(result_df)\n        execution_times.append(execution_time)\n\n    summary_df = pd.DataFrame({\n        'filename': [f\"result_{i}.parquet\" for i in range(len(modules))],\n        'module_name': [module.__name__ for module in modules],\n        'module_params': module_params,\n        'execution_time': execution_times\n    })\n\n    summary_df.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    filtered_results = []\n    for result_df, strategy in zip(result_dfs, strategies):\n        filtered_result = filter_by_threshold(result_df, strategy)\n        filtered_results.append(filtered_result)\n\n    best_result = select_best_average(filtered_results)\n\n    best_result.to_parquet(os.path.join(node_line_dir, \"best_result.parquet\"), index=False)\n\n    return best_result"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    result_df = pd.DataFrame()\n    execution_times = []\n    for i, module in enumerate(modules):\n        logger.info(f\"Running module {module.__name__} with params {module_params[i]}\")\n        result = module(previous_result, **module_params[i])\n        execution_time = measure_speed(result, node_line_dir, module.__name__)\n        execution_times.append(execution_time)\n        result_df[f\"{module.__name__}_retrieved_contents\"] = result['retrieved_contents']\n        result_df[f\"{module.__name__}_retrieved_ids\"] = result['retrieved_ids']\n        result_df[f\"{module.__name__}_retrieve_scores\"] = result['retrieve_scores']\n\n    result_df = filter_by_threshold(result_df, strategies)\n    best_result = select_best_average(result_df, strategies)\n\n    summary_df = pd.DataFrame({\n        'module_name': [module.__name__ for module in modules],\n        'filename': [f\"{module.__name__}_retrieval_result.parquet\" for module in modules],\n        'module_params': module_params,\n        'execution_time': execution_times\n    })\n\n    summary_df = edit_summary_df_params(summary_df, [module.__name__ for module in modules], module_params)\n    summary_df.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    best_result.to_parquet(os.path.join(node_line_dir, \"best_retrieval_result.parquet\"), index=False)\n\n    return best_result"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    result_dfs = []\n    execution_times = []\n    \n    for i, module in enumerate(modules):\n        module_param = module_params[i]\n        result_df, execution_time = measure_speed(module, module_param, previous_result)\n        result_dfs.append(result_df)\n        execution_times.append(execution_time)\n    \n    result_df = select_best_average(result_dfs)\n    result_df.to_parquet(os.path.join(node_line_dir, \"result.parquet\"))\n    \n    summary_df = pd.DataFrame({\n        'filename': [\"result.parquet\"],\n        'module_name': [os.path.basename(node_line_dir)],\n        'module_params': [module_params],\n        'execution_time': [sum(execution_times)]\n    })\n    summary_df.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n    \n    return result_df"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    result_dfs = []\n    execution_times = []\n    for module, params in zip(modules, module_params):\n        result_df, execution_time = measure_speed(module, params, previous_result)\n        result_dfs.append(result_df)\n        execution_times.append(execution_time)\n\n    summary_df = pd.DataFrame({\n        'module_name': [module.__name__ for module in modules],\n        'filename': [f\"result_{i}.parquet\" for i in range(len(modules))],\n        'module_params': module_params,\n        'execution_time': execution_times\n    })\n\n    summary_df.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    filtered_results = []\n    for result_df in result_dfs:\n        filtered_result = filter_by_threshold(result_df, strategies['threshold'])\n        filtered_results.append(filtered_result)\n\n    selected_result = select_best_average(filtered_results)\n    selected_result.to_parquet(os.path.join(node_line_dir, \"selected_result.parquet\"), index=False)\n\n    return selected_result"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    result_dfs = []\n    execution_times = []\n    for module, params in zip(modules, module_params):\n        result_df, execution_time = measure_speed(module, params, previous_result)\n        result_dfs.append(result_df)\n        execution_times.append(execution_time)\n\n    summary_df = pd.DataFrame({\n        'filename': [f\"retrieval_{i}.parquet\" for i in range(len(modules))],\n        'module_name': [module.__name__ for module in modules],\n        'module_params': module_params,\n        'execution_time': execution_times\n    })\n\n    summary_df = filter_by_threshold(summary_df, strategies)\n\n    best_module = select_best_average(summary_df, strategies)\n\n    best_result = result_dfs[summary_df.index[best_module]]\n\n    best_result.to_parquet(os.path.join(node_line_dir, f\"best_retrieval_result.parquet\"), index=False)\n    summary_df.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    return best_result"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    results = []\n    execution_times = []\n\n    for module, params in zip(modules, module_params):\n        result, execution_time = module(previous_result, **params)\n        results.append(result)\n        execution_times.append(execution_time)\n\n    summary = pd.DataFrame({\n        'filename': [f\"result_{i}.parquet\" for i in range(len(modules))],\n        'module_name': [module.__name__ for module in modules],\n        'module_params': module_params,\n        'execution_time': execution_times\n    })\n\n    summary.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    best_results = select_best_average(summary, strategies.get('metrics', []))\n\n    best_results.to_parquet(os.path.join(node_line_dir, \"best_results.parquet\"), index=False)\n\n    return best_results"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    results = []\n    execution_times = []\n    for i, module in enumerate(modules):\n        params = module_params[i]\n        result, time = measure_speed(module, params, previous_result)\n        results.append(result)\n        execution_times.append(time)\n\n    summary_df = pd.DataFrame({\n        'filename': [f\"result_{i}.parquet\" for i in range(len(modules))],\n        'module_name': [module.__name__ for module in modules],\n        'module_params': module_params,\n        'execution_time': execution_times\n    })\n\n    summary_df.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    filtered_results = filter_by_threshold(results, strategies['speed_threshold'])\n    selected_result = select_best_average(filtered_results)\n\n    selected_result.to_parquet(os.path.join(node_line_dir, \"selected_result.parquet\"))\n\n    return selected_result"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    result_dfs = []\n    execution_times = []\n    \n    for module, params in zip(modules, module_params):\n        result_df, execution_time = measure_speed(module, params)\n        result_dfs.append(result_df)\n        execution_times.append(execution_time)\n    \n    result_df = select_best_average(result_dfs, strategies['metrics'])\n    result_df = filter_by_threshold(result_df, strategies.get('thresholds', None))\n    \n    summary_df = pd.DataFrame({\n        'filename': [f\"result_{i}.parquet\" for i in range(len(modules))],\n        'module_name': [module.__name__ for module in modules],\n        'module_params': module_params,\n        'execution_time': execution_times\n    })\n    \n    summary_df.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n    result_df.to_parquet(os.path.join(node_line_dir, \"result.parquet\"), index=False)\n    \n    return result_df"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Run each module with given parameters\n    results = []\n    execution_times = []\n    for i, module in enumerate(modules):\n        params = module_params[i]\n        result = module(previous_result, **params)\n        results.append(result)\n        execution_time = measure_speed(result)\n        execution_times.append(execution_time)\n\n    # Apply specified strategies\n    filtered_results = []\n    for result in results:\n        filtered_result = filter_by_threshold(result, strategies['speed_threshold'])\n        filtered_results.append(filtered_result)\n\n    selected_result = select_best_average(filtered_results)\n\n    # Save results and summary of execution times and evaluation metrics to disk\n    os.makedirs(node_line_dir, exist_ok=True)\n    summary_df = pd.DataFrame({\n        'filename': [f\"result_{i}.parquet\" for i in range(len(modules))],\n        'module_name': [module.__name__ for module in modules],\n        'module_params': module_params,\n        'execution_time': execution_times\n    })\n    summary_df.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n    selected_result.to_parquet(os.path.join(node_line_dir, \"selected_result.parquet\"))\n\n    return selected_result"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Run each module with given parameters\n    results = []\n    execution_times = []\n    for i, module in enumerate(modules):\n        result = module(previous_result, **module_params[i])\n        results.append(result)\n        execution_time = measure_speed(result)\n        execution_times.append(execution_time)\n\n    # Apply specified strategies\n    filtered_results = []\n    for result, execution_time in zip(results, execution_times):\n        if filter_by_threshold(execution_time, strategies.get('speed_threshold', None)):\n            filtered_results.append(result)\n\n    selected_result = select_best_average(filtered_results)\n\n    # Save results and summary of execution times and evaluation metrics to disk\n    os.makedirs(node_line_dir, exist_ok=True)\n    for i, result in enumerate(results):\n        result.to_parquet(os.path.join(node_line_dir, f\"result_{i}.parquet\"))\n    summary = pd.DataFrame({\n        'filename': [f\"result_{i}.parquet\" for i in range(len(results))],\n        'module_name': [module.__name__ for module in modules],\n        'module_params': module_params,\n        'execution_time': execution_times\n    })\n    summary.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    return selected_result"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    results = []\n    execution_times = []\n    for module, params in zip(modules, module_params):\n        result, execution_time = measure_speed(module, params, previous_result)\n        results.append(result)\n        execution_times.append(execution_time)\n\n    result_df = pd.concat(results, axis=1)\n    result_df.columns = [f\"retrieved_{i}\" for i in range(len(results))]\n\n    result_df = filter_by_threshold(result_df, strategies.get('speed_threshold'))\n\n    best_result = select_best_average(result_df, strategies.get('metrics'))\n\n    summary_df = pd.DataFrame({\n        'filename': [f\"result_{i}.parquet\" for i in range(len(results))],\n        'module_name': [module.__name__ for module in modules],\n        'module_params': module_params,\n        'execution_time': execution_times\n    })\n\n    summary_df.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    best_result.to_parquet(os.path.join(node_line_dir, \"best_result.parquet\"))\n\n    return best_result"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    result_dfs = []\n    execution_times = []\n    for module, params in zip(modules, module_params):\n        result_df, execution_time = measure_speed(module, params, previous_result)\n        result_dfs.append(result_df)\n        execution_times.append(execution_time)\n\n    summary_df = pd.DataFrame({\n        'filename': [f\"result_{i}.parquet\" for i in range(len(modules))],\n        'module_name': [module.__name__ for module in modules],\n        'module_params': module_params,\n        'execution_time': execution_times\n    })\n\n    summary_df.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    filtered_results = filter_by_threshold(result_dfs, strategies)\n    best_result = select_best_average(filtered_results)\n\n    best_result.to_parquet(os.path.join(node_line_dir, \"best_result.parquet\"), index=False)\n\n    return best_result"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    result_dfs = []\n    execution_times = []\n    for module, params in zip(modules, module_params):\n        result_df, execution_time = measure_speed(module, params)\n        result_dfs.append(result_df)\n        execution_times.append(execution_time)\n\n    summary_df = pd.DataFrame({\n        'module_name': [module.__name__ for module in modules],\n        'filename': [f\"result_{i}.parquet\" for i in range(len(modules))],\n        'module_params': module_params,\n        'execution_time': execution_times\n    })\n\n    summary_df.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    filtered_results = filter_by_threshold(result_dfs, strategies)\n    selected_result = select_best_average(filtered_results)\n\n    selected_result.to_parquet(os.path.join(node_line_dir, \"selected_result.parquet\"), index=False)\n\n    return selected_result"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    result_dfs = []\n    execution_times = []\n    for module, params in zip(modules, module_params):\n        result_df, execution_time = measure_speed(module, params, previous_result)\n        result_dfs.append(result_df)\n        execution_times.append(execution_time)\n\n    result_df = select_best_average(result_dfs, execution_times)\n    result_df = filter_by_threshold(result_df, strategies)\n\n    # Save result_df to parquet\n    result_df.to_parquet(os.path.join(node_line_dir, \"result.parquet\"))\n\n    # Save summary file\n    summary_df = pd.DataFrame({\n        'filename': [\"result.parquet\"],\n        'module_name': [os.path.basename(node_line_dir)],\n        'module_params': [module_params],\n        'execution_time': [sum(execution_times)]\n    })\n    summary_df.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    return result_df"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    result_df = pd.DataFrame()\n    for module, params in zip(modules, module_params):\n        result = module(previous_result, **params)\n        result_df = pd.concat([result_df, result], ignore_index=True)\n\n    result_df.to_parquet(os.path.join(node_line_dir, \"result.parquet\"))\n\n    summary = {\n        'filename': 'result.parquet',\n        'module_name': 'retrieval',\n        'module_params': module_params,\n        'execution_time': measure_speed(node_line_dir)\n    }\n\n    summary_df = pd.DataFrame(summary, index=[0])\n    summary_df.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    filtered_result = filter_by_threshold(result_df, strategies)\n    best_result = select_best_average(filtered_result)\n\n    return best_result"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    result_dfs = []\n    execution_times = []\n    \n    for i, module in enumerate(modules):\n        logger.info(f\"Running retrieval module {i+1}/{len(modules)}\")\n        start_time = measure_speed()\n        result_df = module(previous_result, **module_params[i])\n        execution_time = measure_speed(start_time)\n        execution_times.append(execution_time)\n        \n        result_df = filter_by_threshold(result_df, strategies.get('speed_threshold'))\n        result_dfs.append(result_df)\n    \n    best_result_df = select_best_average(result_dfs)\n    best_result_df.to_parquet(os.path.join(node_line_dir, \"best_result.parquet\"))\n    \n    summary = pd.DataFrame({\n        'filename': [\"best_result.parquet\"],\n        'module_name': [\"retrieval\"],\n        'module_params': [module_params],\n        'execution_time': [sum(execution_times)]\n    })\n    summary.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n    \n    return best_result_df"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Run each module with given parameters\n    results = []\n    execution_times = []\n    for i, module in enumerate(modules):\n        logger.info(f\"Running retrieval module {i + 1}/{len(modules)}\")\n        result, execution_time = module(previous_result, **module_params[i])\n        results.append(result)\n        execution_times.append(execution_time)\n\n    # Measure execution times\n    total_execution_time = sum(execution_times)\n    logger.info(f\"Total execution time for all modules: {total_execution_time} seconds\")\n\n    # Apply specified strategies\n    result_df = pd.concat(results, axis=1)\n    result_df.columns = [f\"module_{i+1}\" for i in range(len(modules))]\n    result_df = measure_speed(result_df, execution_times)\n    result_df = filter_by_threshold(result_df, strategies.get('speed_threshold'))\n    result_df = select_best_average(result_df)\n\n    # Save results and summary of execution times and evaluation metrics to disk\n    result_df.to_parquet(os.path.join(node_line_dir, \"result.parquet\"))\n    summary_df = pd.DataFrame({\n        'filename': [f\"module_{i+1}\" for i in range(len(modules))],\n        'module_name': [module.__name__ for module in modules],\n        'module_params': module_params,\n        'execution_time': execution_times\n    })\n    summary_df.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    return result_df"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Run each module with given parameters\n    results = []\n    execution_times = []\n    for module, params in zip(modules, module_params):\n        result, execution_time = module(previous_result, **params)\n        results.append(result)\n        execution_times.append(execution_time)\n\n    # Measure execution times\n    total_execution_time = sum(execution_times)\n    measure_speed(total_execution_time, node_line_dir)\n\n    # Apply strategies\n    result_df = pd.concat(results, axis=1)\n    result_df.columns = [f\"retrieved_{i}\" for i in range(len(results))]\n    result_df = filter_by_threshold(result_df, strategies)\n    result_df = select_best_average(result_df)\n\n    # Save results and summary\n    result_df.to_parquet(os.path.join(node_line_dir, \"result.parquet\"))\n    summary = pd.DataFrame({\n        'filename': [\"result.parquet\"],\n        'module_name': [\"retrieval_node\"],\n        'module_params': [module_params],\n        'execution_time': [total_execution_time]\n    })\n    summary.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    return result_df"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    fused_ids, fused_scores = cc_pure(ids, scores, weights, top_k)\n    return [fused_ids], [fused_scores]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    fused_ids, fused_scores = cc_pure(ids, scores, weights, top_k)\n    return [fused_ids], [fused_scores]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    fused_ids = []\n    fused_scores = []\n\n    for i in range(len(ids)):\n        ids_subset = ids[:i+1]\n        scores_subset = scores[:i+1]\n        weights_subset = weights[:i+1]\n\n        ids_subset = tuple(ids_subset)\n        scores_subset = tuple(scores_subset)\n        weights_subset = tuple(weights_subset)\n\n        ids_list, scores_list = cc_pure(ids_subset, scores_subset, weights_subset, top_k)\n\n        fused_ids.append(ids_list)\n        fused_scores.append(scores_list)\n\n    return fused_ids, fused_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    fused_ids = []\n    fused_scores = []\n    for i in range(len(ids)):\n        ids_list = ids[i]\n        scores_list = scores[i]\n        weighted_scores = [score * weights[i] for score in scores_list]\n        fused_ids.extend(ids_list)\n        fused_scores.extend(weighted_scores)\n    sorted_indices = sorted(range(len(fused_scores)), key=lambda k: fused_scores[k], reverse=True)\n    fused_ids = [fused_ids[i] for i in sorted_indices[:top_k]]\n    fused_scores = [fused_scores[i] for i in sorted_indices[:top_k]]\n    return [fused_ids], [fused_scores]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    fused_ids = []\n    fused_scores = []\n\n    for i in range(len(ids)):\n        ids_list, scores_list = ids[i], scores[i]\n        fused_ids.extend(ids_list)\n        fused_scores.extend([score * weights[i] for score in scores_list])\n\n    fused_ids = tuple(fused_ids)\n    fused_scores = tuple(fused_scores)\n\n    return cc_pure(fused_ids, fused_scores, weights, top_k)"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    fused_ids, fused_scores = cc_pure(ids, scores, weights, top_k)\n    return [fused_ids], [fused_scores]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    fused_ids = []\n    fused_scores = []\n\n    for i in range(len(ids)):\n        ids_subset = ids[:i+1]\n        scores_subset = scores[:i+1]\n        weights_subset = weights[:i+1]\n\n        ids_subset = tuple(ids_subset)\n        scores_subset = tuple(scores_subset)\n        weights_subset = tuple(weights_subset)\n\n        fused_id, fused_score = cc_pure(ids_subset, scores_subset, weights_subset, top_k)\n\n        fused_ids.append(fused_id)\n        fused_scores.append(fused_score)\n\n    return fused_ids, fused_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    fused_ids = []\n    fused_scores = []\n    for i in range(len(ids)):\n        ids_list = ids[i]\n        scores_list = scores[i]\n        weighted_scores = [score * weights[i] for score in scores_list]\n        fused_ids.extend(ids_list)\n        fused_scores.extend(weighted_scores)\n    sorted_indices = sorted(range(len(fused_scores)), key=lambda k: fused_scores[k], reverse=True)\n    fused_ids = [fused_ids[i] for i in sorted_indices[:top_k]]\n    fused_scores = [fused_scores[i] for i in sorted_indices[:top_k]]\n    return [fused_ids], [fused_scores]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    fused_ids = []\n    fused_scores = []\n    for i in range(len(ids)):\n        ids_list = ids[i]\n        scores_list = scores[i]\n        weight = weights[i]\n        fused_ids.append(ids_list)\n        fused_scores.append([score * weight for score in scores_list])\n\n    fused_ids = [item for sublist in fused_ids for item in sublist]\n    fused_scores = [item for sublist in fused_scores for item in sublist]\n\n    fused_ids = list(set(fused_ids))\n    df = pd.DataFrame({'id': fused_ids, 'score': fused_scores})\n    df = df.groupby('id').agg({'score': 'sum'}).reset_index()\n    df = df.sort_values(by='score', ascending=False)\n\n    return df['id'][:top_k].tolist(), df['score'][:top_k].tolist()"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    fused_ids = []\n    fused_scores = []\n    for i in range(len(ids)):\n        cc_ids, cc_scores = cc_pure(ids[i], scores[i], weights, top_k)\n        fused_ids.append(cc_ids)\n        fused_scores.append(cc_scores)\n    return fused_ids, fused_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    fused_ids = []\n    fused_scores = []\n\n    for i in range(len(ids)):\n        ids_subset = ids[:i+1]\n        scores_subset = scores[:i+1]\n        weighted_scores = [score * weights[i] for score in scores_subset]\n        fused_ids_subset, fused_scores_subset = cc_pure(ids_subset, weighted_scores, (1,) * len(ids_subset), top_k)\n        fused_ids.append(fused_ids_subset)\n        fused_scores.append(fused_scores_subset)\n\n    return fused_ids, fused_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    fused_ids = []\n    fused_scores = []\n\n    for i in range(len(ids)):\n        ids_list, scores_list = ids[i], scores[i]\n        fused_ids.extend(ids_list)\n        fused_scores.extend([score * weights[i] for score in scores_list])\n\n    fused_ids = tuple(fused_ids)\n    fused_scores = tuple(fused_scores)\n\n    return cc_pure(fused_ids, fused_scores, weights, top_k)"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "\n    def cc_pure(ids: Tuple, scores: Tuple, weights: Tuple, top_k: int) -> Tuple[\n        List[str], List[float]]:\n        df = pd.concat([pd.Series(dict(zip(_id, score))) for _id, score in zip(ids, scores)], axis=1)\n        normalized_scores = (df - df.min()) / (df.max() - df.min())\n        normalized_scores = normalized_scores.fillna(0)\n        normalized_scores['weighted_sum'] = normalized_scores.mul(weights).sum(axis=1)\n        normalized_scores = normalized_scores.sort_values(by='weighted_sum', ascending=False)\n        return normalized_scores.index.tolist()[:top_k], normalized_scores['weighted_sum'][:top_k].tolist()\n\n    return cc_pure(ids, scores, weights, top_k)"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    fused_ids = []\n    fused_scores = []\n\n    for i in range(len(ids)):\n        ids_subset = ids[:i+1]\n        scores_subset = scores[:i+1]\n        weights_subset = weights[:i+1]\n\n        subset_ids, subset_scores = cc_pure(ids_subset, scores_subset, weights_subset, top_k)\n\n        fused_ids.append(subset_ids)\n        fused_scores.append(subset_scores)\n\n    return fused_ids, fused_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    fused_ids, fused_scores = cc_pure(ids, scores, weights, top_k)\n    return [fused_ids], [fused_scores]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    return cc_pure(ids, scores, weights, top_k)"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "\n    def cc_pure(ids: Tuple, scores: Tuple, weights: Tuple, top_k: int) -> Tuple[\n        List[str], List[float]]:\n        df = pd.concat([pd.Series(dict(zip(_id, score))) for _id, score in zip(ids, scores)], axis=1)\n        normalized_scores = (df - df.min()) / (df.max() - df.min())\n        normalized_scores = normalized_scores.fillna(0)\n        normalized_scores['weighted_sum'] = normalized_scores.mul(weights).sum(axis=1)\n        normalized_scores = normalized_scores.sort_values(by='weighted_sum', ascending=False)\n        return normalized_scores.index.tolist()[:top_k], normalized_scores['weighted_sum'][:top_k].tolist()"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    def cc_pure(ids: Tuple, scores: Tuple, weights: Tuple, top_k: int) -> Tuple[\n        List[str], List[float]]:\n        df = pd.concat([pd.Series(dict(zip(_id, score))) for _id, score in zip(ids, scores)], axis=1)\n        normalized_scores = (df - df.min()) / (df.max() - df.min())\n        normalized_scores = normalized_scores.fillna(0)\n        normalized_scores['weighted_sum'] = normalized_scores.mul(weights).sum(axis=1)\n        normalized_scores = normalized_scores.sort_values(by='weighted_sum', ascending=False)\n        return normalized_scores.index.tolist()[:top_k], normalized_scores['weighted_sum'][:top_k].tolist()"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    cc_ids, cc_scores = cc_pure(ids, scores, weights, top_k)\n    return [cc_ids], [cc_scores]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    cc_ids, cc_scores = cc_pure(ids, scores, weights, top_k)\n    return [cc_ids], [cc_scores]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    weighted_scores = [sum([score * weight for score, weight in zip(score_list, weights)]) for score_list in zip(*scores)]\n    normalized_scores = [(score - min(weighted_scores)) / (max(weighted_scores) - min(weighted_scores)) for score in weighted_scores]\n    top_k_indices = sorted(range(len(normalized_scores)), key=lambda i: normalized_scores[i], reverse=True)[:top_k]\n    top_k_ids = [ids[i] for i in top_k_indices]\n    top_k_scores = [normalized_scores[i] for i in top_k_indices]\n    return top_k_ids, top_k_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "\n    # Calculate the weighted sum of scores for each ID\n    weighted_sums = [sum([score * weight for score, weight in zip(score_list, weights)]) for score_list in scores]\n\n    # Normalize the scores\n    normalized_scores = [score / sum(weighted_sums) for score in weighted_sums]\n\n    # Get the indices of the top K scores\n    top_k_indices = sorted(range(len(normalized_scores)), key=lambda i: normalized_scores[i], reverse=True)[:top_k]\n\n    # Return the top K IDs and their corresponding scores\n    top_k_ids = [ids[i] for i in top_k_indices]\n    top_k_scores = [normalized_scores[i] for i in top_k_indices]\n\n    return top_k_ids, top_k_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    weighted_sums = [sum(score * weight for score, weight in zip(scores[i], weights)) for i in range(len(scores))]\n    normalized_sums = [(s - min(weighted_sums)) / (max(weighted_sums) - min(weighted_sums)) for s in weighted_sums]\n    top_indices = sorted(range(len(normalized_sums)), key=lambda i: normalized_sums[i], reverse=True)[:top_k]\n    top_ids = [ids[i] for i in top_indices]\n    top_scores = [normalized_sums[i] for i in top_indices]\n    return top_ids, top_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "\n    weighted_sums = [sum([score * weight for score, weight in zip(score_list, weights)]) for score_list in scores]\n    normalized_sums = [(x - min(weighted_sums)) / (max(weighted_sums) - min(weighted_sums)) for x in weighted_sums]\n    top_indices = sorted(range(len(normalized_sums)), key=lambda i: normalized_sums[i], reverse=True)[:top_k]\n    top_ids = [ids[i] for i in top_indices]\n    top_scores = [normalized_sums[i] for i in top_indices]\n\n    return top_ids, top_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "\n    # Calculate the weighted sum of scores for each ID\n    weighted_sums = [sum(w * s for w, s in zip(weights, score_list)) for score_list in zip(*scores)]\n\n    # Normalize the weighted sums\n    normalized_sums = [(x - min(weighted_sums)) / (max(weighted_sums) - min(weighted_sums)) for x in weighted_sums]\n\n    # Get the top K IDs and their corresponding scores based on the weighted sum\n    top_k_indices = sorted(range(len(normalized_sums)), key=lambda i: normalized_sums[i], reverse=True)[:top_k]\n    top_k_ids = [ids[i] for i in top_k_indices]\n    top_k_scores = [normalized_sums[i] for i in top_k_indices]\n\n    return top_k_ids, top_k_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    weighted_sums = [sum([score * weight for score, weight in zip(score_list, weights)]) for score_list in scores]\n    normalized_sums = [(x - min(weighted_sums)) / (max(weighted_sums) - min(weighted_sums)) for x in weighted_sums]\n    top_k_indices = sorted(range(len(normalized_sums)), key=lambda i: normalized_sums[i], reverse=True)[:top_k]\n    top_k_ids = [ids[i] for i in top_k_indices]\n    top_k_scores = [normalized_sums[i] for i in top_k_indices]\n    return top_k_ids, top_k_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "\n    weighted_sums = [sum(w * s for w, s in zip(weights, score_list)) for score_list in zip(*scores)]\n    normalized_sums = [(x - min(weighted_sums)) / (max(weighted_sums) - min(weighted_sums)) for x in weighted_sums]\n    top_indices = sorted(range(len(normalized_sums)), key=lambda i: normalized_sums[i], reverse=True)[:top_k]\n    top_ids = [ids[i] for i in top_indices]\n    top_scores = [normalized_sums[i] for i in top_indices]\n\n    return top_ids, top_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    weighted_sums = []\n    for i in range(len(ids)):\n        weighted_sum = sum([score * weights[i] for score in scores[i]])\n        weighted_sums.append(weighted_sum)\n\n    normalized_weighted_sums = [(x - min(weighted_sums)) / (max(weighted_sums) - min(weighted_sums)) for x in weighted_sums]\n\n    top_indices = sorted(range(len(normalized_weighted_sums)), key=lambda i: normalized_weighted_sums[i], reverse=True)[:top_k]\n\n    top_ids = [ids[i] for i in top_indices]\n    top_scores = [normalized_weighted_sums[i] for i in top_indices]\n\n    return top_ids, top_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "\n    weighted_sums = []\n    for i in range(len(ids)):\n        weighted_sum = sum([score * weights[i] for score in scores[i]])\n        weighted_sums.append(weighted_sum)\n\n    normalized_weighted_sums = [(x - min(weighted_sums)) / (max(weighted_sums) - min(weighted_sums)) for x in weighted_sums]\n\n    top_k_indices = sorted(range(len(normalized_weighted_sums)), key=lambda i: normalized_weighted_sums[i], reverse=True)[:top_k]\n\n    top_k_ids = [ids[i] for i in top_k_indices]\n    top_k_scores = [normalized_weighted_sums[i] for i in top_k_indices]\n\n    return top_k_ids, top_k_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    weighted_sums = []\n    for i in range(len(ids)):\n        weighted_sum = sum([score * weights[i] for score in scores[i]])\n        weighted_sums.append(weighted_sum)\n\n    normalized_weighted_sums = [(x - min(weighted_sums)) / (max(weighted_sums) - min(weighted_sums)) for x in weighted_sums]\n\n    top_k_indices = sorted(range(len(normalized_weighted_sums)), key=lambda i: normalized_weighted_sums[i], reverse=True)[:top_k]\n\n    top_k_ids = [ids[i] for i in top_k_indices]\n    top_k_scores = [normalized_weighted_sums[i] for i in top_k_indices]\n\n    return top_k_ids, top_k_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "\n    # Calculate the weighted sum of scores for each ID\n    weighted_sums = [sum(score * weight for score, weight in zip(score_list, weights)) for score_list in scores]\n\n    # Normalize the weighted sums\n    max_weighted_sum = max(weighted_sums)\n    normalized_sums = [weighted_sum / max_weighted_sum for weighted_sum in weighted_sums]\n\n    # Get the top K IDs and their corresponding scores based on the weighted sum\n    top_indices = sorted(range(len(normalized_sums)), key=lambda i: normalized_sums[i], reverse=True)[:top_k]\n    top_ids = [ids[i] for i in top_indices]\n    top_scores = [normalized_sums[i] for i in top_indices]\n\n    return top_ids, top_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "\n    weighted_sums = [sum(w * s for w, s in zip(weights, score_list)) for score_list in zip(*scores)]\n    normalized_sums = [(s - min(weighted_sums)) / (max(weighted_sums) - min(weighted_sums)) for s in weighted_sums]\n    top_indices = sorted(range(len(normalized_sums)), key=lambda i: normalized_sums[i], reverse=True)[:top_k]\n\n    return [ids[i] for i in top_indices], [normalized_sums[i] for i in top_indices]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    weighted_sum = [sum([score * weight for score, weight in zip(score_list, weights)]) for score_list in zip(*scores)]\n    normalized_weighted_sum = [(x - min(weighted_sum)) / (max(weighted_sum) - min(weighted_sum)) for x in weighted_sum]\n    top_k_indices = sorted(range(len(normalized_weighted_sum)), key=lambda i: normalized_weighted_sum[i], reverse=True)[:top_k]\n    top_k_ids = [ids[i] for i in top_k_indices]\n    top_k_scores = [normalized_weighted_sum[i] for i in top_k_indices]\n    return top_k_ids, top_k_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "\n    # Calculate the weighted sum of scores for each ID\n    weighted_sums = [sum([score * weight for score, weight in zip(score_list, weights)]) for score_list in scores]\n\n    # Normalize the weighted sums\n    normalized_sums = [(x - min(weighted_sums)) / (max(weighted_sums) - min(weighted_sums)) for x in weighted_sums]\n\n    # Get the top K IDs based on the normalized weighted sums\n    top_indices = sorted(range(len(normalized_sums)), key=lambda i: normalized_sums[i], reverse=True)[:top_k]\n    top_ids = [ids[i] for i in top_indices]\n    top_scores = [normalized_sums[i] for i in top_indices]\n\n    return top_ids, top_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "\n    weighted_sums = [sum(score * weight for score, weight in zip(score_list, weights)) for score_list in scores]\n    normalized_sums = [(x - min(weighted_sums)) / (max(weighted_sums) - min(weighted_sums)) for x in weighted_sums]\n\n    top_indices = sorted(range(len(normalized_sums)), key=lambda i: normalized_sums[i], reverse=True)[:top_k]\n    top_ids = [ids[i] for i in top_indices]\n    top_scores = [normalized_sums[i] for i in top_indices]\n\n    return top_ids, top_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    weighted_sums = []\n    for i in range(len(ids)):\n        weighted_sum = sum([score * weights[i] for score in scores[i]])\n        weighted_sums.append(weighted_sum)\n\n    normalized_weighted_sums = [(x - min(weighted_sums)) / (max(weighted_sums) - min(weighted_sums)) for x in weighted_sums]\n\n    top_k_indices = sorted(range(len(normalized_weighted_sums)), key=lambda i: normalized_weighted_sums[i], reverse=True)[:top_k]\n\n    top_k_ids = [ids[i] for i in top_k_indices]\n    top_k_scores = [normalized_weighted_sums[i] for i in top_k_indices]\n\n    return top_k_ids, top_k_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    weighted_sums = [sum([score * weight for score, weight in zip(score_list, weights)]) for score_list in zip(*scores)]\n    normalized_weighted_sums = [(sum - min(weighted_sums)) / (max(weighted_sums) - min(weighted_sums)) for sum in weighted_sums]\n    top_k_indices = sorted(range(len(normalized_weighted_sums)), key=lambda i: normalized_weighted_sums[i], reverse=True)[:top_k]\n    top_k_ids = [ids[i] for i in top_k_indices]\n    top_k_scores = [normalized_weighted_sums[i] for i in top_k_indices]\n    return top_k_ids, top_k_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    weighted_sums = []\n    for i in range(len(ids)):\n        weighted_sum = sum([score * weights[i] for score in scores[i]])\n        weighted_sums.append(weighted_sum)\n\n    normalized_weighted_sums = [sum(weighted_sums)] * len(weighted_sums)\n    normalized_weighted_sums = [x / y for x, y in zip(weighted_sums, normalized_weighted_sums)]\n\n    sorted_ids = [id for _, id in sorted(zip(normalized_weighted_sums, ids), reverse=True)]\n    sorted_scores = sorted(normalized_weighted_sums, reverse=True)\n\n    return sorted_ids[:top_k], sorted_scores[:top_k]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "\n    weighted_sums = [sum(w * s for w, s in zip(weights, score)) for score in zip(*scores)]\n    normalized_sums = [(x - min(weighted_sums)) / (max(weighted_sums) - min(weighted_sums)) for x in weighted_sums]\n    top_indices = sorted(range(len(normalized_sums)), key=lambda i: normalized_sums[i], reverse=True)[:top_k]\n\n    top_ids = [ids[i] for i in top_indices]\n    top_scores = [normalized_sums[i] for i in top_indices]\n\n    return top_ids, top_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    weighted_sums = []\n    for i in range(len(ids)):\n        weighted_sum = sum([score * weights[i] for score in scores[i]])\n        weighted_sums.append(weighted_sum)\n\n    normalized_weighted_sums = [(x - min(weighted_sums)) / (max(weighted_sums) - min(weighted_sums)) for x in weighted_sums]\n\n    top_k_indices = sorted(range(len(normalized_weighted_sums)), key=lambda i: normalized_weighted_sums[i], reverse=True)[:top_k]\n\n    top_k_ids = [ids[i] for i in top_k_indices]\n    top_k_scores = [normalized_weighted_sums[i] for i in top_k_indices]\n\n    return top_k_ids, top_k_scores"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        data = {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"purpose_embedding\": agent.purpose_embedding.tolist() if agent.purpose_embedding is not None else None,\n            \"usage_count\": agent.usage_count,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n        return data"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        data = {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"usage_count\": agent.usage_count,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n\n        if agent.purpose_embedding is not None:\n            data[\"purpose_embedding\"] = agent.purpose_embedding.tolist()\n        \n        return data"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "\n        data = {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"purpose_embedding\": agent.purpose_embedding.tolist() if agent.purpose_embedding is not None else None,\n            \"usage_count\": agent.usage_count,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n\n        return data"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        data = {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"purpose_embedding\": agent.purpose_embedding.tolist() if agent.purpose_embedding is not None else None,\n            \"usage_count\": agent.usage_count,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n        return data"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        data = {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"usage_count\": agent.usage_count,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n\n        if agent.purpose_embedding is not None:\n            data[\"purpose_embedding\"] = agent.purpose_embedding.tolist()\n        \n        return data"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        data = {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"usage_count\": agent.usage_count,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n\n        if agent.purpose_embedding is not None:\n            data[\"purpose_embedding\"] = agent.purpose_embedding.tolist()\n        \n        return data"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        data = {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n        if agent.purpose_embedding is not None:\n            data[\"purpose_embedding\"] = agent.purpose_embedding.tolist()\n        return data"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        data = {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"purpose_embedding\": agent.purpose_embedding.tolist() if agent.purpose_embedding is not None else None,\n            \"usage_count\": agent.usage_count,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n        return data"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        data = {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"usage_count\": agent.usage_count,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n\n        if agent.purpose_embedding is not None:\n            data[\"purpose_embedding\"] = agent.purpose_embedding.tolist()\n        else:\n            data[\"purpose_embedding\"] = None\n\n        return data"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        data = {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"usage_count\": agent.usage_count,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n\n        if agent.purpose_embedding is not None:\n            data[\"purpose_embedding\"] = agent.purpose_embedding.tolist()\n        \n        return data"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        data = {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"purpose_embedding\": agent.purpose_embedding.tolist() if agent.purpose_embedding is not None else None,\n            \"usage_count\": agent.usage_count,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n        return data"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        data = {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"purpose_embedding\": agent.purpose_embedding.tolist() if agent.purpose_embedding is not None else None,\n            \"usage_count\": agent.usage_count,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n        return data"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        data = {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"usage_count\": agent.usage_count,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n\n        if agent.purpose_embedding is not None:\n            data[\"purpose_embedding\"] = agent.purpose_embedding.tolist()\n        else:\n            data[\"purpose_embedding\"] = None\n\n        return data"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        data = {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"usage_count\": agent.usage_count,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n\n        if agent.purpose_embedding is not None:\n            data[\"purpose_embedding\"] = agent.purpose_embedding.tolist()\n        else:\n            data[\"purpose_embedding\"] = None\n\n        return data"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        data = {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"purpose_embedding\": agent.purpose_embedding.tolist() if agent.purpose_embedding is not None else None,\n            \"usage_count\": agent.usage_count,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n        return data"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        data = {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"purpose_embedding\": agent.purpose_embedding.tolist() if agent.purpose_embedding is not None else None,\n            \"usage_count\": agent.usage_count,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n        return data"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        data = {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"purpose_embedding\": agent.purpose_embedding.tolist() if agent.purpose_embedding is not None else None,\n            \"usage_count\": agent.usage_count,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n        return data"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        data = {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"purpose_embedding\": agent.purpose_embedding.tolist() if agent.purpose_embedding is not None else None,\n            \"usage_count\": agent.usage_count,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n        return data"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        data = {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"purpose_embedding\": agent.purpose_embedding.tolist() if agent.purpose_embedding is not None else None,\n            \"usage_count\": agent.usage_count,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n        return data"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        data = {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"purpose_embedding\": agent.purpose_embedding.tolist() if agent.purpose_embedding is not None else None,\n            \"usage_count\": agent.usage_count,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n        return data"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}\\n\\n{PROMPT_ENGINEERING_TEMPLATE}\\n\\n{EXAMPLES}\\n\\n{sample_input}\"\n        try:\n            response = self.openai_wrapper.get_chat_completion(prompt)\n            if response:\n                return response\n            else:\n                return \"\"\n        except Exception as e:\n            logger.exception(f\"Error generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            # Generate prompt using goal and sample input\n            prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal} {PROMPT_ENGINEERING_TEMPLATE} {sample_input} {EXAMPLES}\"\n            completion = self.openai_wrapper.get_chat_completion(prompt)\n            return completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}\\n\\n{PROMPT_ENGINEERING_TEMPLATE} {sample_input}\\n\\n{EXAMPLES}\"\n            completion = self.openai_wrapper.get_chat_completion(prompt)\n            return completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}\\n\\n{PROMPT_ENGINEERING_TEMPLATE}\\n\\n{EXAMPLES}\\n\\n{sample_input}\"\n            completion = self.openai_wrapper.get_chat_completion(prompt)\n            return completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}\\n\\n{PROMPT_ENGINEERING_TEMPLATE} {sample_input}\\n\\n{EXAMPLES}\"\n            chat_completion = self.openai_wrapper.get_chat_completion(prompt)\n            return chat_completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}\\n\\n{PROMPT_ENGINEERING_TEMPLATE} {sample_input}\\n\\n{EXAMPLES}\"\n        try:\n            chat_completion = self.openai_wrapper.get_chat_completion(prompt)\n            if chat_completion:\n                return chat_completion\n            else:\n                return \"\"\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}\\n{PROMPT_ENGINEERING_TEMPLATE} {sample_input}\\n{EXAMPLES}\"\n            chat_completion = self.openai_wrapper.get_chat_completion(prompt)\n            return chat_completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}\\n{PROMPT_ENGINEERING_TEMPLATE} {sample_input}\\n{EXAMPLES}\"\n            completion = self.openai_wrapper.get_chat_completion(prompt)\n            return completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}\\n{PROMPT_ENGINEERING_TEMPLATE} {sample_input}\\n{EXAMPLES}\"\n            completion = self.openai_wrapper.get_chat_completion(prompt)\n            return completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}\\n{PROMPT_ENGINEERING_TEMPLATE}\\n{sample_input}\\n{EXAMPLES}\"\n            chat_completion = self.openai_wrapper.create_chat_completion(prompt)\n            return chat_completion.choices[0].text.strip()\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}\\n\\n{PROMPT_ENGINEERING_TEMPLATE} {sample_input}\\n\\n{EXAMPLES}\"\n            chat_completion = self.openai_wrapper.get_chat_completion(prompt)\n            return chat_completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}\\n{PROMPT_ENGINEERING_TEMPLATE} {sample_input}\\n{EXAMPLES}\"\n        try:\n            chat_completion = self.openai_wrapper.create_chat_completion(prompt)\n            return chat_completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}\\n{PROMPT_ENGINEERING_TEMPLATE} {sample_input}\\n{EXAMPLES}\"\n            chat_completion = self.openai_wrapper.get_chat_completion(prompt)\n            return chat_completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}\\n{PROMPT_ENGINEERING_TEMPLATE} {sample_input}\\n{EXAMPLES}\"\n            completion = self.openai_wrapper.get_chat_completion(prompt)\n            return completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}:\\n\\n{PROMPT_ENGINEERING_TEMPLATE}\\n\\n{EXAMPLES}\\n\\nSample input: {sample_input}\\n\\n\"\n            completion = self.openai_wrapper.get_chat_completion(prompt)\n            return completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}\\n{PROMPT_ENGINEERING_TEMPLATE} {sample_input}\\n\\n{EXAMPLES}\"\n        try:\n            chat_completion = self.openai_wrapper.get_chat_completion(prompt)\n            return chat_completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}\\n\\n{PROMPT_ENGINEERING_TEMPLATE} {sample_input}\\n\\n{EXAMPLES}\"\n            completion = self.openai_wrapper.get_chat_completion(prompt)\n            return completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}\\n\\n{PROMPT_ENGINEERING_TEMPLATE} {sample_input}\\n\\n{EXAMPLES}\"\n        try:\n            completion = self.openai_wrapper.get_chat_completion(prompt)\n            if completion:\n                return completion\n            else:\n                return \"\"\n        except Exception as e:\n            logger.exception(f\"Error generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}\\n\\n{PROMPT_ENGINEERING_TEMPLATE} {sample_input}\\n\\n{EXAMPLES}\"\n        try:\n            completion = self.openai_wrapper.get_chat_completion(prompt)\n            return completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}\\n\\n{PROMPT_ENGINEERING_TEMPLATE} {sample_input}\\n\\n{EXAMPLES}\"\n            completion = self.openai_wrapper.get_chat_completion(prompt)\n            return completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding and isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding and isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None and isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list back to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None and isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list back to ndarray\n\n        agent = MicroAgent(agent_lifecycle, openai_wrapper)\n        agent.dynamic_prompt = data.get(\"dynamic_prompt\")\n        agent.purpose = data.get(\"purpose\")\n        agent.purpose_embedding = purpose_embedding\n        agent.depth = data.get(\"depth\")\n        agent.max_depth = data.get(\"max_depth\")\n        agent.usage_count = data.get(\"usage_count\")\n        agent.id = data.get(\"id\")\n        agent.parent_id = data.get(\"parent_id\")\n        agent.working_agent = data.get(\"working_agent\")\n        agent.is_prime = data.get(\"is_prime\")\n        agent.evolve_count = data.get(\"evolve_count\")\n        agent.number_of_code_executions = data.get(\"number_of_code_executions\")\n        agent.last_input = data.get(\"last_input\")\n\n        return agent"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None:\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding and isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None:\n            purpose_embedding = np.array(purpose_embedding)  # Convert list back to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None and isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None and isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None:\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None and isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding and isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None and isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None and isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list back to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None and isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None and isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None and isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list back to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding:\n            purpose_embedding = np.array(purpose_embedding)  # Convert list back to ndarray\n\n        agent = MicroAgent(agent_lifecycle, openai_wrapper)\n        agent.dynamic_prompt = data.get(\"dynamic_prompt\")\n        agent.purpose = data.get(\"purpose\")\n        agent.purpose_embedding = purpose_embedding\n        agent.depth = data.get(\"depth\")\n        agent.max_depth = data.get(\"max_depth\")\n        agent.usage_count = data.get(\"usage_count\")\n        agent.id = data.get(\"id\")\n        agent.parent_id = data.get(\"parent_id\")\n        agent.working_agent = data.get(\"working_agent\")\n        agent.is_prime = data.get(\"is_prime\")\n        agent.evolve_count = data.get(\"evolve_count\")\n        agent.number_of_code_executions = data.get(\"number_of_code_executions\")\n        agent.last_input = data.get(\"last_input\")\n\n        return agent"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None:\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding and isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            data.get(\"dynamic_prompt\"),\n            data.get(\"purpose\"),\n            purpose_embedding,\n            data.get(\"depth\"),\n            data.get(\"max_depth\"),\n            data.get(\"usage_count\"),\n            data.get(\"id\"),\n            data.get(\"parent_id\"),\n            data.get(\"working_agent\"),\n            data.get(\"is_prime\"),\n            data.get(\"evolve_count\"),\n            data.get(\"number_of_code_executions\"),\n            data.get(\"last_input\"),\n            agent_lifecycle,\n            openai_wrapper\n        )"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"INSERT OR REPLACE INTO agents (id, purpose, data) VALUES (?, ?, ?)\",\n                           (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT id FROM agents WHERE id = ?\", (agent_dict['id'],))\n            existing_record = cursor.fetchone()\n            if existing_record:\n                conn.execute(\"UPDATE agents SET purpose = ?, data = ? WHERE id = ?\", (agent_dict['purpose'], json.dumps(agent_dict), agent_dict['id']))\n            else:\n                conn.execute(\"INSERT INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT id FROM agents WHERE id = ?\", (agent_dict['id'],))\n            row = cursor.fetchone()\n            if row:\n                conn.execute(\"UPDATE agents SET purpose = ?, data = ? WHERE id = ?\", (agent_dict['purpose'], json.dumps(agent_dict), agent_dict['id']))\n            else:\n                conn.execute(\"INSERT INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT * FROM agents WHERE id = ?\", (agent_dict['id'],))\n            row = cursor.fetchone()\n            if row:\n                conn.execute(\"UPDATE agents SET purpose = ?, data = ? WHERE id = ?\", (agent_dict['purpose'], json.dumps(agent_dict), agent_dict['id']))\n            else:\n                conn.execute(\"INSERT INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"REPLACE INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT id FROM agents WHERE id = ?\", (agent_dict['id'],))\n            existing_agent = cursor.fetchone()\n            if existing_agent:\n                conn.execute(\"UPDATE agents SET purpose = ?, data = ? WHERE id = ?\", (agent_dict['purpose'], json.dumps(agent_dict), agent_dict['id']))\n            else:\n                conn.execute(\"INSERT INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"REPLACE INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT id FROM agents WHERE id = ?\", (agent_dict['id'],))\n            row = cursor.fetchone()\n            if row:\n                conn.execute(\"UPDATE agents SET purpose = ?, data = ? WHERE id = ?\", (agent_dict['purpose'], json.dumps(agent_dict), agent_dict['id']))\n            else:\n                conn.execute(\"INSERT INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"INSERT OR REPLACE INTO agents (id, purpose, data) VALUES (?, ?, ?)\",\n                           (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT id FROM agents WHERE id = ?\", (agent_dict['id'],))\n            row = cursor.fetchone()\n            if row:\n                conn.execute(\"UPDATE agents SET purpose = ?, data = ? WHERE id = ?\", (agent_dict['purpose'], json.dumps(agent_dict), agent_dict['id']))\n            else:\n                conn.execute(\"INSERT INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT id FROM agents WHERE id = ?\", (agent_dict['id'],))\n            existing_record = cursor.fetchone()\n            if existing_record:\n                conn.execute(\"UPDATE agents SET purpose = ?, data = ? WHERE id = ?\", (agent_dict['purpose'], json.dumps(agent_dict), agent_dict['id']))\n            else:\n                conn.execute(\"INSERT INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"INSERT OR REPLACE INTO agents (id, purpose, data) VALUES (?, ?, ?)\",\n                           (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"INSERT OR REPLACE INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT id FROM agents WHERE id = ?\", (agent_dict['id'],))\n            existing_record = cursor.fetchone()\n            if existing_record:\n                conn.execute(\"UPDATE agents SET purpose = ?, data = ? WHERE id = ?\", (agent_dict['purpose'], json.dumps(agent_dict), agent_dict['id']))\n            else:\n                conn.execute(\"INSERT INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT id FROM agents WHERE id = ?\", (agent_dict['id'],))\n            existing_record = cursor.fetchone()\n            if existing_record:\n                conn.execute(\"UPDATE agents SET purpose = ?, data = ? WHERE id = ?\", (agent_dict['purpose'], json.dumps(agent_dict), agent_dict['id']))\n            else:\n                conn.execute(\"INSERT INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"INSERT OR REPLACE INTO agents (id, purpose, data) VALUES (?, ?, ?)\",\n                           (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"REPLACE INTO agents (id, purpose, data) VALUES (?, ?, ?)\",\n                           (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT id FROM agents WHERE id = ?\", (agent_dict['id'],))\n            existing_record = cursor.fetchone()\n            if existing_record:\n                conn.execute(\"UPDATE agents SET purpose = ?, data = ? WHERE id = ?\", (agent_dict['purpose'], json.dumps(agent_dict), agent_dict['id']))\n            else:\n                conn.execute(\"INSERT INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT id FROM agents WHERE id = ?\", (agent_dict['id'],))\n            existing_record = cursor.fetchone()\n            if existing_record:\n                conn.execute(\"UPDATE agents SET purpose = ?, data = ? WHERE id = ?\", (agent_dict['purpose'], json.dumps(agent_dict), agent_dict['id']))\n            else:\n                conn.execute(\"INSERT INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT id FROM agents WHERE id = ?\", (agent_dict['id'],))\n            row = cursor.fetchone()\n            if row:\n                conn.execute(\"UPDATE agents SET purpose = ?, data = ? WHERE id = ?\", (agent_dict['purpose'], json.dumps(agent_dict), agent_dict['id']))\n            else:\n                conn.execute(\"INSERT INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            purposes = [row[0] for row in rows]\n            return purposes"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = func_name.encode('utf-8') + repr(args).encode('utf-8') + repr(kwargs).encode('utf-8')\n        return hashlib.sha256(data).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        data_str = json.dumps(data, sort_keys=True)\n        return hashlib.sha256(data_str.encode()).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        hash_object = hashlib.sha256(json.dumps(data).encode())\n        return hash_object.hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        data_str = json.dumps(data, sort_keys=True)\n        return hashlib.sha256(data_str.encode()).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        data_str = json.dumps(data, sort_keys=True)\n        return hashlib.sha256(data_str.encode()).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = func_name + json.dumps(args) + json.dumps(kwargs)\n        return hashlib.sha256(data.encode('utf-8')).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        hash_input = json.dumps(data, sort_keys=True).encode('utf-8')\n        return hashlib.sha256(hash_input).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        hash_obj = hashlib.sha256(json.dumps(data).encode())\n        return hash_obj.hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        data_str = json.dumps(data, sort_keys=True)\n        return hashlib.sha256(data_str.encode()).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        data_str = json.dumps(data, sort_keys=True)\n        return hashlib.sha256(data_str.encode()).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        hash_input = func_name + json.dumps(args) + json.dumps(kwargs)\n        return hashlib.sha256(hash_input.encode()).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        hash_object = hashlib.sha256(json.dumps(data).encode())\n        return hash_object.hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = func_name + json.dumps(args) + json.dumps(kwargs)\n        return hashlib.sha256(data.encode()).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        hash_object = hashlib.sha256(json.dumps(data, sort_keys=True).encode())\n        return hash_object.hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        data_str = json.dumps(data, sort_keys=True)\n        return hashlib.sha256(data_str.encode()).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        data_str = json.dumps(data, sort_keys=True)\n        return hashlib.sha256(data_str.encode()).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        hash_input = func_name + json.dumps(args) + json.dumps(kwargs)\n        return hashlib.sha256(hash_input.encode()).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        data_str = json.dumps(data, sort_keys=True)\n        return hashlib.sha256(data_str.encode()).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        hash_data = func_name.encode('utf-8')\n        for arg in args:\n            hash_data += str(arg).encode('utf-8')\n        for key, value in kwargs.items():\n            hash_data += str(key).encode('utf-8') + str(value).encode('utf-8')\n        return hashlib.sha256(hash_data).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        data_str = json.dumps(data, sort_keys=True)\n        return hashlib.sha256(data_str.encode()).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"SELECT result FROM cache WHERE hash = ?\",\n            (arg_hash,)\n        )\n        row = cursor.fetchone()\n        if row:\n            return json.loads(row[0])\n        else:\n            return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash=?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result:\n            return json.loads(result[0])\n        else:\n            return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"SELECT result FROM cache WHERE hash = ?\",\n            (arg_hash,)\n        )\n        row = cursor.fetchone()\n        if row:\n            return json.loads(row[0])\n        return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash=?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result:\n            return json.loads(result[0])\n        else:\n            return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"SELECT result FROM cache WHERE hash = ?\",\n            (arg_hash,)\n        )\n        result = cursor.fetchone()\n        if result:\n            return json.loads(result[0])\n        else:\n            return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash = ?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result:\n            return json.loads(result[0])\n        else:\n            return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"SELECT result FROM cache WHERE hash = ?\",\n            (arg_hash,)\n        )\n        result = cursor.fetchone()\n        if result:\n            return json.loads(result[0])\n        else:\n            return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash=?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result:\n            return json.loads(result[0])\n        else:\n            return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash=?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result:\n            return json.loads(result[0])\n        else:\n            return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash=?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result:\n            return json.loads(result[0])\n        else:\n            return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"SELECT result FROM cache WHERE hash = ?\",\n            (arg_hash,)\n        )\n        row = cursor.fetchone()\n        if row:\n            return json.loads(row[0])\n        else:\n            return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash=?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result:\n            return json.loads(result[0])\n        else:\n            return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash=?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result:\n            return json.loads(result[0])\n        else:\n            return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash=?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result:\n            return json.loads(result[0])\n        else:\n            return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"SELECT result FROM cache WHERE hash = ?\",\n            (arg_hash,)\n        )\n        result = cursor.fetchone()\n        if result:\n            return json.loads(result[0])\n        else:\n            return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash=?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result:\n            return json.loads(result[0])\n        else:\n            return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash=?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result:\n            return json.loads(result[0])\n        else:\n            return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash = ?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result:\n            return json.loads(result[0])\n        else:\n            return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"SELECT result FROM cache WHERE hash = ?\",\n            (arg_hash,)\n        )\n        row = cursor.fetchone()\n        if row:\n            return json.loads(row[0])\n        else:\n            return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash = ?\", (arg_hash,))\n        row = cursor.fetchone()\n        if row:\n            return json.loads(row[0])\n        else:\n            return None"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            with SQLiteMemoization(filename) as memo:\n                return memo.fetch_or_compute(func, func_name, *args, **kwargs)\n        return wrapper\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            with SQLiteMemoization(filename) as memoization:\n                return memoization.fetch_or_compute(func, func_name, *args, **kwargs)\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            with SQLiteMemoization(filename) as memoization:\n                return memoization.fetch_or_compute(func, func_name, *args, **kwargs)\n        return wrapper\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            with SQLiteMemoization(filename) as memo:\n                return memo.fetch_or_compute(func, func_name, *args, **kwargs)\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            with SQLiteMemoization(filename) as cache:\n                return cache.fetch_or_compute(func, func_name, *args, **kwargs)\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            with SQLiteMemoization(filename) as memo:\n                return memo.fetch_or_compute(func, func_name, *args, **kwargs)\n        return wrapper\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            with SQLiteMemoization(filename) as memo:\n                return memo.fetch_or_compute(func, func_name, *args, **kwargs)\n        return wrapper\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "        def decorator(func):\n            @functools.wraps(func)\n            def wrapper(*args, **kwargs):\n                with SQLiteMemoization(filename) as memo:\n                    return memo.fetch_or_compute(func, func_name, *args, **kwargs)\n            return wrapper\n        return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            with SQLiteMemoization(filename) as memo:\n                return memo.fetch_or_compute(func, func_name, *args, **kwargs)\n        return wrapper\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            with SQLiteMemoization(filename) as memo:\n                return memo.fetch_or_compute(func, func_name, *args, **kwargs)\n        return wrapper\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            with SQLiteMemoization(filename) as memoization:\n                return memoization.fetch_or_compute(func, func_name, *args, **kwargs)\n        return wrapper\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "\n        def decorator(func):\n            @functools.wraps(func)\n            def wrapper(*args, **kwargs):\n                with SQLiteMemoization(filename) as cache:\n                    return cache.fetch_or_compute(func, func_name, *args, **kwargs)\n\n            return wrapper\n\n        return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            with SQLiteMemoization(filename) as memo:\n                return memo.fetch_or_compute(func, func_name, *args, **kwargs)\n        return wrapper\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "        def decorator(func):\n            @functools.wraps(func)\n            def wrapper(*args, **kwargs):\n                with SQLiteMemoization(filename) as memoization:\n                    return memoization.fetch_or_compute(func, func_name, *args, **kwargs)\n            return wrapper\n        return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "        def decorator(func):\n            @functools.wraps(func)\n            def wrapper(*args, **kwargs):\n                with SQLiteMemoization(filename) as memoization:\n                    return memoization.fetch_or_compute(func, func_name, *args, **kwargs)\n            return wrapper\n        return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            with SQLiteMemoization(filename) as memo:\n                return memo.fetch_or_compute(func, func_name, *args, **kwargs)\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "\n        def decorator(func):\n            @functools.wraps(func)\n            def wrapper(*args, **kwargs):\n                with SQLiteMemoization(filename) as memo:\n                    return memo.fetch_or_compute(func, func_name, *args, **kwargs)\n            return wrapper\n        return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            with SQLiteMemoization(filename) as memoization:\n                return memoization.fetch_or_compute(func, func_name, *args, **kwargs)\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "        def decorator(func):\n            @functools.wraps(func)\n            def wrapper(*args, **kwargs):\n                with SQLiteMemoization(filename) as memoization:\n                    return memoization.fetch_or_compute(func, func_name, *args, **kwargs)\n            return wrapper\n        return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "        def decorator(func):\n            @functools.wraps(func)\n            def wrapper(*args, **kwargs):\n                with SQLiteMemoization(filename) as memoizer:\n                    return memoizer.fetch_or_compute(func, func_name, *args, **kwargs)\n            return wrapper\n        return decorator"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        result_json = json.dumps(result)\n        self.connection.execute(\"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, result_json))"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        result_json = json.dumps(result)\n        self.connection.execute(\"INSERT OR REPLACE INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, result_json))"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        serialized_result = json.dumps(result)\n        self.connection.execute(\"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, serialized_result))"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        result_json = json.dumps(result)\n        self.connection.execute(\"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, result_json))"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        result_json = json.dumps(result)\n        self.connection.execute(\"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, result_json))"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        serialized_result = json.dumps(result)\n        self.connection.execute(\"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, serialized_result))"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        result_json = json.dumps(result)\n        self.connection.execute(\"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, result_json))"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        result_json = json.dumps(result)\n        self.connection.execute(\"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, result_json))"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        result_json = json.dumps(result)\n        self.connection.execute(\"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, result_json))"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        result_json = json.dumps(result)\n        self.connection.execute(\"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, result_json))"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        result_json = json.dumps(result)\n        self.connection.execute(\"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, result_json))"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        result_json = json.dumps(result)\n        self.connection.execute(\"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, result_json))"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        result_json = json.dumps(result)\n        self.connection.execute(\"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, result_json))"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        result_json = json.dumps(result)\n        self.connection.execute(\"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, result_json))"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        result_json = json.dumps(result)\n        self.connection.execute(\"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, result_json))"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, json.dumps(result)))\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        result_json = json.dumps(result)\n        self.connection.execute(\"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, result_json))"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        serialized_result = json.dumps(result)\n        self.connection.execute(\"INSERT OR REPLACE INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, serialized_result))"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        result_json = json.dumps(result)\n        self.connection.execute(\"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, result_json))"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        result_json = json.dumps(result)\n        self.connection.execute(\"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, result_json))"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    for key, value in vars(args).items():\n        if value is not None:\n            CONFIG[key.upper()] = value\n\n    # Redirect standard output to a file if quiet mode is enabled\n    if quiet_mode:\n        with open('output.log', 'w') as f:\n            with redirect_stdout(f):\n                start_command_line(vars(args))\n    else:\n        start_command_line(vars(args))"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    for key, value in vars(args).items():\n        if value is not None:\n            CONFIG[key.upper()] = value\n\n    # If quiet mode is enabled, redirect the standard output to a file\n    if quiet_mode:\n        with open(\"output.log\", \"w\") as f:\n            with redirect_stdout(f):\n                start_command_line(vars(args))\n    else:\n        start_command_line(vars(args))"}
{"namespace": "run.execute_command_line_process", "completion": "    CONFIG.update(vars(args))\n    ARGS.update(vars(args))\n\n    if quiet_mode:\n        with open(os.path.join(args.record_dir, \"output.log\"), \"w\") as f:\n            with redirect_stdout(f):\n                start_command_line(vars(args))\n    else:\n        start_command_line(vars(args))"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    for key, value in args.__dict__.items():\n        if value is not None:\n            CONFIG[key.upper()] = value\n\n    # Redirect standard output to a file if quiet mode is enabled\n    if quiet_mode:\n        with open('output.log', 'w') as f:\n            with redirect_stdout(f):\n                start_command_line(args.__dict__)\n    else:\n        start_command_line(args.__dict__)"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    for key, value in vars(args).items():\n        if value is not None:\n            CONFIG[key.upper()] = value\n\n    # Redirect standard output to a file if quiet mode is enabled\n    if quiet_mode:\n        with open('output.log', 'w') as f:\n            with redirect_stdout(f):\n                start_command_line(vars(args))\n    else:\n        start_command_line(vars(args))"}
{"namespace": "run.execute_command_line_process", "completion": "\n    # Update global configuration parameters with the provided arguments\n    CONFIG.update(vars(args))\n    ARGS.update(vars(args))\n\n    if quiet_mode:\n        # Redirect the standard output to a file if quiet mode is enabled\n        with open('output.log', 'w') as f:\n            with redirect_stdout(f):\n                start_command_line(vars(args))\n    else:\n        start_command_line(vars(args))"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    CONFIG.update(vars(args))\n    \n    # If quiet mode is enabled, redirect the standard output to a file\n    if quiet_mode:\n        with open('output.log', 'w') as f:\n            with redirect_stdout(f):\n                start_command_line(vars(args))\n    else:\n        start_command_line(vars(args))"}
{"namespace": "run.execute_command_line_process", "completion": "    CONFIG.update(vars(args))\n    ARGS.update(vars(args))\n\n    if quiet_mode:\n        with open('output.log', 'w') as f:\n            with redirect_stdout(f):\n                start_command_line(vars(args))\n    else:\n        start_command_line(vars(args))"}
{"namespace": "run.execute_command_line_process", "completion": "    CONFIG.update(vars(args))\n    ARGS.update(vars(args))\n\n    if quiet_mode:\n        with open('output.log', 'w') as f:\n            with redirect_stdout(f):\n                start_command_line(vars(args))\n    else:\n        start_command_line(vars(args))"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    CONFIG.update(vars(args))\n\n    if quiet_mode:\n        # Redirect the standard output to a file if quiet mode is enabled\n        with open('output.log', 'w') as f:\n            with redirect_stdout(f):\n                start_command_line(vars(args))\n    else:\n        start_command_line(vars(args))"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    CONFIG.update(vars(args))\n    \n    if quiet_mode:\n        # Redirect standard output to a file\n        with open('output.log', 'w') as f:\n            with redirect_stdout(f):\n                start_command_line(vars(args))\n    else:\n        start_command_line(vars(args))"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    for key, value in vars(args).items():\n        if value is not None:\n            CONFIG[key.upper()] = value\n\n    # Redirect standard output to a file if quiet mode is enabled\n    if quiet_mode:\n        with open('output.log', 'w') as f:\n            with redirect_stdout(f):\n                start_command_line(vars(args))\n    else:\n        start_command_line(vars(args))"}
{"namespace": "run.execute_command_line_process", "completion": "    CONFIG.update(vars(args))\n    ARGS.update(vars(args))\n\n    if quiet_mode:\n        with open('output.log', 'w') as f:\n            with redirect_stdout(f):\n                start_command_line(vars(args))\n    else:\n        start_command_line(vars(args))"}
{"namespace": "run.execute_command_line_process", "completion": "\n    # Update global configuration parameters\n    CONFIG.update(vars(args))\n\n    if quiet_mode:\n        with open('output.log', 'w') as f:\n            with redirect_stdout(f):\n                start_command_line(vars(args))\n    else:\n        start_command_line(vars(args))"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    for key, value in vars(args).items():\n        if value is not None:\n            CONFIG[key.upper()] = value\n\n    # Redirect standard output to a file if quiet mode is enabled\n    if quiet_mode:\n        with open('output.log', 'w') as f:\n            with redirect_stdout(f):\n                start_command_line(vars(args))\n    else:\n        start_command_line(vars(args))"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    CONFIG.update(vars(args))\n\n    if quiet_mode:\n        # Redirect standard output to a file\n        with open(\"output.log\", \"w\") as f:\n            with redirect_stdout(f):\n                start_command_line(vars(args))\n    else:\n        start_command_line(vars(args))"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    for key, value in vars(args).items():\n        if value is not None:\n            CONFIG[key.upper()] = value\n\n    if quiet_mode:\n        # Redirect standard output to a file\n        with open(os.path.join(CONFIG['RECORD_DIR'], 'output.log'), 'w') as f:\n            with redirect_stdout(f):\n                start_command_line(vars(args))\n    else:\n        start_command_line(vars(args))"}
{"namespace": "run.execute_command_line_process", "completion": "    if quiet_mode:\n        with open('output.log', 'w') as f:\n            with redirect_stdout(f):\n                update_global_config(args)\n                start_command_line(vars(args))\n    else:\n        update_global_config(args)\n        start_command_line(vars(args))"}
{"namespace": "run.execute_command_line_process", "completion": "\n    if quiet_mode:\n        with open('output.txt', 'w') as f:\n            with redirect_stdout(f):\n                CONFIG.update(vars(ARGS))\n                start_command_line(vars(ARGS))\n    else:\n        CONFIG.update(vars(ARGS))\n        start_command_line(vars(ARGS))"}
{"namespace": "run.execute_command_line_process", "completion": "    CONFIG.update(vars(args))\n    ARGS.update(vars(args))\n\n    if quiet_mode:\n        with open('output.log', 'w') as f:\n            with redirect_stdout(f):\n                start_command_line(vars(args))\n    else:\n        start_command_line(vars(args))"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "    pass\n"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "            model_name = get_model_name(\n                kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n            )\n            logger.debug(\"chatcompletion: using \" + model_name)\n            chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n            if \"azure_endpoint\" in chatcompletion_kwargs:\n                api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n                chatcompletion_kwargs.update({\"api_base\": api_base})\n            chatcompletion_kwargs.update(kwargs)\n\n            try:\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n                if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                    raise BadRequestError(\"maximum context length exceeded\", None)\n            except BadRequestError as e:\n                if \"maximum context length\" in e._message:\n                    if model_name == \"gpt-4\":\n                        if \"gpt-4-32k\" in CONFIG.api_keys:\n                            model_name = \"gpt-4-32k\"\n                        elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                            model_name = \"gpt-4-1106-preview\"\n                        else:\n                            model_name = \"gpt-3.5-turbo-16k\"\n                    elif model_name == \"gpt-3.5-turbo\":\n                        if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                            model_name = \"gpt-3.5-turbo-1106\"\n                        else:\n                            model_name = \"gpt-3.5-turbo-16k\"\n                    else:\n                        raise e\n                    print(\"max context length reached, retrying with \" + model_name)\n                    chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                    chatcompletion_kwargs.update(kwargs)\n                    chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                    response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                    response = json.loads(str(response))\n                else:\n                    raise e\n\n            return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "\n        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise InvalidRequestError(\"maximum context length exceeded\", None)\n        except InvalidRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "            model_name = get_model_name(\n                kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n            )\n            logger.debug(\"chatcompletion: using \" + model_name)\n            chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n            if \"azure_endpoint\" in chatcompletion_kwargs:\n                api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n                chatcompletion_kwargs.update({\"api_base\": api_base})\n            chatcompletion_kwargs.update(kwargs)\n\n            try:\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n                if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                    raise InvalidRequestError(\"maximum context length exceeded\", None)\n            except InvalidRequestError as e:\n                if \"maximum context length\" in e._message:\n                    if model_name == \"gpt-4\":\n                        if \"gpt-4-32k\" in CONFIG.api_keys:\n                            model_name = \"gpt-4-32k\"\n                        elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                            model_name = \"gpt-4-1106-preview\"\n                        else:\n                            model_name = \"gpt-3.5-turbo-16k\"\n                    elif model_name == \"gpt-3.5-turbo\":\n                        if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                            model_name = \"gpt-3.5-turbo-1106\"\n                        else:\n                            model_name = \"gpt-3.5-turbo-16k\"\n                    else:\n                        raise e\n                    print(\"max context length reached, retrying with \" + model_name)\n                    chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                    chatcompletion_kwargs.update(kwargs)\n                    chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                    response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                    response = json.loads(str(response))\n                else:\n                    raise e\n\n            return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "            model_name = get_model_name(\n                kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n            )\n            logger.debug(\"chatcompletion: using \" + model_name)\n            chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n            if \"azure_endpoint\" in chatcompletion_kwargs:\n                api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n                chatcompletion_kwargs.update({\"api_base\": api_base})\n            chatcompletion_kwargs.update(kwargs)\n\n            try:\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n                if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                    raise InvalidRequestError(\"maximum context length exceeded\", None)\n            except InvalidRequestError as e:\n                if \"maximum context length\" in e._message:\n                    if model_name == \"gpt-4\":\n                        if \"gpt-4-32k\" in CONFIG.api_keys:\n                            model_name = \"gpt-4-32k\"\n                        elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                            model_name = \"gpt-4-1106-preview\"\n                        else:\n                            model_name = \"gpt-3.5-turbo-16k\"\n                    elif model_name == \"gpt-3.5-turbo\":\n                        if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                            model_name = \"gpt-3.5-turbo-1106\"\n                        else:\n                            model_name = \"gpt-3.5-turbo-16k\"\n                    else:\n                        raise e\n                    print(\"max context length reached, retrying with \" + model_name)\n                    chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                    chatcompletion_kwargs.update(kwargs)\n                    chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                    response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                    response = json.loads(str(response))\n                else:\n                    raise e\n\n            return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "    pass\n"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "    model_name = get_model_name(\n        kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n    )\n    logger.debug(\"chatcompletion: using \" + model_name)\n    chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n    if \"azure_endpoint\" in chatcompletion_kwargs:\n        api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n        chatcompletion_kwargs.update({\"api_base\": api_base})\n    chatcompletion_kwargs.update(kwargs)\n\n    try:\n        response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n        response = json.loads(str(response))\n        if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n            raise BadRequestError(\"maximum context length exceeded\", None)\n    except BadRequestError as e:\n        if \"maximum context length\" in e._message:\n            if model_name == \"gpt-4\":\n                if \"gpt-4-32k\" in CONFIG.api_keys:\n                    model_name = \"gpt-4-32k\"\n                elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                    model_name = \"gpt-4-1106-preview\"\n                else:\n                    model_name = \"gpt-3.5-turbo-16k\"\n            elif model_name == \"gpt-3.5-turbo\":\n                if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                    model_name = \"gpt-3.5-turbo-1106\"\n                else:\n                    model_name = \"gpt-3.5-turbo-16k\"\n            else:\n                raise e\n            print(\"max context length reached, retrying with \" + model_name)\n            chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n            chatcompletion_kwargs.update(kwargs)\n            chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n        else:\n            raise e\n\n    return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "    model_name = get_model_name(\n        kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n    )\n    logger.debug(\"chatcompletion: using \" + model_name)\n    chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n    if \"azure_endpoint\" in chatcompletion_kwargs:\n        api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n        chatcompletion_kwargs.update({\"api_base\": api_base})\n    chatcompletion_kwargs.update(kwargs)\n\n    try:\n        response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n        response = json.loads(str(response))\n        if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n            raise BadRequestError(\"maximum context length exceeded\", None)\n    except BadRequestError as e:\n        if \"maximum context length\" in e._message:\n            if model_name == \"gpt-4\":\n                if \"gpt-4-32k\" in CONFIG.api_keys:\n                    model_name = \"gpt-4-32k\"\n                elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                    model_name = \"gpt-4-1106-preview\"\n                else:\n                    model_name = \"gpt-3.5-turbo-16k\"\n            elif model_name == \"gpt-3.5-turbo\":\n                if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                    model_name = \"gpt-3.5-turbo-1106\"\n                else:\n                    model_name = \"gpt-3.5-turbo-16k\"\n            else:\n                raise e\n            print(\"max context length reached, retrying with \" + model_name)\n            chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n            chatcompletion_kwargs.update(kwargs)\n            chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n        else:\n            raise e\n\n    return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "    pass\n"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "            model_name = get_model_name(\n                kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n            )\n            logger.debug(\"chatcompletion: using \" + model_name)\n            chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n            if \"azure_endpoint\" in chatcompletion_kwargs:\n                api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n                chatcompletion_kwargs.update({\"api_base\": api_base})\n            chatcompletion_kwargs.update(kwargs)\n\n            try:\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n                if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                    raise InvalidRequestError(\"maximum context length exceeded\", None)\n            except InvalidRequestError as e:\n                if \"maximum context length\" in e._message:\n                    if model_name == \"gpt-4\":\n                        if \"gpt-4-32k\" in CONFIG.api_keys:\n                            model_name = \"gpt-4-32k\"\n                        elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                            model_name = \"gpt-4-1106-preview\"\n                        else:\n                            model_name = \"gpt-3.5-turbo-16k\"\n                    elif model_name == \"gpt-3.5-turbo\":\n                        if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                            model_name = \"gpt-3.5-turbo-1106\"\n                        else:\n                            model_name = \"gpt-3.5-turbo-16k\"\n                    else:\n                        raise e\n                    print(\"max context length reached, retrying with \" + model_name)\n                    chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                    chatcompletion_kwargs.update(kwargs)\n                    chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                    response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                    response = json.loads(str(response))\n                else:\n                    raise e\n\n            return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "            model_name = get_model_name(\n                kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n            )\n            logger.debug(\"chatcompletion: using \" + model_name)\n            chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n            if \"azure_endpoint\" in chatcompletion_kwargs:\n                api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n                chatcompletion_kwargs.update({\"api_base\": api_base})\n            chatcompletion_kwargs.update(kwargs)\n\n            try:\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n                if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                    raise BadRequestError(\"maximum context length exceeded\", None)\n            except BadRequestError as e:\n                if \"maximum context length\" in e._message:\n                    if model_name == \"gpt-4\":\n                        if \"gpt-4-32k\" in CONFIG.api_keys:\n                            model_name = \"gpt-4-32k\"\n                        elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                            model_name = \"gpt-4-1106-preview\"\n                        else:\n                            model_name = \"gpt-3.5-turbo-16k\"\n                    elif model_name == \"gpt-3.5-turbo\":\n                        if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                            model_name = \"gpt-3.5-turbo-1106\"\n                        else:\n                            model_name = \"gpt-3.5-turbo-16k\"\n                    else:\n                        raise e\n                    print(\"max context length reached, retrying with \" + model_name)\n                    chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                    chatcompletion_kwargs.update(kwargs)\n                    chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                    response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                    response = json.loads(str(response))\n                else:\n                    raise e\n\n            return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "            model_name = get_model_name(\n                kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n            )\n            logger.debug(\"chatcompletion: using \" + model_name)\n            chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n            if \"azure_endpoint\" in chatcompletion_kwargs:\n                api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n                chatcompletion_kwargs.update({\"api_base\": api_base})\n            chatcompletion_kwargs.update(kwargs)\n\n            try:\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n                if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                    raise BadRequestError(\"maximum context length exceeded\", None)\n            except BadRequestError as e:\n                if \"maximum context length\" in e._message:\n                    if model_name == \"gpt-4\":\n                        if \"gpt-4-32k\" in CONFIG.api_keys:\n                            model_name = \"gpt-4-32k\"\n                        elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                            model_name = \"gpt-4-1106-preview\"\n                        else:\n                            model_name = \"gpt-3.5-turbo-16k\"\n                    elif model_name == \"gpt-3.5-turbo\":\n                        if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                            model_name = \"gpt-3.5-turbo-1106\"\n                        else:\n                            model_name = \"gpt-3.5-turbo-16k\"\n                    else:\n                        raise e\n                    print(\"max context length reached, retrying with \" + model_name)\n                    chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                    chatcompletion_kwargs.update(kwargs)\n                    chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                    response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                    response = json.loads(str(response))\n                else:\n                    raise e\n\n            return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "            model_name = get_model_name(\n                kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n            )\n            logger.debug(\"chatcompletion: using \" + model_name)\n            chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n            if \"azure_endpoint\" in chatcompletion_kwargs:\n                api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n                chatcompletion_kwargs.update({\"api_base\": api_base})\n            chatcompletion_kwargs.update(kwargs)\n\n            try:\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n                if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                    raise BadRequestError(\"maximum context length exceeded\", None)\n            except BadRequestError as e:\n                if \"maximum context length\" in e._message:\n                    if model_name == \"gpt-4\":\n                        if \"gpt-4-32k\" in CONFIG.api_keys:\n                            model_name = \"gpt-4-32k\"\n                        elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                            model_name = \"gpt-4-1106-preview\"\n                        else:\n                            model_name = \"gpt-3.5-turbo-16k\"\n                    elif model_name == \"gpt-3.5-turbo\":\n                        if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                            model_name = \"gpt-3.5-turbo-1106\"\n                        else:\n                            model_name = \"gpt-3.5-turbo-16k\"\n                    else:\n                        raise e\n                    print(\"max context length reached, retrying with \" + model_name)\n                    chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                    chatcompletion_kwargs.update(kwargs)\n                    chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                    response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                    response = json.loads(str(response))\n                else:\n                    raise e\n\n            return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "    model_name = get_model_name(\n        kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n    )\n    logger.debug(\"chatcompletion: using \" + model_name)\n    chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n    if \"azure_endpoint\" in chatcompletion_kwargs:\n        api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n        chatcompletion_kwargs.update({\"api_base\": api_base})\n    chatcompletion_kwargs.update(kwargs)\n\n    try:\n        response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n        response = json.loads(str(response))\n        if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n            raise BadRequestError(\"maximum context length exceeded\", None)\n    except BadRequestError as e:\n        if \"maximum context length\" in e._message:\n            if model_name == \"gpt-4\":\n                if \"gpt-4-32k\" in CONFIG.api_keys:\n                    model_name = \"gpt-4-32k\"\n                elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                    model_name = \"gpt-4-1106-preview\"\n                else:\n                    model_name = \"gpt-3.5-turbo-16k\"\n            elif model_name == \"gpt-3.5-turbo\":\n                if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                    model_name = \"gpt-3.5-turbo-1106\"\n                else:\n                    model_name = \"gpt-3.5-turbo-16k\"\n            else:\n                raise e\n            print(\"max context length reached, retrying with \" + model_name)\n            chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n            chatcompletion_kwargs.update(kwargs)\n            chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n        else:\n            raise e\n\n    return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "            model_name = get_model_name(\n                kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n            )\n            logger.debug(\"chatcompletion: using \" + model_name)\n            chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n            if \"azure_endpoint\" in chatcompletion_kwargs:\n                api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n                chatcompletion_kwargs.update({\"api_base\": api_base})\n            chatcompletion_kwargs.update(kwargs)\n\n            try:\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n                if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                    raise BadRequestError(\"maximum context length exceeded\", None)\n            except BadRequestError as e:\n                if \"maximum context length\" in e._message:\n                    if model_name == \"gpt-4\":\n                        if \"gpt-4-32k\" in CONFIG.api_keys:\n                            model_name = \"gpt-4-32k\"\n                        elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                            model_name = \"gpt-4-1106-preview\"\n                        else:\n                            model_name = \"gpt-3.5-turbo-16k\"\n                    elif model_name == \"gpt-3.5-turbo\":\n                        if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                            model_name = \"gpt-3.5-turbo-1106\"\n                        else:\n                            model_name = \"gpt-3.5-turbo-16k\"\n                    else:\n                        raise e\n                    print(\"max context length reached, retrying with \" + model_name)\n                    chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                    chatcompletion_kwargs.update(kwargs)\n                    chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                    response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                    response = json.loads(str(response))\n                else:\n                    raise e\n\n            return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise InvalidRequestError(\"maximum context length exceeded\", None)\n        except InvalidRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "            model_name = get_model_name(\n                kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n            )\n            logger.debug(\"chatcompletion: using \" + model_name)\n            chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n            if \"azure_endpoint\" in chatcompletion_kwargs:\n                api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n                chatcompletion_kwargs.update({\"api_base\": api_base})\n            chatcompletion_kwargs.update(kwargs)\n\n            try:\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n                if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                    raise BadRequestError(\"maximum context length exceeded\", None)\n            except BadRequestError as e:\n                if \"maximum context length\" in e._message:\n                    if model_name == \"gpt-4\":\n                        if \"gpt-4-32k\" in CONFIG.api_keys:\n                            model_name = \"gpt-4-32k\"\n                        elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                            model_name = \"gpt-4-1106-preview\"\n                        else:\n                            model_name = \"gpt-3.5-turbo-16k\"\n                    elif model_name == \"gpt-3.5-turbo\":\n                        if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                            model_name = \"gpt-3.5-turbo-1106\"\n                        else:\n                            model_name = \"gpt-3.5-turbo-16k\"\n                    else:\n                        raise e\n                    print(\"max context length reached, retrying with \" + model_name)\n                    chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                    chatcompletion_kwargs.update(kwargs)\n                    chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                    response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                    response = json.loads(str(response))\n                else:\n                    raise e\n\n            return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "            model_name = get_model_name(\n                kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n            )\n            logger.debug(\"chatcompletion: using \" + model_name)\n            chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n            if \"azure_endpoint\" in chatcompletion_kwargs:\n                api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n                chatcompletion_kwargs.update({\"api_base\": api_base})\n            chatcompletion_kwargs.update(kwargs)\n\n            try:\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n                if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                    raise BadRequestError(\"maximum context length exceeded\", None)\n            except BadRequestError as e:\n                if \"maximum context length\" in e._message:\n                    if model_name == \"gpt-4\":\n                        if \"gpt-4-32k\" in CONFIG.api_keys:\n                            model_name = \"gpt-4-32k\"\n                        elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                            model_name = \"gpt-4-1106-preview\"\n                        else:\n                            model_name = \"gpt-3.5-turbo-16k\"\n                    elif model_name == \"gpt-3.5-turbo\":\n                        if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                            model_name = \"gpt-3.5-turbo-1106\"\n                        else:\n                            model_name = \"gpt-3.5-turbo-16k\"\n                    else:\n                        raise e\n                    print(\"max context length reached, retrying with \" + model_name)\n                    chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                    chatcompletion_kwargs.update(kwargs)\n                    chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                    response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                    response = json.loads(str(response))\n                else:\n                    raise e\n\n            return response"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        current_time = time()\n        if self._client is None or self._last_time is None or current_time - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = current_time\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (self._last_time is not None and time() - self._last_time > self._refetch_interval):\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (self._last_time is not None and time() - self._last_time > self._refetch_interval):\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        current_time = time()\n        if self._client is None or self._last_time is None or current_time - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = current_time\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        current_time = time()\n        if self._client is None or self._last_time is None or current_time - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = current_time\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        current_time = time()\n        if self._client is None or self._last_time is None or current_time - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = current_time\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (self._last_time is not None and time() - self._last_time > self._refetch_interval):\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        current_time = time()\n        if self._client is None or self._last_time is None or (current_time - self._last_time) > self._refetch_interval:\n            self._create_client()\n            self._last_time = current_time\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        current_time = time()\n        if self._client is None or self._last_time is None or current_time - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = current_time\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        current_time = time()\n        if self._client is None or self._last_time is None or current_time - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = current_time\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (self._last_time is not None and time() - self._last_time > self._refetch_interval):\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        current_time = time()\n        if self._client is None or self._last_time is None or current_time - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = current_time\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        current_time = time()\n        if self._client is None or self._last_time is None or current_time - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = current_time\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        current_time = time()\n        if self._client is None or (self._last_time is not None and current_time - self._last_time > self._refetch_interval):\n            self._create_client()\n            self._last_time = current_time\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (self._last_time is not None and time() - self._last_time > self._refetch_interval):\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        current_time = time()\n        if self._client is None or self._last_time is None or current_time - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = current_time\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        current_time = time()\n        if self._client is None or self._last_time is None or current_time - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = current_time\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        current_time = time()\n        if self._client is None or self._last_time is None or current_time - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = current_time\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        current_time = time()\n        if self._client is None or self._last_time is None or current_time - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = current_time\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (self._last_time is not None and time() - self._last_time > self._refetch_interval):\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict() should be called from the main process, not a DataLoader worker\")\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"shuffle\": self.shuffle,\n            \"seed\": self.seed,\n            \"drop_last\": self.drop_last,\n            \"distributed_env\": {\n                \"world_size\": self.distributed_env.world_size,\n                \"global_rank\": self.distributed_env.global_rank,\n            },\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None\n        }\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"shuffle\": self.shuffle,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size if self.distributed_env else 1,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None\n        }\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict() should not be called from a DataLoader worker process.\")\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"shuffle\": self.shuffle,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"seed\": self.seed,\n            \"drop_last\": self.drop_last,\n            \"world_size\": self.distributed_env.world_size,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None\n        }\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict() should be called outside of the DataLoader worker process.\")\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"shuffle\": self.shuffle,\n            \"seed\": self.seed,\n            \"drop_last\": self.drop_last,\n            \"distributed_env\": {\n                \"world_size\": self.distributed_env.world_size,\n                \"global_rank\": self.distributed_env.global_rank,\n            },\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None,\n        }\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict() should not be called from a DataLoader worker process.\")\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"shuffle\": self.shuffle,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"distributed_env\": self.distributed_env.state_dict(),\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None\n        }\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict() should be called outside of the DataLoader worker process\")\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"shuffle\": self.shuffle,\n            \"world_size\": self.distributed_env.world_size\n        }\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict() should not be called from a DataLoader worker process\")\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"shuffle\": self.shuffle,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader\": None if self.item_loader is None else self.item_loader.state_dict(),\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n        }\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict() should not be called from a DataLoader worker process.\")\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"shuffle\": self.shuffle,\n            \"world_size\": self.distributed_env.world_size\n        }\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict() should not be called from a DataLoader worker process.\")\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"shuffle\": self.shuffle,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n        }\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The `state_dict` method cannot be called from a DataLoader worker process. \"\n                \"Please call it from the main process.\"\n            )\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader\": None if self.item_loader is None else self.item_loader.state_dict(),\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"shuffle\": self.shuffle,\n            \"world_size\": self.distributed_env.world_size,\n        }\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "\n        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict can only be called from the main process, not worker processes\")\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"shuffle\": self.shuffle,\n        }\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict() should not be called from a DataLoader worker process\")\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"shuffle\": self.shuffle,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n        }\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"shuffle\": self.shuffle,\n            \"world_size\": self.distributed_env.world_size\n        }\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict() should not be called from a DataLoader worker process\")\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"shuffle\": self.shuffle,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n        }\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"shuffle\": self.shuffle,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n        }\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "\n        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict() should not be called from a DataLoader worker process.\")\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"shuffle\": self.shuffle,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n        }\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"shuffle\": self.shuffle,\n            \"world_size\": self.distributed_env.world_size\n        }\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict() should be called outside of the DataLoader worker process.\")\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"shuffle\": self.shuffle,\n            \"world_size\": self.distributed_env.world_size,\n        }\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"shuffle\": self.shuffle,\n            \"world_size\": self.distributed_env.world_size\n        }\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict should not be called from a DataLoader worker process.\")\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"shuffle\": self.shuffle,\n            \"world_size\": self.distributed_env.world_size\n        }\n\n        return state_dict"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "\n        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.W, camera.H)\n\n        # Perform the rendering using the camera's settings\n        self.render(camera)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "\n        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.W, camera.H)\n\n        # Render the Mesh instance using the camera's settings\n        self.render(camera)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "\n        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.W, camera.H)\n\n        # Render the Mesh instance using the camera's settings\n        self.render(camera)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "\n        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.W, camera.H)\n\n        # Render the Mesh instance using the camera's settings\n        self.render(camera)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "\n        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize_context(camera.W, camera.H)\n\n        # Perform the rendering of the Mesh instance using the camera's settings\n        self.render(camera)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "\n        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.W, camera.H)\n\n        # Perform rendering of the Mesh instance using the camera's settings\n        self.render(camera)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.W, camera.H)\n\n        # Perform offscreen rendering\n        self.render(camera)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "\n        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.W, camera.H)\n\n        # Perform offscreen rendering of the Mesh instance using the specified camera configuration\n        self.render(camera)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "\n        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.W, camera.H)\n\n        # Perform rendering using the camera's settings\n        self.render(camera)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "\n        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.W, camera.H)\n\n        # Perform rendering of the Mesh instance using the camera's settings\n        self.render(camera)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "\n        # Resize the rendering context to match the camera's width and height\n        eglctx.resize_context(camera.W, camera.H)\n\n        # Render the Mesh instance using the camera's settings\n        self.render(camera)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.W, camera.H)\n\n        # Perform the rendering of the Mesh instance using the camera's settings\n        self.render(camera)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "\n        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.W, camera.H)\n\n        # Render the Mesh instance using the camera's settings\n        self.render(camera)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "\n        # Resize the rendering context to match the camera's width and height\n        eglctx.resize_context(camera.W, camera.H)\n\n        # Render the Mesh instance using the camera's settings\n        self.render(camera)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        eglctx.resize(camera.W, camera.H)\n        eglctx.make_current()\n        gl.glClearColor(0.0, 0.0, 0.0, 1.0)\n        gl.glClear(gl.GL_COLOR_BUFFER_BIT | gl.GL_DEPTH_BUFFER_BIT)\n        self.render(camera)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.W, camera.H)\n\n        # Perform the rendering of the Mesh instance using the camera's settings\n        self.render(camera)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "\n        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.W, camera.H)\n\n        # Perform the rendering of the Mesh instance using the camera's settings\n        self.render(camera)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.W, camera.H)\n\n        # Render the Mesh instance using the camera's settings\n        self.render(camera)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        eglctx.resize(camera.W, camera.H)\n        eglctx.make_current()\n        self.render(camera)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "\n        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.W, camera.H)\n\n        # Render the Mesh instance using the camera's settings\n        self.render(camera)"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "\n    return NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        n_embd=bert_config.hidden_size,\n        n_layer=bert_config.num_hidden_layers,\n        n_head=bert_config.num_attention_heads,\n        n_inner=bert_config.intermediate_size,\n        activation_function=bert_config.hidden_act,\n        resid_pdrop=bert_config.hidden_dropout_prob,\n        attn_pdrop=bert_config.attention_probs_dropout_prob,\n        n_positions=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_epsilon=bert_config.layer_norm_eps,\n        # Additional attributes specific to NomicBertConfig\n        last_layer_subset=False,\n        pad_vocab_size_multiple=1,\n        orig_vocab_size=bert_config.vocab_size,\n    )"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    return NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        n_embd=bert_config.hidden_size,\n        n_layer=bert_config.num_hidden_layers,\n        n_head=bert_config.num_attention_heads,\n        n_inner=bert_config.intermediate_size,\n        activation_function=bert_config.hidden_act,\n        resid_pdrop=bert_config.hidden_dropout_prob,\n        attn_pdrop=bert_config.attention_probs_dropout_prob,\n        n_positions=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_epsilon=bert_config.layer_norm_eps,\n        # Additional attributes specific to NomicBertConfig\n        last_layer_subset=False,\n        pad_vocab_size_multiple=1,\n        orig_vocab_size=bert_config.vocab_size,\n    )"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    return NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        n_embd=bert_config.hidden_size,\n        n_layer=bert_config.num_hidden_layers,\n        n_head=bert_config.num_attention_heads,\n        n_inner=bert_config.intermediate_size,\n        activation_function=bert_config.hidden_act,\n        resid_pdrop=bert_config.hidden_dropout_prob,\n        attn_pdrop=bert_config.attention_probs_dropout_prob,\n        n_positions=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_epsilon=bert_config.layer_norm_eps,\n        # Additional attributes specific to NomicBertConfig\n        last_layer_subset=False,  # Example default value, replace with actual value\n        pad_vocab_size_multiple=1,  # Example default value, replace with actual value\n    )"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "\n    return NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        n_embd=bert_config.hidden_size,\n        n_layer=bert_config.num_hidden_layers,\n        n_head=bert_config.num_attention_heads,\n        n_inner=bert_config.intermediate_size,\n        activation_function=bert_config.hidden_act,\n        resid_pdrop=bert_config.hidden_dropout_prob,\n        attn_pdrop=bert_config.attention_probs_dropout_prob,\n        n_positions=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_epsilon=bert_config.layer_norm_eps,\n        # Additional attributes specific to NomicBertConfig\n        last_layer_subset=False,\n        orig_vocab_size=bert_config.vocab_size,\n        pad_vocab_size_multiple=1,\n    )"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    return NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        n_embd=bert_config.hidden_size,\n        n_layer=bert_config.num_hidden_layers,\n        n_head=bert_config.num_attention_heads,\n        n_inner=bert_config.intermediate_size,\n        activation_function=bert_config.hidden_act,\n        resid_pdrop=bert_config.hidden_dropout_prob,\n        attn_pdrop=bert_config.attention_probs_dropout_prob,\n        n_positions=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_epsilon=bert_config.layer_norm_eps,\n        # Additional attributes specific to NomicBertConfig\n        last_layer_subset=False,\n        pad_vocab_size_multiple=1,\n        orig_vocab_size=bert_config.vocab_size,\n    )"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "\n    return NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        n_embd=bert_config.hidden_size,\n        n_layer=bert_config.num_hidden_layers,\n        n_head=bert_config.num_attention_heads,\n        n_inner=bert_config.intermediate_size,\n        activation_function=bert_config.hidden_act,\n        resid_pdrop=bert_config.hidden_dropout_prob,\n        attn_pdrop=bert_config.attention_probs_dropout_prob,\n        n_positions=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_epsilon=bert_config.layer_norm_eps,\n        # Additional attributes specific to NomicBertConfig\n        last_layer_subset=False,\n        pad_vocab_size_multiple=1,\n        orig_vocab_size=bert_config.vocab_size,\n    )"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    return NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        n_embd=bert_config.hidden_size,\n        n_layer=bert_config.num_hidden_layers,\n        n_head=bert_config.num_attention_heads,\n        n_inner=bert_config.intermediate_size,\n        activation_function=bert_config.hidden_act,\n        resid_pdrop=bert_config.hidden_dropout_prob,\n        attn_pdrop=bert_config.attention_probs_dropout_prob,\n        n_positions=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_epsilon=bert_config.layer_norm_eps,\n        last_layer_subset=False  # This is a new attribute specific to NomicBertConfig\n    )"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    return NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        n_embd=bert_config.hidden_size,\n        n_layer=bert_config.num_hidden_layers,\n        n_head=bert_config.num_attention_heads,\n        n_inner=bert_config.intermediate_size,\n        activation_function=bert_config.hidden_act,\n        resid_pdrop=bert_config.hidden_dropout_prob,\n        attn_pdrop=bert_config.attention_probs_dropout_prob,\n        n_positions=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_epsilon=bert_config.layer_norm_eps,\n        # Add additional attributes specific to NomicBertConfig\n        last_layer_subset=False,  # Example of additional attribute\n        pad_vocab_size_multiple=1,  # Example of additional attribute\n    )"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    return NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        n_embd=bert_config.hidden_size,\n        n_layer=bert_config.num_hidden_layers,\n        n_head=bert_config.num_attention_heads,\n        n_inner=bert_config.intermediate_size,\n        activation_function=bert_config.hidden_act,\n        resid_pdrop=bert_config.hidden_dropout_prob,\n        attn_pdrop=bert_config.attention_probs_dropout_prob,\n        n_positions=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_epsilon=bert_config.layer_norm_eps,\n        # Additional attributes specific to NomicBertConfig\n        last_layer_subset=False,  # Example value, replace with appropriate default\n        pad_vocab_size_multiple=1,  # Example value, replace with appropriate default\n        orig_vocab_size=bert_config.vocab_size,  # Example value, replace with appropriate default\n    )"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "\n    return NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        n_embd=bert_config.hidden_size,\n        n_layer=bert_config.num_hidden_layers,\n        n_head=bert_config.num_attention_heads,\n        n_inner=bert_config.intermediate_size,\n        activation_function=bert_config.hidden_act,\n        resid_pdrop=bert_config.hidden_dropout_prob,\n        attn_pdrop=bert_config.attention_probs_dropout_prob,\n        n_positions=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_epsilon=bert_config.layer_norm_eps,\n        last_layer_subset=False,  # Set to default value\n        orig_vocab_size=bert_config.vocab_size,  # Set to default value\n        pad_vocab_size_multiple=1,  # Set to default value\n    )"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    return NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        n_embd=bert_config.hidden_size,\n        n_layer=bert_config.num_hidden_layers,\n        n_head=bert_config.num_attention_heads,\n        n_inner=bert_config.intermediate_size,\n        activation_function=bert_config.hidden_act,\n        resid_pdrop=bert_config.hidden_dropout_prob,\n        attn_pdrop=bert_config.attention_probs_dropout_prob,\n        n_positions=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_epsilon=bert_config.layer_norm_eps,\n        # Additional attributes specific to NomicBertConfig\n        last_layer_subset=False,\n        pad_vocab_size_multiple=1,\n        orig_vocab_size=bert_config.vocab_size,\n    )"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    return NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        n_embd=bert_config.hidden_size,\n        n_layer=bert_config.num_hidden_layers,\n        n_head=bert_config.num_attention_heads,\n        n_inner=bert_config.intermediate_size,\n        activation_function=bert_config.hidden_act,\n        resid_pdrop=bert_config.hidden_dropout_prob,\n        attn_pdrop=bert_config.attention_probs_dropout_prob,\n        n_positions=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_epsilon=bert_config.layer_norm_eps,\n        # Additional attributes specific to NomicBertConfig\n        last_layer_subset=False,\n        pad_vocab_size_multiple=1,\n        orig_vocab_size=bert_config.vocab_size,\n    )"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    return NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        n_embd=bert_config.hidden_size,\n        n_layer=bert_config.num_hidden_layers,\n        n_head=bert_config.num_attention_heads,\n        n_inner=bert_config.intermediate_size,\n        activation_function=bert_config.hidden_act,\n        resid_pdrop=bert_config.hidden_dropout_prob,\n        attn_pdrop=bert_config.attention_probs_dropout_prob,\n        n_positions=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_epsilon=bert_config.layer_norm_eps,\n        # Additional attributes specific to NomicBertConfig\n        last_layer_subset=False,\n        pad_vocab_size_multiple=1,\n        orig_vocab_size=bert_config.vocab_size,\n    )"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "\n    return NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        n_embd=bert_config.hidden_size,\n        n_layer=bert_config.num_hidden_layers,\n        n_head=bert_config.num_attention_heads,\n        n_inner=bert_config.intermediate_size,\n        activation_function=bert_config.hidden_act,\n        resid_pdrop=bert_config.hidden_dropout_prob,\n        attn_pdrop=bert_config.attention_probs_dropout_prob,\n        n_positions=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_epsilon=bert_config.layer_norm_eps,\n        # Additional attributes specific to NomicBertConfig\n        last_layer_subset=False,  # Example value, replace with actual value\n        pad_vocab_size_multiple=1,  # Example value, replace with actual value\n    )"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "\n    return NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        n_embd=bert_config.hidden_size,\n        n_layer=bert_config.num_hidden_layers,\n        n_head=bert_config.num_attention_heads,\n        n_inner=bert_config.intermediate_size,\n        activation_function=bert_config.hidden_act,\n        resid_pdrop=bert_config.hidden_dropout_prob,\n        attn_pdrop=bert_config.attention_probs_dropout_prob,\n        n_positions=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_epsilon=bert_config.layer_norm_eps,\n        # Additional attributes specific to NomicBertConfig\n        last_layer_subset=False,\n        pad_vocab_size_multiple=1,\n        orig_vocab_size=bert_config.vocab_size,\n    )"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "\n    return NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        n_embd=bert_config.hidden_size,\n        n_layer=bert_config.num_hidden_layers,\n        n_head=bert_config.num_attention_heads,\n        n_inner=bert_config.intermediate_size,\n        activation_function=bert_config.hidden_act,\n        resid_pdrop=bert_config.hidden_dropout_prob,\n        attn_pdrop=bert_config.attention_probs_dropout_prob,\n        n_positions=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_epsilon=bert_config.layer_norm_eps,\n        # Additional attributes specific to NomicBertConfig\n        last_layer_subset=False,\n        orig_vocab_size=bert_config.vocab_size,\n        pad_vocab_size_multiple=1,\n    )"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    return NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        n_embd=bert_config.hidden_size,\n        n_layer=bert_config.num_hidden_layers,\n        n_head=bert_config.num_attention_heads,\n        n_inner=bert_config.intermediate_size,\n        activation_function=bert_config.hidden_act,\n        resid_pdrop=bert_config.hidden_dropout_prob,\n        attn_pdrop=bert_config.attention_probs_dropout_prob,\n        n_positions=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_epsilon=bert_config.layer_norm_eps\n    )"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    return NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        n_embd=bert_config.hidden_size,\n        n_layer=bert_config.num_hidden_layers,\n        n_head=bert_config.num_attention_heads,\n        n_inner=bert_config.intermediate_size,\n        activation_function=bert_config.hidden_act,\n        resid_pdrop=bert_config.hidden_dropout_prob,\n        attn_pdrop=bert_config.attention_probs_dropout_prob,\n        n_positions=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_epsilon=bert_config.layer_norm_eps,\n        # Additional attributes specific to NomicBertConfig\n        last_layer_subset=False,\n        pad_vocab_size_multiple=1,\n        orig_vocab_size=bert_config.vocab_size\n    )"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "\n    return NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        n_embd=bert_config.hidden_size,\n        n_layer=bert_config.num_hidden_layers,\n        n_head=bert_config.num_attention_heads,\n        n_inner=bert_config.intermediate_size,\n        activation_function=bert_config.hidden_act,\n        resid_pdrop=bert_config.hidden_dropout_prob,\n        attn_pdrop=bert_config.attention_probs_dropout_prob,\n        n_positions=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_epsilon=bert_config.layer_norm_eps,\n        # Additional attributes specific to NomicBertConfig\n        last_layer_subset=False,\n        pad_vocab_size_multiple=1,\n        orig_vocab_size=bert_config.vocab_size,\n        add_pooling_layer=True\n    )"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    return NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        n_embd=bert_config.hidden_size,\n        n_layer=bert_config.num_hidden_layers,\n        n_head=bert_config.num_attention_heads,\n        n_inner=bert_config.intermediate_size,\n        activation_function=bert_config.hidden_act,\n        resid_pdrop=bert_config.hidden_dropout_prob,\n        attn_pdrop=bert_config.attention_probs_dropout_prob,\n        n_positions=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_epsilon=bert_config.layer_norm_eps,\n        # Add new attributes specific to NomicBertConfig\n        last_layer_subset=False,\n        pad_vocab_size_multiple=1,\n        orig_vocab_size=bert_config.vocab_size,\n        add_pooling_layer=False\n    )"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        self.upload_gl_uniforms(camera)\n\n        gl.glBindVertexArray(self.vao)\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_LINES, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_QUADS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            if hasattr(self, 'faces'):"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "\n        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        self.upload_gl_uniforms(camera)\n\n        gl.glBindVertexArray(self.vao)\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_QUADS, 0, len(self.verts))\n        elif self.render_type == Mesh"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            self.use_gl_program(self.point_program)\n            self.upload_gl_uniforms(camera)\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n            gl.glBindVertexArray(0)\n        else:\n            self.use_gl_program(self.mesh_program)\n            self.upload_gl_uniforms(camera)\n            gl.glBindVertexArray(self.vao)\n            if len(self.faces) > 0:\n                gl.glDrawElements(self.render_type.value, len(self.faces), gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawArrays(self.render_type.value, 0, len(self.verts))\n            gl.glBindVertexArray(0)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n            self.upload_gl_uniforms(camera)\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n            gl.glBindVertexArray(0)\n        else:\n            gl.glUseProgram(self.mesh_program)\n            self.upload_gl_uniforms(camera)\n            gl.glBindVertexArray(self.vao)\n            if len(self.faces) > 0:\n                gl.glDrawElements(self.render_type.value, len(self.faces), gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawArrays(self.render_type.value, 0, len(self.verts))\n            gl.glBindVertexArray(0)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "\n        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        self.upload_gl_uniforms(camera)\n        gl.glBindVertexArray(self.vao)\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawArrays(gl.GL_QUADS,"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n            self.upload_gl_uniforms(camera)\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n            gl.glBindVertexArray(0)\n        else:\n            gl.glUseProgram(self.mesh_program)\n            self.upload_gl_uniforms(camera)\n            gl.glBindVertexArray(self.vao)\n\n            if self.faces is not None:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces), gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n\n            gl.glBindVertexArray(0)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "\n        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            self.use_gl_program(self.point_program)\n        else:\n            self.use_gl_program(self.mesh_program)\n\n        self.upload_gl_uniforms(camera)\n        gl.glBindVertexArray(self.vao)\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_LINES, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_QUADS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            if hasattr(self, 'faces"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n            self.upload_gl_uniforms(camera)\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n            gl.glBindVertexArray(0)\n        else:\n            use_gl_program(self.mesh_program)\n            self.upload_gl_uniforms(camera)\n            gl.glBindVertexArray(self.vao)\n\n            if self.faces is not None:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces), gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n\n            gl.glBindVertexArray(0)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "\n        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            self.use_gl_program(self.point_program)\n        else:\n            self.use_gl_program(self.mesh_program)\n\n        self.upload_gl_uniforms(camera)\n        gl.glBindVertexArray(self.vao)\n\n        if self.render_type in [Mesh.RenderType.LINES, Mesh.RenderType.TRIS, Mesh.RenderType.QUADS, Mesh.RenderType.STRIPS]:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(self.render_type.value, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(self.render_type.value, 0, len(self.verts))\n        else:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n\n        gl.glBindVertexArray(0)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "\n        if not self.visible:\n            return\n\n        gl.glBindVertexArray(self.vao)\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n            self.upload_gl_uniforms(camera)\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            use_gl_program(self.mesh_program)\n            self.upload_gl_uniforms(camera)\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_LINES, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            use_gl_program(self.mesh_program)\n            self.upload_gl_uniforms(camera)\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.QUADS:\n            use_gl_program(self.mesh_program)\n            self.upload_gl_uniforms(camera)\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_QUADS, 0, len(self."}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n            self.upload_gl_uniforms(camera)\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n            gl.glBindVertexArray(0)\n        else:\n            use_gl_program(self.mesh_program)\n            self.upload_gl_uniforms(camera)\n            gl.glBindVertexArray(self.vao)\n\n            if self.faces is not None:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n\n            gl.glBindVertexArray(0)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "\n        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        self.upload_gl_uniforms(camera)\n\n        gl.glBindVertexArray(self.vao)\n\n        if self.render_type == Mesh.RenderType.LINES:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawArrays(gl.GL_QUADS, 0, len(self.verts))\n\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            if hasattr(self, 'faces'):"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "\n        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        self.upload_gl_uniforms(camera)\n\n        gl.glBindVertexArray(self.vao)\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_LINES, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_QUADS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.STRIPS"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        gl.glUseProgram(self.mesh_program if self.render_type != Mesh.RenderType.POINTS else self.point_program)\n        self.upload_gl_uniforms(camera)\n        gl.glBindVertexArray(self.vao)\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawArrays(gl.GL_QUADS, 0, len(self.verts))"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "\n        if not self.visible:\n            return\n\n        if self.render_type == self.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        self.upload_gl_uniforms(camera)\n\n        gl.glBindVertexArray(self.vao)\n\n        if self.render_type == self.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == self.RenderType.LINES:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_LINES, len(self.faces), gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n        elif self.render_type == self.RenderType.TRIS:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces), gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n        elif self.render_type == self.RenderType.QUADS:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces), gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawArrays(gl.GL_QUADS, 0, len(self.verts))\n        elif self.render_type == self"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        if self.render_type == self.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        self.upload_gl_uniforms(camera)\n\n        gl.glBindVertexArray(self.vao)\n\n        if self.render_type == self.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == self.RenderType.LINES:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_LINES, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n        elif self.render_type == self.RenderType.TRIS:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n        elif self.render_type == self.RenderType.QUADS:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_QUADS, 0, len(self.verts))\n        elif self.render_type == self.RenderType.STRIPS:\n            if hasattr(self"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        self.upload_gl_uniforms(camera)\n        gl.glBindVertexArray(self.vao)\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_LINES, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_QUADS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            if hasattr(self, 'faces'):"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        self.upload_gl_uniforms(camera)\n        gl.glBindVertexArray(self.vao)\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_QUADS, 0, len(self.verts))\n        elif self.render_type == Mesh"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "\n        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            self.use_gl_program(self.point_program)\n        else:\n            self.use_gl_program(self.mesh_program)\n\n        self.upload_gl_uniforms(camera)\n        gl.glBindVertexArray(self.vao)\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_QUADS, 0, len(self.verts))\n        elif self.render_type"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n        else:\n            use_gl_program(self.mesh_program)\n\n        self.upload_gl_uniforms(camera)\n        gl.glBindVertexArray(self.vao)\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if hasattr(self, 'faces'):\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawArrays(gl.GL_QUADS,"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        # Check if the input is a PyTorch tensor and convert it to a numpy array\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        # If width and height are not provided, use the object's width and height\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        # Bind the texture to the current texture unit\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Upload the pixel data to the texture\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_FLOAT, ptr)\n\n        # Unbind the texture\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_FLOAT, ptr)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        # Check if the input is a PyTorch tensor and convert it to a numpy array\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        # Set the default width and height if not provided\n        w = w or self.W\n        h = h or self.H\n\n        # Bind the texture to be updated\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Upload the pixel data to the texture\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_FLOAT, ptr)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()  # convert PyTorch tensor to numpy array\n\n        if w == 0:\n            w = self.W  # default to object's width\n        if h == 0:\n            h = self.H  # default to object's height\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)  # bind the texture to be updated\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_FLOAT, ptr)  # upload the pixel data to the texture\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)  # unbind the texture"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        # Ensure the input is a numpy array\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().detach().numpy()\n\n        # If width and height are not provided, use the object's width and height\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        # Bind the texture to update\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Upload the pixel data to the texture\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "\n        # If the input is a PyTorch tensor, convert it to a numpy array\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        # If width and height are not provided, use the object's width and height\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        # Bind the texture and upload the pixel data\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        # Check if the input data is a PyTorch tensor and convert it to a numpy array\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        # Set the default width and height if not provided\n        w = w or self.W\n        h = h or self.H\n\n        # Bind the texture to be updated\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Upload the pixel data to the texture\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_FLOAT, ptr)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        # Check if the input data is a PyTorch tensor and convert it to a numpy array\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        # Get the dimensions of the input data\n        data_h, data_w = ptr.shape[:2]\n\n        # Set the default width and height if not provided\n        if w == 0:\n            w = data_w\n        if h == 0:\n            h = data_h\n\n        # Ensure that the dimensions of the input data match the specified width and height\n        if w != data_w or h != data_h:\n            raise ValueError(\"The specified width and height do not match the dimensions of the input data\")\n\n        # Bind the texture and upload the data\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        # Check if the input data is a PyTorch tensor and convert it to a numpy array\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        # Determine the width and height of the texture update\n        w = w or self.W\n        h = h or self.H\n\n        # Bind the texture to be updated\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Upload the data to the texture\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_FLOAT, ptr)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_FLOAT, ptr)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        # Check if the input data is a PyTorch tensor and convert it to a numpy array\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        # Default the width and height to the object's width and height if not provided\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        # Bind the texture to the texture unit and specify the texture data\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_FLOAT, ptr)\n\n        # Unbind the texture\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        \"\"\"\n        This function uploads a portion or the entirety of a numpy array or a PyTorch tensor to a texture in OpenGL. It is designed to update the texture content starting from a specified position (x, y) and covering a specified width (w) and height (h). If width and height are not provided, it defaults to the object's width and height. The function handles the conversion from a PyTorch tensor to a numpy array before uploading.\n\n        Input-Output Arguments\n        :param self: Quad. An instance of the Quad class, which contains the texture to be updated and the default dimensions (W, H) for the texture update.\n        :param ptr: np.ndarray or torch.Tensor, the data source for the texture update. It is used as the pixel data to be uploaded to the texture.\n        :param x: int, optional, the x-coordinate of the lower left corner where the texture update will start. Defaults to 0.\n        :param y: int, optional, the y-coordinate of the lower left corner where the texture update will start. Defaults to 0.\n        :param w: int, optional, the width of the portion of the texture to be updated. If 0, it defaults to the object's width (self.W).\n        :param h: int, optional, the height of the portion of the texture to be updated. If 0, it defaults to the object's height (self.H).\n        :return: No return values.\n        \"\"\"\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        w = w or self.W\n        h = h or self.H\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_FLOAT, ptr)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        \"\"\"\n        This function uploads a portion or the entirety of a numpy array or a PyTorch tensor to a texture in OpenGL. It is designed to update the texture content starting from a specified position (x, y) and covering a specified width (w) and height (h). If width and height are not provided, it defaults to the object's width and height. The function handles the conversion from a PyTorch tensor to a numpy array before uploading.\n\n        Input-Output Arguments\n        :param self: Quad. An instance of the Quad class, which contains the texture to be updated and the default dimensions (W, H) for the texture update.\n        :param ptr: np.ndarray or torch.Tensor, the data source for the texture update. It is used as the pixel data to be uploaded to the texture.\n        :param x: int, optional, the x-coordinate of the lower left corner where the texture update will start. Defaults to 0.\n        :param y: int, optional, the y-coordinate of the lower left corner where the texture update will start. Defaults to 0.\n        :param w: int, optional, the width of the portion of the texture to be updated. If 0, it defaults to the object's width (self.W).\n        :param h: int, optional, the height of the portion of the texture to be updated. If 0, it defaults to the object's height (self.H).\n        :return: No return values.\n        \"\"\"\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()  # convert PyTorch tensor to numpy array\n\n        w = w or self.W  # default to object's width if w is not provided\n        h = h or self.H  # default to object's height if h is not provided\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)  # bind the texture for updating\n\n        if len(ptr.shape) == 2:  # grayscale image\n            gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RED, gl.GL_FLOAT, ptr)\n        elif len(ptr.shape) == 3:  # color image\n            gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_FLOAT, ptr)\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)  # unbind the texture"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        \"\"\"\n        This function uploads a portion or the entirety of a numpy array or a PyTorch tensor to a texture in OpenGL. It is designed to update the texture content starting from a specified position (x, y) and covering a specified width (w) and height (h). If width and height are not provided, it defaults to the object's width and height. The function handles the conversion from a PyTorch tensor to a numpy array before uploading.\n\n        Input-Output Arguments\n        :param self: Quad. An instance of the Quad class, which contains the texture to be updated and the default dimensions (W, H) for the texture update.\n        :param ptr: np.ndarray or torch.Tensor, the data source for the texture update. It is used as the pixel data to be uploaded to the texture.\n        :param x: int, optional, the x-coordinate of the lower left corner where the texture update will start. Defaults to 0.\n        :param y: int, optional, the y-coordinate of the lower left corner where the texture update will start. Defaults to 0.\n        :param w: int, optional, the width of the portion of the texture to be updated. If 0, it defaults to the object's width (self.W).\n        :param h: int, optional, the height of the portion of the texture to be updated. If 0, it defaults to the object's height (self.H).\n        :return: No return values.\n        \"\"\"\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()\n\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_FLOAT, ptr)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, np.ndarray):\n            if w == 0:\n                w = self.W\n            if h == 0:\n                h = self.H\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_FLOAT, ptr)\n        elif isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()\n            self.upload_to_texture(ptr, x, y, w, h)\n        else:\n            raise ValueError(\"Unsupported data type for texture upload\")"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        # Check if the input is a PyTorch tensor and convert it to a numpy array\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        # Set the default width and height if not provided\n        w = w or self.W\n        h = h or self.H\n\n        # Bind the texture to the texture unit and set the texture parameters\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexParameteri(gl.GL_TEXTURE_2D, gl.GL_TEXTURE_MAG_FILTER, gl.GL_NEAREST)\n        gl.glTexParameteri(gl.GL_TEXTURE_2D, gl.GL_TEXTURE_MIN_FILTER, gl.GL_NEAREST)\n\n        # Upload the data to the texture\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "\n        # Check if the input is a PyTorch tensor and convert it to a numpy array\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        # Set the width and height to the object's dimensions if not provided\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        # Bind the texture and upload the data\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_FLOAT, ptr)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        :param self: Quad. An instance of the Quad class, which contains the texture to be updated and the default dimensions (W, H) for the texture update.\n        :param ptr: np.ndarray or torch.Tensor, the data source for the texture update. It is used as the pixel data to be uploaded to the texture.\n        :param x: int, optional, the x-coordinate of the lower left corner where the texture update will start. Defaults to 0.\n        :param y: int, optional, the y-coordinate of the lower left corner where the texture update will start. Defaults to 0.\n        :param w: int, optional, the width of the portion of the texture to be updated. If 0, it defaults to the object's width (self.W).\n        :param h: int, optional, the height of the portion of the texture to be updated. If 0, it defaults to the object's height (self.H).\n        :return: No return values.\n        \"\"\"\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()  # convert PyTorch tensor to numpy array\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_FLOAT, ptr)"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "\n    # Validate input shapes\n    assert R.shape[0] == tvec.shape[0] == camera_matrix.shape[0] == image_size.shape[0], \"Batch size mismatch\"\n    assert R.shape[-2:] == (3, 3), \"Invalid shape for rotation matrix\"\n    assert tvec.shape[-2:] == (3, 1), \"Invalid shape for translation vector\"\n    assert camera_matrix.shape[-2:] == (3, 3), \"Invalid shape for camera intrinsic matrix\"\n    assert image_size.shape[-1] == 2, \"Invalid shape for image size\"\n\n    # Compute camera position\n    C = -torch.matmul(torch.transpose(R, -1, -2), tvec)  # B, 3, 1\n\n    # Compute camera rotation\n    R_pulsar = torch.transpose(R, -1, -2)\n\n    # Compute intrinsic parameters\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..., 1, 2]\n\n    # Normalize focal length\n    f = (fx + fy) / 2\n\n    # Adjust principal point offsets\n    cx_pulsar = (cx - image_size[..., 0] / 2) / f\n    cy_pulsar = (cy - image_size[..., 1] / 2) / f\n\n    # Compute sensor width\n    sensor_width = 2 * f * image_size[..., 0]\n\n    # Combine computed parameters\n    pulsar_params = torch.stack([C, R_pulsar, f, cx_pulsar, cy_pulsar, sensor_width], dim=-1)\n\n    return pulsar_params"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "\n    # Validate input shapes\n    assert R.shape[-2:] == (3, 3), \"Invalid shape for R\"\n    assert tvec.shape[-1:] == (3,), \"Invalid shape for tvec\"\n    assert camera_matrix.shape[-2:] == (3, 3), \"Invalid shape for camera_matrix\"\n    assert image_size.shape[-1:] == (2,), \"Invalid shape for image_size\"\n\n    # Compute camera position\n    C = -torch.matmul(torch.transpose(R, -1, -2), tvec.unsqueeze(-1))\n\n    # Compute camera rotation\n    R_pulsar = matrix_to_rotation_6d(R)\n\n    # Extract focal length and principal point\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..., 1, 2]\n\n    # Normalize focal length\n    f_normalized = (fx + fy) / 2\n\n    # Adjust principal point offset\n    cx_normalized = cx - (image_size[..., 0] / 2)\n    cy_normalized = cy - (image_size[..., 1] / 2)\n\n    # Compute sensor width\n    sensor_width = 2 * f_normalized * torch.tan(torch.atan((image_size[..., 0] / 2) / f_normalized))\n\n    # Concatenate camera parameters\n    camera_params = torch.stack([C, R_pulsar, f_normalized, cx_normalized, cy_normalized, sensor_width], dim=-1)\n\n    return camera_params"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate input shapes\n    assert R.shape[-2:] == (3, 3), \"The shape of R must be (batch_size, 3, 3)\"\n    assert tvec.shape[-2:] == (3, 1), \"The shape of tvec must be (batch_size, 3, 1)\"\n    assert camera_matrix.shape[-2:] == (3, 3), \"The shape of camera_matrix must be (batch_size, 3, 3)\"\n    assert image_size.shape[-1] == 2, \"The shape of image_size must be (batch_size, 2)\"\n\n    # Extract batch size\n    batch_size = R.shape[0]\n\n    # Compute camera position\n    C = -torch.matmul(torch.transpose(R, 1, 2), tvec)  # B, 3, 1\n\n    # Compute camera rotation in a different representation\n    rotation_6d = matrix_to_rotation_6d(R)  # Convert rotation matrices to 6D rotation representation\n\n    # Extract camera intrinsic parameters\n    fx = camera_matrix[..., 0, 0]  # Focal length in x-direction\n    fy = camera_matrix[..., 1, 1]  # Focal length in y-direction\n    cx = camera_matrix[..., 0, 2]  # Principal point offset in x-direction\n    cy = camera_matrix[..., 1, 2]  # Principal point offset in y-direction\n\n    # Normalize focal length\n    f = (fx + fy) / 2.0\n\n    # Normalize principal point offsets\n    cx = cx / image_size[..., 0]  # Normalize principal point offset in x-direction\n    cy = cy / image_size[..., 1]  # Normalize principal point offset in y-direction\n\n    # Compute sensor width\n    sensor_width = 2.0 * f * torch.tan(torch.atan(image_size[..., 0] / (2.0 * fx)))  # Compute sensor width\n\n    # Stack the computed camera parameters\n    camera_params = torch.stack([C, rotation_6d, f, cx, cy, sensor_width], dim=-1)\n\n    return camera_params"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "\n    # Validate input shapes\n    assert R.shape[0] == tvec.shape[0] == camera_matrix.shape[0] == image_size.shape[0], \"Batch dimension mismatch\"\n    assert R.shape[1:] == (3, 3), \"Invalid shape for rotation matrix\"\n    assert tvec.shape[1:] == (3, 1), \"Invalid shape for translation vector\"\n    assert camera_matrix.shape[1:] == (3, 3), \"Invalid shape for camera intrinsic matrix\"\n    assert image_size.shape[1:] == (2,), \"Invalid shape for image size\"\n\n    # Compute camera position\n    C = -torch.matmul(torch.transpose(R, 1, 2), tvec)  # B, 3, 1\n\n    # Compute camera rotation\n    R_pulsar = torch.transpose(R, 1, 2)  # B, 3, 3\n\n    # Compute intrinsic parameters\n    fx = camera_matrix[..., 0, 0] / image_size[..., 0]  # focal length in x-direction\n    fy = camera_matrix[..., 1, 1] / image_size[..., 1]  # focal length in y-direction\n    cx = camera_matrix[..., 0, 2] / image_size[..., 0]  # principal point offset in x-direction\n    cy = camera_matrix[..., 1, 2] / image_size[..., 1]  # principal point offset in y-direction\n    sensor_width = 2 * fx  # sensor width\n\n    # Concatenate computed parameters\n    pulsar_camera_params = torch.stack([C, R_pulsar, fx, fy, cx, cy, sensor_width], dim=-1)\n\n    return pulsar_camera_params"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "\n    # Validate input shapes\n    assert R.shape[-2:] == (3, 3), \"Invalid shape for rotation matrix R\"\n    assert tvec.shape[-2:] == (3, 1), \"Invalid shape for translation vector tvec\"\n    assert camera_matrix.shape[-2:] == (3, 3), \"Invalid shape for camera intrinsic matrix camera_matrix\"\n    assert image_size.shape[-1] == 2, \"Invalid shape for image size\"\n\n    # Compute camera position\n    C = -torch.matmul(torch.transpose(R, -1, -2), tvec)\n\n    # Compute camera rotation\n    R_pulsar = matrix_to_rotation_6d(R)\n\n    # Compute intrinsic parameters\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..., 1, 2]\n\n    # Normalize focal length\n    f = (fx + fy) / 2\n\n    # Adjust principal point offsets\n    cx_pulsar = (cx - image_size[..., 0] / 2) / f\n    cy_pulsar = (cy - image_size[..., 1] / 2) / f\n\n    # Compute sensor width\n    sensor_width = 2 * f * image_size[..., 0] / (2 * image_size[..., 0])\n\n    # Concatenate computed parameters\n    pulsar_camera_params = torch.stack([C, R_pulsar, f, cx_pulsar, cy_pulsar, sensor_width], dim=-1)\n\n    return pulsar_camera_params"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "\n    # Validate input shapes\n    assert R.shape[-2:] == (3, 3), \"Invalid shape for R. Expected shape (B, 3, 3).\"\n    assert tvec.shape[-1] == 3, \"Invalid shape for tvec. Expected shape (B, 3).\"\n    assert camera_matrix.shape[-2:] == (3, 3), \"Invalid shape for camera_matrix. Expected shape (B, 3, 3).\"\n    assert image_size.shape[-1] == 2, \"Invalid shape for image_size. Expected shape (B, 2).\"\n\n    # Compute camera position and rotation\n    c2w = affine_inverse(torch.cat([R, tvec.unsqueeze(-1)], dim=-1))\n    c2w[..., 0] *= 1  # flip x\n    c2w[..., 1] *= -1  # flip y\n    c2w[..., 2] *= -1  # flip z\n    ext = affine_inverse(c2w)\n    position = ext[..., :3, 3]\n\n    # Compute intrinsic parameters\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..., 1, 2]\n    f = (fx + fy) / 2  # average focal length\n\n    # Normalize focal length\n    H = image_size[..., 0]\n    W = image_size[..., 1]\n    M = torch.min(H, W)\n    f = f * 2.0 / M\n\n    # Adjust principal point offsets\n    cx = -(cx - W / 2.0) * 2.0 / M\n    cy = -(cy - H / 2.0) * 2.0 / M\n\n    # Calculate sensor width\n    sensor_width = 2 * f * W / M\n\n    # Return computed camera parameters\n    return torch.stack([position, ext[..., :3, :3], f, sensor_width], dim=-1)"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "\n    # Validate input shapes\n    if R.shape[-2:] != (3, 3) or tvec.shape[-1] != 3 or camera_matrix.shape[-2:] != (3, 3) or image_size.shape[-1] != 2:\n        raise ValueError(\"Invalid input shape. Expected R: (*, 3, 3), tvec: (*, 3), camera_matrix: (*, 3, 3), image_size: (*, 2)\")\n\n    # Compute camera position\n    C = -torch.matmul(torch.transpose(R, -1, -2), tvec.unsqueeze(-1))\n\n    # Compute camera rotation\n    R_pulsar = matrix_to_rotation_6d(R)\n\n    # Compute camera intrinsic parameters\n    fx = (camera_matrix[..., 0, 0] + camera_matrix[..., 1, 1]) / 2\n    fy = (camera_matrix[..., 0, 0] + camera_matrix[..., 1, 1]) / 2\n    cx = camera_matrix[..., 0, 2] - image_size[..., 0] / 2\n    cy = camera_matrix[..., 1, 2] - image_size[..., 1] / 2\n    sensor_width = 2 * fx\n\n    # Normalize focal length\n    f = fx / sensor_width\n\n    # Adjust focal length based on znear\n    f = f / (znear / 0.1)\n\n    # Concatenate camera parameters\n    camera_params = torch.cat([C, R_pulsar, f.unsqueeze(-1), cx.unsqueeze(-1), cy.unsqueeze(-1)], dim=-1)\n\n    return camera_params"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "\n    # Validate shapes\n    assert R.shape[-2:] == (3, 3), \"Rotation matrix must have shape (B, 3, 3)\"\n    assert tvec.shape[-2:] == (3, 1), \"Translation vector must have shape (B, 3, 1)\"\n    assert camera_matrix.shape[-2:] == (3, 3), \"Camera intrinsic matrix must have shape (B, 3, 3)\"\n    assert image_size.shape[-1] == 2, \"Image size must have shape (B, 2)\"\n\n    # Compute camera position\n    C = -torch.matmul(torch.transpose(R, -1, -2), tvec)  # B, 3, 1\n\n    # Compute camera rotation\n    R = torch.transpose(R, -1, -2)  # Transpose R for Pulsar's camera rotation representation\n\n    # Compute intrinsic parameters\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..., 1, 2]\n    sensor_width = image_size[..., 0]\n\n    # Normalize focal length\n    f = (fx + fy) / 2\n\n    # Adjust principal point offsets\n    cx = cx - (image_size[..., 0] / 2)\n    cy = cy - (image_size[..., 1] / 2)\n\n    # Create tensor of camera parameters\n    camera_params = torch.stack([C, R, f, sensor_width, cx, cy], dim=-1)\n\n    return camera_params"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Ensure batched inputs\n    assert R.dim() == 3, \"R must be a batch of rotation matrices with shape (B, 3, 3)\"\n    assert tvec.dim() == 3, \"tvec must be a batch of translation vectors with shape (B, 3, 1)\"\n    assert camera_matrix.dim() == 3, \"camera_matrix must be a batch of camera intrinsic matrices with shape (B, 3, 3)\"\n    assert image_size.dim() == 2, \"image_size must be a batch of image sizes with shape (B, 2)\"\n\n    # Validate input shapes\n    assert R.size(0) == tvec.size(0) == camera_matrix.size(0) == image_size.size(0), \"All inputs must have the same batch size\"\n    assert camera_matrix.size(1) == camera_matrix.size(2) == 3, \"camera_matrix must be 3x3 matrices\"\n    assert image_size.size(1) == 2, \"image_size must have shape (B, 2)\"\n\n    # Extract batch size\n    B = R.size(0)\n\n    # Compute camera position\n    C = -torch.bmm(R, tvec)  # B, 3, 1\n\n    # Compute camera rotation in 6D representation\n    rotation_6d = matrix_to_rotation_6d(R)  # B, 6\n\n    # Compute camera intrinsic parameters\n    fx = camera_matrix[:, 0, 0]  # focal length in x-direction\n    fy = camera_matrix[:, 1, 1]  # focal length in y-direction\n    cx = camera_matrix[:, 0, 2]  # principal point offset in x-direction\n    cy = camera_matrix[:, 1, 2]  # principal point offset in y-direction\n    sensor_width = image_size[:, 1]  # sensor width\n\n    # Normalize focal length based on image size and near clipping plane distance\n    fx_normalized = fx / image_size[:, 0]\n    fy_normalized = fy / image_size[:, 1]\n    znear_normalized = znear / image_size[:, 0]\n\n    # Construct the camera parameters tensor\n    camera_params = torch.stack([C, rotation_6d, fx_normalized, fy_normalized, cx, cy, sensor_width, znear_normalized], dim=1)\n\n    return camera_params"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate input shapes\n    assert R.shape[:-2] == tvec.shape[:-2] == camera_matrix.shape[:-2] == image_size.shape[:-1], \"Input shapes are not compatible\"\n    assert R.shape[-1] == tvec.shape[-1] == 3, \"Rotation matrix and translation vector must have shape (..., 3)\"\n    assert camera_matrix.shape[-2:] == (3, 3), \"Camera matrix must have shape (..., 3, 3)\"\n    assert image_size.shape[-1] == 2, \"Image size must have shape (..., 2)\"\n\n    # Compute camera position\n    C = -torch.matmul(R.transpose(-1, -2), tvec.unsqueeze(-1)).squeeze(-1)  # B, 3\n\n    # Compute camera rotation\n    R = R.clone()\n    R[..., 0, :] *= -1  # flip x row\n    R[..., 1, :] *= -1  # flip y row\n\n    # Compute camera intrinsic parameters\n    fx = (camera_matrix[..., 0, 0] + camera_matrix[..., 1, 1]) / 2  # average of focal lengths for x and y directions\n    fy = fx\n    cx = camera_matrix[..., 0, 2] - image_size[..., 0] / 2  # adjust principal point offset for x direction\n    cy = camera_matrix[..., 1, 2] - image_size[..., 1] / 2  # adjust principal point offset for y direction\n    sensor_width = 2 * fx  # sensor width is twice the focal length\n\n    # Normalize focal length\n    f = fx / sensor_width\n\n    # Return computed camera parameters\n    return torch.stack([C, R, f, cx, cy, sensor_width], dim=-1)"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "\n    # Validate input shapes\n    assert R.shape[-2:] == (3, 3), \"Rotation matrix must have shape (B, 3, 3)\"\n    assert tvec.shape[-1] == 3, \"Translation vector must have shape (B, 3)\"\n    assert camera_matrix.shape[-2:] == (3, 3), \"Camera matrix must have shape (B, 3, 3)\"\n    assert image_size.shape[-1] == 2, \"Image size must have shape (B, 2)\"\n\n    # Compute camera position\n    C = -torch.matmul(R.transpose(-1, -2), tvec.unsqueeze(-1)).squeeze(-1)  # B, 3\n\n    # Compute camera rotation\n    R = R.clone()\n    R[..., 0, :] *= -1  # flip x row\n    R[..., 1, :] *= -1  # flip y row\n    R = R.transpose(-1, -2)  # applied left multiply to right multiply\n\n    # Compute camera intrinsic parameters\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..., 1, 2]\n    sensor_width = image_size[..., 1]\n\n    # Normalize focal length and adjust principal point offsets\n    fx_normalized = fx / sensor_width\n    fy_normalized = fy / sensor_width\n    cx_normalized = (cx - (image_size[..., 0] / 2)) / sensor_width\n    cy_normalized = (cy - (image_size[..., 1] / 2)) / sensor_width\n\n    # Adjust focal length based on near clipping plane distance\n    f = (fx_normalized + fy_normalized) / 2\n    f *= znear\n\n    # Concatenate camera parameters\n    camera_params = torch.stack([C, R, f, cx_normalized, cy_normalized], dim=-1)  # B, 3, 3\n\n    return camera_params"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "\n    # Validate input shapes\n    assert R.shape[-2:] == (3, 3), \"The rotation matrix must have the shape (batch_size, 3, 3)\"\n    assert tvec.shape[-2:] == (3, 1), \"The translation vector must have the shape (batch_size, 3, 1)\"\n    assert camera_matrix.shape[-2:] == (3, 3), \"The camera matrix must have the shape (batch_size, 3, 3)\"\n    assert image_size.shape[-1] == 2, \"The image size must have the shape (batch_size, 2)\"\n\n    # Compute camera position\n    C = -torch.matmul(R.transpose(-1, -2), tvec)  # B, 3, 1\n\n    # Compute camera rotation\n    R = R.clone()\n    R[..., 0, :] *= -1  # flip x row\n    R[..., 1, :] *= -1  # flip y row\n    R = R.transpose(-1, -2)  # applied left (left multiply to right multiply)\n\n    # Compute camera intrinsic parameters\n    fx = (camera_matrix[..., 0, 0] + camera_matrix[..., 1, 1]) / 2  # average of focal lengths for x and y\n    fy = fx\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..., 1, 2]\n    sensor_width = image_size[..., 0]\n\n    # Normalize focal length\n    fx = fx * sensor_width / image_size[..., 1]\n\n    # Adjust focal length based on near clipping plane distance\n    fx = fx * znear\n\n    return torch.cat([C, R, fx[..., None], fy[..., None], cx[..., None], cy[..., None]], dim=-1)"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "\n    # Validate input shapes\n    assert R.shape[-2:] == (3, 3), \"Invalid shape for rotation matrix R\"\n    assert tvec.shape[-1] == 3, \"Invalid shape for translation vector tvec\"\n    assert camera_matrix.shape[-2:] == (3, 3), \"Invalid shape for camera intrinsic matrix\"\n    assert image_size.shape[-1] == 2, \"Invalid shape for image size\"\n\n    # Compute camera position\n    C = -torch.matmul(torch.transpose(R, -1, -2), tvec.unsqueeze(-1))\n\n    # Compute camera rotation in 6D representation\n    rotation_6d = matrix_to_rotation_6d(R)\n\n    # Compute camera intrinsic parameters\n    focal_length = torch.mean(camera_matrix[..., :2, :2], dim=(-1, -2))\n    principal_point = camera_matrix[..., :2, 2] / image_size.unsqueeze(-1)\n    sensor_width = 2 * focal_length * torch.tan(camera_matrix[..., 0, 0] / 2)\n\n    # Concatenate and return the computed camera parameters\n    camera_params = torch.cat([C, rotation_6d, focal_length, principal_point, sensor_width], dim=-1)\n    return camera_params"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "\n    # Validate input shapes\n    assert R.shape[-2:] == (3, 3), \"Invalid shape for R\"\n    assert tvec.shape[-2:] == (3, 1), \"Invalid shape for tvec\"\n    assert camera_matrix.shape[-2:] == (3, 3), \"Invalid shape for camera_matrix\"\n    assert image_size.shape[-1] == 2, \"Invalid shape for image_size\"\n\n    # Compute camera position and rotation\n    C = -torch.matmul(R.transpose(-1, -2), tvec)  # Compute camera position\n    R = R.clone()\n    R[..., 0, :] *= -1  # Flip x row\n    R[..., 1, :] *= -1  # Flip y row\n    T = (-torch.matmul(R, C))[..., 0]  # Convert R and C to T\n\n    # Compute camera intrinsic parameters\n    fx = (camera_matrix[..., 0, 0] + camera_matrix[..., 1, 1]) / 2  # Average focal lengths for x and y\n    fy = fx\n    cx = camera_matrix[..., 0, 2] - image_size[..., 0] / 2  # Adjust principal point offsets\n    cy = camera_matrix[..., 1, 2] - image_size[..., 1] / 2\n    sensor_width = image_size[..., 0]  # Sensor width is the same as the image width\n\n    return torch.stack([C, R, fx, fy, cx, cy, sensor_width], dim=-1)"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "\n    # Validate input shapes\n    assert R.shape[-2:] == (3, 3), \"Input R must have shape (B, 3, 3)\"\n    assert tvec.shape[-2:] == (3, 1), \"Input tvec must have shape (B, 3, 1)\"\n    assert camera_matrix.shape[-2:] == (3, 3), \"Input camera_matrix must have shape (B, 3, 3)\"\n    assert image_size.shape[-1] == 2, \"Input image_size must have shape (B, 2)\"\n\n    # Compute camera position\n    C = -torch.matmul(torch.transpose(R, -1, -2), tvec)  # B, 3, 1\n\n    # Compute camera rotation\n    R = torch.transpose(R, -1, -2)  # Transpose R for Pulsar's rotation representation\n\n    # Compute camera intrinsic parameters\n    fx = camera_matrix[..., 0, 0]  # Focal length in x-direction\n    fy = camera_matrix[..., 1, 1]  # Focal length in y-direction\n    px = camera_matrix[..., 0, 2]  # Principal point offset in x-direction\n    py = camera_matrix[..., 1, 2]  # Principal point offset in y-direction\n    sensor_width = image_size[..., 0]  # Sensor width\n    sensor_height = image_size[..., 1]  # Sensor height\n\n    # Normalize focal length\n    fx = fx / sensor_width\n    fy = fy / sensor_height\n\n    # Adjust principal point offsets\n    px = (px - sensor_width / 2) / sensor_width\n    py = (py - sensor_height / 2) / sensor_height\n\n    # Adjust focal length using near clipping plane distance\n    fx = fx / znear\n    fy = fy / znear\n\n    # Concatenate computed camera parameters\n    camera_params = torch.stack([C, R, fx, fy, px, py], dim=-1)  # B, 3, 1 + B, 3, 3 + B, 1 + B, 1 + B, 1\n\n    return camera_params"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate input shapes\n    assert R.shape[-2:] == (3, 3), \"Invalid shape for R: should be (B, 3, 3)\"\n    assert tvec.shape[-2:] == (3, 1), \"Invalid shape for tvec: should be (B, 3, 1)\"\n    assert camera_matrix.shape[-2:] == (3, 3), \"Invalid shape for camera_matrix: should be (B, 3, 3)\"\n    assert image_size.shape[-1] == 2, \"Invalid shape for image_size: should be (B, 2)\"\n\n    # Compute camera position\n    C = -torch.matmul(torch.transpose(R, -1, -2), tvec)\n\n    # Compute rotation matrix to 6D representation\n    rotation_6d = matrix_to_rotation_6d(R)\n\n    # Extract focal length and principal point\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..., 1, 2]\n\n    # Normalize focal length\n    f = (fx + fy) / 2\n\n    # Normalize principal point\n    cx_norm = (cx - image_size[..., 0] / 2) / (image_size[..., 0] / 2)\n    cy_norm = (cy - image_size[..., 1] / 2) / (image_size[..., 1] / 2)\n\n    # Compute sensor width\n    sensor_width = 2 * f * torch.tan(torch.atan(image_size[..., 0] / (2 * fx)))\n\n    # Construct camera parameters tensor\n    camera_params = torch.stack([C, rotation_6d, f, sensor_width, cx_norm, cy_norm], dim=-1)\n\n    return camera_params"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Ensure all inputs are batched and have the same batch size\n    assert R.shape[0] == tvec.shape[0] == camera_matrix.shape[0] == image_size.shape[0], \"Batch size mismatch\"\n    \n    # Validate the shapes of the input tensors\n    assert R.shape[-2:] == (3, 3), \"Invalid shape for rotation matrix\"\n    assert tvec.shape[-2:] == (3, 1), \"Invalid shape for translation vector\"\n    assert camera_matrix.shape[-2:] == (3, 3), \"Invalid shape for camera intrinsic matrix\"\n    assert image_size.shape[-1] == 2, \"Invalid shape for image size\"\n    \n    # Extract batch size\n    batch_size = R.shape[0]\n    \n    # Compute camera rotation in 6D representation\n    rotation_6d = matrix_to_rotation_6d(R)\n    \n    # Compute camera position\n    position = -torch.bmm(R.transpose(-1, -2), tvec)  # Camera position = -R^T * tvec\n    \n    # Extract camera intrinsic parameters\n    fx = camera_matrix[..., 0, 0]  # Focal length in x-direction\n    fy = camera_matrix[..., 1, 1]  # Focal length in y-direction\n    cx = camera_matrix[..., 0, 2]  # Principal point offset in x-direction\n    cy = camera_matrix[..., 1, 2]  # Principal point offset in y-direction\n    \n    # Normalize focal length based on image size and near clipping plane distance\n    normalized_fx = fx / image_size[..., 0] * znear\n    normalized_fy = fy / image_size[..., 1] * znear\n    \n    # Compute sensor width\n    sensor_width = 2 * znear / normalized_fx\n    \n    # Concatenate all computed camera parameters\n    camera_params = torch.stack([position, rotation_6d, normalized_fx, normalized_fy, cx, cy, sensor_width], dim=-1)\n    \n    return camera_params"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "\n    # Validate input shapes\n    assert R.shape[-2:] == (3, 3), \"Rotation matrix must be of shape (B, 3, 3)\"\n    assert tvec.shape[-2:] == (3, 1), \"Translation vector must be of shape (B, 3, 1)\"\n    assert camera_matrix.shape[-2:] == (3, 3), \"Camera matrix must be of shape (B, 3, 3)\"\n    assert image_size.shape[-1] == 2, \"Image size must be of shape (B, 2)\"\n\n    # Compute camera position\n    C = -torch.matmul(torch.transpose(R, -1, -2), tvec)  # B, 3, 1\n\n    # Compute camera rotation\n    R_pulsar = torch.transpose(R, -1, -2)\n\n    # Compute intrinsic parameters\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..., 1, 2]\n\n    # Normalize focal length\n    f = (fx + fy) / 2\n\n    # Adjust principal point offsets\n    cx = (cx - image_size[..., 0] / 2) / f\n    cy = (cy - image_size[..., 1] / 2) / f\n\n    # Compute sensor width\n    sensor_width = 2 * f / image_size[..., 0]\n\n    # Return computed camera parameters\n    return torch.cat([C, R_pulsar, f.unsqueeze(-1), sensor_width.unsqueeze(-1)], dim=-1)"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "\n    # Ensure all inputs are batched\n    assert R.dim() == 3, \"R must be batched (B, 3, 3)\"\n    assert tvec.dim() == 3, \"tvec must be batched (B, 3, 1)\"\n    assert camera_matrix.dim() == 3, \"camera_matrix must be batched (B, 3, 3)\"\n    assert image_size.dim() == 2, \"image_size must be batched (B, 2)\"\n\n    # Validate shapes\n    assert R.size(0) == tvec.size(0) == camera_matrix.size(0) == image_size.size(0), \"All inputs must have the same batch size\"\n\n    # Compute camera position\n    C = -torch.bmm(R.transpose(1, 2), tvec)  # B, 3, 1\n\n    # Compute camera rotation\n    R_pulsar = matrix_to_rotation_6d(R)  # Convert rotation matrices to 6D rotation representation\n\n    # Compute intrinsic parameters\n    fx = camera_matrix[..., 0, 0]  # focal length in x-direction\n    fy = camera_matrix[..., 1, 1]  # focal length in y-direction\n    cx = camera_matrix[..., 0, 2]  # principal point offset in x-direction\n    cy = camera_matrix[..., 1, 2]  # principal point offset in y-direction\n    sensor_width = image_size[..., 0]  # sensor width\n    sensor_height = image_size[..., 1]  # sensor height\n\n    # Normalize focal length\n    fx_normalized = fx / sensor_width\n    fy_normalized = fy / sensor_height\n\n    # Adjust focal length based on near clipping plane distance\n    fx_adjusted = fx_normalized / znear\n    fy_adjusted = fy_normalized / znear\n\n    # Stack the computed camera parameters\n    camera_params = torch.stack([C, R_pulsar, fx_adjusted, fy_adjusted, cx, cy], dim=-1)  # B, 6\n\n    return camera_params"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate input shapes\n    assert R.shape[-2:] == (3, 3), \"R must have shape (batch_size, 3, 3)\"\n    assert tvec.shape[-2:] == (3, 1), \"tvec must have shape (batch_size, 3, 1)\"\n    assert camera_matrix.shape[-2:] == (3, 3), \"camera_matrix must have shape (batch_size, 3, 3)\"\n    assert image_size.shape[-1] == 2, \"image_size must have shape (batch_size, 2)\"\n\n    # Extract batch size\n    batch_size = R.shape[0]\n\n    # Calculate camera position\n    camera_position = -torch.matmul(torch.transpose(R, 1, 2), tvec)\n\n    # Calculate focal length and sensor width\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..., 1, 2]\n    sensor_width = image_size[..., 0]\n\n    # Normalize focal length\n    focal_length = (fx + fy) / 2\n\n    # Adjust principal point offsets\n    cx_norm = (cx - image_size[..., 0] / 2) / image_size[..., 0]\n    cy_norm = (cy - image_size[..., 1] / 2) / image_size[..., 1]\n\n    # Compute camera rotation in 6D representation\n    camera_rotation = matrix_to_rotation_6d(R)\n\n    # Create tensor containing the computed camera parameters\n    camera_params = torch.stack([camera_position, camera_rotation, focal_length, sensor_width, cx_norm, cy_norm], dim=-1)\n\n    return camera_params"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "            if not self.use_quad_draw:\n                self.blit(x, y, w, h)\n                return\n\n            w = w or self.W\n            h = h or self.H\n\n            gl.glViewport(x, y, w, h)\n            gl.glScissor(x, y, w, h)\n            gl.glUseProgram(self.quad_program)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n            gl.glBindVertexArray(0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n            gl.glUseProgram(0)\n            gl.glViewport(0, 0, self.W, self.H)\n            gl.glScissor(0, 0, self.W, self.H)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.visible:\n            return\n\n        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n            return\n\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        gl.glUseProgram(self.quad_program)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        gl.glBindVertexArray(0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n        gl.glUseProgram(0)\n\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        \"\"\"\n        The draw method in the Quad class is responsible for rendering a textured quadrilateral on the screen. It uses OpenGL conventions, specifically targeting the lower-left corner as the origin. If the use_quad_draw attribute is False, it falls back to a simpler blit method for drawing. Otherwise, it sets up a specific viewport and scissor box for rendering, activates a shader program, binds a texture, and draws the quadrilateral using vertex data. After drawing, it restores the viewport and scissor box to their original sizes.\n\n        Input-Output Arguments\n        :param self: Quad. An instance of the Quad class. It uses attributes like use_quad_draw, W, H, quad_program, tex, and vao for drawing operations.\n        :param x: int, optional. The x-coordinate of the lower-left corner where the quadrilateral will be drawn. Defaults to 0.\n        :param y: int, optional. The y-coordinate of the lower-left corner where the quadrilateral will be drawn. Defaults to 0.\n        :param w: int, optional. The width of the quadrilateral. If not provided or 0, the instance's W attribute is used. Defaults to 0.\n        :param h: int, optional. The height of the quadrilateral. If not provided or 0, the instance's H attribute is used. Defaults to 0.\n        :return: No return values. This method performs drawing operations and does not return any value.\n        \"\"\"\n        if not self.visible:\n            return\n\n        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n            return\n\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor_box = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        gl.glUseProgram(self.quad_program)\n        gl.glBindVertexArray(self.vao)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)  # draw the quadrilateral\n\n        gl.glBindVertexArray(0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n        gl.glUseProgram(0)\n\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor_box)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        \"\"\"\n        The draw method in the Quad class is responsible for rendering a textured quadrilateral on the screen. It uses OpenGL conventions, specifically targeting the lower-left corner as the origin. If the use_quad_draw attribute is False, it falls back to a simpler blit method for drawing. Otherwise, it sets up a specific viewport and scissor box for rendering, activates a shader program, binds a texture, and draws the quadrilateral using vertex data. After drawing, it restores the viewport and scissor box to their original sizes.\n\n        Input-Output Arguments\n        :param self: Quad. An instance of the Quad class. It uses attributes like use_quad_draw, W, H, quad_program, tex, and vao for drawing operations.\n        :param x: int, optional. The x-coordinate of the lower-left corner where the quadrilateral will be drawn. Defaults to 0.\n        :param y: int, optional. The y-coordinate of the lower-left corner where the quadrilateral will be drawn. Defaults to 0.\n        :param w: int, optional. The width of the quadrilateral. If not provided or 0, the instance's W attribute is used. Defaults to 0.\n        :param h: int, optional. The height of the quadrilateral. If not provided or 0, the instance's H attribute is used. Defaults to 0.\n        :return: No return values. This method performs drawing operations and does not return any value.\n        \"\"\"\n        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n            return\n\n        # Set up viewport and scissor box for rendering\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n        gl.glUseProgram(self.quad_program)\n\n        # Bind the texture to be drawn\n        gl.glActiveTexture(gl.GL_TEXTURE0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Draw the quadrilateral using vertex data\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        # Restore the viewport and scissor box to their original sizes\n        gl.glViewport(0, 0, self.W, self.H)\n        gl.glScissor(0, 0, self.W, self.H)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.visible:\n            return\n\n        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n            return\n\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        gl.glUseProgram(self.quad_program)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindVertexArray(self.vao)\n\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        gl.glBindVertexArray(0)\n        gl.glUseProgram(0)\n\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n        else:\n            if w == 0:\n                w = self.W\n            if h == 0:\n                h = self.H\n            gl.glViewport(x, y, w, h)\n            gl.glScissor(x, y, w, h)\n            gl.glUseProgram(self.quad_program)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n            gl.glBindVertexArray(0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n            gl.glUseProgram(0)\n            gl.glViewport(0, 0, self.W, self.H)\n            gl.glScissor(0, 0, self.W, self.H)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n        else:\n            if w == 0:\n                w = self.W\n            if h == 0:\n                h = self.H\n\n            old_viewport = gl.glGetInteger(gl.GL_VIEWPORT)\n            old_scissor_box = gl.glGetInteger(gl.GL_SCISSOR_BOX)\n\n            gl.glViewport(x, y, w, h)\n            gl.glScissor(x, y, w, h)\n\n            gl.glUseProgram(self.quad_program)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n            gl.glBindVertexArray(0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n            gl.glUseProgram(0)\n\n            gl.glViewport(*old_viewport)\n            gl.glScissor(*old_scissor_box)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        \"\"\"\n        The draw method in the Quad class is responsible for rendering a textured quadrilateral on the screen. It uses OpenGL conventions, specifically targeting the lower-left corner as the origin. If the use_quad_draw attribute is False, it falls back to a simpler blit method for drawing. Otherwise, it sets up a specific viewport and scissor box for rendering, activates a shader program, binds a texture, and draws the quadrilateral using vertex data. After drawing, it restores the viewport and scissor box to their original sizes.\n\n        Input-Output Arguments\n        :param self: Quad. An instance of the Quad class. It uses attributes like use_quad_draw, W, H, quad_program, tex, and vao for drawing operations.\n        :param x: int, optional. The x-coordinate of the lower-left corner where the quadrilateral will be drawn. Defaults to 0.\n        :param y: int, optional. The y-coordinate of the lower-left corner where the quadrilateral will be drawn. Defaults to 0.\n        :param w: int, optional. The width of the quadrilateral. If not provided or 0, the instance's W attribute is used. Defaults to 0.\n        :param h: int, optional. The height of the quadrilateral. If not provided or 0, the instance's H attribute is used. Defaults to 0.\n        :return: No return values. This method performs drawing operations and does not return any value.\n        \"\"\"\n        # Set up a specific viewport and scissor box for rendering\n        gl.glViewport(x, y, w if w else self.W, h if h else self.H)\n        gl.glScissor(x, y, w if w else self.W, h if h else self.H)\n\n        # Activate the shader program\n        gl.glUseProgram(self.quad_program)\n\n        # Bind the texture\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Draw the quadrilateral using vertex data\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        # Restore the viewport and scissor box to their original sizes\n        gl.glViewport(0, 0, self.W, self.H)\n        gl.glScissor(0, 0, self.W, self.H)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n            return\n\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n        if w == 0: w = self.W\n        if h == 0: h = self.H\n\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        gl.glUseProgram(self.quad_program)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        gl.glBindVertexArray(0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n        gl.glUseProgram(0)\n\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.visible:\n            return\n\n        # Check if the use_quad_draw attribute is False\n        if not self.use_quad_draw:\n            # Fallback to simpler blit method for drawing\n            self.blit(x, y, w, h)\n            return\n\n        # Set up viewport and scissor box for rendering\n        gl.glViewport(x, y, w or self.W, h or self.H)\n        gl.glScissor(x, y, w or self.W, h or self.H)\n\n        # Activate the shader program\n        gl.glUseProgram(self.quad_program)\n\n        # Bind the texture\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Draw the quadrilateral using vertex data\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        # Restore the viewport and scissor box to their original sizes\n        gl.glViewport(0, 0, self.W, self.H)\n        gl.glScissor(0, 0, self.W, self.H)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n        else:\n            if w == 0:\n                w = self.W\n            if h == 0:\n                h = self.H\n            gl.glViewport(x, y, w, h)\n            gl.glScissor(x, y, w, h)\n            gl.glUseProgram(self.quad_program)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n            gl.glBindVertexArray(0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n            gl.glUseProgram(0)\n            gl.glViewport(0, 0, self.W, self.H)\n            gl.glScissor(0, 0, self.W, self.H)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "            if not self.visible: return\n\n            # Set the viewport and scissor box\n            gl.glViewport(x, y, w or self.W, h or self.H)\n            gl.glScissor(x, y, w or self.W, h or self.H)\n\n            # Activate the shader program\n            gl.glUseProgram(self.quad_program)\n\n            # Bind the texture\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n            # Draw the quadrilateral using vertex data\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n            # Restore the viewport and scissor box to their original sizes\n            gl.glViewport(0, 0, self.W, self.H)\n            gl.glScissor(0, 0, self.W, self.H)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        \"\"\"\n        The draw method in the Quad class is responsible for rendering a textured quadrilateral on the screen. It uses OpenGL conventions, specifically targeting the lower-left corner as the origin. If the use_quad_draw attribute is False, it falls back to a simpler blit method for drawing. Otherwise, it sets up a specific viewport and scissor box for rendering, activates a shader program, binds a texture, and draws the quadrilateral using vertex data. After drawing, it restores the viewport and scissor box to their original sizes.\n\n        Input-Output Arguments\n        :param self: Quad. An instance of the Quad class. It uses attributes like use_quad_draw, W, H, quad_program, tex, and vao for drawing operations.\n        :param x: int, optional. The x-coordinate of the lower-left corner where the quadrilateral will be drawn. Defaults to 0.\n        :param y: int, optional. The y-coordinate of the lower-left corner where the quadrilateral will be drawn. Defaults to 0.\n        :param w: int, optional. The width of the quadrilateral. If not provided or 0, the instance's W attribute is used. Defaults to 0.\n        :param h: int, optional. The height of the quadrilateral. If not provided or 0, the instance's H attribute is used. Defaults to 0.\n        :return: No return values. This method performs drawing operations and does not return any value.\n        \"\"\"\n        # Set the viewport and scissor box for rendering\n        if self.use_quad_draw:\n            gl.glViewport(x, y, w or self.W, h or self.H)\n            gl.glScissor(x, y, w or self.W, h or self.H)\n            gl.glUseProgram(self.quad_program)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)  # Draw the quadrilateral using vertex data\n            gl.glBindVertexArray(0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n            gl.glUseProgram(0)\n            gl.glViewport(0, 0, self.W, self.H)  # Restore the original viewport size\n            gl.glScissor(0, 0, self.W, self.H)  # Restore the original scissor box size\n        else:\n            # Use the blit method for drawing\n            self.blit(x, y, w, h)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.visible:\n            return\n\n        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n            return\n\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        gl.glUseProgram(self.quad_program)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        gl.glViewport(0, 0, self.W, self.H)\n        gl.glScissor(0, 0, self.W, self.H)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "            if not self.visible:\n                return\n\n            if not self.use_quad_draw:\n                self.blit(x, y, w, h)\n                return\n\n            if w == 0:\n                w = self.W\n            if h == 0:\n                h = self.H\n\n            old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n            old_scissor_box = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n            gl.glViewport(x, y, w, h)\n            gl.glScissor(x, y, w, h)\n\n            gl.glUseProgram(self.quad_program)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n            gl.glBindVertexArray(0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n            gl.glUseProgram(0)\n\n            gl.glViewport(*old_viewport)\n            gl.glScissor(*old_scissor_box)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n        else:\n            if w == 0:\n                w = self.W\n            if h == 0:\n                h = self.H\n            gl.glViewport(x, y, w, h)\n            gl.glScissor(x, y, w, h)\n            gl.glUseProgram(self.quad_program)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n            gl.glBindVertexArray(0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n            gl.glUseProgram(0)\n            gl.glViewport(0, 0, self.W, self.H)\n            gl.glScissor(0, 0, self.W, self.H)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.visible: \n            return\n\n        # Render the quadrilateral\n        if self.use_quad_draw:\n            gl.glViewport(x, y, w if w else self.W, h if h else self.H)\n            gl.glScissor(x, y, w if w else self.W, h if h else self.H)\n            gl.glUseProgram(self.quad_program)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)  # Draw the quadrilateral using vertex data\n            gl.glBindVertexArray(0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n            gl.glUseProgram(0)\n            gl.glViewport(0, 0, self.W, self.H)\n            gl.glScissor(0, 0, self.W, self.H)\n        else:\n            self.blit(x, y, w, h)  # Fallback to simpler blit method for drawing"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.visible:\n            return\n\n        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n            return\n\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        gl.glUseProgram(self.quad_program)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        gl.glViewport(0, 0, self.W, self.H)\n        gl.glScissor(0, 0, self.W, self.H)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.visible:\n            return\n\n        # Use a simpler blit method for drawing if use_quad_draw is False\n        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n            return\n\n        # Set up the viewport and scissor box for rendering\n        gl.glViewport(x, y, self.W if w == 0 else w, self.H if h == 0 else h)\n        gl.glScissor(x, y, self.W if w == 0 else w, self.H if h == 0 else h)\n\n        # Activate the shader program\n        gl.glUseProgram(self.quad_program)\n\n        # Bind the texture for rendering\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Draw the quadrilateral using vertex data\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        # Restore the viewport and scissor box to their original sizes\n        gl.glViewport(0, 0, self.W, self.H)\n        gl.glScissor(0, 0, self.W, self.H)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n            return\n\n        if w == 0: w = self.W\n        if h == 0: h = self.H\n\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        gl.glUseProgram(self.quad_program)\n        gl.glBindVertexArray(self.vao)\n        gl.glActiveTexture(gl.GL_TEXTURE0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        gl.glBindVertexArray(0)\n        gl.glUseProgram(0)\n\n        gl.glViewport(0, 0, self.W, self.H)\n        gl.glScissor(0, 0, self.W, self.H)"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "\n    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    ixt = get_ndc_perspective_matrix(K, H, W, n[..., 0], f[..., 0]).to(xyz.dtype)  # to opengl, remove last dim of n and f\n    w2c = affine_padding(torch.cat([R, T], dim=-1)).to(xyz.dtype)\n    c2w = affine_inverse(w2c)\n    c2w[..., 0] *= 1  # flip x\n    c2w[..., 1] *= -1  # flip y\n    c2w[..., 2] *= -1  # flip z\n    ext = affine_inverse(c2w)\n    pix_xyz = torch.cat([xyz, torch.ones_like(xyz[..., :1])], dim=-1) @ ext.mT @ ixt.mT\n    pix_rad = abs(H * ixt[..., 1, 1][..., None, None] * rad / pix_xyz[..., -1:])  # z: B, 1 * B, N, world space radius -> ndc radius B, N, 1\n\n    # Prepare data to be rendered\n    data = torch.cat([pix_xyz, rgb, pix_rad], dim=-1).ravel()  # organize the data inside vbo\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "\n    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    ixt = get_ndc_perspective_matrix(K, H, W, n[..., 0], f[..., 0]).to(xyz.dtype)  # to opengl, remove last dim of n and f\n    w2c = affine_padding(torch.cat([R, T], dim=-1)).to(xyz.dtype)\n    c2w = affine_inverse(w2c)\n    c2w[..., 0] *= 1  # flip x\n    c2w[..., 1] *= -1  # flip y\n    c2w[..., 2] *= -1  # flip z\n    ext = affine_inverse(c2w)\n    pix_xyz = torch.cat([xyz, torch.ones_like(xyz[..., :1])], dim=-1) @ ext.mT @ ixt.mT\n    pix_rad = abs(H * ixt[..., 1, 1][..., None, None] * rad / pix_xyz[..., -1:])  # z: B, 1 * B, N, world space radius -> ndc radius B, N, 1\n\n    # Prepare data to be rendered\n    data = torch.cat([pix_xyz, rgb, pix_rad], dim=-1).ravel()  # organize the data inside vbo\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "\n    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    ixt = get_ndc_perspective_matrix(K, H, W, n[..., 0], f[..., 0]).to(xyz.dtype)  # to opengl, remove last dim of n and f\n    w2c = affine_padding(torch.cat([R, T], dim=-1)).to(xyz.dtype)\n    c2w = affine_inverse(w2c)\n    c2w[..., 0] *= 1  # flip x\n    c2w[..., 1] *= -1  # flip y\n    c2w[..., 2] *= -1  # flip z\n    ext = affine_inverse(c2w)\n    pix_xyz = torch.cat([xyz, torch.ones_like(xyz[..., :1])], dim=-1) @ ext.mT @ ixt.mT\n    pix_rad = abs(H * ixt[..., 1, 1][..., None, None] * rad / pix_xyz[..., -1:])  # z: B, 1 * B, N, world space radius -> ndc radius B, N, 1\n\n    # Prepare data to be rendered\n    data = torch.cat([pix_xyz, rgb, pix_rad], dim=-1).ravel()  # organize the data inside vbo\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "\n    H, W, K, R, T, C = get_opencv_camera_params(batch)\n\n    # Adjust rotation matrix\n    R = R.permute(0, 2, 1)  # Transpose R to match PyTorch3D's requirements\n\n    # Adjust translation vector\n    T = -torch.bmm(R, T)  # Apply the transpose of R to T\n\n    # Compute intrinsic matrix for normalized device coordinates (NDC)\n    ndc_K = get_pytorch3d_ndc_K(K, H, W)\n\n    return H, W, ndc_K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "\n    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    ixt = get_ndc_perspective_matrix(K, H, W, n[..., 0], f[..., 0]).to(xyz.dtype)  # to opengl, remove last dim of n and f\n    w2c = affine_padding(torch.cat([R, T], dim=-1)).to(xyz.dtype)\n    c2w = affine_inverse(w2c)\n    c2w[..., 0] *= 1  # flip x\n    c2w[..., 1] *= -1  # flip y\n    c2w[..., 2] *= -1  # flip z\n    ext = affine_inverse(c2w)\n    pix_xyz = torch.cat([xyz, torch.ones_like(xyz[..., :1])], dim=-1) @ ext.mT @ ixt.mT\n    pix_rad = abs(H * ixt[..., 1, 1][..., None, None] * rad / pix_xyz[..., -1:])  # z: B, 1 * B, N, world space radius -> ndc radius B, N, 1\n\n    # Prepare data to be rendered\n    data = torch.cat([pix_xyz, rgb, pix_rad], dim=-1).ravel()  # organize the data inside vbo\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "\n    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    ixt = get_ndc_perspective_matrix(K, H, W, n[..., 0], f[..., 0]).to(xyz.dtype)  # to opengl, remove last dim of n and f\n    w2c = affine_padding(torch.cat([R, T], dim=-1)).to(xyz.dtype)\n    c2w = affine_inverse(w2c)\n    c2w[..., 0] *= 1  # flip x\n    c2w[..., 1] *= -1  # flip y\n    c2w[..., 2] *= -1  # flip z\n    ext = affine_inverse(c2w)\n    pix_xyz = torch.cat([xyz, torch.ones_like(xyz[..., :1])], dim=-1) @ ext.mT @ ixt.mT\n    pix_rad = abs(H * ixt[..., 1, 1][..., None, None] * rad / pix_xyz[..., -1:])  # z: B, 1 * B, N, world space radius -> ndc radius B, N, 1\n\n    # Prepare data to be rendered\n    data = torch.cat([pix_xyz, rgb, pix_rad], dim=-1).ravel()  # organize the data inside vbo\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "\n    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    ixt = get_ndc_perspective_matrix(K, H, W, n[..., 0], f[..., 0]).to(xyz.dtype)  # to opengl, remove last dim of n and f\n    w2c = affine_padding(torch.cat([R, T], dim=-1)).to(xyz.dtype)\n    c2w = affine_inverse(w2c)\n    c2w[..., 0] *= 1  # flip x\n    c2w[..., 1] *= -1  # flip y\n    c2w[..., 2] *= -1  # flip z\n    ext = affine_inverse(c2w)\n    pix_xyz = torch.cat([xyz, torch.ones_like(xyz[..., :1])], dim=-1) @ ext.mT @ ixt.mT\n    pix_rad = abs(H * ixt[..., 1, 1][..., None, None] * rad / pix_xyz[..., -1:])  # z: B, 1 * B, N, world space radius -> ndc radius B, N, 1\n\n    # Prepare data to be rendered\n    data = torch.cat([pix_xyz, rgb, pix_rad], dim=-1).ravel()  # organize the data inside vbo\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H, W, K, R, T, C = get_opencv_camera_params(batch)\n    K = get_pytorch3d_ndc_K(K, H, W)\n    R = R.permute(0, 2, 1)  # Transpose the rotation matrix\n    T = -torch.bmm(R, T)  # Adjust the translation vector\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "\n    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n\n    # Adjust the intrinsic matrix for NDC\n    ndc_K = get_pytorch3d_ndc_K(K, H, W)\n\n    return H, W, ndc_K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "\n    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    ixt = get_ndc_perspective_matrix(K, H, W, n[..., 0], f[..., 0]).to(xyz.dtype)  # to opengl, remove last dim of n and f\n    w2c = affine_padding(torch.cat([R, T], dim=-1)).to(xyz.dtype)\n    c2w = affine_inverse(w2c)\n    c2w[..., 0] *= 1  # flip x\n    c2w[..., 1] *= -1  # flip y\n    c2w[..., 2] *= -1  # flip z\n    ext = affine_inverse(c2w)\n    pix_xyz = torch.cat([xyz, torch.ones_like(xyz[..., :1])], dim=-1) @ ext.mT @ ixt.mT\n    pix_rad = abs(H * ixt[..., 1, 1][..., None, None] * rad / pix_xyz[..., -1:])  # z: B, 1 * B, N, world space radius -> ndc radius B, N, 1\n\n    # Prepare data to be rendered\n    data = torch.cat([pix_xyz, rgb, pix_rad], dim=-1).ravel()  # organize the data inside vbo\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "\n    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    ixt = get_ndc_perspective_matrix(K, H, W, n[..., 0], f[..., 0]).to(xyz.dtype)  # to opengl, remove last dim of n and f\n    w2c = affine_padding(torch.cat([R, T], dim=-1)).to(xyz.dtype)\n    c2w = affine_inverse(w2c)\n    c2w[..., 0] *= 1  # flip x\n    c2w[..., 1] *= -1  # flip y\n    c2w[..., 2] *= -1  # flip z\n    ext = affine_inverse(c2w)\n    pix_xyz = torch.cat([xyz, torch.ones_like(xyz[..., :1])], dim=-1) @ ext.mT @ ixt.mT\n    pix_rad = abs(H * ixt[..., 1, 1][..., None, None] * rad / pix_xyz[..., -1:])  # z: B, 1 * B, N, world space radius -> ndc radius B, N, 1\n\n    # Prepare data to be rendered\n    data = torch.cat([pix_xyz, rgb, pix_rad], dim=-1).ravel()  # organize the data inside vbo\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "\n    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n\n    # Adjusting the intrinsic matrix for NDC\n    ndc_K = get_pytorch3d_ndc_K(K, H, W)\n\n    return H, W, ndc_K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "\n    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    ixt = get_ndc_perspective_matrix(K, H, W, n[..., 0], f[..., 0]).to(xyz.dtype)  # to opengl, remove last dim of n and f\n    w2c = affine_padding(torch.cat([R, T], dim=-1)).to(xyz.dtype)\n    c2w = affine_inverse(w2c)\n    c2w[..., 0] *= 1  # flip x\n    c2w[..., 1] *= -1  # flip y\n    c2w[..., 2] *= -1  # flip z\n    ext = affine_inverse(c2w)\n    pix_xyz = torch.cat([xyz, torch.ones_like(xyz[..., :1])], dim=-1) @ ext.mT @ ixt.mT\n    pix_rad = abs(H * ixt[..., 1, 1][..., None, None] * rad / pix_xyz[..., -1:])  # z: B, 1 * B, N, world space radius -> ndc radius B, N, 1\n\n    # Prepare data to be rendered\n    data = torch.cat([pix_xyz, rgb, pix_rad], dim=-1).ravel()  # organize the data inside vbo\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "\n    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "\n    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    ixt = get_ndc_perspective_matrix(K, H, W, n[..., 0], f[..., 0]).to(xyz.dtype)  # to opengl, remove last dim of n and f\n    w2c = affine_padding(torch.cat([R, T], dim=-1)).to(xyz.dtype)\n    c2w = affine_inverse(w2c)\n    c2w[..., 0] *= 1  # flip x\n    c2w[..., 1] *= -1  # flip y\n    c2w[..., 2] *= -1  # flip z\n    ext = affine_inverse(c2w)\n    pix_xyz = torch.cat([xyz, torch.ones_like(xyz[..., :1])], dim=-1) @ ext.mT @ ixt.mT\n    pix_rad = abs(H * ixt[..., 1, 1][..., None, None] * rad / pix_xyz[..., -1:])  # z: B, 1 * B, N, world space radius -> ndc radius B, N, 1\n\n    # Prepare data to be rendered\n    data = torch.cat([pix_xyz, rgb, pix_rad], dim=-1).ravel()  # organize the data inside vbo\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "\n    H, W, K, R, T, C = get_opencv_camera_params(batch)\n\n    # Adjust rotation matrix\n    R = R.permute(0, 2, 1)  # Transpose R to match PyTorch3D's requirements\n\n    # Adjust translation vector\n    T = -torch.bmm(R, T)  # Apply the transposed R to T\n\n    # Compute intrinsic matrix for normalized device coordinates (NDC)\n    ndc_K = get_pytorch3d_ndc_K(K, H, W)\n\n    return H, W, ndc_K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H, W, K, R, T, C = get_opencv_camera_params(batch)\n    K = get_pytorch3d_ndc_K(K, H, W)\n    R = R.permute(0, 2, 1)  # Transpose R\n    T = -torch.bmm(R, T)  # Adjust T\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "\n    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H, W, K, R, T, C = get_opencv_camera_params(batch)\n    K = get_pytorch3d_ndc_K(K, H, W)\n    R = R.permute(0, 2, 1)  # Transpose R\n    T = -torch.bmm(R, T)  # Adjust T\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "\n    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)  # render the final content onto screen\n        gl.glReadBuffer(gl.GL_COLOR_ATTACHMENT0)\n        gl.glBlitFramebuffer(x, y, w or self.W, h or self.H, x, y, w or self.W, h or self.H, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        # Move content from write_fbo to screen fbo\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, back_fbo)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)  # render the final content onto screen\n        gl.glReadBuffer(gl.GL_COLOR_ATTACHMENT0)\n        gl.glBlitFramebuffer(0, 0, self.W, self.H, 0, 0, self.W, self.H, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        # Move content from write_fbo to screen fbo\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, back_fbo)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)  # render the final content onto screen\n        gl.glReadBuffer(gl.GL_COLOR_ATTACHMENT0)\n        gl.glBlitFramebuffer(0, 0, self.W, self.H, 0, 0, self.W, self.H, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)  # render the final content onto screen\n        gl.glReadBuffer(gl.GL_COLOR_ATTACHMENT0)\n        gl.glBlitFramebuffer(x, y, w, h, 0, 0, self.W, self.H, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)  # render the final content onto screen\n        gl.glReadBuffer(gl.GL_COLOR_ATTACHMENT0)\n        gl.glBlitFramebuffer(x, y, w or self.W, h or self.H, 0, 0, self.W, self.H, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)  # render the final content onto screen\n        gl.glReadBuffer(gl.GL_COLOR_ATTACHMENT0)\n        gl.glBlitFramebuffer(x, y, w or self.W, h or self.H, x, y, w or self.W, h or self.H, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glReadBuffer(gl.GL_COLOR_ATTACHMENT0)\n        gl.glBlitFramebuffer(x, y, w or self.W, h or self.H, 0, 0, self.W, self.H, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)  # render the final content onto screen\n        gl.glReadBuffer(gl.GL_COLOR_ATTACHMENT0)\n        gl.glBlitFramebuffer(x, y, w or self.W, h or self.H, 0, 0, self.W, self.H, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)  # render the final content onto screen\n        gl.glReadBuffer(gl.GL_COLOR_ATTACHMENT0)\n        gl.glBlitFramebuffer(x, y, w, h, 0, 0, self.W, self.H, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        # Move content from write_fbo to screen fbo\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, back_fbo)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)  # render the final content onto screen\n        gl.glReadBuffer(gl.GL_COLOR_ATTACHMENT0)\n        gl.glBlitFramebuffer(0, 0, self.W, self.H, 0, 0, self.W, self.H, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)  # render the final content onto screen\n        gl.glReadBuffer(gl.GL_COLOR_ATTACHMENT0)\n        gl.glBlitFramebuffer(x, y, w, h, 0, 0, self.W, self.H, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)  # render the final content onto screen\n        gl.glReadBuffer(gl.GL_COLOR_ATTACHMENT0)\n        gl.glBlitFramebuffer(x, y, w or self.W, h or self.H, 0, 0, self.W, self.H, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)  # render the final content onto screen\n        gl.glReadBuffer(gl.GL_COLOR_ATTACHMENT0)\n        gl.glBlitFramebuffer(x, y, w or self.W, h or self.H, 0, 0, self.W, self.H, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)  # render the final content onto screen\n        gl.glReadBuffer(gl.GL_COLOR_ATTACHMENT0)\n        gl.glBlitFramebuffer(x, y, w, h, 0, 0, self.W, self.H, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        # Move content from write_fbo to screen fbo\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)  # render the final content onto screen\n        gl.glReadBuffer(gl.GL_COLOR_ATTACHMENT0)\n        gl.glBlitFramebuffer(0, 0, self.W, self.H, 0, 0, self.W, self.H, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)  # render the final content onto screen\n        gl.glReadBuffer(gl.GL_COLOR_ATTACHMENT0)\n        gl.glBlitFramebuffer(x, y, w or self.W, h or self.H, 0, 0, self.W, self.H, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)  # render the final content onto screen\n        gl.glReadBuffer(gl.GL_COLOR_ATTACHMENT0)\n        gl.glBlitFramebuffer(x, y, w, h, 0, 0, self.W, self.H, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)  # render the final content onto screen\n        gl.glReadBuffer(gl.GL_COLOR_ATTACHMENT0)\n        gl.glBlitFramebuffer(x, y, w or self.W, h or self.H, 0, 0, self.W, self.H, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        # Move content from write_fbo to screen fbo\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.write_fbo)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)  # render the final content onto screen\n        gl.glReadBuffer(gl.GL_COLOR_ATTACHMENT0)\n        gl.glBlitFramebuffer(x, y, w, h, 0, 0, self.W, self.H, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)  # render the final content onto screen\n        gl.glReadBuffer(gl.GL_COLOR_ATTACHMENT0)\n        gl.glBlitFramebuffer(x, y, w or self.W, h or self.H, 0, 0, self.W, self.H, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Calculate the cumulative sum of y1\n    y1_cumsum = torch.cumsum(y1, dim=-1)\n\n    # Find the indices of the closest values in t1 to t0\n    idx = searchsorted(t1, t0)\n\n    # Calculate the inner measure\n    inner_measure = y1_cumsum.gather(dim=-1, index=idx)\n\n    # Calculate the outer measure\n    outer_measure = torch.cat([torch.zeros_like(inner_measure[..., :1]), y1_cumsum], dim=-1).gather(dim=-1, index=idx)\n\n    return inner_measure, outer_measure"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    t0, t1 = t0.unsqueeze(-1), t1.unsqueeze(-1)\n    t_diff = t0 - t1\n    t_diff = torch.where(t_diff >= 0, t_diff, torch.tensor(0.0, device=t_diff.device))\n    y1 = y1.unsqueeze(-1)\n    w_inner = torch.cumsum(y1 * t_diff, dim=-1)\n    w_outer = torch.cumsum(y1 * (t0 - t1), dim=-1)\n    return w_inner, w_outer"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Calculate the cumulative sum of the values\n    cumsum_y1 = torch.cumsum(y1, dim=-1)\n\n    # Interpolate the cumulative sum at the target time t0\n    inner_measure = torch.interp(t0, t1, cumsum_y1)\n\n    # Calculate the outer measure as the cumulative sum at the last time step\n    outer_measure = cumsum_y1[..., -1]\n\n    return inner_measure, outer_measure"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    t1 = t1.unsqueeze(0)\n    y1 = y1.unsqueeze(0)\n    t0 = t0.unsqueeze(1)\n    t1 = t1.unsqueeze(2)\n    y1 = y1.unsqueeze(2)\n\n    # Constructing the inner measure\n    t_diff_inner = t0 - t1\n    t_diff_inner = torch.clamp(t_diff_inner, min=0)\n    inner_measure = torch.sum(y1 * t_diff_inner, dim=1)\n\n    # Constructing the outer measure\n    t_diff_outer = t0 - t1\n    t_diff_outer = torch.clamp(t_diff_outer, max=0)\n    outer_measure = torch.sum(y1 * t_diff_outer, dim=1)\n\n    return inner_measure, outer_measure"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    t0, t1 = t0.unsqueeze(-1), t1.unsqueeze(-1)\n    t0, t1 = t0.expand(-1, -1, t1.shape[-1]), t1.expand(-1, -1, t0.shape[-1])\n    y1 = y1.unsqueeze(-1).expand(-1, -1, t0.shape[-1])\n\n    # Inner measure\n    t0_t1 = t0 - t1\n    t1_t0 = t1 - t0\n    inner = torch.sum(torch.relu(t0_t1) * y1, dim=1)\n\n    # Outer measure\n    outer = torch.cumsum(torch.relu(t1_t0) * y1, dim=1)\n\n    return inner, outer"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    t0, t1 = t0.unsqueeze(-1), t1.unsqueeze(-1)\n    dt0 = t0[..., 1:] - t0[..., :-1]\n    dt1 = t1[..., 1:] - t1[..., :-1]\n    y1 = (y1[..., 1:] + y1[..., :-1]) / 2 * dt1\n    y1 = torch.cumsum(y1, dim=-1)\n    y0 = torch.zeros_like(t0)\n    for i in range(t0.shape[-1]):\n        idx = searchsorted(t1, t0[..., i], side='right')\n        y0[..., i] = y1[..., idx - 1]\n    y0 = torch.cumsum(y0 * dt0, dim=-1)\n    return y0, y1"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    t0, t1 = t0.unsqueeze(-1), t1.unsqueeze(-1)\n    t_diff = t0 - t1\n    t_diff_sign = torch.sign(t_diff)\n    y1 = y1.unsqueeze(-1)\n\n    t_diff_sign_padded = F.pad(t_diff_sign, (0, 1), value=1)\n    y1_padded = F.pad(y1, (0, 1), value=0)\n\n    cumsum_y1 = torch.cumsum(y1_padded * t_diff_sign_padded, dim=-1)\n    inner = cumsum_y1[..., :-1]\n    outer = cumsum_y1[..., 1:]\n\n    return inner, outer"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    t0, t1 = t0.unsqueeze(-1), t1.unsqueeze(-1)\n    t_diff = t0 - t1\n    t_diff = torch.where(t_diff >= 0, t_diff, torch.tensor(0.0))\n    y1 = y1.unsqueeze(-1)\n    inner = torch.cumsum(y1 * t_diff, dim=1)\n    outer = torch.cumsum(y1 * (t0 - t1), dim=1)\n    return inner, outer"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Calculate the cumulative sum of the source values\n    cumsum_y1 = torch.cumsum(y1, dim=-1)\n\n    # Interpolate the cumulative sum of source values at the target times\n    t0 = t0.unsqueeze(-1)\n    t1 = t1.unsqueeze(-1)\n    cumsum_y1 = cumsum_y1.unsqueeze(-2)\n    t1_prev = t1[..., :-1]\n    t1_next = t1[..., 1:]\n    cumsum_y1_prev = cumsum_y1[..., :-1]\n    cumsum_y1_next = cumsum_y1[..., 1:]\n\n    # Linear interpolation\n    w_inner = ((t1_next - t0) * cumsum_y1_prev + (t0 - t1_prev) * cumsum_y1_next) / (t1_next - t1_prev)\n\n    # Calculate the outer measure\n    w_outer = cumsum_y1[..., -1]\n\n    return w_inner, w_outer"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    t1, indices = t1.sort(dim=-1)\n    y1 = y1.take_along_dim(indices, dim=-1)\n    t1 = t1.unsqueeze(-2)\n    y1 = y1.unsqueeze(-2)\n    t0 = t0.unsqueeze(-1)\n    inner = ((t0 - t1).clamp(0) * y1).sum(dim=-1)\n    outer = inner.cummax(dim=-1).values\n    return inner, outer"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    t0, t1 = t0.unsqueeze(-1), t1.unsqueeze(-2)\n    dt = t0 - t1\n    dt = torch.where(dt < 0, torch.tensor(1e6, dtype=dt.dtype, device=dt.device), dt)\n    w = 1.0 / dt\n    w = w / w.sum(dim=-1, keepdim=True)\n    w_outer = torch.sum(w * y1, dim=-1)\n    return y1, w_outer"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    \n    # Construct inner measure\n    t0, t1 = t0.unsqueeze(-1), t1.unsqueeze(-1)\n    t_diff = t0 - t1\n    t_diff = torch.where(t_diff < 0, torch.tensor(0.0), t_diff)\n    inner_measure = (y1 * t_diff).cumsum(dim=-1)\n\n    # Construct outer measure\n    t_diff = t1 - t0\n    t_diff = torch.where(t_diff < 0, torch.tensor(0.0), t_diff)\n    outer_measure = (y1 * t_diff).cumsum(dim=-1)\n\n    return inner_measure, outer_measure"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    t0, t1 = t0.unsqueeze(-1), t1.unsqueeze(-1)\n    t_diff = t0 - t1\n    t_diff = torch.where(t_diff < 0, torch.tensor(0.0), t_diff)\n    y1 = y1.unsqueeze(-1)\n    w_inner = torch.cumsum(y1 * t_diff, dim=-1)\n    w_outer = torch.cumsum(y1 * (t0 - t1), dim=-1)\n    return w_inner, w_outer"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Cumulative sum of the source values\n    y1_cumsum = torch.cumsum(y1, dim=-1)\n\n    # Linear interpolation for the inner measure\n    t0_expanded = t0.unsqueeze(-1)\n    t1_expanded = t1.unsqueeze(-2)\n    inner = (y1_cumsum[..., :-1] * (t1_expanded - t0_expanded) + y1_cumsum[..., 1:] * (t0_expanded - t1_expanded)) / (t1_expanded - t0_expanded)\n\n    # Outer measure is the maximum of the source values\n    outer = torch.max(y1_cumsum, dim=-1).values\n\n    return inner, outer"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    t0, t1 = t0.unsqueeze(-1), t1.unsqueeze(-1)\n    t_diff = t0 - t1\n    t_diff = torch.clamp(t_diff, min=0)\n    y1 = y1.unsqueeze(-1)\n    w_inner = ((t1 < t0).float() * y1).sum(dim=1)\n    w_outer = ((t1 <= t0).float() * y1).sum(dim=1)\n    return w_inner, w_outer"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # compute the cumulative sum of y1\n    y1_cumsum = torch.cumsum(y1, dim=-1)\n\n    # find the indices where t0 is greater than or equal to t1\n    indices = torch.sum(t0[..., None] >= t1, dim=-1) - 1\n\n    # compute the inner measure\n    inner_measure = y1_cumsum.gather(dim=-1, index=indices.unsqueeze(-1)).squeeze(-1)\n\n    # compute the outer measure\n    outer_measure = y1_cumsum.gather(dim=-1, index=indices.unsqueeze(-1) + 1).squeeze(-1)\n\n    return inner_measure, outer_measure"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    t0, t1 = t0.unsqueeze(-1), t1.unsqueeze(-2)\n    dt = t0 - t1\n    dt = torch.where(dt < 0, torch.tensor(0.0), dt)\n    y1 = y1.unsqueeze(-2)\n    w_inner = torch.cumsum(y1 * dt, dim=-1)\n    w_outer = torch.cumsum(y1 * (t1 < t0), dim=-1)\n    return w_inner, w_outer"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    \n    # Calculate the cumulative sums for t1 and y1\n    cumsum_t1 = torch.cumsum(t1, dim=-1)\n    cumsum_y1 = torch.cumsum(y1, dim=-1)\n    \n    # Interpolate the cumulative sums at t0\n    inner_measure = torch.interp(t0, t1, cumsum_y1)\n    outer_measure = torch.interp(t0, t1, cumsum_t1)\n    \n    return inner_measure, outer_measure"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    t0, t1 = t0.unsqueeze(-1), t1.unsqueeze(-2)\n    dt = t0 - t1\n    dt = dt.clamp(min=0)\n    y1 = y1.unsqueeze(-2)\n    w_inner = (y1 * dt).cumsum(dim=-1) / t0\n    w_outer = w_inner.max(dim=-1).values\n    return w_inner, w_outer"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "\n    # Compute the cumulative sum of the source values\n    y1_cumsum = torch.cumsum(y1, dim=-1)\n\n    # Interpolate the cumulative sum at the target times\n    y1_interp = torch.interp(t0, t1, y1_cumsum)\n\n    # Compute the inner measure\n    inner_measure = y1_interp\n\n    # Compute the outer measure\n    outer_measure = torch.maximum(y1_cumsum, dim=-1).values\n\n    return inner_measure, outer_measure"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "\n    t, w = matchup_channels(t, w)\n    t_env, w_env = matchup_channels(t_env, w_env)\n\n    w_normalize = w / torch.clamp_min(t[..., 1:] - t[..., :-1], eps)\n\n    t_, w_ = blur_stepfun(t, w_normalize, pulse_width)\n    w_ = torch.clip(w_, min=0.)\n    assert (w_ >= 0.0).all()\n\n    # piecewise linear pdf to piecewise quadratic cdf\n    area = 0.5 * (w_[..., 1:] + w_[..., :-1]) * (t_[..., 1:] - t_[..., :-1])\n\n    cdf = torch.cat([torch.zeros_like(area[..., :1]), torch.cumsum(area, dim=-1)], dim=-1)\n\n    # query piecewise quadratic interpolation\n    cdf_interp = sorted_interp_quad(t_env, t_, w_, cdf)\n    # difference between adjacent interpolated values\n    w_s = torch.diff(cdf_interp, dim=-1)\n\n    return ((w_s - w_env).clip(0.).pow(2) / (w_env + eps)).mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "\n    t, w = matchup_channels(t, w)\n    t_env, w_env = matchup_channels(t_env, w_env)\n\n    w_normalize = w / torch.clamp_min(t[..., 1:] - t[..., :-1], eps)\n\n    t_, w_ = blur_stepfun(t, w_normalize, pulse_width)\n    w_ = torch.clip(w_, min=0.)\n    assert (w_ >= 0.0).all()\n\n    # piecewise linear pdf to piecewise quadratic cdf\n    area = 0.5 * (w_[..., 1:] + w_[..., :-1]) * (t_[..., 1:] - t_[..., :-1])\n\n    cdf = torch.cat([torch.zeros_like(area[..., :1]), torch.cumsum(area, dim=-1)], dim=-1)\n\n    # query piecewise quadratic interpolation\n    cdf_interp = sorted_interp_quad(t_env, t_, w_, cdf)\n    # difference between adjacent interpolated values\n    w_s = torch.diff(cdf_interp, dim=-1)\n\n    return ((w_s - w_env).clip(0.).pow(2) / (w_env + eps)).mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "\n    # Calculate the outer measures\n    y0_inner, y0_outer = inner_outer(t, t_env, w_env)\n\n    # Calculate the loss based on the difference between target weights and the upper envelope\n    loss = ((w - y0_outer).clamp(0).pow(2) / (y0_outer + eps)).mean()\n\n    return loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "\n    t, w = matchup_channels(t, w)\n    t_env, w_env = matchup_channels(t_env, w_env)\n\n    w_normalize = w / torch.clamp_min(t[..., 1:] - t[..., :-1], eps)\n\n    t_, w_ = blur_stepfun(t, w_normalize, pulse_width)\n    w_ = torch.clip(w_, min=0.)\n    assert (w_ >= 0.0).all()\n\n    # piecewise linear pdf to piecewise quadratic cdf\n    area = 0.5 * (w_[..., 1:] + w_[..., :-1]) * (t_[..., 1:] - t_[..., :-1])\n\n    cdf = torch.cat([torch.zeros_like(area[..., :1]), torch.cumsum(area, dim=-1)], dim=-1)\n\n    # query piecewise quadratic interpolation\n    cdf_interp = sorted_interp_quad(t_env, t_, w_, cdf)\n    # difference between adjacent interpolated values\n    w_s = torch.diff(cdf_interp, dim=-1)\n\n    return ((w_s - w_env).clip(0.).pow(2) / (w_env + eps)).mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    t, w = matchup_channels(t, w)\n    t_env, w_env = matchup_channels(t_env, w_env)\n\n    w_normalize = w / torch.clamp_min(t[..., 1:] - t[..., :-1], eps)\n\n    t_, w_ = blur_stepfun(t, w_normalize, pulse_width)\n    w_ = torch.clip(w_, min=0.)\n    assert (w_ >= 0.0).all()\n\n    # piecewise linear pdf to piecewise quadratic cdf\n    area = 0.5 * (w_[..., 1:] + w_[..., :-1]) * (t_[..., 1:] - t_[..., :-1])\n\n    cdf = torch.cat([torch.zeros_like(area[..., :1]), torch.cumsum(area, dim=-1)], dim=-1)\n\n    # query piecewise quadratic interpolation\n    cdf_interp = sorted_interp_quad(t_env, t_, w_, cdf)\n    # difference between adjacent interpolated values\n    w_s = torch.diff(cdf_interp, dim=-1)\n\n    return ((w_s - w_env).clip(0.).pow(2) / (w_env + eps)).mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    t, w = matchup_channels(t, w)\n    t_env, w_env = matchup_channels(t_env, w_env)\n\n    w_normalize = w / torch.clamp_min(t[..., 1:] - t[..., :-1], eps)\n\n    t_, w_ = blur_stepfun(t, w_normalize, pulse_width)\n    w_ = torch.clip(w_, min=0.)\n    assert (w_ >= 0.0).all()\n\n    # piecewise linear pdf to piecewise quadratic cdf\n    area = 0.5 * (w_[..., 1:] + w_[..., :-1]) * (t_[..., 1:] - t_[..., :-1])\n\n    cdf = torch.cat([torch.zeros_like(area[..., :1]), torch.cumsum(area, dim=-1)], dim=-1)\n\n    # query piecewise quadratic interpolation\n    cdf_interp = sorted_interp_quad(t_env, t_, w_, cdf)\n    # difference between adjacent interpolated values\n    w_s = torch.diff(cdf_interp, dim=-1)\n\n    return ((w_s - w_env).clip(0.).pow(2) / (w_env + eps)).mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "\n    # Compute the normalized weights\n    w_normalize = w / torch.clamp_min(t[..., 1:] - t[..., :-1], eps)\n\n    # Calculate the upper envelope weights using blur_stepfun\n    t_, w_ = blur_stepfun(t, w_normalize, 1.0)\n    w_ = torch.clip(w_, min=0.)\n\n    # Calculate the piecewise linear pdf to piecewise quadratic cdf\n    area = 0.5 * (w_[..., 1:] + w_[..., :-1]) * (t_[..., 1:] - t_[..., :-1])\n    cdf = torch.cat([torch.zeros_like(area[..., :1]), torch.cumsum(area, dim=-1)], dim=-1)\n\n    # Query piecewise quadratic interpolation\n    cdf_interp = sorted_interp_quad(t_env, t_, w_, cdf)\n\n    # Calculate the difference between adjacent interpolated values\n    w_s = torch.diff(cdf_interp, dim=-1)\n\n    # Calculate the loss based on the difference between target weights and the upper envelope, scaled by a half-quadratic loss function\n    loss = ((w_s - w_env).clip(0.).pow(2) / (w_env + eps)).mean()\n\n    return loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "\n    t, w = matchup_channels(t, w)\n    t_env, w_env = matchup_channels(t_env, w_env)\n\n    w_normalize = w / torch.clamp_min(t[..., 1:] - t[..., :-1], eps)\n\n    t_, w_ = blur_stepfun(t, w_normalize, pulse_width)\n    w_ = torch.clip(w_, min=0.)\n    assert (w_ >= 0.0).all()\n\n    # piecewise linear pdf to piecewise quadratic cdf\n    area = 0.5 * (w_[..., 1:] + w_[..., :-1]) * (t_[..., 1:] - t_[..., :-1])\n\n    cdf = torch.cat([torch.zeros_like(area[..., :1]), torch.cumsum(area, dim=-1)], dim=-1)\n\n    # query piecewise quadratic interpolation\n    cdf_interp = sorted_interp_quad(t_env, t_, w_, cdf)\n    # difference between adjacent interpolated values\n    w_s = torch.diff(cdf_interp, dim=-1)\n\n    return ((w_s - w_env).clip(0.).pow(2) / (w_env + eps)).mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "\n    t, w = matchup_channels(t, w)\n    t_env, w_env = matchup_channels(t_env, w_env)\n\n    w_normalize = w / torch.clamp_min(t[..., 1:] - t[..., :-1], eps)\n\n    t_, w_ = blur_stepfun(t, w_normalize, pulse_width)\n    w_ = torch.clip(w_, min=0.)\n    assert (w_ >= 0.0).all()\n\n    # piecewise linear pdf to piecewise quadratic cdf\n    area = 0.5 * (w_[..., 1:] + w_[..., :-1]) * (t_[..., 1:] - t_[..., :-1])\n\n    cdf = torch.cat([torch.zeros_like(area[..., :1]), torch.cumsum(area, dim=-1)], dim=-1)\n\n    # query piecewise quadratic interpolation\n    cdf_interp = sorted_interp_quad(t_env, t_, w_, cdf)\n    # difference between adjacent interpolated values\n    w_s = torch.diff(cdf_interp, dim=-1)\n\n    return ((w_s - w_env).clip(0.).pow(2) / (w_env + eps)).mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    t, w = matchup_channels(t, w)\n    t_env, w_env = matchup_channels(t_env, w_env)\n\n    w_normalize = w / torch.clamp_min(t[..., 1:] - t[..., :-1], eps)\n\n    t_, w_ = blur_stepfun(t, w_normalize, pulse_width)\n    w_ = torch.clip(w_, min=0.)\n    assert (w_ >= 0.0).all()\n\n    # piecewise linear pdf to piecewise quadratic cdf\n    area = 0.5 * (w_[..., 1:] + w_[..., :-1]) * (t_[..., 1:] - t_[..., :-1])\n\n    cdf = torch.cat([torch.zeros_like(area[..., :1]), torch.cumsum(area, dim=-1)], dim=-1)\n\n    # query piecewise quadratic interpolation\n    cdf_interp = sorted_interp_quad(t_env, t_, w_, cdf)\n    # difference between adjacent interpolated values\n    w_s = torch.diff(cdf_interp, dim=-1)\n\n    return ((w_s - w_env).clip(0.).pow(2) / (w_env + eps)).mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    t, w = matchup_channels(t, w)\n    t_env, w_env = matchup_channels(t_env, w_env)\n\n    w_normalize = w / torch.clamp_min(t[..., 1:] - t[..., :-1], eps)\n\n    t_, w_ = blur_stepfun(t, w_normalize, pulse_width)\n    w_ = torch.clip(w_, min=0.)\n    assert (w_ >= 0.0).all()\n\n    # piecewise linear pdf to piecewise quadratic cdf\n    area = 0.5 * (w_[..., 1:] + w_[..., :-1]) * (t_[..., 1:] - t_[..., :-1])\n\n    cdf = torch.cat([torch.zeros_like(area[..., :1]), torch.cumsum(area, dim=-1)], dim=-1)\n\n    # query piecewise quadratic interpolation\n    cdf_interp = sorted_interp_quad(t_env, t_, w_, cdf)\n    # difference between adjacent interpolated values\n    w_s = torch.diff(cdf_interp, dim=-1)\n\n    return ((w_s - w_env).clip(0.).pow(2) / (w_env + eps)).mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "\n    t, w = matchup_channels(t, w)\n    t_env, w_env = matchup_channels(t_env, w_env)\n\n    w_normalize = w / torch.clamp_min(t[..., 1:] - t[..., :-1], eps)\n\n    t_, w_ = blur_stepfun(t, w_normalize, pulse_width)\n    w_ = torch.clip(w_, min=0.)\n    assert (w_ >= 0.0).all()\n\n    # piecewise linear pdf to piecewise quadratic cdf\n    area = 0.5 * (w_[..., 1:] + w_[..., :-1]) * (t_[..., 1:] - t_[..., :-1])\n\n    cdf = torch.cat([torch.zeros_like(area[..., :1]), torch.cumsum(area, dim=-1)], dim=-1)\n\n    # query piecewise quadratic interpolation\n    cdf_interp = sorted_interp_quad(t_env, t_, w_, cdf)\n    # difference between adjacent interpolated values\n    w_s = torch.diff(cdf_interp, dim=-1)\n\n    return ((w_s - w_env).clip(0.).pow(2) / (w_env + eps)).mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "\n    # Compute the normalized weights\n    w_normalize = w / torch.clamp_min(t[..., 1:] - t[..., :-1], eps)\n\n    # Blur the step function\n    t_, w_ = blur_stepfun(t, w_normalize, pulse_width)\n\n    # Ensure the weights are non-negative\n    w_ = torch.clip(w_, min=0.)\n\n    # Compute the piecewise linear pdf to piecewise quadratic cdf\n    area = 0.5 * (w_[..., 1:] + w_[..., :-1]) * (t_[..., 1:] - t_[..., :-1])\n    cdf = torch.cat([torch.zeros_like(area[..., :1]), torch.cumsum(area, dim=-1)], dim=-1)\n\n    # Query piecewise quadratic interpolation\n    cdf_interp = sorted_interp_quad(t_env, t_, w_, cdf)\n\n    # Compute the difference between adjacent interpolated values\n    w_s = torch.diff(cdf_interp, dim=-1)\n\n    # Calculate the loss\n    loss = ((w_s - w_env).clip(0.).pow(2) / (w_env + eps)).mean()\n\n    return loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    t, w = matchup_channels(t, w)\n    t_env, w_env = matchup_channels(t_env, w_env)\n\n    w_normalize = w / torch.clamp_min(t[..., 1:] - t[..., :-1], eps)\n\n    t_, w_ = blur_stepfun(t, w_normalize, pulse_width)\n    w_ = torch.clip(w_, min=0.)\n    assert (w_ >= 0.0).all()\n\n    # piecewise linear pdf to piecewise quadratic cdf\n    area = 0.5 * (w_[..., 1:] + w_[..., :-1]) * (t_[..., 1:] - t_[..., :-1])\n\n    cdf = torch.cat([torch.zeros_like(area[..., :1]), torch.cumsum(area, dim=-1)], dim=-1)\n\n    # query piecewise quadratic interpolation\n    cdf_interp = sorted_interp_quad(t_env, t_, w_, cdf)\n    # difference between adjacent interpolated values\n    w_s = torch.diff(cdf_interp, dim=-1)\n\n    return ((w_s - w_env).clip(0.).pow(2) / (w_env + eps)).mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "\n    t, w = matchup_channels(t, w)\n    t_env, w_env = matchup_channels(t_env, w_env)\n\n    w_normalize = w / torch.clamp_min(t[..., 1:] - t[..., :-1], eps)\n\n    t_, w_ = blur_stepfun(t, w_normalize, pulse_width)\n    w_ = torch.clip(w_, min=0.)\n    assert (w_ >= 0.0).all()\n\n    # piecewise linear pdf to piecewise quadratic cdf\n    area = 0.5 * (w_[..., 1:] + w_[..., :-1]) * (t_[..., 1:] - t_[..., :-1])\n\n    cdf = torch.cat([torch.zeros_like(area[..., :1]), torch.cumsum(area, dim=-1)], dim=-1)\n\n    # query piecewise quadratic interpolation\n    cdf_interp = sorted_interp_quad(t_env, t_, w_, cdf)\n    # difference between adjacent interpolated values\n    w_s = torch.diff(cdf_interp, dim=-1)\n\n    return ((w_s - w_env).clip(0.).pow(2) / (w_env + eps)).mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "\n    t, w = matchup_channels(t, w)\n    t_env, w_env = matchup_channels(t_env, w_env)\n\n    w_normalize = w / torch.clamp_min(t[..., 1:] - t[..., :-1], eps)\n\n    t_, w_ = blur_stepfun(t, w_normalize, pulse_width)\n    w_ = torch.clip(w_, min=0.)\n    assert (w_ >= 0.0).all()\n\n    # piecewise linear pdf to piecewise quadratic cdf\n    area = 0.5 * (w_[..., 1:] + w_[..., :-1]) * (t_[..., 1:] - t_[..., :-1])\n\n    cdf = torch.cat([torch.zeros_like(area[..., :1]), torch.cumsum(area, dim=-1)], dim=-1)\n\n    # query piecewise quadratic interpolation\n    cdf_interp = sorted_interp_quad(t_env, t_, w_, cdf)\n    # difference between adjacent interpolated values\n    w_s = torch.diff(cdf_interp, dim=-1)\n\n    return ((w_s - w_env).clip(0.).pow(2) / (w_env + eps)).mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "\n    t, w = matchup_channels(t, w)\n    t_env, w_env = matchup_channels(t_env, w_env)\n\n    w_normalize = w / torch.clamp_min(t[..., 1:] - t[..., :-1], eps)\n\n    t_, w_ = blur_stepfun(t, w_normalize, pulse_width)\n    w_ = torch.clip(w_, min=0.)\n    assert (w_ >= 0.0).all()\n\n    # piecewise linear pdf to piecewise quadratic cdf\n    area = 0.5 * (w_[..., 1:] + w_[..., :-1]) * (t_[..., 1:] - t_[..., :-1])\n\n    cdf = torch.cat([torch.zeros_like(area[..., :1]), torch.cumsum(area, dim=-1)], dim=-1)\n\n    # query piecewise quadratic interpolation\n    cdf_interp = sorted_interp_quad(t_env, t_, w_, cdf)\n    # difference between adjacent interpolated values\n    w_s = torch.diff(cdf_interp, dim=-1)\n\n    return ((w_s - w_env).clip(0.).pow(2) / (w_env + eps)).mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "\n    t, w = matchup_channels(t, w)\n    t_env, w_env = matchup_channels(t_env, w_env)\n\n    w_normalize = w / torch.clamp_min(t[..., 1:] - t[..., :-1], eps)\n\n    t_, w_ = blur_stepfun(t, w_normalize, pulse_width)\n    w_ = torch.clip(w_, min=0.)\n    assert (w_ >= 0.0).all()\n\n    # piecewise linear pdf to piecewise quadratic cdf\n    area = 0.5 * (w_[..., 1:] + w_[..., :-1]) * (t_[..., 1:] - t_[..., :-1])\n\n    cdf = torch.cat([torch.zeros_like(area[..., :1]), torch.cumsum(area, dim=-1)], dim=-1)\n\n    # query piecewise quadratic interpolation\n    cdf_interp = sorted_interp_quad(t_env, t_, w_, cdf)\n    # difference between adjacent interpolated values\n    w_s = torch.diff(cdf_interp, dim=-1)\n\n    return ((w_s - w_env).clip(0.).pow(2) / (w_env + eps)).mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "\n    t, w = matchup_channels(t, w)\n    t_env, w_env = matchup_channels(t_env, w_env)\n\n    w_normalize = w / torch.clamp_min(t[..., 1:] - t[..., :-1], eps)\n\n    t_, w_ = blur_stepfun(t, w_normalize, pulse_width)\n    w_ = torch.clip(w_, min=0.)\n    assert (w_ >= 0.0).all()\n\n    # piecewise linear pdf to piecewise quadratic cdf\n    area = 0.5 * (w_[..., 1:] + w_[..., :-1]) * (t_[..., 1:] - t_[..., :-1])\n\n    cdf = torch.cat([torch.zeros_like(area[..., :1]), torch.cumsum(area, dim=-1)], dim=-1)\n\n    # query piecewise quadratic interpolation\n    cdf_interp = sorted_interp_quad(t_env, t_, w_, cdf)\n    # difference between adjacent interpolated values\n    w_s = torch.diff(cdf_interp, dim=-1)\n\n    return ((w_s - w_env).clip(0.).pow(2) / (w_env + eps)).mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "\n    # Blur the target weights\n    t_, w_ = blur_stepfun(t, w, 1.0)\n\n    # Calculate the upper envelope weights\n    cdf_interp = sorted_interp_quad(t_env, t_, w_, torch.cumsum(0.5 * (w_[..., 1:] + w_[..., :-1]) * (t_[..., 1:] - t_[..., :-1]), dim=-1))\n\n    # Calculate the difference between adjacent interpolated values\n    w_s = torch.diff(cdf_interp, dim=-1)\n\n    # Calculate the loss based on the difference between target weights and the upper envelope, scaled by a half-quadratic loss function\n    return ((w_s - w_env).clamp(0).pow(2) / (w_env + eps)).mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    # Compute the inner and outer measures for t and w\n    t, w = matchup_channels(t, w)\n    t_env, w_env = matchup_channels(t_env, w_env)\n\n    _, w_outer = inner_outer(t, t_env, w_env)\n    w_normalize = w / torch.clamp_min(t[..., 1:] - t[..., :-1], torch.finfo(torch.float32).eps)\n\n    t_, w_ = blur_stepfun(t, w_normalize, pulse_width)\n    w_ = torch.clip(w_, min=0.)\n    assert (w_ >= 0.0).all()\n\n    # Piecewise linear pdf to piecewise quadratic cdf\n    area = 0.5 * (w_[..., 1:] + w_[..., :-1]) * (t_[..., 1:] - t_[..., :-1])\n    cdf = torch.cat([torch.zeros_like(area[..., :1]), torch.cumsum(area, dim=-1)], dim=-1)\n\n    # Query piecewise quadratic interpolation\n    cdf_interp = sorted_interp_quad(t_env, t_, w_, cdf)\n    # Difference between adjacent interpolated values\n    w_s = torch.diff(cdf_interp, dim=-1)\n\n    # Calculate distortion loss\n    distortion_loss = ((w_s - w_env).clip(0.).pow(2) / (w_env + torch.finfo(torch.float32).eps)).mean()\n\n    return distortion_loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    # Calculate the inner and outer measures for t and w\n    t_inner, t_outer = inner_outer(t, w, w)\n    w_inner, w_outer = inner_outer(w, t, t)\n\n    # Compute the inter-interval loss\n    inter_interval_loss = interval_distortion(t_inner, t_outer, w_inner, w_outer)\n\n    # Compute the intra-interval loss\n    intra_interval_loss = lossfun_outer(t, w, t_outer, w_outer, pulse_width=1e-6)\n\n    # Combine the inter-interval and intra-interval losses to get the total distortion loss\n    total_distortion_loss = inter_interval_loss + intra_interval_loss\n\n    return total_distortion_loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    # Compute the inner and outer measures for t and w\n    t, w = matchup_channels(t, w)\n    t_env, w_env = matchup_channels(t_env, w_env)\n    _, w_outer = inner_outer(t, t_env, w_env)\n\n    # Calculate the inter-interval loss\n    inter_interval_loss = (w - w_outer).clip(0.).pow(2) / (w + eps)\n\n    # Calculate the intra-interval loss\n    t_inner, t_outer = inner_outer(t, t, w)\n    w_inner = w_outer\n    intra_interval_loss = interval_distortion(t_inner, t_outer, t_inner, t_outer)\n\n    # Combine the inter-interval and intra-interval losses to get the total distortion loss\n    total_distortion_loss = inter_interval_loss + intra_interval_loss\n\n    return total_distortion_loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    # Calculate the inter-interval loss\n    t_lo = t[..., :-1]\n    t_hi = t[..., 1:]\n    w_lo = w\n    w_hi = w\n    inter_interval_loss = interval_distortion(t_lo, t_hi, t_lo, t_hi)\n\n    # Calculate the intra-interval loss\n    intra_interval_loss = lossfun_outer(t, w, t, w)\n\n    # Combine the inter-interval and intra-interval losses to get the total distortion loss\n    total_distortion_loss = inter_interval_loss + intra_interval_loss\n\n    return total_distortion_loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    # Compute inter-interval loss\n    t_inner, t_outer = inner_outer(t, t, w)\n    w_outer = lossfun_outer(t, w, t_outer, w_outer)\n    inter_loss = torch.mean(w_outer)\n\n    # Compute intra-interval loss\n    w_normalize = w / torch.clamp_min(t[..., 1:] - t[..., :-1], eps)\n    t_, w_ = blur_stepfun(t, w_normalize, pulse_width)\n    w_ = torch.clip(w_, min=0.)\n    w_s = torch.diff(sorted_interp_quad(t, t_, w_, cdf_interp), dim=-1)\n    intra_loss = torch.mean(w_s)\n\n    # Combine inter-interval and intra-interval losses\n    total_loss = inter_loss + intra_loss\n\n    return total_loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    # Calculate the inter-interval loss\n    t_inner, t_outer = inner_outer(t, t, w)\n    w_outer = w\n    inter_loss = lossfun_outer(t, w, t_outer, w_outer)\n\n    # Calculate the intra-interval loss\n    w_env = torch.ones_like(w)\n    pulse_width = 0.1  # Example value, can be adjusted\n    intra_loss = lossfun_zip_outer(t, w, t, w_env, pulse_width)\n\n    # Combine inter-interval and intra-interval losses to get total distortion loss\n    total_loss = inter_loss + intra_loss\n\n    return total_loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    # Compute the inter-interval loss\n    t_inner, t_outer = inner_outer(t[..., :-1], t[..., 1:], w)\n    w_inner, w_outer = inner_outer(w, w, w)\n    inter_loss = lossfun_outer(t_inner, w_inner, t_outer, w_outer)\n\n    # Compute the intra-interval loss\n    intra_loss = interval_distortion(t[..., :-1], t[..., 1:], t[..., :-1], t[..., 1:])\n\n    # Combine the inter-interval and intra-interval losses\n    total_loss = inter_loss + intra_loss\n\n    return total_loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    # Calculate the inter-interval loss\n    t_inner, t_outer = inner_outer(t, t, w)\n    w_inner, w_outer = inner_outer(t, t, w)\n    inter_interval_loss = lossfun_outer(t_inner, w_inner, t_outer, w_outer)\n\n    # Calculate the intra-interval loss\n    pulse_width = 0.1  # Example value for pulse width, can be adjusted\n    intra_interval_loss = lossfun_zip_outer(t, w, t, w, pulse_width)\n\n    # Combine inter-interval and intra-interval losses to get total distortion loss\n    total_distortion_loss = inter_interval_loss + intra_interval_loss\n\n    return total_distortion_loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    # Compute the inner and outer measures\n    t, w = matchup_channels(t, w)\n    t_inner, t_outer = inner_outer(t, t, w)\n\n    # Calculate the inter-interval loss\n    inter_interval_loss = interval_distortion(t_inner[..., :-1], t_outer[..., 1:], t_inner[..., 1:], t_outer[..., :-1])\n\n    # Calculate the intra-interval loss\n    intra_interval_loss = ((w[..., :-1] - w[..., 1:]).abs()).mean()\n\n    # Combine the inter-interval and intra-interval losses to get the total distortion loss\n    total_distortion_loss = inter_interval_loss + intra_interval_loss\n\n    return total_distortion_loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    # Calculate inter-interval loss\n    _, w_outer = inner_outer(t, t, w)\n    inter_interval_loss = (w - w_outer).clip(0.).pow(2)\n\n    # Calculate intra-interval loss\n    w_inner = torch.cat([torch.zeros_like(w[..., :1]), w], dim=-1)\n    w_inner = w_inner[..., 1:] - w_inner[..., :-1]\n    w_inner = w_inner.clip(0.).pow(2)\n\n    # Combine inter-interval and intra-interval losses\n    distortion_loss = inter_interval_loss.mean() + w_inner.mean()\n\n    return distortion_loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    # Calculate the inter-interval loss\n    t_inner, t_outer = inner_outer(t, t, w)\n    inter_loss = interval_distortion(t_inner, t_outer, t, t)\n\n    # Calculate the intra-interval loss\n    w_inner, w_outer = inner_outer(w, w, t)\n    intra_loss = interval_distortion(w_inner, w_outer, w, w)\n\n    # Combine inter-interval and intra-interval losses to produce the total distortion loss\n    total_loss = inter_loss + intra_loss\n    return total_loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    # Calculate the inter-interval loss\n    t_inner, t_outer = inner_outer(t, t, w)\n    w_outer = lossfun_outer(t, w, t_outer, w_outer)\n    inter_interval_loss = torch.mean(w_outer)\n\n    # Calculate the intra-interval loss\n    w_inner = lossfun_outer(t, w, t_inner, w)\n    intra_interval_loss = torch.mean(w_inner)\n\n    # Combine the inter-interval and intra-interval losses to get the total distortion loss\n    total_distortion_loss = inter_interval_loss + intra_interval_loss\n\n    return total_distortion_loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    # Compute the inner and outer measures\n    t, w = matchup_channels(t, w)\n    t_env, w_env = matchup_channels(t_env, w_env)\n\n    _, w_outer = inner_outer(t, t_env, w_env)\n\n    # Calculate the distortion loss\n    distortion_loss = (w - w_outer).clip(0.).pow(2) / (w + eps)\n\n    return distortion_loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    # Compute the inter-interval distortion\n    t_lo = t[..., :-1]\n    t_hi = t[..., 1:]\n    w_lo = w\n    w_hi = w\n    inter_interval_loss = interval_distortion(t_lo, t_hi, t_lo, t_hi)\n\n    # Compute the intra-interval distortion\n    intra_interval_loss = lossfun_outer(t, w, t, w, pulse_width=1e-3)\n\n    # Combine the inter-interval and intra-interval losses\n    total_distortion_loss = inter_interval_loss + intra_interval_loss\n\n    return total_distortion_loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    # Calculate the inter-interval loss\n    t_inner, t_outer = inner_outer(t, t, w)\n    inter_loss = interval_distortion(t_inner[..., :-1], t_outer[..., 1:], t_inner[..., 1:], t_outer[..., :-1])\n\n    # Calculate the intra-interval loss\n    w_normalize = w / torch.clamp_min(t[..., 1:] - t[..., :-1], torch.finfo(torch.float32).eps)\n    t_, w_ = blur_stepfun(t, w_normalize, 1.0)\n    w_ = torch.clip(w_, min=0.)\n    intra_loss = (w_ - w).clip(0.).pow(2).mean()\n\n    # Combine the inter-interval and intra-interval losses to get the total distortion loss\n    total_loss = inter_loss + intra_loss\n\n    return total_loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    # Compute inner and outer measures\n    t_inner, t_outer = inner_outer(t[..., :-1], t[..., 1:], w)\n\n    # Compute the inter-interval distortion\n    inter_interval_distortion = interval_distortion(t_inner, t_outer, t[..., :-1], t[..., 1:])\n\n    # Compute the intra-interval distortion\n    intra_interval_distortion = ((w - w.mean(dim=-1))**2).mean()\n\n    # Combine inter-interval and intra-interval losses to produce the total distortion loss\n    total_distortion_loss = inter_interval_distortion + intra_interval_distortion\n\n    return total_distortion_loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    _, w_outer = inner_outer(t, t, w)\n\n    # Calculate the inter-interval loss\n    inter_interval_loss = (w - w_outer).clip(0.).pow(2).mean()\n\n    # Calculate the intra-interval loss\n    intra_interval_loss = interval_distortion(w[..., :-1], w[..., 1:], w_outer[..., :-1], w_outer[..., 1:]).mean()\n\n    # Combine inter-interval and intra-interval losses to produce total distortion loss\n    total_distortion_loss = inter_interval_loss + intra_interval_loss\n\n    return total_distortion_loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    # Calculate the inter-interval loss\n    w_outer = lossfun_outer(t, w, t, w)\n    inter_interval_loss = torch.mean((w - w_outer).clamp(0).pow(2))\n\n    # Calculate the intra-interval loss\n    w_normalize = w / torch.clamp_min(t[..., 1:] - t[..., :-1], torch.finfo(torch.float32).eps)\n    t_, w_ = blur_stepfun(t, w_normalize, 1)\n    w_ = torch.clamp(w_, min=0.)\n    w_s = torch.diff(sorted_interp_quad(t, t_, w_, w_), dim=-1)\n    intra_interval_loss = torch.mean((w_s - w).clamp(0).pow(2))\n\n    # Combine both inter-interval and intra-interval losses\n    total_distortion_loss = inter_interval_loss + intra_interval_loss\n\n    return total_distortion_loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    # Calculate inter-interval loss\n    t_outer = t[..., 1:]\n    t_inner = t[..., :-1]\n    w_outer = w\n    w_inner = w\n\n    inter_interval_loss = (w_outer - w_inner).clip(0.).pow(2) / (w_outer + torch.finfo(torch.float32).eps)\n\n    # Calculate intra-interval loss\n    intra_interval_loss = (t_outer - t_inner).clip(0.).pow(2)\n\n    # Combine inter-interval and intra-interval losses to get total distortion loss\n    total_distortion_loss = inter_interval_loss.mean() + intra_interval_loss.mean()\n\n    return total_distortion_loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    # Calculate the inter-interval loss\n    t_inner, t_outer = inner_outer(t[..., :-1], t[..., 1:], w)\n    w_inner, w_outer = inner_outer(t, w, t_outer)\n\n    inter_interval_loss = lossfun_outer(t, w, t_outer, w_outer)\n\n    # Calculate the intra-interval loss\n    intra_interval_loss = lossfun_zip_outer(t, w, t_inner, w_inner, pulse_width=1e-6)\n\n    # Combine the inter-interval and intra-interval losses to get the total distortion loss\n    total_distortion_loss = inter_interval_loss + intra_interval_loss\n\n    return total_distortion_loss"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    cw = integrate_weights(w)  # Compute the cumulative sum of w\n    percentiles = torch.tensor(ps, dtype=t.dtype, device=t.device)  # Convert percentile values to tensor\n    interpolated_percentiles = interpolate(percentiles, cw, t)  # Interpolate the integrated weights to find the percentiles\n    return interpolated_percentiles"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "\n    # Match up the channels of the tensors\n    t, w = matchup_channels(t, w)\n\n    # Integrate the weights\n    cw = integrate_weights(w)\n\n    # Compute the weighted percentiles based on the provided percentile values\n    percentiles = interpolate(torch.tensor(ps, device=t.device, dtype=t.dtype), cw, t)\n\n    return percentiles"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    cw0 = integrate_weights(w)\n    cw0_shape = cw0.shape\n    cw0 = cw0.reshape(-1, cw0_shape[-1])\n    t = t.reshape(-1, t.shape[-1])\n\n    percentiles = torch.tensor(ps, device=t.device, dtype=t.dtype)\n    indices = torch.floor((cw0_shape[-1] - 1) * percentiles).to(torch.long)\n\n    interpolated_values = interpolate(indices.to(t.dtype), torch.arange(cw0_shape[-1], device=t.device, dtype=t.dtype), cw0)\n\n    return interpolate(interpolated_values, cw0, t).reshape(t.shape)"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(torch.tensor(ps, device=t.device, dtype=t.dtype), cw, t)"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "\n    cw = integrate_weights(w)  # Compute the cumulative sum of weights\n    percentiles = torch.tensor(ps, dtype=t.dtype, device=t.device)  # Convert percentile values to tensor\n\n    # Interpolate the integrated weights to find the weighted percentiles\n    return interpolate(percentiles, cw, t)"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "\n    # Ensure that the weights sum to 1\n    w = w / torch.sum(w, dim=-1, keepdim=True)\n\n    # Compute the cumulative sum of the weights\n    cw = integrate_weights(w)\n\n    # Interpolate the integrated weights to find the weighted percentiles\n    percentiles = []\n    for p in ps:\n        percentile = interpolate(torch.tensor(p), cw, t)\n        percentiles.append(percentile)\n\n    return torch.stack(percentiles, dim=-1)"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "\n    # Match up the channels of the tensors\n    t, w = matchup_channels(t, w)\n\n    # Integrate the weights\n    cw = integrate_weights(w)\n\n    # Compute the indices for the percentile values\n    indices = torch.tensor(ps) * (cw.shape[-1] - 1)\n\n    # Interpolate the integrated weights to find the weighted percentiles\n    weighted_percentiles = interpolate(indices, torch.arange(cw.shape[-1]), cw)\n\n    return weighted_percentiles"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "\n    t, w = matchup_channels(t, w)\n    p = integrate_weights(w)\n    return interpolate(torch.tensor(ps, dtype=t.dtype, device=t.device), p, t)"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    cw0 = integrate_weights(w)  # Compute the cumulative sum of w\n    cw0_interp = interpolate(torch.tensor(ps), torch.linspace(0, 1, len(cw0[0])), cw0[0])  # Interpolate the integrated weights\n    return cw0_interp"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "\n    # Match up the channels of the tensors\n    t, w = matchup_channels(t, w)\n\n    # Integrate the weights\n    cw = integrate_weights(w)\n\n    # Compute the weighted percentiles based on the provided percentile values\n    percentiles = interpolate(torch.tensor(ps, device=t.device, dtype=t.dtype), cw, t)\n\n    return percentiles"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    cw = integrate_weights(w)\n    cw_values = cw[..., 1:-1]  # Exclude the endpoints as they are 0 and 1\n    percentiles = torch.tensor(ps, dtype=t.dtype, device=t.device)\n\n    # Interpolate the integrated weights to find the weighted percentiles\n    weighted_percentiles = interpolate(percentiles, cw_values, t)\n\n    return weighted_percentiles"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "\n    cw = integrate_weights(w)  # Compute the cumulative sum of w\n    percentiles = []\n    for p in ps:\n        idx = torch.sum(cw < p, dim=-1)  # Find the index where the cumulative weights are less than the percentile\n        idx = torch.clamp(idx, 0, cw.shape[-1] - 1)  # Clamp the index to ensure it's within the range\n        interp = (p - cw[..., idx]) / (cw[..., idx + 1] - cw[..., idx] + 1e-8)  # Interpolation factor\n        percentile = t[..., idx] + interp * (t[..., idx + 1] - t[..., idx])  # Interpolate to find the weighted percentile\n        percentiles.append(percentile)\n    return torch.stack(percentiles, dim=-1)"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "\n    cw = integrate_weights(w)\n    cw_shape = cw.shape\n\n    # Calculate the indices for the weighted percentiles\n    indices = torch.tensor(ps) * (cw_shape[-1] - 1)\n    indices_floor = torch.floor(indices).long()\n    indices_ceil = torch.ceil(indices).long()\n\n    # Interpolate the weighted percentiles\n    vals_floor = cw.gather(dim=-1, index=indices_floor)\n    vals_ceil = cw.gather(dim=-1, index=indices_ceil)\n    interpolated_vals = vals_floor + (indices - indices_floor) * (vals_ceil - vals_floor)\n\n    return interpolated_vals"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "\n    cw0 = integrate_weights(w)\n\n    percentiles = torch.tensor(ps, dtype=t.dtype, device=t.device)\n    indices = (percentiles * (cw0.shape[-1] - 1)).long()\n\n    return interpolate(indices.float(), torch.arange(cw0.shape[-1], device=t.device, dtype=t.dtype), cw0)"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    # Match up the channels of the tensors\n    t, w = matchup_channels(t, w)\n\n    # Compute the cumulative sum of w, assuming all weight vectors sum to 1\n    cw0 = integrate_weights(w)\n\n    # Interpolate the integrated weights to find the weighted percentiles\n    percentiles = interpolate(torch.tensor(ps, dtype=t.dtype, device=t.device), cw0, t)\n\n    return percentiles"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(torch.tensor(ps, device=t.device, dtype=t.dtype), cw, t)"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "\n    cw = integrate_weights(w)\n    percentiles = []\n    for p in ps:\n        index = torch.sum(torch.ge(p, cw), dim=-1) - 1\n        index = torch.clamp(index, 0, cw.shape[-1] - 2)\n        m = (t[..., index + 1] - t[..., index]) / (cw[..., index + 1] - cw[..., index] + 1e-8)\n        b = t[..., index] - (m * cw[..., index])\n        percentile = m * (p - cw[..., index]) + b\n        percentiles.append(percentile)\n    return torch.stack(percentiles, dim=-1)"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "\n    # Match up the channels of the tensors\n    t, w = matchup_channels(t, w)\n\n    # Integrate the weights\n    cw = integrate_weights(w)\n\n    # Compute the weighted percentiles based on the provided percentile values\n    percentiles = []\n    for p in ps:\n        idx = torch.searchsorted(cw, p)\n        interp = interpolate(torch.tensor([p]), cw, t)\n        percentiles.append(interp)\n\n    return torch.stack(percentiles, dim=0)"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "\n    cw = integrate_weights(w)  # Compute the cumulative sum of w\n    percentiles = interpolate(torch.tensor(ps), cw, t)  # Interpolate the integrated weights to find the weighted percentiles\n    return percentiles"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "\n    # Match up the channels of the tensors\n    t, w = matchup_channels(t, w)\n\n    # Integrate the weights\n    cw0 = integrate_weights(w)\n\n    # Compute the weighted percentiles based on the provided percentile values\n    percentiles = torch.tensor(ps, dtype=t.dtype, device=t.device)\n    return interpolate(percentiles, cw0, t)"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx_lo = torch.searchsorted(a, v, side='left')\n    idx_hi = torch.searchsorted(a, v, side='right')\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "\n    idx_lo = torch.searchsorted(a, v, side='left')\n    idx_hi = torch.searchsorted(a, v, side='right')\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx_lo = torch.searchsorted(a, v, side='left')\n    idx_hi = torch.searchsorted(a, v, side='right')\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx_lo = torch.searchsorted(a, v, side='left')\n    idx_hi = torch.searchsorted(a, v, side='right')\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx_lo = torch.searchsorted(a, v, 'left')\n    idx_hi = torch.searchsorted(a, v, 'right')\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "\n    idx_lo = torch.searchsorted(a, v, side='left')\n    idx_hi = torch.searchsorted(a, v, side='right')\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx_lo = torch.searchsorted(a, v, side='left')\n    idx_hi = torch.searchsorted(a, v, side='right')\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx_lo = torch.searchsorted(a, v, side='left')\n    idx_hi = torch.searchsorted(a, v, side='right')\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx_lo = torch.searchsorted(a, v, side='left')\n    idx_hi = torch.searchsorted(a, v, side='right')\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx_lo = torch.searchsorted(a, v, side='left')\n    idx_hi = torch.searchsorted(a, v, side='right')\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "\n    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "\n    idx_lo = torch.searchsorted(a, v, side='left')\n    idx_hi = torch.searchsorted(a, v, side='right')\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    # Compute the cumulative sum of the weights\n    cw = integrate_weights(w)\n    \n    # Generate uniform random numbers\n    u = torch.rand(num_samples, device=t.device)\n    \n    # Invert the CDF to obtain samples\n    samples = invert_cdf(u, t, cw)\n    \n    # Apply perturbation to avoid sample clustering at bin boundaries\n    if perturb:\n        if single_jitter:\n            jitter = torch.rand(1, device=t.device) * (t[1] - t[0])\n            samples += jitter\n        else:\n            jitter = torch.rand(num_samples, device=t.device) * (t[1] - t[0])\n            samples += jitter\n    \n    return samples"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "\n    # Compute the cumulative sum of weights to obtain the CDF\n    cw = integrate_weights(w)\n\n    # Generate random numbers to sample from the CDF\n    u = torch.rand(num_samples, device=t.device)\n\n    # Invert the CDF to obtain the samples\n    samples = invert_cdf(u, t, cw)\n\n    # Apply perturbation to the samples to avoid clustering at bin boundaries\n    if perturb:\n        if single_jitter:\n            jitter = torch.rand(1, device=t.device) * (t[1] - t[0])  # Apply the same jitter to every sample\n        else:\n            jitter = torch.rand(num_samples, device=t.device) * (t[1] - t[0])  # Apply independent jitter to each sample\n        samples += jitter\n\n    return samples"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "\n    # Compute the cumulative sum of the weights\n    cw = integrate_weights(w)\n\n    # Generate uniform samples in the range [0, 1)\n    u = torch.rand(num_samples, device=t.device, dtype=t.dtype)\n\n    # Invert the CDF to obtain samples from the specified PDF\n    samples = invert_cdf(u, t, cw)\n\n    # Apply perturbation to avoid sample clustering at bin boundaries\n    if perturb:\n        if single_jitter:\n            jitter = torch.rand(1, device=t.device, dtype=t.dtype) * (t[1] - t[0])\n            samples += jitter\n        else:\n            jitter = torch.rand(num_samples, device=t.device, dtype=t.dtype) * (t[1] - t[0])\n            samples += jitter\n\n    return samples"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "\n    if perturb:\n        # Apply perturbation to the bin endpoints to avoid sample clustering at bin boundaries\n        t_perturbed = t\n        if single_jitter:\n            # Apply the same jitter to every sample along each dimension\n            t_perturbed = t + torch.rand(t.shape) * (t[..., 1:] - t[..., :-1])\n        else:\n            # Apply independent jitter to each sample\n            jitter = torch.rand((num_samples, t.shape[-1]))\n            t_perturbed = t[None, ...] + jitter * (t[..., 1:] - t[..., :-1])\n\n        # Compute the PDF and CDF for the perturbed bin endpoints\n        p_perturbed = weight_to_pdf(t_perturbed, w)\n        cdf_perturbed = integrate_weights(p_perturbed)\n\n        # Generate random numbers for sampling\n        u = torch.rand((num_samples,))\n\n        # Invert the CDF to obtain the samples\n        samples = invert_cdf(u, t_perturbed, cdf_perturbed)\n\n        return samples\n    else:\n        # Compute the PDF and CDF for the original bin endpoints\n        p = weight_to_pdf(t, w)\n        cdf = integrate_weights(p)\n\n        # Generate random numbers for sampling\n        u = torch.rand((num_samples,))\n\n        # Invert the CDF to obtain the samples\n        samples = invert_cdf(u, t, cdf)\n\n        return samples"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Compute the PDF and CDF for the given weights\n    pdf = weight_to_pdf(t, w)\n    cdf = integrate_weights(w)\n\n    # Generate random uniform samples\n    u = torch.rand((num_samples, *t.shape[:-1]), dtype=t.dtype, device=t.device)\n\n    # Invert the CDF to obtain samples from the PDF\n    samples = invert_cdf(u, t, cdf)\n\n    # Apply perturbation and jittering if specified\n    if perturb:\n        if single_jitter:\n            jitter = torch.rand(1, *t.shape[:-1], dtype=t.dtype, device=t.device)\n        else:\n            jitter = torch.rand(num_samples, *t.shape[:-1], dtype=t.dtype, device=t.device)\n        samples = samples + jitter\n\n    return samples"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "\n    # Compute the cumulative sum of the weights to get the CDF\n    cw = integrate_weights(w)\n\n    # Generate uniform random numbers to use for sampling\n    u = torch.rand(num_samples, device=t.device)\n\n    # Use the inverse CDF to sample from the distribution\n    samples = invert_cdf(u, t, cw)\n\n    # Apply perturbation to avoid sample clustering at bin boundaries\n    if perturb:\n        if single_jitter:\n            # Apply the same jitter to every sample along each dimension\n            jitter = torch.rand(1, device=t.device) * (t[..., 1:] - t[..., :-1])\n            samples += jitter\n        else:\n            # Apply independent jitter to each sample\n            jitter = torch.rand(num_samples, device=t.device) * (t[..., 1:] - t[..., :-1])\n            samples += jitter\n\n    return samples"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    # Compute the PDF from the weights\n    p = weight_to_pdf(t, w)\n    \n    # Generate uniform random numbers for sampling\n    u = torch.rand(num_samples, device=t.device)\n    \n    # Invert the CDF to generate samples\n    samples = invert_cdf(u, t, p)\n    \n    # Apply perturbation to avoid sample clustering at bin boundaries\n    if perturb:\n        if single_jitter:\n            jitter = torch.rand(1, device=t.device) * (t[1] - t[0])\n            samples += jitter\n        else:\n            jitter = torch.rand(num_samples, device=t.device) * (t[1] - t[0])\n            samples += jitter\n    \n    return samples"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "\n    # Compute the cumulative sum of weights\n    cw = integrate_weights(w)\n\n    # Generate random samples\n    u = torch.rand(num_samples, device=t.device, dtype=t.dtype)\n\n    # Invert the CDF to obtain samples\n    samples = invert_cdf(u, t, cw)\n\n    # Apply perturbation if specified\n    if perturb:\n        if single_jitter:\n            jitter = torch.rand(1, device=t.device, dtype=t.dtype) * (t[1] - t[0])  # Generate single jitter value\n            samples += jitter  # Add the same jitter to every sample\n        else:\n            jitter = torch.rand(num_samples, device=t.device, dtype=t.dtype) * (t[1] - t[0])  # Generate independent jitter values\n            samples += jitter  # Add independent jitter to each sample\n\n    return samples"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Invert the CDF to generate samples\n    u = torch.rand((num_samples,), device=t.device, dtype=t.dtype)\n    samples = invert_cdf(u, t, w)\n\n    # Apply perturbation if specified\n    if perturb:\n        if single_jitter:\n            jitter = torch.rand((), device=t.device, dtype=t.dtype) * (t[1] - t[0])\n            samples += jitter\n        else:\n            jitter = torch.rand((num_samples,) + t.shape[:-1], device=t.device, dtype=t.dtype) * (t[1] - t[0])\n            samples += jitter\n\n    return samples"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Compute the cumulative sum of the weights\n    cw = integrate_weights(w)\n\n    # Generate random samples from a uniform distribution\n    u = torch.rand(num_samples, device=t.device)\n\n    # Invert the CDF at the points specified by u\n    samples = invert_cdf(u, t, cw)\n\n    # Apply perturbation to avoid sample clustering at bin boundaries\n    if perturb:\n        if single_jitter:\n            # Apply the same jitter to every sample along each dimension\n            jitter = (t[..., 1:] - t[..., :-1]) * torch.rand(1, device=t.device)\n            samples += jitter\n        else:\n            # Apply independent jitter to each sample\n            jitter = (t[..., 1:] - t[..., :-1]) * torch.rand(num_samples, device=t.device)\n            samples += jitter\n\n    return samples"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    # Compute the PDF from the weights\n    p = weight_to_pdf(t, w)\n    \n    # Compute the cumulative sum of the PDF\n    cdf = torch.cumsum(p, dim=-1)\n    \n    # Generate uniform random numbers for sampling\n    u = torch.rand(num_samples, device=t.device, dtype=t.dtype)\n    \n    # Invert the CDF to obtain the samples\n    samples = invert_cdf(u, t, cdf)\n    \n    # Apply perturbation if specified\n    if perturb:\n        if single_jitter:\n            jitter = torch.rand(1, device=t.device, dtype=t.dtype) * (t[..., 1:] - t[..., :-1])\n            samples += jitter\n        else:\n            jitter = torch.rand(num_samples, device=t.device, dtype=t.dtype) * (t[..., 1:] - t[..., :-1])\n            samples += jitter\n    \n    return samples"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n\n    # Generate uniform random samples and sort them\n    u = torch.rand(num_samples, device=t.device)\n    u_sorted, _ = torch.sort(u)\n\n    # Invert the CDF to obtain samples from the specified PDF\n    samples = invert_cdf(u_sorted, t, w)\n\n    # Apply perturbation to avoid sample clustering at bin boundaries\n    if perturb:\n        if single_jitter:\n            jitter = torch.rand(1, device=t.device) * (t[..., 1:] - t[..., :-1])\n            samples += jitter\n        else:\n            jitter = torch.rand(num_samples, device=t.device) * (t[..., 1:] - t[..., :-1])\n            samples += jitter\n\n    return samples"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Compute the cumulative sum of the weights\n    cw = integrate_weights(w)\n\n    # Generate uniform random numbers for sampling\n    u = torch.rand(num_samples, device=t.device)\n\n    # Invert the CDF to obtain the samples\n    samples = invert_cdf(u, t, cw)\n\n    # Apply perturbation if specified\n    if perturb:\n        if single_jitter:\n            jitter = torch.rand(1, device=t.device)\n            samples += jitter * (t[..., 1:] - t[..., :-1])\n        else:\n            jitter = torch.rand(num_samples, device=t.device)\n            samples += jitter * (t[..., 1:] - t[..., :-1])\n\n    return samples"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Compute the CDF of the input PDF\n    cw = integrate_weights(w)\n\n    # Generate random samples from a uniform distribution\n    u = torch.rand(num_samples, device=t.device, dtype=t.dtype)\n\n    # Invert the CDF to obtain samples from the PDF\n    samples = invert_cdf(u, t, cw)\n\n    # Apply perturbation if specified\n    if perturb:\n        if single_jitter:\n            # Apply the same jitter to every sample along each dimension\n            jitter = torch.rand_like(samples) * (t[1:] - t[:-1])\n        else:\n            # Apply independent jitter to each sample\n            jitter = torch.rand_like(samples) * (t[1:] - t[:-1])[None, :]\n\n        # Add the jitter to the samples\n        samples += jitter\n\n    return samples"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Compute the cumulative sum of the weights to form the CDF\n    cw = integrate_weights(w)\n\n    # Generate random uniform samples\n    u = torch.rand(num_samples, device=t.device)\n\n    # Invert the CDF to obtain samples from the specified PDF\n    samples = invert_cdf(u, t, cw)\n\n    # Apply perturbation to avoid sample clustering at bin boundaries\n    if perturb:\n        if single_jitter:\n            # Apply the same jitter to every sample along each dimension\n            jitter = torch.rand(1, device=t.device) * (t[1] - t[0])\n            samples += jitter\n        else:\n            # Apply independent jitter to each sample\n            jitter = torch.rand(num_samples, device=t.device) * (t[1] - t[0])\n            samples += jitter\n\n    return samples"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "\n    # Compute the cumulative sum of weights\n    cw = integrate_weights(w)\n\n    # Generate random samples from a uniform distribution\n    u = torch.rand(num_samples, device=t.device, dtype=t.dtype)\n\n    # Invert the CDF to obtain samples from the specified PDF\n    samples = invert_cdf(u, t, cw)\n\n    # Apply perturbation to avoid sample clustering at bin boundaries\n    if perturb:\n        if single_jitter:\n            jitter = torch.rand(1, device=t.device, dtype=t.dtype) * (t[1] - t[0])\n            samples += jitter\n        else:\n            jitter = torch.rand(num_samples, device=t.device, dtype=t.dtype) * (t[1] - t[0])\n            samples += jitter\n\n    return samples"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    cdf = integrate_weights(w)\n\n    # Generate uniform samples\n    u = torch.rand(num_samples, device=t.device)\n\n    # Invert the CDF to obtain samples\n    samples = invert_cdf(u, t, cdf)\n\n    # Apply perturbation to avoid sample clustering at bin boundaries\n    if perturb:\n        if single_jitter:\n            jitter = torch.rand(1, device=t.device) * (t[1] - t[0])\n            samples += jitter\n        else:\n            jitter = torch.rand(num_samples, device=t.device) * (t[1] - t[0])\n            samples += jitter\n\n    return samples"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Compute the cumulative sum of the weights\n    cw = integrate_weights(w)\n\n    # Generate random samples from a uniform distribution\n    u = torch.rand(num_samples, device=t.device)\n\n    # Invert the CDF to obtain the samples\n    samples = invert_cdf(u, t, cw)\n\n    # Apply perturbation to avoid sample clustering at bin boundaries\n    if perturb:\n        if single_jitter:\n            jitter = torch.rand(1, device=t.device) * (t[1] - t[0])\n            samples += jitter\n        else:\n            jitter = torch.rand(num_samples, device=t.device) * (t[1] - t[0])\n            samples += jitter\n\n    return samples"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    # Compute the PDF from the weights\n    p = weight_to_pdf(t, w)\n    \n    # Generate uniform random numbers for sampling\n    u = torch.rand(num_samples, device=t.device, dtype=t.dtype)\n    \n    # Invert the CDF to obtain samples\n    samples = invert_cdf(u, t, p)\n    \n    # Apply perturbation to avoid sample clustering at bin boundaries\n    if perturb:\n        if single_jitter:\n            jitter = (t[1:] - t[:-1]) / 2\n            samples += torch.rand(1, device=t.device, dtype=t.dtype) * jitter\n        else:\n            jitter = (t[1:] - t[:-1]) / 2\n            jitter = jitter[None, :] * torch.rand(num_samples, 1, device=t.device, dtype=t.dtype)\n            samples += jitter\n    \n    return samples"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "\n    # Compute the cumulative sum of weights\n    cw = integrate_weights(w)\n\n    # Generate uniform random numbers for sampling\n    u = torch.rand(num_samples, device=t.device)\n\n    # Invert the CDF to get the samples\n    samples = invert_cdf(u, t, cw)\n\n    # Apply perturbation to avoid sample clustering at bin boundaries\n    if perturb:\n        if single_jitter:\n            jitter = torch.rand(1, device=t.device) * (t[1] - t[0])\n            samples += jitter\n        else:\n            jitter = torch.rand(num_samples, device=t.device) * (t[1] - t[0])\n            samples += jitter\n\n    return samples"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        widths = self.tensor[:, 2]\n        heights = self.tensor[:, 3]\n        areas = widths * heights\n        return areas"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        areas = self.tensor[:, 2] * self.tensor[:, 3]\n        return areas"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "\n        return self.tensor[:, 2] * self.tensor[:, 3]"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        gt_boxes = [x.gt_boxes for x in proposals]\n        gt_classes = [x.gt_classes for x in proposals]\n\n        # Calculate classification loss\n        pred_class_logits = scores\n        loss_cls = cross_entropy(pred_class_logits, cat(gt_classes, dim=0), reduction=\"mean\")\n\n        # Calculate box regression loss\n        proposal_boxes = [x.proposal_boxes for x in proposals]\n        loss_box_reg = self.box_reg_loss(cat(proposal_boxes, dim=0), cat(gt_boxes, dim=0), proposal_deltas, cat(gt_classes, dim=0))\n\n        # Apply loss weights\n        loss_cls *= self.loss_weight[\"loss_cls\"]\n        loss_box_reg *= self.loss_weight[\"loss_box_reg\"]\n\n        return {\"loss_cls\": loss_cls, \"loss_box_reg\": loss_box_reg}"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        gt_boxes = [x.gt_boxes for x in proposals]\n        gt_classes = [x.gt_classes for x in proposals]\n\n        # Classification Loss\n        pred_class_logits, _ = scores\n        loss_cls = cross_entropy(pred_class_logits, cat(gt_classes), self.loss_weight[\"loss_cls\"])\n\n        # Box Regression Loss\n        proposal_boxes = [x.proposal_boxes for x in proposals]\n        loss_box_reg = self.box_reg_loss(cat(proposal_boxes), cat(gt_boxes), cat(proposal_deltas), cat(gt_classes))\n\n        return {\"loss_cls\": loss_cls, \"loss_box_reg\": loss_box_reg}"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "\n        scores, proposal_deltas = predictions\n        gt_boxes = [x.gt_boxes for x in proposals]\n        gt_classes = [x.gt_classes for x in proposals]\n\n        # Calculate classification loss\n        pred_class_logits = scores\n        loss_cls = cross_entropy(pred_class_logits, cat(gt_classes, dim=0), reduction=\"mean\")\n\n        # Calculate box regression loss\n        proposal_boxes = [x.proposal_boxes.tensor for x in proposals]\n        loss_box_reg = self.box_reg_loss(\n            cat(proposal_boxes, dim=0), cat(gt_boxes, dim=0), proposal_deltas, cat(gt_classes, dim=0)\n        )\n\n        # Apply loss weights\n        loss_cls *= self.loss_weight[\"loss_cls\"]\n        loss_box_reg *= self.loss_weight[\"loss_box_reg\"]\n\n        return {\"loss_cls\": loss_cls, \"loss_box_reg\": loss_box_reg}"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "\n        scores, proposal_deltas = predictions\n        gt_boxes = [x.gt_boxes for x in proposals]\n        gt_classes = [x.gt_classes for x in proposals]\n\n        # Calculate classification loss\n        pred_class_logits = scores\n        loss_cls = cross_entropy(pred_class_logits, torch.cat(gt_classes, dim=0), reduction=\"mean\")\n\n        # Calculate box regression loss\n        pred_proposal_deltas = proposal_deltas\n        proposal_boxes = [x.proposal_boxes.tensor for x in proposals]\n        loss_box_reg = self.box_reg_loss(\n            torch.cat(proposal_boxes, dim=0),\n            torch.cat(gt_boxes, dim=0),\n            pred_proposal_deltas,\n            torch.cat(gt_classes, dim=0)\n        )\n\n        # Scale the losses by their respective weights\n        loss_cls *= self.loss_weight[\"loss_cls\"]\n        loss_box_reg *= self.loss_weight[\"loss_box_reg\"]\n\n        return {\"loss_cls\": loss_cls, \"loss_box_reg\": loss_box_reg}"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "\n        scores, proposal_deltas = predictions\n        gt_boxes = [x.gt_boxes for x in proposals]\n        gt_classes = [x.gt_classes for x in proposals]\n\n        # Calculate classification loss\n        loss_cls = cross_entropy(scores, cat(gt_classes, dim=0), reduction=\"mean\")\n\n        # Calculate box regression loss\n        loss_box_reg = self.box_reg_loss(\n            cat([x.proposal_boxes.tensor for x in proposals], dim=0),\n            cat(gt_boxes, dim=0),\n            proposal_deltas,\n            cat(gt_classes, dim=0),\n        )\n\n        return {\n            \"loss_cls\": loss_cls * self.loss_weight[\"loss_cls\"],\n            \"loss_box_reg\": loss_box_reg * self.loss_weight[\"loss_box_reg\"],\n        }"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "    scores, proposal_deltas = predictions\n    proposal_boxes = [proposal.proposal_boxes.tensor for proposal in proposals]\n    gt_boxes = [proposal.gt_boxes.tensor for proposal in proposals]\n    gt_classes = [proposal.gt_classes for proposal in proposals]\n\n    # Calculate classification loss\n    pred_class_logits = scores\n    gt_classes = cat(gt_classes, dim=0)\n    loss_cls = cross_entropy(pred_class_logits, gt_classes, reduction=\"mean\")\n\n    # Calculate box regression loss\n    pred_proposal_deltas = proposal_deltas\n    proposal_boxes = cat(proposal_boxes, dim=0)\n    gt_boxes = cat(gt_boxes, dim=0)\n    loss_box_reg = self.box_reg_loss(proposal_boxes, gt_boxes, pred_proposal_deltas, gt_classes)\n\n    # Scale the losses by their respective weights\n    loss_cls *= self.loss_weight[\"loss_cls\"]\n    loss_box_reg *= self.loss_weight[\"loss_box_reg\"]\n\n    return {\"loss_cls\": loss_cls, \"loss_box_reg\": loss_box_reg}"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        gt_boxes = [x.gt_boxes for x in proposals]\n        gt_classes = [x.gt_classes for x in proposals]\n\n        # Calculate classification loss\n        pred_class_logits = scores\n        loss_cls = cross_entropy(pred_class_logits, cat(gt_classes, dim=0), reduction=\"mean\")\n\n        # Calculate box regression loss\n        proposal_boxes = cat([x.proposal_boxes.tensor for x in proposals], dim=0)\n        loss_box_reg = self.box_reg_loss(proposal_boxes, cat(gt_boxes, dim=0), proposal_deltas, cat(gt_classes, dim=0))\n\n        # Apply loss weights\n        loss_cls *= self.loss_weight[\"loss_cls\"]\n        loss_box_reg *= self.loss_weight[\"loss_box_reg\"]\n\n        return {\"loss_cls\": loss_cls, \"loss_box_reg\": loss_box_reg}"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        gt_boxes = [x.gt_boxes for x in proposals]\n        gt_classes = [x.gt_classes for x in proposals]\n\n        # Calculate classification loss\n        pred_class_logits, _ = scores.max(dim=1)\n        loss_cls = cross_entropy(pred_class_logits, cat(gt_classes))\n\n        # Calculate box regression loss\n        proposal_boxes = [x.proposal_boxes for x in proposals]\n        loss_box_reg = self.box_reg_loss(cat(proposal_boxes), cat(gt_boxes), proposal_deltas, cat(gt_classes))\n\n        # Scale the losses by their respective weights\n        loss_cls *= self.loss_weight[\"loss_cls\"]\n        loss_box_reg *= self.loss_weight[\"loss_box_reg\"]\n\n        return {\"loss_cls\": loss_cls, \"loss_box_reg\": loss_box_reg}"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "\n        scores, proposal_deltas = predictions\n        proposal_boxes = [proposal.proposal_boxes.tensor for proposal in proposals]\n        gt_boxes = [proposal.gt_boxes.tensor for proposal in proposals]\n        gt_classes = [proposal.gt_classes for proposal in proposals]\n\n        # Calculate classification loss\n        pred_class_logits = scores\n        loss_cls = cross_entropy(pred_class_logits, cat(gt_classes), reduction=\"mean\")\n\n        # Calculate box regression loss\n        loss_box_reg = self.box_reg_loss(cat(proposal_boxes), cat(gt_boxes), proposal_deltas, cat(gt_classes))\n\n        # Apply loss weights\n        loss_cls *= self.loss_weight[\"loss_cls\"]\n        loss_box_reg *= self.loss_weight[\"loss_box_reg\"]\n\n        return {\"loss_cls\": loss_cls, \"loss_box_reg\": loss_box_reg}"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        gt_boxes = [x.gt_boxes for x in proposals]\n        gt_classes = [x.gt_classes for x in proposals]\n\n        # Calculate classification loss\n        pred_class_logits = scores\n        gt_classes = cat(gt_classes, dim=0)\n        loss_cls = F.cross_entropy(pred_class_logits, gt_classes, reduction=\"mean\")\n\n        # Calculate box regression loss\n        proposal_boxes = cat([x.proposal_boxes.tensor for x in proposals], dim=0)\n        gt_boxes = cat(gt_boxes, dim=0)\n        loss_box_reg = self.box_reg_loss(proposal_boxes, gt_boxes.tensor, proposal_deltas, gt_classes)\n\n        # Scale the losses by their respective weights\n        loss_cls *= self.loss_weight[\"loss_cls\"]\n        loss_box_reg *= self.loss_weight[\"loss_box_reg\"]\n\n        return {\"loss_cls\": loss_cls, \"loss_box_reg\": loss_box_reg}"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "\n        scores, proposal_deltas = predictions\n        gt_boxes = [x.gt_boxes for x in proposals]\n        gt_classes = [x.gt_classes for x in proposals]\n\n        # Calculate classification loss\n        loss_cls = cross_entropy(scores, cat(gt_classes, dim=0), reduction=\"mean\")\n\n        # Calculate box regression loss\n        proposal_boxes = [x.proposal_boxes.tensor for x in proposals]\n        loss_box_reg = self.box_reg_loss(\n            cat(proposal_boxes, dim=0),\n            cat(gt_boxes, dim=0),\n            proposal_deltas,\n            cat(gt_classes, dim=0)\n        )\n\n        return {\n            \"loss_cls\": loss_cls * self.loss_weight[\"loss_cls\"],\n            \"loss_box_reg\": loss_box_reg * self.loss_weight[\"loss_box_reg\"]\n        }"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "\n        scores, proposal_deltas = predictions\n        gt_boxes = [x.gt_boxes for x in proposals]\n        gt_classes = [x.gt_classes for x in proposals]\n\n        # Calculate classification loss\n        loss_cls = cross_entropy(scores, cat(gt_classes, dim=0), reduction=\"mean\")\n\n        # Calculate box regression loss\n        proposal_boxes = cat([x.proposal_boxes.tensor for x in proposals], dim=0)\n        loss_box_reg = self.box_reg_loss(proposal_boxes, cat(gt_boxes, dim=0), proposal_deltas, cat(gt_classes, dim=0))\n\n        # Apply loss weights\n        loss_cls *= self.loss_weight[\"loss_cls\"]\n        loss_box_reg *= self.loss_weight[\"loss_box_reg\"]\n\n        return {\"loss_cls\": loss_cls, \"loss_box_reg\": loss_box_reg}"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        proposal_boxes = [x.proposal_boxes for x in proposals]\n        gt_boxes = [x.gt_boxes for x in proposals]\n        gt_classes = [x.gt_classes for x in proposals]\n\n        # Calculate classification loss\n        pred_class_logits = scores\n        gt_classes = cat(gt_classes, dim=0)\n        loss_cls = cross_entropy(pred_class_logits, gt_classes, reduction=\"mean\")\n\n        # Calculate box regression loss\n        proposal_boxes = cat(proposal_boxes, dim=0)\n        gt_boxes = cat(gt_boxes, dim=0)\n        loss_box_reg = self.box_reg_loss(proposal_boxes.tensor, gt_boxes.tensor, proposal_deltas, gt_classes)\n\n        return {\"loss_cls\": loss_cls * self.loss_weight[\"loss_cls\"], \"loss_box_reg\": loss_box_reg * self.loss_weight[\"loss_box_reg\"]}"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        proposal_boxes = [proposal.proposal_boxes.tensor for proposal in proposals]\n        gt_boxes = [proposal.gt_boxes.tensor for proposal in proposals]\n        gt_classes = [proposal.gt_classes for proposal in proposals]\n\n        # Calculate classification loss\n        pred_class_logits = scores\n        gt_classes = cat(gt_classes, dim=0)\n        loss_cls = F.cross_entropy(pred_class_logits, gt_classes, reduction=\"mean\")\n\n        # Calculate box regression loss\n        loss_box_reg = self.box_reg_loss(\n            cat(proposal_boxes, dim=0),\n            cat(gt_boxes, dim=0),\n            proposal_deltas,\n            gt_classes\n        )\n\n        # Apply loss weights\n        loss_cls *= self.loss_weight.get(\"loss_cls\", 1.0)\n        loss_box_reg *= self.loss_weight.get(\"loss_box_reg\", 1.0)\n\n        return {\"loss_cls\": loss_cls, \"loss_box_reg\": loss_box_reg}"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        gt_boxes = [x.gt_boxes for x in proposals]\n        gt_classes = [x.gt_classes for x in proposals]\n\n        # Calculate classification loss\n        pred_class_logits = scores\n        loss_cls = F.cross_entropy(pred_class_logits, cat(gt_classes, dim=0))\n\n        # Calculate box regression loss\n        proposal_boxes = [x.proposal_boxes for x in proposals]\n        loss_box_reg = self.box_reg_loss(cat(proposal_boxes, dim=0), cat(gt_boxes, dim=0), proposal_deltas, cat(gt_classes, dim=0))\n\n        return {\"loss_cls\": loss_cls * self.loss_weight[\"loss_cls\"], \"loss_box_reg\": loss_box_reg * self.loss_weight[\"loss_box_reg\"]}"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        proposal_boxes = [x.proposal_boxes for x in proposals]\n        gt_boxes = [x.gt_boxes for x in proposals]\n        gt_classes = [x.gt_classes for x in proposals]\n\n        # Calculate classification loss\n        pred_class_logits = scores\n        loss_cls = cross_entropy(pred_class_logits, cat(gt_classes, dim=0), reduction=\"mean\")\n\n        # Calculate box regression loss\n        loss_box_reg = self.box_reg_loss(cat(proposal_boxes, dim=0), cat(gt_boxes, dim=0), proposal_deltas, cat(gt_classes, dim=0))\n\n        return {\"loss_cls\": loss_cls * self.loss_weight[\"loss_cls\"], \"loss_box_reg\": loss_box_reg * self.loss_weight[\"loss_box_reg\"]}"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        gt_boxes = [x.gt_boxes for x in proposals]\n        gt_classes = [x.gt_classes for x in proposals]\n\n        # Calculate classification loss\n        loss_cls = cross_entropy(scores, cat(gt_classes, dim=0), reduction=\"mean\")\n\n        # Calculate box regression loss\n        proposal_boxes = cat([x.proposal_boxes.tensor for x in proposals], dim=0)\n        loss_box_reg = self.box_reg_loss(proposal_boxes, cat(gt_boxes, dim=0), proposal_deltas, cat(gt_classes, dim=0))\n\n        return {\"loss_cls\": loss_cls * self.loss_weight[\"loss_cls\"], \"loss_box_reg\": loss_box_reg * self.loss_weight[\"loss_box_reg\"]}"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "\n        scores, proposal_deltas = predictions\n        gt_boxes = [x.gt_boxes for x in proposals]\n        gt_classes = [x.gt_classes for x in proposals]\n\n        # Calculate classification loss\n        loss_cls = cross_entropy(scores, cat(gt_classes))\n\n        # Calculate box regression loss\n        proposal_boxes = [x.proposal_boxes for x in proposals]\n        loss_box_reg = self.box_reg_loss(cat(proposal_boxes), cat(gt_boxes), proposal_deltas, cat(gt_classes))\n\n        # Apply loss weights\n        loss_cls *= self.loss_weight[\"loss_cls\"]\n        loss_box_reg *= self.loss_weight[\"loss_box_reg\"]\n\n        return {\"loss_cls\": loss_cls, \"loss_box_reg\": loss_box_reg}"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "\n        scores, proposal_deltas = predictions\n        proposal_boxes = [x.proposal_boxes for x in proposals]\n        gt_boxes = [x.gt_boxes for x in proposals]\n        gt_classes = [x.gt_classes for x in proposals]\n\n        # Calculate classification loss\n        loss_cls = cross_entropy(scores, torch.cat(gt_classes))\n\n        # Calculate box regression loss\n        loss_box_reg = self.box_reg_loss(\n            cat([x.tensor for x in proposal_boxes]),\n            cat([x.tensor for x in gt_boxes]),\n            proposal_deltas,\n            torch.cat(gt_classes)\n        )\n\n        # Apply loss weights\n        loss_cls *= self.loss_weight[\"loss_cls\"]\n        loss_box_reg *= self.loss_weight[\"loss_box_reg\"]\n\n        return {\"loss_cls\": loss_cls, \"loss_box_reg\": loss_box_reg}"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "\n        scores, proposal_deltas = predictions\n        gt_boxes = [x.gt_boxes for x in proposals]\n        gt_classes = [x.gt_classes for x in proposals]\n\n        # Calculate classification loss\n        pred_class_logits = scores\n        loss_cls = cross_entropy(pred_class_logits, torch.cat(gt_classes, dim=0), self.loss_weight[\"loss_cls\"])\n\n        # Calculate box regression loss\n        pred_proposal_deltas = proposal_deltas\n        proposal_boxes = [x.proposal_boxes.tensor for x in proposals]\n        loss_box_reg = self.box_reg_loss(torch.cat(proposal_boxes, dim=0), torch.cat(gt_boxes, dim=0), pred_proposal_deltas, torch.cat(gt_classes, dim=0))\n        loss_box_reg = loss_box_reg * self.loss_weight[\"loss_box_reg\"]\n\n        return {\"loss_cls\": loss_cls, \"loss_box_reg\": loss_box_reg}"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER.TRACKER_NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER_HEAD.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER_HEAD.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER_HEAD\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER_HEAD.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER_HEAD.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "\n    name = cfg.MODEL.TRACKER_HEAD.NAME\n    return TRACKER_HEADS_REGISTRY.get(name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert deltas.shape[1] % 4 == 0 and boxes.shape[1] == 4\n\n        boxes = boxes.to(deltas.dtype).unsqueeze(2)\n\n        ctr_x = 0.5 * (boxes[:, 0] + boxes[:, 2])\n        ctr_y = 0.5 * (boxes[:, 1] + boxes[:, 3])\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n\n        dx = deltas[:, 0::4]\n        dy = deltas[:, 1::4]\n        dw = deltas[:, 2::4]\n        dh = deltas[:, 3::4]\n\n        wx, wy, ww, wh = self.weights\n\n        dx = dx / wx\n        dy = dy / wy\n        dw = dw / ww\n        dh = dh / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = dx * widths + ctr_x  # x_ctr\n        pred_boxes[:, 1::4] = dy * heights + ctr_y  # y_ctr\n        pred_boxes[:, 2::4] = torch.exp(dw) * widths  # width\n        pred_boxes[:, 3::4] = torch.exp(dh) * heights  # height\n\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        # Ensure the output is a valid box. See Sec 2.1 of https://arxiv.org/abs/2006.09214\n        deltas = F.relu(deltas)\n        boxes = boxes.to(deltas.dtype)\n\n        ctr_x = 0.5 * (boxes[:, 0] + boxes[:, 2])\n        ctr_y = 0.5 * (boxes[:, 1] + boxes[:, 3])\n\n        dx = deltas[:, 0::4]\n        dy = deltas[:, 1::4]\n        dw = deltas[:, 2::4]\n        dh = deltas[:, 3::4]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = dx + ctr_x[:, None] - 0.5 * dw * (boxes[:, 2] - boxes[:, 0])  # x1\n        pred_boxes[:, 1::4] = dy + ctr_y[:, None] - 0.5 * dh * (boxes[:, 3] - boxes[:, 1])  # y1\n        pred_boxes[:, 2::4] = dx + ctr_x[:, None] + 0.5 * dw * (boxes[:, 2] - boxes[:, 0])  # x2\n        pred_boxes[:, 3::4] = dy + ctr_y[:, None] + 0.5 * dh * (boxes[:, 3] - boxes[:, 1])  # y2\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        # Ensure the output is a valid box. See Sec 2.1 of https://arxiv.org/abs/2006.09214\n        deltas = F.relu(deltas)\n        boxes = boxes.to(deltas.dtype)\n\n        ctr_x = 0.5 * (boxes[:, 0] + boxes[:, 2])\n        ctr_y = 0.5 * (boxes[:, 1] + boxes[:, 3])\n\n        dx = deltas[:, 0::4]\n        dy = deltas[:, 1::4]\n        dw = deltas[:, 2::4]\n        dh = deltas[:, 3::4]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = ctr_x[:, None] + dx  # x1\n        pred_boxes[:, 1::4] = ctr_y[:, None] + dy  # y1\n        pred_boxes[:, 2::4] = ctr_x[:, None] + dw  # x2\n        pred_boxes[:, 3::4] = ctr_y[:, None] + dh  # y2\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        # Ensure the output is a valid box. See Sec 2.1 of https://arxiv.org/abs/2006.09214\n        deltas = F.relu(deltas)\n        boxes = boxes.to(deltas.dtype)\n\n        ctr_x = 0.5 * (boxes[:, 0] + boxes[:, 2])\n        ctr_y = 0.5 * (boxes[:, 1] + boxes[:, 3])\n\n        dx = deltas[:, 0::4]\n        dy = deltas[:, 1::4]\n        dw = deltas[:, 2::4]\n        dh = deltas[:, 3::4]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = dx + ctr_x[:, None] - 0.5 * dw  # x1\n        pred_boxes[:, 1::4] = dy + ctr_y[:, None] - 0.5 * dh  # y1\n        pred_boxes[:, 2::4] = dx + ctr_x[:, None] + 0.5 * dw  # x2\n        pred_boxes[:, 3::4] = dy + ctr_y[:, None] + 0.5 * dh  # y2\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert deltas.shape[1] % 4 == 0 and boxes.shape[1] == 4\n\n        boxes = boxes.to(deltas.dtype).unsqueeze(2)\n\n        ctr_x = 0.5 * (boxes[:, 0] + boxes[:, 2])\n        ctr_y = 0.5 * (boxes[:, 1] + boxes[:, 3])\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n\n        wx, wy, ww, wh = self.weights\n\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = dx * widths + ctr_x  # x_ctr\n        pred_boxes[:, 1::4] = dy * heights + ctr_y  # y_ctr\n        pred_boxes[:, 2::4] = torch.exp(dw) * widths  # width\n        pred_boxes[:, 3::4] = torch.exp(dh) * heights  # height\n\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        # Ensure the output is a valid box. See Sec 2.1 of https://arxiv.org/abs/2006.09214\n        deltas = F.relu(deltas)\n        boxes = boxes.to(deltas.dtype)\n\n        ctr_x = 0.5 * (boxes[:, 0] + boxes[:, 2])\n        ctr_y = 0.5 * (boxes[:, 1] + boxes[:, 3])\n\n        dx = deltas[:, 0::4]\n        dy = deltas[:, 1::4]\n        dw = deltas[:, 2::4]\n        dh = deltas[:, 3::4]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = ctr_x[:, None] + dx  # x1\n        pred_boxes[:, 1::4] = ctr_y[:, None] + dy  # y1\n        pred_boxes[:, 2::4] = ctr_x[:, None] + dw  # x2\n        pred_boxes[:, 3::4] = ctr_y[:, None] + dh  # y2\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        # Ensure the output is a valid box. See Sec 2.1 of https://arxiv.org/abs/2006.09214\n        deltas = F.relu(deltas)\n        boxes = boxes.to(deltas.dtype)\n\n        ctr_x = 0.5 * (boxes[:, 0] + boxes[:, 2])\n        ctr_y = 0.5 * (boxes[:, 1] + boxes[:, 3])\n\n        dx = deltas[:, 0::4]\n        dy = deltas[:, 1::4]\n        dw = deltas[:, 2::4]\n        dh = deltas[:, 3::4]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = dx + ctr_x[:, None] - 0.5 * dw * (boxes[:, 2] - boxes[:, 0])  # x1\n        pred_boxes[:, 1::4] = dy + ctr_y[:, None] - 0.5 * dh * (boxes[:, 3] - boxes[:, 1])  # y1\n        pred_boxes[:, 2::4] = dx + ctr_x[:, None] + 0.5 * dw * (boxes[:, 2] - boxes[:, 0])  # x2\n        pred_boxes[:, 3::4] = dy + ctr_y[:, None] + 0.5 * dh * (boxes[:, 3] - boxes[:, 1])  # y2\n\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        # Ensure the output is a valid box. See Sec 2.1 of https://arxiv.org/abs/2006.09214\n        deltas = F.relu(deltas)\n        boxes = boxes.to(deltas.dtype)\n\n        ctr_x = 0.5 * (boxes[:, 0] + boxes[:, 2])\n        ctr_y = 0.5 * (boxes[:, 1] + boxes[:, 3])\n\n        dx = deltas[:, 0::4]\n        dy = deltas[:, 1::4]\n        dw = deltas[:, 2::4]\n        dh = deltas[:, 3::4]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = ctr_x[:, None] - dx  # x1\n        pred_boxes[:, 1::4] = ctr_y[:, None] - dy  # y1\n        pred_boxes[:, 2::4] = ctr_x[:, None] + dw  # x2\n        pred_boxes[:, 3::4] = ctr_y[:, None] + dh  # y2\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert deltas.shape[1] % 4 == 0 and boxes.shape[1] == 4\n\n        boxes = boxes.to(deltas.dtype)\n\n        dx = deltas[:, 0::4]\n        dy = deltas[:, 1::4]\n        dw = deltas[:, 2::4]\n        dh = deltas[:, 3::4]\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = dx * boxes[:, 2] + boxes[:, 0]  # x1\n        pred_boxes[:, 1::4] = dy * boxes[:, 3] + boxes[:, 1]  # y1\n        pred_boxes[:, 2::4] = torch.exp(dw) * boxes[:, 2]  # width\n        pred_boxes[:, 3::4] = torch.exp(dh) * boxes[:, 3]  # height\n\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        # Ensure the output is a valid box. See Sec 2.1 of https://arxiv.org/abs/2006.09214\n        deltas = F.relu(deltas)\n        boxes = boxes.to(deltas.dtype)\n\n        ctr_x = 0.5 * (boxes[:, 0] + boxes[:, 2])\n        ctr_y = 0.5 * (boxes[:, 1] + boxes[:, 3])\n\n        dx = deltas[:, 0::4]\n        dy = deltas[:, 1::4]\n        dw = deltas[:, 2::4]\n        dh = deltas[:, 3::4]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = ctr_x[:, None] + dx  # x1\n        pred_boxes[:, 1::4] = ctr_y[:, None] + dy  # y1\n        pred_boxes[:, 2::4] = torch.exp(dw) * (boxes[:, 2] - boxes[:, 0])  # width\n        pred_boxes[:, 3::4] = torch.exp(dh) * (boxes[:, 3] - boxes[:, 1])  # height\n\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        # Ensure the output is a valid box. See Sec 2.1 of https://arxiv.org/abs/2006.09214\n        deltas = F.relu(deltas)\n        boxes = boxes.to(deltas.dtype)\n\n        ctr_x = 0.5 * (boxes[:, 0] + boxes[:, 2])\n        ctr_y = 0.5 * (boxes[:, 1] + boxes[:, 3])\n\n        dx = deltas[:, 0::4]  # dx\n        dy = deltas[:, 1::4]  # dy\n        dw = deltas[:, 2::4]  # dw\n        dh = deltas[:, 3::4]  # dh\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = dx + ctr_x[:, None] - 0.5 * dw  # x1\n        pred_boxes[:, 1::4] = dy + ctr_y[:, None] - 0.5 * dh  # y1\n        pred_boxes[:, 2::4] = dx + ctr_x[:, None] + 0.5 * dw  # x2\n        pred_boxes[:, 3::4] = dy + ctr_y[:, None] + 0.5 * dh  # y2\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        # Ensure the output is a valid box. See Sec 2.1 of https://arxiv.org/abs/2006.09214\n        deltas = F.relu(deltas)\n        boxes = boxes.to(deltas.dtype)\n\n        ctr_x = 0.5 * (boxes[:, 0] + boxes[:, 2])\n        ctr_y = 0.5 * (boxes[:, 1] + boxes[:, 3])\n\n        dx = deltas[:, 0::4]\n        dy = deltas[:, 1::4]\n        dw = deltas[:, 2::4]\n        dh = deltas[:, 3::4]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = dx + ctr_x - 0.5 * dw  # x1\n        pred_boxes[:, 1::4] = dy + ctr_y - 0.5 * dh  # y1\n        pred_boxes[:, 2::4] = dx + ctr_x + 0.5 * dw  # x2\n        pred_boxes[:, 3::4] = dy + ctr_y + 0.5 * dh  # y2\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        # Ensure the output is a valid box. See Sec 2.1 of https://arxiv.org/abs/2006.09214\n        deltas = F.relu(deltas)\n        boxes = boxes.to(deltas.dtype)\n\n        ctr_x = 0.5 * (boxes[:, 0] + boxes[:, 2])\n        ctr_y = 0.5 * (boxes[:, 1] + boxes[:, 3])\n\n        dx = deltas[:, 0::4]\n        dy = deltas[:, 1::4]\n        dw = deltas[:, 2::4]\n        dh = deltas[:, 3::4]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = dx + ctr_x[:, None] - 0.5 * dw * (boxes[:, 2] - boxes[:, 0])  # x1\n        pred_boxes[:, 1::4] = dy + ctr_y[:, None] - 0.5 * dh * (boxes[:, 3] - boxes[:, 1])  # y1\n        pred_boxes[:, 2::4] = dx + ctr_x[:, None] + 0.5 * dw * (boxes[:, 2] - boxes[:, 0])  # x2\n        pred_boxes[:, 3::4] = dy + ctr_y[:, None] + 0.5 * dh * (boxes[:, 3] - boxes[:, 1])  # y2\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        # Ensure the output is a valid box. See Sec 2.1 of https://arxiv.org/abs/2006.09214\n        deltas = F.relu(deltas)\n        boxes = boxes.to(deltas.dtype)\n\n        ctr_x = 0.5 * (boxes[:, 0] + boxes[:, 2])\n        ctr_y = 0.5 * (boxes[:, 1] + boxes[:, 3])\n\n        dx = deltas[:, 0::4]\n        dy = deltas[:, 1::4]\n        dw = deltas[:, 2::4]\n        dh = deltas[:, 3::4]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = ctr_x[:, None] + dx  # x1\n        pred_boxes[:, 1::4] = ctr_y[:, None] + dy  # y1\n        pred_boxes[:, 2::4] = ctr_x[:, None] + dw  # x2\n        pred_boxes[:, 3::4] = ctr_y[:, None] + dh  # y2\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        # Ensure the output is a valid box. See Sec 2.1 of https://arxiv.org/abs/2006.09214\n        deltas = F.relu(deltas)\n        boxes = boxes.to(deltas.dtype)\n\n        ctr_x = 0.5 * (boxes[:, 0] + boxes[:, 2])\n        ctr_y = 0.5 * (boxes[:, 1] + boxes[:, 3])\n\n        dx = deltas[:, 0::4]\n        dy = deltas[:, 1::4]\n        dw = deltas[:, 2::4]\n        dh = deltas[:, 3::4]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = ctr_x[:, None] - dx  # x1\n        pred_boxes[:, 1::4] = ctr_y[:, None] - dy  # y1\n        pred_boxes[:, 2::4] = ctr_x[:, None] + dw  # x2\n        pred_boxes[:, 3::4] = ctr_y[:, None] + dh  # y2\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        # Ensure the output is a valid box. See Sec 2.1 of https://arxiv.org/abs/2006.09214\n        deltas = F.relu(deltas)\n        boxes = boxes.to(deltas.dtype)\n\n        ctr_x = 0.5 * (boxes[:, 0] + boxes[:, 2])\n        ctr_y = 0.5 * (boxes[:, 1] + boxes[:, 3])\n\n        dx = deltas[:, 0::4]\n        dy = deltas[:, 1::4]\n        dw = deltas[:, 2::4]\n        dh = deltas[:, 3::4]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = dx + ctr_x[:, None] - 0.5 * dw  # x1\n        pred_boxes[:, 1::4] = dy + ctr_y[:, None] - 0.5 * dh  # y1\n        pred_boxes[:, 2::4] = dx + ctr_x[:, None] + 0.5 * dw  # x2\n        pred_boxes[:, 3::4] = dy + ctr_y[:, None] + 0.5 * dh  # y2\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        # Ensure the output is a valid box. See Sec 2.1 of https://arxiv.org/abs/2006.09214\n        deltas = F.relu(deltas)\n        boxes = boxes.to(deltas.dtype)\n\n        ctr_x = 0.5 * (boxes[:, 0] + boxes[:, 2])\n        ctr_y = 0.5 * (boxes[:, 1] + boxes[:, 3])\n\n        dx = deltas[:, 0::4]\n        dy = deltas[:, 1::4]\n        dw = deltas[:, 2::4]\n        dh = deltas[:, 3::4]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = ctr_x[:, None] + dx  # x1\n        pred_boxes[:, 1::4] = ctr_y[:, None] + dy  # y1\n        pred_boxes[:, 2::4] = torch.exp(dw) * (boxes[:, 2] - boxes[:, 0])  # width\n        pred_boxes[:, 3::4] = torch.exp(dh) * (boxes[:, 3] - boxes[:, 1])  # height\n\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        # Ensure the output is a valid box. See Sec 2.1 of https://arxiv.org/abs/2006.09214\n        deltas = F.relu(deltas)\n        boxes = boxes.to(deltas.dtype)\n\n        ctr_x = 0.5 * (boxes[:, 0] + boxes[:, 2])\n        ctr_y = 0.5 * (boxes[:, 1] + boxes[:, 3])\n\n        dx = deltas[:, 0::4]\n        dy = deltas[:, 1::4]\n        dw = deltas[:, 2::4]\n        dh = deltas[:, 3::4]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = ctr_x[:, None] + dx  # x1\n        pred_boxes[:, 1::4] = ctr_y[:, None] + dy  # y1\n        pred_boxes[:, 2::4] = torch.exp(dw) * (boxes[:, 2] - boxes[:, 0])  # width\n        pred_boxes[:, 3::4] = torch.exp(dh) * (boxes[:, 3] - boxes[:, 1])  # height\n\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert deltas.shape[1] % 4 == 0 and boxes.shape[1] == 4\n\n        boxes = boxes.to(deltas.dtype).unsqueeze(2)\n\n        ctr_x = 0.5 * (boxes[:, 0] + boxes[:, 2])\n        ctr_y = 0.5 * (boxes[:, 1] + boxes[:, 3])\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n\n        wx, wy, ww, wh = self.weights\n\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = dx * widths + ctr_x  # x_ctr\n        pred_boxes[:, 1::4] = dy * heights + ctr_y  # y_ctr\n        pred_boxes[:, 2::4] = torch.exp(dw) * widths  # width\n        pred_boxes[:, 3::4] = torch.exp(dh) * heights  # height\n\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        # Ensure the output is a valid box. See Sec 2.1 of https://arxiv.org/abs/2006.09214\n        deltas = F.relu(deltas)\n        boxes = boxes.to(deltas.dtype)\n\n        ctr_x = 0.5 * (boxes[:, 0] + boxes[:, 2])\n        ctr_y = 0.5 * (boxes[:, 1] + boxes[:, 3])\n\n        dx = deltas[:, 0::4]\n        dy = deltas[:, 1::4]\n        dw = deltas[:, 2::4]\n        dh = deltas[:, 3::4]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = dx + ctr_x[:, None] - 0.5 * dw  # x1\n        pred_boxes[:, 1::4] = dy + ctr_y[:, None] - 0.5 * dh  # y1\n        pred_boxes[:, 2::4] = dx + ctr_x[:, None] + 0.5 * dw  # x2\n        pred_boxes[:, 3::4] = dy + ctr_y[:, None] + 0.5 * dh  # y2\n        return pred_boxes"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        img, k = resize_image(image, 512)\n        img = img.astype(np.float32) / 255.0\n        img = np.transpose(img, (2, 0, 1))\n        img = np.expand_dims(img, axis=0)\n        result = self.general_ins({'img': img})\n        if anno_type is None:\n            return result\n        elif isinstance(anno_type, str):\n            return result[anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            return {key: result[key] for key in anno_type if key in result}\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        img, k = resize_image(image, 512)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = np.transpose(img, (2, 0, 1))\n        img = np.expand_dims(img, axis=0)\n        outputs = self.general_ins({'img': img})\n        if anno_type is None:\n            return outputs\n        elif isinstance(anno_type, str):\n            return outputs[anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            return {anno: outputs[anno] for anno in anno_type if anno in outputs}\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        img, k = resize_image(image, 512)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = np.transpose(img, (2, 0, 1))\n        img = np.expand_dims(img, axis=0)\n        img = img.astype(np.float32) / 255.0\n        img = (img - 0.5) / 0.5\n\n        with torch.no_grad():\n            output = self.general_ins({'img': torch.from_numpy(img)})\n\n        if anno_type is not None:\n            if isinstance(anno_type, str):\n                return output[anno_type]\n            elif isinstance(anno_type, (list, tuple)):\n                return {anno: output[anno] for anno in anno_type if anno in output}\n        else:\n            return output"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        img, k = resize_image(image, 512)\n        img = np.transpose(img, (2, 0, 1))\n        img = np.expand_dims(img, axis=0)\n        img = np.ascontiguousarray(img, dtype=np.float32)\n        img = img / 255.0\n        img = (img - 0.5) / 0.5\n        with torch.no_grad():\n            output = self.general_ins(img)\n        output = output[0]\n\n        if anno_type is None:\n            return output\n        elif isinstance(anno_type, str):\n            return output[anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            return {tp: output[tp] for tp in anno_type if tp in output.keys()}\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        img, k = resize_image(image, 512)\n        img = np.transpose(img, (2, 0, 1))\n        img = np.expand_dims(img, axis=0)\n        img = img.astype(np.float32) / 255.0\n        img = (img - 0.5) / 0.5\n\n        with torch.no_grad():\n            output = self.general_ins({'img': img})\n\n        if anno_type is None:\n            return output\n        elif isinstance(anno_type, str):\n            return output.get(anno_type, None)\n        elif isinstance(anno_type, (list, tuple)):\n            return {key: output[key] for key in anno_type if key in output}\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        img, k = resize_image(image, 512)\n        img = np.array(img, dtype=np.float32)\n        img = np.transpose(img, (2, 0, 1))\n        img = np.expand_dims(img, axis=0)\n        img = img / 255.0\n        img = torch.from_numpy(img).to(we.device_id)\n\n        with torch.no_grad():\n            output = self.general_ins(img)\n\n        if anno_type is not None:\n            if isinstance(anno_type, str):\n                return output[anno_type]\n            elif isinstance(anno_type, (list, tuple)):\n                return {anno: output[anno] for anno in anno_type}\n        else:\n            return output"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        img, k = resize_image(image, 512)\n        img = np.transpose(img, (2, 0, 1))\n        img = img[np.newaxis, ...]\n        img = img.astype(np.float32)\n        img = img / 255.0\n        img = (img - 0.5) / 0.5\n\n        with torch.no_grad():\n            output = self.general_ins({'img': img})\n\n        if anno_type is not None:\n            if isinstance(anno_type, str):\n                assert anno_type in self.anno_type_map.keys()\n                anno_type = [anno_type]\n            elif isinstance(anno_type, (list, tuple)):\n                assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n            else:\n                raise Exception(f'Error anno_type: {anno_type}')\n\n            result = {}\n            for tp in anno_type:\n                if tp in output:\n                    result[tp] = output[tp]\n            return result if result else None\n        else:\n            return output"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        img, k = resize_image(image, 512)\n        img = np.transpose(img, (2, 0, 1))\n        img = np.expand_dims(img, axis=0)\n        img = img.astype(np.float32) / 255.0\n        img = (img - 0.5) / 0.5\n        with torch.no_grad():\n            output = self.general_ins({'img': img})\n        if anno_type is not None:\n            if isinstance(anno_type, str):\n                assert anno_type in self.anno_type_map.keys()\n                anno_type = [anno_type]\n            elif isinstance(anno_type, (list, tuple)):\n                assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n            else:\n                raise Exception(f'Error anno_type: {anno_type}')\n            result = {}\n            for tp in anno_type:\n                if tp in output:\n                    result[tp] = output[tp]\n            return result if result else None\n        else:\n            return output"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        input_image, k = resize_image(image, 512)\n        input_image = input_image.astype(np.float32) / 255.0\n        input_image = np.transpose(input_image, (2, 0, 1))\n        input_image = np.expand_dims(input_image, 0)\n\n        with torch.no_grad():\n            output = self.general_ins({'img': input_image})\n        \n        if anno_type is None:\n            return output\n        elif isinstance(anno_type, str):\n            return output[anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            return {anno: output[anno] for anno in anno_type if anno in output}\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        img, k = resize_image(image, 512)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = np.transpose(img, (2, 0, 1))\n        img = img[np.newaxis, ...]\n        img = img.astype(np.float32) / 255.0\n        img = (img - 0.5) / 0.5\n\n        with torch.no_grad():\n            input_data = {'img': torch.from_numpy(img)}\n            output_data = self.general_ins(input_data)\n\n        if anno_type is None:\n            return output_data\n        elif isinstance(anno_type, str):\n            return output_data[anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            return {anno: output_data[anno] for anno in anno_type if anno in output_data}\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        img, k = resize_image(image, 512)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = np.transpose(img, (2, 0, 1))\n        img = np.expand_dims(img, axis=0)\n        output = self.general_ins({'img': img})\n        if anno_type:\n            if isinstance(anno_type, str):\n                return output[anno_type]\n            elif isinstance(anno_type, (list, tuple)):\n                return {anno: output[anno] for anno in anno_type if anno in output}\n        return output"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        img, k = resize_image(image, 512)\n        img = img.astype(np.float32) / 255.0\n        img = np.transpose(img, (2, 0, 1))\n        img = np.expand_dims(img, axis=0)\n\n        with torch.no_grad():\n            output = self.general_ins({'img': img})\n\n        if anno_type is None:\n            return output\n        elif isinstance(anno_type, str):\n            return output.get(anno_type, None)\n        elif isinstance(anno_type, (list, tuple)):\n            return {key: output.get(key, None) for key in anno_type}\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        img, k = resize_image(image, 512)\n        img = np.transpose(img, (2, 0, 1))\n        img = np.expand_dims(img, 0)\n        img = img.astype(np.float32)\n        img /= 255.0\n        img = torch.from_numpy(img).to(we.device_id)\n\n        with torch.no_grad():\n            output = self.general_ins({'img': img})\n\n        if anno_type is None:\n            return output\n        elif isinstance(anno_type, str):\n            return output.get(anno_type, None)\n        elif isinstance(anno_type, (list, tuple)):\n            return {anno: output.get(anno, None) for anno in anno_type}\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        img, k = resize_image(image, 512)\n        img = np.expand_dims(img, axis=0)\n        img = np.transpose(img, (0, 3, 1, 2))\n        with torch.no_grad():\n            output = self.general_ins({'img': img})\n        if anno_type is not None:\n            if isinstance(anno_type, str):\n                assert anno_type in self.anno_type_map.keys()\n                anno_type = [anno_type]\n            elif isinstance(anno_type, (list, tuple)):\n                assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n            else:\n                raise Exception(f'Error anno_type: {anno_type}')\n            result = {}\n            for tp in anno_type:\n                if tp in output.keys():\n                    result[tp] = output[tp]\n            return result\n        else:\n            return output"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        img, k = resize_image(image, 512)\n        img = img.astype(np.float32) / 255.0\n        img = np.transpose(img, (2, 0, 1))\n        img = np.expand_dims(img, axis=0)\n        img = torch.from_numpy(img)\n        with torch.no_grad():\n            output = self.general_ins(img)\n        result = {}\n        for anno in output:\n            if anno_type is None or anno in anno_type:\n                result[anno] = output[anno]\n        if len(result) == 1:\n            return list(result.values())[0]\n        elif len(result) > 1:\n            return result\n        else:\n            return output"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        img, k = resize_image(image, 512)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = np.transpose(img, (2, 0, 1))\n        img = img[np.newaxis, ...]\n        output = self.general_ins({'img': img})\n\n        if anno_type is None:\n            return output\n        elif isinstance(anno_type, str):\n            return output[anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            return {anno: output[anno] for anno in anno_type if anno in output}\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        img, k = resize_image(image, 512)\n        img = img[:, :, ::-1].transpose(2, 0, 1).copy()\n        img = np.ascontiguousarray(img, dtype=np.float32) / 255.0\n        img = np.expand_dims(img, axis=0)\n        self.general_ins.run({'img': img})\n        output = self.general_ins.get_output()\n        if anno_type is not None:\n            if isinstance(anno_type, str):\n                return output[anno_type]\n            elif isinstance(anno_type, (list, tuple)):\n                return {anno: output[anno] for anno in anno_type if anno in output}\n        return output"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        img, k = resize_image(image, 512)\n        img = img.astype(np.float32) / 255.0\n        img = np.transpose(img, (2, 0, 1))\n        img = np.expand_dims(img, axis=0)\n\n        self.general_ins.eval()\n        with torch.no_grad():\n            output = self.general_ins(img)\n\n        if anno_type is not None:\n            if isinstance(anno_type, str):\n                return output[anno_type]\n            elif isinstance(anno_type, (list, tuple)):\n                return {anno: output[anno] for anno in anno_type if anno in output}\n        else:\n            return output"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        img, k = resize_image(image, 512)\n        img = np.ascontiguousarray(img)\n        img = np.transpose(img, (2, 0, 1))\n        img = np.expand_dims(img, axis=0)\n        with torch.no_grad():\n            output = self.general_ins({'img': img})\n        if anno_type is None:\n            return output\n        elif isinstance(anno_type, str):\n            return output[anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            return {anno: output[anno] for anno in anno_type if anno in output}\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        img, k = resize_image(image, 1024)\n        img = np.ascontiguousarray(img)\n        img = np.transpose(img, (2, 0, 1))\n        img = np.expand_dims(img, axis=0)\n        img = img.astype(np.float32)\n        img = (img - 127.5) / 127.5\n        input_dict = {'img': img}\n        output_dict = self.general_ins(input_dict)\n        if anno_type is None:\n            return output_dict\n        elif isinstance(anno_type, str):\n            return output_dict.get(anno_type, None)\n        elif isinstance(anno_type, (list, tuple)):\n            return {key: output_dict.get(key, None) for key in anno_type}\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query_keywords = normalize_string(query).split(\" \")\n        result = {}\n        for keyword in query_keywords:\n            scores = self.bm25(keyword)\n            result = update_url_scores(result, scores)\n        return result"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        result = {}\n        keywords = normalize_string(query).split(\" \")\n        for kw in keywords:\n            scores = self.bm25(kw)\n            result = update_url_scores(result, scores)\n        return result"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        result = {}\n        keywords = normalize_string(query).split(\" \")\n        for kw in keywords:\n            scores = self.bm25(kw)\n            result = update_url_scores(result, scores)\n        return result"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        result = {}\n        keywords = normalize_string(query).split(\" \")\n        for keyword in keywords:\n            scores = self.bm25(keyword)\n            result = update_url_scores(result, scores)\n        return result"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        result = {}\n        keywords = normalize_string(query).split(\" \")\n        for keyword in keywords:\n            scores = self.bm25(keyword)\n            result = update_url_scores(result, scores)\n        return result"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        result = {}\n        keywords = normalize_string(query).split(\" \")\n        for kw in keywords:\n            scores = self.bm25(kw)\n            result = update_url_scores(result, scores)\n        return result"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query_keywords = normalize_string(query).split(\" \")\n        result = {}\n        for keyword in query_keywords:\n            scores = self.bm25(keyword)\n            result = update_url_scores(result, scores)\n        return result"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        result = {}\n        keywords = normalize_string(query).split(\" \")\n        for keyword in keywords:\n            scores = self.bm25(keyword)\n            result = update_url_scores(result, scores)\n        return result"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        result = {}\n        keywords = normalize_string(query).split(\" \")\n        for keyword in keywords:\n            scores = self.bm25(keyword)\n            result = update_url_scores(result, scores)\n        return result"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        result = {}\n        keywords = normalize_string(query).split(\" \")\n        for kw in keywords:\n            scores = self.bm25(kw)\n            result = update_url_scores(result, scores)\n        return result"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        scores = defaultdict(float)\n        keywords = normalize_string(query).split()\n        for keyword in keywords:\n            bm25_scores = self.bm25(keyword)\n            for url, score in bm25_scores.items():\n                scores[url] += score\n        return scores"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "\n        result = {}\n        keywords = normalize_string(query).split(\" \")\n        for kw in keywords:\n            scores = self.bm25(kw)\n            result = update_url_scores(result, scores)\n        return result"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        result = {}\n        keywords = normalize_string(query).split(\" \")\n        for keyword in keywords:\n            scores = self.bm25(keyword)\n            result = update_url_scores(result, scores)\n        return result"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        result = {}\n        keywords = normalize_string(query).split(\" \")\n        for kw in keywords:\n            scores = self.bm25(kw)\n            result = update_url_scores(result, scores)\n        return result"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        result = {}\n        keywords = normalize_string(query).split(\" \")\n        for keyword in keywords:\n            scores = self.bm25(keyword)\n            result = update_url_scores(result, scores)\n        return result"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        result = {}\n        keywords = normalize_string(query).split(\" \")\n        for kw in keywords:\n            scores = self.bm25(kw)\n            result = update_url_scores(result, scores)\n        return result"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        result = {}\n        keywords = normalize_string(query).split(\" \")\n        for keyword in keywords:\n            scores = self.bm25(keyword)\n            result = update_url_scores(result, scores)\n        return result"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        result = {}\n        keywords = normalize_string(query).split(\" \")\n        for kw in keywords:\n            scores = self.bm25(kw)\n            result = update_url_scores(result, scores)\n        return result"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        result = {}\n        keywords = normalize_string(query).split()\n        for keyword in keywords:\n            scores = self.bm25(keyword)\n            result = update_url_scores(result, scores)\n        return result"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        scores = {}\n        keywords = normalize_string(query).split(\" \")\n        for keyword in keywords:\n            bm25_scores = self.bm25(keyword)\n            scores = update_url_scores(scores, bm25_scores)\n        return scores"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "\n        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "\n        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "\n        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        height, width = box_size\n        self.normalize_angles()\n        horizontal_boxes = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n        horizontal_boxes_indices = torch.nonzero(horizontal_boxes, as_tuple=False).squeeze(1)\n\n        if len(horizontal_boxes_indices) > 0:\n            horizontal_boxes = self.tensor[horizontal_boxes_indices]\n            x_center, y_center, w, h, angle = horizontal_boxes.unbind(dim=1)\n\n            # Convert to (x1, y1, x2, y2)\n            x1 = x_center - w / 2\n            y1 = y_center - h / 2\n            x2 = x_center + w / 2\n            y2 = y_center + h / 2\n\n            # Clamp x and y coordinates to fit within box_size\n            x1 = torch.clamp(x1, 0, width)\n            y1 = torch.clamp(y1, 0, height)\n            x2 = torch.clamp(x2, 0, width)\n            y2 = torch.clamp(y2, 0, height)\n\n            # Convert back to (x_center, y_center, width, height, angle)\n            w = x2 - x1\n            h = y2 - y1\n            x_center = (x1 + x2) / 2\n            y_center = (y1 + y2) / 2\n\n            self.tensor[horizontal_boxes_indices] = torch.stack([x_center, y_center, w, h, angle], dim=1)"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        height, width = box_size\n        self.normalize_angles()\n        horizontal_boxes = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n        for i in range(len(self)):\n            if horizontal_boxes[i]:\n                x_center, y_center, w, h, angle = self.tensor[i]\n                cos_theta = torch.cos(angle * math.pi / 180.0)\n                sin_theta = torch.sin(angle * math.pi / 180.0)\n                x1 = x_center - w / 2 * cos_theta - h / 2 * sin_theta\n                y1 = y_center - w / 2 * sin_theta + h / 2 * cos_theta\n                x2 = x_center + w / 2 * cos_theta + h / 2 * sin_theta\n                y2 = y_center + w / 2 * sin_theta - h / 2 * cos_theta\n                x1 = max(0, min(width, x1))\n                y1 = max(0, min(height, y1))\n                x2 = max(0, min(width, x2))\n                y2 = max(0, min(height, y2))\n                w_clipped = x2 - x1\n                h_clipped = y2 - y1\n                self.tensor[i] = torch.tensor([x1 + w_clipped / 2, y1 + h_clipped / 2, w_clipped, h_clipped, angle])"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        height, width = box_size\n        box = self.tensor\n        self.normalize_angles()\n\n        # Identify nearly horizontal boxes based on the clip_angle_threshold\n        nearly_horizontal = torch.abs(box[:, 4]) < clip_angle_threshold\n\n        # Convert representation from (center x, center y, width, height, angle) to (x1, y1, x2, y2)\n        x1 = box[:, 0] - box[:, 2] / 2.0\n        y1 = box[:, 1] - box[:, 3] / 2.0\n        x2 = box[:, 0] + box[:, 2] / 2.0\n        y2 = box[:, 1] + box[:, 3] / 2.0\n\n        # Clamp x and y coordinates to ensure they do not exceed the specified box_size limits\n        x1 = torch.clamp(x1, min=0, max=width)\n        y1 = torch.clamp(y1, min=0, max=height)\n        x2 = torch.clamp(x2, min=0, max=width)\n        y2 = torch.clamp(y2, min=0, max=height)\n\n        # Convert back to original representation\n        box[:, 0] = (x1 + x2) / 2.0\n        box[:, 1] = (y1 + y2) / 2.0\n        box[:, 2] = torch.abs(x2 - x1)\n        box[:, 3] = torch.abs(y2 - y1)"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        height, width = box_size\n        self.normalize_angles()\n        nearly_horizontal = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n        nearly_horizontal_boxes = self.tensor[nearly_horizontal]\n\n        if nearly_horizontal_boxes.size(0) > 0:\n            x1 = nearly_horizontal_boxes[:, 0] - nearly_horizontal_boxes[:, 2] / 2.0\n            y1 = nearly_horizontal_boxes[:, 1] - nearly_horizontal_boxes[:, 3] / 2.0\n            x2 = nearly_horizontal_boxes[:, 0] + nearly_horizontal_boxes[:, 2] / 2.0\n            y2 = nearly_horizontal_boxes[:, 1] + nearly_horizontal_boxes[:, 3] / 2.0\n\n            x1 = torch.clamp(x1, 0, width)\n            y1 = torch.clamp(y1, 0, height)\n            x2 = torch.clamp(x2, 0, width)\n            y2 = torch.clamp(y2, 0, height)\n\n            nearly_horizontal_boxes[:, 0] = (x1 + x2) / 2.0\n            nearly_horizontal_boxes[:, 1] = (y1 + y2) / 2.0\n            nearly_horizontal_boxes[:, 2] = torch.abs(x2 - x1)\n            nearly_horizontal_boxes[:, 3] = torch.abs(y2 - y1)\n\n            self.tensor[nearly_horizontal] = nearly_horizontal_boxes"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        height, width = box_size\n        self.normalize_angles()\n        horizontal_boxes = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n        horizontal_boxes_indices = torch.nonzero(horizontal_boxes, as_tuple=False).squeeze(1)\n\n        if horizontal_boxes_indices.numel() > 0:\n            horizontal_boxes = self.tensor[horizontal_boxes_indices]\n            horizontal_boxes[:, 4] = 0  # Set angle to 0 for horizontal boxes\n            half_width = horizontal_boxes[:, 2] / 2\n            half_height = horizontal_boxes[:, 3] / 2\n            x1 = horizontal_boxes[:, 0] - half_width\n            y1 = horizontal_boxes[:, 1] - half_height\n            x2 = horizontal_boxes[:, 0] + half_width\n            y2 = horizontal_boxes[:, 1] + half_height\n\n            x1 = torch.clamp(x1, min=0, max=width)\n            y1 = torch.clamp(y1, min=0, max=height)\n            x2 = torch.clamp(x2, min=0, max=width)\n            y2 = torch.clamp(y2, min=0, max=height)\n\n            horizontal_boxes[:, 0] = (x1 + x2) / 2\n            horizontal_boxes[:, 1] = (y1 + y2) / 2\n            horizontal_boxes[:, 2] = x2 - x1\n            horizontal_boxes[:, 3] = y2 - y1\n\n            self.tensor[horizontal_boxes_indices] = horizontal_boxes"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        height, width = box_size\n        self.normalize_angles()\n        nearly_horizontal = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n        x_c, y_c, w, h, a = self.tensor[nearly_horizontal].unbind(dim=1)\n        x1 = x_c - w / 2\n        y1 = y_c - h / 2\n        x2 = x_c + w / 2\n        y2 = y_c + h / 2\n        x1 = torch.clamp(x1, 0, width)\n        y1 = torch.clamp(y1, 0, height)\n        x2 = torch.clamp(x2, 0, width)\n        y2 = torch.clamp(y2, 0, height)\n        w_clipped = x2 - x1\n        h_clipped = y2 - y1\n        self.tensor[nearly_horizontal] = torch.stack([x1 + w_clipped / 2, y1 + h_clipped / 2, w_clipped, h_clipped, a], dim=1)"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        height, width = box_size\n        self.normalize_angles()\n        horizontal_boxes = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n        horizontal_boxes_indices = torch.where(horizontal_boxes)[0]\n        for idx in horizontal_boxes_indices:\n            box = self.tensor[idx]\n            x_c, y_c, w, h, angle = box\n            x1 = x_c - w / 2\n            x2 = x_c + w / 2\n            y1 = y_c - h / 2\n            y2 = y_c + h / 2\n            x1 = max(0, min(x1, width))\n            x2 = max(0, min(x2, width))\n            y1 = max(0, min(y1, height))\n            y2 = max(0, min(y2, height))\n            w = x2 - x1\n            h = y2 - y1\n            x_c = (x1 + x2) / 2\n            y_c = (y1 + y2) / 2\n            self.tensor[idx] = torch.tensor([x_c, y_c, w, h, angle])"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        height, width = box_size\n        self.normalize_angles()\n        nearly_horizontal = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n        if nearly_horizontal.any():\n            boxes = self.tensor[nearly_horizontal]\n            x_c, y_c, w, h, a = boxes.unbind(dim=1)\n            cos_a = torch.cos(a * math.pi / 180.0)\n            sin_a = torch.sin(a * math.pi / 180.0)\n            x1 = x_c - w / 2 * cos_a - h / 2 * sin_a\n            y1 = y_c - w / 2 * sin_a + h / 2 * cos_a\n            x2 = x_c + w / 2 * cos_a + h / 2 * sin_a\n            y2 = y_c + w / 2 * sin_a - h / 2 * cos_a\n            x1 = torch.clamp(x1, 0, width)\n            y1 = torch.clamp(y1, 0, height)\n            x2 = torch.clamp(x2, 0, width)\n            y2 = torch.clamp(y2, 0, height)\n            w = x2 - x1\n            h = y2 - y1\n            x_c = (x1 + x2) / 2\n            y_c = (y1 + y2) / 2\n            self.tensor[nearly_horizontal] = torch.stack([x_c, y_c, w, h, a], dim=1)"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        height, width = box_size\n        self.normalize_angles()\n        nearly_horizontal = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n        x_c, y_c, w, h, angle = self.tensor[nearly_horizontal].unbind(dim=1)\n        x1 = x_c - w / 2\n        y1 = y_c - h / 2\n        x2 = x_c + w / 2\n        y2 = y_c + h / 2\n        x1 = torch.clamp(x1, 0, width)\n        x2 = torch.clamp(x2, 0, width)\n        y1 = torch.clamp(y1, 0, height)\n        y2 = torch.clamp(y2, 0, height)\n        w = x2 - x1\n        h = y2 - y1\n        self.tensor[nearly_horizontal] = torch.stack([x1, y1, w, h, angle], dim=1)"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        height, width = box_size\n        self.normalize_angles()\n\n        # Identify nearly horizontal boxes\n        horizontal_boxes = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n\n        # Convert representation to (x1, y1, x2, y2)\n        x_center, y_center, w, h, angle = self.tensor[:, 0], self.tensor[:, 1], self.tensor[:, 2], self.tensor[:, 3], self.tensor[:, 4]\n        cos_theta = torch.cos(angle * math.pi / 180.0)\n        sin_theta = torch.sin(angle * math.pi / 180.0)\n        x1 = x_center - w / 2 * cos_theta - h / 2 * sin_theta\n        y1 = y_center - w / 2 * sin_theta + h / 2 * cos_theta\n        x2 = x_center + w / 2 * cos_theta + h / 2 * sin_theta\n        y2 = y_center + w / 2 * sin_theta - h / 2 * cos_theta\n\n        # Clamp x and y coordinates\n        x1 = torch.clamp(x1, min=0, max=width)\n        y1 = torch.clamp(y1, min=0, max=height)\n        x2 = torch.clamp(x2, min=0, max=width)\n        y2 = torch.clamp(y2, min=0, max=height)\n\n        # Convert back to original representation\n        self.tensor[horizontal_boxes, 0] = (x1[horizontal_boxes] + x2[horizontal_boxes]) / 2\n        self.tensor[horizontal_boxes, 1] = (y1[horizontal_boxes] + y2[horizontal_boxes]) / 2\n        self.tensor[horizontal_boxes, 2] = torch.abs(x2[horizontal_boxes] - x1[horizontal_boxes])\n        self.tensor[horizontal_boxes, 3] = torch.abs(y2[horizontal_boxes] - y1[horizontal_boxes])\n        self.tensor[horizontal_boxes, 4] = angle[horizontal_boxes]"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        height, width = box_size\n        self.normalize_angles()\n        nearly_horizontal = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n        nearly_horizontal_boxes = self.tensor[nearly_horizontal]\n\n        if len(nearly_horizontal_boxes) > 0:\n            x_c, y_c, w, h, a = nearly_horizontal_boxes.unbind(dim=1)\n            x1 = x_c - w / 2\n            y1 = y_c - h / 2\n            x2 = x_c + w / 2\n            y2 = y_c + h / 2\n\n            x1 = torch.clamp(x1, 0, width)\n            y1 = torch.clamp(y1, 0, height)\n            x2 = torch.clamp(x2, 0, width)\n            y2 = torch.clamp(y2, 0, height)\n\n            w = x2 - x1\n            h = y2 - y1\n            x_c = (x1 + x2) / 2\n            y_c = (y1 + y2) / 2\n\n            self.tensor[nearly_horizontal] = torch.stack([x_c, y_c, w, h, a], dim=1)"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        height, width = box_size\n\n        # Normalize angles\n        self.normalize_angles()\n\n        # Identify nearly horizontal boxes\n        nearly_horizontal = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n\n        # Convert representation for nearly horizontal boxes\n        horizontal_boxes = self.tensor[nearly_horizontal]\n        if len(horizontal_boxes) > 0:\n            x_center, y_center, w, h, angle = horizontal_boxes.unbind(1)\n            x1 = x_center - w / 2\n            y1 = y_center - h / 2\n            x2 = x_center + w / 2\n            y2 = y_center + h / 2\n\n            # Clamp x and y coordinates to box_size limits\n            x1 = torch.clamp(x1, 0, width)\n            y1 = torch.clamp(y1, 0, height)\n            x2 = torch.clamp(x2, 0, width)\n            y2 = torch.clamp(y2, 0, height)\n\n            # Convert back to original representation\n            w = x2 - x1\n            h = y2 - y1\n            x_center = (x1 + x2) / 2\n            y_center = (y1 + y2) / 2\n            horizontal_boxes = torch.stack((x_center, y_center, w, h, angle), dim=1)\n            self.tensor[nearly_horizontal] = horizontal_boxes"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        height, width = box_size\n        self.normalize_angles()\n        horizontal_boxes = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n        horizontal_boxes_indices = torch.where(horizontal_boxes)[0]\n        for idx in horizontal_boxes_indices:\n            x_c, y_c, w, h, angle = self.tensor[idx]\n            x1 = x_c - w / 2\n            y1 = y_c - h / 2\n            x2 = x_c + w / 2\n            y2 = y_c + h / 2\n            x1 = max(0, min(x1, width))\n            y1 = max(0, min(y1, height))\n            x2 = max(0, min(x2, width))\n            y2 = max(0, min(y2, height))\n            self.tensor[idx] = torch.tensor([x1, y1, x2, y2, angle])"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        height, width = box_size\n        self.normalize_angles()\n        nearly_horizontal = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n        nearly_horizontal_boxes = self.tensor[nearly_horizontal]\n\n        if len(nearly_horizontal_boxes) > 0:\n            x_c, y_c, w, h, angle = nearly_horizontal_boxes.split(1, dim=-1)\n            x1 = x_c - w / 2\n            y1 = y_c - h / 2\n            x2 = x_c + w / 2\n            y2 = y_c + h / 2\n\n            x1 = torch.clamp(x1, min=0, max=width)\n            y1 = torch.clamp(y1, min=0, max=height)\n            x2 = torch.clamp(x2, min=0, max=width)\n            y2 = torch.clamp(y2, min=0, max=height)\n\n            w = x2 - x1\n            h = y2 - y1\n\n            nearly_horizontal_boxes = torch.cat([x1, y1, x2, y2, angle], dim=-1)\n            self.tensor[nearly_horizontal] = nearly_horizontal_boxes\n\n        self.tensor = torch.cat([self.tensor[~nearly_horizontal], nearly_horizontal_boxes], dim=0)"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        height, width = box_size\n        self.normalize_angles()\n        horizontal_boxes = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n        horizontal_boxes_indices = torch.nonzero(horizontal_boxes, as_tuple=False).squeeze(1)\n\n        if len(horizontal_boxes_indices) > 0:\n            boxes = self.tensor[horizontal_boxes_indices]\n            x_center, y_center, w, h, angle = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3], boxes[:, 4]\n\n            cos_theta = torch.abs(torch.cos(angle * math.pi / 180.0))\n            sin_theta = torch.abs(torch.sin(angle * math.pi / 180.0))\n\n            x1 = x_center - (w / 2) * cos_theta - (h / 2) * sin_theta\n            y1 = y_center - (w / 2) * sin_theta + (h / 2) * cos_theta\n            x2 = x_center + (w / 2) * cos_theta + (h / 2) * sin_theta\n            y2 = y_center + (w / 2) * sin_theta - (h / 2) * cos_theta\n\n            x1 = torch.clamp(x1, min=0, max=width)\n            y1 = torch.clamp(y1, min=0, max=height)\n            x2 = torch.clamp(x2, min=0, max=width)\n            y2 = torch.clamp(y2, min=0, max=height)\n\n            w_clipped = x2 - x1\n            h_clipped = y2 - y1\n            x_center_clipped = (x1 + x2) / 2\n            y_center_clipped = (y1 + y2) / 2\n\n            self.tensor[horizontal_boxes_indices] = torch.stack([x_center_clipped, y_center_clipped, w_clipped, h_clipped, angle], dim=1)"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        height, width = box_size\n        self.normalize_angles()\n\n        # Identify nearly horizontal boxes based on the angle threshold\n        horizontal_boxes = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n\n        # Convert representation to (x1, y1, x2, y2) for nearly horizontal boxes\n        x_center, y_center, w, h, angle = self.tensor[horizontal_boxes].unbind(dim=1)\n        x1 = x_center - w / 2\n        y1 = y_center - h / 2\n        x2 = x_center + w / 2\n        y2 = y_center + h / 2\n\n        # Clamp x and y coordinates to ensure they fit within the specified box size\n        x1 = torch.clamp(x1, 0, width)\n        y1 = torch.clamp(y1, 0, height)\n        x2 = torch.clamp(x2, 0, width)\n        y2 = torch.clamp(y2, 0, height)\n\n        # Convert back to original representation\n        self.tensor[horizontal_boxes] = torch.stack([x1, y1, x2, y2, angle], dim=1)"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        height, width = box_size\n        self.normalize_angles()\n        nearly_horizontal = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n        box = self.tensor[nearly_horizontal]\n        x1 = box[:, 0] - box[:, 2] / 2\n        y1 = box[:, 1] - box[:, 3] / 2\n        x2 = box[:, 0] + box[:, 2] / 2\n        y2 = box[:, 1] + box[:, 3] / 2\n        x1 = torch.clamp(x1, 0, width)\n        y1 = torch.clamp(y1, 0, height)\n        x2 = torch.clamp(x2, 0, width)\n        y2 = torch.clamp(y2, 0, height)\n        box[:, 0] = (x1 + x2) / 2\n        box[:, 1] = (y1 + y2) / 2\n        box[:, 2] = x2 - x1\n        box[:, 3] = y2 - y1\n        self.tensor[nearly_horizontal] = box"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        height, width = box_size\n        self.normalize_angles()\n        nearly_horizontal = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n        boxes = self.tensor.clone()\n        boxes[nearly_horizontal, 4] = 0.0  # Set angle to 0 for nearly horizontal boxes\n        x1 = boxes[:, 0] - boxes[:, 2] / 2.0\n        y1 = boxes[:, 1] - boxes[:, 3] / 2.0\n        x2 = boxes[:, 0] + boxes[:, 2] / 2.0\n        y2 = boxes[:, 1] + boxes[:, 3] / 2.0\n        x1 = torch.clamp(x1, 0, width)\n        y1 = torch.clamp(y1, 0, height)\n        x2 = torch.clamp(x2, 0, width)\n        y2 = torch.clamp(y2, 0, height)\n        self.tensor[:, 0] = (x1 + x2) / 2.0\n        self.tensor[:, 1] = (y1 + y2) / 2.0\n        self.tensor[:, 2] = x2 - x1\n        self.tensor[:, 3] = y2 - y1\n        self.tensor[nearly_horizontal, 4] = boxes[nearly_horizontal, 4]  # Restore original angles"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        height, width = box_size\n        self.normalize_angles()\n        nearly_horizontal = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n        x_c, y_c, w, h, angle = self.tensor[nearly_horizontal].unbind(dim=1)\n        x1 = x_c - w / 2\n        x2 = x_c + w / 2\n        y1 = y_c - h / 2\n        y2 = y_c + h / 2\n        x1 = torch.clamp(x1, 0, width)\n        x2 = torch.clamp(x2, 0, width)\n        y1 = torch.clamp(y1, 0, height)\n        y2 = torch.clamp(y2, 0, height)\n        w_clipped = x2 - x1\n        h_clipped = y2 - y1\n        self.tensor[nearly_horizontal] = torch.stack([x1, y1, w_clipped, h_clipped, angle], dim=1)"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        height, width = box_size\n        self.normalize_angles()\n        nearly_horizontal = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n        horizontal_boxes = self.tensor[nearly_horizontal]\n\n        if len(horizontal_boxes) > 0:\n            x_center, y_center, w, h, angle = horizontal_boxes.unbind(dim=1)\n            x1 = x_center - w / 2\n            y1 = y_center - h / 2\n            x2 = x_center + w / 2\n            y2 = y_center + h / 2\n\n            x1 = torch.clamp(x1, 0, width)\n            y1 = torch.clamp(y1, 0, height)\n            x2 = torch.clamp(x2, 0, width)\n            y2 = torch.clamp(y2, 0, height)\n\n            w_clipped = x2 - x1\n            h_clipped = y2 - y1\n\n            self.tensor[nearly_horizontal] = torch.stack([x1 + w_clipped / 2, y1 + h_clipped / 2, w_clipped, h_clipped, angle], dim=1)"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            if 'type' in item:\n                statistics[item['type']] += 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            if 'type' in item:\n                if item['type'] == 'doc':\n                    statistics['doc'] += 1\n                elif item['type'] == 'gen':\n                    statistics['gen'] += 1\n                elif item['type'] == 'kno':\n                    statistics['kno'] += 1\n                elif item['type'] == 'num':\n                    statistics['num'] += 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        type_count = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            if 'type' in item:\n                type_count[item['type']] += 1\n        return type_count"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            if 'type' in item:\n                if item['type'] == 'doc':\n                    statistics['doc'] += 1\n                elif item['type'] == 'gen':\n                    statistics['gen'] += 1\n                elif item['type'] == 'kno':\n                    statistics['kno'] += 1\n                elif item['type'] == 'num':\n                    statistics['num'] += 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            if 'type' in item:\n                if item['type'] == 'doc':\n                    statistics['doc'] += 1\n                elif item['type'] == 'gen':\n                    statistics['gen'] += 1\n                elif item['type'] == 'kno':\n                    statistics['kno'] += 1\n                elif item['type'] == 'num':\n                    statistics['num'] += 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            if 'type' in item:\n                if item['type'] == 'doc':\n                    statistics['doc'] += 1\n                elif item['type'] == 'gen':\n                    statistics['gen'] += 1\n                elif item['type'] == 'kno':\n                    statistics['kno'] += 1\n                elif item['type'] == 'num':\n                    statistics['num'] += 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            if 'type' in item:\n                if item['type'] == 'doc':\n                    statistics['doc'] += 1\n                elif item['type'] == 'gen':\n                    statistics['gen'] += 1\n                elif item['type'] == 'kno':\n                    statistics['kno'] += 1\n                elif item['type'] == 'num':\n                    statistics['num'] += 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            if 'type' in item:\n                statistics[item['type']] += 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            if 'type' in item:\n                if item['type'] == 'doc':\n                    statistics['doc'] += 1\n                elif item['type'] == 'gen':\n                    statistics['gen'] += 1\n                elif item['type'] == 'kno':\n                    statistics['kno'] += 1\n                elif item['type'] == 'num':\n                    statistics['num'] += 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        types_count = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            if 'type' in item:\n                types_count[item['type']] += 1\n        return types_count"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            if 'type' in item:\n                if item['type'] == 'doc':\n                    statistics['doc'] += 1\n                elif item['type'] == 'gen':\n                    statistics['gen'] += 1\n                elif item['type'] == 'kno':\n                    statistics['kno'] += 1\n                elif item['type'] == 'num':\n                    statistics['num'] += 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            if 'type' in item:\n                statistics[item['type']] += 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        type_counts = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            if 'type' in item:\n                type_counts[item['type']] += 1\n        return type_counts"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            if 'type' in item:\n                statistics[item['type']] += 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            if 'type' in item:\n                if item['type'] == 'doc':\n                    statistics['doc'] += 1\n                elif item['type'] == 'gen':\n                    statistics['gen'] += 1\n                elif item['type'] == 'kno':\n                    statistics['kno'] += 1\n                elif item['type'] == 'num':\n                    statistics['num'] += 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0\n        }\n        for item in self.data:\n            if 'type' in item:\n                if item['type'] == 'doc':\n                    statistics['doc'] += 1\n                elif item['type'] == 'gen':\n                    statistics['gen'] += 1\n                elif item['type'] == 'kno':\n                    statistics['kno'] += 1\n                elif item['type'] == 'num':\n                    statistics['num'] += 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n\n        for item in self.data:\n            if 'type' in item:\n                if item['type'] == 'doc':\n                    statistics['doc'] += 1\n                elif item['type'] == 'gen':\n                    statistics['gen'] += 1\n                elif item['type'] == 'kno':\n                    statistics['kno'] += 1\n                elif item['type'] == 'num':\n                    statistics['num'] += 1\n\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            if 'type' in item:\n                if item['type'] == 'doc':\n                    statistics['doc'] += 1\n                elif item['type'] == 'gen':\n                    statistics['gen'] += 1\n                elif item['type'] == 'kno':\n                    statistics['kno'] += 1\n                elif item['type'] == 'num':\n                    statistics['num'] += 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            if 'type' in item:\n                if item['type'] == 'doc':\n                    statistics['doc'] += 1\n                elif item['type'] == 'gen':\n                    statistics['gen'] += 1\n                elif item['type'] == 'kno':\n                    statistics['kno'] += 1\n                elif item['type'] == 'num':\n                    statistics['num'] += 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        types_count = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            if 'type' in item:\n                types_count[item['type']] += 1\n        return types_count"}
{"namespace": "common.bleu4_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    bleu = evaluate.load('uhgeval/.cache/huggingface/bleu')\n    results = bleu.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['bleu']\n    if with_penalty:\n        brevity_penalty = min(1, len(continuation) / len(reference))\n        score *= brevity_penalty\n    return score"}
{"namespace": "common.bleu4_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    bleu = evaluate.load('uhgeval/.cache/huggingface/bleu')\n    results = bleu.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['bleu']\n    if with_penalty:\n        brevity_penalty = min(1, len(continuation) / len(reference))\n        score *= brevity_penalty\n    return score"}
{"namespace": "common.bleu4_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    bleu = evaluate.load('uhgeval/.cache/huggingface/bleu')\n    results = bleu.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['bleu']\n    if with_penalty:\n        brevity_penalty = min(1, len(continuation) / len(reference))\n        score *= brevity_penalty\n    return score"}
{"namespace": "common.bleu4_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    bleu = evaluate.load('uhgeval/.cache/huggingface/bleu')\n    results = bleu.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['bleu']\n    if with_penalty:\n        brevity_penalty = min(1, len(continuation) / len(reference))\n        score *= brevity_penalty\n    return score"}
{"namespace": "common.bleu4_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    bleu = evaluate.load('uhgeval/.cache/huggingface/bleu')\n    results = bleu.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['bleu']\n    if with_penalty:\n        brevity_penalty = min(1, len(continuation) / len(reference))\n        score *= brevity_penalty\n    return score"}
{"namespace": "common.bleu4_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    bleu = evaluate.load('uhgeval/.cache/huggingface/bleu')\n    results = bleu.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['bleu']\n    if with_penalty:\n        brevity_penalty = min(1, len(continuation) / len(reference))\n        score *= brevity_penalty\n    return score"}
{"namespace": "common.bleu4_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    bleu = evaluate.load('uhgeval/.cache/huggingface/bleu')\n    results = bleu.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['bleu']\n    if with_penalty:\n        brevity_penalty = min(1, len(continuation) / len(reference))\n        score *= brevity_penalty\n    return score"}
{"namespace": "common.bleu4_score", "completion": "\n    f = lambda text: list(jieba.cut(text))\n    bleu = evaluate.load('uhgeval/.cache/huggingface/bleu')\n    results = bleu.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['bleu']\n    if with_penalty:\n        brevity_penalty = min(1, len(continuation) / len(reference))\n        score *= brevity_penalty\n    return score"}
{"namespace": "common.bleu4_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    bleu = evaluate.load('uhgeval/.cache/huggingface/bleu')\n    results = bleu.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['bleu']\n    if with_penalty:\n        brevity_penalty = min(1, len(continuation) / len(reference))\n        score *= brevity_penalty\n    return score"}
{"namespace": "common.bleu4_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    bleu = evaluate.load('uhgeval/.cache/huggingface/bleu')\n    results = bleu.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['bleu']\n    if with_penalty:\n        brevity_penalty = min(1, len(continuation) / len(reference))\n        score *= brevity_penalty\n    return score"}
{"namespace": "common.bleu4_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    bleu = evaluate.load('uhgeval/.cache/huggingface/bleu')\n    results = bleu.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['bleu']\n    if with_penalty:\n        brevity_penalty = min(1, len(continuation) / len(reference))\n        score *= brevity_penalty\n    return score"}
{"namespace": "common.bleu4_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    bleu = evaluate.load('uhgeval/.cache/huggingface/bleu')\n    results = bleu.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['bleu']\n    if with_penalty:\n        brevity_penalty = min(1, len(continuation) / len(reference))\n        score *= brevity_penalty\n    return score"}
{"namespace": "common.bleu4_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    bleu = evaluate.load('uhgeval/.cache/huggingface/bleu')\n    results = bleu.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['bleu']\n    if with_penalty:\n        brevity_penalty = min(1, len(continuation) / len(reference))\n        score *= brevity_penalty\n    return score"}
{"namespace": "common.bleu4_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    bleu = evaluate.load('uhgeval/.cache/huggingface/bleu')\n    results = bleu.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['bleu']\n    if with_penalty:\n        brevity_penalty = min(1, len(continuation) / len(reference))\n        score *= brevity_penalty\n    return score"}
{"namespace": "common.bleu4_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    bleu = evaluate.load('uhgeval/.cache/huggingface/bleu')\n    results = bleu.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['bleu']\n    if with_penalty:\n        brevity_penalty = min(1, len(continuation) / len(reference))\n        score *= brevity_penalty\n    return score"}
{"namespace": "common.bleu4_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    bleu = evaluate.load('uhgeval/.cache/huggingface/bleu')\n    results = bleu.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['bleu']\n    if with_penalty:\n        brevity_penalty = min(1, len(continuation) / len(reference))\n        score *= brevity_penalty\n    return score"}
{"namespace": "common.bleu4_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    bleu = evaluate.load('uhgeval/.cache/huggingface/bleu')\n    results = bleu.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['bleu']\n    if with_penalty:\n        brevity_penalty = min(1, len(continuation) / len(reference))\n        score *= brevity_penalty\n    return score"}
{"namespace": "common.bleu4_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    bleu = evaluate.load('uhgeval/.cache/huggingface/bleu')\n    results = bleu.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['bleu']\n    if with_penalty:\n        brevity_penalty = min(1, len(continuation) / len(reference))\n        score *= brevity_penalty\n    return score"}
{"namespace": "common.bleu4_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    bleu = evaluate.load('uhgeval/.cache/huggingface/bleu')\n    results = bleu.compute(predictions=[continuation], references=[[reference]], tokenizer=f, use_bp=with_penalty)\n    score = results['bleu']\n    return score"}
{"namespace": "common.bleu4_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    bleu = evaluate.load('uhgeval/.cache/huggingface/bleu')\n    results = bleu.compute(predictions=[continuation], references=[[reference]], tokenizer=f, use_bp=with_penalty)\n    score = results['bleu']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    return results['rougeL']"}
{"namespace": "common.rougeL_score", "completion": "\n    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "\n    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "\n    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "\n    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rouge-l']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "\n    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rouge-l']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rouge-l']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    f = lambda text: list(jieba.cut(text))\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "\n    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)"}
