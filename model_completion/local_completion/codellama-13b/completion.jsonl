{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(cmd)\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(cmd)\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(cmd)\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(cmd)\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(cmd)\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(cmd)\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing command: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running bash command: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(cmd)\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(cmd)\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(cmd)\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(cmd)\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(cmd)\n    return os.system(cmd)\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (1 - 2 * jnp.sqrt(x_mag_sq)) / x_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |z| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = jnp.sqrt(1 - (2 / 3) * z_mag_sq)\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |z| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = 1 / (2 * jnp.sqrt(z_mag_sq) - 1)\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = 1 / (2 * jnp.sqrt(z_mag_sq) - 1)\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |z| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = 1 / (2 * jnp.sqrt(z_mag_sq) - 1)\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = 1 / (2 * jnp.sqrt(x_mag_sq) - 1)\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |z| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (1 - jnp.sqrt(1 - z_mag_sq)) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = jnp.sqrt(x_mag_sq) / (2 * jnp.sqrt(x_mag_sq) - 1)\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (1 - jnp.sqrt(x_mag_sq)) / (2 * jnp.sqrt(x_mag_sq) - 1)\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (1 - jnp.sqrt(x_mag_sq)) / (1 + jnp.sqrt(x_mag_sq))\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |z| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (1 - jnp.sqrt(z_mag_sq)) / (1 + jnp.sqrt(z_mag_sq))\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (1 - jnp.sqrt(x_mag_sq)) / (1 + jnp.sqrt(x_mag_sq))\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (jnp.sqrt(x_mag_sq) - 1) / (2 * jnp.sqrt(x_mag_sq))\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (1 - jnp.sqrt(x_mag_sq)) / (2 * jnp.sqrt(x_mag_sq) - 1)\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = 1 / (2 * jnp.sqrt(x_mag_sq) - 1)\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (1 - jnp.sqrt(x_mag_sq)) / (2 * jnp.sqrt(x_mag_sq) - 1)\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (1 - jnp.sqrt(x_mag_sq)) / (2 * jnp.sqrt(x_mag_sq) - 1)\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = jnp.sqrt(1 - 1 / z_mag_sq) / jnp.sqrt(z_mag_sq)\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |z| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = jnp.sqrt(1 - 1 / (2 * z_mag_sq)) / jnp.sqrt(z_mag_sq)\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (1 + jnp.sqrt(1 + 4 * x_mag_sq)) / (2 * x_mag_sq)\n  x = scale * z\n  return x\n\n"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            conn = sqlite3.connect(filename)\n            cur = conn.cursor()\n            cur.execute(f\"CREATE TABLE IF NOT EXISTS {func_name} (key TEXT, value TEXT)\")\n            key = json.dumps((args, kwargs))\n            cur.execute(f\"SELECT value FROM {func_name} WHERE key = ?\", (key,))\n            result = cur.fetchone()\n            if result:\n                return json.loads(result[0])\n            result = func(*args, **kwargs)\n            cur.execute(f\"INSERT INTO {func_name} (key, value) VALUES (?, ?)\", (key, json.dumps(result)))\n            conn.commit()\n            conn.close()\n            return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n            c.execute(f\"CREATE TABLE IF NOT EXISTS {func_name} (key TEXT PRIMARY KEY, value TEXT)\")\n            key = json.dumps((args, kwargs))\n            key_hash = hashlib.md5(key.encode()).hexdigest()\n            c.execute(f\"SELECT value FROM {func_name} WHERE key = ?\", (key_hash,))\n            result = c.fetchone()\n            if result:\n                return json.loads(result[0])\n            result = func(*args, **kwargs)\n            c.execute(f\"INSERT INTO {func_name} VALUES (?, ?)\", (key_hash, json.dumps(result)))\n            conn.commit()\n            conn.close()\n            return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args):\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n            c.execute(f\"CREATE TABLE IF NOT EXISTS {func_name} (key text, value text)\")\n            key = json.dumps(args)\n            key_hash = hashlib.sha256(key.encode(\"utf-8\")).hexdigest()\n            c.execute(f\"SELECT value FROM {func_name} WHERE key=?\", (key_hash,))\n            result = c.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                result = func(*args)\n                c.execute(f\"INSERT INTO {func_name} VALUES (?, ?)\", (key_hash, json.dumps(result)))\n                conn.commit()\n                return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            conn = sqlite3.connect(filename)\n            cur = conn.cursor()\n            cur.execute(f\"CREATE TABLE IF NOT EXISTS {func_name} (key TEXT, value TEXT)\")\n            key = hashlib.md5(json.dumps({\"args\": args, \"kwargs\": kwargs}).encode(\"utf-8\")).hexdigest()\n            cur.execute(f\"SELECT value FROM {func_name} WHERE key=?\", (key,))\n            result = cur.fetchone()\n            if result:\n                return json.loads(result[0])\n            result = func(*args, **kwargs)\n            cur.execute(f\"INSERT INTO {func_name} VALUES (?, ?)\", (key, json.dumps(result)))\n            conn.commit()\n            conn.close()\n            return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n            c.execute(f\"CREATE TABLE IF NOT EXISTS {func_name} (key TEXT PRIMARY KEY, value TEXT)\")\n            key = hashlib.md5(json.dumps(args).encode(\"utf-8\") + json.dumps(kwargs).encode(\"utf-8\")).hexdigest()\n            c.execute(f\"SELECT value FROM {func_name} WHERE key = ?\", (key,))\n            result = c.fetchone()\n            if result:\n                result = eval(result[0])\n            else:\n                result = func(*args, **kwargs)\n                c.execute(f\"INSERT INTO {func_name} VALUES (?, ?)\", (key, str(result)))\n                conn.commit()\n            conn.close()\n            return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            conn = sqlite3.connect(filename)\n            cur = conn.cursor()\n            cur.execute(f\"CREATE TABLE IF NOT EXISTS {func_name} (key TEXT PRIMARY KEY, value TEXT)\")\n            key = json.dumps((args, kwargs))\n            cur.execute(f\"SELECT value FROM {func_name} WHERE key = ?\", (key,))\n            result = cur.fetchone()\n            if result:\n                result = json.loads(result[0])\n            else:\n                result = func(*args, **kwargs)\n                result = json.dumps(result)\n                cur.execute(f\"INSERT INTO {func_name} (key, value) VALUES (?, ?)\", (key, result))\n                conn.commit()\n            conn.close()\n            return result\n\n        return wrapper\n\n    return decorator\n\n"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            conn = sqlite3.connect(filename)\n            cur = conn.cursor()\n            cur.execute(\n                \"CREATE TABLE IF NOT EXISTS cache(func_name TEXT, args_hash TEXT, kwargs_hash TEXT, output_hash TEXT)\"\n            )\n            args_hash = hashlib.md5(json.dumps(args).encode(\"utf-8\")).hexdigest()\n            kwargs_hash = hashlib.md5(json.dumps(kwargs).encode(\"utf-8\")).hexdigest()\n            cur.execute(\n                \"SELECT output_hash FROM cache WHERE func_name=? AND args_hash=? AND kwargs_hash=?\",\n                (func_name, args_hash, kwargs_hash),\n            )\n            result = cur.fetchone()\n            if result is None:\n                output = func(*args, **kwargs)\n                output_hash = hashlib.md5(json.dumps(output).encode(\"utf-8\")).hexdigest()\n                cur.execute(\n                    \"INSERT INTO cache VALUES (?, ?, ?, ?)\",\n                    (func_name, args_hash, kwargs_hash, output_hash),\n                )\n                conn.commit()\n                conn.close()\n                return output\n            else:\n                conn.close()\n                return result[0]\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            conn = sqlite3.connect(filename)\n            cur = conn.cursor()\n            cur.execute(f\"CREATE TABLE IF NOT EXISTS {func_name} (key TEXT PRIMARY KEY, value TEXT)\")\n            key = json.dumps((args, kwargs))\n            cur.execute(f\"SELECT value FROM {func_name} WHERE key=?\", (key,))\n            result = cur.fetchone()\n            if result is None:\n                result = func(*args, **kwargs)\n                cur.execute(f\"INSERT INTO {func_name} (key, value) VALUES (?, ?)\", (key, json.dumps(result)))\n                conn.commit()\n            else:\n                result = json.loads(result[0])\n            conn.close()\n            return result\n        return wrapper\n    return decorator\n\n"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            conn = sqlite3.connect(filename)\n            cur = conn.cursor()\n            cur.execute(\"CREATE TABLE IF NOT EXISTS cache (func_name TEXT, args_hash TEXT, kwargs_hash TEXT, result_hash TEXT)\")\n            args_hash = hashlib.md5(json.dumps(args).encode()).hexdigest()\n            kwargs_hash = hashlib.md5(json.dumps(kwargs).encode()).hexdigest()\n            cur.execute(\"SELECT result_hash FROM cache WHERE func_name=? AND args_hash=? AND kwargs_hash=?\", (func_name, args_hash, kwargs_hash))\n            result_hash = cur.fetchone()\n            if result_hash is not None:\n                result_hash = result_hash[0]\n                cur.execute(\"SELECT result FROM cache WHERE func_name=? AND args_hash=? AND kwargs_hash=? AND result_hash=?\", (func_name, args_hash, kwargs_hash, result_hash))\n                result = cur.fetchone()[0]\n                conn.close()\n                return result\n            result = func(*args, **kwargs)\n            result_hash = hashlib.md5(json.dumps(result).encode()).hexdigest()\n            cur.execute(\"INSERT INTO cache (func_name, args_hash, kwargs_hash, result_hash) VALUES (?, ?, ?, ?)\", (func_name, args_hash, kwargs_hash, result_hash))\n            cur.execute(\"INSERT INTO cache (func_name, args_hash, kwargs_hash, result_hash, result) VALUES (?, ?, ?, ?, ?)\", (func_name, args_hash, kwargs_hash, result_hash, json.dumps(result)))\n            conn.commit()\n            conn.close()\n            return result\n        return wrapper\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            conn = sqlite3.connect(filename)\n            cursor = conn.cursor()\n            cursor.execute(\"CREATE TABLE IF NOT EXISTS cache (key text, value text)\")\n            key = hashlib.md5(json.dumps(args).encode()).hexdigest()\n            cursor.execute(\"SELECT value FROM cache WHERE key = ?\", (key,))\n            result = cursor.fetchone()\n            if result:\n                return json.loads(result[0])\n            result = func(*args, **kwargs)\n            cursor.execute(\"INSERT INTO cache VALUES (?, ?)\", (key, json.dumps(result)))\n            conn.commit()\n            return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n\n            conn = sqlite3.connect(filename)\n            cursor = conn.cursor()\n            cursor.execute(\"CREATE TABLE IF NOT EXISTS cache (func_name TEXT, args_hash TEXT, kwargs_hash TEXT, output TEXT)\")\n\n            args_hash = hashlib.md5(str(args).encode(\"utf-8\")).hexdigest()\n            kwargs_hash = hashlib.md5(str(kwargs).encode(\"utf-8\")).hexdigest()\n\n            cursor.execute(\"SELECT output FROM cache WHERE func_name=? AND args_hash=? AND kwargs_hash=?\", (func_name, args_hash, kwargs_hash))\n            output = cursor.fetchone()\n\n            if output is None:\n                output = func(*args, **kwargs)\n                cursor.execute(\"INSERT INTO cache VALUES (?, ?, ?, ?)\", (func_name, args_hash, kwargs_hash, json.dumps(output)))\n                conn.commit()\n                conn.close()\n\n            else:\n                output = json.loads(output[0])\n                conn.close()\n\n            return output\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n\n            # Connect to the SQLite database\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n\n            # Create the table if it doesn't exist\n            c.execute(f\"CREATE TABLE IF NOT EXISTS {func_name}(key TEXT PRIMARY KEY, value TEXT)\")\n\n            # Hash the args and kwargs into a key\n            key = hashlib.md5(json.dumps((args, kwargs)).encode()).hexdigest()\n\n            # Check if the key exists in the database\n            c.execute(f\"SELECT value FROM {func_name} WHERE key=?\", (key,))\n            result = c.fetchone()\n\n            # If the key exists, return the value\n            if result:\n                return json.loads(result[0])\n\n            # Otherwise, compute the result, store it in the database, and return it\n            else:\n                result = func(*args, **kwargs)\n                c.execute(f\"INSERT INTO {func_name}(key, value) VALUES (?, ?)\", (key, json.dumps(result)))\n                conn.commit()\n                return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            conn = sqlite3.connect(filename)\n            cur = conn.cursor()\n            cur.execute(f\"CREATE TABLE IF NOT EXISTS {func_name} (key TEXT, value TEXT)\")\n            key = hashlib.md5(json.dumps({\"args\": args, \"kwargs\": kwargs}).encode()).hexdigest()\n            cur.execute(f\"SELECT value FROM {func_name} WHERE key=?\", (key,))\n            result = cur.fetchone()\n            if result:\n                cur.close()\n                conn.close()\n                return json.loads(result[0])\n            else:\n                result = func(*args, **kwargs)\n                cur.execute(f\"INSERT INTO {func_name} VALUES (?, ?)\", (key, json.dumps(result)))\n                conn.commit()\n                cur.close()\n                conn.close()\n                return result\n\n        return wrapper\n\n    return decorator\n\n"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n\n            # Create the SQLite database if it does not already exist.\n            with sqlite3.connect(filename) as conn:\n                cursor = conn.cursor()\n                cursor.execute(\n                    f\"\"\"CREATE TABLE IF NOT EXISTS {func_name}(\n                        id INTEGER PRIMARY KEY AUTOINCREMENT,\n                        args_hash TEXT,\n                        kwargs_hash TEXT,\n                        result TEXT\n                    )\"\"\"\n                )\n\n            # Compute the hash of the arguments and the keyword arguments.\n            args_hash = hashlib.md5(json.dumps(args).encode(\"utf-8\")).hexdigest()\n            kwargs_hash = hashlib.md5(json.dumps(kwargs).encode(\"utf-8\")).hexdigest()\n\n            # Check if the function's output is already stored in the database.\n            with sqlite3.connect(filename) as conn:\n                cursor = conn.cursor()\n                cursor.execute(\n                    f\"\"\"SELECT result FROM {func_name} WHERE args_hash=? AND kwargs_hash=?\"\"\",\n                    (args_hash, kwargs_hash),\n                )\n                result = cursor.fetchone()\n\n            # If the output is already stored in the database, retrieve it.\n            if result:\n                return json.loads(result[0])\n\n            # Otherwise, compute the output, store it in the database, and return it.\n            else:\n                result = func(*args, **kwargs)\n                with sqlite3.connect(filename) as conn:\n                    cursor = conn.cursor()\n                    cursor.execute(\n                        f\"\"\"INSERT INTO {func_name}(args_hash, kwargs_hash, result) VALUES(?, ?, ?)\"\"\",\n                        (args_hash, kwargs_hash, json.dumps(result)),\n                    )\n                return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Create the database if it doesn't already exist\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n            c.execute(f\"CREATE TABLE IF NOT EXISTS {func_name} (key TEXT, value TEXT)\")\n            conn.commit()\n\n            # Create a unique key for the function's input\n            key = hashlib.md5(json.dumps(args, sort_keys=True).encode()).hexdigest()\n            key += hashlib.md5(json.dumps(kwargs, sort_keys=True).encode()).hexdigest()\n\n            # Retrieve the function's output from the database if it already exists\n            c.execute(f\"SELECT value FROM {func_name} WHERE key = ?\", (key,))\n            result = c.fetchone()\n            if result:\n                result = json.loads(result[0])\n            else:\n                # Compute the function's output if it does not exist in the database\n                result = func(*args, **kwargs)\n                c.execute(f\"INSERT INTO {func_name} VALUES (?, ?)\", (key, json.dumps(result)))\n                conn.commit()\n            conn.close()\n            return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n\n        # Create the SQLite database file if it does not already exist.\n        conn = sqlite3.connect(filename)\n        cursor = conn.cursor()\n        cursor.execute(f\"CREATE TABLE IF NOT EXISTS {func_name} (key TEXT, value TEXT)\")\n        conn.commit()\n        conn.close()\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n\n            # Get the function's arguments as a hashable key.\n            key = hashlib.md5(json.dumps({'args': args, 'kwargs': kwargs}).encode('utf-8')).hexdigest()\n\n            # Check if the function's output is already stored in the SQLite database.\n            conn = sqlite3.connect(filename)\n            cursor = conn.cursor()\n            cursor.execute(f\"SELECT value FROM {func_name} WHERE key=?\", (key,))\n            result = cursor.fetchone()\n            conn.close()\n\n            # If the output is already stored, retrieve it from the database.\n            if result:\n                return json.loads(result[0])\n\n            # Otherwise, compute the output, store it in the database, and return it.\n            else:\n                result = func(*args, **kwargs)\n                conn = sqlite3.connect(filename)\n                cursor = conn.cursor()\n                cursor.execute(f\"INSERT INTO {func_name} VALUES (?, ?)\", (key, json.dumps(result)))\n                conn.commit()\n                conn.close()\n                return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Create the SQLite database if it does not exist.\n            with sqlite3.connect(filename) as conn:\n                # Create the table if it does not exist.\n                conn.execute(\n                    f\"CREATE TABLE IF NOT EXISTS {func_name} (hash TEXT, result TEXT)\"\n                )\n                # Create a hash of the function's arguments.\n                hash_args = hashlib.sha1(\n                    str(args).encode(\"utf-8\") + str(kwargs).encode(\"utf-8\")\n                ).hexdigest()\n                # Query the database for the function's result.\n                result = conn.execute(\n                    f\"SELECT result FROM {func_name} WHERE hash = ?\", (hash_args,)\n                ).fetchone()\n                # If the function's result is not in the database, compute it, store it in the database, and return it.\n                if not result:\n                    result = func(*args, **kwargs)\n                    conn.execute(\n                        f\"INSERT INTO {func_name} VALUES (?, ?)\",\n                        (hash_args, json.dumps(result)),\n                    )\n                    conn.commit()\n                    return result\n                # If the function's result is in the database, return it.\n                else:\n                    return json.loads(result[0])\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Create a connection to the SQLite database file.\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n\n            # Create the table if it does not exist.\n            c.execute(\n                f\"\"\"CREATE TABLE IF NOT EXISTS {func_name}\n                    (\n                        args JSON,\n                        kwargs JSON,\n                        result JSON\n                    )\n                \"\"\"\n            )\n\n            # Hash the args and kwargs to create a primary key.\n            key = hashlib.md5(\n                str(args + tuple(kwargs.items())).encode()\n            ).hexdigest()\n\n            # Retrieve the result from the database if it exists.\n            c.execute(f\"SELECT result FROM {func_name} WHERE args=? AND kwargs=?\", (key, key))\n            result = c.fetchone()\n\n            # Close the database connection.\n            conn.close()\n\n            # If the result exists in the database, return it.\n            if result:\n                return json.loads(result[0])\n\n            # Otherwise, compute the result, store it in the database, and return it.\n            else:\n                result = func(*args, **kwargs)\n                conn = sqlite3.connect(filename)\n                c = conn.cursor()\n                c.execute(\n                    f\"INSERT INTO {func_name} (args, kwargs, result) VALUES (?, ?, ?)\",\n                    (key, key, json.dumps(result)),\n                )\n                conn.commit()\n                conn.close()\n                return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n\n        # Connect to the database\n        conn = sqlite3.connect(filename)\n        c = conn.cursor()\n\n        # Create the cache table if it doesn't exist\n        c.execute(\n            \"\"\"CREATE TABLE IF NOT EXISTS cache (\n            func_name TEXT,\n            args_json TEXT,\n            kwargs_json TEXT,\n            output_json TEXT,\n            PRIMARY KEY (func_name, args_json, kwargs_json)\n            );\"\"\"\n        )\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n\n            # Convert the function arguments to JSON\n            args_json = json.dumps(args, sort_keys=True)\n            kwargs_json = json.dumps(kwargs, sort_keys=True)\n\n            # Hash the function name and arguments to get the cache key\n            key = hashlib.md5((func_name + args_json + kwargs_json).encode()).hexdigest()\n\n            # Try to retrieve the result from the cache\n            c.execute(\"SELECT output_json FROM cache WHERE func_name = ? AND args_json = ? AND kwargs_json = ?\", (func_name, args_json, kwargs_json))\n            result = c.fetchone()\n\n            if result:\n                # If the result exists in the cache, return it\n                return json.loads(result[0])\n\n            # Otherwise, compute the result, store it in the database, and return it\n            output = func(*args, **kwargs)\n            output_json = json.dumps(output, sort_keys=True)\n            c.execute(\"INSERT INTO cache (func_name, args_json, kwargs_json, output_json) VALUES (?, ?, ?, ?)\", (func_name, args_json, kwargs_json, output_json))\n            conn.commit()\n            return output\n\n        return wrapper\n\n    return decorator\n\n"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    # Create the database and the table if they don't exist.\n    conn = sqlite3.connect(filename)\n    c = conn.cursor()\n    c.execute(\"CREATE TABLE IF NOT EXISTS cache (key text, value text)\")\n    conn.commit()\n    conn.close()\n\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args):\n            # Create the key for this function call.\n            key = func_name + \"(\" + json.dumps(args) + \")\"\n            # Hash the key to avoid storing a huge key in the database.\n            key = hashlib.sha256(key.encode()).hexdigest()\n\n            # Connect to the database.\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n\n            # Check if the function output is already stored in the database.\n            c.execute(\"SELECT value FROM cache WHERE key = ?\", (key,))\n            result = c.fetchone()\n            if result is not None:\n                # The output is already stored in the database.\n                result = json.loads(result[0])\n            else:\n                # The output is not stored in the database.\n                result = func(*args)\n                result = json.dumps(result)\n                c.execute(\"INSERT INTO cache VALUES (?, ?)\", (key, result))\n                conn.commit()\n\n            # Close the connection to the database.\n            conn.close()\n\n            return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max\")\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max\")\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values.get(\"x_min\") >= values.get(\"x_max\"):\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max. Received x_min: {values.get('x_min')} and x_max: {values.get('x_max')}\")\n    if values.get(\"y_min\") >= values.get(\"y_max\"):\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max. Received y_min: {values.get('y_min')} and y_max: {values.get('y_max')}\")\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max. Received x_min: {values['x_min']} and x_max: {values['x_max']}\")\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max. Received y_min: {values['y_min']} and y_max: {values['y_max']}\")\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max. Received x_min: {values['x_min']} and x_max: {values['x_max']}\")\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max. Received y_min: {values['y_min']} and y_max: {values['y_max']}\")\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max. Received x_min={values['x_min']} and x_max={values['x_max']}\")\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max. Received y_min={values['y_min']} and y_max={values['y_max']}\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max. Received x_min={values['x_min']} and x_max={values['x_max']}\")\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max. Received y_min={values['y_min']} and y_max={values['y_max']}\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_max\"] <= values[\"x_min\"]:\n        raise ValueError(f\"{cls.__name__}: x_max must be greater than x_min. Received x_min={values['x_min']} and x_max={values['x_max']}\")\n\n    if values[\"y_max\"] <= values[\"y_min\"]:\n        raise ValueError(f\"{cls.__name__}: y_max must be greater than y_min. Received y_min={values['y_min']} and y_max={values['y_max']}\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max. Received {values['x_min']} and {values['x_max']} respectively.\")\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max. Received {values['y_min']} and {values['y_max']} respectively.\")\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max. Got x_min: {values['x_min']} and x_max: {values['x_max']}\")\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max. Got y_min: {values['y_min']} and y_max: {values['y_max']}\")\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max. Received x_min={values['x_min']} and x_max={values['x_max']}\")\n\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max. Received y_min={values['y_min']} and y_max={values['y_max']}\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values.get(\"x_min\") >= values.get(\"x_max\"):\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max. Received {values.get('x_min')} and {values.get('x_max')} for bbox.\")\n    if values.get(\"y_min\") >= values.get(\"y_max\"):\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max. Received {values.get('y_min')} and {values.get('y_max')} for bbox.\")\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max. Received x_min: {values['x_min']} and x_max: {values['x_max']}\")\n\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max. Received y_min: {values['y_min']} and y_max: {values['y_max']}\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max. Got x_min: {values['x_min']} and x_max: {values['x_max']}.\")\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max. Got y_min: {values['y_min']} and y_max: {values['y_max']}.\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max. Received {values['x_min']} and {values['x_max']} for x coordinates.\")\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max. Received {values['y_min']} and {values['y_max']} for y coordinates.\")\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values.get(\"x_min\", None) > values.get(\"x_max\", None):\n        raise ValueError(f\"{cls.__name__}: x_min must be less than or equal to x_max\")\n\n    if values.get(\"y_min\", None) > values.get(\"y_max\", None):\n        raise ValueError(f\"{cls.__name__}: y_min must be less than or equal to y_max\")\n\n    return values\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  sq_norm0 = np.sum(np.square(mat0), axis=0)\n  sq_norm1 = np.sum(np.square(mat1), axis=0)\n\n  sq_dist = np.transpose(\n      np.tile(sq_norm0, (mat1.shape[1], 1)) + np.tile(sq_norm1,\n                                                     (mat0.shape[1], 1)))\n  sq_dist -= 2 * np.dot(mat0.T, mat1)\n\n  return np.maximum(sq_dist, 0)\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  mat0_norm = np.sum(np.square(mat0), axis=0)\n  mat1_norm = np.sum(np.square(mat1), axis=0)\n  dist_mat = -2 * np.dot(mat0.T, mat1)\n  dist_mat += mat0_norm\n  dist_mat += mat1_norm\n  dist_mat[dist_mat < 0] = 0\n  return dist_mat\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  # Compute the norms of the vectors in each set\n  norms0 = np.sum(np.square(mat0), axis=0)\n  norms1 = np.sum(np.square(mat1), axis=0)\n\n  # Compute the dot products of the vectors in each set\n  dot_prod = mat0.T @ mat1\n\n  # Compute the squared distances\n  sq_dist = norms0[:, np.newaxis] + norms1 - 2 * dot_prod\n\n  # Set negative distances to zero\n  sq_dist[sq_dist < 0] = 0\n\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  # Compute norms of vectors in both matrices\n  norms0 = np.sum(mat0**2, axis=0)\n  norms1 = np.sum(mat1**2, axis=0)\n\n  # Compute dot products of vectors in both matrices\n  dot_products = np.dot(mat0.T, mat1)\n\n  # Compute squared distances\n  sq_dists = norms0[:, np.newaxis] + norms1 - 2 * dot_products\n\n  # Set negative distances to zero\n  sq_dists[sq_dists < 0] = 0\n\n  return sq_dists\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  # Compute the norms of each vector\n  norms0 = np.sum(np.square(mat0), axis=0)\n  norms1 = np.sum(np.square(mat1), axis=0)\n\n  # Compute the dot product of each vector pair\n  dot_product = np.dot(mat0.T, mat1)\n\n  # Compute the squared distances\n  sq_dist = norms0[:, np.newaxis] + norms1 - 2 * dot_product\n\n  # Ensure that negative distances are set to zero\n  sq_dist = np.maximum(sq_dist, 0)\n\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  # Compute the norms of all vectors in both matrices\n  norms0 = np.sum(np.square(mat0), axis=0)\n  norms1 = np.sum(np.square(mat1), axis=0)\n\n  # Compute the dot product of all vectors in both matrices\n  dot_products = np.dot(mat0.T, mat1)\n\n  # Compute the squared Euclidean distances\n  sq_dists = norms0[:, np.newaxis] + norms1[np.newaxis, :] - 2 * dot_products\n\n  # Ensure that negative distances are set to zero\n  sq_dists[sq_dists < 0] = 0\n\n  return sq_dists\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  norms0 = np.sum(mat0**2, axis=0)\n  norms1 = np.sum(mat1**2, axis=0)\n  dot_product = np.dot(mat0.T, mat1)\n  sq_dist = norms0[:, np.newaxis] + norms1[np.newaxis, :] - 2 * dot_product\n  sq_dist[sq_dist < 0] = 0\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  sq_norm0 = np.sum(mat0**2, axis=0)\n  sq_norm1 = np.sum(mat1**2, axis=0)\n  sq_dist = -2.0 * np.dot(mat0.T, mat1)\n  sq_dist += sq_norm0[:, np.newaxis]\n  sq_dist += sq_norm1[np.newaxis, :]\n  sq_dist[sq_dist < 0.0] = 0.0\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  # Compute the norms of each vector in each matrix\n  norms_0 = np.sum(mat0 ** 2, axis=0)\n  norms_1 = np.sum(mat1 ** 2, axis=0)\n\n  # Compute the dot products of each vector pair\n  dot_products = np.dot(mat0.T, mat1)\n\n  # Compute the squared distance matrix\n  sq_dist_mat = norms_0[:, np.newaxis] + norms_1[np.newaxis, :] - 2 * dot_products\n\n  # Ensure that the distance is positive\n  sq_dist_mat = np.maximum(sq_dist_mat, 0)\n\n  return sq_dist_mat\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  # Compute the norms of each column of each matrix\n  norms0 = np.sum(mat0**2, axis=0)\n  norms1 = np.sum(mat1**2, axis=0)\n\n  # Compute the dot product of each column of mat0 with each column of mat1\n  dot_prod = np.dot(mat0.T, mat1)\n\n  # Compute the squared distance matrix\n  sq_dist_mat = norms0[:, np.newaxis] + norms1 - 2*dot_prod\n\n  # Set negative distances to zero\n  sq_dist_mat[sq_dist_mat < 0] = 0\n\n  return sq_dist_mat\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  # Compute the norms of each vector in each matrix\n  norm0 = np.sum(np.square(mat0), axis=0)\n  norm1 = np.sum(np.square(mat1), axis=0)\n\n  # Compute the dot product of each vector pair\n  dot_prod = np.dot(mat0.T, mat1)\n\n  # Compute the squared distance matrix\n  sq_dist = norm0[:, np.newaxis] + norm1 - 2 * dot_prod\n\n  # Ensure that all distances are non-negative\n  sq_dist = np.maximum(sq_dist, 0)\n\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  # Compute norms of each column of each matrix\n  norm0 = np.sum(mat0 ** 2, axis=0)\n  norm1 = np.sum(mat1 ** 2, axis=0)\n\n  # Compute the dot product of each column of each matrix\n  dot_prod = np.dot(mat0.T, mat1)\n\n  # Compute the squared distance between each column of each matrix\n  sq_dist = norm0[:, np.newaxis] + norm1 - 2 * dot_prod\n\n  # Ensure that all negative distances are zero\n  sq_dist[sq_dist < 0] = 0\n\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  # Compute the norms of each column of mat0 and mat1.\n  norms0 = np.sum(mat0 ** 2, axis=0)\n  norms1 = np.sum(mat1 ** 2, axis=0)\n\n  # Compute the dot products of each column of mat0 and mat1.\n  dot_prod = mat0.T.dot(mat1)\n\n  # Compute the squared distances.\n  sq_dist = norms0[:, None] + norms1[None, :] - 2 * dot_prod\n\n  # Ensure that distances are non-negative.\n  sq_dist = np.maximum(sq_dist, 0)\n\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  # Compute the norms of each column of each matrix\n  norm0 = np.sum(np.square(mat0), axis=0)\n  norm1 = np.sum(np.square(mat1), axis=0)\n\n  # Compute the dot product between the two matrices\n  dot_prod = np.dot(mat0.T, mat1)\n\n  # Compute the squared distances\n  sq_dist = norm0[:, np.newaxis] + norm1 - 2 * dot_prod\n\n  # Set negative distances to zero\n  sq_dist = np.maximum(sq_dist, 0)\n\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  # Compute norms of vectors in each set\n  norms0 = np.sum(mat0**2, axis=0)\n  norms1 = np.sum(mat1**2, axis=0)\n\n  # Compute dot products of vectors in each set\n  dot_product = np.dot(mat0.T, mat1)\n\n  # Compute squared distances\n  sq_dist = norms0[:, np.newaxis] + norms1 - 2 * dot_product\n\n  # Set negative distances to zero\n  sq_dist[sq_dist < 0] = 0\n\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  # Compute the squared norms of each column of mat0 and mat1\n  sq_norm0 = np.sum(np.square(mat0), axis=0)\n  sq_norm1 = np.sum(np.square(mat1), axis=0)\n\n  # Compute the dot product of each column of mat0 and mat1\n  dot_prod = mat0.T @ mat1\n\n  # Compute the squared distances\n  sq_dist = sq_norm0[:, np.newaxis] + sq_norm1 - 2 * dot_prod\n\n  # Set negative distances to zero\n  sq_dist[sq_dist < 0] = 0\n\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  # Compute the squared norms of all vectors\n  sq_norm_0 = np.sum(np.square(mat0), axis=0)\n  sq_norm_1 = np.sum(np.square(mat1), axis=0)\n\n  # Compute the dot products of all pairs of vectors\n  dot_prod = np.dot(mat0.T, mat1)\n\n  # Compute the squared distances\n  sq_dist = np.outer(sq_norm_0, np.ones(mat1.shape[1]))\n  sq_dist += np.outer(np.ones(mat0.shape[1]), sq_norm_1)\n  sq_dist -= 2 * dot_prod\n\n  # Ensure that distances are non-negative\n  sq_dist = np.maximum(sq_dist, 0)\n\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  norm0 = np.sum(mat0 ** 2, axis=0)\n  norm1 = np.sum(mat1 ** 2, axis=0)\n  dot_product = np.dot(mat0.T, mat1)\n  sq_dist = norm0[:, np.newaxis] + norm1 - 2 * dot_product\n  sq_dist = np.maximum(sq_dist, 0)\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  norm0 = np.sum(mat0**2, axis=0)\n  norm1 = np.sum(mat1**2, axis=0)\n  dot_prod = np.dot(mat0.T, mat1)\n\n  sq_dist = norm0[:, np.newaxis] + norm1 - 2*dot_prod\n  sq_dist = np.maximum(sq_dist, 0)\n\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  norm0 = np.sum(mat0**2, axis=0)\n  norm1 = np.sum(mat1**2, axis=0)\n  dot = mat0.T @ mat1\n\n  sq_dist = norm0[:, np.newaxis] + norm1 - 2*dot\n\n  return sq_dist\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    return path is None or path == \"\" or path.startswith(\"s3://\") or path.startswith(\"gs://\") or path.startswith(\"hdfs://\")\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    return path is None or len(path) == 0 or path.startswith((\"gs://\", \"hdfs://\", \"s3://\"))\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    return path is None or path == \"\" or path.startswith(\"gs://\") or path.startswith(\"s3://\") or path.startswith(\"hdfs://\")\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\":\n        return True\n    if path.startswith(\"gs://\") or path.startswith(\"s3://\") or path.startswith(\"hdfs://\"):\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None:\n        return True\n    if path == \"\":\n        return True\n    if path.startswith(\"file://\"):\n        return True\n    if path.startswith(\"hdfs://\"):\n        return True\n    if path.startswith(\"s3://\"):\n        return True\n    if path.startswith(\"gs://\"):\n        return True\n    if path.startswith(\"az://\"):\n        return True\n    if path.startswith(\"https://\"):\n        return True\n    if path.startswith(\"http://\"):\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\":\n        return True\n\n    if path.startswith(\"gs://\") or path.startswith(\"s3://\") or path.startswith(\"hdfs://\"):\n        return True\n\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if not path:\n        return True\n\n    if path == \"\":\n        return True\n\n    if path.startswith(\"file://\"):\n        return True\n\n    if path.startswith(\"http://\"):\n        return True\n\n    if path.startswith(\"https://\"):\n        return True\n\n    if path.startswith(\"s3://\"):\n        return True\n\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\":\n        return True\n    if path.startswith(\"gs://\") or path.startswith(\"s3://\"):\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if not path:\n        return True\n    if path.startswith(\"gs://\") or path.startswith(\"s3://\") or path.startswith(\"hdfs://\"):\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or len(path) == 0:\n        return True\n    prefixes = [\"gs://\", \"s3://\", \"hdfs://\", \"file://\"]\n    for prefix in prefixes:\n        if path.startswith(prefix):\n            return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or len(path) == 0:\n        return True\n    for prefix in [\"gs://\", \"hdfs://\", \"s3://\", \"https://\", \"http://\"]:\n        if path.startswith(prefix):\n            return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    return path is None or path == \"\" or path.startswith(\"gs://\") or path.startswith(\"s3://\") or path.startswith(\"hdfs://\")\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or len(path) == 0:\n        return True\n\n    if path.startswith(\"gs://\") or path.startswith(\"s3://\") or path.startswith(\"hdfs://\"):\n        return True\n\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    return path is None or path == \"\" or path.startswith((\"http://\", \"https://\", \"hdfs://\"))\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None:\n        return True\n    if len(path) == 0:\n        return True\n    if path.startswith(\"file://\"):\n        return True\n    if path.startswith(\"gs://\"):\n        return True\n    if path.startswith(\"s3://\"):\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or len(path) == 0:\n        return True\n\n    if path.startswith(\"gs://\") or path.startswith(\"s3://\") or path.startswith(\"hdfs://\"):\n        return True\n\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    return path is None or path == \"\" or path.startswith(\"gs://\") or path.startswith(\"s3://\")\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if not path:\n        return True\n    if path.startswith(\"gs://\"):\n        return True\n    if path.startswith(\"s3://\"):\n        return True\n    if path.startswith(\"hdfs://\"):\n        return True\n    if path.startswith(\"http://\"):\n        return True\n    if path.startswith(\"https://\"):\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    return path is None or path == \"\" or path.startswith(\"gs://\") or path.startswith(\"s3://\")\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    return path is None or path == \"\" or path.startswith(\"gs://\") or path.startswith(\"s3://\")\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\"'assets_names' must be provided when 'items' is a dictionary\")\n        if len(assets_names) != n_assets:\n            raise ValueError(\n                f\"'assets_names' must be of length '{n_assets}' when 'items' is a dictionary\"\n            )\n        if dim == 1:\n            array = np.full(n_assets, fill_value, dtype=float)\n        else:\n            array = np.full((n_assets, n_assets), fill_value, dtype=float)\n        for asset, value in items.items():\n            if asset in assets_names:\n                if dim == 1:\n                    array[assets_names.get_loc(asset)] = value\n                else:\n                    array[np.diag_indices(n_assets)] = value\n            else:\n                raise ValueError(f\"'{asset}' is not an asset name\")\n    else:\n        array = np.asarray(items)\n        if dim == 1:\n            if array.ndim != 1:\n                raise ValueError(\n                    f\"'{name}' must be a 1-D array with shape (n_assets,) when 'dim' is 1\"\n                )\n            if array.shape[0] != n_assets:\n                raise ValueError(\n                    f\"'{name}' must be a 1-D array with shape (n_assets,) when 'dim' is 1\"\n                )\n        else:\n            if array.ndim != 2:\n                raise ValueError(\n                    f\"'{name}' must be a 2-D array with shape (n_assets, n_assets) when 'dim' is 2\"\n                )\n            if array.shape != (n_assets, n_assets):\n                raise ValueError(\n                    f\"'{name}' must be a 2-D array with shape (n_assets, n_assets) when 'dim' is 2\"\n                )\n    return array\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                f\"When '{name}' is a dictionary, the parameter 'assets_names' must be provided.\"\n            )\n        if dim == 1:\n            array = np.full(n_assets, fill_value)\n        else:\n            array = np.full((len(assets_names), n_assets), fill_value)\n        for i, asset_name in enumerate(assets_names):\n            if asset_name in items:\n                array[i] = items[asset_name]\n    else:\n        array = np.asarray(items)\n        if dim == 1:\n            if array.ndim == 1:\n                if len(array) != n_assets:\n                    raise ValueError(\n                        f\"The parameter '{name}' must have shape ({n_assets},) when 'dim' is 1.\"\n                    )\n            elif array.ndim == 2:\n                if array.shape[1] != n_assets:\n                    raise ValueError(\n                        f\"The parameter '{name}' must have shape (n_groups, {n_assets}) when 'dim' is 2.\"\n                    )\n            else:\n                raise ValueError(\n                    f\"The parameter '{name}' must be 1-dimensional or have shape (n_groups, {n_assets}) when 'dim' is 2.\"\n                )\n        elif dim == 2:\n            if array.ndim == 1:\n                if len(array) != n_assets:\n                    raise ValueError(\n                        f\"The parameter '{name}' must have shape ({n_assets},) when 'dim' is 1.\"\n                    )\n                array = array.reshape(1, -1)\n            elif array.ndim == 2:\n                if array.shape[1] != n_assets:\n                    raise ValueError(\n                        f\"The parameter '{name}' must have shape (n_groups, {n_assets}) when 'dim' is 2.\"\n                    )\n            else:\n                raise ValueError("}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                f\"When 'items' is a dictionary, 'assets_names' must be provided.\"\n            )\n        if dim == 1:\n            items = np.array(\n                [items.get(asset_name, fill_value) for asset_name in assets_names]\n            )\n        else:\n            items = np.array(\n                [\n                    [items.get(asset_name, fill_value) for asset_name in assets_names]\n                    for asset_name in assets_names\n                ]\n            )\n    if dim == 1:\n        if len(items.shape) != 1:\n            raise ValueError(\n                f\"'{name}' must be a 1D array with shape (n_assets,), got {items.shape}.\"\n            )\n        if items.shape[0] != n_assets:\n            raise ValueError(\n                f\"'{name}' must be a 1D array with shape (n_assets,), got {items.shape}.\"\n            )\n    elif dim == 2:\n        if len(items.shape) != 2:\n            raise ValueError(\n                f\"'{name}' must be a 2D array with shape (n_assets, n_assets), got {items.shape}.\"\n            )\n        if items.shape[0] != items.shape[1]:\n            raise ValueError(\n                f\"'{name}' must be a 2D array with shape (n_assets, n_assets), got {items.shape}.\"\n            )\n        if items.shape[0] != n_assets:\n            raise ValueError(\n                f\"'{name}' must be a 2D array with shape (n_assets, n_assets), got {items.shape}.\"\n            )\n    return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                f\"When '{name}' is a dictionary, the parameter 'assets_names' must be specified.\"\n            )\n        if dim == 1:\n            items_array = np.full(n_assets, fill_value, dtype=float)\n        else:\n            items_array = np.full((n_assets, n_assets), fill_value, dtype=float)\n        for asset_name, value in items.items():\n            if asset_name not in assets_names:\n                raise ValueError(\n                    f\"The asset '{asset_name}' in '{name}' is not present in 'assets_names'.\"\n                )\n            if dim == 1:\n                items_array[np.where(assets_names == asset_name)] = value\n            else:\n                items_array[np.where(assets_names == asset_name), np.where(assets_names == asset_name)] = value\n    else:\n        items_array = np.asarray(items, dtype=float)\n\n    if dim == 1:\n        if items_array.ndim != 1:\n            raise ValueError(\n                f\"The parameter '{name}' should be a 1-D array, got {items_array.ndim}-D.\"\n            )\n        if items_array.shape[0] != n_assets:\n            raise ValueError(\n                f\"The parameter '{name}' should have {n_assets} elements, got {items_array.shape[0]}.\"\n            )\n    else:\n        if items_array.ndim != 2:\n            raise ValueError(\n                f\"The parameter '{name}' should be a 2-D array, got {items_array.ndim}-D.\"\n            )\n        if items_array.shape[0] != n_assets or items_array.shape[1] != n_assets:\n            raise ValueError(\n                f\"The parameter '{name}' should have shape ({n_assets}, {n_assets}), got {items_array.shape}.\"\n            )\n\n    return items"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                \"If 'items' is a dictionary, 'assets_names' must be provided.\"\n            )\n        if len(assets_names) != n_assets:\n            raise ValueError(\n                f\"'assets_names' must be of length '{n_assets}', got '{len(assets_names)}'.\"\n            )\n        if dim == 1:\n            array = np.full(n_assets, fill_value)\n        else:\n            array = np.full((len(items), n_assets), fill_value)\n        for key, value in items.items():\n            if key in assets_names:\n                array[np.where(assets_names == key)] = value\n    else:\n        array = np.asarray(items)\n\n    if dim == 1:\n        if array.ndim != 1:\n            raise ValueError(\n                f\"'{name}' must be a 1-D array, got {array.ndim}-D.\"\n            )\n        if array.shape[0] != n_assets:\n            raise ValueError(\n                f\"'{name}' must be of shape '({n_assets},)', got '{array.shape}'.\"\n            )\n    elif dim == 2:\n        if array.ndim != 2:\n            raise ValueError(\n                f\"'{name}' must be a 2-D array, got {array.ndim}-D.\"\n            )\n        if array.shape[1] != n_assets:\n            raise ValueError(\n                f\"'{name}' must be of shape '(_, {n_assets})', got {array.shape}.\"\n            )\n    else:\n        raise ValueError(\n            f\"'dim' must be either 1 or 2, got {dim}.\"\n        )\n\n    return array\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                \"When passing a dictionary, the parameter 'assets_names' must be provided.\"\n            )\n        if not isinstance(assets_names, np.ndarray):\n            raise TypeError(\n                \"The parameter 'assets_names' must be a numpy array when passing a dictionary.\"\n            )\n        if len(assets_names.shape) != 1:\n            raise ValueError(\n                \"The parameter 'assets_names' must be a 1D array when passing a dictionary.\"\n            )\n        if len(assets_names) != n_assets:\n            raise ValueError(\n                \"The parameter 'assets_names' must be of the same length as the number of assets.\"\n            )\n        if dim == 1:\n            array = np.full(n_assets, fill_value)\n        elif dim == 2:\n            array = np.full((n_assets, n_assets), fill_value)\n        else:\n            raise ValueError(\"The parameter 'dim' must be either 1 or 2.\")\n        for asset_name, value in items.items():\n            if asset_name not in assets_names:\n                raise ValueError(f\"The asset '{asset_name}' is not present.\")\n            array[assets_names.get_loc(asset_name)] = value\n    else:\n        array = np.asarray(items)\n        if dim == 1:\n            if len(array.shape) != 1:\n                raise ValueError(\n                    f\"The parameter '{name}' must be a 1D array when 'dim' is 1.\"\n                )\n            if array.shape[0] != n_assets:\n                raise ValueError(\n                    f\"The parameter '{name}' must have length equal to the number of assets.\"\n                )\n        elif dim == 2:\n            if len(array.shape) != 2:\n                raise ValueError(\n                    f\"The parameter '{name}' must be a 2D array when 'dim' is 2.\"\n                )\n            if array.shape[0] != array"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    # Check if the input is a dictionary.\n    if isinstance(items, dict):\n        # Check if the dictionary is empty.\n        if len(items) == 0:\n            raise ValueError(f\"{name} dictionary is empty\")\n        # Check if the dictionary is not empty.\n        if assets_names is None:\n            raise ValueError(f\"{name} names must be provided when {name} is a dictionary\")\n        # Check if the dictionary is not empty.\n        if len(assets_names) == 0:\n            raise ValueError(f\"{name} names must be provided when {name} is a dictionary\")\n        # Check if the dictionary is not empty.\n        if dim == 2:\n            raise ValueError(f\"{name} must be 1-dimensional when {name} is a dictionary\")\n        # Check if the dictionary is not empty.\n        if not isinstance(assets_names, np.ndarray):\n            raise TypeError(\n                f\"{name} names must be provided as a numpy array when {name} is a dictionary\"\n            )\n        # Check if the dictionary is not empty.\n        if assets_names.ndim != 1:\n            raise ValueError(\n                f\"{name} names must be provided as a 1-dimensional numpy array when {name} is a dictionary\"\n            )\n        # Check if the dictionary is not empty.\n        if len(assets_names) != len(set(assets_names)):\n            raise ValueError(f\"{name} names must be unique\")\n        # Check if the dictionary is not empty.\n        if len(assets_names) != len(items):\n            raise ValueError(\n                f\"{name} names must be the same as {name} keys when {name} is a dictionary\"\n            )\n        # Check if the dictionary is not empty.\n        if not set(assets_names).issubset(set(items.keys())):\n            raise ValueError(\n                f\"{name} names must be the same as {name} keys when {name} is a dictionary\"\n            )\n        # Check if the dictionary is not empty.\n        if not set(items.keys"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                f\"'{name}' is a dictionary but 'assets_names' is not provided.\"\n            )\n        if dim == 1:\n            items_arr = np.full(n_assets, fill_value)\n        else:\n            items_arr = np.full((len(assets_names), n_assets), fill_value)\n        for asset, item in items.items():\n            if asset not in assets_names:\n                raise ValueError(\n                    f\"'{name}' dictionary contains a key '{asset}' that is not in 'assets_names'.\"\n                )\n            if dim == 1:\n                items_arr[assets_names.get_loc(asset)] = item\n            else:\n                items_arr[:, assets_names.get_loc(asset)] = item\n        return items_arr\n    if isinstance(items, np.ndarray):\n        if items.ndim == 1:\n            items_arr = items.reshape(1, -1)\n        else:\n            items_arr = items\n        if items_arr.shape[1] != n_assets:\n            raise ValueError(\n                f\"'{name}' has shape {items_arr.shape} but expected number of assets is {n_assets}.\"\n            )\n        return items_arr\n    if isinstance(items, Iterator):\n        items_arr = np.fromiter(items, dtype=float)\n        if items_arr.shape[0] != n_assets:\n            raise ValueError(\n                f\"'{name}' has shape {items_arr.shape} but expected number of assets is {n_assets}.\"\n            )\n        return items_arr\n    if isinstance(items, pd.Series):\n        if items.shape[0] != n_assets:\n            raise ValueError(\n                f\"'{name}' has shape {items.shape} but expected number of assets is {n_assets}.\"\n            )\n        return items.to_numpy()\n    if isinstance(items, pd.DataFrame):\n        if"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    # Check if the input is a dictionary\n    if isinstance(items, dict):\n        # Check if the dictionary is empty\n        if len(items) == 0:\n            raise ValueError(f\"{name} cannot be an empty dictionary\")\n\n        # Check if the dictionary is indexed by strings\n        if not all(isinstance(k, str) for k in items.keys()):\n            raise TypeError(f\"{name} keys must be strings\")\n\n        # Check if the dictionary is indexed by valid asset names\n        if assets_names is not None:\n            if not all(k in assets_names for k in items.keys()):\n                raise ValueError(f\"{name} keys must be valid asset names\")\n\n        # Convert the dictionary into an array\n        if dim == 1:\n            items_arr = np.array(\n                [items.get(k, fill_value) for k in assets_names]\n                if assets_names is not None\n                else [items.get(k, fill_value) for k in items.keys()],\n                dtype=float,\n            )\n        elif dim == 2:\n            items_arr = np.array(\n                [\n                    [items.get(k, fill_value) for k in assets_names]\n                    if assets_names is not None\n                    else [items.get(k, fill_value) for k in items.keys()]\n                ],\n                dtype=float,\n            )\n        else:\n            raise ValueError(f\"{name} cannot have dimension {dim}\")\n    else:\n        # Convert the array-like object into a numpy array\n        items_arr = np.array(items, dtype=float)\n\n        # Check if the array is empty\n        if items_arr.size == 0:\n            raise ValueError(f\"{name} cannot be an empty array\")\n\n        # Check if the array is 1-dimensional\n        if items_arr.ndim != 1:\n            raise ValueError(f\"{name} must be 1-dimensional\")\n\n        # Check if the array has the expected number of elements\n        if items_arr."}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                \"You must provide the 'assets_names' parameter when 'items' is a dictionary\"\n            )\n        if not isinstance(assets_names, np.ndarray):\n            raise TypeError(\n                \"The 'assets_names' parameter must be a numpy.ndarray when 'items' is a dictionary\"\n            )\n        if len(assets_names) != n_assets:\n            raise ValueError(\n                f\"The length of the 'assets_names' parameter ({len(assets_names)}) must be equal to the number of assets ({n_assets})\"\n            )\n        if dim == 1:\n            result = np.full(n_assets, fill_value)\n        else:\n            result = np.full((n_assets, n_assets), fill_value)\n        for asset, value in items.items():\n            if asset not in assets_names:\n                raise ValueError(\n                    f\"The asset '{asset}' in '{name}' is not present in 'assets_names'\"\n                )\n            index = np.where(assets_names == asset)[0][0]\n            result[index] = value\n    else:\n        result = np.asarray(items)\n        if dim == 1:\n            if len(result.shape) != 1:\n                raise ValueError(\n                    f\"The '{name}' parameter must be a 1D array, got {result.shape}\"\n                )\n            if result.shape[0] != n_assets:\n                raise ValueError(\n                    f\"The length of the '{name}' parameter ({result.shape[0]}) must be equal to the number of assets ({n_assets})\"\n                )\n        elif dim == 2:\n            if len(result.shape) != 2:\n                raise ValueError(\n                    f\"The '{name}' parameter must be a 2D array, got {result.shape}\"\n                )\n            if result.shape[0] != result.shape[1]:\n                raise ValueError(\n                    f\"The first dimension of the '{name}'"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                f\"When {name} is a dictionary, the parameter 'assets_names' must be specified.\"\n            )\n        if len(assets_names) != n_assets:\n            raise ValueError(\n                f\"The number of assets in the parameter 'assets_names' must match the expected number of assets ({n_assets}).\"\n            )\n        if dim == 1:\n            items = np.array(\n                [items.get(k, fill_value) for k in assets_names], dtype=np.float64\n            )\n        elif dim == 2:\n            items = np.array(\n                [\n                    [items.get(k, fill_value) for k in assets_names]\n                    for k in assets_names\n                ],\n                dtype=np.float64,\n            )\n    else:\n        items = np.asarray(items, dtype=np.float64)\n\n    if dim == 1:\n        if items.ndim != 1 or len(items) != n_assets:\n            raise ValueError(\n                f\"The parameter '{name}' must be a 1D array with length {n_assets}.\"\n            )\n    elif dim == 2:\n        if items.ndim != 2 or items.shape != (n_assets, n_assets):\n            raise ValueError(\n                f\"The parameter '{name}' must be a 2D array with shape {(n_assets, n_assets)}.\"\n            )\n    return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                f\"When '{name}' is a dictionary, 'assets_names' must be specified.\"\n            )\n        if dim == 1:\n            items_arr = np.full(n_assets, fill_value)\n        else:\n            items_arr = np.full((len(assets_names), n_assets), fill_value)\n        for asset, item in items.items():\n            if asset not in assets_names:\n                raise ValueError(\n                    f\"Asset '{asset}' in '{name}' dictionary is not in 'assets_names'.\"\n                )\n            if dim == 1:\n                items_arr[assets_names == asset] = item\n            else:\n                items_arr[assets_names == asset, :] = item\n    else:\n        items_arr = np.asarray(items)\n        if dim == 1:\n            if items_arr.ndim != 1:\n                raise ValueError(\n                    f\"When '{name}' is a numpy array, it must be 1D, but got {items_arr.ndim}D.\"\n                )\n            if items_arr.shape[0] != n_assets:\n                raise ValueError(\n                    f\"When '{name}' is a numpy array, it must have the same number of assets as 'assets_names'.\"\n                )\n        else:\n            if items_arr.ndim != 2:\n                raise ValueError(\n                    f\"When '{name}' is a numpy array, it must be 2D, but got {items_arr.ndim}D.\"\n                )\n            if items_arr.shape[1] != n_assets:\n                raise ValueError(\n                    f\"When '{name}' is a numpy array, it must have the same number of assets as 'assets_names'.\"\n                )\n    return items_arr\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                \"Assets names must be provided to convert a dictionary into an array\"\n            )\n        if not isinstance(assets_names, np.ndarray):\n            assets_names = np.array(assets_names)\n        if len(assets_names.shape) != 1:\n            raise ValueError(\n                \"Assets names must be provided as a 1-dimensional array of strings\"\n            )\n        if items.keys() != set(assets_names):\n            raise ValueError(\n                \"The assets provided in the dictionary must match the assets names\"\n            )\n        if dim == 1:\n            items_arr = np.full(n_assets, fill_value, dtype=float)\n        elif dim == 2:\n            items_arr = np.full((n_assets, n_assets), fill_value, dtype=float)\n        else:\n            raise ValueError(\n                \"The dimension of the array must be either 1 or 2, got \"\n                f\"{dim} instead\"\n            )\n        for asset, value in items.items():\n            if dim == 1:\n                items_arr[np.where(assets_names == asset)] = value\n            elif dim == 2:\n                items_arr[np.where(assets_names == asset), np.where(assets_names == asset)] = value\n            else:\n                raise ValueError(\n                    \"The dimension of the array must be either 1 or 2, got \"\n                    f\"{dim} instead\"\n                )\n    else:\n        items_arr = np.array(items)\n        if len(items_arr.shape) == 1:\n            if dim == 1:\n                if items_arr.shape[0] != n_assets:\n                    raise ValueError(\n                        f\"The {name} array has an invalid shape. Expected {n_assets} \"\n                        f\"elements, got {items_arr.shape[0]} instead\"\n                    )\n            elif dim == 2:\n                if items_arr"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                f\"When '{name}' is a dictionary, 'assets_names' must be provided.\"\n            )\n        if dim == 1:\n            array = np.full(n_assets, fill_value)\n        else:\n            array = np.full((len(assets_names), n_assets), fill_value)\n        for i, asset in enumerate(assets_names):\n            if asset in items:\n                array[i] = items[asset]\n    else:\n        array = np.asarray(items)\n        if array.ndim == 0:\n            array = array.reshape(1, 1)\n        if array.ndim == 1:\n            if array.shape[0] != n_assets:\n                raise ValueError(\n                    f\"The number of elements in '{name}' must be equal to the number of assets.\"\n                )\n            array = array.reshape(1, n_assets)\n        elif array.ndim == 2:\n            if array.shape[1] != n_assets:\n                raise ValueError(\n                    f\"The number of columns in '{name}' must be equal to the number of assets.\"\n                )\n        else:\n            raise ValueError(\n                f\"The number of dimensions of '{name}' must be 1 or 2, got {array.ndim}.\"\n            )\n    return array\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                f\"When providing a dictionary as '{name}', you must provide the 'assets_names' parameter.\"\n            )\n        if len(items) != len(assets_names):\n            raise ValueError(\n                f\"The number of assets in '{name}' does not match the number of assets in 'assets_names'\"\n            )\n        if dim == 1:\n            output = np.full(n_assets, fill_value, dtype=float)\n        else:\n            output = np.full((n_assets, n_assets), fill_value, dtype=float)\n        for asset, value in items.items():\n            if asset not in assets_names:\n                raise ValueError(\n                    f\"The asset '{asset}' in '{name}' is not present in 'assets_names'\"\n                )\n            if dim == 1:\n                output[np.where(assets_names == asset)] = value\n            else:\n                output[np.where(assets_names == asset), np.where(assets_names == asset)] = value\n        return output\n    else:\n        items = np.asarray(items)\n        if items.ndim == 0:\n            items = items.reshape(-1)\n        if items.ndim == 1:\n            if len(items) != n_assets:\n                raise ValueError(\n                    f\"The number of elements in '{name}' does not match the number of assets in 'assets_names'\"\n                )\n            return items\n        else:\n            if dim == 1:\n                raise ValueError(\n                    f\"The dimension of '{name}' is greater than 1, but it must be 1 for '{name}'.\"\n                )\n            if items.shape[0] != n_assets or items.shape[1] != n_assets:\n                raise ValueError(\n                    f\"The shape of '{name}' is not equal to (n_assets, n_assets), where 'n_assets' is the number of assets in 'assets_names'.\"\n                )\n            return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                \"When using a dictionary, you must specify the 'assets_names' parameter.\"\n            )\n        if not isinstance(assets_names, np.ndarray):\n            assets_names = np.asarray(assets_names)\n        if assets_names.ndim != 1:\n            raise ValueError(\"The parameter 'assets_names' must be a 1D array.\")\n        if assets_names.size != n_assets:\n            raise ValueError(\n                f\"The parameter 'assets_names' must have the same number of assets as the data.\"\n            )\n        if not isinstance(fill_value, (int, float)):\n            raise TypeError(\"The parameter 'fill_value' must be a number.\")\n        if dim == 1:\n            array = np.full(n_assets, fill_value)\n        elif dim == 2:\n            array = np.full((1, n_assets), fill_value)\n        else:\n            raise ValueError(\"'dim' must be either 1 or 2.\")\n        for asset, value in items.items():\n            if asset in assets_names:\n                array[np.where(assets_names == asset)] = value\n    elif isinstance(items, np.ndarray):\n        if items.ndim == 1:\n            array = items.reshape(1, -1)\n        elif items.ndim == 2:\n            array = items\n        else:\n            raise ValueError(\n                f\"The parameter '{name}' must be a 1D or 2D array, got {items.ndim}D.\"\n            )\n        if array.shape[1] != n_assets:\n            raise ValueError(\n                f\"The parameter '{name}' must have the same number of assets as the data.\"\n            )\n    else:\n        try:\n            array = np.asarray(items)\n        except Exception as e:\n            raise TypeError(\n                f\"The parameter '{name}' must be a dictionary, array-like or a numpy array.\"\n            ) from e\n        if array"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                f\"Missing argument. The vector of assets' names must be provided to check the keys in the dictionary of '{name}'.\"\n            )\n        if not isinstance(assets_names, np.ndarray):\n            raise TypeError(\n                f\"The vector of assets' names must be a numpy array, got {type(assets_names)}.\"\n            )\n        if items.keys() != set(assets_names):\n            raise ValueError(\n                f\"The keys in the dictionary of '{name}' do not match the vector of assets' names.\"\n            )\n        items = np.array(\n            [\n                items[asset_name] if asset_name in items else fill_value\n                for asset_name in assets_names\n            ]\n        )\n    if not isinstance(items, np.ndarray):\n        raise TypeError(f\"The '{name}' must be a dictionary or a numpy array, got {type(items)}.\")\n    if dim == 1:\n        if items.ndim == 1:\n            if items.size != n_assets:\n                raise ValueError(\n                    f\"The '{name}' must have the same number of elements as the number of assets, got {items.size} and {n_assets} respectively.\"\n                )\n        elif items.ndim == 2:\n            if items.shape[1] != n_assets:\n                raise ValueError(\n                    f\"The '{name}' must have the same number of columns as the number of assets, got {items.shape[1]} and {n_assets} respectively.\"\n                )\n            items = items.squeeze()\n        else:\n            raise ValueError(\n                f\"The '{name}' must be a vector of size {n_assets} or a matrix with the number of columns equal to the number of assets, got {items.ndim} dimensions and {items.shape} respectively.\"\n            )\n    elif dim == 2:\n        if items.ndim == 1:\n            items = items.reshape(1, -1)\n        if items.ndim"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                \"If 'items' is a dictionary, then 'assets_names' must be provided.\"\n            )\n        if len(assets_names) != n_assets:\n            raise ValueError(\n                f\"If 'items' is a dictionary, then 'assets_names' must have length {n_assets}.\"\n            )\n        if dim == 1:\n            array = np.full(n_assets, fill_value, dtype=float)\n        else:\n            array = np.full((len(assets_names), n_assets), fill_value, dtype=float)\n        for name, value in items.items():\n            if name not in assets_names:\n                raise ValueError(\n                    f\"Invalid asset name '{name}' in '{name}' argument. Must be one of {assets_names}.\"\n                )\n            array[assets_names.get_loc(name)] = value\n    else:\n        array = np.asarray(items)\n        if array.ndim == 1:\n            if dim == 2:\n                array = array.reshape(-1, 1)\n        elif array.ndim == 2:\n            if array.shape[1] != n_assets:\n                raise ValueError(\n                    f\"The number of columns in '{name}' must be {n_assets}.\"\n                )\n        else:\n            raise ValueError(f\"'{name}' must be 1D or 2D.\")\n    return array\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                \"When 'items' is a dictionary, 'assets_names' must be provided.\"\n            )\n        if len(assets_names) != n_assets:\n            raise ValueError(\n                f\"The length of 'assets_names' does not match the expected number of assets.\"\n            )\n        if dim == 2:\n            raise ValueError(\n                f\"When 'items' is a dictionary, 'dim' must be 1, not {dim}.\"\n            )\n        if not set(assets_names).issubset(set(items.keys())):\n            raise ValueError(\n                f\"Some assets are missing in 'items' dictionary, which is not allowed.\"\n            )\n        items = np.array(\n            [items.get(asset, fill_value) for asset in assets_names], dtype=float\n        )\n    else:\n        if dim == 1:\n            items = np.array(items, dtype=float).flatten()\n        elif dim == 2:\n            items = np.array(items, dtype=float)\n        else:\n            raise ValueError(\n                f\"'dim' must be either 1 or 2, not {dim}.\"\n            )\n        if items.shape[0] != n_assets:\n            raise ValueError(\n                f\"The length of 'items' does not match the expected number of assets.\"\n            )\n    return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if assets_names is not None and not isinstance(assets_names, np.ndarray):\n        raise TypeError(\"'assets_names' must be a numpy array.\")\n\n    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                \"When 'items' is a dictionary, 'assets_names' must be provided.\"\n            )\n        if len(assets_names) != len(items):\n            raise ValueError(\n                f\"The number of assets in 'assets_names' must be the same as the number of elements in 'items'.\"\n            )\n        if not isinstance(fill_value, (int, float, bool)):\n            raise TypeError(\n                f\"When 'items' is a dictionary, 'fill_value' must be a number. Got {type(fill_value)}\"\n            )\n        if dim == 1:\n            array = np.full(n_assets, fill_value, dtype=float)\n        else:\n            array = np.full((len(items), n_assets), fill_value, dtype=float)\n        for i, asset in enumerate(assets_names):\n            if asset in items:\n                array[i] = items[asset]\n    else:\n        if isinstance(items, np.ndarray):\n            array = items\n        else:\n            array = np.asarray(items)\n        if array.ndim != dim:\n            raise ValueError(\n                f\"The number of dimensions of 'items' must be {dim}. Got {array.ndim}\"\n            )\n        if array.shape[0] != n_assets:\n            raise ValueError(\n                f\"The number of assets in 'items' must be {n_assets}. Got {array.shape[0]}\"\n            )\n    return array\n\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        agent = MicroAgent(\n            agent_lifecycle,\n            openai_wrapper,\n            data[\"dynamic_prompt\"],\n            data[\"purpose\"],\n            data[\"purpose_embedding\"],\n            data[\"depth\"],\n            data[\"max_depth\"],\n            data[\"usage_count\"],\n            data[\"id\"],\n            data[\"parent_id\"],\n            data[\"working_agent\"],\n            data[\"is_prime\"],\n            data[\"evolve_count\"],\n            data[\"number_of_code_executions\"],\n            data[\"last_input\"],\n        )\n        return agent"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        agent = MicroAgent(agent_lifecycle, openai_wrapper)\n\n        agent.dynamic_prompt = data[\"dynamic_prompt\"]\n        agent.purpose = data[\"purpose\"]\n        agent.purpose_embedding = data[\"purpose_embedding\"]\n        agent.depth = data[\"depth\"]\n        agent.max_depth = data[\"max_depth\"]\n        agent.usage_count = data[\"usage_count\"]\n        agent.id = data[\"id\"]\n        agent.parent_id = data[\"parent_id\"]\n        agent.working_agent = data[\"working_agent\"]\n        agent.is_prime = data[\"is_prime\"]\n        agent.evolve_count = data[\"evolve_count\"]\n        agent.number_of_code_executions = data[\"number_of_code_executions\"]\n        agent.last_input = data[\"last_input\"]\n\n        return agent"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        agent = MicroAgent(\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n            dynamic_prompt=data[\"dynamic_prompt\"],\n            purpose=data[\"purpose\"],\n            purpose_embedding=data[\"purpose_embedding\"],\n            depth=data[\"depth\"],\n            max_depth=data[\"max_depth\"],\n            usage_count=data[\"usage_count\"],\n            id=data[\"id\"],\n            parent_id=data[\"parent_id\"],\n            working_agent=data[\"working_agent\"],\n            is_prime=data[\"is_prime\"],\n            evolve_count=data[\"evolve_count\"],\n            number_of_code_executions=data[\"number_of_code_executions\"],\n            last_input=data[\"last_input\"],\n        )\n\n        return agent"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        agent = MicroAgent(agent_lifecycle, openai_wrapper)\n        agent.dynamic_prompt = data[\"dynamic_prompt\"]\n        agent.purpose = data[\"purpose\"]\n        agent.purpose_embedding = data[\"purpose_embedding\"]\n        agent.depth = data[\"depth\"]\n        agent.max_depth = data[\"max_depth\"]\n        agent.usage_count = data[\"usage_count\"]\n        agent.id = data[\"id\"]\n        agent.parent_id = data[\"parent_id\"]\n        agent.working_agent = data[\"working_agent\"]\n        agent.is_prime = data[\"is_prime\"]\n        agent.evolve_count = data[\"evolve_count\"]\n        agent.number_of_code_executions = data[\"number_of_code_executions\"]\n        agent.last_input = data[\"last_input\"]\n\n        return agent"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        agent = MicroAgent(agent_lifecycle, openai_wrapper)\n        agent.dynamic_prompt = data.get(\"dynamic_prompt\")\n        agent.purpose = data.get(\"purpose\")\n        agent.purpose_embedding = data.get(\"purpose_embedding\")\n        agent.depth = data.get(\"depth\")\n        agent.max_depth = data.get(\"max_depth\")\n        agent.usage_count = data.get(\"usage_count\")\n        agent.id = data.get(\"id\")\n        agent.parent_id = data.get(\"parent_id\")\n        agent.working_agent = data.get(\"working_agent\")\n        agent.is_prime = data.get(\"is_prime\")\n        agent.evolve_count = data.get(\"evolve_count\")\n        agent.number_of_code_executions = data.get(\"number_of_code_executions\")\n        agent.last_input = data.get(\"last_input\")\n        return agent"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        agent = MicroAgent(agent_lifecycle, openai_wrapper)\n        agent.id = data[\"id\"]\n        agent.parent_id = data[\"parent_id\"]\n        agent.dynamic_prompt = data[\"dynamic_prompt\"]\n        agent.purpose = data[\"purpose\"]\n        agent.purpose_embedding = data[\"purpose_embedding\"]\n        agent.depth = data[\"depth\"]\n        agent.max_depth = data[\"max_depth\"]\n        agent.usage_count = data[\"usage_count\"]\n        agent.working_agent = data[\"working_agent\"]\n        agent.is_prime = data[\"is_prime\"]\n        agent.evolve_count = data[\"evolve_count\"]\n        agent.number_of_code_executions = data[\"number_of_code_executions\"]\n        agent.last_input = data[\"last_input\"]\n        return agent"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        agent = MicroAgent(agent_lifecycle, openai_wrapper)\n        agent.dynamic_prompt = data.get(\"dynamic_prompt\", None)\n        agent.purpose = data.get(\"purpose\", None)\n        purpose_embedding = data.get(\"purpose_embedding\", None)\n        if purpose_embedding is not None:\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n        agent.purpose_embedding = purpose_embedding\n        agent.depth = data.get(\"depth\", None)\n        agent.max_depth = data.get(\"max_depth\", None)\n        agent.usage_count = data.get(\"usage_count\", None)\n        agent.id = data.get(\"id\", None)\n        agent.parent_id = data.get(\"parent_id\", None)\n        agent.working_agent = data.get(\"working_agent\", None)\n        agent.is_prime = data.get(\"is_prime\", None)\n        agent.evolve_count = data.get(\"evolve_count\", None)\n        agent.number_of_code_executions = data.get(\"number_of_code_executions\", None)\n        agent.last_input = data.get(\"last_input\", None)\n        return agent"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        return MicroAgent(\n            agent_lifecycle,\n            openai_wrapper,\n            purpose=data[\"purpose\"],\n            purpose_embedding=data[\"purpose_embedding\"],\n            dynamic_prompt=data[\"dynamic_prompt\"],\n            depth=data[\"depth\"],\n            max_depth=data[\"max_depth\"],\n            usage_count=data[\"usage_count\"],\n            id=data[\"id\"],\n            parent_id=data[\"parent_id\"],\n            working_agent=data[\"working_agent\"],\n            is_prime=data[\"is_prime\"],\n            evolve_count=data[\"evolve_count\"],\n            number_of_code_executions=data[\"number_of_code_executions\"],\n            last_input=data[\"last_input\"],\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        agent = MicroAgent(agent_lifecycle, openai_wrapper)\n        agent.dynamic_prompt = data.get(\"dynamic_prompt\")\n        agent.purpose = data.get(\"purpose\")\n        agent.purpose_embedding = data.get(\"purpose_embedding\")\n        agent.depth = data.get(\"depth\")\n        agent.max_depth = data.get(\"max_depth\")\n        agent.usage_count = data.get(\"usage_count\")\n        agent.id = data.get(\"id\")\n        agent.parent_id = data.get(\"parent_id\")\n        agent.working_agent = data.get(\"working_agent\")\n        agent.is_prime = data.get(\"is_prime\")\n        agent.evolve_count = data.get(\"evolve_count\")\n        agent.number_of_code_executions = data.get(\"number_of_code_executions\")\n        agent.last_input = data.get(\"last_input\")\n        return agent\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        agent = MicroAgent(\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n            dynamic_prompt=data[\"dynamic_prompt\"],\n            purpose=data[\"purpose\"],\n            purpose_embedding=data[\"purpose_embedding\"],\n            depth=data[\"depth\"],\n            max_depth=data[\"max_depth\"],\n            usage_count=data[\"usage_count\"],\n            id=data[\"id\"],\n            parent_id=data[\"parent_id\"],\n            working_agent=data[\"working_agent\"],\n            is_prime=data[\"is_prime\"],\n            evolve_count=data[\"evolve_count\"],\n            number_of_code_executions=data[\"number_of_code_executions\"],\n            last_input=data[\"last_input\"],\n        )\n\n        return agent\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        agent = MicroAgent(\n            agent_lifecycle,\n            openai_wrapper,\n            purpose=data.get(\"purpose\", None),\n            purpose_embedding=data.get(\"purpose_embedding\", None),\n            dynamic_prompt=data.get(\"dynamic_prompt\", None),\n            depth=data.get(\"depth\", None),\n            max_depth=data.get(\"max_depth\", None),\n            usage_count=data.get(\"usage_count\", None),\n            id=data.get(\"id\", None),\n            parent_id=data.get(\"parent_id\", None),\n            working_agent=data.get(\"working_agent\", None),\n            is_prime=data.get(\"is_prime\", None),\n            evolve_count=data.get(\"evolve_count\", None),\n            number_of_code_executions=data.get(\"number_of_code_executions\", None),\n            last_input=data.get(\"last_input\", None),\n        )\n\n        return agent\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding:\n            purpose_embedding = np.array(purpose_embedding)\n\n        agent = MicroAgent(\n            purpose_embedding=purpose_embedding,\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )\n\n        return agent"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        # Initialize the agent\n        agent = MicroAgent(agent_lifecycle, openai_wrapper)\n\n        # Set the agent's attributes based on the dictionary's key-value pairs\n        agent.dynamic_prompt = data[\"dynamic_prompt\"]\n        agent.purpose = data[\"purpose\"]\n        agent.purpose_embedding = np.array(data[\"purpose_embedding\"])\n        agent.depth = data[\"depth\"]\n        agent.max_depth = data[\"max_depth\"]\n        agent.usage_count = data[\"usage_count\"]\n        agent.id = data[\"id\"]\n        agent.parent_id = data[\"parent_id\"]\n        agent.working_agent = data[\"working_agent\"]\n        agent.is_prime = data[\"is_prime\"]\n        agent.evolve_count = data[\"evolve_count\"]\n        agent.number_of_code_executions = data[\"number_of_code_executions\"]\n        agent.last_input = data[\"last_input\"]\n\n        return agent"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data[\"purpose_embedding\"]\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            agent_lifecycle,\n            openai_wrapper,\n            purpose=data[\"purpose\"],\n            purpose_embedding=purpose_embedding,\n            depth=data[\"depth\"],\n            max_depth=data[\"max_depth\"],\n            usage_count=data[\"usage_count\"],\n            id=data[\"id\"],\n            parent_id=data[\"parent_id\"],\n            working_agent=data[\"working_agent\"],\n            is_prime=data[\"is_prime\"],\n            evolve_count=data[\"evolve_count\"],\n            number_of_code_executions=data[\"number_of_code_executions\"],\n            last_input=data[\"last_input\"],\n        )\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        agent = MicroAgent(\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n            purpose=data[\"purpose\"],\n            depth=data[\"depth\"],\n            max_depth=data[\"max_depth\"],\n            usage_count=data[\"usage_count\"],\n            id=data[\"id\"],\n            parent_id=data[\"parent_id\"],\n            working_agent=data[\"working_agent\"],\n            is_prime=data[\"is_prime\"],\n            evolve_count=data[\"evolve_count\"],\n            number_of_code_executions=data[\"number_of_code_executions\"],\n            last_input=data[\"last_input\"],\n        )\n\n        agent.dynamic_prompt = data[\"dynamic_prompt\"]\n        agent.purpose_embedding = data[\"purpose_embedding\"]\n\n        return agent\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data[\"purpose_embedding\"]\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            agent_lifecycle,\n            openai_wrapper,\n            purpose_embedding=purpose_embedding,\n            depth=data[\"depth\"],\n            max_depth=data[\"max_depth\"],\n            usage_count=data[\"usage_count\"],\n            id=data[\"id\"],\n            parent_id=data[\"parent_id\"],\n            working_agent=data[\"working_agent\"],\n            is_prime=data[\"is_prime\"],\n            evolve_count=data[\"evolve_count\"],\n            number_of_code_executions=data[\"number_of_code_executions\"],\n            last_input=data[\"last_input\"],\n        )\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        agent = MicroAgent(\n            agent_lifecycle,\n            openai_wrapper\n        )\n\n        agent.dynamic_prompt = data[\"dynamic_prompt\"]\n        agent.purpose = data[\"purpose\"]\n        agent.purpose_embedding = np.array(data[\"purpose_embedding\"])\n        agent.depth = data[\"depth\"]\n        agent.max_depth = data[\"max_depth\"]\n        agent.usage_count = data[\"usage_count\"]\n        agent.id = data[\"id\"]\n        agent.parent_id = data[\"parent_id\"]\n        agent.working_agent = data[\"working_agent\"]\n        agent.is_prime = data[\"is_prime\"]\n        agent.evolve_count = data[\"evolve_count\"]\n        agent.number_of_code_executions = data[\"number_of_code_executions\"]\n        agent.last_input = data[\"last_input\"]\n\n        return agent\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        if data.get('purpose_embedding') is not None:\n            purpose_embedding = np.array(data['purpose_embedding'])\n        else:\n            purpose_embedding = None\n\n        return MicroAgent(\n            agent_lifecycle,\n            openai_wrapper,\n            data['dynamic_prompt'],\n            data['purpose'],\n            purpose_embedding,\n            data['depth'],\n            data['max_depth'],\n            data['usage_count'],\n            data['id'],\n            data['parent_id'],\n            data['working_agent'],\n            data['is_prime'],\n            data['evolve_count'],\n            data['number_of_code_executions'],\n            data['last_input'],\n        )\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        # Set the agent's purpose embedding to None if it is not present in the dictionary\n        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None:\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        # Initialize the MicroAgent\n        agent = MicroAgent(\n            agent_lifecycle,\n            openai_wrapper,\n            purpose_embedding,\n            data[\"purpose\"],\n            data[\"dynamic_prompt\"],\n            data[\"depth\"],\n            data[\"max_depth\"],\n            data[\"usage_count\"],\n            data[\"id\"],\n            data[\"parent_id\"],\n            data[\"working_agent\"],\n            data[\"is_prime\"],\n            data[\"evolve_count\"],\n            data[\"number_of_code_executions\"],\n            data[\"last_input\"],\n        )\n\n        return agent"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        agent = MicroAgent(\n            agent_lifecycle,\n            openai_wrapper,\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n        )\n\n        return agent\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 12.92\n  linear1 = (srgb + eps) ** (1 / 2.4) * 1.055 - 0.055\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  return xnp.where(\n    srgb <= 0.04045,\n    srgb / 12.92,\n    xnp.power((srgb + eps) / 1.055, 2.4),\n  )\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb * 12.92\n  linear1 = 1.055 * xnp.maximum(eps, srgb) ** (1 / 2.4) - 0.055\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  return xnp.where(\n      srgb <= 0.04045,\n      srgb / 12.92,\n      ((srgb + eps) / (1 + eps) ** 2.4) ** 1 / 12.92,\n  )\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb * 12.92\n  linear1 = (srgb + eps) ** (1 / 2.4) * 1.055 - 0.055\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  return xnp.where(\n    srgb <= 0.04045,\n    srgb / 12.92,\n    ((srgb + eps) / 1.055) ** 2.4,\n  )\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  return xnp.where(\n    srgb <= 0.04045,\n    srgb / 12.92,\n    xnp.power((srgb + eps) / 1.055, 2.4),\n  )\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  return xnp.where(\n    srgb <= 0.04045,\n    srgb / 12.92,\n    xnp.power(((srgb + eps) / 1.055), 2.4),\n  )\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n\n  return xnp.where(\n      srgb <= 0.04045,\n      srgb / 12.92,\n      ((srgb + eps) / (12.92 + eps)) ** 2.4,\n  )\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  return xnp.where(srgb <= 0.04045, srgb / 12.92, ((srgb + eps) / (12.92 + eps)) ** 2.4)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  return xnp.where(\n      srgb <= 0.04045, srgb / 12.92, ((srgb + eps) / (12.92 + eps)) ** 2.4\n  )\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  return xnp.where(\n      srgb <= 0.04045,\n      srgb / 12.92,\n      ((srgb + eps) / 1.055) ** 2.4,\n  )\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  return xnp.where(\n    srgb <= 0.04045,\n    srgb / 12.92,\n    ((srgb + eps) / (1 + eps) ** 2.4) ** 1 / 12.2,\n  )\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  return xnp.where(\n    srgb <= 0.04045,\n    srgb / 12.92,\n    ((srgb + eps) / (1 + eps) ** 2.4) ** 1 / 12.2,\n  )\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  return xnp.where(\n    srgb <= 0.04045,\n    srgb / 12.92,\n    ((srgb + eps) / 1.055) ** 2.4,\n  )\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n\n  # Convert to linear space\n  linear = xnp.where(\n    srgb <= 0.04045,\n    srgb / 12.92,\n    ((srgb + 0.055) / 1.055) ** 2.4\n  )\n\n  return linear\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb * 12.92\n  linear1 = xnp.maximum(eps, srgb) ** (1 / 2.4) * 1.055 - 0.055\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb * 25 / 323\n  linear1 = (116 * xnp.maximum(eps, srgb) ** (5 / 12) - 16) / 220\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 12.92\n  linear1 = (srgb + eps) ** (1 / 2.4) * 1.055 - 0.055\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  return xnp.where(srgb <= 0.04045, srgb / 12.92, ((srgb + eps) / (1 + eps) ** 2.4) ** 1 / 1.055)\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Convert x, t_input, t_output to numpy arrays.\n  x = np.array(x)\n  t_input = np.array(t_input)\n  t_output = np.array(t_output)\n\n  # Adjust spline_degree to be at most one less than the number of points in x.\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Interpolate.\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n  return scipy.interpolate.splev(t_output, tck)\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Adjust spline degree to be at most one less than the number of points in x.\n  n = len(x)\n  spline_degree = min(spline_degree, n - 1)\n\n  # Interpolate the signal.\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n  y = scipy.interpolate.splev(t_output, tck)\n\n  return y\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Set the spline degree to be at most one less than the number of points in x.\n  spline_degree = min(spline_degree, len(x) - 1)\n  # Interpolate the signal.\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n  y = scipy.interpolate.splev(t_output, tck)\n  return y\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Check that the input and output times are sorted\n  assert np.all(np.diff(t_input) > 0)\n  assert np.all(np.diff(t_output) > 0)\n\n  # Adjust the spline degree to be at most one less than the number of points in x\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Calculate the spline coefficients\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n\n  # Interpolate the signal\n  x_interp = scipy.interpolate.splev(t_output, tck)\n\n  return x_interp\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  x = np.asarray(x)\n  t_input = np.asarray(t_input)\n  t_output = np.asarray(t_output)\n  spline_degree = min(spline_degree, len(x) - 1)\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n  return scipy.interpolate.splev(t_output, tck)\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Adjust the spline degree to be at most one less than the number of points in x.\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Use scipy to interpolate the signal.\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n  return scipy.interpolate.splev(t_output, tck)\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  t_input = np.array(t_input)\n  t_output = np.array(t_output)\n  x = np.array(x)\n\n  if t_input.size < 2:\n    raise ValueError(\"t_input must have at least two elements.\")\n  if t_output.size < 2:\n    raise ValueError(\"t_output must have at least two elements.\")\n  if t_input.size != x.size:\n    raise ValueError(\"t_input and x must have the same length.\")\n  if t_input.size < spline_degree + 1:\n    spline_degree = t_input.size - 1\n  if spline_degree < 1:\n    raise ValueError(\"spline_degree must be at least 1.\")\n\n  # Interpolate the signal.\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n  x_output = scipy.interpolate.splev(t_output, tck)\n\n  return x_output\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # If there are fewer points than the spline degree, set the degree to one less.\n  if len(x) < spline_degree:\n    spline_degree = len(x) - 1\n\n  # Use scipy's spline interpolation function.\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n  return scipy.interpolate.splev(t_output, tck)\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Check if x, t_input, and t_output are array-like.\n  if not isinstance(x, np.ndarray):\n    raise TypeError(\"x must be an array-like object\")\n  if not isinstance(t_input, np.ndarray):\n    raise TypeError(\"t_input must be an array-like object\")\n  if not isinstance(t_output, np.ndarray):\n    raise TypeError(\"t_output must be an array-like object\")\n\n  # Check if x, t_input, and t_output are 1-dimensional.\n  if len(x.shape) != 1:\n    raise ValueError(\"x must be a 1-dimensional array-like object\")\n  if len(t_input.shape) != 1:\n    raise ValueError(\"t_input must be a 1-dimensional array-like object\")\n  if len(t_output.shape) != 1:\n    raise ValueError(\"t_output must be a 1-dimensional array-like object\")\n\n  # Check if x, t_input, and t_output have the same number of elements.\n  if x.shape[0] != t_input.shape[0]:\n    raise ValueError(\"x and t_input must have the same number of elements\")\n\n  # Check if t_output is sorted.\n  if not np.all(np.diff(t_output) >= 0):\n    raise ValueError(\"t_output must be sorted\")\n\n  # Check if t_input is sorted.\n  if not np.all(np.diff(t_input) >= 0):\n    raise ValueError(\"t_input must be sorted\")\n\n  # Check if t_input and t_output are strictly increasing.\n  if np.any(np.diff(t_input) <= 0):\n    raise ValueError(\"t_input must be strictly increasing\")\n  if np.any(np.diff(t_output) <= 0):\n    raise ValueError(\"t_output must be strictly increasing\")\n\n  # Check if t_input and t_output are strictly increasing.\n  if np.any(np.diff("}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  if len(x) <= 2:\n    return np.interp(t_output, t_input, x)\n  spline_degree = min(spline_degree, len(x) - 2)\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n  return scipy.interpolate.splev(t_output, tck)\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Ensure that the input signal is a 1-dimensional array.\n  x = np.asarray(x)\n\n  # Ensure that the input times are a 1-dimensional array.\n  t_input = np.asarray(t_input)\n\n  # Ensure that the output times are a 1-dimensional array.\n  t_output = np.asarray(t_output)\n\n  # Ensure that the number of input times equals the number of input samples.\n  if t_input.shape[0] != x.shape[0]:\n    raise ValueError(\"The number of input times must equal the number of input samples.\")\n\n  # Ensure that the input times are sorted in ascending order.\n  if not np.all(t_input[1:] - t_input[:-1] >= 0):\n    raise ValueError(\"The input times must be sorted in ascending order.\")\n\n  # Ensure that the output times are sorted in ascending order.\n  if not np.all(t_output[1:] - t_output[:-1] >= 0):\n    raise ValueError(\"The output times must be sorted in ascending order.\")\n\n  # Ensure that the spline degree is a non-negative integer.\n  if not isinstance(spline_degree, int) or spline_degree < 0:\n    raise ValueError(\"The spline degree must be a non-negative integer.\")\n\n  # Ensure that the smoothness is a non-negative float.\n  if not isinstance(smoothness, float) or smoothness < 0:\n    raise ValueError(\"The smoothness must be a non-negative float.\")\n\n  # Ensure that the spline degree is at most one less than the number of input samples.\n  if spline_degree > x.shape[0] - 1:\n    raise ValueError(\"The spline degree must be at most one less than the number of input samples.\")\n\n  # Ensure that the input times do not contain duplicates.\n  if np.unique(t_input).shape[0] != t_input.shape[0]:\n    raise ValueError(\"The input times must"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Adjust the spline degree to be at most one less than the number of points in x.\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Convert x to a numpy array.\n  x = np.array(x)\n\n  # Convert t_input and t_output to numpy arrays.\n  t_input = np.array(t_input)\n  t_output = np.array(t_output)\n\n  # Make sure that the number of input and output times are the same.\n  if len(t_input) != len(t_output):\n    raise ValueError('Number of input and output times must be the same.')\n\n  # Make sure that the input and output times are sorted.\n  if not np.all(np.diff(t_input) >= 0):\n    raise ValueError('Input times must be sorted.')\n  if not np.all(np.diff(t_output) >= 0):\n    raise ValueError('Output times must be sorted.')\n\n  # Make sure that the input and output times are 1-dimensional.\n  if t_input.ndim != 1 or t_output.ndim != 1:\n    raise ValueError('Input and output times must be 1-dimensional.')\n\n  # Make sure that the input and output times have the same shape.\n  if t_input.shape != t_output.shape:\n    raise ValueError('Input and output times must have the same shape.')\n\n  # Make sure that the input and output times have the same length.\n  if len(t_input) != len(t_output):\n    raise ValueError('Input and output times must have the same length.')\n\n  # Make sure that the spline degree is positive.\n  if spline_degree < 0:\n    raise ValueError('Spline degree must be positive.')\n\n  # Make sure that the smoothness is non-negative.\n  if smoothness < 0:\n    raise ValueError('Smoothness must be non-negative.')\n\n  # Make sure that the input and output times are strictly"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  t_input = np.array(t_input)\n  t_output = np.array(t_output)\n  x = np.array(x)\n  if t_input.shape[0] == 1:\n    return np.ones_like(t_output) * x\n  if t_input.shape[0] == 2:\n    return np.linspace(x[0], x[1], t_output.shape[0])\n  spline_degree = min(spline_degree, t_input.shape[0] - 2)\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n  return scipy.interpolate.splev(t_output, tck)\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  if len(x) < 2:\n    raise ValueError(\"x must have at least 2 elements.\")\n  if len(x) < spline_degree:\n    spline_degree = len(x) - 1\n  if len(t_input) < 2:\n    raise ValueError(\"t_input must have at least 2 elements.\")\n  if len(t_output) < 2:\n    raise ValueError(\"t_output must have at least 2 elements.\")\n  if len(t_input) != len(x):\n    raise ValueError(\"t_input and x must have the same length.\")\n  if not np.all(np.diff(t_input) > 0):\n    raise ValueError(\"t_input must be sorted in ascending order.\")\n  if not np.all(np.diff(t_output) > 0):\n    raise ValueError(\"t_output must be sorted in ascending order.\")\n  if t_input[0] > t_output[0]:\n    raise ValueError(\"t_input[0] must be less than or equal to t_output[0].\")\n  if t_input[-1] < t_output[-1]:\n    raise ValueError(\"t_input[-1] must be greater than or equal to t_output[-1].\")\n\n  # t_input and t_output are assumed to be sorted in ascending order.\n  # If this is not the case, we need to re-order them.\n  if t_input[0] > t_output[0] or t_input[-1] < t_output[-1]:\n    t_input, t_output = (\n        np.concatenate([t_input, t_output]),\n        np.concatenate([t_output, t_input]),\n    )\n    x = np.concatenate([x, x])\n\n  # Perform spline interpolation.\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n  return scipy.interpolate.splev(t_output, t"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Adjust the spline degree to be at most one less than the number of points in x.\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Make sure that the input and output time arrays are sorted.\n  t_input = np.sort(t_input)\n  t_output = np.sort(t_output)\n\n  # Use a cubic spline to interpolate the input signal.\n  spline = scipy.interpolate.splrep(t_input, x, s=smoothness, k=spline_degree)\n  return scipy.interpolate.splev(t_output, spline)\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Adjust spline degree to be at most one less than the number of points in x.\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Calculate the spline.\n  spline = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n\n  # Evaluate the spline at the output times.\n  y = scipy.interpolate.splev(t_output, spline)\n\n  return y\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Get the spline degree.\n  n_input = len(x)\n  spline_degree = min(spline_degree, n_input - 1)\n\n  # Get the spline parameters.\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n\n  # Interpolate the signal.\n  y = scipy.interpolate.splev(t_output, tck)\n\n  return y\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Adjust spline degree to be at most one less than the number of points in x.\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Create spline.\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n\n  # Query spline at t_output.\n  return scipy.interpolate.splev(t_output, tck)\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Adjust the spline degree to be at most one less than the number of points in x.\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Get the spline coefficients.\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n\n  # Interpolate the signal.\n  return scipy.interpolate.splev(t_output, tck)\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  x = np.asarray(x)\n  t_input = np.asarray(t_input)\n  t_output = np.asarray(t_output)\n\n  # Adjust the spline degree to be at most one less than the number of points.\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Use scipy to perform the spline interpolation.\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n  return scipy.interpolate.splev(t_output, tck)\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    elif word.islower():\n        return word\n    else:\n        first_two = word[0:2]\n        if first_two.isupper():\n            return word.lower()\n        else:\n            return word.capitalize()\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    if word.istitle():\n        return word\n    if word.islower():\n        return word\n    if word.istitle():\n        return word\n    if word.isupper():\n        return word\n    if word.istitle():\n        return word\n    if word.islower():\n        return word\n    if word.istitle():\n        return word\n    if word.isupper():\n        return word\n    if word.istitle():\n        return word\n    if word.islower():\n        return word\n    if word.istitle():\n        return word\n    if word.isupper():\n        return word\n    if word.istitle():\n        return word\n    if word.islower():\n        return word\n    if word.istitle():\n        return word\n    if word.isupper():\n        return word\n    if word.istitle():\n        return word\n    if word.islower():\n        return word\n    if word.istitle():\n        return word\n    if word.isupper():\n        return word\n    if word.istitle():\n        return word\n    if word.islower():\n        return word\n    if word.istitle():\n        return word\n    if word.isupper():\n        return word\n    if word.istitle():\n        return word\n    if word.islower():\n        return word\n    if word.istitle():\n        return word\n    if word.isupper():\n        return word\n    if word.istitle():\n        return word\n    if word.islower():\n        return word\n    if word.istitle():\n        return word\n    if word.isupper():\n        return word\n    if word.istitle():\n        return word\n    if word.islower():\n        return word\n    if word.istitle():\n        return word\n    if word.isupper():\n        return word\n    if word.istitle():\n        return word\n    if word.islower():\n        return word\n    if word.istitle():\n        return word\n    if word.isupper():"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    if word.islower():\n        return word\n    if word[0].isupper() and word[1:].islower():\n        return word.lower()\n    if word[0].islower() and word[1:].isupper():\n        return word.upper()\n    if word[0].isupper() and word[1:].isupper():\n        return word.capitalize()\n    return word\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    if word.islower():\n        return word\n    if word.istitle():\n        return word\n    if word[0].isupper() and word[1].isupper():\n        return word\n    if word[0].isupper() and word[1].islower():\n        return word.lower()\n    if word[0].islower() and word[1].islower():\n        return word.title()\n    if word[0].islower() and word[1].isupper():\n        return word.upper()\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    elif word.islower():\n        return word\n    else:\n        if word[0].isupper() and word[1].isupper():\n            return word\n        elif word[0].isupper() and word[1].islower():\n            return word.lower()\n        elif word[0].islower() and word[1].isupper():\n            return word.capitalize()\n        elif word[0].islower() and word[1].islower():\n            return word\n        else:\n            return word\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    if word.islower():\n        return word\n    if word.istitle():\n        return word\n    if word.isupper() == False and word.islower() == False:\n        first_two = word[0:2]\n        if first_two.isupper():\n            return word.lower()\n        if first_two.islower():\n            return word.title()\n        if first_two.istitle():\n            return word.upper()\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    if word.islower():\n        return word\n    if word.istitle():\n        return word\n    if word.isupper():\n        return word\n\n    # if word.istitle():\n    #     return word\n    # if word.istitle():\n    #     return word\n    # if word.istitle():\n    #     return word\n    # if word.istitle():\n    #     return word\n    # if word.istitle():\n    #     return word\n    # if word.istitle():\n    #     return word\n    # if word.istitle():\n    #     return word\n    # if word.istitle():\n    #     return word\n    # if word.istitle():\n    #     return word\n    # if word.istitle():\n    #     return word\n    # if word.istitle():\n    #     return word\n    # if word.istitle():\n    #     return word\n    # if word.istitle():\n    #     return word\n    # if word.istitle():\n    #     return word\n    # if word.istitle():\n    #     return word\n    # if word.istitle():\n    #     return word\n    # if word.istitle():\n    #     return word\n    # if word.istitle():\n    #     return word\n    # if word.istitle():\n    #     return word\n    # if word.istitle():\n    #     return word\n    # if word.istitle():\n    #     return word\n    # if word.istitle():\n    #     return word\n    # if word.istitle():\n    #     return word\n    # if word.istitle():\n    #     return word\n    # if word.istitle():\n    #     return word\n    # if word.istitle():\n    #     return word\n    # if word.istitle():\n    #     return word\n    # if word.istitle():\n    #     return word\n    # if word.istitle():\n    #     return word\n    # if word.istitle():\n    #     return word"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    elif word.isupper():\n        return word\n    else:\n        first = word[0]\n        second = word[1]\n        if first.isupper() and second.isupper():\n            return word\n        elif first.islower() and second.islower():\n            return word.lower()\n        elif first.isupper() and second.islower():\n            return word.capitalize()\n        else:\n            return word\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    if word.islower():\n        return word\n    if word.istitle():\n        return word\n    if word[0].isupper() and word[1].isupper():\n        return word\n    if word[0].isupper() and word[1].islower():\n        return word.lower()\n    if word[0].islower() and word[1].isupper():\n        return word.capitalize()\n    if word[0].islower() and word[1].islower():\n        return word.upper()\n    return word\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    if word.islower():\n        return word\n    else:\n        return word.capitalize()\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    if word.islower():\n        return word\n    if word.istitle():\n        return word\n\n    # if word is mixed case\n    # if first two letters are upper\n    # if first letter is upper, second is lower\n    # if first letter is lower, second is upper\n\n    # if first two letters are upper\n    if word[0].isupper() and word[1].isupper():\n        return word.lower()\n    # if first letter is upper, second is lower\n    if word[0].isupper() and word[1].islower():\n        return word.title()\n    # if first letter is lower, second is upper\n    if word[0].islower() and word[1].isupper():\n        return word.capitalize()\n\n\n\n    return word"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    # TODO: Complete this function to correct the casing of the given word.\n    # TODO: Return the word after applying the corrections\n    if word.isupper():\n        return word\n    elif word.islower():\n        return word\n    else:\n        if word[0].isupper() and word[1].isupper():\n            return word.lower()\n        elif word[0].isupper() and word[1].islower():\n            return word.capitalize()\n        elif word[0].islower() and word[1].isupper():\n            return word\n        else:\n            return word.lower()\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    elif word.islower():\n        return word\n    else:\n        if word[0].isupper() and word[1].isupper():\n            return word.lower()\n        elif word[0].isupper() and word[1].islower():\n            return word.capitalize()\n        elif word[0].islower() and word[1].isupper():\n            return word.upper()\n        else:\n            return word\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    if word.istitle():\n        return word\n    if word[0].isupper() and word[1].isupper():\n        return word\n    if word[0].isupper() and word[1].islower():\n        return word.lower()\n    if word[0].islower() and word[1].isupper():\n        return word.capitalize()\n    return word\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    # if word is lowercase or uppercase, return word\n    if word.islower() or word.isupper():\n        return word\n    # if word is mixed case, return corrected word\n    else:\n        # if first two letters are lowercase, return lowercase word\n        if word[0].islower() and word[1].islower():\n            return word.lower()\n        # if first two letters are uppercase, return uppercase word\n        elif word[0].isupper() and word[1].isupper():\n            return word.upper()\n        # if first letter is uppercase, capitalize first letter\n        elif word[0].isupper() and word[1].islower():\n            return word[0].upper() + word[1:]\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    # TODO: Implement this function\n    if word.isupper():\n        return word\n    elif word.islower():\n        return word\n    else:\n        if word[0].isupper() and word[1].isupper():\n            return word.lower()\n        elif word[0].isupper() and word[1].islower():\n            return word.capitalize()\n        elif word[0].islower() and word[1].isupper():\n            return word\n        else:\n            return word.lower()\n\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    if word.isupper():\n        return word\n\n    if word[0].isupper() and word[1].isupper():\n        return word\n\n    if word[0].isupper() and word[1].islower():\n        return word.lower()\n\n    if word[0].islower() and word[1].isupper():\n        return word.capitalize()\n\n    return word\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    if word.isupper():\n        return word\n\n    if len(word) <= 2:\n        return word.capitalize()\n\n    if word[0].isupper() and word[1].isupper():\n        return word.capitalize()\n\n    if word[0].isupper() and word[1].islower():\n        return word\n\n    if word[0].islower() and word[1].isupper():\n        return word.capitalize()\n\n    return word\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    if word.islower():\n        return word\n    if word.istitle():\n        return word\n\n    # if word is mixed case\n    # if word is lowercase\n    # if word is uppercase\n    # if word is title case\n\n    # if word is mixed case\n    if len(word) >= 2:\n        first_two = word[0:2]\n        if first_two.isupper():\n            return word.title()\n        if first_two.islower():\n            return word.lower()\n\n    # if word is lowercase\n    if word.islower():\n        return word\n\n    # if word is uppercase\n    if word.isupper():\n        return word\n\n    # if word is title case\n    if word.istitle():\n        return word\n\n    return word\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    if word.istitle():\n        return word\n    if word[0].isupper() and word[1].isupper():\n        return word\n    if word[0].isupper() and word[1].islower():\n        return word[0] + word[1].upper() + word[2:]\n    if word[0].islower() and word[1].isupper():\n        return word[0].upper() + word[1] + word[2:]\n    if word[0].islower() and word[1].islower():\n        return word[0].upper() + word[1] + word[2:]\n    return word\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.all(np.isin(v, [True, False])):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be binary array.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.all(np.isin(v, [True, False])):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be binary values.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.all(np.isin(v, [True, False])):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be binary.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.all(np.isin(v, [True, False])):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be binary values.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.all(np.isin(v, [True, False])):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be binary values.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if v.dtype.type != np.bool_:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be binary values.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.all(np.isin(v, [True, False])):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be binary values.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.isin(v, [True, False]).all():\n        raise ValueError(f\"{cls.__name__}: {field.name} must be binary (i.e., contain only True or False values).\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if v.dtype != bool:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be binary values.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.all(np.isin(np.unique(v), [True, False])):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be binary values.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.all(np.isin(v, [True, False])):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be binary values.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.all(np.isin(v, [True, False])):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be binary (contains only True or False values).\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.isin(v, [True, False]).all():\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain binary values (True or False).\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.all(np.isin(v, [True, False])):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be binary.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.all(np.isin(v, [0, 1])):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be binary values (True or False).\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.all(np.isin(np.unique(v), [True, False])):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be binary values.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.all(np.isin(v, [True, False])):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be binary (contains only True or False values).\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.all(np.isin(v, [0, 1])):\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only binary values (0 or 1).\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.all(np.isin(v, [0, 1])):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be binary.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.isin(v, [True, False]).all():\n        raise ValueError(f\"{cls.__name__}: {field.name} must be binary, but found {v.dtype} instead.\")\n\n    return v\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  inv_scale = 2 * jnp.sqrt(x_mag_sq) - x_mag_sq\n  x = x / inv_scale\n  return x\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  inv_scale = 2 * jnp.sqrt(x_mag_sq) - x_mag_sq\n  z = x / inv_scale\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  inv_scale = 2 * jnp.sqrt(x_mag_sq) - x_mag_sq\n  return x * inv_scale\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  inv_scale = 2 * jnp.sqrt(x_mag_sq) - x_mag_sq\n  x = x * inv_scale\n  return x\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  inv_scale = 2 * jnp.sqrt(x_mag_sq) - x_mag_sq\n  return x / inv_scale\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  inv_scale = 2 * jnp.sqrt(x_mag_sq) - x_mag_sq\n  x = x / inv_scale\n  return x\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  inv_scale = 2 * jnp.sqrt(x_mag_sq) - x_mag_sq\n  x = x / inv_scale\n  return x\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  inv_scale = 2 * jnp.sqrt(x_mag_sq) - x_mag_sq\n  z = x / inv_scale\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  inv_scale = 2 * jnp.sqrt(x_mag_sq) - x_mag_sq\n  z = x / inv_scale\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  if x.shape[-1] != 3:\n    raise ValueError(\n        f'The last dimension of the input array must be 3, but got {x.shape[-1]}.'\n    )\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = 2 * jnp.sqrt(x_mag_sq) - x_mag_sq\n  z = scale * x\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  inv_scale = 2 * jnp.sqrt(x_mag_sq) - x_mag_sq\n  x = x / inv_scale\n  return x\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  inv_scale = 2 * jnp.sqrt(x_mag_sq) - x_mag_sq\n  return x * inv_scale\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  inv_scale = 2 * jnp.sqrt(x_mag_sq) - x_mag_sq\n  x = x / inv_scale\n  return x\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  inv_scale = 2 * jnp.sqrt(x_mag_sq) - x_mag_sq\n  x = x / inv_scale\n  return x\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    # Load summary file\n    summary_df = pd.read_csv(summary_path, sep='\\t', header=0, index_col=0)\n\n    # Convert specified columns to dictionary objects\n    for col in dict_columns:\n        summary_df[col] = summary_df[col].apply(ast.literal_eval)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    # Load the summary file\n    summary_df = pd.read_csv(summary_path, sep='\\t')\n\n    # Convert specified columns to dictionaries\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(ast.literal_eval)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    with open(summary_path, 'r') as summary_file:\n        summary_df = pd.read_csv(summary_file, sep='\\t', index_col=0)\n\n    for column in dict_columns:\n        if column in summary_df.columns:\n            summary_df[column] = summary_df[column].apply(ast.literal_eval)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path, sep='\\t')\n    for dict_column in dict_columns:\n        summary_df[dict_column] = summary_df[dict_column].apply(ast.literal_eval)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(ast.literal_eval)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for column_name in dict_columns:\n        if column_name in summary_df.columns:\n            summary_df[column_name] = summary_df[column_name].apply(ast.literal_eval)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    # Load summary file into dataframe\n    summary_df = pd.read_csv(summary_path, sep='\\t')\n\n    # Convert specified columns to dictionaries\n    for column_name in dict_columns:\n        summary_df[column_name] = summary_df[column_name].apply(ast.literal_eval)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    # Load summary file\n    summary_df = pd.read_csv(summary_path)\n\n    # Convert specified columns to dictionaries\n    if dict_columns is None:\n        dict_columns = ['module_params']\n    for col in dict_columns:\n        summary_df[col] = summary_df[col].apply(ast.literal_eval)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    # Load summary file\n    summary_df = pd.read_csv(summary_path)\n\n    # Convert specified columns to dictionaries\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(ast.literal_eval)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path, sep='\\t', encoding='utf-8', keep_default_na=False)\n\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(ast.literal_eval)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    # Set default value for dict_columns\n    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    # Load the summary file into a DataFrame\n    summary_df = pd.read_csv(summary_path)\n\n    # Convert specified columns into dictionaries\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(ast.literal_eval)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    # Read summary file\n    summary_df = pd.read_csv(summary_path)\n\n    # Convert specified columns to dictionaries\n    for column_name in dict_columns:\n        summary_df[column_name] = summary_df[column_name].apply(ast.literal_eval)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n    for dict_column in dict_columns:\n        summary_df[dict_column] = summary_df[dict_column].apply(ast.literal_eval)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path, index_col=0)\n\n    for col in dict_columns:\n        summary_df[col] = summary_df[col].apply(ast.literal_eval)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(ast.literal_eval)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    # Set default value for dict_columns\n    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    # Load summary file\n    summary_df = pd.read_csv(summary_path)\n\n    # Convert specified columns to dictionaries\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(ast.literal_eval)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path, sep='\\t')\n    for col in dict_columns:\n        summary_df[col] = summary_df[col].apply(ast.literal_eval)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    # Load the summary file into a pandas DataFrame.\n    summary_df = pd.read_csv(summary_path)\n\n    # If dict_columns is None, assume that the only column containing a dictionary is 'module_params'.\n    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    # Convert the specified columns to dictionary objects.\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(ast.literal_eval)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n    for column_name in dict_columns:\n        if column_name in summary_df.columns:\n            summary_df[column_name] = summary_df[column_name].apply(ast.literal_eval)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    def convert_dict_str_to_dict(dict_str: str) -> Dict[str, Any]:\n        \"\"\"\n        Converts a dictionary-like string into a dictionary object.\n        \"\"\"\n        # Remove single quotes from the string\n        dict_str = dict_str.replace('\\'', '\\\"')\n        # Convert to a dictionary\n        dict_str = ast.literal_eval(dict_str)\n        return dict_str\n\n    # Read the summary file into a DataFrame\n    summary_df = pd.read_csv(summary_path, sep='\\t')\n\n    # Convert specified columns to dictionaries\n    for dict_column in dict_columns:\n        if dict_column in summary_df.columns:\n            summary_df[dict_column] = summary_df[dict_column].apply(lambda x: convert_dict_str_to_dict(x))\n\n    return summary_df\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov) ** (1 / cov.shape[-1])\n    return det * jnp.eye(cov.shape[-1])\n  elif mode == 'accurate':\n    det = jnp.exp(jnp.log(jnp.linalg.det(cov)) / cov.shape[-1])\n    return det * jnp.eye(cov.shape[-1])\n  else:\n    raise ValueError(\"Mode must be either 'fast' or 'accurate'.\")\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov) ** (1 / cov.shape[-1])\n    return det * jnp.eye(cov.shape[-1])\n  elif mode == 'accurate':\n    det = jnp.exp(jnp.log(jnp.linalg.det(cov)) / cov.shape[-1])\n    return det * jnp.eye(cov.shape[-1])\n  else:\n    raise ValueError(\"mode must be 'fast' or 'accurate'.\")\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    cov_det = jnp.linalg.det(cov)\n    cov_isotropic = cov * cov_det ** (-1 / cov.shape[-1])\n  elif mode == 'accurate':\n    cov_logdet = jnp.linalg.slogdet(cov)[1]\n    cov_isotropic = cov * jnp.exp(-cov_logdet / cov.shape[-1])\n  else:\n    raise ValueError('Invalid mode.')\n  return cov_isotropic\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov)**(1/cov.shape[-1])\n    return det * jnp.eye(cov.shape[-1])\n  elif mode == 'accurate':\n    det = jnp.exp(jnp.log(jnp.linalg.det(cov))/(cov.shape[-1]))\n    return det * jnp.eye(cov.shape[-1])\n  else:\n    raise NotImplementedError\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n    # Check for invalid determinants.\n    det = jnp.where(det <= 0, 1e-8, det)\n    iso_cov = cov / jnp.sqrt(det)\n  elif mode == 'accurate':\n    logdet = jnp.log(jnp.linalg.det(cov))\n    # Check for invalid logarithms of determinants.\n    logdet = jnp.where(jnp.isnan(logdet), -100, logdet)\n    iso_cov = cov * jnp.exp(-0.5 * logdet)\n  else:\n    raise ValueError('Invalid mode: {}'.format(mode))\n\n  return iso_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'accurate':\n    det = jnp.exp(jnp.log(jnp.linalg.det(cov)) / cov.shape[-1])\n  elif mode == 'fast':\n    det = jnp.linalg.det(cov)\n  else:\n    raise ValueError(f'Invalid mode {mode}')\n\n  return det * jnp.eye(cov.shape[-1])\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n    iso = jnp.zeros_like(cov)\n    iso = jax.ops.index_update(iso, jax.ops.index[:, 0, 0], det)\n    iso = jax.ops.index_update(iso, jax.ops.index[:, 1, 1], det)\n    iso = jax.ops.index_update(iso, jax.ops.index[:, 2, 2], det)\n  elif mode == 'accurate':\n    log_det = jnp.log(jnp.linalg.det(cov))\n    iso = jnp.zeros_like(cov)\n    iso = jax.ops.index_update(iso, jax.ops.index[:, 0, 0], log_det)\n    iso = jax.ops.index_update(iso, jax.ops.index[:, 1, 1], log_det)\n    iso = jax.ops.index_update(iso, jax.ops.index[:, 2, 2], log_det)\n  else:\n    raise ValueError('Invalid mode.')\n\n  return iso\n\n"}
{"namespace": "coord.isotropize", "completion": "  # Compute the determinant of the covariance matrix.\n  det = jnp.linalg.det(cov)\n\n  # Handle invalid determinants or logarithms of determinants.\n  if mode == 'accurate':\n    det = jnp.where(det <= 0, jnp.exp(-100), det)\n  elif mode == 'fast':\n    det = jnp.maximum(det, 0)\n  else:\n    raise ValueError('Invalid mode.')\n\n  # Compute the isotropic covariance matrix.\n  return det * jnp.eye(cov.shape[-1])\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov) ** 0.25\n    return det * jnp.eye(cov.shape[-1])\n  elif mode == 'accurate':\n    logdet = jnp.log(jnp.linalg.det(cov)) * 0.25\n    if jnp.any(jnp.isnan(logdet)):\n      return jnp.full_like(cov, jnp.nan)\n    else:\n      return jnp.exp(logdet) * jnp.eye(cov.shape[-1])\n  else:\n    raise ValueError('Invalid mode: ' + mode)\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov)**(1/cov.shape[-1])\n    return det * jnp.eye(cov.shape[-1])\n  elif mode == 'accurate':\n    det = jnp.exp(jnp.log(jnp.linalg.det(cov))/(cov.shape[-1]))\n    return det * jnp.eye(cov.shape[-1])\n  else:\n    raise ValueError('Invalid mode.')\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n    iso_cov = cov / jnp.power(det, 1 / cov.shape[-1])\n  elif mode == 'accurate':\n    logdet = jnp.linalg.slogdet(cov)[1]\n    iso_cov = cov * jnp.exp(-logdet / cov.shape[-1])\n  else:\n    raise ValueError(f'Invalid mode {mode}, must be \"fast\" or \"accurate\".')\n  return iso_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  # Compute the logarithm of the determinant of the covariance matrix\n  if mode == 'accurate':\n    log_det_cov = jnp.log(jnp.linalg.det(cov))\n  elif mode == 'fast':\n    log_det_cov = jnp.log(jnp.linalg.det(cov))\n  else:\n    raise ValueError(f'Invalid mode {mode}.')\n\n  # Compute the isotropic covariance matrix\n  cov_isotropic = jnp.exp(log_det_cov / cov.shape[-1]) * jnp.eye(cov.shape[-1])\n\n  return cov_isotropic\n\n"}
{"namespace": "coord.isotropize", "completion": "  det = jnp.linalg.det(cov)\n  if mode == 'fast':\n    det_sqrt = jnp.sqrt(det)\n    return cov / (det_sqrt[Ellipsis, None, None] * det_sqrt[Ellipsis, None])\n  elif mode == 'accurate':\n    det_log = jnp.log(det)\n    det_log_2 = det_log / 2\n    return jnp.exp(det_log_2) * cov / det_log[Ellipsis, None, None]\n  else:\n    raise ValueError(f'Invalid mode {mode}.')\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n    iso_cov = cov / jnp.sqrt(det)\n  elif mode == 'accurate':\n    log_det = jnp.log(jnp.linalg.det(cov))\n    iso_cov = jnp.exp(log_det / 2) * cov\n    iso_cov = iso_cov / jnp.sqrt(jnp.linalg.det(iso_cov))\n  else:\n    raise ValueError('Invalid mode.')\n  return iso_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  # Compute the logarithm of the determinant of the input covariance matrix or matrices.\n  log_det = jnp.log(jnp.linalg.det(cov))\n\n  # Check if the logarithm of the determinant is finite, and if not, set it to zero.\n  log_det = jnp.where(jnp.isfinite(log_det), log_det, 0)\n\n  # Compute the isotropic covariance matrices.\n  if mode == 'fast':\n    iso_cov = jnp.exp(log_det / 3) * jnp.eye(cov.shape[-1])\n  elif mode == 'accurate':\n    iso_cov = jnp.exp(log_det / 6) * jnp.eye(cov.shape[-1])\n  else:\n    raise ValueError(f'Invalid mode {mode}')\n\n  return iso_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n    if det < 0:\n      raise ValueError('Determinant of covariance matrix must be non-negative.')\n    d = jnp.sqrt(det)\n    return cov / d\n  elif mode == 'accurate':\n    logdet = jnp.linalg.slogdet(cov)[1]\n    if jnp.any(logdet < 0):\n      raise ValueError('Log-determinant of covariance matrix must be non-negative.')\n    d = jnp.exp(0.5 * logdet)\n    return cov / d\n  else:\n    raise ValueError('Invalid mode.')\n\n"}
{"namespace": "coord.isotropize", "completion": "  # Check if the covariance matrix or matrices is valid.\n  if not np.all(np.linalg.eigvals(cov) > 0):\n    raise ValueError('The covariance matrix or matrices is not positive-definite.')\n\n  # Compute the determinant or logarithm of the determinant of the covariance matrix or matrices.\n  if mode == 'fast':\n    log_det = np.log(np.linalg.det(cov))\n  elif mode == 'accurate':\n    log_det = np.log(np.linalg.det(cov))\n  else:\n    raise ValueError('The mode of operation must be either \"fast\" or \"accurate\".')\n\n  # Check if the determinant or logarithm of the determinant is valid.\n  if np.any(np.isinf(log_det)):\n    raise ValueError('The determinant or logarithm of the determinant of the covariance matrix or matrices is infinite.')\n  if np.any(np.isnan(log_det)):\n    raise ValueError('The determinant or logarithm of the determinant of the covariance matrix or matrices is not a number.')\n\n  # Compute the isotropic covariance matrix or matrices.\n  iso_cov = cov * np.exp(log_det) / np.trace(cov)\n\n  return iso_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  # Compute the determinant of the covariance matrix or matrices.\n  det = jnp.linalg.det(cov)\n\n  # Compute the logarithm of the determinant of the covariance matrix or matrices.\n  log_det = jnp.log(det)\n\n  # Check if the determinant is valid.\n  if mode == 'accurate':\n    if jnp.any(det <= 0):\n      raise ValueError('Invalid determinant.')\n\n  # Check if the logarithm of the determinant is valid.\n  if mode == 'accurate':\n    if jnp.any(jnp.isnan(log_det)):\n      raise ValueError('Invalid logarithm of determinant.')\n\n  # Compute the isotropic covariance matrix or matrices.\n  if mode == 'fast':\n    isotropic_cov = jnp.ones_like(cov) * (det ** (-1 / cov.shape[-1]))\n  elif mode == 'accurate':\n    isotropic_cov = jnp.ones_like(cov) * (jnp.exp(-log_det / cov.shape[-1]))\n\n  return isotropic_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  # Compute the logarithm of the determinant\n  det_log = jnp.log(jnp.linalg.det(cov))\n\n  # Check for invalid logarithms\n  if mode == 'accurate':\n    det_log = jnp.where(jnp.isnan(det_log), 0., det_log)\n    det_log = jnp.where(det_log < -500, -500, det_log)\n\n  # Compute the isotropic covariance matrices\n  if mode == 'fast':\n    cov_iso = cov * jnp.exp(det_log / cov.shape[-1])\n  elif mode == 'accurate':\n    cov_iso = cov * jnp.exp(det_log / (cov.shape[-1] - 1))\n  else:\n    raise Exception('Invalid mode: must be \"fast\" or \"accurate\"')\n\n  return cov_iso\n\n"}
{"namespace": "coord.isotropize", "completion": "  # Check that the input covariance matrix is valid\n  if not isinstance(cov, np.ndarray):\n    raise TypeError('The input covariance matrix must be a numpy array.')\n  elif len(cov.shape) != 2:\n    raise ValueError('The input covariance matrix must be 2-dimensional.')\n  elif cov.shape[0] != cov.shape[1]:\n    raise ValueError('The input covariance matrix must be square.')\n  elif np.any(np.linalg.eigvals(cov) <= 0):\n    raise ValueError('The input covariance matrix must be positive-definite.')\n\n  # Compute the logarithm of the determinant of the covariance matrix\n  log_det = np.log(np.linalg.det(cov))\n\n  # Check that the logarithm of the determinant is valid\n  if np.isnan(log_det):\n    raise ValueError('The logarithm of the determinant of the input covariance matrix is not valid.')\n\n  # Compute the isotropic covariance matrix\n  if mode == 'fast':\n    iso_cov = cov * np.exp(log_det)\n  elif mode == 'accurate':\n    iso_cov = cov * np.exp(log_det / cov.shape[0])\n  else:\n    raise ValueError('The mode of operation must be either \"fast\" or \"accurate\".')\n\n  return iso_cov\n\n"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"Runs a task specified by the user.\")\n    parser.add_argument(\"--task\", type=str, required=True, help=\"The task description, specifying what task should be performed.\")\n    parser.add_argument(\"--upload-files\", type=str, nargs=\"*\", help=\"List of files to upload, allowing multiple files to be specified.\")\n    parser.add_argument(\"--model\", type=str, help=\"Model identifier for the task, specifying which model to use.\")\n    parser.add_argument(\"--record-dir\", type=str, help=\"Directory to record task execution logs, specifying where to save the logs.\")\n    parser.add_argument(\"--mode\", type=str, choices=[\"auto\", \"manual\"], default=\"auto\", help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\")\n    parser.add_argument(\"--quiet\", action=\"store_true\", help=\"If set, the program runs in quiet mode with minimal output.\")\n    parser.add_argument(\"--max-subtask-chain-length\", type=int, help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\")\n    parser.add_argument(\"--enable-ask-human-for-help\", action=\"store_true\", help=\"Flag to enable asking for human assistance during task execution.\")\n    parser.add_argument(\"--max-plan-refine-chain-length\", type=int, help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\")\n    parser.add_argument(\"--max-plan-tree-depth\", type=int, help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\")\n    parser.add_argument(\"--max-plan-tree-width\", type=int, help=\"Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.\")\n    parser.add_argument(\"--max-retry-times\", type=int, help=\"Maximum number of retry attempts, specifying how many times a task can be retried upon failure.\")\n    parser.add_argument(\"--config-file"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent: An agent for executing tasks.')\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', type=str, nargs='+', help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', choices=['auto', 'manual'], help='Operational mode, which can be \\'auto\\' or \\'manual\\', specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"Run a task with the specified parameters.\")\n    parser.add_argument(\"--task\", type=str, required=True, help=\"The task description, specifying what task should be performed.\")\n    parser.add_argument(\"--upload-files\", type=str, nargs=\"*\", help=\"List of files to upload, allowing multiple files to be specified.\")\n    parser.add_argument(\"--model\", type=str, help=\"Model identifier for the task, specifying which model to use.\")\n    parser.add_argument(\"--record-dir\", type=str, help=\"Directory to record task execution logs, specifying where to save the logs.\")\n    parser.add_argument(\"--mode\", type=str, default=\"auto\", help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\")\n    parser.add_argument(\"--quiet\", action=\"store_true\", help=\"If set, the program runs in quiet mode with minimal output.\")\n    parser.add_argument(\"--max-subtask-chain-length\", type=int, help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\")\n    parser.add_argument(\"--enable-ask-human-for-help\", action=\"store_true\", help=\"Flag to enable asking for human assistance during task execution.\")\n    parser.add_argument(\"--max-plan-refine-chain-length\", type=int, help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\")\n    parser.add_argument(\"--max-plan-tree-depth\", type=int, help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\")\n    parser.add_argument(\"--max-plan-tree-width\", type=int, help=\"Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.\")\n    parser.add_argument(\"--max-retry-times\", type=int, help=\"Maximum number of retry attempts, specifying how many times a task can be retried upon failure.\")\n    parser.add_argument(\"--config-file\", type=str, default=os."}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"Run a task.\")\n    parser.add_argument(\"--task\", type=str, required=True, help=\"The task description, specifying what task should be performed.\")\n    parser.add_argument(\"--upload-files\", type=str, nargs=\"+\", default=[], help=\"List of files to upload, allowing multiple files to be specified.\")\n    parser.add_argument(\"--model\", type=str, default=None, help=\"Model identifier for the task, specifying which model to use.\")\n    parser.add_argument(\"--record-dir\", type=str, default=None, help=\"Directory to record task execution logs, specifying where to save the logs.\")\n    parser.add_argument(\"--mode\", type=str, default=\"auto\", choices=[\"auto\", \"manual\"], help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\")\n    parser.add_argument(\"--quiet\", action=\"store_true\", default=False, help=\"If set, the program runs in quiet mode with minimal output.\")\n    parser.add_argument(\"--max-subtask-chain-length\", type=int, default=None, help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\")\n    parser.add_argument(\"--enable-ask-human-for-help\", action=\"store_true\", default=False, help=\"Flag to enable asking for human assistance during task execution.\")\n    parser.add_argument(\"--max-plan-refine-chain-length\", type=int, default=None, help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\")\n    parser.add_argument(\"--max-plan-tree-depth\", type=int, default=None, help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\")\n    parser.add_argument(\"--max-plan-tree-width\", type=int, default=None, help=\"Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.\")\n    parser.add_argument(\"--max-retry-times\", type=int, default=None, help"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"XAgent CLI\")\n\n    parser.add_argument(\"--task\", type=str, required=True, help=\"The task description, specifying what task should be performed.\")\n    parser.add_argument(\"--upload-files\", type=str, nargs='*', help=\"List of files to upload, allowing multiple files to be specified.\")\n    parser.add_argument(\"--model\", type=str, help=\"Model identifier for the task, specifying which model to use.\")\n    parser.add_argument(\"--record-dir\", type=str, help=\"Directory to record task execution logs, specifying where to save the logs.\")\n    parser.add_argument(\"--mode\", type=str, default=\"auto\", help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\")\n    parser.add_argument(\"--quiet\", action=\"store_true\", help=\"If set, the program runs in quiet mode with minimal output.\")\n    parser.add_argument(\"--max-subtask-chain-length\", type=int, help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\")\n    parser.add_argument(\"--enable-ask-human-for-help\", action=\"store_true\", help=\"Flag to enable asking for human assistance during task execution.\")\n    parser.add_argument(\"--max-plan-refine-chain-length\", type=int, help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\")\n    parser.add_argument(\"--max-plan-tree-depth\", type=int, help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\")\n    parser.add_argument(\"--max-plan-tree-width\", type=int, help=\"Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.\")\n    parser.add_argument(\"--max-retry-times\", type=int, help=\"Maximum number of retry attempts, specifying how many times a task can be retried upon failure.\")\n    parser.add_argument(\"--config-file\", type=str, default=os.environ.get"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"Run the XAgent program.\")\n\n    parser.add_argument(\"--task\", required=True, type=str, help=\"The task description, specifying what task should be performed.\")\n    parser.add_argument(\"--upload-files\", nargs=\"*\", type=str, help=\"List of files to upload, allowing multiple files to be specified.\")\n    parser.add_argument(\"--model\", type=str, help=\"Model identifier for the task, specifying which model to use.\")\n    parser.add_argument(\"--record-dir\", type=str, help=\"Directory to record task execution logs, specifying where to save the logs.\")\n    parser.add_argument(\"--mode\", type=str, choices=[\"auto\", \"manual\"], default=\"auto\", help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\")\n    parser.add_argument(\"--quiet\", action=\"store_true\", help=\"If set, the program runs in quiet mode with minimal output.\")\n    parser.add_argument(\"--max-subtask-chain-length\", type=int, help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\")\n    parser.add_argument(\"--enable-ask-human-for-help\", action=\"store_true\", help=\"Flag to enable asking for human assistance during task execution.\")\n    parser.add_argument(\"--max-plan-refine-chain-length\", type=int, help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\")\n    parser.add_argument(\"--max-plan-tree-depth\", type=int, help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\")\n    parser.add_argument(\"--max-plan-tree-width\", type=int, help=\"Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.\")\n    parser.add_argument(\"--max-retry-times\", type=int, help=\"Maximum number of retry attempts, specifying how many times a task can be retried upon failure.\")\n    parser.add_argument(\"--config-file\", type"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='Command line interface for XAgent.')\n    parser.add_argument('--task', required=True, type=str, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', nargs='+', type=str, help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', help='Operational mode, which can be \\'auto\\' or \\'manual\\', specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent: An AI-powered agent to assist with task execution.')\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', type=str, nargs='+', help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', choices=['auto', 'manual'], help='Operational mode, which can be \\'auto\\' or \\'manual\\', specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"XAgent - An Automation Agent\")\n    parser.add_argument(\"--task\", type=str, required=True, help=\"The task description, specifying what task should be performed.\")\n    parser.add_argument(\"--upload-files\", type=str, nargs=\"+\", help=\"List of files to upload, allowing multiple files to be specified.\")\n    parser.add_argument(\"--model\", type=str, help=\"Model identifier for the task, specifying which model to use.\")\n    parser.add_argument(\"--record-dir\", type=str, help=\"Directory to record task execution logs, specifying where to save the logs.\")\n    parser.add_argument(\"--mode\", type=str, default=\"auto\", help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\")\n    parser.add_argument(\"--quiet\", action=\"store_true\", help=\"If set, the program runs in quiet mode with minimal output.\")\n    parser.add_argument(\"--max-subtask-chain-length\", type=int, help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\")\n    parser.add_argument(\"--enable-ask-human-for-help\", action=\"store_true\", help=\"Flag to enable asking for human assistance during task execution.\")\n    parser.add_argument(\"--max-plan-refine-chain-length\", type=int, help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\")\n    parser.add_argument(\"--max-plan-tree-depth\", type=int, help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\")\n    parser.add_argument(\"--max-plan-tree-width\", type=int, help=\"Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.\")\n    parser.add_argument(\"--max-retry-times\", type=int, help=\"Maximum number of retry attempts, specifying how many times a task can be retried upon failure.\")\n    parser.add_argument(\"--config-file\", type=str, default=os."}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(\n        description=\"XAgent - An AI Agent for XWorld Tasks\"\n    )\n    parser.add_argument(\n        \"--task\",\n        type=str,\n        required=True,\n        help=\"The task description, specifying what task should be performed.\",\n    )\n    parser.add_argument(\n        \"--upload-files\",\n        type=str,\n        nargs=\"+\",\n        help=\"List of files to upload, allowing multiple files to be specified.\",\n    )\n    parser.add_argument(\n        \"--model\",\n        type=str,\n        help=\"Model identifier for the task, specifying which model to use.\",\n    )\n    parser.add_argument(\n        \"--record-dir\",\n        type=str,\n        help=\"Directory to record task execution logs, specifying where to save the logs.\",\n    )\n    parser.add_argument(\n        \"--mode\",\n        type=str,\n        default=\"auto\",\n        choices=[\"auto\", \"manual\"],\n        help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\",\n    )\n    parser.add_argument(\n        \"--quiet\",\n        action=\"store_true\",\n        help=\"If set, the program runs in quiet mode with minimal output.\",\n    )\n    parser.add_argument(\n        \"--max-subtask-chain-length\",\n        type=int,\n        help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\",\n    )\n    parser.add_argument(\n        \"--enable-ask-human-for-help\",\n        action=\"store_true\",\n        help=\"Flag to enable asking for human assistance during task execution.\",\n    )\n    parser.add_argument(\n        \"--max-plan-refine-chain-length\",\n        type=int,\n        help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\",\n    )\n    parser.add_argument(\n        \"--max-plan-tree-depth\",\n        type=int,\n        help=\"Maximum"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"Runs a task specified by the user.\")\n\n    parser.add_argument(\"--task\", required=True, type=str, help=\"The task description, specifying what task should be performed.\")\n    parser.add_argument(\"--upload-files\", type=str, nargs=\"+\", help=\"List of files to upload, allowing multiple files to be specified.\")\n    parser.add_argument(\"--model\", type=str, help=\"Model identifier for the task, specifying which model to use.\")\n    parser.add_argument(\"--record-dir\", type=str, help=\"Directory to record task execution logs, specifying where to save the logs.\")\n    parser.add_argument(\"--mode\", type=str, default=\"auto\", help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\")\n    parser.add_argument(\"--quiet\", action=\"store_true\", help=\"If set, the program runs in quiet mode with minimal output.\")\n    parser.add_argument(\"--max-subtask-chain-length\", type=int, help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\")\n    parser.add_argument(\"--enable-ask-human-for-help\", action=\"store_true\", help=\"Flag to enable asking for human assistance during task execution.\")\n    parser.add_argument(\"--max-plan-refine-chain-length\", type=int, help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\")\n    parser.add_argument(\"--max-plan-tree-depth\", type=int, help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\")\n    parser.add_argument(\"--max-plan-tree-width\", type=int, help=\"Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.\")\n    parser.add_argument(\"--max-retry-times\", type=int, help=\"Maximum number of retry attempts, specifying how many times a task can be retried upon failure.\")\n    parser.add_argument(\"--config-file\", type=str, default="}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"XAgent: An Open-Source Framework for Executing Multi-Agent Tasks\")\n\n    parser.add_argument(\"--task\", type=str, required=True, help=\"Task description, specifying what task should be performed.\")\n    parser.add_argument(\"--upload-files\", type=str, nargs=\"*\", help=\"List of files to upload, allowing multiple files to be specified.\")\n    parser.add_argument(\"--model\", type=str, help=\"Model identifier for the task, specifying which model to use.\")\n    parser.add_argument(\"--record-dir\", type=str, help=\"Directory to record task execution logs, specifying where to save the logs.\")\n    parser.add_argument(\"--mode\", type=str, default=\"auto\", choices=[\"auto\", \"manual\"], help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\")\n    parser.add_argument(\"--quiet\", action=\"store_true\", help=\"Flag to enable quiet mode with minimal output.\")\n    parser.add_argument(\"--max-subtask-chain-length\", type=int, help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\")\n    parser.add_argument(\"--enable-ask-human-for-help\", action=\"store_true\", help=\"Flag to enable asking for human assistance during task execution.\")\n    parser.add_argument(\"--max-plan-refine-chain-length\", type=int, help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\")\n    parser.add_argument(\"--max-plan-tree-depth\", type=int, help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\")\n    parser.add_argument(\"--max-plan-tree-width\", type=int, help=\"Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.\")\n    parser.add_argument(\"--max-retry-times\", type=int, help=\"Maximum number of retry attempts, specifying how many times a task can be retried upon failure.\")\n    parser.add_argument(\""}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(\n        description=\"XAgent is a command line tool for executing automated tasks.\"\n    )\n\n    parser.add_argument(\n        \"--task\",\n        type=str,\n        required=True,\n        help=\"Task description, specifying what task should be performed.\",\n    )\n\n    parser.add_argument(\n        \"--upload-files\",\n        type=str,\n        nargs=\"+\",\n        default=[],\n        help=\"List of files to upload, allowing multiple files to be specified.\",\n    )\n\n    parser.add_argument(\n        \"--model\",\n        type=str,\n        default=None,\n        help=\"Model identifier for the task, specifying which model to use.\",\n    )\n\n    parser.add_argument(\n        \"--record-dir\",\n        type=str,\n        default=None,\n        help=\"Directory to record task execution logs, specifying where to save the logs.\",\n    )\n\n    parser.add_argument(\n        \"--mode\",\n        type=str,\n        default=\"auto\",\n        choices=[\"auto\", \"manual\"],\n        help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\",\n    )\n\n    parser.add_argument(\n        \"--quiet\",\n        action=\"store_true\",\n        help=\"If set, the program runs in quiet mode with minimal output.\",\n    )\n\n    parser.add_argument(\n        \"--max-subtask-chain-length\",\n        type=int,\n        default=None,\n        help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\",\n    )\n\n    parser.add_argument(\n        \"--enable-ask-human-for-help\",\n        action=\"store_true\",\n        help=\"Flag to enable asking for human assistance during task execution.\",\n    )\n\n    parser.add_argument(\n        \"--max-plan-refine-chain-length\",\n        type=int,\n        default=None,\n        help=\"Maximum length of plan refinement chain, specifying the limit for refining"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(\n        description=\"XAgent is a lightweight and extensible agent for executing autonomous tasks in a distributed system.\"\n    )\n\n    parser.add_argument(\n        \"--task\",\n        type=str,\n        required=True,\n        help=\"The task description, specifying what task should be performed.\",\n    )\n\n    parser.add_argument(\n        \"--upload-files\",\n        type=str,\n        nargs=\"+\",\n        help=\"List of files to upload, allowing multiple files to be specified.\",\n    )\n\n    parser.add_argument(\n        \"--model\",\n        type=str,\n        help=\"Model identifier for the task, specifying which model to use.\",\n    )\n\n    parser.add_argument(\n        \"--record-dir\",\n        type=str,\n        help=\"Directory to record task execution logs, specifying where to save the logs.\",\n    )\n\n    parser.add_argument(\n        \"--mode\",\n        type=str,\n        default=\"auto\",\n        choices=[\"auto\", \"manual\"],\n        help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\",\n    )\n\n    parser.add_argument(\n        \"--quiet\",\n        action=\"store_true\",\n        help=\"If set, the program runs in quiet mode with minimal output.\",\n    )\n\n    parser.add_argument(\n        \"--max-subtask-chain-length\",\n        type=int,\n        help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\",\n    )\n\n    parser.add_argument(\n        \"--enable-ask-human-for-help\",\n        action=\"store_true\",\n        help=\"Flag to enable asking for human assistance during task execution.\",\n    )\n\n    parser.add_argument(\n        \"--max-plan-refine-chain-length\",\n        type=int,\n        help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\",\n    )\n\n    parser.add_argument(\n        \"--max-plan"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='Run the XAgent system.')\n    parser.add_argument('--task', required=True, type=str, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', nargs='*', help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', help='Operational mode, which can be \\'auto\\' or \\'manual\\', specifying how the task should be executed.', default='auto')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', help='Path to the configuration file, specifying where"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(\n        description=\"XAgent: An AI-Based Agent for XAI Debugging\",\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n    )\n\n    parser.add_argument(\n        \"--task\",\n        type=str,\n        required=True,\n        help=\"The task description, specifying what task should be performed.\",\n    )\n    parser.add_argument(\n        \"--upload-files\",\n        type=str,\n        nargs=\"+\",\n        help=\"List of files to upload, allowing multiple files to be specified.\",\n    )\n    parser.add_argument(\n        \"--model\",\n        type=str,\n        help=\"Model identifier for the task, specifying which model to use.\",\n    )\n    parser.add_argument(\n        \"--record-dir\",\n        type=str,\n        help=\"Directory to record task execution logs, specifying where to save the logs.\",\n    )\n    parser.add_argument(\n        \"--mode\",\n        type=str,\n        default=\"auto\",\n        choices=[\"auto\", \"manual\"],\n        help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\",\n    )\n    parser.add_argument(\n        \"--quiet\",\n        action=\"store_true\",\n        help=\"If set, the program runs in quiet mode with minimal output.\",\n    )\n    parser.add_argument(\n        \"--max-subtask-chain-length\",\n        type=int,\n        help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\",\n    )\n    parser.add_argument(\n        \"--enable-ask-human-for-help\",\n        action=\"store_true\",\n        help=\"Flag to enable asking for human assistance during task execution.\",\n    )\n    parser.add_argument(\n        \"--max-plan-refine-chain-length\",\n        type=int,\n        help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\",\n    )\n    parser.add_argument(\n        \"--max"}
{"namespace": "run.parse_args", "completion": "    # Initialize the argument parser\n    parser = argparse.ArgumentParser(\n        description=\"Run a task with the specified arguments.\"\n    )\n\n    # Add the command line arguments\n    parser.add_argument(\n        \"--task\",\n        type=str,\n        required=True,\n        help=\"The task description, specifying what task should be performed.\",\n    )\n    parser.add_argument(\n        \"--upload-files\",\n        type=str,\n        nargs=\"*\",\n        help=\"List of files to upload, allowing multiple files to be specified.\",\n    )\n    parser.add_argument(\n        \"--model\",\n        type=str,\n        help=\"Model identifier for the task, specifying which model to use.\",\n    )\n    parser.add_argument(\n        \"--record-dir\",\n        type=str,\n        help=\"Directory to record task execution logs, specifying where to save the logs.\",\n    )\n    parser.add_argument(\n        \"--mode\",\n        type=str,\n        default=\"auto\",\n        choices=[\"auto\", \"manual\"],\n        help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\",\n    )\n    parser.add_argument(\n        \"--quiet\",\n        action=\"store_true\",\n        help=\"If set, the program runs in quiet mode with minimal output.\",\n    )\n    parser.add_argument(\n        \"--max-subtask-chain-length\",\n        type=int,\n        help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\",\n    )\n    parser.add_argument(\n        \"--enable-ask-human-for-help\",\n        action=\"store_true\",\n        help=\"Flag to enable asking for human assistance during task execution.\",\n    )\n    parser.add_argument(\n        \"--max-plan-refine-chain-length\",\n        type=int,\n        help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\",\n    )\n    parser.add_argument(\n        \"--max-plan-tree-depth\","}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"XAgent - An AI-based Agent for eXplainable AI\")\n    parser.add_argument(\"--task\", type=str, required=True, help=\"The task description, specifying what task should be performed.\")\n    parser.add_argument(\"--upload-files\", type=str, nargs=\"+\", default=[], help=\"List of files to upload, allowing multiple files to be specified.\")\n    parser.add_argument(\"--model\", type=str, default=\"\", help=\"Model identifier for the task, specifying which model to use.\")\n    parser.add_argument(\"--record-dir\", type=str, default=\"\", help=\"Directory to record task execution logs, specifying where to save the logs.\")\n    parser.add_argument(\"--mode\", type=str, default=\"auto\", choices=[\"auto\", \"manual\"], help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\")\n    parser.add_argument(\"--quiet\", action=\"store_true\", help=\"If set, the program runs in quiet mode with minimal output.\")\n    parser.add_argument(\"--max-subtask-chain-length\", type=int, default=0, help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\")\n    parser.add_argument(\"--enable-ask-human-for-help\", action=\"store_true\", help=\"Flag to enable asking for human assistance during task execution.\")\n    parser.add_argument(\"--max-plan-refine-chain-length\", type=int, default=0, help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\")\n    parser.add_argument(\"--max-plan-tree-depth\", type=int, default=0, help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\")\n    parser.add_argument(\"--max-plan-tree-width\", type=int, default=0, help=\"Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.\")\n    parser.add_argument(\"--max-retry-times\", type=int, default="}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"Runs a task using a specified model.\")\n    parser.add_argument(\"--task\", type=str, required=True, help=\"The task description, specifying what task should be performed.\")\n    parser.add_argument(\"--upload-files\", nargs=\"+\", type=str, help=\"List of files to upload, allowing multiple files to be specified.\")\n    parser.add_argument(\"--model\", type=str, help=\"Model identifier for the task, specifying which model to use.\")\n    parser.add_argument(\"--record-dir\", type=str, help=\"Directory to record task execution logs, specifying where to save the logs.\")\n    parser.add_argument(\"--mode\", type=str, choices=[\"auto\", \"manual\"], default=\"auto\", help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\")\n    parser.add_argument(\"--quiet\", action=\"store_true\", default=False, help=\"If set, the program runs in quiet mode with minimal output.\")\n    parser.add_argument(\"--max-subtask-chain-length\", type=int, default=CONFIG.MAX_SUBTASK_CHAIN_LENGTH, help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\")\n    parser.add_argument(\"--enable-ask-human-for-help\", action=\"store_true\", default=False, help=\"Flag to enable asking for human assistance during task execution.\")\n    parser.add_argument(\"--max-plan-refine-chain-length\", type=int, default=CONFIG.MAX_PLAN_REFINE_CHAIN_LENGTH, help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\")\n    parser.add_argument(\"--max-plan-tree-depth\", type=int, default=CONFIG.MAX_PLAN_TREE_DEPTH, help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\")\n    parser.add_argument(\"--max-plan-tree-width\", type=int, default=CONFIG.MAX_PLAN_TREE_WIDTH, help=\"Maximum width"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"XAgent is a task execution agent that executes a task based on a plan.\")\n\n    parser.add_argument(\n        \"--task\",\n        type=str,\n        required=True,\n        help=\"The task description, specifying what task should be performed.\"\n    )\n    parser.add_argument(\n        \"--upload-files\",\n        nargs=\"+\",\n        default=[],\n        help=\"List of files to upload, allowing multiple files to be specified.\"\n    )\n    parser.add_argument(\n        \"--model\",\n        type=str,\n        default=\"\",\n        help=\"Model identifier for the task, specifying which model to use.\"\n    )\n    parser.add_argument(\n        \"--record-dir\",\n        type=str,\n        default=\"\",\n        help=\"Directory to record task execution logs, specifying where to save the logs.\"\n    )\n    parser.add_argument(\n        \"--mode\",\n        type=str,\n        default=\"auto\",\n        choices=[\"auto\", \"manual\"],\n        help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\"\n    )\n    parser.add_argument(\n        \"--quiet\",\n        action=\"store_true\",\n        help=\"If set, the program runs in quiet mode with minimal output.\"\n    )\n    parser.add_argument(\n        \"--max-subtask-chain-length\",\n        type=int,\n        default=ARGS[\"max_subtask_chain_length\"],\n        help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\"\n    )\n    parser.add_argument(\n        \"--enable-ask-human-for-help\",\n        action=\"store_true\",\n        help=\"Flag to enable asking for human assistance during task execution.\"\n    )\n    parser.add_argument(\n        \"--max-plan-refine-chain-length\",\n        type=int,\n        default=ARGS[\"max_plan_refine_chain_length\"],\n        help=\"Maximum length of plan refinement chain, specifying"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.ndim != 2 or v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape {v.shape}\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[-1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Expected shape {(_, 2)}, got {v.shape}.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.ndim != 2 or v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape {v.shape}\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.ndim != 2 or v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape {v.shape}\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.ndim != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Expected 2 dimensions, got {v.ndim} dimensions.\")\n\n    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Expected 2 columns, got {v.shape[1]} columns.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape {v.shape}\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.ndim != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a 2D array. Got {v.ndim}D array.\")\n\n    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Got {v.shape[1]}D points.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.ndim != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. got ndim {v.ndim}\")\n\n    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape {v.shape}\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.ndim != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. got ndim={v.ndim}.\")\n    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape={v.shape}.\")\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.ndim != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Got shape {v.shape} instead.\")\n\n    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Got shape {v.shape} instead.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[-1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Expected shape (_, 2). Got {v.shape}\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[-1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Expected shape of (*, 2), but got {v.shape}.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[-1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Expected shape of (*, 2), got {v.shape}.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[-1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Got shape {v.shape}.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if not (v.shape[1] == 2 and v.ndim == 2):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape {v.shape}\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.ndim != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. got ndim={v.ndim}.\")\n    elif v.shape[-1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape={v.shape}.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.ndim != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Expected 2D array, got {v.ndim}D array.\")\n    elif v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Expected 2D array, got {v.shape[1]}D array.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if not v.shape[1] == 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Expected shape (_, 2). Got {v.shape}.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[-1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Got {v.shape}.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[-1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Got shape {v.shape}.\")\n\n    return v\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    char_set = string.ascii_lowercase + string.digits + '_'\n    if n < 63:\n        return char_set[n]\n    else:\n        return encode_int(n // 63) + char_set[n % 63]\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # Define the character set for encoding\n    char_set = string.ascii_lowercase + string.digits + '_'\n\n    # Encode the integer\n    if n < 0:\n        raise ValueError('The integer to be encoded must be non-negative.')\n    elif n < len(char_set):\n        return char_set[n]\n    else:\n        return encode_int(n // len(char_set)) + char_set[n % len(char_set)]\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # Define the character set for encoding\n    character_set = string.ascii_lowercase + string.digits + '_'\n\n    if n < len(character_set):\n        return character_set[n]\n    else:\n        return encode_int(n // len(character_set)) + character_set[n % len(character_set)]\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    char_set = string.ascii_lowercase + string.digits + '_'\n    if n < len(char_set):\n        return char_set[n]\n    else:\n        return encode_int(n // len(char_set)) + char_set[n % len(char_set)]\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + \"_\"\n    if n < len(character_set):\n        return character_set[n]\n    else:\n        raise ValueError(\"Integer is out of range for this encoding.\")\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # Define the character set for encoding\n    char_set = string.ascii_lowercase + string.digits + '_'\n    if n < 0:\n        raise ValueError('Cannot encode negative numbers.')\n    if n < len(char_set):\n        return char_set[n]\n    else:\n        return encode_int(n // len(char_set)) + char_set[n % len(char_set)]\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    char_set = string.ascii_lowercase + string.digits + '_'\n    return char_set[n]\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    if n < 10:\n        return chr(97+n)\n    if n < 36:\n        return str(n-10)\n    return chr(97+n-36)\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # Define the character set for encoding\n    char_set = string.ascii_lowercase + string.digits + '_'\n    # Check if the integer is positive or negative\n    if n < 0:\n        # If negative, add the length of the character set to the integer\n        n += len(char_set)\n    # Return the character corresponding to the integer\n    return char_set[n]\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # Define the character set for encoding\n    character_set = string.ascii_lowercase + string.digits + '_'\n    # Check if the input integer is valid\n    if n < 0 or n >= len(character_set):\n        raise ValueError('The input integer is not valid. It is outside the range of the character set.')\n    return character_set[n]\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # Define the character set for encoding\n    char_set = string.ascii_lowercase + string.digits + '_'\n    # If the integer is less than the length of the character set, return the character at that index\n    if n < len(char_set):\n        return char_set[n]\n    # Otherwise, return the encoded character using the remainder after dividing by the length of the character set\n    else:\n        return encode_int(n // len(char_set)) + char_set[n % len(char_set)]\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # Define the character set for encoding\n    char_set = string.ascii_lowercase + string.digits + '_'\n    # Encode the integer into a character\n    return char_set[n]\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + '_'\n    if n < len(character_set):\n        return character_set[n]\n    else:\n        return encode_int(n // len(character_set)) + character_set[n % len(character_set)]\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # Define the character set for encoding\n    char_set = string.ascii_lowercase + string.digits + '_'\n    char_set_len = len(char_set)\n\n    # Check if the input integer is positive\n    if n >= 0:\n        # Convert the integer to string\n        n = str(n)\n\n        # Check if the input integer is 0\n        if n == '0':\n            # Return the first character in the character set\n            return char_set[0]\n        else:\n            # Convert the integer to a list of characters\n            n = list(n)\n\n            # Convert the list of characters to a list of integers\n            n = [int(i) for i in n]\n\n            # Encode the list of integers\n            n = [char_set[i] for i in n]\n\n            # Return the list of encoded integers as a string\n            return ''.join(n)\n\n    # Check if the input integer is negative\n    else:\n        # Convert the integer to string\n        n = str(n)\n\n        # Check if the input integer is -1\n        if n == '-1':\n            # Return the last character in the character set\n            return char_set[-1]\n        else:\n            # Convert the integer to a list of characters\n            n = list(n)\n\n            # Convert the list of characters to a list of integers\n            n = [int(i) for i in n]\n\n            # Encode the list of integers\n            n = [char_set[i] for i in n]\n\n            # Return the list of encoded integers as a string\n            return ''.join(n)\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # Define the character set for encoding\n    char_set = string.ascii_lowercase + string.digits + '_'\n\n    # Check if the input integer is zero\n    if n == 0:\n        return char_set[0]\n\n    # Initialize the result\n    result = ''\n\n    # Check if the integer is negative\n    if n < 0:\n        # If so, make it positive\n        n = -n\n\n        # Add a negative sign\n        result += '-'\n\n    # Keep a copy of the original integer\n    original_n = n\n\n    # Keep dividing by the length of the character set\n    while n > 0:\n        n = n // len(char_set)\n        remainder = n % len(char_set)\n\n        # Add the remainder to the result\n        result += char_set[remainder]\n\n    # If the result is longer than 12, raise an exception\n    if len(result) > 12:\n        raise ValueError(f'The integer {original_n} cannot be encoded.')\n\n    # Reverse the result\n    result = result[::-1]\n\n    # Return the result\n    return result\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # Define the character set for encoding\n    character_set = string.ascii_lowercase + string.digits + \"_\"\n\n    # Check if the integer is in the range of the character set\n    if n < len(character_set):\n        return character_set[n]\n    else:\n        # If the integer is too large, divide it by the size of the character set and recursively call the function\n        return encode_int(n // len(character_set)) + character_set[n % len(character_set)]\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    char_set = string.ascii_lowercase + string.digits + \"_\"\n    if n < 63:\n        return char_set[n]\n    else:\n        raise ValueError(\"Integer value is too large to be encoded\")\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # Define the character set for encoding\n    char_set = string.ascii_lowercase + string.digits + '_'\n\n    # Encode the integer\n    if n < 0:\n        raise ValueError('Only non-negative integers can be encoded.')\n    elif n < len(char_set):\n        return char_set[n]\n    else:\n        return encode_int(n // len(char_set)) + char_set[n % len(char_set)]\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # Define the character set for encoding\n    char_set = string.ascii_lowercase + string.digits + '_'\n\n    # If the integer is 0, return the first character in the set\n    if n == 0:\n        return char_set[0]\n\n    # Create an empty string for storing the encoded value\n    encoded_str = ''\n\n    # While the integer is not 0\n    while n > 0:\n        # Find the remainder of the division of the integer by the length of the character set\n        rem = n % len(char_set)\n        # Add the character at the index rem to the string\n        encoded_str += char_set[rem]\n        # Divide the integer by the length of the character set\n        n = n // len(char_set)\n\n    # Return the encoded string in reverse order\n    return encoded_str[::-1]\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # Define the character set for encoding\n    char_set = string.ascii_lowercase + string.digits + '_'\n\n    # If the integer is 0, return the first character in the character set\n    if n == 0:\n        return char_set[0]\n\n    # Create an empty string for storing the result\n    result = ''\n\n    # While the integer is greater than 0, divide by 36 and update the result\n    while n > 0:\n        n, remainder = divmod(n, 36)\n        result = char_set[remainder] + result\n\n    # Return the result\n    return result\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  return jnp.log(jnp.where(x > eps, x, jnp.full_like(x, value_at_zero)))\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  return jnp.log(jnp.where(x > eps, x, jnp.full_like(x, value_at_zero)))\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  return jnp.log(jnp.where(x > eps, x, jnp.full_like(x, value_at_zero)))\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  return jnp.log(jnp.where(x > eps, x, jnp.full_like(x, value_at_zero)))\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  return jnp.log(jnp.where(x > eps, x, jnp.full_like(x, value_at_zero)))\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  return jnp.log(jnp.where(x <= eps, value_at_zero, x))\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  return jnp.log(jnp.where(x > eps, x, jnp.full_like(x, value_at_zero)))\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  return jnp.log(jnp.where(x < eps, value_at_zero, x))\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  return jnp.log(jnp.where(x > eps, x, jnp.full_like(x, value_at_zero)))\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  return jnp.log(jnp.where(x > eps, x, jnp.full_like(x, value_at_zero)))\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  return jnp.log(jnp.clip(x, eps, value_at_zero))\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  return jnp.log(jnp.where(x > eps, x, jnp.full_like(x, value_at_zero)))\n\n"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    workers_chunks = {}\n    for worker_idx, intervals in workers_intervals.items():\n        chunk_index = 0\n        for interval in intervals:\n            if indexes[worker_idx] >= interval[0] and indexes[worker_idx] < interval[1]:\n                break\n            chunk_index += 1\n        workers_chunks[worker_idx] = chunk_index\n\n    return workers_chunks, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    workers_chunks = {}\n    for worker_idx, worker_intervals in workers_intervals.items():\n        chunk_index = 0\n        for interval in worker_intervals:\n            if indexes[worker_idx] >= interval[0] and indexes[worker_idx] < interval[1]:\n                break\n            chunk_index += 1\n        workers_chunks[worker_idx] = chunk_index\n        indexes[worker_idx] -= interval[0]\n    return workers_chunks, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx in indexes:\n        chunk_index = 0\n        while indexes[worker_idx] >= workers_intervals[worker_idx][chunk_index][1]:\n            indexes[worker_idx] -= workers_intervals[worker_idx][chunk_index][1]\n            chunk_index += 1\n            if chunk_index == len(workers_intervals[worker_idx]):\n                break\n        chunks_index[worker_idx] = chunk_index\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunk_indexes = {}\n    for worker_idx, worker_intervals in workers_intervals.items():\n        chunk_index = 0\n        for interval in worker_intervals:\n            if indexes[worker_idx] < interval[0]:\n                break\n            chunk_index += 1\n            indexes[worker_idx] -= interval[0]\n            if indexes[worker_idx] > interval[1]:\n                indexes[worker_idx] = interval[1]\n        chunk_indexes[worker_idx] = chunk_index\n\n    return chunk_indexes, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx in indexes:\n        if indexes[worker_idx] == workers_intervals[worker_idx][0][1]:\n            chunks_index[worker_idx] = 1\n            indexes[worker_idx] = 0\n        else:\n            chunks_index[worker_idx] = 0\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx in indexes:\n        if indexes[worker_idx] >= workers_intervals[worker_idx][-1][-1]:\n            chunks_index[worker_idx] = len(workers_intervals[worker_idx]) - 1\n        else:\n            for i, interval in enumerate(workers_intervals[worker_idx]):\n                if indexes[worker_idx] < interval[-1]:\n                    chunks_index[worker_idx] = i\n                    break\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx, worker_intervals in workers_intervals.items():\n        chunk_index = 0\n        for interval in worker_intervals:\n            if indexes[worker_idx] < interval[0]:\n                break\n            elif interval[0] <= indexes[worker_idx] < interval[1]:\n                break\n            else:\n                chunk_index += 1\n                indexes[worker_idx] -= interval[1]\n        chunks_index[worker_idx] = chunk_index\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    workers_chunks = {}\n    for worker_idx, intervals in workers_intervals.items():\n        chunk_index = 0\n        for interval in intervals:\n            if indexes[worker_idx] < interval[0]:\n                break\n            indexes[worker_idx] -= interval[0]\n            chunk_index += 1\n        workers_chunks[worker_idx] = chunk_index\n    return workers_chunks, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx, worker_intervals in workers_intervals.items():\n        for interval in worker_intervals:\n            if indexes[worker_idx] < interval[0]:\n                break\n            elif indexes[worker_idx] >= interval[0] and indexes[worker_idx] < interval[1]:\n                chunks_index[worker_idx] = worker_intervals.index(interval)\n                indexes[worker_idx] = indexes[worker_idx] - interval[0]\n                break\n            elif indexes[worker_idx] >= interval[1]:\n                chunks_index[worker_idx] = worker_intervals.index(interval) + 1\n                indexes[worker_idx] = indexes[worker_idx] - interval[0]\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    # replay the chunks\n    chunks_index = {}\n    for worker_idx in range(len(workers_intervals)):\n        interval = workers_intervals[worker_idx][indexes[worker_idx]]\n        indexes[worker_idx] += 1\n        chunks_index[worker_idx] = interval[0]\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx in indexes:\n        interval_index = 0\n        while indexes[worker_idx] >= workers_intervals[worker_idx][interval_index][1]:\n            indexes[worker_idx] -= workers_intervals[worker_idx][interval_index][1]\n            interval_index += 1\n            if interval_index >= len(workers_intervals[worker_idx]):\n                break\n        chunks_index[worker_idx] = interval_index\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx in indexes.keys():\n        interval_index = 0\n        while interval_index < len(workers_intervals[worker_idx]) and indexes[worker_idx] >= workers_intervals[worker_idx][interval_index][-1]:\n            indexes[worker_idx] -= workers_intervals[worker_idx][interval_index][-1]\n            interval_index += 1\n        chunks_index[worker_idx] = interval_index\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx, worker_intervals in workers_intervals.items():\n        for interval in worker_intervals:\n            if indexes[worker_idx] < interval[0]:\n                break\n            if indexes[worker_idx] >= interval[0] and indexes[worker_idx] < interval[1]:\n                chunks_index[worker_idx] = interval[1] - interval[0]\n                indexes[worker_idx] = interval[1]\n                break\n            chunks_index[worker_idx] = interval[1] - interval[0]\n            indexes[worker_idx] = interval[1]\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx, intervals in workers_intervals.items():\n        for i, interval in enumerate(intervals):\n            if indexes[worker_idx] < interval[0]:\n                chunks_index[worker_idx] = i - 1\n                break\n            if i == len(intervals) - 1:\n                chunks_index[worker_idx] = i\n                break\n            if indexes[worker_idx] < interval[1]:\n                chunks_index[worker_idx] = i\n                break\n            indexes[worker_idx] -= interval[1] - interval[0]\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunk_indexes = {}\n    for worker_idx in range(len(workers_intervals)):\n        if len(workers_intervals[worker_idx]) == 0:\n            chunk_indexes[worker_idx] = 0\n        else:\n            chunk_indexes[worker_idx] = 0\n            for i, interval in enumerate(workers_intervals[worker_idx]):\n                if indexes[worker_idx] >= interval[0] and indexes[worker_idx] < interval[1]:\n                    chunk_indexes[worker_idx] = i\n                    break\n                indexes[worker_idx] -= interval[1] - interval[0]\n\n    return chunk_indexes, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx in indexes.keys():\n        interval_index = 0\n        interval = workers_intervals[worker_idx][interval_index]\n        chunk_index = 0\n        while interval[0] <= indexes[worker_idx] < interval[1]:\n            chunk_index += 1\n            if interval_index == len(workers_intervals[worker_idx]) - 1:\n                break\n            interval_index += 1\n            interval = workers_intervals[worker_idx][interval_index]\n        chunks_index[worker_idx] = chunk_index\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunk_indexes = {}\n    for worker_idx in indexes.keys():\n        chunk_indexes[worker_idx] = 0\n\n    current_indexes = {}\n    for worker_idx in indexes.keys():\n        current_indexes[worker_idx] = 0\n\n    for worker_idx in indexes.keys():\n        interval = workers_intervals[worker_idx][chunk_indexes[worker_idx]]\n        if interval[1] - interval[0] > indexes[worker_idx]:\n            current_indexes[worker_idx] = indexes[worker_idx]\n        else:\n            current_indexes[worker_idx] = indexes[worker_idx] - interval[0]\n            chunk_indexes[worker_idx] += 1\n\n    return chunk_indexes, current_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunk_indexes = {}\n    for worker_idx in range(len(workers_intervals)):\n        interval = workers_intervals[worker_idx][0]\n        chunk_indexes[worker_idx] = 0\n        if interval[0] <= indexes[worker_idx] < interval[-1]:\n            chunk_indexes[worker_idx] = 0\n        else:\n            for interval in workers_intervals[worker_idx]:\n                if interval[0] <= indexes[worker_idx] < interval[-1]:\n                    break\n                else:\n                    chunk_indexes[worker_idx] += 1\n\n    return chunk_indexes, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    # replay the chunks\n    chunks_index = {}\n    for worker_idx, worker_intervals in workers_intervals.items():\n        # get the index of the interval that contains the current index\n        interval_index = 0\n        for i, interval in enumerate(worker_intervals):\n            if interval[0] <= indexes[worker_idx] < interval[1]:\n                interval_index = i\n                break\n        # update the chunk index\n        chunks_index[worker_idx] = interval_index\n        # update the current index\n        indexes[worker_idx] = indexes[worker_idx] - worker_intervals[interval_index][0]\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    workers_chunks = {}\n    for worker_idx, worker_intervals in workers_intervals.items():\n        # the current index within the chunk\n        index = indexes[worker_idx]\n\n        # the current chunk index\n        chunk_index = 0\n\n        # iterate through the intervals to find the chunk index\n        for interval in worker_intervals:\n            if index < interval[0]:\n                break\n            chunk_index += 1\n            index -= interval[0]\n\n        # update the chunk index\n        workers_chunks[worker_idx] = chunk_index\n\n    return workers_chunks, indexes"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    if len(values.shape) != 4:\n      raise ValueError('Voxel grid values must be a 4D array with shape (D,H,W,C)')\n    if len(coordinates.shape) < 2:\n      raise ValueError('Voxel grid coordinates must be a 2D or higher dimensional array with shape (..., 3)')\n    if coordinates.shape[-1] != 3:\n      raise ValueError('Voxel grid coordinates must be a 2D or higher dimensional array with shape (..., 3)')\n    return _trilerp_grid(values, coordinates)\n  elif datastructure == 'hash':\n    if len(values.shape) != 2:\n      raise ValueError('Hash values must be a 2D array with shape (N,C)')\n    if len(coordinates.shape) < 2:\n      raise ValueError('Hash coordinates must be a 2D or higher dimensional array with shape (..., 3)')\n    if coordinates.shape[-1] != 3:\n      raise ValueError('Hash coordinates must be a 2D or higher dimensional array with shape (..., 3)')\n    return _trilerp_hash(values, coordinates)\n  else:\n    raise ValueError('Invalid datastructure. Must be either \"grid\" or \"hash\".')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return _trilerp_grid(values, coordinates)\n  elif datastructure == 'hash':\n    return _trilerp_hash(values, coordinates)\n  else:\n    raise ValueError(f'Invalid datastructure {datastructure} passed to trilerp.')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == \"grid\":\n    return _trilerp_grid(values, coordinates)\n  elif datastructure == \"hash\":\n    return _trilerp_hash(values, coordinates)\n  else:\n    raise ValueError(f\"Invalid datastructure {datastructure}.\")\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return _trilerp_grid(values, coordinates)\n  elif datastructure == 'hash':\n    return _trilerp_hash(values, coordinates)\n  else:\n    raise ValueError(f'Invalid datastructure {datastructure}, must be \"grid\" or \"hash\"')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return trilerp_grid(values, coordinates)\n  elif datastructure == 'hash':\n    return trilerp_hash(values, coordinates)\n  else:\n    raise ValueError(f'Invalid datastructure {datastructure}, expected \"grid\" or \"hash\".')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return _trilerp_grid(values, coordinates)\n  elif datastructure == 'hash':\n    return _trilerp_hash(values, coordinates)\n  else:\n    raise ValueError(f'Invalid datastructure {datastructure}')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return _trilerp_grid(values, coordinates)\n  elif datastructure == 'hash':\n    return _trilerp_hash(values, coordinates)\n  else:\n    raise ValueError(f'Invalid datastructure: {datastructure}')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    # Adjust coordinates to account for voxel grid offset.\n    coordinates = (coordinates + 1) * 0.5 * (values.shape[0] - 1)\n    return trilerp_grid(values, coordinates)\n  elif datastructure == 'hash':\n    # Adjust coordinates to account for hashed grid offset.\n    coordinates = (coordinates + 1) * 0.5 * (values.shape[0] - 1)\n    return trilerp_hash(values, coordinates)\n  else:\n    raise ValueError(\n        'datastructure must be either \\'grid\\' or \\'hash\\'.')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return grid_trilerp(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_trilerp(values, coordinates)\n  else:\n    raise ValueError(\n        f'Invalid datastructure {datastructure} passed to trilerp. Must be either grid or hash.'\n    )\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return _trilerp_grid(values, coordinates)\n  elif datastructure == 'hash':\n    return _trilerp_ngp(values, coordinates)\n  else:\n    raise ValueError(f\"Invalid datastructure {datastructure}, expected 'grid' or 'hash'.\")\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return _trilerp_grid(values, coordinates)\n  elif datastructure == 'hash':\n    return _trilerp_hash(values, coordinates)\n  else:\n    raise ValueError(\n        f'Invalid datastructure {datastructure} passed to trilerp. Expected grid or hash.'\n    )\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    # Adjust coordinates to account for the fact that voxel grids are defined in the range [0, D-1], [0, H-1], [0, W-1].\n    coordinates = (coordinates + 0.5) * (values.shape[0] - 1)\n\n    return trilerp_grid(values, coordinates)\n\n  elif datastructure == 'hash':\n    # Adjust coordinates to account for the fact that hashes are defined in the range [-1, 1].\n    coordinates = coordinates * 0.5 + 0.5\n\n    return trilerp_hash(values, coordinates)\n\n  else:\n    raise ValueError(f'Invalid datastructure {datastructure}.')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return _trilerp_grid(values, coordinates)\n  elif datastructure == 'hash':\n    return _trilerp_hash(values, coordinates)\n  else:\n    raise ValueError('Invalid datastructure passed to trilerp')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return trilerp_grid(values, coordinates)\n  elif datastructure == 'hash':\n    return trilerp_hash(values, coordinates)\n  else:\n    raise ValueError(f'Invalid datastructure {datastructure} passed to trilerp.')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return trilerp_grid(values, coordinates)\n  elif datastructure == 'hash':\n    return trilerp_hash(values, coordinates)\n  else:\n    raise ValueError('Invalid datastructure. Must be \"grid\" or \"hash\"')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    # Voxel grid coordinates are in range [0, D-1], [0, H-1], [0, W-1].\n    # We adjust coordinates to be in range [-0.5, D-0.5], [-0.5, H-0.5], [-0.5, W-0.5] to match the grid center positions.\n    coordinates = coordinates - 0.5\n    return resample.trilerp(values, coordinates)\n  elif datastructure == 'hash':\n    # Hash coordinates are in range [-1, 1], [-1, 1], [-1, 1].\n    # We adjust coordinates to be in range [-1.5, 1.5], [-1.5, 1.5], [-1.5, 1.5] to match the hashed grid center positions.\n    coordinates = coordinates + 1.5\n    return hash_resample.trilerp(values, coordinates)\n  else:\n    raise ValueError('Invalid datastructure')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    # Adjust coordinates to be in the range [-1, 1]\n    dims = values.shape[:3]\n    coordinates = (2 * coordinates / (onp.array(dims) - 1) - 1)\n\n    return resample.trilerp(values, coordinates)\n\n  elif datastructure == 'hash':\n    # Adjust coordinates to be in the range [0, 1]\n    coordinates = coordinates / (onp.array(datastructure.dims) - 1)\n\n    return hash_resample.trilerp(values, coordinates, datastructure)\n\n  else:\n    raise ValueError(f'Invalid datastructure {datastructure}.')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return _trilerp_grid(values, coordinates)\n  elif datastructure == 'hash':\n    return _trilerp_hash(values, coordinates)\n  else:\n    raise ValueError(f'Invalid datastructure {datastructure}')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    # Adjust the coordinates to account for the voxel grid\n    coordinates = (coordinates + 1) * 0.5 * (values.shape[0] - 1)\n    # Sample the values from the voxel grid\n    return resample.trilerp(values, coordinates)\n  elif datastructure == 'hash':\n    # Sample the values from the hashed data structure\n    return hash_resample.trilerp(values, coordinates)\n  else:\n    raise ValueError(f'Invalid datastructure {datastructure}.')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  # Check if the data structure is a grid or hash.\n  if datastructure == 'grid':\n    # If the data structure is a grid, we need to adjust the coordinates\n    # to account for the grid resolution.\n    coordinates = (coordinates * (values.shape[:3] - 1)).astype(jnp.int32)\n    # We then use grid sampling to get the interpolated values.\n    return resample.trilinear_interp(values, coordinates)\n  elif datastructure == 'hash':\n    # If the data structure is a hash, we do not need to adjust the\n    # coordinates.\n    return hash_resample.trilerp(values, coordinates)\n  else:\n    raise ValueError('Invalid datastructure.')\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate the integer weights for each vertex of the triangle\n  weights = np.array(list(itertools.product(range(v + 1), repeat=3)))\n\n  # Normalize the weights to get the barycentric coordinates\n  weights = weights.astype(np.float32)\n  weights[:, 0] /= v\n  weights[:, 1] /= v\n  weights[:, 2] /= v\n  weights = np.sum(weights, axis=1)\n\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate all integer weights for each vertex of the triangle\n  weights = np.array(list(itertools.product(*[range(v + 1)] * 3)))\n\n  # Normalize the weights to get the barycentric coordinates\n  weights = weights.astype(np.float)\n  weights[:, 0] /= v\n  weights[:, 1] /= v\n  weights[:, 2] /= v\n  weights = weights[weights.sum(axis=1) == 1]\n\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Compute the barycentric weights for each vertex of the triangle.\n  weights = np.array(list(itertools.product(range(v + 1), repeat=3)))\n\n  # Normalize the barycentric weights so that they sum to 1.\n  weights = weights.astype(np.float)\n  weights[:, 0] /= v\n  weights[:, 1] /= v\n  weights[:, 2] /= v\n\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate the weights for each vertex of the triangle\n  w = np.array([[v - i - j, i, j] for i in range(v) for j in range(v + 1 - i)])\n\n  # Normalize the weights so that they sum to 1\n  w = w / np.sum(w, axis=1, keepdims=True)\n\n  return w\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if v < 1:\n    raise ValueError(\"Tessellation factor must be greater than or equal to 1.\")\n\n  # Generate the weights for each vertex of the triangle\n  weights = np.array(list(itertools.product(range(v + 1), repeat=3)))\n\n  # Normalize the weights so that they sum to 1\n  weights = weights / np.sum(weights, axis=1, keepdims=True)\n\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Compute the weights for each vertex of the triangle.\n  weights = np.array(list(itertools.product(range(v + 1), repeat=3)))\n\n  # Normalize the weights to get barycentric coordinates.\n  weights = weights.astype(float)\n  weights[:, 0] /= v\n  weights[:, 1] /= v\n  weights[:, 2] /= v\n\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate the integer weights for each vertex of the triangle.\n  w = np.array(list(itertools.product(range(v + 1), repeat=3)))\n\n  # Normalize the weights to get the barycentric coordinates.\n  w = w.astype(float)\n  w[:, 0] /= v\n  w[:, 1] /= v\n  w[:, 2] /= v\n\n  return w\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate the weights for the first vertex\n  weights_1 = np.zeros((v, v))\n  for i in range(v):\n    for j in range(v):\n      weights_1[i, j] = (v - i) * (v - j)\n\n  # Generate the weights for the second vertex\n  weights_2 = np.zeros((v, v))\n  for i in range(v):\n    for j in range(v):\n      weights_2[i, j] = i * (v - j)\n\n  # Generate the weights for the third vertex\n  weights_3 = np.zeros((v, v))\n  for i in range(v):\n    for j in range(v):\n      weights_3[i, j] = i * j\n\n  # Normalize the weights\n  weights_1 = weights_1 / np.sum(weights_1, axis=0)\n  weights_2 = weights_2 / np.sum(weights_2, axis=0)\n  weights_3 = weights_3 / np.sum(weights_3, axis=0)\n\n  # Concatenate the weights\n  weights = np.concatenate((weights_1, weights_2, weights_3), axis=0)\n\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Check that the tessellation factor is greater than or equal to 1.\n  if v < 1:\n    raise ValueError(\"The tessellation factor must be greater than or equal to 1.\")\n\n  # Create the weights for the tessellation.\n  weights = np.array(list(itertools.product(range(v + 1), repeat=3)))\n  weights = weights / weights.sum(axis=1)[:, None]\n\n  # Return the weights.\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate the integer weights for each vertex of the triangle\n  weights = np.array(list(itertools.product(*[range(v + 1)] * 3)))\n  weights = weights[:, [0, 2, 1]]\n\n  # Normalize the weights to get the barycentric coordinates\n  weights = weights.astype(float)\n  weights[:, 0] /= v\n  weights[:, 1] /= v\n  weights[:, 2] /= v\n  weights[:, 0] -= 1 / v\n  weights[:, 1] -= 1 / v\n  weights[:, 2] -= 1 / v\n\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate the integer weights for each vertex of the triangle.\n  weights = np.array(list(itertools.product(range(v + 1), repeat=3)))\n\n  # Normalize the weights to get the barycentric coordinates.\n  weights = weights.astype(np.float32)\n  weights[:, 0] /= (v * (v + 1) / 2)\n  weights[:, 1] /= (v * (v + 1) / 2)\n  weights[:, 2] = 1 - weights[:, 0] - weights[:, 1]\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate the weights for each vertex of the triangle.\n  weights = np.array(list(itertools.product(range(v + 1), repeat=3)))\n  weights = weights[weights[:, 0] + weights[:, 1] + weights[:, 2] == v]\n\n  # Normalize the weights to get the barycentric coordinates.\n  weights = weights.astype(np.float32)\n  weights[:, 0] /= v\n  weights[:, 1] /= v\n  weights[:, 2] /= v\n\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Compute the barycentric weights for the tessellated triangle.\n  weights = np.array(list(itertools.product(*[range(v + 1)] * 3)))\n  weights = weights.reshape((-1, 3))\n  weights = weights / np.sum(weights, axis=1, keepdims=True)\n\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate the barycentric weights for the tessellated triangle.\n  weights = np.array([[v - i - j, i, j] for i in range(v) for j in range(v + 1 - i)])\n  # Normalize the barycentric weights.\n  weights = weights / np.sum(weights, axis=1, keepdims=True)\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate the integer weights for each vertex of the triangle.\n  weights = np.array(list(itertools.product(range(v + 1), repeat=3)))\n  weights = weights[weights[:, 0] + weights[:, 1] + weights[:, 2] == v, :]\n\n  # Normalize the weights to get the barycentric coordinates.\n  weights = weights.astype(np.float32)\n  weights[:, 0] /= v\n  weights[:, 1] /= v\n  weights[:, 2] /= v\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if v < 1:\n    raise ValueError('The tessellation factor must be greater than or equal to 1.')\n\n  # Generate the weights for the first vertex\n  weights = np.array([v, 1, 0])\n  weights = np.stack([weights] * v, axis=0)\n\n  # Generate the weights for the second vertex\n  for i in range(1, v):\n    weights[i, 0] = v - i\n    weights[i, 1] = i\n\n  # Generate the weights for the third vertex\n  weights[v - 1, 0] = 1\n  weights[v - 1, 1] = 0\n  weights[v - 1, 2] = v\n\n  # Normalize the weights\n  weights = weights / np.sum(weights, axis=1, keepdims=True)\n\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if v < 1:\n    raise ValueError(\"Tessellation factor must be greater than or equal to 1.\")\n  if v == 1:\n    return np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n  # Generate all possible integer weights for each vertex.\n  weights = np.array(list(itertools.product(range(v+1), repeat=3)))\n  # Normalize the weights so that they sum to 1.\n  weights = weights.astype(np.float32)\n  weights = weights / np.sum(weights, axis=1)[:, None]\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if v < 1:\n    raise ValueError(\"v must be greater than or equal to 1.\")\n\n  # The number of points in the tessellated triangle.\n  n = v + 1\n\n  # Generate the integer weights for each vertex of the triangle.\n  weights = np.zeros((3, n, n))\n  weights[0, 0, 0] = 1\n  weights[1, 0, 1:] = 1\n  weights[2, 1:, 0] = 1\n  weights[0, 1:, 1:] = v\n  weights[1, 1:, 1:] = v\n  weights[2, 1:, 1:] = v\n\n  # Normalize the weights to get the barycentric coordinates.\n  weights = weights / np.sum(weights, axis=0)\n\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Compute the barycentric weights for each point in the tessellated triangle.\n  # The weights are normalized so that they sum to 1.\n  weights = np.array([[v - i - j, i, j] for i in range(v) for j in range(v - i)])\n  weights = weights / np.sum(weights, axis=1, keepdims=True)\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate the integer weights for each vertex of the triangle.\n  # The weights are arranged in a 2D array where each row is a set of weights for a single vertex.\n  weights = np.array([[i, j, v - i - j] for i, j in itertools.product(range(v + 1), range(v + 1)) if i + j <= v])\n\n  # Normalize the weights to get the barycentric coordinates.\n  weights = weights / np.sum(weights, axis=1, keepdims=True)\n\n  return weights\n\n"}
{"namespace": "linspline.query", "completion": "  # Assert the spline is valid.\n  check_zero_endpoints(v)\n\n  # Interpolate the spline.\n  return jnp.interp(tq, t, v)\n\n"}
{"namespace": "linspline.query", "completion": "  tq = jnp.asarray(tq)\n  t = jnp.asarray(t)\n  v = jnp.asarray(v)\n  checkify.check(jnp.all(t[:-1] < t[1:]), 'Time points must be strictly increasing.')\n  check_zero_endpoints(v)\n  return jnp.interp(tq, t, v, 0, 0)\n\n"}
{"namespace": "linspline.query", "completion": "  checkify.check(v.shape[-1] == t.shape[-1] - 1, 'Number of time points (t) must be one more than the number of values (v).')\n\n  check_zero_endpoints(v)\n\n  return jnp.interp(tq, t, v)\n\n"}
{"namespace": "linspline.query", "completion": "  # TODO: Add check for tq, t, v all being array-like.\n\n  # TODO: Add check for tq, t, v all having the same number of dimensions.\n\n  # TODO: Add check for tq, t, v all having the same shape in all dimensions except the last.\n\n  # TODO: Add check for tq, t, v all having at least 2 elements in the last dimension.\n\n  # TODO: Add check for tq, t, v all having the same dtype.\n\n  # TODO: Add check for tq, t, v all being finite.\n\n  # TODO: Add check for tq, t, v all being sorted in ascending order.\n\n  # TODO: Add check for tq, t, v all being strictly increasing.\n\n  # TODO: Add check for tq, t, v all being strictly positive.\n\n  # TODO: Add check for tq, t, v all having the same shape.\n\n  # TODO: Add check for tq, t, v all having the same dtype.\n\n  # TODO: Add check for tq, t, v all being finite.\n\n  # TODO: Add check for tq, t, v all being strictly increasing.\n\n  # TODO: Add check for tq, t, v all being strictly positive.\n\n  # TODO: Add check for tq, t, v all having the same shape.\n\n  # TODO: Add check for tq, t, v all having the same dtype.\n\n  # TODO: Add check for tq, t, v all being finite.\n\n  # TODO: Add check for tq, t, v all being strictly increasing.\n\n  # TODO: Add check for tq, t, v all being strictly positive.\n\n  # TODO: Add check for tq, t, v all having the same shape.\n\n  # TODO: Add check for tq, t, v all having the same dtype.\n\n  # TODO: Add check for tq, t, v all being finite.\n\n  # TODO: Add check for tq, t, v all being strictly increasing.\n\n  # TODO: Add check for tq, t, v all being"}
{"namespace": "linspline.query", "completion": "  checkify.check(v.ndim == 2, message='Spline values must be two-dimensional.')\n  checkify.check(t.shape == (v.shape[1],), message='Spline time points must be one-dimensional.')\n  checkify.check(tq.ndim == 1, message='Query points must be one-dimensional.')\n  checkify.check(tq.shape == t.shape, message='Query points must be the same length as the time points.')\n\n  check_zero_endpoints(v)\n  checkify.check(jnp.all(t[1:] > t[:-1]), message='Time points must be strictly increasing.')\n\n  return jnp.interp(tq, t, v, left=0, right=0)\n\n"}
{"namespace": "linspline.query", "completion": "  # Ensure that the input is valid.\n  checkify.check(\n      jnp.all(t[Ellipsis, 1:] > t[Ellipsis, :-1]),\n      'The time points must be in strictly increasing order.')\n  checkify.check(\n      jnp.all(t[Ellipsis, 0] == 0),\n      'The first time point must be 0.')\n  checkify.check(\n      jnp.all(t[Ellipsis, -1] == 1),\n      'The last time point must be 1.')\n  checkify.check(\n      jnp.all(v[Ellipsis, 0] == 0),\n      'The first value must be 0.')\n  checkify.check(\n      jnp.all(v[Ellipsis, -1] == 0),\n      'The last value must be 0.')\n\n  # Interpolate the spline.\n  tq = jnp.expand_dims(tq, -1)\n  t = jnp.expand_dims(t, -2)\n  v = jnp.expand_dims(v, -2)\n  v = jnp.expand_dims(v, -2)\n  v_interp = jnp.sum(v * (tq - t) * (1 - tq), axis=-1)\n\n  # Extrapolate outside the original range.\n  v_interp = jnp.where(tq < t[Ellipsis, 0], 0, v_interp)\n  v_interp = jnp.where(tq > t[Ellipsis, -1], 0, v_interp)\n\n  return v_interp\n\n"}
{"namespace": "linspline.query", "completion": "  # Validate the input.\n  tq = jnp.asarray(tq)\n  t = jnp.asarray(t)\n  v = jnp.asarray(v)\n  checkify.check(t.ndim == 1, 'Time points must be a 1-dimensional array.')\n  checkify.check(v.ndim == 1, 'Values must be a 1-dimensional array.')\n  checkify.check(t.shape == v.shape, 'Time points and values must have the same shape.')\n  checkify.check(jnp.all(jnp.diff(t) > 0), 'Time points must be sorted in ascending order.')\n  checkify.check(jnp.all(jnp.isfinite(tq)), 'Query points must all be finite.')\n  checkify.check(jnp.all(jnp.isfinite(t)), 'Time points must all be finite.')\n  checkify.check(jnp.all(jnp.isfinite(v)), 'Values must all be finite.')\n  check_zero_endpoints(v)\n\n  # Find the index of the first time point past each query point.\n  tq_indices = jnp.searchsorted(t, tq, side='left')\n\n  # If a query point is exactly on a time point, then return the corresponding value.\n  return jnp.where(jnp.isclose(tq, t[tq_indices]), v[tq_indices], 0)\n\n"}
{"namespace": "linspline.query", "completion": "  # Check if the spline is valid.\n  check_zero_endpoints(v)\n\n  # Find the index of the first time point in 't' that is larger than the query points.\n  t_indices = jnp.searchsorted(t, tq, side='left')\n\n  # Find the difference between the query points and the previous time point in 't'.\n  t_diffs = tq - t[t_indices - 1]\n\n  # Find the difference between the next time point in 't' and the query points.\n  t_next_diffs = t[t_indices] - tq\n\n  # Find the ratio of these two differences.\n  t_ratios = t_diffs / (t_diffs + t_next_diffs)\n\n  # Use the ratio to interpolate the value at each query point.\n  return (1 - t_ratios) * v[t_indices - 1] + t_ratios * v[t_indices]\n\n"}
{"namespace": "linspline.query", "completion": "  # Check that the time points are valid.\n  checkify.check(jnp.all(t[1:] > t[:-1]), 'Time points must be strictly increasing.')\n\n  # Check that the query points are valid.\n  checkify.check(jnp.all(tq >= t[0]), 'Query points must be greater than the first time point.')\n  checkify.check(jnp.all(tq <= t[-1]), 'Query points must be less than the last time point.')\n\n  # Check that the values are valid.\n  check_zero_endpoints(v)\n\n  # Find the query points' indices in the time points.\n  t_shape = t.shape\n  tq_shape = tq.shape\n  t = t.reshape((-1,))\n  tq = tq.reshape((-1,))\n  indices = jnp.searchsorted(t, tq, side='right') - 1\n\n  # Extract the query points' time and value indices.\n  t_indices = indices.reshape(tq_shape)\n  v_indices = jnp.concatenate([t_indices - 1, t_indices], axis=-1)\n  v_indices = jnp.clip(v_indices, 0, len(t) - 1)\n\n  # Extract the query points' time and value coordinates.\n  t_coordinates = jnp.gather(t, t_indices)\n  t_coordinates = jnp.expand_dims(tq, axis=-1) - t_coordinates\n  t_coordinates = t_coordinates.reshape(tq_shape + t_shape[1:])\n  v_coordinates = jnp.gather(v, v_indices, axis=-2)\n  v_coordinates = v_coordinates.reshape(tq_shape + t_shape[1:] * 2)\n\n  # Interpolate the query points.\n  v_coordinates = v_coordinates * jnp.expand_dims(t_coordinates, axis=-2"}
{"namespace": "linspline.query", "completion": "  # Check the input is valid.\n  checkify.check(jnp.all(t[Ellipsis, 1:] - t[Ellipsis, :-1] >= 0),\n                 'Time points must be sorted in ascending order.')\n  checkify.check(jnp.all(v[Ellipsis, 1:] >= v[Ellipsis, :-1]),\n                 'Values must be non-decreasing.')\n  check_zero_endpoints(v)\n\n  # Find the index of the first time point in 't' after each query point.\n  t_index = jnp.searchsorted(t, tq, side='right')\n\n  # If the query point is outside the range of 't', return 0.\n  out_of_range = (t_index == 0) | (t_index == len(t))\n  return jnp.where(out_of_range, 0, v[t_index - 1] + (\n      v[t_index] - v[t_index - 1]) * (tq - t[t_index - 1]) / (t[t_index] - t[t_index - 1]))\n\n"}
{"namespace": "linspline.query", "completion": "  tq = jnp.atleast_1d(tq)\n  t = jnp.atleast_1d(t)\n  v = jnp.atleast_1d(v)\n\n  checkify.check(t.ndim == 1, message='Time points must be a 1D array.')\n  checkify.check(v.ndim == 1, message='Values must be a 1D array.')\n  checkify.check(t.shape == v.shape, message='Time points and values must be the same length.')\n  checkify.check(tq.ndim == 1, message='Query points must be a 1D array.')\n  checkify.check(jnp.all(tq >= t[0]), message='Query points must be greater than or equal to the first time point.')\n  checkify.check(jnp.all(tq <= t[-1]), message='Query points must be less than or equal to the last time point.')\n\n  # Ensure the spline is valid.\n  check_zero_endpoints(v)\n  checkify.check(jnp.all(v[1:] >= v[:-1]), message='Spline values must be monotonically increasing.')\n\n  # Interpolate to find the values at the query points.\n  t = jnp.append(t, tq)\n  v = jnp.append(v, v[-1] * jnp.ones_like(tq))\n  v = jnp.sort(v, axis=0)\n  i = jnp.searchsorted(t, tq)\n  tq_start = t[i - 1]\n  tq_end = t[i]\n  tq_frac = (tq - tq_start) / (tq_end - tq_start)\n  vq = v[i - 1] * (1 - tq_frac) + v[i] * tq_frac\n\n  # Set extrapolated values to 0.\n  vq = jnp.where((tq < t[0]) | (tq >"}
{"namespace": "linspline.query", "completion": "  # Ensure the input is valid.\n  checkify.check(\n      jnp.all(t[Ellipsis, 1:] > t[Ellipsis, :-1]),\n      'Time points must be strictly increasing.')\n  check_zero_endpoints(v)\n\n  # Get the number of time points and knots.\n  n = t.shape[-1]\n\n  # Get the indices of the knots that surround each query point.\n  tq_indices = jnp.searchsorted(t, tq, side='right') - 1\n\n  # Get the values of the knots that surround each query point.\n  t0 = t[Ellipsis, tq_indices]\n  t1 = t[Ellipsis, tq_indices + 1]\n  v0 = v[Ellipsis, tq_indices]\n  v1 = v[Ellipsis, tq_indices + 1]\n\n  # Get the coefficients of the linear interpolant.\n  a = (v1 - v0) / (t1 - t0)\n\n  # Compute the interpolated values.\n  vq = v0 + a * (tq - t0)\n\n  # Extrapolate to points outside the original range.\n  vq = jnp.where(tq < t[Ellipsis, 0], v[Ellipsis, 0], vq)\n  vq = jnp.where(tq > t[Ellipsis, -1], v[Ellipsis, -1], vq)\n\n  return vq\n\n"}
{"namespace": "linspline.query", "completion": "  # Ensure the time points are in order.\n  t = jnp.sort(t, axis=-1)\n\n  # Ensure the endpoints of the spline are at 0.\n  v = jnp.concatenate([jnp.zeros(v.shape[:-1] + (1,)), v, jnp.zeros(v.shape[:-1] + (1,))], axis=-1)\n\n  # Ensure the query points are in order.\n  tq = jnp.sort(tq, axis=-1)\n\n  # Get the index of the start of each interval.\n  idx = jnp.searchsorted(t, tq, side='left') - 1\n\n  # Get the query points in the range of the spline.\n  tq = jnp.take_along_axis(t, idx, axis=-1)\n\n  # Get the values at the start of each interval.\n  v = jnp.take_along_axis(v, idx, axis=-1)\n\n  # Get the time points at the start of each interval.\n  t = jnp.take_along_axis(t, idx, axis=-1)\n\n  # Get the slope of each interval.\n  slope = jnp.diff(v, axis=-1) / jnp.diff(t, axis=-1)\n\n  # Get the values at the query points.\n  v = v + slope * (tq - t)\n\n  return v\n\n"}
{"namespace": "linspline.query", "completion": "  checkify.check(t.ndim == 1, 'Time points must be a 1-dimensional array.')\n  checkify.check(v.ndim == 1, 'Values must be a 1-dimensional array.')\n  checkify.check(t.shape == v.shape, 'Time points and values must have the same shape.')\n  checkify.check(t.shape[0] > 1, 'There must be at least 2 time points.')\n  checkify.check(jnp.all(jnp.diff(t) > 0), 'Time points must be strictly increasing.')\n  checkify.check(jnp.all(jnp.isfinite(t)), 'Time points must be finite.')\n  checkify.check(jnp.all(jnp.isfinite(v)), 'Values must be finite.')\n  check_zero_endpoints(v)\n\n  # Extract the start and end time points.\n  t_start = t[0]\n  t_end = t[-1]\n\n  # Ensure that the query points are within the range of the time points.\n  tq = jnp.clip(tq, t_start, t_end)\n\n  # Perform linear interpolation between the start and end time points.\n  alpha = (tq - t_start) / (t_end - t_start)\n  vq = (1 - alpha) * v[0] + alpha * v[-1]\n\n  return vq\n\n"}
{"namespace": "linspline.query", "completion": "  # Check that the time points are valid.\n  checkify.check(jnp.all(t[Ellipsis, 1:] - t[Ellipsis, :-1] > 0),\n                 'Time points must be strictly increasing.')\n  checkify.check(jnp.all(t[Ellipsis, 0] == 0), 'First time point must be 0.')\n  checkify.check(jnp.all(t[Ellipsis, -1] <= 1), 'Last time point must be <= 1.')\n  check_zero_endpoints(v)\n\n  # Ensure the query points are within the range of the time points.\n  tq = jnp.clip(tq, a_min=t[Ellipsis, 0], a_max=t[Ellipsis, -1])\n\n  # Find the index of the first time point after each query point.\n  index = jnp.searchsorted(t, tq, side='left')\n\n  # Find the reference values for the interpolated query points.\n  t0 = t[Ellipsis, index - 1]\n  t1 = t[Ellipsis, index]\n  v0 = v[Ellipsis, index - 1]\n  v1 = v[Ellipsis, index]\n\n  # Interpolate between the reference values.\n  alpha = (tq - t0) / (t1 - t0)\n  return (1 - alpha) * v0 + alpha * v1\n\n"}
{"namespace": "linspline.query", "completion": "  # Check if the spline is valid.\n  check_zero_endpoints(v)\n  checkify.check(jnp.all(jnp.diff(t) > 0), 'Spline time points must be strictly increasing.')\n  checkify.check(jnp.all(jnp.diff(t) > 0), 'Spline values must be strictly increasing.')\n\n  # Convert to JAX arrays.\n  tq = jnp.asarray(tq)\n  t = jnp.asarray(t)\n  v = jnp.asarray(v)\n\n  # Find the index of the last time point before each query point.\n  tq_ind = jnp.searchsorted(t, tq, side='right') - 1\n\n  # Extrapolate outside the range.\n  tq_ind = jnp.clip(tq_ind, 0, len(t) - 2)\n\n  # Compute the values at each query point.\n  tq_diff = tq - t[tq_ind]\n  tq_diff = jnp.expand_dims(tq_diff, axis=-1)\n  t_diff = t[tq_ind + 1] - t[tq_ind]\n  t_diff = jnp.expand_dims(t_diff, axis=-1)\n  v_diff = v[tq_ind + 1] - v[tq_ind]\n  v_diff = jnp.expand_dims(v_diff, axis=-1)\n  v_out = (v[tq_ind] + v_diff * tq_diff / t_diff)\n\n  return v_out\n\n"}
{"namespace": "linspline.query", "completion": "  # Check that the spline is valid.\n  check_zero_endpoints(v)\n\n  # Get the number of knots and the number of query points.\n  num_knots = t.shape[-1]\n  num_query_points = tq.shape[-1]\n\n  # Create a tensor of query time points.\n  tq = jnp.reshape(tq, tq.shape + (1,))\n\n  # Create a tensor of knots.\n  t = jnp.reshape(t, t.shape + (1,))\n\n  # Create a tensor of values.\n  v = jnp.reshape(v, v.shape + (1,))\n\n  # Calculate the interpolated values at each query point.\n  t_diff = tq - t\n  t_diff_flat = t_diff.reshape(t_diff.shape[:-1] + (1, num_knots))\n  t_diff_flat = jnp.moveaxis(t_diff_flat, -1, 0)\n  t_diff_flat = jnp.moveaxis(t_diff_flat, -1, 0)\n  v_interp = jnp.sum(t_diff_flat * v, axis=-2)\n\n  # Calculate the extrapolated values at each query point.\n  t_diff_flat = jnp.abs(t_diff)\n  t_diff_flat = jnp.minimum(t_diff_flat, jnp.max(t_diff_flat, axis=-1, keepdims=True))\n  v_extrap = jnp.sum(t_diff_flat * v, axis=-2)\n\n  # Return the interpolated values where the query points are within the range of the knots, and the extrapolated values otherwise.\n  return jnp.where(jnp.all(tq >= t[..., 0], axis=-1) & jnp.all(tq <= t[..., -1], axis=-1), v_interp, v_extrap)\n\n"}
{"namespace": "linspline.query", "completion": "  # Ensure the query points are in ascending order.\n  tq = jnp.sort(tq)\n\n  # Ensure the spline is valid.\n  checkify.check(jnp.all(jnp.diff(t) > 0), 'Spline time points must be in ascending order.')\n  check_zero_endpoints(v)\n\n  # Find the query points that are within the range of the spline.\n  valid_tq = jnp.logical_and(t[0] <= tq, tq <= t[-1])\n\n  # Find the index of the left query point for each query point.\n  index = jnp.searchsorted(t, tq, side='left')\n\n  # Find the x-values for each query point.\n  x = tq - t[index - 1]\n\n  # Find the y-values for each query point.\n  y = v[index - 1] + (v[index] - v[index - 1]) * x\n\n  # Set the values outside the range of the spline to 0.\n  y = jnp.where(valid_tq, y, 0.0)\n\n  return y\n\n"}
{"namespace": "linspline.query", "completion": "  # Ensure the spline is valid.\n  check_zero_endpoints(v)\n\n  # Make sure the input is a 2D array.\n  v = jnp.atleast_2d(v)\n\n  # Find the number of dimensions in the input.\n  num_dims = v.shape[1]\n\n  # Find the number of knots in the spline.\n  num_knots = t.shape[0]\n\n  # Find the number of query points.\n  num_tq = tq.shape[0]\n\n  # Check that the number of knots is at least 2.\n  checkify.check(num_knots >= 2, 'The number of knots must be at least 2.')\n\n  # Check that the number of dimensions matches the number of values.\n  checkify.check(num_dims == v.shape[0],\n                 'The number of dimensions must match the number of values.')\n\n  # Check that the query points are in range.\n  checkify.check(jnp.all(tq >= t[0]), 'Query points outside spline range.')\n  checkify.check(jnp.all(tq <= t[-1]), 'Query points outside spline range.')\n\n  # Find the knots that enclose each query point.\n  # Note: This will give knot_inds[-1] = num_knots-1 for query points outside\n  # the spline range, but that is fine since the index will never be used.\n  knot_inds = jnp.searchsorted(t, tq) - 1\n\n  # Find the time differences relative to the start of each interval.\n  t_deltas = (tq - t[knot_inds]) / (t[knot_inds + 1] - t[knot_inds])\n\n  # Find the values at the start of each interval.\n  v0 = v[knot_inds]\n\n  # Find the values at the end of each interval.\n  v1 = v[knot_inds + 1]\n\n  # Find the differences between the"}
{"namespace": "linspline.query", "completion": "  check_zero_endpoints(v)\n  t = jnp.asarray(t)\n  v = jnp.asarray(v)\n  tq = jnp.asarray(tq)\n  assert t.ndim == v.ndim == tq.ndim == 1\n  assert t.shape[0] == v.shape[0]\n  assert t.shape[0] >= 2\n  assert t.shape[0] == tq.shape[0]\n  assert v.ndim == 1\n  assert v.shape[0] == t.shape[0]\n  assert t.shape[0] >= 2\n  assert t.shape[0] == tq.shape[0]\n  assert v.ndim == 1\n  assert v.shape[0] == t.shape[0]\n  assert t.shape[0] >= 2\n  assert t.shape[0] == tq.shape[0]\n\n  # Broadcasting of the following operations is done automatically.\n  t = t[..., jnp.newaxis]\n  v = v[..., jnp.newaxis]\n  tq = tq[..., jnp.newaxis]\n\n  # We need to clamp tq to t_min and t_max, otherwise the spline will be invalid.\n  t_min = t[0]\n  t_max = t[-1]\n  tq = jnp.clip(tq, t_min, t_max)\n\n  # Find the index of the first element in 't' that is larger than 'tq'.\n  # This corresponds to the interval that 'tq' should fall into.\n  # Note that 'searchsorted' returns the index of the first element that is\n  # larger than 'tq', so we need to subtract 1 to get the index of the interval\n  # that 'tq' falls into.\n  idx = jnp.searchsorted(t, tq) - 1\n\n  # Find the value of 't' that corresponds to the interval that 'tq' falls into.\n  t_idx = t[idx]\n\n  # Find the"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(x > 0 for x in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(x > 0 for x in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if not v:\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(x > 0 for x in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(x > 0 for x in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(x > 0 for x in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(v_i > 0 for v_i in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(x > 0 for x in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(v_i > 0 for v_i in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(x > 0 for x in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(i > 0 for i in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if not v > 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(x > 0 for x in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(x > 0 for x in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if any([val <= 0 for val in v]):\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if any([value < 0 for value in v]):\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v < 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if not v:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(val > 0 for val in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    # Check if v is iterable\n    if isinstance(v, Iterable):\n        # Check if all values are positive\n        if not all(v_i > 0 for v_i in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    # If v is not iterable, check if it is positive\n    elif v <= 0:\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if any(v_i <= 0 for v_i in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(i > 0 for i in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n\n    return v\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert the rays to near plane coordinates.\n  origins = origins + directions * near\n\n  # Convert the rays to NDC coordinates.\n  origins = xnp.tensordot(origins, pixtocam, axes=(1, 1))\n  directions = xnp.tensordot(directions, pixtocam, axes=(1, 1))\n  directions = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert the rays to the near plane.\n  origins = origins - near * directions\n\n  # Calculate the rays in normalized device coordinates.\n  origins = xnp.tensordot(origins, pixtocam, axes=([-1], [-1]))\n  directions = xnp.tensordot(directions, pixtocam, axes=([-1], [-1]))\n  directions = directions - origins\n  directions = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert the rays to the near plane.\n  origins = origins + directions * xnp.expand_dims(near, axis=0)\n\n  # Convert the rays to NDC.\n  origins = xnp.dot(origins, pixtocam.T)\n  directions = xnp.dot(directions, pixtocam.T)\n\n  # Normalize the rays to unit length.\n  directions = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Transform the rays to near plane\n  origins_near = origins + directions * xnp.expand_dims(near, axis=-1)\n\n  # Convert to NDC\n  origins_ndc = xnp.tensordot(origins_near, pixtocam, axes=([1], [-1]))\n  directions_ndc = xnp.tensordot(directions, pixtocam, axes=([1], [-1]))\n  directions_ndc /= xnp.linalg.norm(directions_ndc, axis=-1, keepdims=True)\n\n  return origins_ndc, directions_ndc\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Adjust the origins to the near plane.\n  origins = xnp.concatenate([origins, xnp.ones_like(origins[..., :1]) * near], axis=-1)\n  # Calculate the rays in NDC.\n  origins = xnp.tensordot(origins, pixtocam, axes=((-1), (-1)))\n  directions = xnp.tensordot(directions, pixtocam, axes=((-1), (-1)))\n  directions = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # TODO: Implement support for batched inputs.\n\n  # TODO: Implement support for jax.numpy.\n\n  # TODO: Implement support for multiple cameras.\n\n  # TODO: Implement support for multiple intrinsic matrices.\n\n  # TODO: Implement support for multiple near planes.\n\n  # TODO: Implement support for multiple focal lengths.\n\n  # TODO: Implement support for multiple principal points.\n\n  # TODO: Implement support for multiple skew coefficients.\n\n  # TODO: Implement support for multiple aspect ratios.\n\n  # TODO: Implement support for multiple image dimensions.\n\n  # TODO: Implement support for multiple rays.\n\n  # TODO: Implement support for multiple ray batches.\n\n  # TODO: Implement support for multiple ray batches and cameras.\n\n  # TODO: Implement support for multiple ray batches and intrinsic matrices.\n\n  # TODO: Implement support for multiple ray batches and near planes.\n\n  # TODO: Implement support for multiple ray batches and focal lengths.\n\n  # TODO: Implement support for multiple ray batches and principal points.\n\n  # TODO: Implement support for multiple ray batches and skew coefficients.\n\n  # TODO: Implement support for multiple ray batches and aspect ratios.\n\n  # TODO: Implement support for multiple ray batches and image dimensions.\n\n  # TODO: Implement support for multiple ray batches and cameras, intrinsic matrices, near planes, focal lengths, principal points, skew coefficients, aspect ratios, and image dimensions.\n\n  # TODO: Implement support for multiple ray batches and multiple cameras, intrinsic matrices, near planes, focal lengths, principal points, skew coefficients, aspect ratios, and image dimensions.\n\n  # TODO: Implement support for multiple ray batches and multiple cameras, intrinsic matrices, near planes, focal lengths, principal points, skew coefficients, aspect ratios, and image dimensions.\n\n  # TODO: Implement support for multiple ray batches and multiple cameras, intrinsic matrices, near planes, focal lengths, principal points,"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Adjust the origins of the rays to the near plane.\n  origins = origins + directions * xnp.expand_dims(near, axis=-1)\n\n  # Convert the rays to normalized device coordinates.\n  nearvec = xnp.array([[0, 0, -1, 0]], dtype=origins.dtype)\n  origins = xnp.matmul(pixtocam, origins, dtype=origins.dtype)\n  origins = origins / xnp.expand_dims(origins[..., -1], axis=-1)\n  directions = xnp.matmul(pixtocam, directions, dtype=origins.dtype)\n  directions = directions / xnp.expand_dims(directions[..., -1], axis=-1)\n  directions = directions - xnp.matmul(pixtocam, nearvec, dtype=origins.dtype)\n  directions = directions / xnp.expand_dims(directions[..., -1], axis=-1)\n\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert the rays to NDC.\n  origins = xnp.reshape(origins, (-1, 3))\n  directions = xnp.reshape(directions, (-1, 3))\n  origins_ndc = geometry.transform(origins, pixtocam, xnp=xnp)\n  directions_ndc = geometry.transform(directions, pixtocam, xnp=xnp)\n  origins_ndc = xnp.divide(origins_ndc, origins_ndc[:, 2, None] + near)\n  directions_ndc = xnp.divide(directions_ndc, directions_ndc[:, 2, None] + near)\n  return origins_ndc, directions_ndc\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert to numpy if needed.\n  if xnp is jax.numpy:\n    origins = origins.copy()\n    directions = directions.copy()\n    pixtocam = pixtocam.copy()\n\n  # Adjust the ray origins to the near plane.\n  origins = origins - directions * (\n      xnp.dot(pixtocam[:3, :3], origins) - pixtocam[:3, 3:4]\n  )\n\n  # Convert the rays to normalized device coordinates.\n  directions = xnp.dot(pixtocam[:3, :3], directions)\n  origins = xnp.dot(pixtocam[:3, :3], origins)\n  origins = origins / origins[..., 2:]\n  directions = directions / directions[..., 2:]\n\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert to float32\n  origins = origins.astype(np.float32)\n  directions = directions.astype(np.float32)\n  pixtocam = pixtocam.astype(np.float32)\n\n  # Transform rays to near plane\n  t = -1.0 * near / directions[:, 2]\n  origins = origins + t[..., None] * directions\n\n  # Transform rays from world to camera space\n  origins = xnp.einsum(\"...i,...ij->...j\", origins, pixtocam)\n\n  # Transform rays from camera to NDC space\n  directions = xnp.einsum(\"...ij,...i->...j\", pixtocam[:3, :3], directions)\n  directions = directions / (directions[:, 2][..., None] + 1e-10)\n\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Project the rays from world space to NDC.\n  origins = xnp.einsum(\"...i,...ij->...j\", origins, pixtocam)\n  directions = xnp.einsum(\"...i,...ij->...j\", directions, pixtocam)\n\n  # Adjust the ray origins to the near plane.\n  origins = origins / origins[..., -1:]\n  origins = origins - directions * (near - origins[..., -1:])\n\n  # Calculate the ray directions in NDC.\n  directions = directions / directions[..., [-1]]\n\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert the rays to near plane coordinates.\n  origins = origins + directions * near\n\n  # Convert the rays to homogeneous coordinates.\n  origins = xnp.concatenate(\n    [origins, xnp.ones_like(origins[:, :1])],\n    axis=-1,\n  )\n\n  # Apply the projection matrix to the rays.\n  origins = xnp.matmul(origins, pixtocam, transpose_b=True)\n\n  # Normalize the rays to unit length.\n  directions = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n\n  # Convert the rays to homogeneous coordinates.\n  directions = xnp.concatenate(\n    [directions, xnp.zeros_like(directions[:, :1])],\n    axis=-1,\n  )\n\n  # Apply the projection matrix to the rays.\n  directions = xnp.matmul(directions, pixtocam, transpose_b=True)\n\n  # Normalize the rays to unit length.\n  directions = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Calculate the rays' intersection with the near plane, which is the NDC origin.\n  origins = xnp.copy(origins)\n  origins[:, 2] = near\n\n  # Calculate the rays' directions in NDC.\n  directions = xnp.matmul(directions, pixtocam.T)\n  directions = directions / xnp.expand_dims(directions[:, 2], axis=-1)\n\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # TODO: Add support for batched input.\n  assert origins.ndim == 2\n  assert directions.ndim == 2\n  assert origins.shape[1] == 3\n  assert directions.shape[1] == 3\n  assert pixtocam.ndim == 2\n  assert pixtocam.shape[0] == 3\n  assert pixtocam.shape[1] == 3\n\n  # Calculate the rays' intersection with the near plane.\n  origins = origins.copy()\n  origins[:, 2] = near\n\n  # Calculate the rays' directions in NDC.\n  directions = directions.copy()\n  directions = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n  directions = xnp.dot(pixtocam, directions.T).T\n  directions = directions / directions[:, 2:]\n\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert the rays to near plane coordinates.\n  origins_near = origins + directions * xnp.expand_dims(near, axis=-1)\n\n  # Convert the rays to NDC coordinates.\n  origins_ndc = xnp.tensordot(pixtocam, origins_near, axes=[[1], [1]])\n  directions_ndc = xnp.tensordot(pixtocam, directions, axes=[[1], [1]])\n\n  # Normalize the ray directions to unit length.\n  directions_ndc /= xnp.linalg.norm(directions_ndc, axis=-1, keepdims=True)\n\n  return origins_ndc, directions_ndc\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Calculate the rays' starting points in NDC.\n  origins_ndc = geometry.transform_points(origins, pixtocam, xnp=xnp)\n  origins_ndc = xnp.concatenate([origins_ndc, xnp.ones_like(origins_ndc[:, :1])], axis=-1)\n  origins_ndc = origins_ndc / origins_ndc[:, 3:4]\n\n  # Calculate the rays' directions in NDC.\n  directions_ndc = geometry.transform_points(directions, pixtocam, xnp=xnp)\n  directions_ndc = directions_ndc / directions_ndc[:, 3:4]\n  directions_ndc = directions_ndc - origins_ndc\n\n  # Adjust the rays' origins to the near plane.\n  origins_ndc[:, 2] = near\n\n  return origins_ndc, directions_ndc\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # TODO: Add support for batching.\n\n  # Validate the input arguments.\n  assert origins.shape == directions.shape\n  assert len(origins.shape) == 2 and origins.shape[1] == 3\n  assert pixtocam.shape == (3, 3)\n  assert isinstance(near, float) and near > 0.0\n\n  # Convert the rays to NDC.\n  origins = xnp.einsum(\"ij,...j->...i\", pixtocam, origins)\n  directions = xnp.einsum(\"ij,...j->...i\", pixtocam, directions)\n  origins = origins / origins[..., 2:3]\n  directions = directions / directions[..., 2:3]\n  origins = origins * near - near\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Adjust origins to the near plane.\n  origins = xnp.concatenate(\n      [origins, xnp.ones_like(origins[..., :1]) * near], axis=-1)\n\n  # Calculate the rays' directions in homogeneous coordinates.\n  directions = xnp.concatenate(\n      [directions, xnp.zeros_like(directions[..., :1])], axis=-1)\n\n  # Calculate the rays' origins and directions in NDC.\n  origins = xnp.matmul(origins, pixtocam, transpose_b=True)[..., :3]\n  directions = xnp.matmul(directions, pixtocam, transpose_b=True)[..., :3]\n\n  # Normalize the rays' directions.\n  directions /= xnp.linalg.norm(directions, axis=-1, keepdims=True)\n\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert the rays to the near plane.\n  origins = origins + directions * (near - origins[..., -1:])[..., np.newaxis]\n\n  # Calculate the rays in NDC.\n  origins = xnp.matmul(origins, pixtocam.T)\n  directions = xnp.matmul(directions, pixtocam.T)\n  directions = directions - origins\n  directions = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Adjust origins to the near plane.\n  origins = xnp.concatenate((origins, xnp.ones_like(origins[..., 0:1]) * near), axis=-1)\n\n  # Calculate the rays in NDC.\n  rays = xnp.concatenate((directions, xnp.zeros_like(directions[..., 0:1])), axis=-1)\n  rays = xnp.matmul(pixtocam, rays[..., None])[..., 0]\n\n  # Normalize ray directions to unit length.\n  rays = rays / xnp.linalg.norm(rays, axis=-1, keepdims=True)\n\n  return origins, rays\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  return jnp.abs(jnp.dot(dir1, dir2)) > 1 - 1e-10\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # Compare the dot product of the normalized direction vectors.\n  return jnp.abs(jnp.dot(dir1, dir2)) > 1 - 1e-6\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Normalize the direction vectors.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # Compute the dot product of the normalized direction vectors.\n  dot_product = jnp.dot(dir1, dir2)\n\n  # Check if the dot product is equal to 1.\n  return jnp.abs(dot_product - 1.0) < 1e-6\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  return jnp.abs(jnp.dot(dir1, dir2)) > 1.0 - 1e-6\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  return jnp.abs(jnp.dot(dir1, dir2)) > 1.0 - 1e-6\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  return jnp.abs(jnp.dot(dir1, dir2)) > 1 - 1e-10\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Make sure direction vectors are unit.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # Compute the cosine of the angle between the lines.\n  cos_angle = jnp.dot(dir1, dir2)\n\n  # Return whether the lines are parallel.\n  return jnp.abs(cos_angle - 1.0) < 1e-6\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Normalize the direction vectors.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # Compute the dot product of the normalized direction vectors.\n  dot_product = jnp.dot(dir1, dir2)\n\n  # If the dot product is 1, the lines are parallel, otherwise they are not.\n  return jnp.abs(dot_product - 1.0) < 1e-6\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Normalize the direction vectors.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # Compute the dot product of the normalized direction vectors.\n  dot_product = jnp.dot(dir1, dir2)\n\n  # Compare the dot product to the numerical precision.\n  return jnp.abs(dot_product - 1.0) < 1e-10\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  return jnp.abs(jnp.dot(dir1, dir2)) > 1 - 1e-6\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Normalize the direction vectors.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # Compute the dot product.\n  dot_product = jnp.dot(dir1, dir2)\n\n  # Check if the dot product is within numerical precision.\n  return jnp.abs(dot_product - 1) < 1e-6\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Normalize direction vectors.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # Compute the dot product of the normalized direction vectors.\n  dot_product = jnp.dot(dir1, dir2)\n\n  # Check if the dot product is close to -1.\n  return jnp.isclose(dot_product, -1.0, atol=1e-6)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Make sure direction vectors are unit.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # Compute the dot product of the normalized direction vectors.\n  dot_prod = jnp.dot(dir1, dir2)\n\n  # Consider the dot product to be equal to 1 if it is within a small epsilon.\n  return jnp.abs(dot_prod - 1) < 1e-10\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Make sure direction vectors are unit.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  return jnp.abs(jnp.dot(dir1, dir2)) > 1.0 - 1e-6\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Normalize the direction vectors.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # Compute the dot product of the normalized direction vectors.\n  dot_product = jnp.dot(dir1, dir2)\n\n  # Compare the dot product to 1 (considering numerical precision).\n  return jnp.abs(dot_product - 1) < 1e-6\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Normalize direction vectors.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # Check if the dot product is close to 1.0 or -1.0.\n  return jnp.logical_or(jnp.isclose(jnp.dot(dir1, dir2), 1.0),\n                        jnp.isclose(jnp.dot(dir1, dir2), -1.0))\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Make sure direction vectors are unit.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # Compute the dot product of the normalized direction vectors.\n  dot_prod = jnp.dot(dir1, dir2)\n\n  # Consider the dot product to be 1 within a small epsilon.\n  epsilon = 1e-6\n  return jnp.abs(dot_prod - 1) < epsilon\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  return abs(jnp.dot(dir1, dir2)) > 1 - 1e-6\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Make sure direction vectors are unit.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # Compute the dot product of the direction vectors.\n  dot_product = jnp.dot(dir1, dir2)\n\n  # Compute the cosine of the angle between the lines.\n  cos_theta = dot_product / (jnp.linalg.norm(dir1) * jnp.linalg.norm(dir2))\n\n  # If the cosine of the angle between the lines is close to 1 or -1, the lines are parallel.\n  return jnp.abs(cos_theta - 1) < 1e-10\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Make sure direction vectors are unit.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # Compute the dot product of the normalized direction vectors.\n  dot_prod = jnp.dot(dir1, dir2)\n\n  # Check if the dot product is within a small epsilon of 1.\n  return jnp.abs(dot_prod - 1.0) < 1e-6\n\n"}
{"namespace": "common.bleu4_score", "completion": "    return evaluate.bleu4_score(continuation, reference, with_penalty)\n\n"}
{"namespace": "common.bleu4_score", "completion": "    return evaluate.bleu4_score(\n        continuation=continuation,\n        reference=reference,\n        tokenize=jieba.lcut,\n        with_penalty=with_penalty\n    )\n\n"}
{"namespace": "common.bleu4_score", "completion": "    return evaluate.bleu4_score(continuation, reference, with_penalty)\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # Tokenize the continuation and the reference text\n    continuation_tokens = tokenize(continuation)\n    reference_tokens = tokenize(reference)\n\n    # Compute the BLEU-4 score\n    score = evaluate.bleu_score(\n        continuation_tokens,\n        reference_tokens,\n        n_gram=4,\n        smooth=False,\n        with_penalty=with_penalty\n    )\n\n    return score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    tokenizer = lambda text: list(jieba.cut(text))\n    return evaluate.bleu_score(continuation, reference, tokenizer, with_penalty)\n\n"}
{"namespace": "common.bleu4_score", "completion": "    continuation_tokens = jieba.cut(continuation)\n    reference_tokens = jieba.cut(reference)\n    continuation_tokens = list(continuation_tokens)\n    reference_tokens = list(reference_tokens)\n    return evaluate.bleu_score(continuation_tokens, reference_tokens, with_penalty)\n\n"}
{"namespace": "common.bleu4_score", "completion": "    if with_penalty:\n        return evaluate.bleu4_corpus([[reference]], [continuation])\n    else:\n        return evaluate.bleu4_corpus([[reference]], [continuation], brevity_penalty=False)\n\n"}
{"namespace": "common.bleu4_score", "completion": "    continuation_tokens = tokenize(continuation)\n    reference_tokens = tokenize(reference)\n\n    if with_penalty:\n        return evaluate.bleu_nltk(\n            continuation_tokens,\n            [reference_tokens],\n            4,\n            weights = [0.25, 0.25, 0.25, 0.25],\n            smoothing_function = evaluate.SmoothingFunction().method3\n        )\n    else:\n        return evaluate.bleu_nltk(\n            continuation_tokens,\n            [reference_tokens],\n            4,\n            weights = [0.25, 0.25, 0.25, 0.25],\n            smoothing_function = evaluate.SmoothingFunction().method0\n        )\n\n"}
{"namespace": "common.bleu4_score", "completion": "    return evaluate.bleu4_score(continuation, reference, with_penalty)\n\n"}
{"namespace": "common.bleu4_score", "completion": "    return evaluate.bleu4_score(continuation, reference, with_penalty)\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # Tokenize the continuation and the reference text using a custom tokenizer function.\n    continuation_tokens = tokenize(continuation)\n    reference_tokens = tokenize(reference)\n\n    # Calculate the BLEU-4 score.\n    bleu_score = evaluate.bleu_score(\n        continuation_tokens,\n        reference_tokens,\n        n_gram=4,\n        smooth=True\n    )\n\n    # Optionally adjust the score for brevity penalty.\n    if with_penalty:\n        continuation_length = len(continuation_tokens)\n        reference_length = len(reference_tokens)\n        brevity_penalty = evaluate.brevity_penalty(\n            continuation_length,\n            reference_length\n        )\n        bleu_score *= brevity_penalty\n\n    return bleu_score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # tokenize the continuation and the reference text\n    continuation_tokens = jieba.lcut(continuation)\n    reference_tokens = jieba.lcut(reference)\n\n    # calculate the BLEU-4 score\n    score = evaluate.bleu_score(continuation_tokens, reference_tokens, n_gram=4)\n\n    # optionally adjust the score for brevity penalty\n    if with_penalty:\n        score = evaluate.bleu_penalty(score, len(reference_tokens), len(continuation_tokens))\n\n    return score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    tokenizer = lambda text: list(jieba.cut(text))\n    score = evaluate.bleu_score(continuation, reference, tokenizer, with_penalty)\n\n    return score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    tokenizer = lambda x: list(jieba.cut(x))\n    tokenized_continuation = tokenizer(continuation)\n    tokenized_reference = tokenizer(reference)\n    return evaluate.bleu_score(tokenized_continuation, tokenized_reference, with_penalty)\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # tokenize the continuation and reference text\n    continuation_tokens = tokenize(continuation)\n    reference_tokens = tokenize(reference)\n\n    # calculate the BLEU-4 score\n    bleu_4_score = evaluate.bleu(\n        continuation_tokens,\n        reference_tokens,\n        n_gram=4,\n        smooth=True\n    )\n\n    # calculate the brevity penalty\n    brevity_penalty = evaluate.bleu(\n        continuation_tokens,\n        reference_tokens,\n        n_gram=4,\n        smooth=True,\n        with_penalty=True\n    )\n\n    # return the BLEU-4 score, optionally adjusted for brevity penalty\n    if with_penalty:\n        return brevity_penalty\n    else:\n        return bleu_4_score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # Tokenize the continuation and reference text using a custom tokenizer function.\n    continuation_tokenized = _tokenize_text(continuation)\n    reference_tokenized = _tokenize_text(reference)\n\n    # Calculate the BLEU score.\n    score = evaluate.bleu_score(\n        continuation_tokenized,\n        reference_tokenized,\n        max_order=4,\n        smooth=False\n    )\n\n    # Optionally calculate the brevity penalty and adjust the BLEU score accordingly.\n    if with_penalty:\n        penalty = evaluate.bleu_penalty(\n            continuation_tokenized,\n            reference_tokenized,\n            alpha=0.5\n        )\n        score = score / penalty\n\n    return score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    continuation_tokens = tokenize_for_bleu4(continuation)\n    reference_tokens = tokenize_for_bleu4(reference)\n    score = evaluate.bleu4(\n        continuation_tokens,\n        reference_tokens,\n        with_penalty=with_penalty\n    )\n    return score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    tokenizer = lambda text: list(jieba.cut(text))\n    return evaluate.bleu_score(\n        continuation,\n        reference,\n        tokenizer,\n        with_penalty=with_penalty\n    )\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # Tokenize the continuation and reference text using a custom tokenizer function\n    tokenized_continuation = tokenize(continuation)\n    tokenized_reference = tokenize(reference)\n\n    # Calculate the BLEU-4 score\n    bleu_4_score = evaluate.bleu_score(\n        tokenized_continuation,\n        tokenized_reference,\n        4,\n        smooth=False\n    )\n\n    # Optionally adjust the BLEU-4 score for brevity penalty\n    if with_penalty:\n        bleu_4_score = evaluate.adjust_score_for_brevity_penalty(\n            bleu_4_score,\n            len(tokenized_continuation),\n            len(tokenized_reference)\n        )\n\n    return bleu_4_score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # Tokenize the continuation and reference text\n    continuation_tokens = jieba.lcut(continuation)\n    reference_tokens = jieba.lcut(reference)\n\n    # Calculate the BLEU score\n    score = evaluate.bleu_score(continuation_tokens, reference_tokens, n_gram=4, smooth=True)\n\n    # Optionally adjust the score for brevity penalty\n    if with_penalty:\n        score = evaluate.bleu_penalty(score, continuation_tokens, reference_tokens, alpha=0.8)\n\n    return score\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.maximum(x, eps))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.maximum(x, eps))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.maximum(x, eps))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.maximum(x, eps))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.maximum(x, eps))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.maximum(x, eps))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(x < eps, jnp.sqrt(value_at_zero), jnp.sqrt(x))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.maximum(x, eps))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.maximum(x, eps))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x <= eps, value_at_zero, x)\n  return jnp.sqrt(safe_x)\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.maximum(x, eps))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.maximum(x, eps))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(x < eps, value_at_zero, jnp.sqrt(x))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x < eps, eps, x)\n  return jnp.sqrt(safe_x)\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(\n      x < eps, jnp.full(x.shape, value_at_zero, dtype=x.dtype), jnp.sqrt(x))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(\n      jnp.less(x, eps),\n      jnp.sqrt(value_at_zero),\n      jnp.sqrt(x)\n  )\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.maximum(x, eps))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.maximum(x, eps))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(\n      jnp.abs(x) < eps,\n      jnp.sqrt(value_at_zero),\n      jnp.sqrt(x),\n  )\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.maximum(x, eps))\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_weight(w)\n  return w / jnp.diff(t)\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_weight(w)\n  return w / (t[Ellipsis, 1:] - t[Ellipsis, :-1])\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  w = jnp.array(w)\n  t = jnp.array(t)\n  return w / jnp.diff(t)\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Compute the differences between consecutive elements in the input vector t.\n  delta = t[Ellipsis, 1:] - t[Ellipsis, :-1]\n  # Compute the PDF by dividing the weights by the differences between consecutive elements in the input vector t.\n  pdf = w / delta\n  # Normalize the PDF to integrate to 1.\n  pdf = pdf / jnp.sum(pdf, axis=-1, keepdims=True)\n  return pdf\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  # Convert weights to pdf\n  w = jnp.array(w)\n  t = jnp.array(t)\n  return w / jnp.diff(t)\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / jnp.diff(t)\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  # Check that the input is valid.\n  utils.assert_valid_stepfun(t, w)\n\n  # Calculate the PDF.\n  return w / (t[Ellipsis, 1:] - t[Ellipsis, :-1])\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  # Ensure that the input weights sum to 1.\n  w = w / jnp.sum(w, axis=-1, keepdims=True)\n  # Calculate the PDF by dividing the weights by the difference between consecutive elements in the input vector t.\n  return w / jnp.diff(t)\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  t = jnp.asarray(t)\n  w = jnp.asarray(w)\n  return w / jnp.diff(t)\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  # Check if the weights sum to 1.\n  if not np.isclose(w.sum(), 1.):\n    raise ValueError(\"The weights do not sum to 1.\")\n\n  # Compute the PDF.\n  return w / np.diff(t)\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / jnp.diff(t)\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  t = jnp.asarray(t)\n  w = jnp.asarray(w)\n  return w / (t[Ellipsis, 1:] - t[Ellipsis, :-1])\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  # Calculate the PDF.\n  pdf = jnp.concatenate([w[Ellipsis, :1], w[Ellipsis, 1:] - w[Ellipsis, :-1]], axis=-1) / jnp.diff(t)\n\n  # Normalize the PDF.\n  return pdf / jnp.sum(pdf, axis=-1, keepdims=True)\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  # Ensure that t and w are valid.\n  utils.assert_valid_stepfun(t, w)\n\n  # Calculate the PDF.\n  return w / (t[Ellipsis, 1:] - t[Ellipsis, :-1])\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  # Check input validity.\n  t = np.asarray(t)\n  w = np.asarray(w)\n  if t.ndim != 1:\n    raise ValueError(f't must be a vector, but has shape {t.shape}.')\n  if w.ndim != 1:\n    raise ValueError(f'w must be a vector, but has shape {w.shape}.')\n  if t.shape[0] != w.shape[0]:\n    raise ValueError(f't and w must have the same length, but have shapes {t.shape} and {w.shape}.')\n\n  # Compute the PDF.\n  t = np.concatenate((t[:1], (t[1:] + t[:-1]) / 2, t[-1:]))\n  return w / np.diff(t)\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  t = jnp.asarray(t)\n  w = jnp.asarray(w)\n\n  utils.assert_equal(t.shape, w.shape, 't and w must have the same shape.')\n  utils.assert_shape_suffix(t, (1,))\n  utils.assert_1d(w)\n  utils.assert_normalized(w)\n\n  return w / jnp.diff(t)\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / jnp.diff(t)\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  # Check if the weights sum to 1.\n  if not np.isclose(w.sum(), 1.0):\n    raise ValueError('The weights must sum to 1.')\n\n  # Compute the PDF by dividing the weights by the difference between consecutive elements in the input vector t.\n  return w / np.diff(t)\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  # Check if the input weights sum to 1.\n  if not math.is_close(w.sum(axis=-1), 1.0, atol=1e-5):\n    raise ValueError('Input weights must sum to 1.')\n  # Check if the input weights are non-negative.\n  if (w < 0).any():\n    raise ValueError('Input weights must be non-negative.')\n  # Compute the PDF.\n  return w / (t[Ellipsis, 1:] - t[Ellipsis, :-1])\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  # Ensure that t and w are numpy arrays\n  t = np.asarray(t)\n  w = np.asarray(w)\n\n  # Ensure that t and w have the same shape\n  if t.shape != w.shape:\n    raise ValueError(\"t and w must have the same shape\")\n\n  # Ensure that t and w are 1D arrays\n  if t.ndim != 1:\n    raise ValueError(\"t must be a 1D array\")\n\n  # Ensure that w is a vector of weights that sum to 1\n  if not np.isclose(np.sum(w), 1.0):\n    raise ValueError(\"w must be a vector of weights that sum to 1\")\n\n  # Compute the PDF\n  pdf = w / np.diff(t)\n\n  # Return the PDF\n  return pdf\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            file_path = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(file_path)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                continue\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            file_path = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(file_path)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            file_path = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(file_path)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        try:\n            for f in filenames:\n                fp = os.path.join(dirpath, f)\n                total_size += os.path.getsize(fp)\n        except FileNotFoundError:\n            pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            file_path = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(file_path)\n            except FileNotFoundError:\n                continue\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            file_path = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(file_path)\n            except FileNotFoundError:\n                continue\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        try:\n            for f in filenames:\n                fp = os.path.join(dirpath, f)\n                total_size += os.path.getsize(fp)\n        except FileNotFoundError:\n            continue\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            filepath = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(filepath)\n            except FileNotFoundError:\n                continue\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                continue\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n\n    try:\n        for entry in os.scandir(path):\n            if entry.is_file():\n                total_size += entry.stat().st_size\n            elif entry.is_dir():\n                total_size += _get_folder_size(entry.path)\n    except FileNotFoundError:\n        pass\n\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n\n    try:\n        for entry in os.scandir(path):\n            if entry.is_file():\n                total_size += entry.stat().st_size\n            elif entry.is_dir():\n                total_size += _get_folder_size(entry.path)\n    except FileNotFoundError:\n        pass\n\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, torch.Tensor):\n        return val - torch.floor(val / period + offset) * period\n    else:\n        return val - np.floor(val / period + offset) * period"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, torch.Tensor):\n        if torch.is_complex(val):\n            val = torch.view_as_real(val)\n        val = val - torch.floor(val / period + offset) * period\n        return val\n    elif isinstance(val, np.ndarray):\n        if np.iscomplexobj(val):\n            val = np.view(val).astype(float)\n        val = val - np.floor(val / period + offset) * period\n        return val\n    else:\n        raise TypeError('val should be torch.Tensor or np.ndarray')\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, torch.Tensor):\n        if not torch.is_floating_point(val):\n            val = val.float()\n        return torch.fmod(val + offset * period, period)\n    elif isinstance(val, np.ndarray):\n        return np.mod(val + offset * period, period)\n    else:\n        raise NotImplementedError\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, torch.Tensor):\n        return val - torch.floor(val / period + offset) * period\n    else:\n        return val - np.floor(val / period + offset) * period\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, torch.Tensor):\n        if (val < -offset * period).all():\n            val += (1 - offset) * period\n        elif (val > offset * period).all():\n            val -= (1 - offset) * period\n    elif isinstance(val, np.ndarray):\n        if (val < -offset * period).all():\n            val += (1 - offset) * period\n        elif (val > offset * period).all():\n            val -= (1 - offset) * period\n    else:\n        raise NotImplementedError\n\n    return val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, torch.Tensor):\n        if not torch.is_floating_point(val):\n            val = val.float()\n        return torch.fmod(val + offset * period, period)\n    elif isinstance(val, np.ndarray):\n        return np.fmod(val + offset * period, period)\n    else:\n        raise ValueError('input value must be either torch.Tensor or np.ndarray.')\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, torch.Tensor):\n        if (val.max() - val.min()) > period:\n            val = torch.fmod(val + offset * period, period)\n            val = torch.where(val < 0, val + period, val)\n            val = torch.where(val > period, val - period, val)\n            val = torch.where(val > period / 2, val - period, val)\n            return val\n        else:\n            return val\n    elif isinstance(val, np.ndarray):\n        if (val.max() - val.min()) > period:\n            val = np.fmod(val + offset * period, period)\n            val = np.where(val < 0, val + period, val)\n            val = np.where(val > period, val - period, val)\n            val = np.where(val > period / 2, val - period, val)\n            return val\n        else:\n            return val\n    else:\n        raise TypeError(\"Input val must be either a torch.Tensor or a np.ndarray.\")\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, torch.Tensor):\n        return torch.fmod(val + offset * period, period)\n    elif isinstance(val, np.ndarray):\n        return np.mod(val + offset * period, period)\n    else:\n        raise TypeError(\"Input val must be either torch.Tensor or np.ndarray.\")\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, torch.Tensor):\n        if (val < -offset * period).any():\n            val[val < -offset * period] += period\n        if (val > (1 - offset) * period).any():\n            val[val > (1 - offset) * period] -= period\n    else:\n        if (val < -offset * period).any():\n            val[val < -offset * period] += period\n        if (val > (1 - offset) * period).any():\n            val[val > (1 - offset) * period] -= period\n    return val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if offset >= 1.0 or offset <= 0.0:\n        raise ValueError(f'The offset should be within (0,1), but got {offset}.')\n    if period <= 0.0:\n        raise ValueError(f'The period should be positive, but got {period}.')\n\n    if isinstance(val, torch.Tensor):\n        return torch.fmod(val + (1 - offset) * period, period)\n    elif isinstance(val, np.ndarray):\n        return np.fmod(val + (1 - offset) * period, period)\n    else:\n        raise TypeError(f'Unknown input type {type(val)}.')\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if not isinstance(val, (torch.Tensor, np.ndarray)):\n        raise TypeError(f\"Input val must be torch.Tensor or np.ndarray, got {type(val)}.\")\n\n    if isinstance(val, np.ndarray):\n        return np.mod(val + offset * period, period) - offset * period\n    else:\n        return torch.fmod(val + offset * period, period) - offset * period\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if offset >= 1.0 or offset <= 0.0:\n        raise ValueError(f'The parameter offset should be a float within the range of (0,1), but got {offset}')\n\n    if isinstance(val, (torch.Tensor, np.ndarray)):\n        if isinstance(val, torch.Tensor):\n            if torch.any(torch.abs(val) > period):\n                warning(f'The input value is not within the range of (-{period}, {period}), but got {val}')\n\n        if isinstance(val, np.ndarray):\n            if np.any(np.abs(val) > period):\n                warning(f'The input value is not within the range of (-{period}, {period}), but got {val}')\n\n        return val - torch.floor(val / period + offset) * period\n    else:\n        raise TypeError(f'Input value should be either a Tensor or ndarray, but got {type(val)}')\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if offset + period <= 1:\n        raise ValueError('(offset + period) should be greater than 1')\n    return val - torch.floor(val / period + offset) * period\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, (torch.Tensor, np.ndarray)):\n        val_out = val - torch.floor(val / period + offset) * period\n    else:\n        raise TypeError('Only support torch.Tensor or np.ndarray')\n    return val_out\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if not isinstance(val, (torch.Tensor, np.ndarray)):\n        raise TypeError(f\"Input val must be either Tensor or ndarray, got {type(val)}.\")\n\n    if isinstance(val, np.ndarray):\n        val = torch.from_numpy(val)\n\n    if torch.is_tensor(val):\n        if val.dim() == 0:\n            return val\n        else:\n            return torch.fmod(val + offset * period, period)\n    else:\n        raise TypeError(f\"Input val must be either Tensor or ndarray, got {type(val)}.\")\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, np.ndarray):\n        val_shape = val.shape\n    else:\n        val_shape = val.size()\n\n    if len(val_shape) == 0:\n        # scalar value\n        val_ori = val\n        val = (val - offset * period) % period\n        val = offset * period + (val + (period / 2)) % period\n        if val_ori - val > period / 2:\n            val += period\n    else:\n        # val is a np.ndarray or torch.Tensor\n        val_ori = val\n        val = (val - offset * period) % period\n        val = offset * period + (val + (period / 2)) % period\n        mask = (val - offset * period) > period / 2\n        val[mask] += period\n\n    return val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, torch.Tensor):\n        if torch.is_floating_point(val):\n            return val - torch.floor(val / period + offset) * period\n        else:\n            return val - (val // period + offset) * period\n    elif isinstance(val, np.ndarray):\n        return val - np.floor(val / period + offset) * period\n    else:\n        raise TypeError(f'Incorrect type of val:{type(val)}!')\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if not isinstance(val, (torch.Tensor, np.ndarray)):\n        raise TypeError(f\"Input val must be either Tensor or ndarray, got {type(val)}.\")\n\n    if isinstance(val, torch.Tensor):\n        return val - torch.floor(val / period + offset) * period\n    else:\n        return val - np.floor(val / period + offset) * period\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, np.ndarray):\n        return np.mod(val + offset * period, period) - offset * period\n    elif isinstance(val, torch.Tensor):\n        return torch.fmod(val + offset * period, period) - offset * period\n    else:\n        raise TypeError(\"Input val must be torch.Tensor or np.ndarray.\")\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, torch.Tensor):\n        if not val.is_floating_point():\n            val = val.to(torch.float32)\n        val = val - torch.floor(val / period + offset) * period\n    else:\n        val = val - np.floor(val / period + offset) * period\n    return val\n\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        return {\n            'dynamic_prompt': agent.dynamic_prompt,\n            'purpose': agent.purpose,\n            'purpose_embedding': agent.purpose_embedding.tolist(),\n            'depth': agent.depth,\n            'max_depth': agent.max_depth,\n            'usage_count': agent.usage_count,\n            'id': agent.id,\n            'parent_id': agent.parent_id,\n            'working_agent': agent.working_agent,\n            'is_prime': agent.is_prime,\n            'evolve_count': agent.evolve_count,\n            'number_of_code_executions': agent.number_of_code_executions,\n            'last_input': agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if agent.purpose_embedding is not None:\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n        return {\n            'dynamic_prompt': agent.dynamic_prompt,\n            'purpose': agent.purpose,\n            'purpose_embedding': agent.purpose_embedding,\n            'depth': agent.depth,\n            'max_depth': agent.max_depth,\n            'usage_count': agent.usage_count,\n            'id': agent.id,\n            'parent_id': agent.parent_id,\n            'working_agent': agent.working_agent,\n            'is_prime': agent.is_prime,\n            'evolve_count': agent.evolve_count,\n            'number_of_code_executions': agent.number_of_code_executions,\n            'last_input': agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        # convert purpose_embedding from numpy array to list\n        if type(agent.purpose_embedding) == np.ndarray:\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n\n        return {\n            'dynamic_prompt': agent.dynamic_prompt,\n            'purpose': agent.purpose,\n            'purpose_embedding': agent.purpose_embedding,\n            'depth': agent.depth,\n            'max_depth': agent.max_depth,\n            'usage_count': agent.usage_count,\n            'id': agent.id,\n            'parent_id': agent.parent_id,\n            'working_agent': agent.working_agent,\n            'is_prime': agent.is_prime,\n            'evolve_count': agent.evolve_count,\n            'number_of_code_executions': agent.number_of_code_executions,\n            'last_input': agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent, MicroAgent):\n            return {\n                \"dynamic_prompt\": agent.dynamic_prompt,\n                \"purpose\": agent.purpose,\n                \"purpose_embedding\": agent.purpose_embedding.tolist() if isinstance(agent.purpose_embedding, np.ndarray) else agent.purpose_embedding,\n                \"depth\": agent.depth,\n                \"max_depth\": agent.max_depth,\n                \"usage_count\": agent.usage_count,\n                \"id\": agent.id,\n                \"parent_id\": agent.parent_id,\n                \"working_agent\": agent.working_agent,\n                \"is_prime\": agent.is_prime,\n                \"evolve_count\": agent.evolve_count,\n                \"number_of_code_executions\": agent.number_of_code_executions,\n                \"last_input\": agent.last_input\n            }\n        else:\n            raise TypeError(\"The agent must be a MicroAgent instance.\")\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent, MicroAgent):\n            return {\n                'dynamic_prompt': agent.dynamic_prompt,\n                'purpose': agent.purpose,\n                'purpose_embedding': agent.purpose_embedding.tolist() if isinstance(agent.purpose_embedding, np.ndarray) else agent.purpose_embedding,\n                'depth': agent.depth,\n                'max_depth': agent.max_depth,\n                'usage_count': agent.usage_count,\n                'id': agent.id,\n                'parent_id': agent.parent_id,\n                'working_agent': agent.working_agent,\n                'is_prime': agent.is_prime,\n                'evolve_count': agent.evolve_count,\n                'number_of_code_executions': agent.number_of_code_executions,\n                'last_input': agent.last_input\n            }\n        else:\n            raise TypeError('Argument is not of type MicroAgent.')\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent, MicroAgent):\n            return {\n                'dynamic_prompt': agent.dynamic_prompt,\n                'purpose': agent.purpose,\n                'purpose_embedding': agent.purpose_embedding.tolist(),\n                'depth': agent.depth,\n                'max_depth': agent.max_depth,\n                'usage_count': agent.usage_count,\n                'id': agent.id,\n                'parent_id': agent.parent_id,\n                'working_agent': agent.working_agent,\n                'is_prime': agent.is_prime,\n                'evolve_count': agent.evolve_count,\n                'number_of_code_executions': agent.number_of_code_executions,\n                'last_input': agent.last_input\n            }\n        else:\n            raise TypeError('The agent must be a MicroAgent object.')\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if not isinstance(agent, MicroAgent):\n            raise TypeError('The agent parameter is not of type MicroAgent.')\n\n        return {\n            'dynamic_prompt': agent.dynamic_prompt,\n            'purpose': agent.purpose,\n            'purpose_embedding': agent.purpose_embedding.tolist(),\n            'depth': agent.depth,\n            'max_depth': agent.max_depth,\n            'usage_count': agent.usage_count,\n            'id': agent.id,\n            'parent_id': agent.parent_id,\n            'working_agent': agent.working_agent,\n            'is_prime': agent.is_prime,\n            'evolve_count': agent.evolve_count,\n            'number_of_code_executions': agent.number_of_code_executions,\n            'last_input': agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if not isinstance(agent, MicroAgent):\n            raise TypeError(\"The agent argument must be of type MicroAgent.\")\n\n        agent_dict = {}\n        agent_dict[\"dynamic_prompt\"] = agent.dynamic_prompt\n        agent_dict[\"purpose\"] = agent.purpose\n        agent_dict[\"purpose_embedding\"] = agent.purpose_embedding.tolist() if agent.purpose_embedding is not None else None\n        agent_dict[\"depth\"] = agent.depth\n        agent_dict[\"max_depth\"] = agent.max_depth\n        agent_dict[\"usage_count\"] = agent.usage_count\n        agent_dict[\"id\"] = agent.id\n        agent_dict[\"parent_id\"] = agent.parent_id\n        agent_dict[\"working_agent\"] = agent.working_agent\n        agent_dict[\"is_prime\"] = agent.is_prime\n        agent_dict[\"evolve_count\"] = agent.evolve_count\n        agent_dict[\"number_of_code_executions\"] = agent.number_of_code_executions\n        agent_dict[\"last_input\"] = agent.last_input\n\n        return agent_dict\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        # If the purpose embedding is a numpy array, convert it to a list to ensure compatibility with serialization formats.\n        if isinstance(agent.purpose_embedding, np.ndarray):\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n\n        # Return a dictionary representation of the MicroAgent instance, including all relevant attributes such as dynamic_prompt, purpose, purpose_embedding, depth, max_depth, usage_count, id, parent_id, working_agent, is_prime, evolve_count, number_of_code_executions, and last_input.\n        return {\n            'dynamic_prompt': agent.dynamic_prompt,\n            'purpose': agent.purpose,\n            'purpose_embedding': agent.purpose_embedding,\n            'depth': agent.depth,\n            'max_depth': agent.max_depth,\n            'usage_count': agent.usage_count,\n            'id': agent.id,\n            'parent_id': agent.parent_id,\n            'working_agent': agent.working_agent,\n            'is_prime': agent.is_prime,\n            'evolve_count': agent.evolve_count,\n            'number_of_code_executions': agent.number_of_code_executions,\n            'last_input': agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        # If the purpose_embedding is a numpy array, convert to list for persistence\n        if isinstance(agent.purpose_embedding, np.ndarray):\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n\n        return {\n            'dynamic_prompt': agent.dynamic_prompt,\n            'purpose': agent.purpose,\n            'purpose_embedding': agent.purpose_embedding,\n            'depth': agent.depth,\n            'max_depth': agent.max_depth,\n            'usage_count': agent.usage_count,\n            'id': agent.id,\n            'parent_id': agent.parent_id,\n            'working_agent': agent.working_agent,\n            'is_prime': agent.is_prime,\n            'evolve_count': agent.evolve_count,\n            'number_of_code_executions': agent.number_of_code_executions,\n            'last_input': agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        # Check if the purpose_embedding is a numpy array. If so, convert to a list.\n        if isinstance(agent.purpose_embedding, np.ndarray):\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n\n        # Create a dictionary representation of the MicroAgent instance.\n        agent_dict = {\n            'dynamic_prompt': agent.dynamic_prompt,\n            'purpose': agent.purpose,\n            'purpose_embedding': agent.purpose_embedding,\n            'depth': agent.depth,\n            'max_depth': agent.max_depth,\n            'usage_count': agent.usage_count,\n            'id': agent.id,\n            'parent_id': agent.parent_id,\n            'working_agent': agent.working_agent,\n            'is_prime': agent.is_prime,\n            'evolve_count': agent.evolve_count,\n            'number_of_code_executions': agent.number_of_code_executions,\n            'last_input': agent.last_input\n        }\n\n        return agent_dict\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent, MicroAgent):\n            return {\n                'dynamic_prompt': agent.dynamic_prompt,\n                'purpose': agent.purpose,\n                'purpose_embedding': agent.purpose_embedding.tolist() if isinstance(agent.purpose_embedding, np.ndarray) else agent.purpose_embedding,\n                'depth': agent.depth,\n                'max_depth': agent.max_depth,\n                'usage_count': agent.usage_count,\n                'id': agent.id,\n                'parent_id': agent.parent_id,\n                'working_agent': agent.working_agent,\n                'is_prime': agent.is_prime,\n                'evolve_count': agent.evolve_count,\n                'number_of_code_executions': agent.number_of_code_executions,\n                'last_input': agent.last_input\n            }\n        else:\n            return {}\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        return {\n            'dynamic_prompt': agent.dynamic_prompt,\n            'purpose': agent.purpose,\n            'purpose_embedding': agent.purpose_embedding.tolist() if isinstance(agent.purpose_embedding, np.ndarray) else agent.purpose_embedding,\n            'depth': agent.depth,\n            'max_depth': agent.max_depth,\n            'usage_count': agent.usage_count,\n            'id': agent.id,\n            'parent_id': agent.parent_id,\n            'working_agent': agent.working_agent,\n            'is_prime': agent.is_prime,\n            'evolve_count': agent.evolve_count,\n            'number_of_code_executions': agent.number_of_code_executions,\n            'last_input': agent.last_input,\n            'last_output': agent.last_output\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent, MicroAgent):\n            agent_dict = {}\n            agent_dict['dynamic_prompt'] = agent.dynamic_prompt\n            agent_dict['purpose'] = agent.purpose\n            agent_dict['purpose_embedding'] = agent.purpose_embedding.tolist() if isinstance(agent.purpose_embedding, np.ndarray) else agent.purpose_embedding\n            agent_dict['depth'] = agent.depth\n            agent_dict['max_depth'] = agent.max_depth\n            agent_dict['usage_count'] = agent.usage_count\n            agent_dict['id'] = agent.id\n            agent_dict['parent_id'] = agent.parent_id\n            agent_dict['working_agent'] = agent.working_agent\n            agent_dict['is_prime'] = agent.is_prime\n            agent_dict['evolve_count'] = agent.evolve_count\n            agent_dict['number_of_code_executions'] = agent.number_of_code_executions\n            agent_dict['last_input'] = agent.last_input\n            return agent_dict\n        else:\n            raise TypeError('The argument to serialize must be of type MicroAgent.')\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if not isinstance(agent, MicroAgent):\n            raise TypeError(\"agent must be a MicroAgent object\")\n\n        if not isinstance(agent.purpose_embedding, np.ndarray):\n            raise TypeError(\"agent.purpose_embedding must be a numpy array\")\n\n        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding.tolist(),\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input,\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if not isinstance(agent, MicroAgent):\n            raise TypeError(\"AgentSerializer.to_dict() accepts only MicroAgent instances as input. Please check your inputs.\")\n\n        if isinstance(agent.purpose_embedding, np.ndarray):\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n\n        return {\n            'dynamic_prompt': agent.dynamic_prompt,\n            'purpose': agent.purpose,\n            'purpose_embedding': agent.purpose_embedding,\n            'depth': agent.depth,\n            'max_depth': agent.max_depth,\n            'usage_count': agent.usage_count,\n            'id': agent.id,\n            'parent_id': agent.parent_id,\n            'working_agent': agent.working_agent,\n            'is_prime': agent.is_prime,\n            'evolve_count': agent.evolve_count,\n            'number_of_code_executions': agent.number_of_code_executions,\n            'last_input': agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if not isinstance(agent, MicroAgent):\n            raise TypeError(\"AgentSerializer.to_dict() expects a MicroAgent as input\")\n\n        if isinstance(agent.purpose_embedding, np.ndarray):\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n\n        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        # convert the purpose_embedding from a numpy array to a list if necessary\n        if isinstance(agent.purpose_embedding, np.ndarray):\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n\n        return {\n            'dynamic_prompt': agent.dynamic_prompt,\n            'purpose': agent.purpose,\n            'purpose_embedding': agent.purpose_embedding,\n            'depth': agent.depth,\n            'max_depth': agent.max_depth,\n            'usage_count': agent.usage_count,\n            'id': agent.id,\n            'parent_id': agent.parent_id,\n            'working_agent': agent.working_agent,\n            'is_prime': agent.is_prime,\n            'evolve_count': agent.evolve_count,\n            'number_of_code_executions': agent.number_of_code_executions,\n            'last_input': agent.last_input,\n            'code': agent.code\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        # Convert purpose_embedding from numpy array to list if necessary\n        if isinstance(agent.purpose_embedding, np.ndarray):\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n\n        # Create dictionary representation of agent\n        return {\n            'dynamic_prompt': agent.dynamic_prompt,\n            'purpose': agent.purpose,\n            'purpose_embedding': agent.purpose_embedding,\n            'depth': agent.depth,\n            'max_depth': agent.max_depth,\n            'usage_count': agent.usage_count,\n            'id': agent.id,\n            'parent_id': agent.parent_id,\n            'working_agent': agent.working_agent,\n            'is_prime': agent.is_prime,\n            'evolve_count': agent.evolve_count,\n            'number_of_code_executions': agent.number_of_code_executions,\n            'last_input': agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if not isinstance(agent, MicroAgent):\n            raise TypeError('Argument is not of type MicroAgent.')\n\n        dict_agent = agent.__dict__\n\n        if isinstance(dict_agent['purpose_embedding'], np.ndarray):\n            dict_agent['purpose_embedding'] = dict_agent['purpose_embedding'].tolist()\n\n        return dict_agent\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    assert len(items) == len(weights)\n    assert num_bins > 0\n\n    bin_to_items = defaultdict(list)\n    bin_to_total_weight = defaultdict(int)\n\n    for item, weight in zip(items, weights):\n        bin_index = min(bin_to_total_weight, key=bin_to_total_weight.get)\n        bin_to_items[bin_index].append(item)\n        bin_to_total_weight[bin_index] += weight\n\n    return bin_to_items, bin_to_total_weight\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Check that the number of items and weights match.\n    assert len(items) == len(weights), \"The number of items and weights must match.\"\n\n    # Check that the number of bins is positive.\n    assert num_bins > 0, \"The number of bins must be positive.\"\n\n    # Check that all weights are positive.\n    assert all(weight > 0 for weight in weights), \"All weights must be positive.\"\n\n    # Check that the number of bins is not greater than the number of items.\n    assert num_bins <= len(items), \"The number of bins cannot be greater than the number of items.\"\n\n    # Sort the items by weight in descending order.\n    items_sorted = sorted(items, key=lambda item: weights[items.index(item)], reverse=True)\n\n    # Create a dictionary that maps each bin index to a list of items that have been placed in that bin.\n    bins_to_items = defaultdict(list)\n\n    # Create a dictionary that maps each bin index to the total weight of the items in that bin.\n    bins_to_total_weight = defaultdict(int)\n\n    # Loop through the items in descending order of weight.\n    for item in items_sorted:\n\n        # Find the bin with the lowest total weight.\n        min_bin_index = min(bins_to_total_weight, key=bins_to_total_weight.get)\n\n        # Add the item to the bin with the lowest total weight.\n        bins_to_items[min_bin_index].append(item)\n\n        # Update the total weight of the bin with the lowest total weight.\n        bins_to_total_weight[min_bin_index] += weights[items.index(item)]\n\n    return bins_to_items, bins_to_total_weight\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    assert len(items) == len(weights) and num_bins > 0\n\n    # Sort the items by weight in descending order.\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Initialize the dictionaries that will be returned by the function.\n    bin_to_items_map = defaultdict(list)\n    bin_to_weight_map = defaultdict(int)\n\n    # Iterate through the sorted items.\n    for item, weight in sorted_items:\n\n        # Find the bin with the lowest total weight.\n        min_bin_index = min(bin_to_weight_map, key=bin_to_weight_map.get)\n\n        # Add the item to the bin.\n        bin_to_items_map[min_bin_index].append(item)\n        bin_to_weight_map[min_bin_index] += weight\n\n    return bin_to_items_map, bin_to_weight_map\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    assert len(items) == len(weights)\n    assert len(items) > 0\n    assert num_bins > 0\n    assert len(weights) == len(set(weights))\n    assert all(weight > 0 for weight in weights)\n\n    # Sort the items by weight in descending order.\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Create a dictionary that maps each bin index to a list of items that have been placed in that bin.\n    bin_to_items_mapping: Dict[int, List[Any]] = defaultdict(list)\n\n    # Create a dictionary that maps each bin index to the total weight of the items in that bin.\n    bin_to_weight_mapping: Dict[int, int] = defaultdict(int)\n\n    # Place each item into the bin with the current lowest total weight.\n    for item, weight in sorted_items:\n        min_bin_index = min(bin_to_weight_mapping, key=bin_to_weight_mapping.get)\n        bin_to_items_mapping[min_bin_index].append(item)\n        bin_to_weight_mapping[min_bin_index] += weight\n\n    return bin_to_items_mapping, bin_to_weight_mapping\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    assert len(items) == len(weights)\n    assert num_bins > 0\n    assert all(weight > 0 for weight in weights)\n\n    # Sort the items by weight in descending order.\n    items_sorted_by_weight = [item for _, item in sorted(zip(weights, items), key=lambda pair: pair[0], reverse=True)]\n\n    # Initialize a dictionary that maps each bin index to a list of items that have been placed in that bin.\n    bins_to_items = defaultdict(list)\n\n    # Initialize a dictionary that maps each bin index to the total weight of the items in that bin.\n    bins_to_total_weight = defaultdict(int)\n\n    # Initialize a list that will be used to keep track of the bin indices that are currently available for receiving items.\n    available_bin_indices = list(range(num_bins))\n\n    # Iterate over the items in descending order of weight.\n    for item in items_sorted_by_weight:\n\n        # Find the bin index that has the current lowest total weight.\n        bin_index = min(available_bin_indices, key=lambda bin_index: bins_to_total_weight[bin_index])\n\n        # Add the item to the bin.\n        bins_to_items[bin_index].append(item)\n\n        # Update the total weight of the bin.\n        bins_to_total_weight[bin_index] += weights[items.index(item)]\n\n        # Remove the bin index from the list of available bin indices if it is now full.\n        if bins_to_total_weight[bin_index] == sum(weights) / num_bins:\n            available_bin_indices.remove(bin_index)\n\n    return bins_to_items, bins_to_total_weight\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # check that the input lists have the same length\n    if len(items) != len(weights):\n        raise ValueError(\"The items and weights lists must have the same length.\")\n\n    # check that the number of bins is positive\n    if num_bins <= 0:\n        raise ValueError(\"The number of bins must be positive.\")\n\n    # check that the weights are positive\n    if any(w <= 0 for w in weights):\n        raise ValueError(\"The weights must be positive.\")\n\n    # sort the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # initialize the output dictionaries\n    bins_to_items = {i: [] for i in range(num_bins)}\n    bins_to_weights = {i: 0 for i in range(num_bins)}\n\n    # distribute the items greedily\n    for item, weight in sorted_items:\n        # find the bin with the lowest total weight\n        min_bin = min(bins_to_weights, key=bins_to_weights.get)\n        # add the item to the bin\n        bins_to_items[min_bin].append(item)\n        bins_to_weights[min_bin] += weight\n\n    return bins_to_items, bins_to_weights\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    if len(items) != len(weights):\n        raise ValueError(\"The length of the 'items' list must be equal to the length of the 'weights' list\")\n\n    if num_bins < 1:\n        raise ValueError(\"The number of bins must be positive\")\n\n    if len(items) == 0:\n        return {}, {}\n\n    for weight in weights:\n        if weight <= 0:\n            raise ValueError(\"The weight of each item must be positive\")\n\n    item_to_weight = dict(zip(items, weights))\n    items_sorted_by_weight = sorted(items, key=lambda x: item_to_weight[x], reverse=True)\n\n    bin_to_items: Dict[int, List[Any]] = defaultdict(list)\n    bin_to_weight: Dict[int, int] = defaultdict(int)\n\n    for item in items_sorted_by_weight:\n        lightest_bin = min(bin_to_weight, key=bin_to_weight.get)\n        bin_to_items[lightest_bin].append(item)\n        bin_to_weight[lightest_bin] += item_to_weight[item]\n\n    return bin_to_items, bin_to_weight\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Check if the number of bins is positive\n    if num_bins <= 0:\n        raise ValueError(\"Number of bins must be positive.\")\n\n    # Check if the number of weights is equal to the number of items\n    if len(weights) != len(items):\n        raise ValueError(\"Number of weights must be equal to the number of items.\")\n\n    # Check if the weights are positive\n    if any(weight <= 0 for weight in weights):\n        raise ValueError(\"Weights must be positive.\")\n\n    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Create a dictionary that maps each bin index to a list of items that have been placed in that bin\n    bins = defaultdict(list)\n\n    # Create a dictionary that maps each bin index to the total weight of the items in that bin\n    bin_weights = defaultdict(int)\n\n    # Place each item greedily into the bin with the current lowest total weight\n    for item, weight in sorted_items:\n        # Find the bin index with the current lowest total weight\n        bin_index = min(bin_weights, key=bin_weights.get)\n\n        # Place the item into the bin with the current lowest total weight\n        bins[bin_index].append(item)\n        bin_weights[bin_index] += weight\n\n    return bins, bin_weights\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    assert len(items) == len(weights)\n    assert num_bins > 0\n    assert len(items) >= num_bins\n    assert len(weights) >= num_bins\n    assert all(weight > 0 for weight in weights)\n\n    items_by_bin = defaultdict(list)\n    weights_by_bin = defaultdict(int)\n\n    # sort items by weight in descending order\n    items_sorted_by_weight = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    for item, weight in items_sorted_by_weight:\n        # find bin with current lowest total weight\n        bin_index = min(weights_by_bin, key=weights_by_bin.get)\n        items_by_bin[bin_index].append(item)\n        weights_by_bin[bin_index] += weight\n\n    return items_by_bin, weights_by_bin\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Check that the lists of items and weights are of the same length\n    assert len(items) == len(weights)\n\n    # Check that the number of bins is positive\n    assert num_bins > 0\n\n    # Check that the weights are positive\n    assert all(weight > 0 for weight in weights)\n\n    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Initialize a dictionary that maps each bin index to a list of items that have been placed in that bin\n    bins = defaultdict(list)\n\n    # Initialize a dictionary that maps each bin index to the total weight of the items in that bin\n    bin_weights = defaultdict(int)\n\n    # Loop over the sorted items\n    for item, weight in sorted_items:\n\n        # Find the bin with the lowest total weight\n        min_bin = min(bin_weights, key=bin_weights.get)\n\n        # Add the item to the bin\n        bins[min_bin].append(item)\n\n        # Update the total weight of the bin\n        bin_weights[min_bin] += weight\n\n    # Return the dictionary of bins and the dictionary of bin weights\n    return bins, bin_weights\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Check that the input lists have the same length.\n    if len(items) != len(weights):\n        raise ValueError('The items and weights lists must have the same length.')\n\n    # Check that the number of bins is positive.\n    if num_bins <= 0:\n        raise ValueError('The number of bins must be positive.')\n\n    # Check that all the weights are positive.\n    if any(weight <= 0 for weight in weights):\n        raise ValueError('All weights must be positive.')\n\n    # Sort the items and weights by weight in descending order.\n    sorted_items = [item for _, item in sorted(zip(weights, items), key=lambda pair: pair[0], reverse=True)]\n    sorted_weights = sorted(weights, reverse=True)\n\n    # Initialize a dictionary that maps each bin index to a list of items that have been placed in that bin.\n    bins_to_items = defaultdict(list)\n\n    # Initialize a dictionary that maps each bin index to the total weight of the items in that bin.\n    bins_to_total_weight = defaultdict(int)\n\n    # Distribute the items greedily into the bins.\n    for item, weight in zip(sorted_items, sorted_weights):\n        # Find the bin with the lowest total weight.\n        min_bin_index = min(bins_to_total_weight, key=bins_to_total_weight.get)\n        # Add the current item to the bin.\n        bins_to_items[min_bin_index].append(item)\n        # Update the total weight of the bin.\n        bins_to_total_weight[min_bin_index] += weight\n\n    return bins_to_items, bins_to_total_weight\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    assert len(items) == len(weights)\n    assert num_bins > 0\n\n    # Sort items by weight in descending order\n    sorted_items = [item for _, item in sorted(zip(weights, items), key=lambda pair: -pair[0])]\n    sorted_weights = sorted(weights, reverse=True)\n\n    # Initialize dictionary that maps bin indices to a list of items\n    bins_to_items: Dict[int, List[Any]] = defaultdict(list)\n\n    # Initialize dictionary that maps bin indices to the total weight of the items in that bin\n    bins_to_weight: Dict[int, int] = defaultdict(int)\n\n    # Greedily pack items into bins\n    for item, weight in zip(sorted_items, sorted_weights):\n        # Find bin with the lowest total weight\n        bin_index = min(bins_to_weight, key=bins_to_weight.get)\n        bins_to_items[bin_index].append(item)\n        bins_to_weight[bin_index] += weight\n\n    return bins_to_items, bins_to_weight\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Check that the number of items is equal to the number of weights.\n    if len(items) != len(weights):\n        raise ValueError(f\"The number of items ({len(items)}) is not equal to the number of weights ({len(weights)}).\")\n\n    # Check that the number of bins is positive.\n    if num_bins <= 0:\n        raise ValueError(f\"The number of bins ({num_bins}) must be positive.\")\n\n    # Check that the weights are positive.\n    if any(weight <= 0 for weight in weights):\n        raise ValueError(f\"The weights ({weights}) must be positive.\")\n\n    # Check that the number of bins is not greater than the number of items.\n    if num_bins > len(items):\n        raise ValueError(f\"The number of bins ({num_bins}) is greater than the number of items ({len(items)}).\")\n\n    # Sort the items by weight in descending order.\n    sorted_items_and_weights = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Initialize a dictionary that maps each bin index to a list of items that have been placed in that bin.\n    bins_to_items = defaultdict(list)\n\n    # Initialize a dictionary that maps each bin index to the total weight of the items in that bin.\n    bins_to_weights = defaultdict(int)\n\n    # Initialize a list of bin indices.\n    bin_indices = list(range(num_bins))\n\n    # Initialize a list of bin weights.\n    bin_weights = [0] * num_bins\n\n    # Iterate over the items and weights.\n    for item, weight in sorted_items_and_weights:\n\n        # Find the bin with the lowest weight.\n        bin_index = bin_indices[bin_weights.index(min(bin_weights))]\n\n        # Add the item to the bin.\n        bins_to_items[bin_index].append(item)\n\n        # Update the bin weight.\n       "}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Check if the number of items is equal to the number of weights.\n    if len(items) != len(weights):\n        raise ValueError('The number of items is not equal to the number of weights.')\n\n    # Check if all weights are positive.\n    if any(weight <= 0 for weight in weights):\n        raise ValueError('All weights must be positive.')\n\n    # Check if the number of bins is positive.\n    if num_bins <= 0:\n        raise ValueError('The number of bins must be positive.')\n\n    # Check if the number of bins is greater than or equal to the number of items.\n    if num_bins < len(items):\n        raise ValueError('The number of bins must be greater than or equal to the number of items.')\n\n    # Sort the items by weight in descending order.\n    sorted_items = [item for _, item in sorted(zip(weights, items), key=lambda pair: pair[0], reverse=True)]\n\n    # Create a dictionary that maps each bin index to a list of items that have been placed in that bin.\n    bins_to_items = defaultdict(list)\n\n    # Create a dictionary that maps each bin index to the total weight of the items in that bin.\n    bins_to_total_weight = defaultdict(int)\n\n    # Initialize a bin index.\n    bin_index = 0\n\n    # Iterate over the sorted items.\n    for item in sorted_items:\n\n        # Add the current item to the current bin.\n        bins_to_items[bin_index].append(item)\n\n        # Increment the total weight of the current bin by the weight of the current item.\n        bins_to_total_weight[bin_index] += weights[items.index(item)]\n\n        # Increment the bin index.\n        bin_index = bin_index + 1\n\n        # Reset the bin index if it is equal to the number of bins.\n        bin_index = 0 if bin_index == num_bins else bin_index\n\n    return bins_to_items,"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Check if the input arguments are valid\n    if len(items) != len(weights):\n        raise ValueError(\"The number of items does not match the number of weights provided.\")\n\n    if num_bins <= 0:\n        raise ValueError(\"The number of bins must be positive.\")\n\n    if not all(weight > 0 for weight in weights):\n        raise ValueError(\"All weights must be positive.\")\n\n    # Sort the items by weight in descending order\n    items_sorted = sorted(zip(items, weights), key=lambda item: item[1], reverse=True)\n\n    # Initialize a dictionary that maps each bin index to a list of items that have been placed in that bin\n    bins: Dict[int, List[Any]] = defaultdict(list)\n\n    # Initialize a dictionary that maps each bin index to the total weight of the items in that bin\n    bin_weights: Dict[int, int] = defaultdict(int)\n\n    # Iterate over the items\n    for item, weight in items_sorted:\n\n        # Find the bin with the lowest total weight\n        min_bin = min(bin_weights, key=bin_weights.get)\n\n        # Add the item to the bin\n        bins[min_bin].append(item)\n\n        # Update the total weight of the bin\n        bin_weights[min_bin] += weight\n\n    return bins, bin_weights\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    assert len(items) == len(weights)\n    assert num_bins >= 1\n\n    # sort the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # create a dictionary that maps each bin index to a list of items\n    # that have been placed in that bin\n    bins_to_items = defaultdict(list)\n\n    # create a dictionary that maps each bin index to the total weight of\n    # the items in that bin\n    bins_to_weight = defaultdict(int)\n\n    # iterate through the items\n    for item, weight in sorted_items:\n\n        # initialize a flag that indicates whether the item has been placed\n        # into a bin\n        item_placed = False\n\n        # iterate through the bins\n        for bin_index in range(num_bins):\n\n            # check if the total weight of the bin plus the weight of the item\n            # does not exceed the maximum bin weight\n            if bins_to_weight[bin_index] + weight <= max_bin_weight:\n\n                # add the item to the bin\n                bins_to_items[bin_index].append(item)\n\n                # update the total weight of the bin\n                bins_to_weight[bin_index] += weight\n\n                # set the flag to True\n                item_placed = True\n\n                # break from the loop\n                break\n\n        # check if the item has not been placed into a bin\n        if not item_placed:\n\n            # raise an error\n            raise ValueError(\"Could not place item into a bin.\")\n\n    # return the dictionaries\n    return bins_to_items, bins_to_weight\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    if len(items) != len(weights):\n        raise ValueError(\"The number of items does not match the number of weights\")\n    if num_bins <= 0:\n        raise ValueError(\"The number of bins must be positive\")\n\n    # Sort the items by weight in descending order\n    sorted_indices = sorted(range(len(weights)), key=lambda i: weights[i], reverse=True)\n    items = [items[i] for i in sorted_indices]\n    weights = [weights[i] for i in sorted_indices]\n\n    # Initialize the output dictionaries\n    items_in_bins: Dict[int, List[Any]] = defaultdict(list)\n    weight_in_bins: Dict[int, int] = defaultdict(int)\n\n    # Distribute the items greedily into bins\n    for item, weight in zip(items, weights):\n        min_bin_index = min(weight_in_bins, key=weight_in_bins.get)\n        items_in_bins[min_bin_index].append(item)\n        weight_in_bins[min_bin_index] += weight\n\n    return items_in_bins, weight_in_bins\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    if len(items) != len(weights):\n        raise ValueError(\"The length of the 'items' list must be equal to the length of the 'weights' list.\")\n    if num_bins <= 0:\n        raise ValueError(\"The number of bins must be positive.\")\n    if len(items) == 0:\n        return {}, {}\n    if len(items) < num_bins:\n        raise ValueError(\"The number of bins must be less than or equal to the number of items.\")\n\n    # Sort the items by weight in descending order.\n    sorted_items = sorted(range(len(items)), key=lambda i: weights[i], reverse=True)\n\n    # Initialize the dictionaries that will be returned by the function.\n    bin_to_items_map = defaultdict(list)\n    bin_to_total_weight_map = defaultdict(int)\n\n    # Loop over the sorted items.\n    for item_index in sorted_items:\n\n        # Initialize a flag that indicates whether or not the item has been placed into a bin.\n        item_placed = False\n\n        # Loop over the bins.\n        for bin_index in range(num_bins):\n\n            # Check if the item can be placed into the bin.\n            if bin_to_total_weight_map[bin_index] + weights[item_index] <= weights[item_index]:\n\n                # Place the item into the bin.\n                bin_to_items_map[bin_index].append(items[item_index])\n                bin_to_total_weight_map[bin_index] += weights[item_index]\n\n                # Mark that the item has been placed.\n                item_placed = True\n\n                # Break out of the loop since the item has been placed.\n                break\n\n        # Check if the item has not been placed.\n        if not item_placed:\n\n            # Place the item into the bin with the lowest weight.\n            bin_to_items_map[bin_index].append(items[item_index])\n            bin_to_total_weight_map[bin_index] +="}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    if len(items) != len(weights):\n        raise ValueError(\"The number of items must be equal to the number of weights.\")\n\n    if num_bins <= 0:\n        raise ValueError(\"The number of bins must be positive.\")\n\n    if not all(weight > 0 for weight in weights):\n        raise ValueError(\"The weights must be positive.\")\n\n    if len(items) == 0:\n        return {}, {}\n\n    if num_bins == 1:\n        return {0: items}, {0: sum(weights)}\n\n    # sort the items in descending order of weight\n    sorted_items = sorted(range(len(items)), key=lambda x: -weights[x])\n\n    # initialize a dictionary that maps each bin index to a list of items that have been placed in that bin\n    bins: Dict[int, List[Any]] = defaultdict(list)\n\n    # initialize a dictionary that maps each bin index to the total weight of the items in that bin\n    bin_weights: Dict[int, int] = defaultdict(int)\n\n    # initialize a dictionary that maps each bin index to the total weight of the items in that bin\n    bin_weight_to_index: Dict[int, int] = defaultdict(int)\n\n    for item_index in sorted_items:\n\n        # find the bin with the lowest total weight\n        min_bin_index = min(bin_weight_to_index, key=bin_weight_to_index.get)\n\n        # add the item to the bin\n        bins[min_bin_index].append(items[item_index])\n\n        # update the total weight of the bin\n        bin_weights[min_bin_index] += weights[item_index]\n\n        # update the mapping from total weight to bin index\n        bin_weight_to_index[bin_weights[min_bin_index]] = min_bin_index\n\n    return bins, bin_weights\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    if len(items) != len(weights):\n        raise ValueError(\"The number of items and the number of weights do not match.\")\n\n    if num_bins <= 0:\n        raise ValueError(\"The number of bins must be positive.\")\n\n    if len(items) == 0:\n        return {}, {}\n\n    if len(items) == 1:\n        return {0: items}, {0: weights[0]}\n\n    if num_bins == 1:\n        return {0: items}, {0: sum(weights)}\n\n    if num_bins >= len(items):\n        return {bin_index: [item] for bin_index, item in enumerate(items)}, {bin_index: weight for bin_index, weight in enumerate(weights)}\n\n    # sort the items in descending order of weight\n    sorted_items = [item for _, item in sorted(zip(weights, items), key=lambda x: x[0], reverse=True)]\n\n    # sort the weights in descending order\n    sorted_weights = sorted(weights, reverse=True)\n\n    # initialize the bins\n    bins = {bin_index: [] for bin_index in range(num_bins)}\n    # initialize the total weight of the items in each bin\n    bins_total_weight = {bin_index: 0 for bin_index in range(num_bins)}\n\n    # place each item into the bin with the current lowest total weight\n    for item in sorted_items:\n        # find the bin with the lowest total weight\n        min_bin_index = min(bins_total_weight, key=bins_total_weight.get)\n        # place the item into that bin\n        bins[min_bin_index].append(item)\n        # update the total weight of the bin\n        bins_total_weight[min_bin_index] += sorted_weights[sorted_items.index(item)]\n\n    return bins, bins_total_weight\n\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = {\n            \"func_name\": func_name,\n            \"args\": args,\n            \"kwargs\": kwargs,\n        }\n        data_str = json.dumps(data, sort_keys=True, default=str)\n        data_bytes = data_str.encode(\"utf-8\")\n        hash = hashlib.sha256(data_bytes)\n        return hash.hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        arg_hash = hashlib.sha256()\n        arg_hash.update(func_name.encode(\"utf-8\"))\n        arg_hash.update(json.dumps(args).encode(\"utf-8\"))\n        arg_hash.update(json.dumps(kwargs).encode(\"utf-8\"))\n        return arg_hash.hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = {\n            \"func_name\": func_name,\n            \"args\": args,\n            \"kwargs\": kwargs\n        }\n        return hashlib.sha256(json.dumps(data).encode(\"utf-8\")).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        return hashlib.sha256(json.dumps(data).encode(\"utf-8\")).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = {\n            \"func_name\": func_name,\n            \"args\": args,\n            \"kwargs\": kwargs\n        }\n        data_str = json.dumps(data, sort_keys=True)\n        return hashlib.sha256(data_str.encode(\"utf-8\")).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        arg_hash = hashlib.sha256()\n        arg_hash.update(func_name.encode())\n        arg_hash.update(json.dumps(args).encode())\n        arg_hash.update(json.dumps(kwargs).encode())\n        return arg_hash.hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = [func_name, args, kwargs]\n        data_json = json.dumps(data, sort_keys=True, default=str)\n        return hashlib.sha256(data_json.encode(\"utf-8\")).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = [func_name, args, kwargs]\n        data_str = json.dumps(data, sort_keys=True)\n        return hashlib.sha256(data_str.encode(\"utf-8\")).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        # Hash the function name.\n        hasher = hashlib.sha256()\n        hasher.update(func_name.encode(\"utf-8\"))\n        data = hasher.digest()\n\n        # Hash the positional arguments.\n        for arg in args:\n            hasher = hashlib.sha256()\n            hasher.update(arg.encode(\"utf-8\"))\n            data += hasher.digest()\n\n        # Hash the keyword arguments.\n        for key, value in kwargs.items():\n            hasher = hashlib.sha256()\n            hasher.update(key.encode(\"utf-8\"))\n            hasher.update(value.encode(\"utf-8\"))\n            data += hasher.digest()\n\n        # Hash the data and return the hexadecimal digest.\n        hasher = hashlib.sha256()\n        hasher.update(data)\n        return hasher.hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = {\n            \"func_name\": func_name,\n            \"args\": args,\n            \"kwargs\": kwargs,\n        }\n        data_str = json.dumps(data, sort_keys=True, default=str)\n        data_bytes = data_str.encode(\"utf-8\")\n        hash = hashlib.sha256(data_bytes).hexdigest()\n        return hash\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = {\n            \"func_name\": func_name,\n            \"args\": args,\n            \"kwargs\": kwargs,\n        }\n        data_as_str = json.dumps(data, sort_keys=True, default=str)\n        return hashlib.sha256(data_as_str.encode(\"utf-8\")).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        hash_obj = hashlib.sha256()\n        hash_obj.update(func_name.encode(\"utf-8\"))\n        hash_obj.update(json.dumps((args, kwargs)).encode(\"utf-8\"))\n        return hash_obj.hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        hasher = hashlib.sha256()\n        hasher.update(func_name.encode())\n        hasher.update(json.dumps((args, kwargs)).encode())\n        return hasher.hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = [func_name, args, kwargs]\n        data_as_json = json.dumps(data, sort_keys=True, default=str)\n        return hashlib.sha256(data_as_json.encode()).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        arg_hash = hashlib.sha256()\n        arg_hash.update(func_name.encode(\"utf-8\"))\n        arg_hash.update(json.dumps(args).encode(\"utf-8\"))\n        arg_hash.update(json.dumps(kwargs).encode(\"utf-8\"))\n        return arg_hash.hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        # Convert the arguments to a string representation\n        args_str = json.dumps(args)\n        kwargs_str = json.dumps(kwargs)\n\n        # Hash the function name, arguments, and keyword arguments\n        hasher = hashlib.sha256()\n        hasher.update(bytes(func_name, \"utf-8\"))\n        hasher.update(bytes(args_str, \"utf-8\"))\n        hasher.update(bytes(kwargs_str, \"utf-8\"))\n        return hasher.hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = {\n            \"function\": func_name,\n            \"args\": args,\n            \"kwargs\": kwargs,\n        }\n\n        serialized = json.dumps(data, sort_keys=True).encode(\"utf-8\")\n        hash = hashlib.sha256(serialized).hexdigest()\n\n        return hash\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        # The order of the arguments is important to the hash.\n        data = [func_name, args, kwargs]\n        data_str = json.dumps(data, sort_keys=True)\n        data_bytes = data_str.encode(\"utf-8\")\n        hasher = hashlib.sha256()\n        hasher.update(data_bytes)\n        return hasher.hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        # We need to make sure that the arguments are hashable.\n        args = tuple(args)\n        kwargs = tuple(sorted(kwargs.items()))\n\n        # We need to make sure that the arguments can be serialized as JSON.\n        args_json = json.dumps(args)\n        kwargs_json = json.dumps(kwargs)\n\n        # We need to make sure that the arguments can be encoded as UTF-8.\n        args_utf8 = args_json.encode(\"utf-8\")\n        kwargs_utf8 = kwargs_json.encode(\"utf-8\")\n\n        # We need to make sure that the arguments can be hashed.\n        args_hash = hashlib.sha256(args_utf8)\n        kwargs_hash = hashlib.sha256(kwargs_utf8)\n\n        # We can now compute the hash.\n        data = (func_name, args_hash.hexdigest(), kwargs_hash.hexdigest())\n        data_utf8 = json.dumps(data).encode(\"utf-8\")\n        data_hash = hashlib.sha256(data_utf8)\n        return data_hash.hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = {\n            \"func_name\": func_name,\n            \"args\": args,\n            \"kwargs\": kwargs\n        }\n        serialized = json.dumps(data, sort_keys=True, default=str)\n        hash = hashlib.sha256(serialized.encode(\"utf-8\")).hexdigest()\n        return hash\n"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the distances between consecutive points\n    distances = np.linalg.norm(polygon[:-1] - polygon[1:], axis=1)\n\n    # Compute the total length of the polygon\n    total_length = np.sum(distances[distances < max_point_distance])\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the distances between consecutive points.\n    distances = np.linalg.norm(polygon[:-1] - polygon[1:], axis=1)\n\n    # Compute the total length of the polygon, excluding large gaps.\n    total_length = np.sum(distances[distances < max_point_distance])\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the distances between consecutive points\n    point_distances = np.linalg.norm(polygon[:-1] - polygon[1:], axis=1)\n\n    # Exclude distances that exceed the maximum threshold\n    point_distances[point_distances > max_point_distance] = 0\n\n    # Return the sum of the distances\n    return np.sum(point_distances)"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the distances between consecutive points in the polygon.\n    point_distances = np.linalg.norm(np.diff(polygon, axis=0), axis=1)\n\n    # Compute the total length of the polygon, excluding distances that exceed the specified maximum.\n    total_length = np.sum(point_distances[point_distances <= max_point_distance])\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the distances between consecutive points in the polygon\n    point_distances = np.linalg.norm(polygon - np.roll(polygon, -1, axis=0), axis=1)\n\n    # Compute the total length of the polygon, excluding distances that exceed the maximum point distance\n    return np.sum(point_distances[point_distances < max_point_distance])"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the distances between consecutive points in the polygon\n    distances = np.linalg.norm(polygon[1:, :] - polygon[:-1, :], axis=1)\n\n    # Sum the distances that are below the maximum distance threshold\n    length = np.sum(distances[distances < max_point_distance])\n\n    return length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the distances between consecutive points in the polygon\n    point_distances = np.linalg.norm(polygon[:-1] - polygon[1:], axis=1)\n\n    # Compute the total length of the polygon, excluding the distances between consecutive points that exceed the maximum distance\n    return np.sum(point_distances[point_distances <= max_point_distance])"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the distances between each consecutive pair of points in the polygon.\n    point_distances = np.linalg.norm(polygon[:-1] - polygon[1:], axis=1)\n\n    # Compute the total length of the polygon by summing the distances between consecutive points that are below the specified maximum distance.\n    total_length = np.sum(np.where(point_distances < max_point_distance, point_distances, 0))\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the distances between consecutive points\n    point_distances = np.linalg.norm(polygon[1:, :] - polygon[:-1, :], axis=1)\n\n    # Discard the points that exceed the maximum distance threshold\n    point_distances = point_distances[point_distances < max_point_distance]\n\n    # Compute the total length of the polygon\n    polygon_length = np.sum(point_distances)\n\n    return polygon_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the distance between consecutive points in the polygon\n    point_distances = np.linalg.norm(polygon[:-1] - polygon[1:], axis=1)\n\n    # Exclude distances that are larger than the maximum distance threshold\n    point_distances[point_distances > max_point_distance] = 0\n\n    # Return the sum of the distances\n    return np.sum(point_distances)"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Initialize the total length to zero\n    total_length = 0\n\n    # Iterate over the points of the polygon\n    for i in range(len(polygon) - 1):\n\n        # Compute the distance between the current point and the next one\n        distance = np.linalg.norm(polygon[i + 1] - polygon[i])\n\n        # If the distance is below the maximum distance, add it to the total length\n        if distance < max_point_distance:\n            total_length += distance\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the distances between consecutive points\n    point_differences = np.diff(polygon, axis=0)\n    point_distances = np.linalg.norm(point_differences, axis=1)\n\n    # Compute the total length of the polygon, excluding points that are too far from their predecessors\n    total_length = np.sum(point_distances[point_distances < max_point_distance])\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Initialize the total length of the polygon\n    total_length = 0.0\n\n    # Initialize the number of points in the polygon\n    num_points = polygon.shape[0]\n\n    # Iterate over the points in the polygon\n    for i in range(num_points):\n\n        # Get the current point and the next point in the polygon\n        current_point = polygon[i]\n        next_point = polygon[(i + 1) % num_points]\n\n        # Compute the distance between the current and next point\n        point_distance = np.linalg.norm(current_point - next_point)\n\n        # If the distance is below the specified maximum, add it to the total length\n        if point_distance < max_point_distance:\n            total_length += point_distance\n\n    # Return the total length of the polygon\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the distances between consecutive points\n    point_distances = np.linalg.norm(polygon[:-1] - polygon[1:], axis=1)\n\n    # Only consider distances that are below the maximum threshold\n    point_distances[point_distances > max_point_distance] = 0\n\n    # Sum the distances to get the total length\n    return np.sum(point_distances)\n\n"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # If the polygon is empty, return 0\n    if len(polygon) == 0:\n        return 0\n\n    # If the polygon has only one point, return 0\n    if len(polygon) == 1:\n        return 0\n\n    # If the polygon has only two points, return the distance between them\n    if len(polygon) == 2:\n        return np.linalg.norm(polygon[0] - polygon[1])\n\n    # If the polygon has more than two points, compute the distances between consecutive points\n    point_distances = np.linalg.norm(polygon[:-1] - polygon[1:], axis=1)\n\n    # Compute the total length of the polygon, excluding distances that exceed the maximum distance\n    return np.sum(point_distances[point_distances < max_point_distance])"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Initialize the total length to zero\n    total_length = 0\n\n    # Iterate over all points in the polygon\n    for i in range(len(polygon)):\n\n        # If we are not at the last point, consider the distance between the current point and the next point\n        if i < len(polygon) - 1:\n            point_distance = np.linalg.norm(polygon[i] - polygon[i + 1])\n\n            # If the distance is below the maximum, add it to the total length\n            if point_distance <= max_point_distance:\n                total_length += point_distance\n\n        # If we are at the last point, consider the distance between the last point and the first point\n        else:\n            point_distance = np.linalg.norm(polygon[i] - polygon[0])\n\n            # If the distance is below the maximum, add it to the total length\n            if point_distance <= max_point_distance:\n                total_length += point_distance\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the distance between each pair of consecutive points\n    point_distances = np.linalg.norm(polygon[:-1] - polygon[1:], axis=1)\n\n    # Ignore points that are too far away from their neighbors\n    point_distances[point_distances > max_point_distance] = 0\n\n    # Sum the distances between consecutive points that are below the maximum distance\n    return np.sum(point_distances)"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the distances between consecutive points.\n    point_distances = np.linalg.norm(polygon - np.roll(polygon, -1, axis=0), axis=1)\n\n    # Compute the cumulative sum of the distances.\n    cumulative_point_distances = np.cumsum(point_distances)\n\n    # Find the indices of the points that are below the maximum distance threshold.\n    point_indices_below_threshold = np.where(point_distances < max_point_distance)[0]\n\n    # Compute the total length of the polygon, considering only the distances between consecutive points that are below the specified maximum distance.\n    return cumulative_point_distances[point_indices_below_threshold[-1]] - cumulative_point_distances[point_indices_below_threshold[0]]"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the distances between consecutive points.\n    point_distances = np.linalg.norm(polygon[1:] - polygon[:-1], axis=1)\n\n    # Compute the total length of the polygon, excluding the distances that exceed the maximum point distance.\n    total_length = np.sum(point_distances[point_distances < max_point_distance])\n\n    return total_length\n\n"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the distances between consecutive points\n    point_distances = np.linalg.norm(polygon[1:] - polygon[:-1], axis=1)\n\n    # Get the indices of the points that are below the maximum distance threshold\n    point_indices = np.where(point_distances <= max_point_distance)[0]\n\n    # Sum the distances between consecutive points that are below the maximum distance threshold\n    return np.sum(point_distances[point_indices])\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    # Check if the polygons are empty\n    if not polygons:\n        raise VectorizationError(\"No polygons to filter\")\n\n    # Get the largest polygon's area\n    largest_area = max([area(p) for p in polygons])\n\n    # Filter out polygons based on their area\n    return [p for p in polygons if area(p) > abs_tr or area(p) > rel_tr * largest_area]\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    # Get the largest polygon's area\n    largest_area = max([area(p) for p in polygons])\n\n    # Filter out polygons based on their area\n    filtered_polygons = []\n    for polygon in polygons:\n        if area(polygon) > rel_tr * largest_area or area(polygon) > abs_tr:\n            filtered_polygons.append(polygon)\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if len(polygons) == 0:\n        return []\n\n    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n    return [polygon for polygon, area in zip(polygons, areas) if area > abs_tr or area > rel_tr * max_area]\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if len(polygons) == 0:\n        return []\n\n    areas = [area(p) for p in polygons]\n    max_area = max(areas)\n\n    filtered_polygons = []\n    for p in polygons:\n        if area(p) > abs_tr and area(p) > rel_tr * max_area:\n            filtered_polygons.append(p)\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if len(polygons) == 0:\n        return polygons\n\n    # Calculate the area of each polygon\n    areas = [area(polygon) for polygon in polygons]\n\n    # Find the largest polygon in the list\n    max_area = max(areas)\n\n    # Filter out polygons whose area is smaller than the absolute threshold or the relative threshold\n    filtered_polygons = [\n        polygon\n        for polygon, area in zip(polygons, areas)\n        if area > abs_tr or area > rel_tr * max_area\n    ]\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if len(polygons) == 0:\n        return polygons\n\n    largest_area = max([area(p) for p in polygons])\n\n    return [\n        p\n        for p in polygons\n        if (area(p) > (abs_tr or rel_tr * largest_area))\n    ]\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    # calculate the area of each polygon\n    areas = [area(polygon) for polygon in polygons]\n\n    # find the index of the polygon with the largest area\n    max_idx = np.argmax(areas)\n\n    # calculate the area threshold\n    area_threshold = max(areas[max_idx] * rel_tr, abs_tr)\n\n    # filter out polygons with area smaller than the threshold\n    filtered_polygons = [polygon for polygon, area in zip(polygons, areas) if area >= area_threshold]\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if len(polygons) == 0:\n        return []\n\n    largest_area = max([area(p) for p in polygons])\n    return [p for p in polygons if area(p) >= abs_tr or area(p) >= rel_tr * largest_area]\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if rel_tr < 0 or abs_tr < 0:\n        raise ValueError(\"The relative and absolute thresholds must be non-negative.\")\n\n    if len(polygons) == 0:\n        return polygons\n\n    largest_area = max([area(polygon) for polygon in polygons])\n    return [\n        polygon\n        for polygon in polygons\n        if area(polygon) > abs_tr or area(polygon) > rel_tr * largest_area\n    ]\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if rel_tr < 0 or abs_tr < 0:\n        raise ValueError(\"Thresholds must be non-negative.\")\n\n    # Get the area of each polygon\n    polygon_areas = [area(polygon) for polygon in polygons]\n\n    # Get the largest polygon's area\n    max_area = max(polygon_areas)\n\n    # Filter out polygons based on their area\n    return [\n        polygon\n        for polygon, polygon_area in zip(polygons, polygon_areas)\n        if polygon_area > abs_tr or polygon_area > rel_tr * max_area\n    ]\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if len(polygons) == 0:\n        return []\n\n    largest_area = max([area(polygon) for polygon in polygons])\n    return [polygon for polygon in polygons if area(polygon) > abs_tr + rel_tr * largest_area]\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if len(polygons) == 0:\n        return []\n\n    largest_area = area(polygons[0])\n    if abs_tr > largest_area:\n        raise VectorizationError(\n            \"The absolute threshold for the area is larger than the area of the largest polygon.\"\n        )\n\n    return [\n        polygon\n        for polygon in polygons\n        if area(polygon) >= (abs_tr + rel_tr * largest_area)\n    ]\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    # Calculate the area of each polygon\n    areas = [area(p) for p in polygons]\n\n    # Get the largest polygon's area\n    largest_area = max(areas)\n\n    # Filter out polygons based on their area\n    filtered_polygons = [\n        p\n        for p, a in zip(polygons, areas)\n        if a >= abs_tr or a >= rel_tr * largest_area\n    ]\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    # Calculate the area of each polygon\n    areas = [area(polygon) for polygon in polygons]\n\n    # Find the maximum area\n    max_area = max(areas)\n\n    # Filter out polygons based on their area\n    return [polygon for polygon, area in zip(polygons, areas) if area > abs_tr or area > rel_tr * max_area]\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if not 0 <= rel_tr <= 1:\n        raise ValueError(\n            f\"The relative threshold should be a fraction between 0 and 1, but got {rel_tr} instead.\"\n        )\n\n    if len(polygons) == 0:\n        return []\n\n    max_area = max(area(polygon) for polygon in polygons)\n    return [\n        polygon\n        for polygon in polygons\n        if area(polygon) > (abs_tr or rel_tr * max_area)\n    ]\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if len(polygons) == 0:\n        return polygons\n\n    # Calculate the area of each polygon\n    polygons_areas = [area(p) for p in polygons]\n\n    # Find the largest polygon's area\n    max_area = max(polygons_areas)\n\n    # Filter out polygons whose area is smaller than the absolute threshold or the relative threshold\n    return [\n        p\n        for p, a in zip(polygons, polygons_areas)\n        if a > abs_tr or a > rel_tr * max_area\n    ]\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    # Get the area of each polygon\n    areas = [area(polygon) for polygon in polygons]\n\n    # Get the largest area\n    largest_area = max(areas)\n\n    # Filter out polygons based on their area\n    return [polygon for polygon, area in zip(polygons, areas) if area > abs_tr or area > rel_tr * largest_area]\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    # Filter out polygons with area smaller than the threshold\n    filtered_polygons = []\n    for polygon in polygons:\n        polygon_area = area(polygon)\n        if polygon_area > max(abs_tr, rel_tr * max([area(x) for x in polygons])):\n            filtered_polygons.append(polygon)\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if len(polygons) == 0:\n        return []\n    if len(polygons) == 1:\n        return polygons\n    if rel_tr < 0.0 or abs_tr < 0.0:\n        raise ValueError(\"rel_tr and abs_tr must be non-negative\")\n    if rel_tr + abs_tr > 1.0:\n        raise ValueError(\"rel_tr and abs_tr must sum to less than 1.0\")\n    largest_area = max([area(p) for p in polygons])\n    return [p for p in polygons if area(p) > abs_tr + rel_tr * largest_area]\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if len(polygons) == 0:\n        return []\n\n    # Find the largest polygon in the list\n    max_area = max([area(polygon) for polygon in polygons])\n\n    # Filter out polygons that are smaller than the threshold\n    return [\n        polygon\n        for polygon in polygons\n        if area(polygon) > (abs_tr + rel_tr * max_area)\n    ]\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # The number of samples that each worker has processed\n    num_samples_per_worker = {}\n\n    # The number of samples that each worker has processed\n    num_samples_per_worker = {}\n\n    # The number of samples that each worker has processed\n    num_samples_per_worker = {}\n\n    # The number of samples that each worker has processed\n    num_samples_per_worker = {}\n\n    # The number of samples that each worker has processed\n    num_samples_per_worker = {}\n\n    # The number of samples that each worker has processed\n    num_samples_per_worker = {}\n\n    # The number of samples that each worker has processed\n    num_samples_per_worker = {}\n\n    # The number of samples that each worker has processed\n    num_samples_per_worker = {}\n\n    # The number of samples that each worker has processed\n    num_samples_per_worker = {}\n\n    # The number of samples that each worker has processed\n    num_samples_per_worker = {}\n\n    # The number of samples that each worker has processed\n    num_samples_per_worker = {}\n\n    # The number of samples that each worker has processed\n    num_samples_per_worker = {}\n\n    # The number of samples that each worker has processed\n    num_samples_per_worker = {}\n\n    # The number of samples that each worker has processed\n    num_samples_per_worker = {}\n\n    # The number of samples that each worker has processed\n    num_samples_per_worker = {}\n\n    # The number of samples that each worker has processed\n    num_samples_per_worker = {}\n\n    # The number of samples that each worker has processed\n    num_samples_per_worker = {}\n\n    # The number of samples that each worker has processed\n    num_samples_per_worker = {}\n\n    # The number of samples that each worker has processed\n    num_samples_per_worker = {}\n\n    # The number of samples that each worker has processed\n    num_samples_per_worker = {}\n\n    # The number of samples that each worker has processed\n    num_samples_per"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples that each worker has processed\n    samples_per_worker = num_samples_yielded // num_workers\n\n    # Calculate the number of samples that each worker has processed\n    samples_per_worker = num_samples_yielded // num_workers\n\n    # Calculate the number of samples that each worker has processed\n    samples_per_worker = num_samples_yielded // num_workers\n\n    # Calculate the number of samples that each worker has processed\n    samples_per_worker = num_samples_yielded // num_workers\n\n    # Calculate the number of samples that each worker has processed\n    samples_per_worker = num_samples_yielded // num_workers\n\n    # Calculate the number of samples that each worker has processed\n    samples_per_worker = num_samples_yielded // num_workers\n\n    # Calculate the number of samples that each worker has processed\n    samples_per_worker = num_samples_yielded // num_workers\n\n    # Calculate the number of samples that each worker has processed\n    samples_per_worker = num_samples_yielded // num_workers\n\n    # Calculate the number of samples that each worker has processed\n    samples_per_worker = num_samples_yielded // num_workers\n\n    # Calculate the number of samples that each worker has processed\n    samples_per_worker = num_samples_yielded // num_workers\n\n    # Calculate the number of samples that each worker has processed\n    samples_per_worker = num_samples_yielded // num_workers\n\n    # Calculate the number of samples that each worker has processed\n    samples_per_worker = num_samples_yielded // num_workers\n\n    # Calculate the number of samples that each worker has processed\n    samples_per_worker = num_samples_yielded // num_workers\n\n    # Calculate the number of samples that each worker has processed\n    samples_per_worker = num_samples_yielded // num_workers\n\n    # Calculate the number of samples"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # The number of samples that each worker has processed\n    workers_samples = {}\n\n    # The number of samples that each worker has processed\n    workers_samples_per_batch = {}\n\n    # The number of samples that each worker has processed\n    workers_samples_remaining = {}\n\n    # The number of samples that each worker has processed\n    workers_samples_remaining_per_batch = {}\n\n    # The number of samples that each worker has processed\n    workers_samples_remaining_total = {}\n\n    # The number of samples that each worker has processed\n    workers_samples_remaining_total_per_batch = {}\n\n    # The number of samples that each worker has processed\n    workers_samples_remaining_total_per_batch_per_worker = {}\n\n    # The number of samples that each worker has processed\n    workers_samples_remaining_total_per_batch_per_worker_per_batch = {}\n\n    # The number of samples that each worker has processed\n    workers_samples_remaining_total_per_batch_per_worker_per_batch_per_worker = {}\n\n    # The number of samples that each worker has processed\n    workers_samples_remaining_total_per_batch_per_worker_per_batch_per_worker_per_batch = {}\n\n    # The number of samples that each worker has processed\n    workers_samples_remaining_total_per_batch_per_worker_per_batch_per_worker_per_batch_per_worker = {}\n\n    # The number of samples that each worker has processed\n    workers_samples_remaining_total_per_batch_per_worker_per_batch_per_worker_per_batch_per_worker_per_batch = {}\n\n    # The number of samples that each worker has processed\n    workers_samples_remaining_total_per_batch_per_worker_per_batch_per_worker_per_batch_per_worker_per_batch_per_worker = {}\n\n    # The number of samples that each worker has processed\n    workers_samples_remaining_total_per_batch_per_worker_per_batch_per"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    num_samples_per_worker = num_samples_yielded // num_workers\n    num_samples_per_worker_remainder = num_samples_yielded % num_workers\n    num_samples_per_worker_remainder_per_worker = num_samples_per_worker_remainder // num_workers\n    num_samples_per_worker_remainder_per_worker_remainder = num_samples_per_worker_remainder % num_workers\n\n    num_samples_per_worker += num_samples_per_worker_remainder_per_worker\n    num_samples_per_worker_remainder_per_worker -= num_samples_per_worker_remainder_per_worker_remainder\n\n    num_batches_per_worker = num_samples_per_worker // batch_size\n    num_batches_per_worker_remainder = num_samples_per_worker % batch_size\n    num_batches_per_worker_remainder_per_worker = num_batches_per_worker_remainder // num_workers\n    num_batches_per_worker_remainder_per_worker_remainder = num_batches_per_worker_remainder % num_workers\n\n    num_batches_per_worker += num_batches_per_worker_remainder_per_worker\n    num_batches_per_worker_remainder_per_worker -= num_batches_per_worker_remainder_per_worker_remainder\n\n    num_samples_per_worker_per_worker = num_batches_per_worker * batch_size\n    num_samples_per_worker_per_worker_remainder = num_batches_per_worker_remainder\n\n    num_samples_per_worker_per_worker += num_samples_per_worker_remainder_per_worker\n    num_samples_per_worker_per_worker_remainder -= num_samples_per_worker_remainder_per_worker_remainder"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # The number of samples that each worker has processed.\n    samples_per_worker = {}\n\n    # The number of samples that each worker should process.\n    samples_per_worker_per_epoch = {}\n\n    # The number of samples that remain to be processed.\n    remaining_samples = num_samples_yielded\n\n    # The number of samples that each worker should process in the current epoch.\n    samples_per_worker_per_epoch_current_epoch = {}\n\n    # The number of samples that each worker has processed in the current epoch.\n    samples_per_worker_current_epoch = {}\n\n    # The number of samples that each worker should process in the next epoch.\n    samples_per_worker_per_epoch_next_epoch = {}\n\n    # The number of samples that each worker has processed in the next epoch.\n    samples_per_worker_next_epoch = {}\n\n    # The number of samples that each worker should process in the next epoch.\n    samples_per_worker_per_epoch_next_epoch = {}\n\n    # The number of samples that each worker has processed in the next epoch.\n    samples_per_worker_next_epoch = {}\n\n    # The number of samples that each worker should process in the next epoch.\n    samples_per_worker_per_epoch_next_epoch = {}\n\n    # The number of samples that each worker has processed in the next epoch.\n    samples_per_worker_next_epoch = {}\n\n    # The number of samples that each worker should process in the next epoch.\n    samples_per_worker_per_epoch_next_epoch = {}\n\n    # The number of samples that each worker has processed in the next epoch.\n    samples_per_worker_next_epoch = {}\n\n    # The number of samples that each worker should process in the next epoch.\n    samples_per_worker_per_epoch_next_epoch = {}\n\n    # The number of samples that each worker has processed in the next epoch.\n    samples_per_worker_next_"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # calculate the number of samples that each worker should process\n    samples_per_worker = num_samples_yielded // num_workers\n\n    # calculate the number of remaining samples\n    remaining_samples = num_samples_yielded % num_workers\n\n    # calculate the number of samples that each worker should process\n    samples_per_worker = num_samples_yielded // num_workers\n\n    # calculate the number of remaining samples\n    remaining_samples = num_samples_yielded % num_workers\n\n    # calculate the number of batches that each worker should process\n    batches_per_worker = samples_per_worker // batch_size\n\n    # calculate the number of remaining batches\n    remaining_batches = samples_per_worker % batch_size\n\n    # calculate the number of samples that each worker should process\n    samples_per_worker = num_samples_yielded // num_workers\n\n    # calculate the number of remaining samples\n    remaining_samples = num_samples_yielded % num_workers\n\n    # calculate the number of batches that each worker should process\n    batches_per_worker = samples_per_worker // batch_size\n\n    # calculate the number of remaining batches\n    remaining_batches = samples_per_worker % batch_size\n\n    # create a dictionary where each key is a worker index (starting from 0) and its value is the number of samples that worker has processed\n    indexes = {}\n\n    # iterate over all workers\n    for worker_idx in range(num_workers):\n\n        # calculate the number of batches that the current worker should process\n        num_batches = batches_per_worker\n\n        # if the current worker is one of the remaining workers\n        if worker_idx < remaining_batches:\n\n            # increment the number of batches that the current worker should process\n            num_batches += 1\n\n        # calculate the number of samples that the current worker should process\n        num_samples = num_batches * batch_size\n\n        # if the current worker is one of the remaining workers\n        if worker_idx < remaining_samples:"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples that each worker has processed\n    samples_per_worker = {worker_idx: 0 for worker_idx in range(num_workers)}\n    samples_per_worker = _distribute_samples(num_samples_yielded, batch_size, samples_per_worker)\n\n    # Calculate the number of samples that each worker has processed\n    samples_per_worker = {worker_idx: 0 for worker_idx in range(num_workers)}\n    samples_per_worker = _distribute_samples(num_samples_yielded, batch_size, samples_per_worker)\n\n    # Calculate the number of samples that each worker has processed\n    samples_per_worker = {worker_idx: 0 for worker_idx in range(num_workers)}\n    samples_per_worker = _distribute_samples(num_samples_yielded, batch_size, samples_per_worker)\n\n    return samples_per_worker\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # The number of samples that each worker has processed\n    workers_samples = {}\n\n    # The number of samples that each worker should process\n    workers_samples_to_process = {}\n\n    # The number of samples that should be distributed among the workers\n    samples_to_distribute = num_samples_yielded % num_workers\n\n    # The number of samples that each worker should process\n    samples_per_worker = num_samples_yielded // num_workers\n\n    # The number of batches that each worker should process\n    batches_per_worker = samples_per_worker // batch_size\n\n    # The number of batches that should be distributed among the workers\n    batches_to_distribute = samples_to_distribute // batch_size\n\n    # The number of samples that each worker should process\n    samples_per_worker += batches_to_distribute * batch_size\n\n    # The number of samples that each worker should process\n    samples_to_process = samples_per_worker * num_workers\n\n    # The number of samples that each worker should process\n    samples_to_process_per_worker = samples_to_process // num_workers\n\n    # The number of samples that each worker should process\n    samples_to_process_remaining = samples_to_process % num_workers\n\n    # The number of batches that each worker should process\n    batches_per_worker += batches_to_distribute\n\n    # The number of batches that each worker should process\n    batches_per_worker += samples_to_process_remaining // batch_size\n\n    # The number of batches that each worker should process\n    batches_to_process = batches_per_worker * num_workers\n\n    # The number of samples that each worker should process\n    samples_to_process = batches_to_process * batch_size\n\n    # The number of samples that each worker should process\n    samples_to_process_per_worker = samples_to_process // num_workers\n\n    # The number of samples that each worker should process\n    samples_to_process_rem"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples each worker should process.\n    num_samples_per_worker = num_samples_yielded // num_workers\n    num_samples_remaining = num_samples_yielded % num_workers\n\n    # Calculate the number of batches each worker should process.\n    num_batches_per_worker = num_samples_per_worker // batch_size\n    num_batches_remaining = num_samples_per_worker % batch_size\n\n    # Calculate the number of samples each worker should process.\n    num_samples_per_worker = num_samples_per_worker + num_samples_remaining\n    num_samples_remaining = num_samples_remaining - num_samples_per_worker\n\n    # Calculate the number of batches each worker should process.\n    num_batches_per_worker = num_batches_per_worker + num_batches_remaining\n    num_batches_remaining = num_batches_remaining - num_batches_per_worker\n\n    # Calculate the number of samples each worker should process.\n    num_samples_per_worker = num_samples_per_worker + num_batches_remaining\n\n    # Calculate the number of samples each worker should process.\n    num_samples_per_worker = num_samples_per_worker * batch_size\n\n    # Create a dictionary of the number of samples each worker should process.\n    num_samples_per_worker_dict = {i: num_samples_per_worker for i in range(num_workers)}\n\n    # Distribute any remaining samples to the workers.\n    for i in range(num_samples_remaining):\n        num_samples_per_worker_dict[i] += 1\n\n    return num_samples_per_worker_dict\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # calculate the number of samples that each worker has processed\n    samples_per_worker = (num_samples_yielded // num_workers) + (batch_size if num_samples_yielded % num_workers > 0 else 0)\n\n    # calculate the number of samples that remain to be distributed\n    remaining_samples = num_samples_yielded - samples_per_worker * num_workers\n\n    # calculate the number of samples that each worker will process\n    samples_per_worker += remaining_samples // num_workers\n\n    # calculate the number of samples that each worker will process\n    remaining_samples = remaining_samples % num_workers\n\n    # create a dictionary where each key is a worker index (starting from 0) and its value is the number of samples that worker has processed\n    indexes = {}\n    for worker_idx in range(num_workers):\n        indexes[worker_idx] = samples_per_worker\n\n    # distribute the remaining samples\n    for worker_idx in range(remaining_samples):\n        indexes[worker_idx] += 1\n\n    return indexes\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    num_samples_per_worker = (num_samples_yielded // num_workers) + (batch_size if num_samples_yielded % num_workers != 0 else 0)\n    num_samples_per_worker_remainder = num_samples_yielded % num_workers\n    num_samples_per_worker_remainder_per_worker = num_samples_per_worker_remainder // num_workers\n    num_samples_per_worker_remainder_per_worker_remainder = num_samples_per_worker_remainder % num_workers\n\n    num_samples_per_worker = num_samples_per_worker - num_samples_per_worker_remainder_per_worker\n    num_samples_per_worker_remainder = num_samples_per_worker_remainder_per_worker_remainder\n\n    num_samples_per_worker_dict = {}\n    for worker_idx in range(num_workers):\n        num_samples_per_worker_dict[worker_idx] = num_samples_per_worker\n\n    for worker_idx in range(num_samples_per_worker_remainder):\n        num_samples_per_worker_dict[worker_idx] += 1\n\n    return num_samples_per_worker_dict\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples each worker should process\n    samples_per_worker = num_samples_yielded // num_workers\n    num_samples_per_worker = [samples_per_worker for _ in range(num_workers)]\n\n    # Distribute any remaining samples\n    remaining_samples = num_samples_yielded % num_workers\n    for i in range(remaining_samples):\n        num_samples_per_worker[i] += 1\n\n    # Calculate the number of batches each worker should process\n    batches_per_worker = [num_samples_per_worker[i] // batch_size for i in range(num_workers)]\n\n    # Distribute any remaining batches\n    remaining_batches = [num_samples_per_worker[i] % batch_size for i in range(num_workers)]\n    for i in range(num_workers):\n        if remaining_batches[i] > 0:\n            batches_per_worker[i] += 1\n\n    # Calculate the number of samples each worker should process\n    num_samples_per_worker = [batches_per_worker[i] * batch_size for i in range(num_workers)]\n\n    return num_samples_per_worker\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    assert num_workers > 0\n    assert batch_size > 0\n\n    num_samples_per_worker = num_samples_yielded // num_workers\n    num_samples_remaining = num_samples_yielded % num_workers\n\n    num_samples_per_worker_with_remaining = num_samples_per_worker + (num_samples_remaining // num_workers)\n    num_samples_per_worker_without_remaining = num_samples_per_worker\n\n    num_batches_per_worker_with_remaining = num_samples_per_worker_with_remaining // batch_size\n    num_batches_per_worker_without_remaining = num_samples_per_worker_without_remaining // batch_size\n\n    num_samples_per_worker = []\n    for i in range(num_workers):\n        if i < num_samples_remaining:\n            num_samples_per_worker.append(num_batches_per_worker_with_remaining * batch_size)\n        else:\n            num_samples_per_worker.append(num_batches_per_worker_without_remaining * batch_size)\n\n    return num_samples_per_worker\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # calculate the number of samples that each worker should process\n    num_samples_per_worker = num_samples_yielded // num_workers\n\n    # calculate the number of samples that are left to be distributed\n    num_samples_left = num_samples_yielded % num_workers\n\n    # calculate the number of batches that each worker should process\n    num_batches_per_worker = num_samples_per_worker // batch_size\n\n    # calculate the number of batches that are left to be distributed\n    num_batches_left = num_samples_per_worker % batch_size\n\n    # create a list of the number of batches that each worker will process\n    num_batches_per_worker_list = [num_batches_per_worker] * num_workers\n\n    # distribute the left-over batches to the workers\n    for i in range(num_samples_left):\n        num_batches_per_worker_list[i] += 1\n\n    # create a list of the number of samples that each worker will process\n    num_samples_per_worker_list = [batches * batch_size for batches in num_batches_per_worker_list]\n\n    # create a list of the number of indexes that each worker will process\n    indexes_per_worker_list = []\n    for i in range(num_workers):\n        indexes_per_worker_list.append(\n            list(range(i, num_samples_yielded, num_workers))\n        )\n\n    # distribute the left-over samples to the workers\n    for i in range(num_batches_left):\n        indexes_per_worker_list[i].append(num_samples_yielded - 1)\n\n    # create a dictionary where each key is a worker index (starting from 0) and its value is the number of samples that worker has processed\n    indexes_per_worker_dict = {}\n    for i in range(num_workers):\n        indexes_per_worker_dict[i] = indexes_per_worker_list[i]\n\n    return indexes"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    num_samples_yielded = num_samples_yielded % (num_workers * batch_size)\n    num_samples_per_worker = num_samples_yielded // num_workers\n    num_samples_remaining = num_samples_yielded % num_workers\n    num_samples_per_worker += 1 if num_samples_remaining > 0 else 0\n\n    # Calculate the number of samples each worker has processed\n    num_samples_processed = {}\n    for i in range(num_workers):\n        num_samples_processed[i] = num_samples_per_worker\n        num_samples_remaining -= 1\n        if num_samples_remaining > 0:\n            num_samples_processed[i] += 1\n            num_samples_remaining -= 1\n\n    return num_samples_processed\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    num_samples_per_worker = num_samples_yielded // num_workers\n    num_samples_remaining = num_samples_yielded % num_workers\n\n    samples_per_worker = {}\n    for worker_idx in range(num_workers):\n        if num_samples_remaining > 0:\n            num_samples = num_samples_per_worker + 1\n            num_samples_remaining -= 1\n        else:\n            num_samples = num_samples_per_worker\n\n        samples_per_worker[worker_idx] = num_samples\n\n    return samples_per_worker\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    samples_per_worker = num_samples_yielded // num_workers\n    remaining_samples = num_samples_yielded % num_workers\n    batches_per_worker = samples_per_worker // batch_size\n    remaining_batches = samples_per_worker % batch_size\n\n    indexes = []\n    for i in range(num_workers):\n        indexes.append(i)\n\n    samples_per_worker_list = [batches_per_worker] * num_workers\n    remaining_samples_list = [remaining_batches] * num_workers\n\n    # If there are remaining samples, distribute them evenly among workers.\n    if remaining_samples > 0:\n        for i in range(remaining_samples):\n            index = np.random.choice(indexes, 1)[0]\n            samples_per_worker_list[index] += 1\n            indexes.remove(index)\n\n    # If there are remaining batches, distribute them evenly among workers.\n    if remaining_batches > 0:\n        for i in range(remaining_batches):\n            index = np.random.choice(indexes, 1)[0]\n            samples_per_worker_list[index] += 1\n            indexes.remove(index)\n\n    return samples_per_worker_list\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples to be processed by each worker\n    num_samples_per_worker = int(num_samples_yielded / num_workers)\n\n    # Calculate the number of samples to be processed by each worker\n    num_samples_remaining = num_samples_yielded - (num_samples_per_worker * num_workers)\n\n    # Calculate the number of batches to be processed by each worker\n    num_batches_per_worker = num_samples_per_worker // batch_size\n\n    # Calculate the number of batches to be processed by each worker\n    num_batches_remaining = num_samples_remaining // batch_size\n\n    # Create a dictionary where each key is a worker index (starting from 0) and its value is the number of samples that worker has processed\n    num_samples_per_worker_dict = {}\n\n    # For each worker\n    for worker_idx in range(num_workers):\n\n        # Calculate the number of batches to be processed by this worker\n        num_batches_to_process = num_batches_per_worker\n        if worker_idx < num_batches_remaining:\n            num_batches_to_process += 1\n\n        # Calculate the number of samples to be processed by this worker\n        num_samples_to_process = num_batches_to_process * batch_size\n\n        # Add the number of samples to the dictionary\n        num_samples_per_worker_dict[worker_idx] = num_samples_to_process\n\n    return num_samples_per_worker_dict\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Initialize the dictionary that will contain the number of samples yielded by each worker.\n    indexes = {}\n\n    # Calculate the number of samples yielded by each worker.\n    for worker_idx in range(num_workers):\n\n        # Calculate the number of samples that will be processed by this worker.\n        num_samples = (num_samples_yielded // num_workers) + (worker_idx < num_samples_yielded % num_workers)\n\n        # Calculate the number of batches that will be processed by this worker.\n        num_batches = num_samples // batch_size\n\n        # Calculate the number of samples that will be processed by this worker.\n        num_samples = num_batches * batch_size\n\n        # Store the number of samples that will be processed by this worker.\n        indexes[worker_idx] = num_samples\n\n    return indexes\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples that each worker should process\n    samples_per_worker = num_samples_yielded // num_workers\n    remaining_samples = num_samples_yielded % num_workers\n    # Calculate the number of batches that each worker should process\n    batches_per_worker = samples_per_worker // batch_size\n    remaining_batches = samples_per_worker % batch_size\n    # Calculate the number of samples that each worker should process\n    samples_per_worker = batches_per_worker * batch_size\n    remaining_samples += remaining_batches\n\n    # Initialize a dictionary that will be used to store the number of samples that each worker should process\n    num_samples_per_worker = {}\n    # Initialize a list that will be used to store the number of samples that each worker should process\n    num_samples_per_worker_list = []\n    # Initialize a list that will be used to store the number of batches that each worker should process\n    batches_per_worker_list = []\n\n    # Distribute the samples among the workers\n    for i in range(num_workers):\n        if remaining_samples > 0:\n            samples_per_worker += 1\n            remaining_samples -= 1\n\n        # Add the number of samples that each worker should process to the dictionary and list\n        num_samples_per_worker[i] = samples_per_worker\n        num_samples_per_worker_list.append(samples_per_worker)\n        # Add the number of batches that each worker should process to the list\n        batches_per_worker_list.append(samples_per_worker // batch_size)\n\n    # Initialize a dictionary that will be used to store the number of samples that each worker should process\n    num_samples_per_worker_dict = {}\n\n    # Distribute the samples among the workers\n    for i in range(num_workers):\n        # Add the number of samples that each worker should process to the dictionary\n        num_samples_per_worker_dict[i] = num_samples_per_worker_list[i]\n        # Decrease the"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n\n    if len(results) != len(value) or len(results) != len(metadatas):\n        raise ValueError(\"The results, values, and metadata lists must have the same length.\")\n\n    if not isinstance(threshold, (int, float)):\n        raise TypeError(\"The threshold must be a numeric value.\")\n\n    filtered_results = []\n    filtered_metadatas = []\n\n    for result, val, metadata in zip(results, value, metadatas):\n        if val <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadata)\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n\n    if len(results) != len(value) or len(results) != len(metadatas):\n        raise ValueError(\"The results, value, and metadatas lists must be the same length\")\n\n    filtered_results = []\n    filtered_metadatas = []\n    for i in range(len(results)):\n        if value[i] <= threshold:\n            filtered_results.append(results[i])\n            filtered_metadatas.append(metadatas[i])\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n    if len(results) != len(value) or len(results) != len(metadatas):\n        raise ValueError(\"The length of results, values and metadatas should be equal.\")\n    filtered_results = []\n    filtered_metadatas = []\n    for result, val, metadata in zip(results, value, metadatas):\n        if val <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadata)\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n\n    if len(results) != len(value) or len(results) != len(metadatas):\n        raise ValueError(\"The results, value, and metadata lists must have the same length.\")\n\n    filtered_results = []\n    filtered_metadatas = []\n    for result, val, metadata in zip(results, value, metadatas):\n        if val <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadata)\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n\n    if len(results) != len(value) or len(results) != len(metadatas):\n        raise ValueError(\"The results, values, and metadata lists must all be the same length\")\n\n    # filter the results and metadata based on the threshold\n    filtered_results = []\n    filtered_metadatas = []\n    for result, val, metadata in zip(results, value, metadatas):\n        if val <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadata)\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if not metadatas:\n        metadatas = [None] * len(results)\n\n    if len(results) != len(value) or len(results) != len(metadatas):\n        raise ValueError(\"The results, values, and metadata lists must have the same length.\")\n\n    filtered_results = []\n    filtered_metadatas = []\n    for result, val, metadata in zip(results, value, metadatas):\n        if val <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadata)\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if not metadatas:\n        metadatas = [None] * len(results)\n\n    if len(results) != len(value) or len(results) != len(metadatas):\n        raise ValueError(f'The results, value, and metadata lists must all be of the same length.')\n\n    filtered_results = []\n    filtered_metadatas = []\n    for result, val, metadata in zip(results, value, metadatas):\n        if val <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadata)\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n    assert len(results) == len(value) == len(metadatas)\n    assert threshold is not None\n\n    if not results:\n        return [], []\n\n    filtered_results = []\n    filtered_metadatas = []\n\n    for result, val, metadata in zip(results, value, metadatas):\n        if val <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadata)\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n    assert len(results) == len(value) == len(metadatas), \"The length of results, value and metadata should be the same.\"\n    return_results = []\n    return_metadatas = []\n    for i, result in enumerate(results):\n        if value[i] <= threshold:\n            return_results.append(result)\n            return_metadatas.append(metadatas[i])\n    return return_results, return_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n\n    if len(results) != len(value) or len(results) != len(metadatas):\n        raise ValueError(\"The results, value, and metadata lists must have the same length.\")\n\n    filtered_results = []\n    filtered_metadatas = []\n\n    for result, val, metadata in zip(results, value, metadatas):\n        if val <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadata)\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if not metadatas:\n        metadatas = [None] * len(results)\n\n    if len(results) != len(value) or len(results) != len(metadatas):\n        raise ValueError(\"The lengths of the results, value, and metadata lists do not match.\")\n\n    filtered_results = []\n    filtered_metadatas = []\n    for result, val, metadata in zip(results, value, metadatas):\n        if val <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadata)\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n    if len(results) != len(value) or len(results) != len(metadatas):\n        raise ValueError(\"The results, values, and metadata lists must all be of the same length.\")\n    return [result for result, val in zip(results, value) if val <= threshold], \\\n           [metadata for metadata, val in zip(metadatas, value) if val <= threshold]\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n    assert len(results) == len(value) == len(metadatas)\n    return [results[i] for i in range(len(results)) if value[i] <= threshold], [metadatas[i] for i in range(len(results)) if value[i] <= threshold]\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n\n    if not (len(results) == len(value) == len(metadatas)):\n        raise ValueError(\"The results, values, and metadatas lists must have the same length.\")\n\n    if not isinstance(threshold, (int, float)):\n        raise TypeError(\"The threshold argument must be a numeric value.\")\n\n    filtered_results = []\n    filtered_metadatas = []\n    for result, val, metadata in zip(results, value, metadatas):\n        if val <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadata)\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n\n    if len(results) != len(value) or len(results) != len(metadatas):\n        raise ValueError(\"The results, values, and metadata lists must all be of the same length\")\n\n    filtered_results = []\n    filtered_metadatas = []\n    for i in range(len(results)):\n        if value[i] <= threshold:\n            filtered_results.append(results[i])\n            filtered_metadatas.append(metadatas[i])\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None for _ in range(len(results))]\n    assert len(results) == len(value) == len(metadatas), \"The lengths of results, value and metadatas must be the same.\"\n    assert len(results) > 0, \"The length of results must be greater than 0.\"\n    assert len(value) > 0, \"The length of value must be greater than 0.\"\n    assert len(metadatas) > 0, \"The length of metadatas must be greater than 0.\"\n\n    filtered_results = []\n    filtered_metadatas = []\n    for result, val, metadata in zip(results, value, metadatas):\n        if val <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadata)\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n    assert len(results) == len(value) == len(metadatas)\n    return [result for result, val in zip(results, value) if val <= threshold], [metadata for metadata, val in zip(metadatas, value) if val <= threshold]\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n\n    if len(results) != len(value) or len(results) != len(metadatas):\n        raise ValueError(\"The results, values, and metadata lists must all have the same length.\")\n\n    if not isinstance(threshold, (int, float)):\n        raise TypeError(\"The threshold must be a numeric value.\")\n\n    filtered_results = []\n    filtered_metadatas = []\n    for result, val, metadata in zip(results, value, metadatas):\n        if val <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadata)\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n    if len(results) != len(value) or len(results) != len(metadatas):\n        raise ValueError(\"The results, values, and metadata lists must be of the same length\")\n\n    filtered_results = []\n    filtered_metadatas = []\n    for i, result in enumerate(results):\n        if value[i] <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadatas[i])\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n\n    assert len(results) == len(value) == len(metadatas), \"The results, value, and metadata lists must have the same length.\"\n\n    filtered_results = []\n    filtered_metadatas = []\n    for result, val, metadata in zip(results, value, metadatas):\n        if val <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadata)\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(f\"The input array does not have the correct shape. The shape of the array must be (_, 2), where _ can be any number of points. The shape of the input array is {array.shape}\")\n\n    return 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"The input array does not have the shape (_, 2), indicating it does not represent a valid list of polygon points.\")\n\n    return 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if not isinstance(array, np.ndarray):\n        raise ValueError(\"Input array must be a numpy array.\")\n    if len(array.shape) != 2:\n        raise ValueError(\"Input array must be a 2D array.\")\n    if array.shape[1] != 2:\n        raise ValueError(\"Input array must be a list of points.\")\n\n    x = array[:,0]\n    y = array[:,1]\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"The input array does not have the correct shape. The shape of the array must be (_, 2), where _ can be any number of points.\")\n\n    return 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if not isinstance(array, np.ndarray):\n        raise TypeError(\"Input array must be of type numpy.ndarray.\")\n\n    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have shape (_, 2), where _ can be any number of points.\")\n\n    x = array[:, 0]\n    y = array[:, 1]\n\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if not isinstance(array, np.ndarray):\n        raise TypeError(\"Input array must be a numpy array.\")\n\n    if array.shape[1] != 2:\n        raise ValueError(\"Input array must be a numpy array of shape (_, 2).\")\n\n    x = array[:, 0]\n    y = array[:, 1]\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    # Checking if the input array has the correct shape\n    if not isinstance(array, np.ndarray):\n        raise TypeError(\"Input array must be of type numpy.ndarray\")\n\n    if array.shape[1] != 2:\n        raise ValueError(\"Input array must be of shape (_, 2)\")\n\n    # Calculating the area\n    area = 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n    return area\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    # Checking if the input array has the correct shape\n    if not isinstance(array, np.ndarray):\n        raise TypeError('The input array must be a numpy ndarray.')\n    if array.shape[1] != 2:\n        raise ValueError('The input array must be of the shape (_, 2), where _ can be any number of points.')\n\n    # Calculating the area\n    area = 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n    return area\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    # Checking if the array is of the correct shape\n    if not isinstance(array, np.ndarray):\n        raise TypeError(\"Input array must be a numpy array.\")\n    if array.shape[1] != 2:\n        raise ValueError(\n            \"Input array must be a numpy array with shape (_, 2), where _ is any number of points.\"\n        )\n\n    # Calculating the area\n    area = 0.5 * np.abs(\n        np.dot(array[:, 0], np.roll(array[:, 1], 1))\n        - np.dot(array[:, 1], np.roll(array[:, 0], 1))\n    )\n\n    return area\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"The input array does not have the shape (_, 2), indicating it does not represent a valid list of polygon points.\")\n\n    return 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    # Checking the shape of the input array\n    if not isinstance(array, np.ndarray):\n        raise ValueError(\"Input array must be of type np.ndarray\")\n    if array.shape[1] != 2:\n        raise ValueError(\"Input array must be of shape (_, 2)\")\n\n    # Calculating the area using the Shoelace formula\n    x = array[:, 0]\n    y = array[:, 1]\n    area = 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n\n    return area\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError('The input array must be a list of points, where each point is a pair of coordinates (x, y).')\n\n    x = array[:, 0]\n    y = array[:, 1]\n\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    # Checking if the input array has the correct shape\n    if not isinstance(array, np.ndarray):\n        raise ValueError(f\"Input array must be an np.ndarray, got {type(array)} instead.\")\n    if array.shape[1] != 2:\n        raise ValueError(f\"The second dimension of the array must be 2, got {array.shape[1]} instead.\")\n\n    # Calculating the area\n    area = 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n    return area\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    # Checking if the input is of the correct shape\n    if not isinstance(array, np.ndarray):\n        raise ValueError(\"Input array must be a numpy ndarray\")\n\n    if array.shape[1] != 2:\n        raise ValueError(\"Input array must be of the shape (_, 2), where _ can be any number of points.\")\n\n    # Calculating the area using the Shoelace formula\n    return 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(f\"The input array does not have the correct shape. Expected (_, 2). Got {array.shape}.\")\n\n    return 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"The input array must have the shape (_, 2), where _ can be any number of points.\")\n\n    x = array[:, 0]\n    y = array[:, 1]\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"The input array must have shape (_, 2), where _ can be any number of points.\")\n\n    return 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(f\"The input array must have shape (_, 2), but the shape of the input array is {array.shape}.\")\n\n    x = array[:, 0]\n    y = array[:, 1]\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    # check that the input is a valid array of points\n    if not isinstance(array, np.ndarray):\n        raise ValueError(f\"Input must be a numpy array. Got {type(array)}\")\n\n    if array.shape[1] != 2:\n        raise ValueError(f\"Input array must have shape (_, 2). Got {array.shape}\")\n\n    # calculate the area\n    area = 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n    return area\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if not isinstance(array, np.ndarray):\n        raise ValueError(f\"Input array must be of type np.ndarray. Got {type(array)}\")\n\n    if not array.shape[1] == 2:\n        raise ValueError(f\"Input array must be of shape (_, 2). Got {array.shape}\")\n\n    # calculate area\n    area = 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n    return area\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # Get upper and lower bounds\n    lower_bounds = torch.searchsorted(a, v, right=True)\n    upper_bounds = torch.searchsorted(a, v, right=False)\n\n    # If the bounds are equal, then the value is within the range of a\n    within_range = lower_bounds != upper_bounds\n\n    # If a[lower_bounds] > v, then shift the lower bounds back by 1\n    lower_bounds = torch.where(\n        torch.logical_and(within_range, a[lower_bounds] > v), lower_bounds - 1, lower_bounds\n    )\n\n    # If a[upper_bounds] < v, then shift the upper bounds back by 1\n    upper_bounds = torch.where(\n        torch.logical_and(within_range, a[upper_bounds] < v), upper_bounds + 1, upper_bounds\n    )\n\n    return lower_bounds, upper_bounds\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # a = torch.cat([a, v], dim=-1)\n    # sorted_a, sort_idx = torch.sort(a, dim=-1)\n    # sorted_v = torch.gather(sorted_a, dim=-1, index=sort_idx)\n    # sorted_a = sorted_v[..., :-1]\n    # sorted_v = sorted_v[..., -1:]\n    # idx_lo = torch.searchsorted(sorted_a, sorted_v, right=True)\n    # idx_hi = torch.clamp_max(idx_lo + 1, a.shape[-1] - 1)\n    # return sort_idx[..., :-1], idx_lo, idx_hi\n\n    a = torch.cat([a, v], dim=-1)\n    sorted_a, sort_idx = torch.sort(a, dim=-1)\n    sorted_v = torch.gather(sorted_a, dim=-1, index=sort_idx)\n    sorted_a = sorted_v[..., :-1]\n    sorted_v = sorted_v[..., -1:]\n    idx_lo = torch.searchsorted(sorted_a, sorted_v, right=True)\n    idx_hi = torch.clamp_max(idx_lo + 1, a.shape[-1] - 1)\n    return sort_idx[..., :-1], idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # Get the index of the first element in a that is greater than or equal to each element in v.\n    idx_lo = torch.searchsorted(a, v, right=True)\n\n    # Get the index of the first element in a that is greater than each element in v.\n    idx_hi = torch.searchsorted(a, v, right=False)\n\n    # If the index of the first element in a that is greater than or equal to each element in v is the same as the index of the first element in a that is greater than each element in v, then the element in v is out of the range of a.\n    idx_lo = torch.where(idx_lo == idx_hi, torch.ones_like(idx_lo) * a.shape[-1], idx_lo)\n\n    # If the index of the first element in a that is greater than or equal to each element in v is the same as the index of the last element in a, then the element in v is out of the range of a.\n    idx_hi = torch.where(idx_lo == a.shape[-1], idx_lo - 1, idx_hi)\n\n    # Return the lower and upper bounds where each element of v could be inserted into a.\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # idx_lo is the lower index where the element could be inserted\n    # idx_hi is the upper index where the element could be inserted\n    idx_lo = torch.searchsorted(a, v, right=True)\n    idx_hi = torch.searchsorted(a, v, right=False)\n\n    # If idx_hi == len(a), then we know that the element should be inserted at the last index.\n    # However, we need to make sure that idx_lo is also pointing to the last index in that case.\n    idx_hi[idx_hi == a.shape[-1]] = a.shape[-1] - 1\n    idx_lo[idx_hi == a.shape[-1]] = a.shape[-1]\n\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # TODO: add support for batched inputs\n    # TODO: add support for torch.float16\n    # TODO: add support for torch.float32\n\n    # Check if the input tensors are on the same device\n    if a.device != v.device:\n        raise Exception(\"The input tensors are not on the same device.\")\n\n    # Check if the input tensors have the same dtype\n    if a.dtype != v.dtype:\n        raise Exception(\"The input tensors are not of the same dtype.\")\n\n    # Check if the input tensors are 1D tensors\n    if a.ndim != 1:\n        raise Exception(\"The input tensors are not 1D tensors.\")\n\n    # Check if the input tensors are sorted\n    if not torch.all(a[1:] - a[:-1] >= 0):\n        raise Exception(\"The input tensors are not sorted.\")\n\n    # Check if the shapes of the input tensors are compatible\n    if v.ndim != a.ndim:\n        raise Exception(\"The input tensors do not have the same number of dimensions.\")\n    if v.shape[:-1] != a.shape[:-1]:\n        raise Exception(\"The input tensors are not broadcastable.\")\n\n    # Check if the input tensors are of the same dtype\n    if a.dtype != v.dtype:\n        raise Exception(\"The input tensors are not of the same dtype.\")\n\n    # Check if the input tensors are of the same device\n    if a.device != v.device:\n        raise Exception(\"The input tensors are not on the same device.\")\n\n    # Check if the input tensors are of the same dtype\n    if a.dtype not in [torch.float64, torch.float32, torch.float16]:\n        raise Exception(\"The input tensors are not of floating point dtype.\")\n\n    # Check if the input tensors are of the same dtype\n    if a.dtype != v.dtype:\n        raise Exception(\"The input tensors are not of the same dtype.\")\n\n    # Check if the input tensors are on the"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    a = a.contiguous()\n    v = v.contiguous()\n    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # Find the index of the first element that is greater than or equal to v\n    idx_hi = torch.searchsorted(a, v, right=True)\n    # Find the index of the last element that is smaller than or equal to v\n    idx_lo = torch.searchsorted(a, v, right=False)\n    # If the indices are identical, then v is already in a\n    idx_lo = torch.where(idx_lo == idx_hi, idx_lo - 1, idx_lo)\n    idx_hi = torch.where(idx_lo == idx_hi, idx_hi, idx_hi - 1)\n    # If idx_hi < 0, then v is smaller than all elements of a\n    idx_hi = torch.clamp(idx_hi, min=0)\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # Get the index of the first element that is larger than v\n    idx_hi = torch.searchsorted(a, v, right=True)\n    # Get the index of the last element that is smaller than v\n    idx_lo = torch.searchsorted(a, v, right=False)\n\n    # If the index of the larger element is the same as the index of the smaller element, then the value is within the range of a\n    idx_hi = torch.where(idx_hi == idx_lo, idx_lo, idx_hi - 1)\n\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # Find the index of the first element in a that is greater than each element in v.\n    idx_lo = torch.searchsorted(a, v, right=True)\n    # If the index of the first element in a that is greater than each element in v is equal to the length of a, then v is out of the range of a, and the last index of a should be returned.\n    idx_lo = torch.where(idx_lo == a.shape[-1], a.shape[-1] - 1, idx_lo)\n    # Find the index of the last element in a that is less than each element in v.\n    idx_hi = torch.searchsorted(a, v, right=False)\n    # If the index of the last element in a that is less than each element in v is equal to -1, then v is out of the range of a, and the first index of a should be returned.\n    idx_hi = torch.where(idx_hi == -1, 0, idx_hi)\n    # Return the indices.\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    if v.ndim == 0:\n        v = v.unsqueeze(0)\n\n    if a.ndim == 0:\n        a = a.unsqueeze(0)\n\n    assert a.ndim == 1\n    assert a.shape[0] > 0\n    assert v.ndim == 1\n\n    # If the tensor a is empty, then there is no point in doing anything.\n    if a.shape[0] == 0:\n        return torch.tensor([], device=a.device, dtype=torch.long), torch.tensor([], device=a.device, dtype=torch.long)\n\n    # If the tensor v is empty, then there is no point in doing anything.\n    if v.shape[0] == 0:\n        return torch.tensor([], device=a.device, dtype=torch.long), torch.tensor([], device=a.device, dtype=torch.long)\n\n    # If the tensor v is the same size as the tensor a, then there is no point in doing anything.\n    if a.shape[0] == v.shape[0]:\n        return torch.arange(v.shape[0], device=a.device, dtype=torch.long), torch.arange(v.shape[0], device=a.device, dtype=torch.long)\n\n    # If the tensor v is larger than the tensor a, then there is no point in doing anything.\n    if v.shape[0] > a.shape[0]:\n        return torch.tensor([], device=a.device, dtype=torch.long), torch.tensor([], device=a.device, dtype=torch.long)\n\n    # The tensor a is not empty, the tensor v is not empty, and the tensor v is smaller than the tensor a.\n    # We can proceed with the algorithm.\n\n    # We will be using the following notation:\n    #   a = (a_0, a_1, ..., a_n) is the reference tensor\n    #   v = (v_0, v_1, ...,"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # TODO: Make this compatible with arbitrary dimensions\n    # TODO: Make this compatible with unsorted a\n\n    # Make sure that a and v are both tensors\n    if not torch.is_tensor(a):\n        a = torch.tensor(a)\n    if not torch.is_tensor(v):\n        v = torch.tensor(v)\n\n    # Convert v to a tensor if it is not one already\n    v = torch.as_tensor(v)\n\n    # If a is empty, return an empty tensor\n    if a.size == 0:\n        return torch.tensor([]), torch.tensor([])\n\n    # Make sure that a and v have the same number of dimensions\n    if a.ndim != v.ndim:\n        raise ValueError(\"a and v must have the same number of dimensions\")\n\n    # Make sure that the last dimension of a and v are the same\n    if a.shape[-1] != v.shape[-1]:\n        raise ValueError(\"The last dimension of a and v must be the same size\")\n\n    # Make sure that a is sorted\n    if not torch.all(a[1:] > a[:-1]):\n        raise ValueError(\"a must be sorted\")\n\n    # Make sure that a and v are both 1D\n    if a.ndim > 1:\n        raise NotImplementedError(\"searchsorted only supports 1D tensors\")\n\n    # Make sure that a and v are both on the same device\n    if a.device != v.device:\n        raise ValueError(\"a and v must be on the same device\")\n\n    # Make sure that a and v are both either on the CPU or on the GPU\n    if a.device.type != v.device.type:\n        raise ValueError(\"a and v must be either both on the CPU or both on the GPU\")\n\n    # Make sure that the tensor is not empty\n    if a.numel() == 0:\n        raise ValueError(\"a must be non-empty\")\n\n    # Make sure that the tensor is not empty\n    if v.numel() == 0:\n        raise"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    if v.ndim > 1:\n        raise NotImplementedError(\"searchsorted only implemented for 1D tensors\")\n\n    # Get the index of the last element in a that is smaller than each element in v.\n    idx_lo = torch.searchsorted(a, v, right=True)\n\n    # Get the index of the first element in a that is larger than each element in v.\n    idx_hi = torch.searchsorted(a, v, right=False)\n\n    # If the index of the last element in a that is smaller than each element in v is the same as the index of the first element in a that is larger than each element in v, then the element in v is out of the range of a.\n    idx_hi = torch.where(idx_hi == a.shape[0], a.shape[0] - 1, idx_hi)\n    idx_lo = torch.where(idx_lo == a.shape[0], a.shape[0] - 1, idx_lo)\n\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    if v.shape[-1] != a.shape[-1]:\n        raise ValueError(\"The last dimension of v and a should be equal\")\n\n    if a.shape[-1] == 1:\n        return torch.full_like(v[..., 0], 0), torch.full_like(v[..., 0], len(a) - 1)\n\n    # Find the lower and upper bounds of each query point in the reference tensor\n    upper = torch.searchsorted(a, v, right=True)\n    lower = torch.searchsorted(a, v, right=False)\n\n    # If the lower bound is equal to the upper bound, then the query point is out of the range of the reference tensor\n    out_of_range_max = (upper == len(a))\n    out_of_range_min = (lower == 0)\n\n    # Set the indices for out of range query points\n    upper[out_of_range_max] = len(a) - 1\n    lower[out_of_range_min] = 0\n    upper[out_of_range_min] = 0\n    lower[out_of_range_max] = len(a) - 1\n\n    return lower, upper\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # Find indices where elements of v should be inserted into a to maintain order\n    idx_lo = torch.searchsorted(a, v, right=True)\n    idx_hi = torch.searchsorted(a, v, right=False)\n\n    # Clip the indices such that they are within the bounds of a\n    idx_lo = torch.clamp(idx_lo, min=1, max=a.shape[-1] - 1)\n    idx_hi = torch.clamp(idx_hi, min=1, max=a.shape[-1] - 1)\n\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # Find the lower bounds of insertion for each query point\n    lower_bounds = torch.searchsorted(a, v, right=True)\n\n    # Find the upper bounds of insertion for each query point\n    upper_bounds = torch.searchsorted(a, v, right=False)\n\n    return lower_bounds, upper_bounds\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    if v.ndim == 0:\n        v = v[None]\n    if a.ndim == 0:\n        a = a[None]\n\n    assert a.ndim == 1, \"a should be one-dimensional\"\n    assert a.shape[0] > 0, \"a should have non-zero elements\"\n    assert v.ndim <= a.ndim, \"v should have equal or fewer dimensions as a\"\n\n    # expand v to match the dimensionality of a\n    v = v.expand([1] * (a.ndim - v.ndim) + list(v.shape))\n\n    # calculate the shape of the output\n    idx_shape = v.shape[:-1] + (1,)\n\n    # find the upper and lower index for each element of v\n    upper = torch.searchsorted(a, v, right=True)\n    lower = torch.searchsorted(a, v, right=False)\n\n    # deal with out of bounds indices\n    upper = torch.clamp(upper, 0, a.numel() - 1)\n    lower = torch.clamp(lower, 0, a.numel() - 1)\n\n    # generate the indices for the lower and upper bounds\n    idx_upper = torch.cat([torch.arange(v.numel(), device=a.device).reshape(-1, 1), upper.reshape(-1, 1)], dim=-1)\n    idx_lower = torch.cat([torch.arange(v.numel(), device=a.device).reshape(-1, 1), lower.reshape(-1, 1)], dim=-1)\n\n    # reshape the indices for the lower and upper bounds\n    idx_upper = idx_upper.reshape(idx_shape)\n    idx_lower = idx_lower.reshape(idx_shape)\n\n    return idx_lower, idx_upper\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # Find the upper and lower indices of insertion\n    idx_lo = torch.searchsorted(a, v, right=True)\n    idx_hi = torch.searchsorted(a, v, right=False)\n\n    # If idx_hi == len(a), then the element is out of bounds, and should be appended to the end of a\n    # If idx_lo == idx_hi, then the element is already in the tensor a, and should be left-padded\n    idx_hi[idx_hi == len(a)] = len(a) - 1\n    idx_lo[idx_lo == idx_hi] = max(0, idx_lo[idx_lo == idx_hi] - 1)\n\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # Use binary search to find the index where the element of v should be inserted into a\n    # to maintain the sorted order.\n    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n\n    # If an element of v is out of the range of a, we need to adjust the index accordingly.\n    # This is because the binary search returns the index of the nearest element in a,\n    # which may not be the index where the element of v should be inserted.\n    idx_lo = torch.clamp(idx_lo, 0, a.shape[-1] - 1)\n    idx_hi = torch.clamp(idx_hi, 0, a.shape[-1] - 1)\n\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # Create a tensor with the same shape as v, but with the last dimension of a.\n    # This is used for the upper and lower bound indices.\n    # If v has shape [..., 3], then lower_bounds will have shape [..., 3, a.shape[-1]]\n    lower_bounds = torch.zeros_like(v[..., :1])\n    upper_bounds = (torch.ones_like(v[..., :1]) * (a.shape[-1] - 1)).long()\n\n    # If v is greater than a, idx_hi will point to the last element of a.\n    # If v is less than a, idx_lo will point to the first element of a.\n    idx_hi = torch.ones_like(lower_bounds) * (a.shape[-1] - 1)\n    idx_lo = torch.zeros_like(upper_bounds)\n\n    # If v is greater than a, idx_hi will decrease, until idx_hi and idx_lo are the same.\n    # If v is less than a, idx_lo will increase, until idx_hi and idx_lo are the same.\n    while idx_hi > idx_lo:\n        # Find the indices where v could be inserted in a without breaking order.\n        indices = (idx_hi + idx_lo + 1).long() // 2\n\n        # Get the values at those indices.\n        a_at_indices = a.index_select(-1, indices.squeeze(-1))\n\n        # Find which elements of v are less than a_at_indices.\n        # If v is greater than a, idx_hi will decrease.\n        # If v is less than a, idx_lo will increase.\n        idx_hi = torch.where(v > a_at_indices, indices, idx_hi)\n        idx_lo = torch.where(v < a_at_indices, indices, idx_lo)\n\n    # Return the lower and upper bounds of the indices where elements of v could be inserted into a.\n    return lower_bounds, upper_bounds\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    if not (a.shape[:-1] == v.shape[:-1]):\n        raise ValueError(\"The shape of a and v must match, except for the last dimension.\")\n\n    if not (a.shape[-1] >= v.shape[-1]):\n        raise ValueError(\"The last dimension of a must be greater or equal to the last dimension of v.\")\n\n    if not (a.shape[-1] > 0):\n        raise ValueError(\"The last dimension of a must be greater than 0.\")\n\n    if not (torch.all(a[..., 1:] >= a[..., :-1])):\n        raise ValueError(\"The elements in a must be sorted.\")\n\n    # Initialize the output tensors.\n    idx_lo = torch.zeros(v.shape, dtype=torch.long, device=a.device)\n    idx_hi = torch.zeros(v.shape, dtype=torch.long, device=a.device)\n\n    # The following code is based on the original code from\n    # https://github.com/wkentaro/torch-ranking/blob/master/torchrpf/functions/rank_ops.py\n\n    # Create a tensor with the same shape as v, but with the same number of elements as a.\n    # This is used to store the indices of the elements of v, as they are copied from v to a.\n    # This is necessary to prevent the values of v from being overwritten.\n    a_idx = torch.arange(a.shape[-1], device=a.device)\n    a_idx = a_idx.expand(v.shape[:-1] + (a.shape[-1],))\n\n    # Create a mask tensor.\n    mask = torch.ones(idx_lo.shape, dtype=torch.bool, device=a.device)\n\n    # Iterate through the last dimension of v.\n    for i in range(v.shape[-1]):\n        # Get the values in a that are greater than the current value of v.\n        masked_a = torch.masked_select(a, mask)\n        masked_"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array(\n      [\n          [fx, 0, cx],\n          [0, fy, cy],\n          [0, 0, 1],\n      ]\n  )\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array(\n      [\n          [fx, 0.0, cx],\n          [0.0, fy, cy],\n          [0.0, 0.0, 1.0],\n      ]\n  )\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array(\n      [\n          [fx, 0, cx],\n          [0, fy, cy],\n          [0, 0, 1],\n      ]\n  )\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array(\n      [[fx, 0, cx], [0, fy, cy], [0, 0, 1]],\n      dtype=np.float32,\n  )\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array(\n      [\n          [fx, 0.0, cx],\n          [0.0, fy, cy],\n          [0.0, 0.0, 1.0],\n      ]\n  )\n\n"}
{"namespace": "coord.contract", "completion": "  return jnp.where(jnp.abs(x) < 1, jnp.sign(x) * (1 - jnp.power(jnp.abs(x), 3)), x)\n\n"}
{"namespace": "coord.contract", "completion": "  return x / (1.0 + jnp.linalg.norm(x, axis=-1, keepdims=True) ** 2)\n\n"}
{"namespace": "coord.contract", "completion": "  return jnp.where(x >= 0, x / (1 + x), x / (1 - x))\n\n"}
{"namespace": "coord.contract", "completion": "  # Calculate the magnitude squared of the points\n  x_mag_sq = jnp.sum(jnp.square(x), axis=-1, keepdims=True)\n\n  # Calculate the scaling factor\n  scaling_factor = jnp.sqrt(1 - jnp.sqrt(1 - x_mag_sq))\n\n  # Scale the points\n  x = x * scaling_factor\n\n  return x\n\n"}
{"namespace": "coord.contract", "completion": "  x_magnitude_squared = jnp.sum(x**2, axis=-1, keepdims=True)\n  x_magnitude_squared = jnp.maximum(x_magnitude_squared, 1e-5)\n  x_magnitude = jnp.sqrt(x_magnitude_squared)\n  x_magnitude = jnp.maximum(x_magnitude, 1e-5)\n  x_scaled = x / x_magnitude\n  x_scaled = x_scaled * (x_magnitude + 1) / (x_magnitude + 2)\n  return x_scaled\n\n"}
{"namespace": "coord.contract", "completion": "  # Calculate the magnitude squared of the points\n  magnitude_squared = jnp.sum(jnp.square(x), axis=-1)\n\n  # Calculate the scale factor for the points\n  scale_factor = jnp.sqrt(jnp.maximum(1 - magnitude_squared, 0))\n\n  # Calculate the scaled points\n  return scale_factor * x\n\n"}
{"namespace": "coord.contract", "completion": "  return x / jnp.sqrt(1. + jnp.linalg.norm(x, axis=-1, keepdims=True) ** 2)\n\n"}
{"namespace": "coord.contract", "completion": "  # Calculate the magnitude squared of the points\n  x_mag_sq = jnp.sum(jnp.square(x), axis=-1)\n\n  # Calculate the scaling factor for the points\n  scale = jnp.sqrt(jnp.abs(jnp.sqrt(jnp.square(x_mag_sq) - 1) - x_mag_sq))\n\n  # Scale the points towards the origin\n  return scale * x\n\n"}
{"namespace": "coord.contract", "completion": "  # Calculate the magnitude squared of the input vector(s).\n  x_mag_squared = jnp.sum(jnp.square(x), axis=-1)\n\n  # Calculate the scaling factor for the input vector(s) based on the magnitude squared.\n  scaling_factor = 1 - jnp.sqrt(1 - x_mag_squared)\n\n  # Scale the input vector(s) based on the scaling factor.\n  return x * scaling_factor[..., jnp.newaxis]\n\n"}
{"namespace": "coord.contract", "completion": "  # Check if the input is a vector or a matrix.\n  if len(x.shape) == 1:\n    # If the input is a vector, convert it into a matrix.\n    x = jnp.expand_dims(x, axis=0)\n\n  # Calculate the magnitude squared of the points.\n  x_mag_squared = jnp.sum(x**2, axis=-1)\n\n  # Calculate the scaling factor.\n  scaling_factor = 1 - (x_mag_squared / 3)\n\n  # Scale the points.\n  x = x * scaling_factor[..., jnp.newaxis]\n\n  return x\n\n"}
{"namespace": "coord.contract", "completion": "  # Checking if the input is a single point or a set of points.\n  if x.ndim == 1:\n    # Calculating the magnitude squared of the input point.\n    magnitude_squared = jnp.sum(x ** 2)\n    # Calculating the scale factor based on the magnitude squared of the input point.\n    scale_factor = 1 / jnp.sqrt(1 + magnitude_squared)\n    # Scaling the input point with the scale factor.\n    return scale_factor * x\n\n  # Calculating the magnitude squared of the input points.\n  magnitude_squared = jnp.sum(x ** 2, axis=-1)\n  # Calculating the scale factor based on the magnitude squared of the input points.\n  scale_factor = 1 / jnp.sqrt(1 + magnitude_squared)\n  # Scaling the input points with the scale factor.\n  return scale_factor[..., jnp.newaxis] * x\n\n"}
{"namespace": "coord.contract", "completion": "  # The epsilon value is used to avoid division by zero error.\n  eps = 1e-10\n\n  # The magnitude squared of the points is calculated.\n  magnitude_squared = jnp.sum(jnp.square(x), axis=-1, keepdims=True)\n\n  # The points are scaled based on the magnitude squared of the points.\n  return x / jnp.sqrt(magnitude_squared + eps)\n\n"}
{"namespace": "coord.contract", "completion": "  # Calculate the magnitude squared of the points.\n  x_norm = jnp.sum(x**2, axis=-1, keepdims=True)\n\n  # Calculate the scaling factor for each point.\n  factor = (jnp.sqrt(1 - jnp.sqrt(1 - x_norm)) - 1) / (jnp.sqrt(x_norm) - 1)\n\n  # Scale the points.\n  x = x * factor\n\n  return x\n\n"}
{"namespace": "coord.contract", "completion": "  x = jnp.asarray(x)\n  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  return x / jnp.sqrt(1 + x_norm)\n\n"}
{"namespace": "coord.contract", "completion": "  return x * jnp.tanh(1.0 / jnp.sqrt(jnp.sum(x * x, axis=-1, keepdims=True)))\n\n"}
{"namespace": "coord.contract", "completion": "  # Calculate the magnitude squared of the points\n  magnitude_squared = math.sum_over_axis(x ** 2, axis=1)\n\n  # Calculate the scaling factor for the points\n  scaling_factor = jnp.sqrt(1.0 / jnp.sqrt(magnitude_squared))\n\n  # Scale the points\n  return x * scaling_factor[:, jnp.newaxis]\n\n"}
{"namespace": "coord.contract", "completion": "  # Calculate the magnitude squared of the points\n  x_mag_sq = math.dot(x, x)\n\n  # Calculate the scaling factor\n  scale = jnp.sqrt(jnp.maximum(1.0 - x_mag_sq, 0.0)) / jnp.sqrt(x_mag_sq)\n\n  # Scale the points\n  return x * scale\n\n"}
{"namespace": "coord.contract", "completion": "  x = jnp.asarray(x)\n  x = jnp.where(jnp.abs(x) < 1, 0.5 * jnp.power(x, 3), jnp.sign(x) * (jnp.abs(x) - 1) ** 2 / (2 * jnp.abs(x)))\n  return x\n\n"}
{"namespace": "coord.contract", "completion": "  # If the input is a single point, then we need to reshape it to be a 1D array\n  if len(x.shape) == 1:\n    x = np.reshape(x, (1, len(x)))\n\n  # We calculate the magnitude squared of the input vector(s)\n  magnitude_squared = np.sum(x**2, axis=1)\n\n  # We calculate the scaling factor for each vector\n  scaling_factor = 1.0 / np.sqrt(1.0 + magnitude_squared)\n\n  # We scale the input vectors\n  return scaling_factor.reshape(-1, 1) * x\n\n"}
{"namespace": "coord.contract", "completion": "  x_mag_sq = jnp.sum(jnp.square(x), axis=-1, keepdims=True)\n  x_mag_sq = jnp.where(x_mag_sq < 1., x_mag_sq, 1.)\n  x = x / jnp.sqrt(x_mag_sq)\n  x = jnp.where(x_mag_sq < 1., x, x / jnp.sqrt(x_mag_sq))\n  return x\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"\", \"K\", \"M\", \"G\", \"T\", \"P\"]:\n        if abs(num_bytes) < 1000.0:\n            return f\"{num_bytes:3.1f}{unit}B\"\n        num_bytes /= 1000.0\n    return f\"{num_bytes:.1f}YB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"\", \"K\", \"M\", \"G\", \"T\", \"P\"]:\n        if abs(num_bytes) < 1000.0:\n            return f\"{num_bytes:3.1f} {unit}B\"\n        num_bytes /= 1000.0\n    return f\"{num_bytes:.1f} YB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in reversed(_FORMAT_TO_RATIO):\n        if num_bytes >= _FORMAT_TO_RATIO[suffix]:\n            return f\"{num_bytes / _FORMAT_TO_RATIO[suffix]:.2f}{suffix}\"\n    return f\"{num_bytes}{suffix}\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if abs(num_bytes) < 1000.0:\n            return f\"{num_bytes:3.1f}{unit}\"\n        num_bytes /= 1000.0\n    return f\"{num_bytes:.1f}PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in ['', 'K', 'M', 'G', 'T', 'P']:\n        if abs(num_bytes) < 1000.0:\n            return f\"{num_bytes:3.1f} {unit}B\"\n        num_bytes /= 1000.0\n    return f\"{num_bytes:.1f} YB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in reversed(_FORMAT_TO_RATIO):\n        if num_bytes >= _FORMAT_TO_RATIO[suffix]:\n            return f\"{num_bytes / _FORMAT_TO_RATIO[suffix]:.2f}{suffix}\"\n    return f\"{num_bytes}{_FORMAT_TO_RATIO['b']}\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in ['', 'K', 'M', 'G', 'T', 'P']:\n        if abs(num_bytes) < 1000.0:\n            return \"%3.1f%sB\" % (num_bytes, unit)\n        num_bytes /= 1000.0\n    return \"%.1f%sB\" % (num_bytes, 'Z')\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"\", \"K\", \"M\", \"G\", \"T\", \"P\"]:\n        if abs(num_bytes) < 1000.0:\n            return f\"{num_bytes:3.1f} {unit}B\"\n        num_bytes /= 1000.0\n    return f\"{num_bytes:.1f} PB\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"b\", \"kb\", \"mb\", \"gb\", \"tb\", \"pb\"]:\n        if abs(num_bytes) < 1000:\n            return f\"{num_bytes:.2f}{unit}\"\n        num_bytes /= 1000\n    raise ValueError(\"The number of bytes is too large to convert.\")\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\" \", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if abs(num_bytes) < 1000.0:\n            return f\"{num_bytes:3.1f}{unit}\"\n        num_bytes /= 1000.0\n    return f\"{num_bytes:.1f} PB\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in reversed(_FORMAT_TO_RATIO):\n        if num_bytes >= _FORMAT_TO_RATIO[suffix]:\n            return f\"{num_bytes / _FORMAT_TO_RATIO[suffix]:.2f}{suffix}\"\n    return f\"{num_bytes}{suffix}\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in ['', 'K', 'M', 'G', 'T', 'P']:\n        if abs(num_bytes) < 1000.0:\n            return \"%3.1f%sB\" % (num_bytes, unit)\n        num_bytes /= 1000.0\n    return \"%.1f%sB\" % (num_bytes, 'Z')\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [' ', 'K', 'M', 'G', 'T', 'P']:\n        if abs(num_bytes) < 1000.0:\n            return f'{num_bytes:3.1f}{unit}B'\n        num_bytes /= 1000.0\n    return f'{num_bytes:3.1f}YB'\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1000:\n            return f\"{num_bytes:.2f} {suffix}\"\n        num_bytes /= 1000\n    return f\"{num_bytes:.2f} {suffix}\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"\", \"K\", \"M\", \"G\", \"T\", \"P\"]:\n        if abs(num_bytes) < 1000.0:\n            return f\"{num_bytes:3.1f}{unit}B\"\n        num_bytes /= 1000.0\n    return f\"{num_bytes:.1f}YB\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if abs(num_bytes) < 1000.0:\n            return f\"{num_bytes:3.1f}{unit}\"\n        num_bytes /= 1000.0\n    return f\"{num_bytes:.1f}PB\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in _FORMAT_TO_RATIO:\n        if num_bytes >= _FORMAT_TO_RATIO[suffix]:\n            return f\"{num_bytes / _FORMAT_TO_RATIO[suffix]:.2f}{suffix}\"\n    return f\"{num_bytes / _FORMAT_TO_RATIO['b']:.2f}{'b'}\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"\", \"K\", \"M\", \"G\", \"T\", \"P\"]:\n        if abs(num_bytes) < 1000.0:\n            return f\"{num_bytes:3.1f} {unit}B\"\n        num_bytes /= 1000.0\n    return f\"{num_bytes:.1f} ZB\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in ['', 'K', 'M', 'G', 'T', 'P']:\n        if abs(num_bytes) < 1000.0:\n            return \"%3.1f%sB\" % (num_bytes, unit)\n        num_bytes /= 1000.0\n    return \"%.1f%sB\" % (num_bytes, 'Z')\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"b\", \"kb\", \"mb\", \"gb\", \"tb\", \"pb\"]:\n        if abs(num_bytes) < 1000.0:\n            return f\"{num_bytes:3.1f}{unit}\"\n        num_bytes /= 1000.0\n    raise ValueError(\"num_bytes is too large\")\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n\n        if v.ndim != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. Got {v.ndim} dimensions.\")\n\n        return v\n\n    return _is_array_n_dimensions"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if v.ndim != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be {nb_dimensions} dimensional. Received {v.ndim} dimensional.\")\n\n        return v\n\n    return _is_array_n_dimensions"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n\n        if v.ndim != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. Got {v.ndim}.\"\n            )\n\n        return v\n\n    return _is_array_n_dimensions"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. Got {len(v.shape)}.\")\n\n        return v\n\n    return _is_array_n_dimensions\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must be an array with {nb_dimensions} dimensions. Got {len(v.shape)} dimensions.\"\n            )\n        return v\n\n    return _is_array_n_dimensions"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"\n        This function checks if a given array has a specific number of dimensions. It is designed to be used within Pydantic models to validate the dimensions of array fields.\n\n        Input-Output Arguments\n        :param cls: Type. The class of the model being validated.\n        :param v: np.ndarray. The array being validated.\n        :param field: fields.ModelField. The field of the model that is being validated.\n        :return: np.ndarray. The validated array if it meets the specified number of dimensions.\n        \"\"\"\n        if v.ndim != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be {nb_dimensions}-dimensional. Received {v.ndim}-dimensional.\")\n\n        return v\n\n    return _is_array_n_dimensions\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n\n        if v.ndim != nb_dimensions:\n            raise ValueError(f'{cls.__name__}: {field.name} must be {nb_dimensions}-dimensional.')\n\n        return v\n\n    return _is_array_n_dimensions\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if v.ndim != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be {nb_dimensions}D. Got {v.ndim}D.\")\n\n        return v\n\n    return _is_array_n_dimensions\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if v.ndim != nb_dimensions:\n            raise ValueError(f'{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. Received {v.ndim}')\n\n        return v\n\n    return _is_array_n_dimensions\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be {nb_dimensions}D. Got {len(v.shape)}D\")\n\n        return v\n\n    return _is_array_n_dimensions\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"\n        Check if a given array has a specific number of dimensions.\n\n        Input-Output Arguments\n        :param cls: Type. The class of the model being validated.\n        :param v: np.ndarray. The array being validated.\n        :param field: fields.ModelField. The field of the model that is being validated.\n        :return: np.ndarray. The validated array if it meets the specified number of dimensions.\n        \"\"\"\n\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. Got {len(v.shape)}\")\n\n        return v\n\n    return _is_array_n_dimensions\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be {nb_dimensions} dimensional. Got {len(v.shape)} dimensions.\")\n\n        return v\n\n    return _is_array_n_dimensions\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"\n        This function is a validator that checks if a given array has a specific number of dimensions. It is designed to be used within Pydantic models to validate the dimensions of array fields.\n\n        Input-Output Arguments\n        :param cls: Type. The class of the model being validated.\n        :param v: np.ndarray. The array being validated.\n        :param field: fields.ModelField. The field of the model that is being validated.\n        :return: np.ndarray. The validated array if it meets the specified number of dimensions.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be {nb_dimensions}-dimensional. Got {len(v.shape)} dimensions.\")\n        return v\n\n    return _is_array_n_dimensions\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if v.ndim != nb_dimensions:\n            raise ValueError(f'{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. Got {v.ndim}')\n        return v\n\n    return _is_array_n_dimensions\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"\n        This function is a validator function that checks if a given array has a specific number of dimensions.\n\n        Input-Output Arguments\n        :param cls: Type. The class of the model being validated.\n        :param v: np.ndarray. The array being validated.\n        :param field: fields.ModelField. The field of the model that is being validated.\n        :return: np.ndarray. The validated array if it meets the specified number of dimensions.\n        \"\"\"\n        if v.ndim != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be {nb_dimensions} dimensional. Received {v.ndim} dimensional.\")\n\n        return v\n\n    return _is_array_n_dimensions\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"\n        This function checks if a given array has a specific number of dimensions. It is designed to be used within Pydantic models to validate the dimensions of array fields.\n\n        Input-Output Arguments\n        :param cls: Type. The class of the model being validated.\n        :param v: np.ndarray. The array being validated.\n        :param field: fields.ModelField. The field of the model that is being validated.\n        :return: np.ndarray. The validated array if it meets the specified number of dimensions.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be {nb_dimensions} dimensional. Got {len(v.shape)} dimensions\")\n\n        return v\n\n    return _is_array_n_dimensions\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n\n        if v.ndim != nb_dimensions:\n            raise ValueError(\n                f'{cls.__name__}: {field.name} must be an array with {nb_dimensions} dimensions. Got {v.ndim} dimensions.'\n            )\n\n        return v\n\n    return _is_array_n_dimensions\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f'{cls.__name__}: {field.name} must be a {nb_dimensions}-dimensional array.')\n\n        return v\n\n    return _is_array_n_dimensions\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"\n        This function checks if a given array has a specific number of dimensions.\n\n        Input-Output Arguments\n        :param cls: Type. The class of the model being validated.\n        :param v: np.ndarray. The array being validated.\n        :param field: fields.ModelField. The field of the model that is being validated.\n        :return: np.ndarray. The validated array if it meets the specified number of dimensions.\n        \"\"\"\n\n        if v.ndim != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. Got {v.ndim} dimensions instead.\"\n            )\n\n        return v\n\n    return _is_array_n_dimensions\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. Got {len(v.shape)}.\")\n\n        return v\n\n    return _is_array_n_dimensions\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n  theta = jnp.arccos(jnp.clip(cartesian_vector[..., 2] / (r + eps), -1.0, 1.0))\n  phi = jnp.arctan2(cartesian_vector[..., 1], cartesian_vector[..., 0])\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n  theta = jnp.arccos(jnp.clip(z / jnp.maximum(r, eps), -1.0, 1.0))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  theta = jnp.arccos(jnp.clip(cartesian_vector[..., 2] / (r + eps), -1.0, 1.0))\n  phi = jnp.arctan2(cartesian_vector[..., 1], cartesian_vector[..., 0])\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n  theta = jnp.arccos(jnp.clip(cartesian_vector[..., 2] / (r + eps), -1.0, 1.0))\n  phi = jnp.arctan2(cartesian_vector[..., 1], cartesian_vector[..., 0])\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n  theta = jnp.arccos(jnp.clip(cartesian_vector[..., 2] / (r + eps), -1., 1.))\n  phi = jnp.arctan2(cartesian_vector[..., 1], cartesian_vector[..., 0])\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  theta = jnp.arccos(jnp.clip(cartesian_vector[..., 2] / jnp.maximum(r, eps), -1, 1))\n  phi = jnp.arctan2(cartesian_vector[..., 1], cartesian_vector[..., 0])\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  # Calculate the radius\n  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n\n  # Calculate the inclination (theta)\n  theta = jnp.arccos(jnp.clip(cartesian_vector[..., 2] / (r + eps), -1.0, 1.0))\n\n  # Calculate the azimuth (phi)\n  phi = jnp.arctan2(cartesian_vector[..., 1], cartesian_vector[..., 0])\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n\n  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n  theta = jnp.arccos(jnp.clip(z / jnp.maximum(r, eps), -1., 1.))\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n\n  radius = jnp.linalg.norm(cartesian_vector, axis=-1)\n  inclination = jnp.arctan2(jnp.sqrt(x**2 + y**2), z + eps)\n  azimuth = jnp.arctan2(y, x)\n\n  return radius, inclination, azimuth\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  theta = jnp.arccos(jnp.clip(cartesian_vector[..., 2] / (r + eps), -1.0, 1.0))\n  phi = jnp.arctan2(cartesian_vector[..., 1], cartesian_vector[..., 0])\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n  theta = jnp.arccos(jnp.clip(z / jnp.maximum(r, eps), -1.0, 1.0))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n\n  radius = jnp.linalg.norm(cartesian_vector, axis=-1)\n  inclination = jnp.arccos(jnp.clip(z / (radius + eps), -1.0, 1.0))\n  azimuth = jnp.arctan2(y, x)\n\n  return radius, inclination, azimuth\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  # Calculate the radius, r, of the point.\n  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n\n  # Calculate the inclination, theta, of the point.\n  theta = jnp.arccos(jnp.clip(cartesian_vector[..., 2] / r, -1., 1.))\n\n  # Calculate the azimuth, phi, of the point.\n  phi = jnp.arctan2(cartesian_vector[..., 1], cartesian_vector[..., 0])\n\n  # Ensure theta is in the range [0, pi].\n  theta = jnp.where(theta < 0, jnp.pi + theta, theta)\n\n  # Ensure phi is in the range [-pi, pi].\n  phi = jnp.where(phi < 0, 2 * jnp.pi + phi, phi)\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  # Compute the radius.\n  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n\n  # Compute the azimuth.\n  phi = jnp.arctan2(cartesian_vector[..., 1], cartesian_vector[..., 0])\n\n  # Compute the inclination.\n  theta = jnp.arccos(jnp.clip(cartesian_vector[..., 2] / (r + eps), -1.0, 1.0))\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  # Calculate the radius, r, of the point.\n  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n\n  # Calculate the azimuth, phi, of the point.\n  phi = jnp.arctan2(cartesian_vector[..., 1], cartesian_vector[..., 0])\n\n  # Calculate the elevation, theta, of the point.\n  theta = jnp.arccos(jnp.clip(cartesian_vector[..., 2] / (r + eps), -1.0, 1.0))\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  # Calculate the radius, r, of the point.\n  radius = jnp.linalg.norm(cartesian_vector, axis=-1)\n\n  # Calculate the azimuth, phi, of the point.\n  azimuth = jnp.arctan2(cartesian_vector[..., 1], cartesian_vector[..., 0])\n\n  # Calculate the inclination, theta, of the point.\n  inclination = jnp.arccos(jnp.maximum(cartesian_vector[..., 2] / radius, -1.0))\n\n  return radius, inclination, azimuth\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n\n  # Calculate radius.\n  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n\n  # Calculate azimuth.\n  phi = jnp.arctan2(y, x)\n\n  # Calculate inclination.\n  theta = jnp.arccos(jnp.clip(z / (r + eps), -1., 1.))\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  # Calculate the radius, r, of the point\n  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n\n  # Calculate the inclination, theta, of the point\n  theta = jnp.arccos(jnp.clip(cartesian_vector[..., 2] / (r + eps), -1., 1.))\n\n  # Calculate the azimuth, phi, of the point\n  phi = jnp.arctan2(cartesian_vector[..., 1], cartesian_vector[..., 0])\n\n  # Convert the azimuth to the range [0, 2*pi]\n  phi = jnp.where(phi < 0, phi + 2 * jnp.pi, phi)\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  # Compute the radius, r, by calculating the Euclidean norm.\n  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n\n  # Compute the inclination, theta, by calculating the inverse cosine of the z-axis projection.\n  theta = jnp.arccos(jnp.clip(cartesian_vector[..., 2] / (r + eps), -1, 1))\n\n  # Compute the azimuth, phi, by calculating the inverse sine of the x-axis projection.\n  phi = jnp.where(cartesian_vector[..., 1] >= 0,\n                  jnp.arcsin(cartesian_vector[..., 0] / (r * jnp.sin(theta) + eps)),\n                  2 * jnp.pi - jnp.arcsin(cartesian_vector[..., 0] / (r * jnp.sin(theta) + eps)))\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  # Ensure that the input has a shape of (..., 3)\n  cartesian_vector = jnp.asarray(cartesian_vector)\n  cartesian_vector_shape = cartesian_vector.shape\n  cartesian_vector = cartesian_vector.reshape((-1, 3))\n\n  # Calculate the radius, inclination, and azimuth\n  radius = jnp.linalg.norm(cartesian_vector, axis=-1)\n  inclination = jnp.arccos(cartesian_vector[..., 2] / (radius + eps))\n  azimuth = jnp.arctan2(cartesian_vector[..., 1], cartesian_vector[..., 0])\n\n  # Convert the inclination and azimuth angles to the correct ranges\n  inclination = (jnp.pi / 2.0) - inclination\n  azimuth = (azimuth + jnp.pi) % (2.0 * jnp.pi) - jnp.pi\n\n  return radius, inclination, azimuth\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    return results['rouge1'].mid.fmeasure\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    return results['rougeL']\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    return results['rougeL'].mid.fmeasure\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    return results['rougeL'].mid.fmeasure\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    return results['rougeL'].mid.fmeasure\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    return results['rougeL'].mid.fmeasure\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    return results['rougeL']\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    return results['rougeL'].mid.fmeasure\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL'].mid.fmeasure\n    return score\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    return results['rougeL'].mid.fmeasure\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    return results['rougeL'].mid.fmeasure\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    return results['rouge1'].mid.fmeasure\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    return results['rougeL'].mid.fmeasure\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    return results['rougeL'].mid.fmeasure\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    return results['rougeL'].mid.fmeasure\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    return results['rougeL'].mid.fmeasure\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    return results['rouge1'].mid.fmeasure\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    return results['rougeL'].mid.fmeasure\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL'].mid.fmeasure\n    return score\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    return results['rougeL'].mid.fmeasure\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    \"\"\"\n    Locates and returns a Python object based on its fully qualified name.\n\n    Args:\n        name (str): The fully qualified name of the object to locate, in the format\n            ``module.submodule.class_name``.\n\n    Returns:\n        Any: The located Python object.\n    \"\"\"\n    return pydoc.locate(name)"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    \"\"\"\n    Locates and returns a Python object based on its fully qualified name.\n\n    Args:\n        name (str): The fully qualified name of the object to locate, in the\n            format \"module.submodule.class_name\".\n\n    Returns:\n        Any: The located Python object.\n    \"\"\"\n    return pydoc.locate(name)"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # Try to find the class using the standard method\n    try:\n        return pydoc.locate(name)\n    except pydoc.ErrorDuringImport:\n        pass\n\n    # Try to find the class using a fallback method\n    parts = name.rsplit(\".\", 1)\n    if len(parts) == 2:\n        try:\n            m = __import__(parts[0], fromlist=parts[1])\n            return getattr(m, parts[1])\n        except AttributeError:\n            pass\n\n    raise ImportError(f\"Could not locate '{name}'\")"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # Try to find the function the normal way.\n    try:\n        return pydoc.locate(name)\n    except pydoc.ErrorDuringImport:\n        pass\n\n    # If that fails, fall back on our custom method.\n    try:\n        module_name, obj_name = name.rsplit(\".\", 1)\n        module = __import__(module_name, fromlist=[obj_name])\n        return getattr(module, obj_name)\n    except Exception as e:\n        raise RuntimeError(f\"Could not locate '{name}': {e}\")"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # Try to find the class using the standard locator.\n    obj = pydoc.locate(name)\n\n    # Fallback method.\n    if obj is None:\n        parts = name.split(\".\")\n        if len(parts) <= 1:\n            raise ValueError(f\"Could not locate \\'{name}\\'\")\n        obj = pydoc.locate(parts[0])\n        for part in parts[1:]:\n            obj = getattr(obj, part)\n\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # if name.startswith(\"torchvision.models.\"):\n    #     return locate_torchvision_model(name)\n    # if name.startswith(\"torchvision.ops.\"):\n    #     return locate_torchvision_op(name)\n    if name.startswith(\"detectron2.\"):\n        return locate_detectron2_model(name)\n    if name.startswith(\"detectron2.layers.\"):\n        return locate_detectron2_layer(name)\n    if name.startswith(\"detectron2.modeling.\"):\n        return locate_detectron2_modeling(name)\n    if name.startswith(\"detectron2.modeling.meta_arch.\"):\n        return locate_detectron2_meta_arch(name)\n    if name.startswith(\"detectron2.modeling.meta_arch.build\"):\n        return locate_detectron2_meta_arch_build(name)\n    if name.startswith(\"detectron2.modeling.meta_arch.build_backbone\"):\n        return locate_detectron2_meta_arch_build_backbone(name)\n    if name.startswith(\"detectron2.modeling.meta_arch.build_box_head\"):\n        return locate_detectron2_meta_arch_build_box_head(name)\n    if name.startswith(\"detectron2.modeling.meta_arch.build_keypoint_head\"):\n        return locate_detectron2_meta_arch_build_keypoint_head(name)\n    if name.startswith(\"detectron2.modeling.meta_arch.build_mask_head\"):\n        return locate_detectron2_meta_arch_build_mask_head(name)\n    if name.startswith(\"detectron2.modeling.meta_arch.build_sem_seg_head\"):\n        return locate_detectron2_meta_arch_build_sem_seg_head(name)\n    if name.startswith(\"detectron2.modeling.meta_arch.build"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # First, attempt to locate using the standard method.\n    obj = pydoc.locate(name)\n\n    # If the object cannot be located by the standard method, attempt to locate using a fallback method.\n    if obj is None:\n        obj = _locate_fallback(name)\n\n    # If the object still cannot be located, raise an exception.\n    if obj is None:\n        raise ValueError(f\"Could not locate '{name}'.\")\n\n    # Return the located Python object.\n    return obj\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    \"\"\"\n    Locate and return an object using its name.\n\n    Args:\n        name (str): the fully-qualified name of the object to locate.\n    Returns:\n        Any: the located object.\n    \"\"\"\n    # Try to find the object using the standard locator.\n    obj = pydoc.locate(name)\n    if obj is not None:\n        return obj\n    # Try to find the object using a fallback method.\n    mod_name, obj_name = name.rsplit(\".\", 1)\n    try:\n        module = __import__(mod_name, fromlist=[obj_name])\n        obj = getattr(module, obj_name)\n        return obj\n    except:\n        pass\n    # Raise an exception.\n    raise ImportError(f\"Could not locate '{name}'\")"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # Try to find the function using the standard import mechanism.\n    obj = pydoc.locate(name)\n    if obj is not None:\n        return obj\n\n    # If the search failed, try to import the module using the custom method.\n    parts = name.split(\".\")\n    if len(parts) != 2:\n        raise ImportError(f\"Input to locate() must be a fully qualified name: {name}\")\n    mod_name, obj_name = parts[0], parts[1]\n    mod = pydoc.locate(mod_name)\n    if mod is None:\n        raise ImportError(f\"Error loading module {mod_name}\")\n    if not hasattr(mod, obj_name):\n        raise ImportError(f\"No function named '{obj_name}' in module '{mod_name}'\")\n    return getattr(mod, obj_name)"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # Try to find the class using the standard import mechanism.\n    try:\n        return pydoc.locate(name)\n    except pydoc.ErrorDuringImport:\n        pass\n\n    # Try to find the class using a custom method.\n    # Split the fully qualified name of the object into module name and class name.\n    parts = name.split(\".\")\n    # Check that the module name is valid.\n    module_name = \".\".join(parts[:-1])\n    if module_name not in sys.modules:\n        raise pydoc.ErrorDuringImport(\n            f\"Module {module_name} not found while trying to locate {name}\"\n        )\n    # Check that the module contains the specified class.\n    module = sys.modules[module_name]\n    if not hasattr(module, parts[-1]):\n        raise pydoc.ErrorDuringImport(\n            f\"Class {parts[-1]} not found in module {module_name} while trying to locate {name}\"\n        )\n    # Return the class.\n    return getattr(module, parts[-1])"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # Try to find the class using the standard method\n    try:\n        return pydoc.locate(name)\n    except pydoc.ErrorDuringImport as e:\n        # Try to find the class using a fallback method\n        try:\n            parts = name.rsplit(\".\", 1)\n            return getattr(sys.modules[parts[0]], parts[1])\n        except (ImportError, AttributeError, KeyError, ValueError):\n            raise ImportError(\n                f\"Could not locate {name} using pydoc.locate, and could not import {parts[0]} manually.\"\n            ) from e"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # Try to find the object using the standard import mechanism.\n    obj = pydoc.locate(name)\n\n    # If the object could not be found using the standard import mechanism,\n    # try to import the top-level module.\n    if obj is None:\n        parts = name.split(\".\")\n        obj = pydoc.locate(parts[0])\n\n    # If the object could still not be found, then try to import custom modules.\n    if obj is None:\n        obj = pydoc.locate(f\"fairscale.optim.{name}\")\n\n    # If the object could still not be found, then try to import custom modules.\n    if obj is None:\n        obj = pydoc.locate(f\"fairscale.nn.{name}\")\n\n    # If the object could still not be found, then try to import custom modules.\n    if obj is None:\n        obj = pydoc.locate(f\"fairscale.nn.data.{name}\")\n\n    # If the object could still not be found, then try to import custom modules.\n    if obj is None:\n        obj = pydoc.locate(f\"fairscale.nn.modules.{name}\")\n\n    # If the object could still not be found, then try to import custom modules.\n    if obj is None:\n        obj = pydoc.locate(f\"fairscale.nn.modeling.{name}\")\n\n    # If the object could still not be found, then try to import custom modules.\n    if obj is None:\n        obj = pydoc.locate(f\"fairscale.nn.optim.{name}\")\n\n    # If the object could still not be found, then try to import custom modules.\n    if obj is None:\n        obj = pydoc.locate(f\"fairscale.nn.wrap.{name}\")\n\n    # If the object could still not be found, then try to import custom modules.\n    if obj is None:\n        obj = pydoc.locate(f\"fairscale.training.{name}\")\n\n    # If the object could still not be found, then try to import custom modules"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # Try to find the object using the standard import mechanism.\n    try:\n        return pydoc.locate(name)\n    except pydoc.ErrorDuringImport:\n        pass\n\n    # Try to find the object as a fully-qualified name.\n    try:\n        return locate_using_fully_qualified_name(name)\n    except ValueError:\n        pass\n\n    # Try to find the object as a class.\n    try:\n        return locate_using_class_name(name)\n    except ValueError:\n        pass\n\n    raise ValueError(f\"Unable to locate object: {name}\")\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # Try to find the object using the standard import mechanism.\n    try:\n        return pydoc.locate(name)\n    except pydoc.ErrorDuringImport:\n        pass\n\n    # Try to find the object as a fully-qualified name within the globals of all modules that have been imported.\n    # This handles the case where the object is in a binary extension (see https://github.com/facebookresearch/fvcore/issues/46).\n    # This code is based on https://stackoverflow.com/a/50990839.\n    module_names = {k for k, v in sys.modules.items() if v is not None}\n    for module_name in module_names:\n        try:\n            module = sys.modules[module_name]\n            if name.startswith(module.__name__):\n                obj = module\n                for attr in name[len(module.__name__) + 1 :].split(\".\"):\n                    obj = getattr(obj, attr)\n                return obj\n        except AttributeError:\n            pass\n\n    raise RuntimeError(f\"Could not locate '{name}'\")"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # Try to find the class using the standard import mechanism.\n    obj = pydoc.locate(name)\n    if obj is not None:\n        return obj\n\n    # If the class cannot be located by the standard import mechanism, try to\n    # import the top-level module.\n    parts = name.split(\".\")\n    try:\n        obj = __import__(parts[0])\n    except ModuleNotFoundError as e:\n        # If the module itself cannot be found, then add more context to the exception\n        # message and re-raise it.\n        raise ModuleNotFoundError(\n            f\"Module '{parts[0]}' cannot be found. If this is a model provided by detectron2, \"\n            \"please make sure the model name is correct. \"\n            \"Otherwise, please make sure the module is installed. \"\n            f\"See https://detectron2.readthedocs.io/en/latest/modules.html#models for the list of models provided by detectron2.\"\n        ) from e\n\n    # Use the remaining parts of the name as attributes to traverse down the module\n    # to the class.\n    for part in parts[1:]:\n        obj = getattr(obj, part)\n\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    \"\"\"\n    Locate and return an object based on a fully-qualified string name.\n\n    Args:\n        name (str): The fully-qualified name of the object to locate,\n            e.g. \"fvcore.common.registry.Registry\".\n\n    Returns:\n        Any\n    \"\"\"\n    obj = pydoc.locate(name)\n\n    if obj is None:\n        # obj was not found by pydoc.locate. Try to import the module\n        # in case it was a failure of pydoc.locate to identify the module\n        # (happens when obj is a class that is not explicitly defined in its module).\n        *module_parts, name = name.split(\".\")\n        module_name = \".\".join(module_parts)\n        try:\n            obj = getattr(pydoc.locate(module_name), name)\n        except (AttributeError, ModuleNotFoundError):\n            pass\n\n    if obj is None:\n        raise ModuleNotFoundError(\n            \"Could not locate object '%s' in the registry; make sure the module \"\n            \"the class is defined in has been imported\" % name\n        )\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # Try to find the function using the standard import mechanism.\n    try:\n        return pydoc.locate(name)\n    except Exception:\n        pass\n\n    # If that doesn't work, try to import the module.\n    try:\n        module_name = name.rpartition(\".\")[0]\n        module = __import__(module_name, fromlist=[name])\n        return getattr(module, name)\n    except Exception:\n        pass\n\n    # If that doesn't work, try to locate the function using a fallback method.\n    try:\n        module_name, class_name = name.rsplit(\".\", 1)\n        module = __import__(module_name, fromlist=[name])\n        module_path = module.__path__\n        module_path = [str(path) for path in module_path]\n        fallback_path = \".\".join(module_path[:-1])\n        module = __import__(module_name, fromlist=[name])\n        fallback_module = __import__(fallback_path, fromlist=[class_name])\n        return getattr(fallback_module, class_name)\n    except Exception:\n        pass\n\n    # If that doesn't work, try to locate the function using a fallback method.\n    try:\n        module_name, class_name = name.rsplit(\".\", 1)\n        module = __import__(module_name, fromlist=[name])\n        module_path = module.__path__\n        module_path = [str(path) for path in module_path]\n        fallback_path = \".\".join(module_path[:-1])\n        module = __import__(module_name, fromlist=[name])\n        fallback_module = __import__(fallback_path, fromlist=[class_name])\n        return getattr(fallback_module, class_name)\n    except Exception:\n        pass\n\n    raise RuntimeError(f\"Could not locate '{name}'\")"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    \"\"\"\n    Locate and return an object using it's name.\n\n    Args:\n        name (str): fully qualified name (E.g., module.submodule.class_name)\n    Returns:\n        object (Any): the located object\n    \"\"\"\n    # Try to find the object using the standard importlib method.\n    try:\n        return pydoc.locate(name)\n    except pydoc.ErrorDuringImport as e:\n        # If this fails, then try to import the module using a custom method.\n        try:\n            paths = name.split(\".\")\n            # If there are multiple paths, import the module.\n            if len(paths) > 1:\n                module_name = \".\".join(paths[:-1])\n                module = __import__(module_name, fromlist=[paths[-1]])\n            # If there is just one path, assume that the calling scope is the module.\n            else:\n                module = __import__(paths[0], fromlist=[\"_dummy\"])\n            return getattr(module, paths[-1])\n        except ModuleNotFoundError as e:\n            # If the module could not be imported, then we cannot locate the object.\n            raise ImportError(f\"Could not locate the object {name} using the standard import method or the custom import method.\") from e"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    \"\"\"\n    Locate and return an object based on a fully-qualified string name.\n\n    Args:\n        name (str): fully qualified name to lookup\n\n    Returns:\n        object (Any): the located object\n    \"\"\"\n    # Try to find the object by normal means\n    try:\n        return pydoc.locate(name)\n    except pydoc.ErrorDuringImport:\n        # Try to import the name directly - this works for things that are\n        # built into the interpreter, like \"sys\" and \"math\".\n        try:\n            return __import__(name)\n        except ImportError:\n            pass\n\n        # Could not import the module. This is a local file, specified as\n        # \"module.submodule.file_name\". We need to locate the file and\n        # import it.\n        if \".\" in name:\n            parts = name.split(\".\")\n            target = parts[-1]\n            module_name = \".\".join(parts[:-1])\n            try:\n                module = __import__(module_name, fromlist=[target])\n            except ImportError:\n                # Could not import the module. Treat the first part as the\n                # module name, and the rest as the target.\n                module_name = parts[0]\n                target = \".\".join(parts[1:])\n                module = __import__(module_name, fromlist=[target])\n\n            # Recursively call this function on the rest of the name, using\n            # the imported module as a context. This will perform the correct\n            # late-binding of the import.\n            return locate(f\"{module_name}.{target}\")\n        else:\n            # Not a fully-qualified name. Try to import it normally.\n            return __import__(name)"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # Try to find the object using the standard import mechanism.\n    try:\n        return pydoc.locate(name)\n    except pydoc.ErrorDuringImport:\n        pass\n\n    # Try to find the object using the fallback method.\n    try:\n        parts = name.split(\".\")\n        target = __import__(\".\".join(parts[:-1]))\n        for part in parts[1:]:\n            target = getattr(target, part)\n        return target\n    except ModuleNotFoundError:\n        pass\n\n    # Raise an exception with a helpful message.\n    raise RuntimeError(\n        f\"Unable to locate the object named '{name}'. \"\n        f\"Please make sure that the module name is correct and that the file defining the object is accessible.\"\n    )\n\n"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)\n\n"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    # Save module to buffer\n    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n\n    # Load module from buffer\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    # Save the module to an in-memory buffer\n    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n\n    # Reset the buffer's current position to the beginning\n    buffer.seek(0)\n\n    # Load the module from the buffer\n    module_reloaded = torch.jit.load(buffer)\n\n    return module_reloaded"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)\n\n"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)\n\n"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)\n\n"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)\n\n"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)\n\n"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    # Save module to an in-memory buffer\n    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n\n    # Reset the buffer's current position to the beginning\n    buffer.seek(0)\n\n    # Load the module from the buffer\n    return torch.jit.load(buffer)\n\n"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)\n\n"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)\n\n"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)\n\n"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)\n\n"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)\n\n"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    # Save module to buffer\n    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n\n    # Load module from buffer\n    return torch.jit.load(buffer)\n\n"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)\n\n"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)\n\n"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Normalize the weights\n    weights = [w / sum(weights) for w in weights]\n\n    # Combine the scores\n    combined_scores = []\n    for i in range(len(ids)):\n        combined_scores.append([scores[i][j] * weights[i] for j in range(len(ids[i]))])\n\n    # Combine the ids\n    combined_ids = []\n    for i in range(len(ids)):\n        combined_ids.append([ids[i][j] for j in range(len(ids[i]))])\n\n    # Combine the scores and ids\n    combined_scores = [sum(x) for x in zip(*combined_scores)]\n    combined_ids = [x[0] for x in zip(*combined_ids)]\n\n    # Sort the scores and ids\n    combined_scores, combined_ids = (list(t) for t in zip(*sorted(zip(combined_scores, combined_ids), reverse=True)))\n\n    # Return the top k results\n    return combined_ids[:top_k], combined_scores[:top_k]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check that the ids and scores tuples have the same length\n    if len(ids) != len(scores):\n        raise ValueError(\"The ids and scores tuples must have the same length.\")\n\n    # Check that the ids and scores tuples have the same length\n    if len(ids) != len(weights):\n        raise ValueError(\"The ids and weights tuples must have the same length.\")\n\n    # Check that the sum of the weights is 1\n    if round(sum(weights), 3) != 1:\n        raise ValueError(\"The sum of the weights must equal 1.\")\n\n    # Create a DataFrame\n    df = pd.DataFrame()\n\n    # Add the ids and scores to the DataFrame\n    for i in range(len(ids)):\n        df[f\"id_{i}\"] = ids[i]\n        df[f\"score_{i}\"] = scores[i]\n\n    # Normalize the scores\n    for i in range(len(ids)):\n        df[f\"score_{i}\"] = df[f\"score_{i}\"] / df[f\"score_{i}\"].max()\n\n    # Combine the scores\n    df[\"combined_score\"] = 0\n    for i in range(len(ids)):\n        df[\"combined_score\"] += df[f\"score_{i}\"] * weights[i]\n\n    # Sort the DataFrame\n    df = df.sort_values(by=\"combined_score\", ascending=False)\n\n    # Select the top_k results\n    df = df.head(top_k)\n\n    # Return the ids and scores\n    return df.values.tolist(), df[\"combined_score\"].values.tolist()"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    assert len(ids) == len(scores) == len(weights), \"The length of the ids, scores, and weights tuples must match.\"\n    assert sum(weights) == 1, \"The sum of the weights must equal 1.\"\n\n    # Normalize the scores\n    norm_scores = []\n    for i in range(len(scores)):\n        norm_scores.append([score / weights[i] for score in scores[i]])\n\n    # Combine the scores\n    comb_scores = []\n    for i in range(len(norm_scores[0])):\n        comb_scores.append([sum(score[i] for score in norm_scores)])\n\n    # Create a dataframe for the combined scores\n    df = pd.DataFrame({\"id\": ids[0], \"score\": comb_scores})\n\n    # Group by id and aggregate the scores\n    df = df.groupby(\"id\").agg({\"score\": \"sum\"}).reset_index()\n\n    # Sort the dataframe by score\n    df = df.sort_values(by=\"score\", ascending=False)\n\n    # Select the top_k ids and scores\n    ids = df[\"id\"].values[:top_k].tolist()\n    scores = df[\"score\"].values[:top_k].tolist()\n\n    return ids, scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    assert len(ids) == len(scores) == len(weights), \"The lengths of the ids, scores, and weights tuples must match.\"\n    assert sum(weights) == 1, \"The sum of the weights must equal 1.\"\n\n    # Normalize the scores based on the provided weights\n    norm_scores = []\n    for i in range(len(scores)):\n        norm_scores.append([score * weights[i] for score in scores[i]])\n\n    # Combine the normalized scores into a single list\n    norm_scores = [item for sublist in norm_scores for item in sublist]\n\n    # Create a dataframe with the ids and scores\n    df = pd.DataFrame({\"id\": ids, \"score\": norm_scores})\n\n    # Group the dataframe by id\n    df = df.groupby(\"id\").sum()\n\n    # Sort the dataframe by score\n    df = df.sort_values(by=[\"score\"], ascending=False)\n\n    # Return the top_k ids and scores\n    return df.head(top_k).index.to_list(), df.head(top_k)[\"score\"].to_list()"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Normalize the scores\n    norm_scores = []\n    for i in range(len(scores)):\n        norm_scores.append([score / sum(scores[i]) for score in scores[i]])\n\n    # Combine the scores\n    comb_scores = []\n    for i in range(len(norm_scores)):\n        comb_scores.append([norm_scores[i][j] * weights[i] for j in range(len(norm_scores[i]))])\n\n    # Combine the ids\n    comb_ids = []\n    for i in range(len(ids)):\n        comb_ids.append([ids[i][j] for j in range(len(ids[i]))])\n\n    # Combine the lists\n    comb_scores = [sum(x) for x in zip(*comb_scores)]\n    comb_ids = [x[0] for x in zip(*comb_ids)]\n\n    # Sort the lists\n    sorted_scores = sorted(comb_scores, reverse=True)\n    sorted_ids = [x for _, x in sorted(zip(comb_scores, comb_ids), reverse=True)]\n\n    # Return the top k results\n    return sorted_ids[:top_k], sorted_scores[:top_k]\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check that the ids and scores tuples have the same length\n    assert len(ids) == len(scores)\n\n    # Check that the weights tuple has the same length as the ids and scores tuples\n    assert len(weights) == len(ids)\n\n    # Check that the weights sum to 1\n    assert round(sum(weights), 3) == 1\n\n    # Combine the ids and scores into a single dataframe\n    df = pd.DataFrame({\n        \"id\": [item for sublist in ids for item in sublist],\n        \"score\": [item for sublist in scores for item in sublist]\n    })\n\n    # Normalize the scores based on the weights\n    df[\"score\"] = df[\"score\"] * df.groupby(\"id\").transform(\n        lambda x: weights[x.name] / sum(weights))\n\n    # Select the top_k results\n    df = df.sort_values(by=\"score\", ascending=False).head(top_k)\n\n    # Return the fused ids and scores\n    return df[\"id\"].tolist(), df[\"score\"].tolist()"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # validate input\n    assert len(ids) == len(scores) == len(weights), \"The length of the ids, scores, and weights tuples must match.\"\n    assert sum(weights) == 1, \"The sum of the weights must equal 1.\"\n\n    # normalize scores\n    normalized_scores = []\n    for i in range(len(scores)):\n        norm_scores = []\n        for j in range(len(scores[i])):\n            norm_scores.append(scores[i][j] * weights[i])\n        normalized_scores.append(norm_scores)\n\n    # combine scores\n    combined_scores = []\n    for i in range(len(normalized_scores[0])):\n        combined_score = 0\n        for j in range(len(normalized_scores)):\n            combined_score += normalized_scores[j][i]\n        combined_scores.append(combined_score)\n\n    # create dataframe\n    df = pd.DataFrame(\n        {\"ids\": ids[0], \"scores\": combined_scores, \"source\": \"hybrid_cc\"})\n\n    # sort dataframe by score\n    df = df.sort_values(by=[\"scores\"], ascending=False)\n\n    # select top k\n    df = df.head(top_k)\n\n    # return results\n    return df[\"ids\"].tolist(), df[\"scores\"].tolist()"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # check that the number of weights matches the number of ids and scores\n    if len(weights) != len(ids) or len(weights) != len(scores):\n        raise ValueError(\n            \"The number of weights must match the number of ids and scores.\")\n\n    # check that the weights sum to 1\n    if round(sum(weights), 2) != 1:\n        raise ValueError(\"The weights must sum to 1.\")\n\n    # normalize the scores\n    normalized_scores = []\n    for i in range(len(ids)):\n        normalized_scores.append([score * weights[i] for score in scores[i]])\n\n    # combine the scores\n    combined_scores = []\n    for i in range(len(ids)):\n        if i == 0:\n            combined_scores = normalized_scores[i]\n        else:\n            combined_scores = [\n                combined_scores[j] + normalized_scores[i][j]\n                for j in range(len(combined_scores))\n            ]\n\n    # create the combined ids and scores dataframes\n    combined_ids = pd.DataFrame(ids[0][:top_k])\n    combined_scores = pd.DataFrame(combined_scores[:top_k])\n\n    # return the combined ids and scores\n    return (combined_ids.values.tolist(), combined_scores.values.tolist())"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check that the ids and scores tuples are the same length\n    assert len(ids) == len(scores)\n\n    # Check that the weights tuple is the same length as the ids and scores tuples\n    assert len(weights) == len(ids)\n\n    # Check that the weights tuple sums to 1\n    assert sum(weights) == 1\n\n    # Normalize the scores\n    norm_scores = []\n    for i in range(len(scores)):\n        norm_scores.append([s/sum(scores[i]) for s in scores[i]])\n\n    # Combine the scores based on the weights\n    comb_scores = []\n    for i in range(len(norm_scores)):\n        comb_scores.append([norm_scores[i][j] * weights[i] for j in range(len(norm_scores[i]))])\n\n    # Combine the ids and scores\n    comb_ids = []\n    comb_scores = []\n    for i in range(len(ids)):\n        comb_ids.append(ids[i])\n        comb_scores.append(comb_scores[i])\n\n    # Create a dataframe of the ids and scores\n    df = pd.DataFrame({'ids': comb_ids, 'scores': comb_scores})\n\n    # Aggregate the ids and scores\n    df = df.groupby('ids', as_index=False).agg('sum')\n\n    # Sort the aggregated results\n    df = df.sort_values(by='scores', ascending=False)\n\n    # Select the top_k results\n    df = df.head(top_k)\n\n    # Return the ids and scores\n    return df['ids'].tolist(), df['scores'].tolist()"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check that the ids and scores tuples are of the same length\n    if len(ids) != len(scores):\n        raise ValueError(\"ids and scores must be of the same length\")\n\n    # Check that the ids and scores tuples are of the same length\n    if len(ids) != len(weights):\n        raise ValueError(\"ids and weights must be of the same length\")\n\n    # Check that the sum of the weights is 1\n    if sum(weights) != 1:\n        raise ValueError(\"The sum of the weights must equal 1\")\n\n    # Normalize the scores\n    scores = [\n        [score / sum(scores[i]) for score in scores[i]]\n        for i in range(len(scores))\n    ]\n\n    # Combine the scores\n    scores = [\n        [scores[i][j] * weights[i] for i in range(len(scores))]\n        for j in range(len(scores[0]))\n    ]\n\n    # Create a dataframe containing the ids and scores\n    df = pd.DataFrame(\n        {\n            \"ids\": [ids[i][j] for i in range(len(ids)) for j in range(len(ids[i]))],\n            \"scores\": [scores[i][j] for i in range(len(scores)) for j in range(len(scores[i]))],\n        }\n    )\n\n    # Group by the ids\n    df = df.groupby(\"ids\").sum().reset_index()\n\n    # Sort by scores\n    df = df.sort_values(by=\"scores\", ascending=False).reset_index(drop=True)\n\n    # Select the top k results\n    df = df.head(top_k)\n\n    # Return the ids and scores\n    return df.ids.tolist(), df.scores.tolist()"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    if len(ids) != len(scores) or len(ids) != len(weights):\n        raise Exception(\"The length of the ids, scores, and weights tuples must be equal.\")\n\n    if sum(weights) != 1:\n        raise Exception(\"The weights must sum to 1.\")\n\n    # Normalize the scores\n    normalized_scores = []\n    for i in range(len(scores)):\n        normalized_scores.append([score / weights[i] for score in scores[i]])\n\n    # Combine the normalized scores\n    combined_scores = []\n    for i in range(len(normalized_scores[0])):\n        combined_scores.append(\n            sum([normalized_scores[j][i] for j in range(len(normalized_scores))])\n        )\n\n    # Create a dataframe of the combined scores\n    df = pd.DataFrame(\n        {\"id\": [id for ids in ids for id in ids], \"score\": combined_scores}\n    )\n\n    # Group the scores by id and take the mean\n    df = df.groupby([\"id\"], as_index=False).mean()\n\n    # Sort the scores\n    df = df.sort_values(by=[\"score\"], ascending=False)\n\n    # Select the top k scores\n    df = df.head(top_k)\n\n    # Return the ids and scores\n    return df[\"id\"].tolist(), df[\"score\"].tolist()"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check that the length of the ids and scores tuples are the same\n    assert len(ids) == len(scores)\n\n    # Check that the length of the ids and scores tuples are the same as the length of the weights tuple\n    assert len(ids) == len(weights)\n\n    # Check that the weights sum to 1\n    assert sum(weights) == 1\n\n    # Normalize the scores based on the weights\n    norm_scores = []\n    for i in range(len(scores)):\n        norm_scores.append([score * weights[i] for score in scores[i]])\n\n    # Combine the scores into a single list\n    combined_scores = [sum(x) for x in zip(*norm_scores)]\n\n    # Create a pandas dataframe with the ids and scores\n    df = pd.DataFrame({\"id\": ids[0], \"score\": combined_scores})\n\n    # Group the ids based on the scores, and keep only the top_k ids\n    df = df.sort_values(\"score\", ascending=False).groupby(\"id\").head(top_k)\n\n    # Return the fused ids and scores\n    return df[\"id\"].tolist(), df[\"score\"].tolist()"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check that the ids and scores tuples have the same length\n    assert len(ids) == len(scores)\n\n    # Check that the ids and scores tuples have the same length as the weights tuple\n    assert len(ids) == len(weights)\n\n    # Check that the weights tuple has a sum of 1\n    assert round(sum(weights), 3) == 1\n\n    # Normalize the scores\n    scores = [\n        [score / max(score) for score in scores[i]]\n        for i in range(len(scores))\n    ]\n\n    # Combine the scores\n    scores = [\n        [scores[i][j] * weights[i] for i in range(len(scores))]\n        for j in range(len(scores[0]))\n    ]\n\n    # Create a dataframe from the ids and scores\n    df = pd.DataFrame(\n        {\"id\": [i for sublist in ids for i in sublist], \"score\": [i for sublist in scores for i in sublist]}\n    )\n\n    # Group the dataframe by id and aggregate the scores\n    df = df.groupby(\"id\").agg({\"score\": sum}).reset_index()\n\n    # Sort the dataframe by score\n    df = df.sort_values(by=\"score\", ascending=False)\n\n    # Get the top_k ids and scores\n    ids = df[\"id\"].tolist()[:top_k]\n    scores = df[\"score\"].tolist()[:top_k]\n\n    return ids, scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check that the ids and scores tuples have the same length\n    if len(ids) != len(scores):\n        raise ValueError(\n            \"The ids and scores tuples must have the same length.\")\n\n    # Check that the weights tuple has the same length as the ids and scores tuples\n    if len(weights) != len(ids):\n        raise ValueError(\n            \"The weights tuple must have the same length as the ids and scores tuples.\")\n\n    # Check that the weights tuple sums to 1\n    if round(sum(weights), 2) != 1:\n        raise ValueError(\n            \"The weights tuple must sum to 1.\")\n\n    # Normalize the scores based on the weights\n    norm_scores = []\n    for i in range(len(scores)):\n        norm_scores.append([score * weights[i] for score in scores[i]])\n\n    # Combine the normalized scores\n    combined_scores = []\n    for i in range(len(norm_scores[0])):\n        combined_scores.append(sum([norm_score[i] for norm_score in norm_scores]))\n\n    # Create a dataframe with the ids and scores\n    df = pd.DataFrame(\n        {'id': [item for sublist in ids for item in sublist],\n         'score': combined_scores\n         })\n\n    # Group the dataframe by id and aggregate the scores\n    df = df.groupby('id').agg({'score': 'sum'}).reset_index()\n\n    # Sort the dataframe by score\n    df = df.sort_values(by=['score'], ascending=False)\n\n    # Select the top_k ids and scores\n    df = df.head(top_k)\n\n    # Return the fused ids and scores\n    return df['id'].tolist(), df['score'].tolist()"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Normalize the weights\n    weights = [float(w) / sum(weights) for w in weights]\n\n    # Get the number of retrieval results\n    num_results = len(ids)\n\n    # Check that the number of ids, scores, and weights are equal\n    assert len(ids) == len(scores) == len(weights)\n\n    # Combine the ids and scores\n    combined_ids = []\n    combined_scores = []\n    for i in range(num_results):\n        combined_ids.append(ids[i])\n        combined_scores.append(scores[i])\n\n    # Convert the lists to dataframes\n    df_ids = pd.DataFrame(combined_ids)\n    df_scores = pd.DataFrame(combined_scores)\n\n    # Normalize the scores\n    df_scores = df_scores.div(df_scores.sum(axis=1), axis=0)\n\n    # Multiply the scores by the weights\n    df_scores = df_scores.mul(weights, axis=1)\n\n    # Get the top k results\n    df_ids = df_ids.iloc[df_scores.sum(axis=1).sort_values(ascending=False).head(top_k).index]\n    df_scores = df_scores.iloc[df_scores.sum(axis=1).sort_values(ascending=False).head(top_k).index]\n\n    # Convert the dataframes to lists\n    combined_ids = df_ids.values.tolist()\n    combined_scores = df_scores.values.tolist()\n\n    return combined_ids, combined_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Normalize the weights\n    weights = [w / sum(weights) for w in weights]\n\n    # Normalize the scores\n    normalized_scores = []\n    for score in scores:\n        normalized_scores.append(\n            [score_val / max(score) for score_val in score]\n        )\n\n    # Combine the scores\n    combined_scores = []\n    for weight, score in zip(weights, normalized_scores):\n        combined_scores.append([weight * score_val for score_val in score])\n\n    # Sum the scores\n    combined_scores = [\n        sum(score_vals) for score_vals in zip(*combined_scores)\n    ]\n\n    # Get the top k scores\n    top_k_scores = sorted(combined_scores, reverse=True)[:top_k]\n\n    # Get the ids of the top k scores\n    top_k_ids = [ids[i] for i, score in enumerate(combined_scores) if score in top_k_scores]\n\n    return top_k_ids, top_k_scores\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check that the ids and scores tuples are the same length\n    if len(ids) != len(scores):\n        raise ValueError(\"The ids and scores tuples must be the same length.\")\n\n    # Check that the weights tuple is the same length as the ids and scores tuples\n    if len(weights) != len(ids):\n        raise ValueError(\"The weights tuple must be the same length as the ids and scores tuples.\")\n\n    # Check that the weights tuple sums to 1\n    if round(sum(weights), 3) != 1:\n        raise ValueError(\"The weights tuple must sum to 1.\")\n\n    # Normalize the scores\n    scores = [\n        [score / max(score) for score in scores_list] for scores_list in scores\n    ]\n\n    # Combine the scores\n    scores = [\n        [\n            sum([weights[i] * scores_list[i] for i in range(len(scores_list))])\n            for scores_list in zip(*scores)\n        ]\n        for scores in scores\n    ]\n\n    # Combine the ids\n    ids = [\n        [\n            ids_list[i]\n            for ids_list in zip(*ids)\n        ]\n        for ids in ids\n    ]\n\n    # Convert the ids and scores to dataframes\n    ids = pd.DataFrame(ids)\n    scores = pd.DataFrame(scores)\n\n    # Combine the scores and ids\n    df = pd.concat([scores, ids], axis=1)\n\n    # Sort the dataframe by the scores\n    df = df.sort_values(by=0, ascending=False)\n\n    # Select the top_k results\n    df = df.head(top_k)\n\n    # Return the ids and scores\n    return df[1].values.tolist(), df[0].values.tolist()"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Normalize weights\n    weights = [w / sum(weights) for w in weights]\n\n    # Get the length of each list\n    ids_lengths = [len(ids_list) for ids_list in ids]\n\n    # Combine the scores\n    combined_scores = [\n        sum(\n            [\n                weights[i] * scores_list[j]\n                for i, scores_list in enumerate(scores)\n            ]\n        )\n        for j in range(min(ids_lengths))\n    ]\n\n    # Combine the ids\n    combined_ids = [\n        [ids_list[i] for ids_list in ids]\n        for i in range(min(ids_lengths))\n    ]\n\n    # Sort the combined results\n    combined_df = pd.DataFrame(\n        {\"ids\": combined_ids, \"scores\": combined_scores}).sort_values(\n        \"scores\", ascending=False)\n\n    # Return the top k results\n    return combined_df[\"ids\"].head(top_k).tolist(), combined_df[\"scores\"].head(\n        top_k).tolist()"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    assert len(ids) == len(scores)\n    assert len(ids) == len(weights)\n    assert sum(weights) == 1\n\n    # Normalize the scores\n    scores = [\n        [score / max(score) for score in scores_list] for scores_list in scores\n    ]\n\n    # Combine the scores\n    scores = [\n        [score_list[i] * weight for score_list, weight in zip(scores, weights)]\n        for i in range(len(scores[0]))\n    ]\n\n    # Combine the ids\n    ids = [\n        [ids_list[i] for ids_list in ids]\n        for i in range(len(ids[0]))\n    ]\n\n    # Combine the ids and scores\n    ids_scores = [\n        (ids_list[i], score_list[i])\n        for ids_list, score_list in zip(ids, scores)\n        for i in range(len(ids_list))\n    ]\n\n    # Sort the ids and scores\n    ids_scores.sort(key=lambda x: x[1], reverse=True)\n\n    # Return the top_k ids and scores\n    return [\n        [ids_score[0] for ids_score in ids_scores[:top_k]],\n        [ids_score[1] for ids_score in ids_scores[:top_k]],\n    ]\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check if the weights sum to 1\n    if round(sum(weights), 2) != 1:\n        raise ValueError(\"Weights must sum to 1.\")\n\n    # Check if the weights and scores are of the same length\n    if len(weights) != len(scores):\n        raise ValueError(\"The length of the weights and scores must be the same.\")\n\n    # Check if the weights and ids are of the same length\n    if len(weights) != len(ids):\n        raise ValueError(\"The length of the weights and ids must be the same.\")\n\n    # Check if the top_k is positive\n    if top_k < 1:\n        raise ValueError(\"top_k must be a positive integer.\")\n\n    # Check if the ids and scores are of the same length\n    for i in range(len(ids)):\n        if len(ids[i]) != len(scores[i]):\n            raise ValueError(\"The length of the ids and scores must be the same.\")\n\n    # Combine the ids and scores\n    hybrid_ids = []\n    hybrid_scores = []\n    for i in range(len(ids)):\n        hybrid_ids += ids[i]\n        hybrid_scores += [score * weights[i] for score in scores[i]]\n\n    # Combine the ids and scores into a dataframe\n    hybrid_df = pd.DataFrame({\"id\": hybrid_ids, \"score\": hybrid_scores})\n\n    # Group the results by id\n    hybrid_df = hybrid_df.groupby([\"id\"]).sum().reset_index()\n\n    # Sort the results by score\n    hybrid_df = hybrid_df.sort_values(by=[\"score\"], ascending=False).reset_index(drop=True)\n\n    # Select the top_k results\n    hybrid_df = hybrid_df.head(top_k)\n\n    # Return the ids and scores\n    return hybrid_df[\"id\"].tolist(), hybrid_df[\"score\"].tolist()"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    if percent:\n        x = x * 100\n    if abs(x) > 1:\n        return f\"{x:.0f}\"\n    if abs(x) > 0.01:\n        return f\"{x:.2f}\"\n    if abs(x) > 0.0001:\n        return f\"{x:.4f}\"\n    return f\"{x:.6e}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    elif percent:\n        x = x * 100\n        if x == 0:\n            return \"0.00%\"\n        elif 0.01 <= abs(x) < 100:\n            return f\"{x:.2f}%\"\n        else:\n            return f\"{x:.0f}%\"\n    else:\n        if x == 0:\n            return \"0.00\"\n        elif 0.01 <= abs(x) < 10:\n            return f\"{x:.2f}\"\n        elif 10 <= abs(x) < 1000:\n            return f\"{x:.1f}\"\n        else:\n            return f\"{x:.0f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    # If the number is NaN, return the string representation of NaN\n    if np.isnan(x):\n        return str(x)\n\n    # If the number is an integer, return the integer\n    if x == int(x):\n        return str(int(x))\n\n    # If the number is a percentage, multiply it by 100\n    if percent:\n        x *= 100\n\n    # If the number is a percentage, add a percentage sign\n    if percent:\n        return f\"{x:.2f}%\"\n\n    # If the number is not a percentage, return the number with a dynamic number of decimal places\n    if x < 0.0001:\n        return f\"{x:.4f}\"\n    elif x < 0.01:\n        return f\"{x:.4f}\"\n    elif x < 1:\n        return f\"{x:.2f}\"\n    else:\n        return f\"{x:.0f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n\n    if percent:\n        x = x * 100\n\n    if percent and x == 100:\n        return \"100%\"\n\n    if percent and x == 0:\n        return \"0%\"\n\n    if x == 0:\n        return \"0\"\n\n    if percent:\n        return f\"{x:.2f}%\"\n\n    if x < 0.0001:\n        return f\"{x:.4e}\"\n\n    if x < 0.01:\n        return f\"{x:.4f}\"\n\n    if x < 0.1:\n        return f\"{x:.3f}\"\n\n    if x < 1:\n        return f\"{x:.2f}\"\n\n    if x < 10:\n        return f\"{x:.1f}\"\n\n    return f\"{x:.0f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n\n    if percent:\n        x *= 100\n\n    if x == 0:\n        return f\"{x:.0f}\"\n\n    if abs(x) > 10000:\n        return f\"{x:.0f}\"\n\n    if abs(x) < 1:\n        return f\"{x:.4f}\"\n\n    if abs(x) < 10:\n        return f\"{x:.3f}\"\n\n    if abs(x) < 100:\n        return f\"{x:.2f}\"\n\n    if abs(x) < 1000:\n        return f\"{x:.1f}\"\n\n    return f\"{x:.0f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    if percent:\n        x *= 100\n    x = round(x, 2)\n    if x == 0:\n        return \"0\"\n    if x == int(x):\n        return str(int(x))\n    return str(x)\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n\n    if percent:\n        x = x * 100\n\n    if x == 0:\n        return f\"{x:.0f}\"\n    elif abs(x) >= 1000000:\n        return f\"{x:,.0f}\"\n    elif abs(x) >= 10000:\n        return f\"{x:,.1f}\"\n    elif abs(x) >= 1000:\n        return f\"{x:,.2f}\"\n    elif abs(x) >= 100:\n        return f\"{x:,.3f}\"\n    else:\n        return f\"{x:,.4f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n\n    if percent:\n        x = 100 * x\n\n    if x == 0:\n        return \"0\"\n    elif 0.01 <= abs(x) < 1:\n        return f\"{x:.2%}\" if percent else f\"{x:.2f}\"\n    elif 1 <= abs(x) < 100:\n        return f\"{x:.0%}\" if percent else f\"{x:.0f}\"\n    else:\n        return f\"{x:,.0f}\" if percent else f\"{x:,.0f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n\n    if percent:\n        x *= 100\n\n    if x == 0:\n        return \"0\"\n    elif np.abs(x) < 1e-3:\n        return f\"{x:.4f}\"\n    elif np.abs(x) < 1e-2:\n        return f\"{x:.3f}\"\n    elif np.abs(x) < 1e-1:\n        return f\"{x:.2f}\"\n    elif np.abs(x) < 1e0:\n        return f\"{x:.1f}\"\n    else:\n        return f\"{x:.0f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n\n    if percent:\n        x = 100 * x\n\n    if x == 0:\n        return \"0\"\n    elif np.abs(x) >= 1000000:\n        return f\"{x:.1f}\"\n    elif np.abs(x) >= 10000:\n        return f\"{x:.0f}\"\n    elif np.abs(x) >= 100:\n        return f\"{x:.2f}\"\n    elif np.abs(x) >= 1:\n        return f\"{x:.3f}\"\n    else:\n        return f\"{x:.4f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    # Convert the number to a percentage if requested.\n    if percent:\n        x *= 100\n\n    # If the number is not a number, return the string representation of NaN.\n    if np.isnan(x):\n        return str(x)\n\n    # If the number is an integer, return the string representation of the number.\n    if x == int(x):\n        return str(int(x))\n\n    # If the number is a whole number, return the string representation of the number with one decimal place.\n    if x % 1 == 0:\n        return f\"{x:.1f}\"\n\n    # Otherwise, return the string representation of the number with a dynamic number of decimal places.\n    return f\"{x:.4g}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n\n    if percent:\n        x = x * 100\n\n    if abs(x) > 1000:\n        return f\"{x:.0f}\"\n    elif abs(x) > 10:\n        return f\"{x:.1f}\"\n    elif abs(x) > 1:\n        return f\"{x:.2f}\"\n    else:\n        return f\"{x:.3f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    # Checks if the input is a number.\n    if not np.isnan(x):\n        # Checks if the number is an integer.\n        if x % 1 == 0:\n            # Rounds the number.\n            x = int(round(x))\n        else:\n            # Gets the number of decimal places to use.\n            decimals = -int(np.math.floor(np.log10(np.abs(x)))) + 1\n            # Formats the number.\n            x = round(x, decimals)\n\n    # Checks if the number should be formatted as a percentage.\n    if percent:\n        # Multiplies the number by 100.\n        x *= 100\n        # Adds a percentage sign.\n        x = str(x) + \"%\"\n\n    return str(x)\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    if percent:\n        x = x * 100\n    if x == 0:\n        return \"0\"\n    elif x < 0.001:\n        return f\"{x:.6f}\"\n    elif x < 0.1:\n        return f\"{x:.5f}\"\n    elif x < 1:\n        return f\"{x:.4f}\"\n    elif x < 10:\n        return f\"{x:.3f}\"\n    elif x < 100:\n        return f\"{x:.2f}\"\n    else:\n        return f\"{x:.1f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    if percent:\n        x *= 100\n    if x == 0:\n        return \"0\"\n    if abs(x) > 1000000000 or abs(x) < 0.000001:\n        return f\"{x:.1e}\"\n    if abs(x) >= 1000000 or abs(x) < 0.001:\n        return f\"{x:,.0f}\"\n    if abs(x) >= 1000 or abs(x) < 1:\n        return f\"{x:,.1f}\"\n    return f\"{x:,.2f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n\n    if percent:\n        x *= 100\n\n    if x == 0:\n        x = 0\n\n    if x < 0.0001:\n        x = f\"{x:.4f}\"\n    elif x < 0.01:\n        x = f\"{x:.3f}\"\n    elif x < 0.1:\n        x = f\"{x:.2f}\"\n    elif x < 1:\n        x = f\"{x:.1f}\"\n    else:\n        x = f\"{x:.0f}\"\n\n    if percent:\n        x += \"%\"\n\n    return x\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    else:\n        if percent:\n            x = x * 100\n            if x == 0:\n                return \"0.00%\"\n            else:\n                return f\"{x:.2f}%\"\n        else:\n            if x == 0:\n                return \"0.00\"\n            else:\n                return f\"{x:.2f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    # Convert the number to a percentage if requested.\n    if percent:\n        x *= 100\n\n    # If the number is not a number, return the string representation of NaN.\n    if np.isnan(x):\n        return \"NaN\"\n\n    # If the number is an integer, return the integer as a string.\n    if x == int(x):\n        return str(int(x))\n\n    # If the number is a whole number, return it with 0 decimal places.\n    if x % 1 == 0:\n        return f\"{int(x)}\"\n\n    # If the number is a float, return it with a dynamic number of decimal places.\n    if x % 1 != 0:\n        return f\"{x:.4g}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(np.nan)\n    elif percent:\n        x = x * 100\n        x = round(x, 2)\n        return f\"{x:.2f}%\"\n    else:\n        x = round(x, 2)\n        return f\"{x:.2f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n\n    if percent:\n        x *= 100\n\n    if x == 0:\n        x = 0\n\n    elif 0.01 <= abs(x) < 100:\n        x = f\"{x:.2f}\"\n\n    else:\n        x = f\"{x:.0f}\"\n\n    if percent:\n        x += \"%\"\n\n    return x\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while shutil.disk_usage(input_dir).free / 1024**3 > threshold_in_gb:\n        sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while shutil.disk_usage(input_dir).free / 1024**3 > threshold_in_gb:\n        sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while shutil.disk_usage(input_dir).free / 1024 ** 3 > threshold_in_gb:\n        sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while shutil.disk_usage(input_dir).free / 1024**3 > threshold_in_gb:\n        sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        if shutil.disk_usage(input_dir).free > threshold_in_gb * 1024 * 1024 * 1024:\n            sleep(sleep_time)\n        else:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    if not isinstance(threshold_in_gb, int):\n        raise TypeError(f\"The parameter threshold_in_gb has to be an integer but is {type(threshold_in_gb)}\")\n    if not isinstance(sleep_time, int):\n        raise TypeError(f\"The parameter sleep_time has to be an integer but is {type(sleep_time)}\")\n    if threshold_in_gb < 0:\n        raise ValueError(f\"The parameter threshold_in_gb has to be a positive integer but is {threshold_in_gb}\")\n    if sleep_time < 0:\n        raise ValueError(f\"The parameter sleep_time has to be a positive integer but is {sleep_time}\")\n\n    while shutil.disk_usage(input_dir).free / 1024**3 > threshold_in_gb:\n        sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while shutil.disk_usage(input_dir).free / 1024**3 > threshold_in_gb:\n        sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        disk_usage = shutil.disk_usage(input_dir)\n        if disk_usage.free / 1024 / 1024 / 1024 < threshold_in_gb:\n            break\n        else:\n            sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    # Get the free disk space in bytes.\n    free_space_bytes = shutil.disk_usage(input_dir).free\n\n    # Convert the free disk space in bytes to gigabytes.\n    free_space_gb = free_space_bytes / (1024 * 1024 * 1024)\n\n    # Check if the free space is lower than the threshold.\n    while free_space_gb > threshold_in_gb:\n\n        # Sleep for a specified amount of time.\n        sleep(sleep_time)\n\n        # Get the free disk space in bytes.\n        free_space_bytes = shutil.disk_usage(input_dir).free\n\n        # Convert the free disk space in bytes to gigabytes.\n        free_space_gb = free_space_bytes / (1024 * 1024 * 1024)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        if free / 2**30 > threshold_in_gb:\n            break\n        sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        _, _, free_space_in_gb = shutil.disk_usage(input_dir)\n        if free_space_in_gb < threshold_in_gb:\n            break\n        else:\n            sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        disk_usage = shutil.disk_usage(input_dir)\n        if disk_usage.free / 1024 / 1024 / 1024 < threshold_in_gb:\n            return\n        else:\n            sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while shutil.disk_usage(input_dir).free / 1024**3 > threshold_in_gb:\n        sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        free_gb = free // (2 ** 30)\n        if free_gb > threshold_in_gb:\n            sleep(sleep_time)\n        else:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while shutil.disk_usage(input_dir).free / (1024 ** 3) > threshold_in_gb:\n        sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        if free / (1024.0**3) < threshold_in_gb:\n            break\n        sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        if free / (2 ** 30) < threshold_in_gb:\n            sleep(sleep_time)\n        else:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while shutil.disk_usage(input_dir).free / 1024**3 > threshold_in_gb:\n        sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while shutil.disk_usage(input_dir).free / (1024 ** 3) > threshold_in_gb:\n        sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while shutil.disk_usage(input_dir).free > threshold_in_gb * 1024 * 1024 * 1024:\n        sleep(sleep_time)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, p * td)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p, td))\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_mul(p, td))\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return math.safe_div(p * td, jnp.sum(p * td))\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return math.safe_div(p, td)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, p * td)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, p * td)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return math.safe_div(p, td)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_mul(p, td))\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return math.safe_div(p, td)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p, td))\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return math.safe_div(p, td)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return math.safe_div(p, td)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_mul(p, td))\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p, td))\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, p * td)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return math.safe_div(p, td)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  w = math.safe_div(p, td)\n  return jnp.concatenate([w, jnp.array([0.])], axis=-1)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_mul(p, td))\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p, td))\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all whitespace characters from the input text.\n    line_text = re.sub(r\"\\s+\", \"\", line_text)\n\n    # Segment the text into smaller parts or tokens.\n    line_text = line_text.split(\" \")\n\n    return line_text"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all whitespace characters from the input text.\n    line_text = re.sub(r\"\\s\", \"\", line_text)\n\n    # Segment the modified text into smaller parts or tokens.\n    line_text = line_text.split(\" \")\n\n    return line_text"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # remove all whitespace characters from the input text and then segment the modified text into smaller parts or tokens\n    line_text = re.sub(r\"\\s+\", \"\", line_text)\n    line_text = line_text.split(\" \")\n\n    return line_text\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all whitespace characters from the input text.\n    line_text = re.sub(r\"\\s+\", \"\", line_text)\n\n    # Segment the text into smaller parts or tokens.\n    tokens = re.split(r\"([^\\w\\s])\", line_text)\n\n    # Return the segmented parts of the modified input text.\n    return tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u201c\", '\"')\n    line_text = line_text.replace(\"\u201d\", '\"')\n    line_text = line_text.replace(\"\u2018\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"`\", \"'\")\n    line_text = line_text.replace(\"``\", '\"')\n    line_text = line_text.replace(\"--\", \"\u2014\")\n    line_text = line_text.replace(\"- -\", \"\u2014\")\n    line_text = line_text.replace(\"\u2026\", \"...\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u201c\", '\"')\n    line_text = line_text.replace(\"\u201d\", '\"')\n    line_text = line_text.replace(\"\u2018\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"`\", \"'\")\n    line_text = line_text.replace(\"``\", '\"')\n    line_text = line_text.replace(\"--\", \"\u2014\")\n    line_text = line_text.replace(\"- -\", \"\u2014\")\n    line_text = line_text.replace(\"\u2026\", \"...\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u201c\", '\"')\n    line_text = line_text.replace(\"\u201d\", '\"')\n    line_text = line_text.replace(\"\u2018\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"`\", \"'\")\n    line_text = line_text.replace(\"``\", '\"')\n    line_text = line_text.replace(\"--\", \"\u2014\")\n    line_text = line_text.replace(\"- -\", \"\u2014\")\n    line_text = line_text.replace(\"\u2026\", \"...\")\n    line_text = line_text."}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u201c\", '\"')\n    line_text = line_text.replace(\"\u201d\", '\"')\n    line_text = line_text.replace(\"\u2018\", \"'\")\n    line_text = line_text.replace(\"\u2013\", \"-\")\n    line_text = line_text.replace(\"\u2014\", \"-\")\n    line_text = line_text.replace(\"\u2026\", \"...\")\n    line_text = line_text.replace(\"\u00b4\", \"'\")\n    line_text = line_text.replace(\"`\", \"'\")\n    line_text = line_text.replace(\"\u201c\", '\"')\n    line_text = line_text.replace(\"\u201d\", '\"')\n    line_text = line_text.replace(\"\u2018\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"`\", \"'\")\n    line_text = line_text.replace(\"\u00b4\", \"'\")\n    line_text = line_text.replace(\"\u2026\", \"...\")\n    line_text = line_text.replace(\"\u2018\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u201c\", '\"')\n    line_text = line_text.replace(\"\u201d\", '\"')\n    line_text = line_text.replace(\"\u201c\", '\"')\n    line_text = line_text.replace(\"\u201d\", '\"')\n    line_text = line_text.replace(\"`\", \"'\")\n    line_text = line_text.replace(\"\u00b4\", \"'\")\n    line_text = line_text.replace(\"\u2026\", \"...\")\n    line_text = line_text.replace(\"\u2018\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u201c\", '\"')\n    line_text = line_text.replace(\"\u201d\", '\"')\n    line_text = line_text.replace(\"\u201c\", '\"')\n    line_text = line_text.replace(\"\u201d\", '\"')\n    line"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = re.sub(r\"[\\n\\t]\", \" \", line_text)\n    line_text = re.sub(r\"[ ]+\", \" \", line_text)\n    line_text = re.sub(r\"[ ]$\", \"\", line_text)\n    line_text = re.sub(r\"^[ ]\", \"\", line_text)\n    line_text = re.sub(r\"^[ ]\", \"\", line_text)\n    line_text = re.sub(r\"[ ]+\", \" \", line_text)\n    line_text = re.sub(r\"[ ]$\", \"\", line_text)\n    line_text = re.sub(r\"^[ ]\", \"\", line_text)\n    line_text = re.sub(r\"^[ ]\", \"\", line_text)\n    line_text = re.sub(r\"[ ]+\", \" \", line_text)\n    line_text = re.sub(r\"[ ]$\", \"\", line_text)\n    line_text = re.sub(r\"^[ ]\", \"\", line_text)\n    line_text = re.sub(r\"^[ ]\", \"\", line_text)\n    line_text = re.sub(r\"[ ]+\", \" \", line_text)\n    line_text = re.sub(r\"[ ]$\", \"\", line_text)\n    line_text = re.sub(r\"^[ ]\", \"\", line_text)\n    line_text = re.sub(r\"^[ ]\", \"\", line_text)\n    line_text = re.sub(r\"[ ]+\", \" \", line_text)\n    line_text = re.sub(r\"[ ]$\", \"\", line_text)\n    line_text = re.sub(r\"^[ ]\", \"\", line_text)\n    line_text = re.sub(r\"^[ ]\", \"\", line_text)\n    line_text = re.sub(r\"[ ]+\", \" \", line_text)\n    line_text = re.sub(r\"[ ]$\", \"\", line_text)\n    line_text = re"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\"-\", \" \")\n    line_text = re.sub(r\"\\s+\", \" \", line_text)\n    line_text = line_text.replace(\" ,\", \",\")\n    line_text = line_text.replace(\" .\", \".\")\n    line_text = line_text.replace(\" :\", \":\")\n    line_text = line_text.replace(\" ;\", \";\")\n    line_text = line_text.replace(\"( \", \"(\")\n    line_text = line_text.replace(\" )\", \")\")\n    line_text = line_text.replace(\"[ \", \"[\")\n    line_text = line_text.replace(\" ]\", \"]\")\n    line_text = line_text.replace(\" /\", \"/\")\n    line_text = line_text.replace(\"\\\\\", \"\")\n    line_text = line_text.replace(\"\\\\\", \"\")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \","}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u201c\", '\"')\n    line_text = line_text.replace(\"\u201d\", '\"')\n    line_text = line_text.replace(\"\u2018\", \"'\")\n    line_text = line_text.replace(\"\u2013\", \"-\")\n    line_text = line_text.replace(\"\u2014\", \"-\")\n    line_text = line_text.replace(\"\u2026\", \"...\")\n    line_text = line_text.replace(\"\u00b4\", \"'\")\n    line_text = line_text.replace(\"`\", \"'\")\n    line_text = line_text.replace(\"\u2026\", \"...\")\n    line_text = line_text.replace(\"\u00b4\", \"'\")\n    line_text = line_text.replace(\"`\", \"'\")\n    line_text = line_text.replace(\"\u2026\", \"...\")\n    line_text = line_text.replace(\"\u00b4\", \"'\")\n    line_text = line_text.replace(\"`\", \"'\")\n    line_text = line_text.replace(\"\u201c\", '\"')\n    line_text = line_text.replace(\"\u201d\", '\"')\n    line_text = line_text.replace(\"\u2018\", \"'\")\n    line_text = line_text.replace(\"\u2013\", \"-\")\n    line_text = line_text.replace(\"\u2014\", \"-\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u201c\", '\"')\n    line_text = line_text.replace(\"\u201d\", '\"')\n    line_text = line_text.replace(\"\u2018\", \"'\")\n    line_text = line_text.replace(\"\u2013\", \"-\")\n    line_text = line_text.replace(\"\u2014\", \"-\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u201c\", '\"')\n    line_text = line_text.replace(\"\u201d\", '\"')\n    line_text = line_text.replace(\"\u2018\", \"'\")\n    line_text = line_text.replace(\"\u2013\", \"-\")\n    line"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u201c\", \"\\\"\")\n    line_text = line_text.replace(\"\u201d\", \"\\\"\")\n    line_text = line_text.replace(\"\u2018\", \"'\")\n    line_text = line_text.replace(\"\u2013\", \"-\")\n    line_text = line_text.replace(\"\u2014\", \"-\")\n    line_text = line_text.replace(\"\u2212\", \"-\")\n    line_text = line_text.replace(\"\u2022\", \"-\")\n    line_text = line_text.replace(\"\u2026\", \"...\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u201c\", '\"')\n    line_text = line_text.replace(\"\u201d\", '\"')\n    line_text = line_text.replace(\"\u2018\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2014\", \"-\")\n    line_text = line_text.replace(\"\u2013\", \"-\")\n    line_text = line_text.replace(\"\u2212\", \"-\")\n    line_text = line_text.replace(\"\u2026\", \"...\")\n    line_text = line_text.replace(\"\u00b4\", \"'\")\n    line_text = line_text.replace(\"`\", \"'\")\n    line_text = line_text.replace(\"\u00b4\u00b4\", '\"')\n    line_text = line_text.replace(\"``\", '\"')\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2018\", \"'\")\n    line_text = line_text.replace(\"`\", \"'\")\n    line_text = line_text.replace(\"\u00b4\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u201c\", '\"')\n    line_text = line_text.replace(\"\u201d\", '\"')\n    line_text = line_text.replace(\"\u2018\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2026\", \"...\")\n    line_text = line_text.replace(\"\u2014\", \"-\")\n    line_text = line_text.replace(\"\u2013\", \"-\")\n    line_text = line_text.replace(\"\u2212\", \"-\")\n    line_text = line_text.replace(\"\u00b4\u00b4\", '\"')\n    line_text = line_text.replace(\"``\", '\"')\n    line_text = line_text.replace(\"\u00b4\", \"'\")\n    line_text = line_text.replace(\"`\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n   "}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\" \", \"\")\n    line_text = line_text.replace(\"-\", \"\")\n    line_text = line_text.replace(\"_\", \"\")\n    line_text = line_text.replace(\"~\", \"\")\n    line_text = line_text.replace(\"(\", \"\")\n    line_text = line_text.replace(\")\", \"\")\n    line_text = line_text.replace(\":\", \"\")\n    line_text = line_text.replace(\";\", \"\")\n    line_text = line_text.replace(\"+\", \"\")\n    line_text = line_text.replace(\"*\", \"\")\n    line_text = line_text.replace(\"=\", \"\")\n    line_text = line_text.replace(\"|\", \"\")\n    line_text = line_text.replace(\"\\\\\", \"\")\n    line_text = line_text.replace(\"/\", \"\")\n    line_text = line_text.replace(\"?\", \"\")\n    line_text = line_text.replace(\"!\", \"\")\n    line_text = line_text.replace(\"@\", \"\")\n    line_text = line_text.replace(\"#\", \"\")\n    line_text = line_text.replace(\"%\", \"\")\n    line_text = line_text.replace(\"^\", \"\")\n    line_text = line_text.replace(\"&\", \"\")\n    line_text = line_text.replace(\"$\", \"\")\n    line_text = line_text.replace(\"`\", \"\")\n    line_text = line_text.replace(\"{\", \"\")\n    line_text = line_text.replace(\"}\", \"\")\n    line_text = line_text.replace(\"[\", \"\")\n    line_text = line_text.replace(\"]\", \"\")\n    line_text = line_text.replace(\">\", \"\")\n    line_text = line_text.replace(\"<\", \"\")\n    line_text = line_text.replace(\"'\", \"\")\n    line_text = line_text.replace('\"', \"\")\n    line_text = line_text.replace(\"0\", \"\")\n    line_text = line_text.replace(\"1\", \"\")\n    line_text = line_text.replace(\"2\","}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all whitespace characters from the input text and then segment the modified text into smaller parts or tokens.\n    line_text = line_text.replace(\"-\", \" \")\n    line_text = line_text.replace(\"\u2013\", \" \")\n    line_text = line_text.replace(\"\u2014\", \" \")\n    line_text = line_text.replace(\"\u2019\", \" \")\n    line_text = line_text.replace(\"\u2018\", \" \")\n    line_text = line_text.replace(\"\u201c\", \" \")\n    line_text = line_text.replace(\"\u201d\", \" \")\n    line_text = line_text.replace(\"\\\"\", \" \")\n    line_text = line_text.replace(\"\u2019\", \" \")\n    line_text = line_text.replace(\":\", \" \")\n    line_text = line_text.replace(\";\", \" \")\n    line_text = line_text.replace(\"(\", \" \")\n    line_text = line_text.replace(\")\", \" \")\n    line_text = line_text.replace(\"[\", \" \")\n    line_text = line_text.replace(\"]\", \" \")\n    line_text = line_text.replace(\"{\", \" \")\n    line_text = line_text.replace(\"}\", \" \")\n    line_text = line_text.replace(\"=\", \" \")\n    line_text = line_text.replace(\"|\", \" \")\n    line_text = line_text.replace(\"!\", \" \")\n    line_text = line_text.replace(\"?\", \" \")\n    line_text = line_text.replace(\"*\", \" \")\n    line_text = line_text.replace(\"&\", \" \")\n    line_text = line_text.replace(\"+\", \" \")\n    line_text = line_text.replace(\"\\\\\", \" \")\n    line_text = line_text.replace(\"@\", \" \")\n    line_text = line_text.replace(\"#\", \" \")\n    line_text = line_text.replace(\"%\", \" \")\n    line_text = line_text.replace(\"^\", \" \")\n    line_text = line_text.replace(\"$\", \" \")\n   "}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all whitespace characters from the input text and then segment the modified text into smaller parts or tokens.\n    line_text = re.sub(r\"\\s+\", \"\", line_text)\n    line_text = re.sub(r\"(.)-([A-Za-z])\", r\"\\1\\2\", line_text)\n    line_text = re.sub(r\"([A-Za-z])-([A-Za-z])\", r\"\\1\\2\", line_text)\n    line_text = re.sub(r\"([0-9])-([0-9])\", r\"\\1\\2\", line_text)\n    line_text = re.sub(r\"([0-9])([\\u0966-\\u096f])\", r\"\\1\\2\", line_text)\n    line_text = re.sub(r\"([\\u0966-\\u096f])([0-9])\", r\"\\1\\2\", line_text)\n    line_text = re.sub(r\"([\\u0966-\\u096f])-([\\u0966-\\u096f])\", r\"\\1\\2\", line_text)\n    line_text = re.sub(r\"([\\u0966-\\u096f])([\\u0966-\\u096f])\", r\"\\1\\2\", line_text)\n    line_text = re.sub(r\"([\\u0966-\\u096f])([\\u0900-\\u0901])\", r\"\\1\\2\", line_text)\n    line_text = re.sub(r\"([\\u0900-\\u0901])([\\u0966-\\u096f])\", r\"\\1\\2\", line_text)\n    line_text = re.sub(r\"([\\u0900-\\u0901])-([\\u0900-\\u0901])\", r\"\\1\\2\", line_text)\n    line_text = re"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all whitespace characters from the input text.\n    line_text = re.sub(r\"\\s\", \"\", line_text)\n\n    # Segment the modified text into smaller parts or tokens.\n    line_text = line_text.split(\" \")\n\n    return line_text\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\"-\", \" \")\n    line_text = line_text.replace(\"_\", \" \")\n    line_text = line_text.replace(\"&\", \" \")\n    line_text = line_text.replace(\":\", \" \")\n    line_text = line_text.replace(\";\", \" \")\n    line_text = line_text.replace(\"+\", \" \")\n    line_text = line_text.replace(\"=\", \" \")\n    line_text = line_text.replace(\"(\", \" \")\n    line_text = line_text.replace(\")\", \" \")\n    line_text = line_text.replace(\"{\", \" \")\n    line_text = line_text.replace(\"}\", \" \")\n    line_text = line_text.replace(\"[\", \" \")\n    line_text = line_text.replace(\"]\", \" \")\n    line_text = line_text.replace(\"<\", \" \")\n    line_text = line_text.replace(\">\", \" \")\n    line_text = line_text.replace(\"/\", \" \")\n    line_text = line_text.replace(\"\\\\\", \" \")\n    line_text = line_text.replace(\"*\", \" \")\n    line_text = line_text.replace(\"|\", \" \")\n    line_text = line_text.replace(\"?\", \" \")\n    line_text = line_text.replace(\"!\", \" \")\n    line_text = line_text.replace(\"$\", \" \")\n    line_text = line_text.replace(\"%\", \" \")\n    line_text = line_text.replace(\"@\", \" \")\n    line_text = line_text.replace(\"#\", \" \")\n    line_text = line_text.replace(\"^\", \" \")\n    line_text = line_text.replace(\"~\", \" \")\n    line_text = line_text.replace(\"`\", \" \")\n    line_text = line_text.replace(\"'\", \" \")\n    line_text = line_text.replace(\"\\\"\", \" \")\n    line_text = line_text.replace(\"\u2018\", \" \")\n    line_text = line_text.replace(\""}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = re.sub(r\"[\\s+]\", \"\", line_text)\n    return line_text\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # remove all whitespace characters\n    line_text = re.sub(r\"\\s+\", \"\", line_text)\n\n    # segment the text into smaller parts or tokens\n    line_text = re.split(\"([^a-zA-Z0-9\\\\-\\\\_])\", line_text)\n\n    # return the segmented parts of the modified input text\n    return line_text\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all whitespace characters from the input text\n    line_text = re.sub(r\"\\s+\", \"\", line_text)\n\n    # Segment the modified text into smaller parts or tokens\n    tokens = re.split(r\"([^\\w\\s])\", line_text)\n\n    return tokens\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zero weights cannot exceed the total number of weights.\")\n\n    weights = np.random.uniform(0, 1, n)\n    weights = weights / weights.sum()\n\n    if zeros > 0:\n        zero_indices = np.random.choice(n, zeros, replace=False)\n        weights[zero_indices] = 0\n\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zero weights cannot exceed the total number of weights.\")\n\n    weights = np.random.uniform(low=0, high=1, size=n)\n    weights = weights / weights.sum()\n\n    if zeros > 0:\n        zero_indices = np.random.choice(n, zeros, replace=False)\n        weights[zero_indices] = 0\n\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    assert zeros <= n, \"The number of zeros cannot exceed the number of weights to generate.\"\n\n    weights = np.random.uniform(0, 1, n)\n    weights = weights / weights.sum()\n\n    if zeros > 0:\n        zero_indices = np.random.choice(n, zeros, replace=False)\n        weights[zero_indices] = 0\n\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros >= n:\n        raise ValueError(\"The number of zero weights cannot exceed the total number of weights.\")\n\n    weights = np.random.uniform(low=0, high=1, size=n)\n    weights = weights / np.sum(weights)\n\n    if zeros > 0:\n        zero_indices = np.random.choice(n, size=zeros, replace=False)\n        weights[zero_indices] = 0\n\n    weights = weights / np.sum(weights)\n\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if n <= 0:\n        raise ValueError(\"n must be positive\")\n    if zeros >= n:\n        raise ValueError(\"zeros must be less than n\")\n\n    # Generate n random weights that sum to one\n    weights = np.random.dirichlet(np.ones(n))\n\n    # Set a specified number of weights to zero\n    if zeros > 0:\n        zero_indices = np.random.choice(n, zeros, replace=False)\n        weights[zero_indices] = 0\n\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros >= n:\n        raise ValueError(\"The number of zero weights cannot exceed the total number of weights.\")\n\n    weights = np.random.uniform(low=0.0, high=1.0, size=n)\n    weights = weights / np.sum(weights)\n\n    if zeros > 0:\n        zero_indices = np.random.choice(range(n), size=zeros, replace=False)\n        weights[zero_indices] = 0\n        weights = weights / np.sum(weights)\n\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if n < zeros:\n        raise ValueError(\"The number of zeros cannot exceed the number of weights\")\n\n    if zeros == 0:\n        return np.random.dirichlet(np.ones(n))\n\n    else:\n        weights = np.zeros(n)\n        weights[0:n-zeros] = np.random.dirichlet(np.ones(n-zeros))\n        return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    # Check if the number of zero weights exceeds the total number of weights.\n    if zeros > n:\n        raise ValueError('The number of zero weights cannot exceed the total number of weights.')\n\n    # Create a numpy array of n random weights that sum to one.\n    weights = np.array(np.random.dirichlet(np.ones(n)))\n\n    # Set the specified number of weights to zero.\n    if zeros > 0:\n        zero_indices = np.random.choice(n, zeros, replace=False)\n        weights[zero_indices] = 0\n\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    # Check if the number of zeros is not greater than the number of weights\n    if zeros > n:\n        raise ValueError(\"The number of zeros cannot exceed the number of weights.\")\n\n    # Generate n random weights that sum to one\n    weights = rand_weights_dirichlet(n)\n\n    # Set the first zeros weights to zero\n    weights[0:zeros] = 0\n\n    # Normalize the weights\n    weights = weights / np.sum(weights)\n\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if n <= 0:\n        raise ValueError(\"n must be a positive integer.\")\n\n    if zeros >= n:\n        raise ValueError(\"The number of zero weights cannot exceed n.\")\n\n    if zeros == 0:\n        return np.random.dirichlet(np.ones(n))\n\n    weights = np.zeros(n)\n    weights[0:n-zeros] = np.random.dirichlet(np.ones(n-zeros))\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if n <= 0:\n        raise ValueError(\"n must be a positive integer\")\n    if zeros < 0 or zeros > n:\n        raise ValueError(\"zeros must be an integer between 0 and n\")\n\n    weights = np.random.uniform(0, 1, n)\n    weights = weights / weights.sum()\n    zero_indices = np.random.choice(n, zeros, replace=False)\n    weights[zero_indices] = 0\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zeros cannot exceed the number of weights.\")\n    if zeros == n:\n        raise ValueError(\"The number of zeros cannot be equal to the number of weights.\")\n    weights = np.random.dirichlet(np.ones(n), 1)[0]\n    zero_indices = np.random.choice(n, zeros, replace=False)\n    weights[zero_indices] = 0\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zero-weights cannot exceed the total number of weights.\")\n\n    weights = np.random.uniform(low=0, high=1, size=n)\n    weights = weights / weights.sum()\n\n    if zeros == 0:\n        return weights\n\n    zero_indices = np.random.choice(np.arange(n), size=zeros, replace=False)\n    weights[zero_indices] = 0\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros >= n:\n        raise ValueError(\"The number of zero weights must not exceed the total number of weights\")\n    elif zeros < 0:\n        raise ValueError(\"The number of zero weights must be non-negative\")\n\n    weights = rand_weights_dirichlet(n)\n    zero_indices = np.random.choice(np.arange(n), zeros, replace=False)\n    weights[zero_indices] = 0\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if n <= 0:\n        raise ValueError(\"n must be a positive integer\")\n    if zeros < 0:\n        raise ValueError(\"zeros must be a non-negative integer\")\n    if zeros > n:\n        raise ValueError(\"zeros must be less than or equal to n\")\n\n    weights = np.random.dirichlet(np.ones(n))\n    weights[np.random.choice(n, zeros, replace=False)] = 0\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros >= n:\n        raise ValueError(f\"The number of zeros ({zeros}) cannot exceed the number of weights ({n})\")\n\n    weights = np.random.uniform(0, 1, n)\n    weights = weights / np.sum(weights)\n\n    zero_indices = np.random.choice(n, zeros, replace=False)\n    weights[zero_indices] = 0\n\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if n < 1:\n        raise ValueError(\"The number of weights to generate must be a positive integer\")\n    if zeros < 0 or zeros > n:\n        raise ValueError(\"The number of zero weights must be a non-negative integer and not exceed the total number of weights\")\n\n    weights = rand_weights_dirichlet(n)\n    if zeros > 0:\n        zero_indices = np.random.choice(n, zeros, replace=False)\n        weights[zero_indices] = 0\n\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if n <= 0:\n        raise ValueError('n must be positive')\n    if zeros > n:\n        raise ValueError('zeros cannot be greater than n')\n\n    weights = np.random.dirichlet(np.ones(n))\n    zero_indices = np.random.choice(n, zeros, replace=False)\n    weights[zero_indices] = 0\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zeros cannot exceed the number of weights.\")\n\n    weights = np.zeros(n)\n    zero_indices = np.random.choice(n, zeros, replace=False)\n    weights[zero_indices] = 0\n\n    while weights.sum() != 1:\n        for i in range(n):\n            if weights.sum() < 1:\n                weights[i] += np.random.uniform(0, 1)\n            else:\n                weights[i] -= np.random.uniform(0, 1)\n\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if n <= 0:\n        raise ValueError(\"The number of weights to generate must be positive.\")\n    if zeros > n:\n        raise ValueError(\"The number of weights to set to zero must not exceed the total number of weights to generate.\")\n    if n == zeros:\n        raise ValueError(\"The number of weights to generate must be greater than the number of weights to set to zero.\")\n\n    if zeros == 0:\n        return np.random.dirichlet(np.ones(n))\n\n    # Generate a set of weights with the specified number of zero weights\n    weights = np.zeros(n)\n    weights[np.random.choice(n, n - zeros, replace=False)] = 1\n    weights = np.random.dirichlet(weights)\n\n    # Normalize the weights to sum to one\n    weights = weights / weights.sum()\n\n    return weights\n\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        return cls(module_type=module_dict['module_type'], module_param=deepcopy(module_dict))"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        module_param = deepcopy(module_dict)\n        return cls(module_type, module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        module_param = deepcopy(module_dict)\n        return cls(module_type=module_type, module_param=module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        return cls(module_type, module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        return cls(\n            module_type=module_dict[\"module_type\"],\n            module_param=deepcopy(module_dict)\n        )\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        module_param = deepcopy(module_dict)\n        return cls(module_type, module_param)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        return cls(module_type=module_dict['module_type'], module_param=deepcopy(module_dict))\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        return cls(module_type, module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop(\"module_type\")\n        return cls(module_type, module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        module_param = module_dict\n        return cls(module_type=module_type, module_param=module_param)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop(\"module_type\")\n        return cls(module_type, module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        return cls(module_type=module_dict.pop('module_type'), module_param=module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        # Extract the module type from the dictionary\n        module_type = module_dict.pop(\"module_type\")\n\n        # Return a new instance of the Module class, using the remaining dictionary as module parameters\n        return cls(module_type=module_type, module_param=module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        module_param = deepcopy(module_dict)\n        return cls(module_type, module_param)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop(\"module_type\")\n        return cls(module_type, module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        return cls(module_type, module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        if \"module_type\" not in module_dict:\n            raise ValueError(f\"Module dictionary must contain a 'module_type' key.\")\n\n        module_type = module_dict.pop(\"module_type\")\n        return cls(module_type, module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        return cls(module_type, module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        return cls(module_type, module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        return cls(module_type, module_dict)\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    crop_size = np.asarray(crop_size, dtype=np.int32)\n    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_yx = (bbox[1] + bbox[3]) * 0.5, (bbox[0] + bbox[2]) * 0.5\n\n    assert (\n        image_size[0] >= center_yx[0] and image_size[1] >= center_yx[1]\n    ), \"The annotation bounding box is outside of the image!\"\n    assert (\n        image_size[0] >= crop_size[0] and image_size[1] >= crop_size[1]\n    ), \"Crop size is larger than image size!\"\n\n    min_yx = np.maximum(np.ceil(center_yx).astype(np.int32) - crop_size, 0)\n    max_yx = np.maximum(np.asarray(image_size, dtype=np.int32) - crop_size, 0)\n    max_yx = np.minimum(max_yx, np.floor(center_yx).astype(np.int32))\n\n    y0 = np.random.randint(min_yx[0], max_yx[0] + 1)\n    x0 = np.random.randint(min_yx[1], max_yx[1] + 1)\n    return T.CropTransform(x0, y0, crop_size[1], crop_size[0])\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    crop_size = np.asarray(crop_size, dtype=np.int32)\n    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_yx = (bbox[1] + bbox[3]) * 0.5, (bbox[0] + bbox[2]) * 0.5\n    assert (\n        image_size[0] > center_yx[0] and image_size[1] > center_yx[1]\n    ), \"The annotation bounding box is outside of the image!\"\n    assert (\n        image_size[0] > crop_size[0] and image_size[1] > crop_size[1]\n    ), \"Crop size is larger than image size!\"\n\n    min_yx = np.maximum(np.ceil(center_yx).astype(np.int32) - crop_size, 0)\n    max_yx = np.maximum(np.asarray(image_size, dtype=np.int32) - crop_size, 0)\n    max_yx = np.minimum(max_yx, np.floor(center_yx).astype(np.int32))\n\n    y0 = np.random.randint(min_yx[0], max_yx[0] + 1)\n    x0 = np.random.randint(min_yx[1], max_yx[1] + 1)\n    return T.CropTransform(x0, y0, crop_size[1], crop_size[0])\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    crop_size = np.asarray(crop_size, dtype=np.int32)\n    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_yx = (bbox[1] + bbox[3]) * 0.5, (bbox[0] + bbox[2]) * 0.5\n\n    assert (\n        image_size[0] >= center_yx[0] and image_size[1] >= center_yx[1]\n    ), \"The annotation bounding box is outside of the image!\"\n    assert (\n        image_size[0] >= crop_size[0] and image_size[1] >= crop_size[1]\n    ), \"Crop size is larger than image size!\"\n\n    min_yx = np.maximum(np.ceil(center_yx).astype(np.int32) - crop_size, 0)\n    max_yx = np.maximum(np.asarray(image_size, dtype=np.int32) - crop_size, 0)\n    max_yx = np.minimum(max_yx, np.floor(center_yx).astype(np.int32))\n\n    y0 = np.random.randint(min_yx[0], max_yx[0] + 1)\n    x0 = np.random.randint(min_yx[1], max_yx[1] + 1)\n    return T.CropTransform(x0, y0, crop_size[1], crop_size[0])\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    crop_size = np.asarray(crop_size, dtype=np.int32)\n    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_yx = (bbox[1] + bbox[3]) * 0.5, (bbox[0] + bbox[2]) * 0.5\n    assert (\n        image_size[0] > crop_size[0]\n    ), \"Can't crop an area {} larger than image size {}!\".format(crop_size, image_size)\n    assert (\n        image_size[1] > crop_size[1]\n    ), \"Can't crop an area {} larger than image size {}!\".format(crop_size, image_size)\n    min_yx = np.maximum(np.floor(center_yx).astype(np.int32) - crop_size, 0)\n    max_yx = np.maximum(np.asarray(image_size, dtype=np.int32) - crop_size, 0)\n    max_yx = np.minimum(max_yx, np.ceil(center_yx).astype(np.int32))\n    y0 = np.random.randint(min_yx[0], max_yx[0] + 1)\n    x0 = np.random.randint(min_yx[1], max_yx[1] + 1)\n    return T.CropTransform(x0, y0, crop_size[1], crop_size[0])\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    crop_size = np.asarray(crop_size, dtype=np.int32)\n    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_yx = (bbox[1] + bbox[3]) * 0.5, (bbox[0] + bbox[2]) * 0.5\n\n    assert (\n        image_size[0] >= center_yx[0] and image_size[1] >= center_yx[1]\n    ), \"The annotation bounding box is outside of the image!\"\n    assert (\n        image_size[0] >= crop_size[0] and image_size[1] >= crop_size[1]\n    ), \"Crop size is larger than image size!\"\n\n    min_yx = np.maximum(np.ceil(center_yx).astype(np.int32) - crop_size, 0)\n    max_yx = np.maximum(np.asarray(image_size, dtype=np.int32) - crop_size, 0)\n    max_yx = np.minimum(max_yx, np.floor(center_yx).astype(np.int32))\n\n    y0 = np.random.randint(min_yx[0], max_yx[0] + 1)\n    x0 = np.random.randint(min_yx[1], max_yx[1] + 1)\n    return T.CropTransform(x0, y0, crop_size[1], crop_size[0])\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    crop_size = np.asarray(crop_size, dtype=np.int32)\n    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_yx = (bbox[1] + bbox[3]) * 0.5, (bbox[0] + bbox[2]) * 0.5\n\n    assert (\n        image_size[0] > crop_size[0]\n    ), \"Can only crop image size {} greater than crop size {}.\".format(\n        image_size, crop_size\n    )\n    assert (\n        image_size[1] > crop_size[1]\n    ), \"Can only crop image size {} greater than crop size {}.\".format(\n        image_size, crop_size\n    )\n    min_yx = np.maximum(np.ceil(center_yx).astype(np.int32) - crop_size, 0)\n    max_yx = np.maximum(np.asarray(image_size, dtype=np.int32) - crop_size, 0)\n    max_yx = np.minimum(max_yx, np.floor(center_yx).astype(np.int32))\n\n    y0 = np.random.randint(min_yx[0], max_yx[0] + 1)\n    x0 = np.random.randint(min_yx[1], max_yx[1] + 1)\n    return T.CropTransform(x0, y0, crop_size[1], crop_size[0])\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    crop_size = np.asarray(crop_size, dtype=np.int32)\n    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_yx = (bbox[1] + bbox[3]) * 0.5, (bbox[0] + bbox[2]) * 0.5\n\n    assert (\n        image_size[0] > crop_size[0]\n    ), \"Can only crop image if the image height is larger than crop height\"\n    assert (\n        image_size[1] > crop_size[1]\n    ), \"Can only crop image if the image width is larger than crop width\"\n\n    min_yx = np.maximum(np.ceil(center_yx).astype(np.int32) - crop_size, 0)\n    max_yx = np.maximum(np.asarray(image_size, dtype=np.int32) - crop_size, 0)\n    max_yx = np.minimum(max_yx, np.floor(center_yx).astype(np.int32))\n\n    y0 = np.random.randint(min_yx[0], max_yx[0] + 1)\n    x0 = np.random.randint(min_yx[1], max_yx[1] + 1)\n    return T.CropTransform(x0, y0, crop_size[1], crop_size[0])\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    crop_size = np.asarray(crop_size, dtype=np.int32)\n    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_yx = (bbox[1] + bbox[3]) * 0.5, (bbox[0] + bbox[2]) * 0.5\n\n    assert (\n        image_size[0] > crop_size[0]\n    ), \"Can't crop an image smaller than the crop size.\"\n    assert (\n        image_size[1] > crop_size[1]\n    ), \"Can't crop an image smaller than the crop size.\"\n\n    min_yx = np.maximum(np.ceil(center_yx).astype(np.int32) - crop_size, 0)\n    max_yx = np.maximum(np.asarray(image_size, dtype=np.int32) - crop_size, 0)\n    max_yx = np.minimum(max_yx, np.floor(center_yx).astype(np.int32))\n\n    y0 = np.random.randint(min_yx[0], max_yx[0] + 1)\n    x0 = np.random.randint(min_yx[1], max_yx[1] + 1)\n    return T.CropTransform(x0, y0, crop_size[1], crop_size[0])\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    crop_size = np.asarray(crop_size, dtype=np.int32)\n    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_yx = (bbox[1] + bbox[3]) * 0.5, (bbox[0] + bbox[2]) * 0.5\n    assert (\n        image_size[0] >= center_yx[0] and image_size[1] >= center_yx[1]\n    ), \"The annotation bounding box is outside of the image!\"\n    assert (\n        image_size[0] >= crop_size[0] and image_size[1] >= crop_size[1]\n    ), \"Crop size is larger than image size!\"\n\n    min_yx = np.maximum(np.ceil(center_yx).astype(np.int32) - crop_size, 0)\n    max_yx = np.maximum(np.asarray(image_size, dtype=np.int32) - crop_size, 0)\n    max_yx = np.minimum(max_yx, np.floor(center_yx).astype(np.int32))\n\n    y0 = np.random.randint(min_yx[0], max_yx[0] + 1)\n    x0 = np.random.randint(min_yx[1], max_yx[1] + 1)\n    return T.CropTransform(x0, y0, crop_size[1], crop_size[0])\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    crop_size = np.asarray(crop_size, dtype=np.int32)\n    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_yx = (bbox[1] + bbox[3]) * 0.5, (bbox[0] + bbox[2]) * 0.5\n\n    assert (\n        image_size[0] > crop_size[0]\n    ), \"Can only crop image if the image height is larger than crop height\"\n    assert (\n        image_size[1] > crop_size[1]\n    ), \"Can only crop image if the image width is larger than crop width\"\n\n    min_yx = np.maximum(np.floor(center_yx).astype(np.int32) - crop_size, 0)\n    max_yx = np.maximum(np.asarray(image_size, dtype=np.int32) - crop_size, 0)\n    max_yx = np.minimum(max_yx, np.ceil(center_yx).astype(np.int32))\n\n    y0 = np.random.randint(min_yx[0], max_yx[0] + 1)\n    x0 = np.random.randint(min_yx[1], max_yx[1] + 1)\n    return T.CropTransform(x0, y0, crop_size[1], crop_size[0])\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    crop_size = np.asarray(crop_size, dtype=np.int32)\n    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_yx = (bbox[1] + bbox[3]) * 0.5, (bbox[0] + bbox[2]) * 0.5\n\n    assert (\n        image_size[0] > crop_size[0]\n    ), \"Can only crop image size {} greater than crop size {}.\".format(\n        image_size, crop_size\n    )\n    assert (\n        image_size[1] > crop_size[1]\n    ), \"Can only crop image size {} greater than crop size {}.\".format(\n        image_size, crop_size\n    )\n    min_yx = np.maximum(np.floor(center_yx).astype(np.int32) - crop_size, 0)\n    max_yx = np.maximum(np.asarray(image_size, dtype=np.int32) - crop_size, 0)\n    max_yx = np.minimum(max_yx, np.ceil(center_yx).astype(np.int32))\n\n    y0 = np.random.randint(min_yx[0], max_yx[0] + 1)\n    x0 = np.random.randint(min_yx[1], max_yx[1] + 1)\n    return T.CropTransform(x0, y0, crop_size[1], crop_size[0])\n\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    crop_size = np.asarray(crop_size, dtype=np.int32)\n    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_yx = (bbox[1] + bbox[3]) * 0.5, (bbox[0] + bbox[2]) * 0.5\n    assert (\n        image_size[0] > crop_size[0]\n    ), \"Can only crop image size {} greater than crop size {}.\".format(\n        image_size, crop_size\n    )\n    assert (\n        image_size[1] > crop_size[1]\n    ), \"Can only crop image size {} greater than crop size {}.\".format(\n        image_size, crop_size\n    )\n    min_yx = np.maximum(np.ceil(center_yx).astype(np.int32) - crop_size, 0)\n    max_yx = np.maximum(np.asarray(image_size, dtype=np.int32) - crop_size, 0)\n    max_yx = np.minimum(max_yx, np.floor(center_yx).astype(np.int32))\n\n    y0 = np.random.randint(min_yx[0], max_yx[0] + 1)\n    x0 = np.random.randint(min_yx[1], max_yx[1] + 1)\n    return T.CropTransform(x0, y0, crop_size[1], crop_size[0])\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    crop_size = np.asarray(crop_size, dtype=np.int32)\n    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_yx = (bbox[1] + bbox[3]) * 0.5, (bbox[0] + bbox[2]) * 0.5\n\n    assert (\n        image_size[0] > crop_size[0]\n    ), \"Can't crop an image smaller than the crop size.\"\n    assert (\n        image_size[1] > crop_size[1]\n    ), \"Can't crop an image smaller than the crop size.\"\n\n    min_yx = np.maximum(np.ceil(center_yx).astype(np.int32) - crop_size, 0)\n    max_yx = np.maximum(np.asarray(image_size, dtype=np.int32) - crop_size, 0)\n    max_yx = np.minimum(max_yx, np.floor(center_yx).astype(np.int32))\n\n    y0 = np.random.randint(min_yx[0], max_yx[0] + 1)\n    x0 = np.random.randint(min_yx[1], max_yx[1] + 1)\n    return T.CropTransform(x0, y0, crop_size[1], crop_size[0])\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    crop_size = np.asarray(crop_size, dtype=np.int32)\n    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_yx = (bbox[1] + bbox[3]) * 0.5, (bbox[0] + bbox[2]) * 0.5\n    assert (\n        image_size[0] > crop_size[0]\n    ), \"Can only crop image if the height is larger than crop height\"\n    assert (\n        image_size[1] > crop_size[1]\n    ), \"Can only crop image if the width is larger than crop width\"\n    min_yx = np.maximum(np.floor(center_yx).astype(np.int32) - crop_size, 0)\n    max_yx = np.maximum(np.asarray(image_size, dtype=np.int32) - crop_size, 0)\n    max_yx = np.minimum(max_yx, np.ceil(center_yx).astype(np.int32))\n    y0 = np.random.randint(min_yx[0], max_yx[0] + 1)\n    x0 = np.random.randint(min_yx[1], max_yx[1] + 1)\n    return T.CropTransform(x0, y0, crop_size[1], crop_size[0])\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    crop_size = np.asarray(crop_size, dtype=np.int32)\n    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_yx = (bbox[1] + bbox[3]) * 0.5, (bbox[0] + bbox[2]) * 0.5\n\n    assert (\n        image_size[0] > crop_size[0]\n    ), \"Can't crop an image of {} pixels in the y-dimension to a crop size of {} pixels!\".format(\n        image_size[0], crop_size[0]\n    )\n    assert (\n        image_size[1] > crop_size[1]\n    ), \"Can't crop an image of {} pixels in the x-dimension to a crop size of {} pixels!\".format(\n        image_size[1], crop_size[1]\n    )\n    min_yx = np.maximum(np.floor(center_yx).astype(np.int32) - crop_size, 0)\n    max_yx = np.maximum(np.asarray(image_size, dtype=np.int32) - crop_size, 0)\n    max_yx = np.minimum(max_yx, np.ceil(center_yx).astype(np.int32))\n\n    y0 = np.random.randint(min_yx[0], max_yx[0] + 1)\n    x0 = np.random.randint(min_yx[1], max_yx[1] + 1)\n    return T.CropTransform(x0, y0, crop_size[1], crop_size[0])\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    crop_size = np.asarray(crop_size, dtype=np.int32)\n    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_yx = (bbox[1] + bbox[3]) * 0.5, (bbox[0] + bbox[2]) * 0.5\n\n    assert (\n        image_size[0] > crop_size[0]\n    ), \"Can't crop a region larger than the image in y direction.\"\n    assert (\n        image_size[1] > crop_size[1]\n    ), \"Can't crop a region larger than the image in x direction.\"\n\n    min_yx = np.maximum(np.floor(center_yx).astype(np.int32) - crop_size, 0)\n    max_yx = np.maximum(np.asarray(image_size, dtype=np.int32) - crop_size, 0)\n    max_yx = np.minimum(max_yx, np.ceil(center_yx).astype(np.int32))\n\n    y0 = np.random.randint(min_yx[0], max_yx[0] + 1)\n    x0 = np.random.randint(min_yx[1], max_yx[1] + 1)\n    return T.CropTransform(x0, y0, crop_size[1], crop_size[0])\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    crop_size = np.asarray(crop_size, dtype=np.int32)\n    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_yx = (bbox[1] + bbox[3]) * 0.5, (bbox[0] + bbox[2]) * 0.5\n\n    assert (\n        image_size[0] > crop_size[0]\n    ), \"Can't crop an area {} larger than image size {}!\".format(crop_size, image_size)\n    assert (\n        image_size[1] > crop_size[1]\n    ), \"Can't crop an area {} larger than image size {}!\".format(crop_size, image_size)\n    if (crop_size[0] > image_size[0]) or (crop_size[1] > image_size[1]):\n        # crop does not fit in the image, no crop\n        return T.CropTransform(np.asarray([0, 0], dtype=np.float32), crop_size)\n\n    # shift center to be within image\n    center_yx = np.clip(center_yx, crop_size[0] * 0.5, image_size - crop_size[0] * 0.5)\n\n    # convert box to top-left, bottom-right\n    x1y1 = np.asarray(center_yx, dtype=np.int32) - crop_size * 0.5\n    x2y2 = x1y1 + crop_size\n\n    bbox = np.asarray([x1y1[1], x1y1[0], x2y2[1], x2y2[0]], dtype=np.int32)\n    return T.CropTransform(np.array(bbox), crop_size)\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    crop_size = np.asarray(crop_size, dtype=np.int32)\n    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_yx = (bbox[1] + bbox[3]) * 0.5, (bbox[0] + bbox[2]) * 0.5\n    assert (\n        image_size[0] > crop_size[0]\n    ), \"Can't crop a region larger than the image in y direction.\"\n    assert (\n        image_size[1] > crop_size[1]\n    ), \"Can't crop a region larger than the image in x direction.\"\n    # determine the top-left corner of the crop region.\n    ymin = np.maximum(0, int(center_yx[0] - crop_size[0] * 0.5))\n    xmin = np.maximum(0, int(center_yx[1] - crop_size[1] * 0.5))\n    ymax = ymin + crop_size[0]\n    xmax = xmin + crop_size[1]\n    ymin = np.minimum(ymin, image_size[0] - crop_size[0])\n    xmin = np.minimum(xmin, image_size[1] - crop_size[1])\n    # adjust to make the crop region positive\n    top = ymin\n    left = xmin\n    bottom = ymax\n    right = xmax\n    return CropTransform(top, left, bottom, right, image_size)\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    crop_size = np.asarray(crop_size, dtype=np.int32)\n    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_yx = (bbox[1] + bbox[3]) * 0.5, (bbox[0] + bbox[2]) * 0.5\n\n    assert (\n        image_size[0] > crop_size[0]\n    ), \"Can only crop image if the image height is larger than crop height\"\n    assert (\n        image_size[1] > crop_size[1]\n    ), \"Can only crop image if the image width is larger than crop width\"\n\n    # The amount of padding to add to ensure the cropped region includes the center of the instance\n    pad = (crop_size - bbox[2:]).astype(np.int32) // 2\n\n    # The box coordinates are swapped to ensure the long dimension is the height\n    start_yx = center_yx - crop_size // 2\n    # The starting point of the box needs to be adjusted to ensure it fits within the image bounds\n    start_yx = np.maximum(0, start_yx).astype(np.int32)\n    start_yx = np.minimum(start_yx, image_size - crop_size).astype(np.int32)\n\n    return CropTransform(start_yx, crop_size)\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    crop_size = np.asarray(crop_size, dtype=np.int32)\n    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_yx = (bbox[1] + bbox[3]) * 0.5, (bbox[0] + bbox[2]) * 0.5\n\n    assert (\n        image_size[0] > crop_size[0]\n    ), \"Can't crop an image smaller than the crop size.\"\n    assert (\n        image_size[1] > crop_size[1]\n    ), \"Can't crop an image smaller than the crop size.\"\n\n    # The amount of bbox padding is determined by the amount of crop extension.\n    # The bbox is extended by the difference between the crop size and the bbox size.\n    # If the difference is odd, one extra pixel is added at the bottom and at the right of the bbox.\n    # The top-left corner of the bbox shifts by this amount to preserve the center.\n    bbox_padding = (crop_size - bbox[2:]).astype(np.int32)\n    bbox_padding += bbox_padding % 2\n    center_yx += bbox_padding / 2.0\n\n    # Determine the crop rectangle bounds.\n    crop_size = np.tile(crop_size, 2)\n    crop_center_yx = np.maximum(0, np.minimum(center_yx, image_size - crop_size))\n    crop_y1y2x1x2 = np.concatenate((crop_center_yx - crop_size / 2, crop_center_yx + crop_size / 2))\n\n    return CropTransform(*crop_y1y2x1x2)\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  return x * jnp.rsqrt(jnp.maximum(jnp.sum(x**2, axis=-1, keepdims=True), grad_eps))\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  x_norm_eps = x_norm + grad_eps\n  x_norm_eps = jnp.maximum(x_norm_eps, jnp.sqrt(grad_eps))\n  x_normalized = x / x_norm_eps\n  return x_normalized\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  return x * jnp.sqrt(jnp.maximum(1.0 - grad_eps, jnp.sum(x * x, axis=-1, keepdims=True)))\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  return x * jnp.reciprocal(jnp.maximum(jnp.linalg.norm(x, axis=-1, keepdims=True), grad_eps))\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  return x * jnp.reciprocal(jnp.maximum(jnp.linalg.norm(x, ord=2, axis=-1, keepdims=True), grad_eps))\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  return x * jnp.sqrt(jnp.maximum(1.0, 1.0 / (jnp.sum(x * x, axis=-1, keepdims=True) + grad_eps)))\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  return x * jnp.reciprocal(jnp.maximum(jnp.linalg.norm(x, axis=-1, keepdims=True), grad_eps))\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # This function is equivalent to the following, but with a more numerically stable gradient implementation.\n  # norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  # return x / norm.clip(min=grad_eps)\n\n  norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  return jnp.where(norm > grad_eps, x / norm, x / jnp.sqrt(grad_eps))\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  x_norm = jnp.maximum(x_norm, math.sqrt(grad_eps))\n  return x / x_norm\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  return x * jnp.rsqrt(jnp.maximum(jnp.sum(x ** 2, axis=-1, keepdims=True), grad_eps))\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared norm of the input vector(s).\n  x_norm = jnp.sum(x**2, axis=-1, keepdims=True)\n  # Clamp the norm to a minimum value before taking the square root.\n  x_norm = jnp.maximum(x_norm, grad_eps)\n  # Normalize the input vector(s).\n  x_norm = x / jnp.sqrt(x_norm)\n  return x_norm\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  return x * jnp.reciprocal(jnp.maximum(jnp.linalg.norm(x, axis=-1, keepdims=True), grad_eps))\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  return x * jnp.reciprocal(jnp.maximum(jnp.linalg.norm(x, ord=2, axis=-1, keepdims=True), grad_eps))\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  norm_eps = norm + grad_eps\n  return x / norm_eps\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  return x * jnp.reciprocal(jnp.linalg.norm(x, axis=-1, keepdims=True) + grad_eps)\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  return x * jnp.reciprocal(jnp.maximum(jnp.linalg.norm(x, ord=2, axis=-1, keepdims=True), grad_eps))\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  norm_eps = jnp.maximum(norm, grad_eps)\n  return x * norm_eps.rsqrt()\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  return x * jnp.sqrt(jnp.maximum(1.0, jnp.sum(x ** 2, axis=-1, keepdims=True) / grad_eps))\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  return x * jnp.sqrt(jnp.maximum(1.0, 1.0 / (jnp.sum(x * x, axis=-1, keepdims=True) + grad_eps)))\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared norm along the last dimension.\n  x_norm = jnp.sum(x ** 2, axis=-1, keepdims=True)\n\n  # Clamp the norm to the smallest value specified by grad_eps before division.\n  x_norm = jnp.maximum(x_norm, grad_eps)\n\n  # Normalize the array.\n  x = x / jnp.sqrt(x_norm)\n\n  return x\n\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1]\n        agent_name = agent_info.split(\"]\")[0]\n        if \":\" in agent_info:\n            input_text = agent_info.split(\":\")[1]\n        else:\n            input_text = \"\"\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_name = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        if \":\" in response:\n            input_text = response.split(\":\")[1]\n        else:\n            input_text = \"\"\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_name = response.split('Use Agent[')[1].split(']')[0]\n        input_text = response.split('Use Agent[')[1].split(']')[1].split(':')[1].strip()\n\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        # Extract the agent name\n        agent_name = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n\n        # Extract the input text\n        if \":\" in response:\n            input_text = response.split(\"Use Agent[\")[1].split(\"]:\")[1]\n        else:\n            input_text = \"\"\n\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name = agent_info.split(\":\")[0]\n        if len(agent_info.split(\":\")) > 1:\n            input_text = agent_info.split(\":\")[1]\n        else:\n            input_text = \"\"\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        split_response = response.split(\"Use Agent[\")[1].split(\"]\")\n        agent_name = split_response[0]\n        input_text = \"\"\n        if len(split_response) > 1:\n            input_text = split_response[1].split(\":\")[1]\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name = agent_info.split(\":\")[0]\n        input_text = agent_info.split(\":\")[1] if len(agent_info.split(\":\")) > 1 else \"\"\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_name = response.split('Use Agent[')[1].split(']')[0]\n        if ':' in response:\n            input_text = response.split(':')[1]\n        else:\n            input_text = \"\"\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name = agent_info.split(\":\")[0]\n        if len(agent_info.split(\":\")) > 1:\n            input_text = agent_info.split(\":\")[1]\n        else:\n            input_text = \"\"\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        split_response = response.split(\"Use Agent[\")\n        agent_name = split_response[1].split(\"]\")[0]\n        if \":\" in split_response[1]:\n            input_text = split_response[1].split(\":\")[1]\n        else:\n            input_text = \"\"\n\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1]\n        agent_name = agent_info.split(\"]\")[0]\n        if \":\" in agent_info:\n            input_text = agent_info.split(\":\")[1]\n        else:\n            input_text = \"\"\n\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name = agent_info.split(\":\")[0]\n        input_text = \"\"\n        if len(agent_info.split(\":\")) > 1:\n            input_text = agent_info.split(\":\")[1]\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split('Use Agent[')[-1]\n        agent_info = agent_info.split(']')\n        agent_name = agent_info[0]\n        input_text = agent_info[1] if len(agent_info) > 1 else ''\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1]\n        agent_info = agent_info.split(\"]\")[0]\n        agent_info = agent_info.split(\":\")\n        agent_name = agent_info[0]\n        agent_input = \"\"\n        if len(agent_info) > 1:\n            agent_input = agent_info[1]\n        return agent_name, agent_input\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        # Find the start of the agent name\n        agent_name_start_index = response.find(\"Use Agent[\") + len(\"Use Agent[\")\n        # Find the end of the agent name\n        agent_name_end_index = response.find(\"]\")\n        # Extract the agent name\n        agent_name = response[agent_name_start_index:agent_name_end_index]\n        # Extract the input text\n        input_text = response[agent_name_end_index + 1:]\n        # Return the agent name and input text\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        response_split = response.split(\"Use Agent[\")\n        if len(response_split) < 2:\n            return \"\", \"\"\n        agent_info = response_split[1]\n        agent_name = agent_info.split(\"]\")[0]\n        if \":\" in agent_info:\n            agent_input = agent_info.split(\":\")[1]\n            return agent_name, agent_input\n        else:\n            return agent_name, \"\"\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        try:\n            agent_name = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n            input_text = response.split(\"Use Agent[\")[1].split(\"]\")[1].split(\":\")[1].strip()\n            return agent_name, input_text\n        except Exception as e:\n            logger.error(f\"Exception occured during agent invocation: {e}\")\n            return \"\", \"\"\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name = agent_info.split(\":\")[0]\n        if len(agent_info.split(\":\")) > 1:\n            input_text = agent_info.split(\":\")[1]\n        else:\n            input_text = \"\"\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        split_response = response.split('Use Agent[')\n        if len(split_response) < 2:\n            raise ValueError(f\"Expected response string to contain 'Use Agent[' but found {response}\")\n        if len(split_response) > 2:\n            raise ValueError(f\"Expected response string to contain only one 'Use Agent[' but found {response}\")\n\n        agent_info = split_response[1]\n        split_agent_info = agent_info.split(']')\n        if len(split_agent_info) < 2:\n            raise ValueError(f\"Expected response string to contain ']' after 'Use Agent[' but found {response}\")\n        if len(split_agent_info) > 2:\n            raise ValueError(f\"Expected response string to contain only one ']' after 'Use Agent[' but found {response}\")\n\n        agent_name_info = split_agent_info[0]\n        split_agent_name_info = agent_name_info.split(':')\n        if len(split_agent_name_info) > 2:\n            raise ValueError(f\"Expected response string to contain only one ':' after 'Use Agent[' but found {response}\")\n\n        agent_name = split_agent_name_info[0]\n        input_text = \"\"\n        if len(split_agent_name_info) == 2:\n            input_text = split_agent_name_info[1]\n\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        # Extract the agent information from the response string\n        agent_info = response.split('Use Agent[')[1].split(']')[0]\n\n        # Extract the agent name\n        agent_name = agent_info.split(':')[0]\n\n        # Extract the input text\n        input_text = ''\n        if len(agent_info.split(':')) > 1:\n            input_text = agent_info.split(':')[1]\n\n        return agent_name, input_text\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 2, \"Expect segmentation of 2 dimensions, got {}.\".format(\n                        segm.ndim\n                    )\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot convert segmentation of type '{}' to BitMasks!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict, or a full-image segmentation mask \"\n                        \"as a 2D ndarray.\".format(type(segm))\n                    )\n            # torch.from_numpy does not support array with negative stride.\n            masks = BitMasks(\n                torch.stack([torch.from_numpy(np.as"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 2, \"Expect segmentation of 2 dimensions, got {}.\".format(\n                        segm.ndim\n                    )\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot convert segmentation of type '{}' to BitMasks!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict, or a full-image segmentation mask \"\n                        \"as a 2D ndarray.\".format(type(segm))\n                    )\n            # torch.from_numpy does not support array with negative stride.\n            masks = BitMasks(\n                torch.stack([torch.from_numpy(np.as"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 2, \"Expect segmentation of 2 dimensions, got {}.\".format(\n                        segm.ndim\n                    )\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot convert segmentation of type '{}' to BitMasks!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict, or a full-image segmentation mask \"\n                        \"as a 2D ndarray.\".format(type(segm))\n                    )\n            # torch.from_numpy does not support array with negative stride.\n            masks = BitMasks(\n                torch.stack([torch.from_numpy(np.as"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 2, \"Expect segmentation of 2 dimensions, got {}.\".format(\n                        segm.ndim\n                    )\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot convert segmentation of type '{}' to BitMasks!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict, or a full-image segmentation mask \"\n                        \"as a 2D ndarray.\".format(type(segm))\n                    )\n            # torch.from_numpy does not support array with negative stride.\n            masks = BitMasks(\n                torch.stack([torch.from_numpy(np.as"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 2, \"Expect segmentation of 2 dimensions, got {}.\".format(\n                        segm.ndim\n                    )\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot convert segmentation of type '{}' to BitMasks!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict, or a full-image segmentation mask \"\n                        \"as a 2D ndarray.\".format(type(segm))\n                    )\n            # torch.from_numpy does not support array with negative stride.\n            masks = BitMasks(\n                torch.stack([torch.from_numpy(np.as"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 2, \"Expect segmentation of 2 dimensions, got {}.\".format(\n                        segm.ndim\n                    )\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot convert segmentation of type '{}' to BitMasks!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict, or a full-image segmentation mask \"\n                        \"as a 2D ndarray.\".format(type(segm))\n                    )\n            # torch.from_numpy does not support array with negative stride.\n            masks = BitMasks(\n                torch.stack([torch.from_numpy(np.as"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 2, \"Expect segmentation of 2 dimensions, got {}.\".format(\n                        segm.ndim\n                    )\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot convert segmentation of type '{}' to BitMasks!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict, or a full-image segmentation mask \"\n                        \"as a 2D ndarray.\".format(type(segm))\n                    )\n            # torch.from_numpy does not support array with negative stride.\n            masks = BitMasks(\n                torch.stack([torch.from_numpy(np.as"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 2, \"Expect segmentation of 2 dimensions, got {}.\".format(\n                        segm.ndim\n                    )\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot convert segmentation of type '{}' to BitMasks!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict, or a full-image segmentation mask \"\n                        \"as a 2D ndarray.\".format(type(segm))\n                    )\n            # torch.from_numpy does not support array with negative stride.\n            masks = BitMasks(\n                torch.stack([torch.from_numpy(np.as"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 2, \"Expect segmentation of 2 dimensions, got {}.\".format(\n                        segm.ndim\n                    )\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot convert segmentation of type '{}' to BitMasks!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict, or a full-image segmentation mask \"\n                        \"as a 2D ndarray.\".format(type(segm))\n                    )\n            # torch.from_numpy does not support array with negative stride.\n            masks = BitMasks(\n                torch.stack([torch.from_numpy(np.as"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes)\n\n    classes = [int(obj[\"category_id\"]) for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 2, \"Expect segmentation of 2 dimensions, got {}.\".format(\n                        segm.ndim\n                    )\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot convert segmentation of type '{}' to BitMasks!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict, or a full-image segmentation mask \"\n                        \"as a 2D ndarray.\".format(type(segm))\n                    )\n            # torch.from_numpy does not support array with negative stride.\n            masks = BitMasks(\n                torch.stack([torch.from_numpy(np"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 2, \"Expect segmentation of 2 dimensions, got {}.\".format(\n                        segm.ndim\n                    )\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot convert segmentation of type '{}' to BitMasks!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict, or a full-image segmentation mask \"\n                        \"as a 2D ndarray.\".format(type(segm))\n                    )\n            # torch.from_numpy does not support array with negative stride.\n            masks = BitMasks(\n                torch."}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 2, \"Expect segmentation of 2 dimensions, got {}.\".format(\n                        segm.ndim\n                    )\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot convert segmentation of type '{}' to BitMasks!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict, or a full-image segmentation mask \"\n                        \"as a 2D ndarray.\".format(type(segm))\n                    )\n            # torch.from_numpy does not support array with negative stride.\n            masks = BitMasks(\n                torch."}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 2, \"Expect segmentation of 2 dimensions, got {}.\".format(\n                        segm.ndim\n                    )\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot convert segmentation of type '{}' to BitMasks!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict, or a full-image segmentation mask \"\n                        \"as a 2D ndarray.\".format(type(segm))\n                    )\n            # torch.from_numpy does not support array with negative stride.\n            masks = BitMasks(\n                torch."}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 2, \"Expect segmentation of 2 dimensions, got {}.\".format(\n                        segm.ndim\n                    )\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot convert segmentation of type '{}' to BitMasks!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict, or a full-image segmentation mask \"\n                        \"as a 2D ndarray.\".format(type(segm))\n                    )\n            # torch.from_numpy does not support array with negative stride.\n            masks = BitMasks(\n                torch."}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 2, \"Expect segmentation of 2 dimensions, got {}.\".format(\n                        segm.ndim\n                    )\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot convert segmentation of type '{}' to BitMasks!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict, or a full-image segmentation mask \"\n                        \"as a 2D ndarray.\".format(type(segm))\n                    )\n            # torch.from_numpy does not support array with negative stride.\n            masks = BitMasks(\n                torch."}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 2, \"Expect segmentation of 2 dimensions, got {}.\".format(\n                        segm.ndim\n                    )\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot convert segmentation of type '{}' to BitMasks!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict, or a full-image segmentation mask \"\n                        \"as a 2D ndarray.\".format(type(segm))\n                    )\n            # torch.from_numpy does not support array with negative stride.\n            masks = BitMasks(\n                torch.stack(["}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 2, \"Expect segmentation of 2 dimensions, got {}.\".format(\n                        segm.ndim\n                    )\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot convert segmentation of type '{}' to BitMasks!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict, or a full-image segmentation mask \"\n                        \"as a 2D ndarray.\".format(type(segm))\n                    )\n            # torch.from_numpy does not support array with negative stride.\n            masks = BitMasks(\n                torch.stack([torch.from_numpy(np.ascont"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 2, \"Expect segmentation of 2 dimensions, got {}.\".format(\n                        segm.ndim\n                    )\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot convert segmentation of type '{}' to BitMasks!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict, or a full-image segmentation mask \"\n                        \"as a 2D ndarray.\".format(type(segm))\n                    )\n            masks = BitMasks(\n                torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n            )\n       "}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 2, \"Expect segmentation of 2 dimensions, got {}.\".format(\n                        segm.ndim\n                    )\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot convert segmentation of type '{}' to BitMasks!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict, or a full-image segmentation mask \"\n                        \"as a 2D ndarray.\".format(type(segm))\n                    )\n            # torch.from_numpy does not support array with negative stride.\n            masks = BitMasks(\n                torch.stack"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes)\n\n    classes = [int(obj[\"category_id\"]) for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            try:\n                masks = PolygonMasks(segms)\n            except ValueError as e:\n                raise ValueError(\n                    \"Failed to use mask_format=='polygon' for the annotations. Two possible reasons:\\n\"\n                    \"1. The segmentation annotations are not in a format that's compatible with polygon masks.\\n\"\n                    \"2. The segmentation annotations have some unsupported features, such as multiple parts.\\n\"\n                    \"Please set mask_format='bitmask' instead.\\n\"\n                    f\"Original error message: {e}\"\n                )\n        else:\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 2, \"Expect segmentation of 2 dimensions, got {}.\".format(\n                        segm.ndim\n                    )\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot convert segmentation of type '{}' to BitMasks!\"\n                        \"Supported"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", os.path.join(\"~\", \"skfolio_data\"))\n\n    data_home = os.path.expanduser(data_home)\n    if not os.path.exists(data_home):\n        os.makedirs(data_home)\n\n    return data_home\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", str(Path.home() / \"skfolio_data\"))\n\n    data_home = Path(data_home).expanduser()\n    data_home.mkdir(parents=True, exist_ok=True)\n\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", str(Path.home() / \"skfolio_data\"))\n\n    data_home = Path(data_home)\n    data_home.mkdir(parents=True, exist_ok=True)\n\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", str(Path.home() / \"skfolio_data\"))\n    data_home = Path(data_home).expanduser()\n    data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\n            \"SKFOLIO_DATA\", Path.home() / \"skfolio_data\"\n        )\n    data_home = Path(data_home)\n    data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", str(Path.home() / \"skfolio_data\"))\n\n    data_home = Path(data_home)\n    data_home.mkdir(parents=True, exist_ok=True)\n\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", os.path.join(\"~\", \"skfolio_data\"))\n\n    data_home = os.path.expanduser(data_home)\n    if not os.path.exists(data_home):\n        os.makedirs(data_home)\n\n    return data_home\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", str(Path.home() / \"skfolio_data\"))\n\n    data_home = Path(data_home)\n\n    if not data_home.exists():\n        data_home.mkdir(parents=True, exist_ok=True)\n\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    data_home = Path(data_home).expanduser()\n    data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    data_home = Path(data_home).expanduser()\n    data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", os.path.join(\"~\", \"skfolio_data\"))\n\n    data_home = os.path.expanduser(data_home)\n    if not os.path.exists(data_home):\n        os.makedirs(data_home)\n\n    return data_home\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", str(Path.home() / \"skfolio_data\"))\n\n    data_home = Path(data_home).expanduser()\n    data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n\n    data_home = Path(data_home).expanduser()\n    data_home.mkdir(parents=True, exist_ok=True)\n\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", str(Path.home() / \"skfolio_data\"))\n\n    data_home = Path(data_home)\n    data_home.mkdir(parents=True, exist_ok=True)\n\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", str(Path.home() / \"skfolio_data\"))\n\n    data_home = Path(data_home).expanduser()\n    if not data_home.exists():\n        data_home.mkdir(parents=True)\n\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", str(Path.home() / \"skfolio_data\"))\n    data_home = Path(data_home)\n    data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    data_home = Path(data_home).expanduser()\n    data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n\n    data_home = Path(data_home)\n    data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", os.path.join(\"~\", \"skfolio_data\"))\n\n    data_home = os.path.expanduser(data_home)\n    if not os.path.exists(data_home):\n        os.makedirs(data_home)\n\n    return data_home\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", str(Path.home() / \"skfolio_data\"))\n    data_home = Path(data_home).expanduser()\n    if not data_home.exists():\n        data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Checking the input is a 2D array\n    if cov.ndim != 2:\n        raise ValueError(\"The input covariance matrix must be a 2D array\")\n\n    # Checking the input is square\n    if cov.shape[0] != cov.shape[1]:\n        raise ValueError(\"The input covariance matrix must be a square matrix\")\n\n    # Calculating the standard deviations for each variable\n    std = np.sqrt(np.diag(cov))\n\n    # Calculating the correlation matrix\n    corr = cov / np.outer(std, std)\n\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Ensure that the input is a 2D array\n    if cov.ndim != 2:\n        raise ValueError(\"The input covariance matrix must be a 2D array.\")\n\n    # Calculate the standard deviation for each variable\n    std = np.sqrt(np.diag(cov))\n\n    # Convert the covariance matrix into a correlation matrix\n    corr = cov / np.outer(std, std)\n\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert_is_square(cov)\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Checks if the input is a 2D array\n    if cov.ndim != 2:\n        raise ValueError(\n            f\"The input covariance matrix is not a 2D array. It has {cov.ndim} dimensions.\"\n        )\n\n    # Checks if the input is a square matrix\n    if cov.shape[0] != cov.shape[1]:\n        raise ValueError(\n            f\"The input covariance matrix is not square. It has shape {cov.shape}.\"\n        )\n\n    # Calculates the standard deviations for each variable\n    std = np.sqrt(np.diag(cov))\n\n    # Calculates the correlation matrix\n    corr = cov / np.outer(std, std)\n\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Check if the input is a 2D array\n    if cov.ndim != 2:\n        raise ValueError(\"The input is not a 2D array\")\n\n    # Check if the input is a square matrix\n    if cov.shape[0] != cov.shape[1]:\n        raise ValueError(\"The input is not a square matrix\")\n\n    # Check if the input is a positive semi-definite matrix\n    if not is_positive_definite(cov):\n        raise ValueError(\"The input is not a positive semi-definite matrix\")\n\n    # Calculate standard deviation for each variable\n    std = np.sqrt(np.diag(cov))\n\n    # Convert covariance matrix to correlation matrix\n    corr = cov / np.outer(std, std)\n\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Checking if input is a 2D array\n    if cov.ndim != 2:\n        raise ValueError(\"The input array must be a 2D array\")\n\n    # Checking if input is a square matrix\n    if cov.shape[0] != cov.shape[1]:\n        raise ValueError(\"The input array must be a square matrix\")\n\n    # Calculating standard deviation for each variable\n    std = np.sqrt(np.diag(cov))\n\n    # Calculating correlation matrix\n    corr = cov / np.outer(std, std)\n\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert_is_symmetric(cov)\n    assert_is_distance(cov)\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Ensure the input is a 2D array\n    if cov.ndim != 2:\n        raise ValueError(\"The input covariance matrix must be a 2D array.\")\n\n    # Compute the standard deviations for each variable\n    std = np.sqrt(np.diag(cov))\n\n    # Convert the covariance matrix into a correlation matrix\n    corr = cov / np.outer(std, std)\n\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Ensure that the input is a 2D array\n    if cov.ndim != 2:\n        raise ValueError(\"Input must be a 2D array\")\n\n    # Calculate the standard deviations for each variable\n    std = np.sqrt(np.diag(cov))\n\n    # Convert the covariance matrix into a correlation matrix\n    corr = cov / np.outer(std, std)\n\n    # Return the correlation matrix and standard deviations\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Ensure that the input is a 2D array\n    if cov.ndim != 2:\n        raise ValueError(\"The input argument must be a 2D array\")\n\n    # Calculate standard deviations for each variable\n    std = np.sqrt(np.diag(cov))\n\n    # Convert the covariance matrix into a correlation matrix\n    corr = np.zeros(cov.shape)\n    for i in range(cov.shape[0]):\n        for j in range(cov.shape[1]):\n            corr[i, j] = cov[i, j] / (std[i] * std[j])\n\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Check the input is a 2D array\n    if cov.ndim != 2:\n        raise ValueError(\"The input array must be 2D\")\n\n    # Calculate the standard deviations for each variable\n    std = np.sqrt(np.diag(cov))\n\n    # Convert the covariance matrix to a correlation matrix\n    corr = cov / np.outer(std, std)\n\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if cov.ndim != 2:\n        raise ValueError(\"The covariance matrix must be a 2D array\")\n\n    std_dev = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std_dev, std_dev)\n    corr[corr < -1] = -1\n    corr[corr > 1] = 1\n    return corr, std_dev\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Checks that the input is a 2D array\n    if cov.ndim != 2:\n        raise ValueError(\n            \"The input matrix must be a 2D array. Please check that you have entered the correct data.\"\n        )\n\n    # Checks that the input is a square matrix\n    if cov.shape[0] != cov.shape[1]:\n        raise ValueError(\n            \"The input matrix must be a square matrix. Please check that you have entered the correct data.\"\n        )\n\n    # Calculates the standard deviations for each variable\n    std = np.sqrt(np.diag(cov))\n\n    # Calculates the correlation matrix\n    corr = cov / np.outer(std, std)\n\n    # Returns the correlation matrix and the standard deviations\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert_is_square(cov)\n    assert_is_symmetric(cov)\n    assert_is_distance(cov)\n\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Check if covariance matrix is 2D\n    if cov.ndim != 2:\n        raise ValueError(\"The covariance matrix must be a 2D array\")\n\n    # Check if covariance matrix is square\n    if cov.shape[0] != cov.shape[1]:\n        raise ValueError(\"The covariance matrix must be a square matrix\")\n\n    # Calculate the standard deviation for each variable\n    std = np.sqrt(np.diag(cov))\n\n    # Convert to correlation matrix\n    corr = cov / np.outer(std, std)\n\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if cov.ndim != 2:\n        raise ValueError(\"The covariance matrix must be a 2D array\")\n\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if cov.ndim != 2 or cov.shape[0] != cov.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n\n    std_vector = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std_vector, std_vector)\n    corr[corr < -1], corr[corr > 1] = -1, 1\n    corr = np.round(corr, 3)\n    return corr, std_vector\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Check that the input is a 2D array\n    if cov.ndim != 2:\n        raise ValueError(\"Input must be a 2D array\")\n\n    # Calculate the standard deviations\n    std = np.sqrt(np.diag(cov))\n\n    # Convert the covariance matrix into a correlation matrix\n    corr = cov / np.outer(std, std)\n\n    # Return the correlation matrix and standard deviations\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Check if covariance matrix is valid\n    assert_is_square(cov)\n    assert_is_symmetric(cov)\n    assert is_positive_definite(cov)\n\n    # Calculate standard deviations for each variable\n    sd = np.sqrt(np.diag(cov))\n\n    # Convert to correlation matrix\n    corr = cov / sd[:, None]\n    corr = corr / sd[None, :]\n\n    return corr, sd\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Ensure the input is a 2D array\n    if cov.ndim != 2:\n        raise ValueError(\"The input covariance matrix must be a 2D array\")\n\n    # Get the standard deviation for each variable\n    std_dev = np.sqrt(np.diag(cov))\n\n    # Convert the covariance matrix into a correlation matrix\n    corr = cov / np.outer(std_dev, std_dev)\n\n    return corr, std_dev\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # Store the original values of the training attributes of the model's submodules.\n    original_training_attrs = {}\n    for name, module in model.named_modules():\n        original_training_attrs[name] = module.training\n\n    # Temporarily set the training attributes of the model's submodules to a constant value.\n    for name, module in model.named_modules():\n        module.training = False\n\n    # Yield to the context manager.\n    yield\n\n    # Revert the training attributes of the model's submodules to their original values.\n    for name, module in model.named_modules():\n        module.training = original_training_attrs[name]"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # Save the old state of the model\n    old_state = {}\n    for name, module in model.named_modules():\n        old_state[name] = module.training\n\n    # Freeze the model\n    for name, module in model.named_modules():\n        module.training = False\n\n    # Yield to the caller\n    yield\n\n    # Unfreeze the model\n    for name, module in model.named_modules():\n        module.training = old_state[name]"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # Keep track of the original \"training\" attributes of the model's submodules.\n    training_states = {}\n\n    # Keep track of the original \"training\" attributes of the model's submodules.\n    for name, module in model.named_modules():\n        training_states[name] = module.training\n\n    # Set the \"training\" attributes of the model's submodules to a constant value.\n    for name, module in model.named_modules():\n        module.training = False\n\n    # Yield to the context manager.\n    yield\n\n    # Set the \"training\" attributes of the model's submodules to their original values.\n    for name, module in model.named_modules():\n        module.training = training_states[name]"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # Store the original values of the \"training\" attributes of every submodule of the model.\n    original_training_flags = {}\n    for name, submodule in model.named_modules():\n        original_training_flags[name] = submodule.training\n\n    # Set the \"training\" attributes of every submodule of the model to a constant value.\n    for name, submodule in model.named_modules():\n        submodule.training = False\n\n    # Yield to the context manager.\n    yield\n\n    # Restore the original \"training\" attributes of every submodule of the model.\n    for name, submodule in model.named_modules():\n        submodule.training = original_training_flags[name]"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # Save the original \"training\" attributes of the model and its submodules.\n    original_training_attrs = {}\n    for name, module in model.named_modules():\n        original_training_attrs[name] = getattr(module, \"training\", None)\n\n    # Temporarily modify the \"training\" attributes of the model and its submodules to be constant.\n    for name, module in model.named_modules():\n        if hasattr(module, \"training\"):\n            module.training = torch.jit.Final[bool](module.training)\n\n    # Yield to the context manager.\n    yield\n\n    # Restore the original \"training\" attributes of the model and its submodules.\n    for name, module in model.named_modules():\n        if hasattr(module, \"training\"):\n            module.training = original_training_attrs[name]"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    def _freeze_module_training_mode(module):\n        \"\"\"\n        This function temporarily sets the \"training\" attribute of a given module to a constant value, allowing for optimization by meta-compilation. It uses a context manager to ensure that this change is reverted back to its original state after the context manager exits.\n        Input-Output Arguments\n        :param module: The module whose \"training\" attribute is to be temporarily annotated as a constant. It is used to modify the class definition of the module.\n        :return: No return values. This function operates by side effects, modifying the class definition of the module within the context.\n        \"\"\"\n\n        def _freeze_training_mode(self):\n            \"\"\"\n            This function temporarily sets the \"training\" attribute of a given module to a constant value, allowing for optimization by meta-compilation. It uses a context manager to ensure that this change is reverted back to its original state after the context manager exits.\n            Input-Output Arguments\n            :param self: The module whose \"training\" attribute is to be temporarily annotated as a constant. It is used to modify the class definition of the module.\n            :return: No return values. This function operates by side effects, modifying the class definition of the module within the context.\n            \"\"\"\n            return torch.jit.annotate(bool, not self.training)\n\n        module.training = torch.jit.annotate(bool, not module.training)\n        module.__class__.training = property(_freeze_training_mode)\n\n    def _unfreeze_module_training_mode(module):\n        \"\"\"\n        This function reverts the \"training\" attribute of a given module back to its original state, undoing the effects of the _freeze_module_training_mode function. It uses a context manager to ensure that this change is reverted back to its original state after the context manager exits.\n        Input-Output Arguments\n        :param module: The module whose \"training\" attribute is to be reverted back to its original state. It is used to modify the class definition of the module.\n        :return: No return values. This function operates by side effects, modifying the class"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    try:\n        # Store the original \"training\" attributes of the model's submodules.\n        original_training_flags = {}\n        for name, submodule in model.named_modules():\n            original_training_flags[name] = submodule.training\n        # Set the \"training\" attributes of the model's submodules to constants.\n        for name, submodule in model.named_modules():\n            submodule.training = torch.jit.Attribute(submodule.training, bool)\n        # Yield to context manager.\n        yield\n    finally:\n        # Revert the \"training\" attributes of the model's submodules back to their original state.\n        for name, submodule in model.named_modules():\n            submodule.training = original_training_flags[name]"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    def freeze_module(module):\n        \"\"\"\n        This function sets the \"training\" attribute of a module to a constant value, allowing for optimization by meta-compilation.\n        Input-Output Arguments\n        :param module: The module whose \"training\" attribute is to be set to a constant value.\n        :return: No return values. This function operates by side effects, modifying the class definition of the module.\n        \"\"\"\n        module.training = torch.jit.Attribute(module.training, bool)\n\n    # Iterate through all submodules of the model and annotate their \"training\" attributes as constants.\n    model.apply(freeze_module)\n\n    # Return the context manager.\n    with ExitStack() as stack:\n        yield stack"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # Save the original training mode for each submodule\n    training_modes = {}\n    for name, module in model.named_modules():\n        training_modes[name] = getattr(module, \"training\", None)\n\n    # Temporarily modify the training mode of every submodule to a constant value\n    for name, module in model.named_modules():\n        if name == \"\":\n            continue\n        module.training = torch.jit.Final[bool](False)\n\n    # Yield to the context manager\n    yield\n\n    # Revert the training mode of every submodule back to their original values\n    for name, module in model.named_modules():\n        if name == \"\":\n            continue\n        if training_modes[name] is not None:\n            module.training = torch.jit.Final[bool](training_modes[name])\n        else:\n            delattr(module, \"training\")"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # Save original class definitions of the model's submodules.\n    orig_classes = {}\n    for name, module in model.named_modules():\n        orig_classes[name] = module.__class__\n\n    # Temporarily modify the class definitions of the model's submodules to add the \"training\" attribute as a constant.\n    for name, module in model.named_modules():\n        class_dict = {\"training\": torch.jit.Attribute(module.training, type=bool)}\n        new_class = type(orig_classes[name].__name__, (orig_classes[name],), class_dict)\n        module.__class__ = new_class\n\n    # Yield to the context manager.\n    yield\n\n    # Revert the class definitions of the model's submodules to their original state.\n    for name, module in model.named_modules():\n        module.__class__ = orig_classes[name]"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # Save original class definitions of the model's submodules\n    orig_classes = {}\n    for name, module in model.named_modules():\n        orig_classes[name] = type(module)\n\n    # Temporarily modify the class definitions of the model's submodules to set the \"training\" attribute as a constant\n    for name, module in model.named_modules():\n        class DensePoseDeepLabSemanticHead(type(module)):\n            def __init__(self, *args, **kwargs):\n                super().__init__(*args, **kwargs)\n                self.training = False\n        type_ = type(module)\n        module.__class__ = DensePoseDeepLabSemanticHead\n\n    # Yield to context manager\n    yield\n\n    # Restore original class definitions of the model's submodules\n    for name, module in model.named_modules():\n        module.__class__ = orig_classes[name]"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # Save the initial state of the model\n    modules_orig = {}\n    for name, module in model.named_modules():\n        modules_orig[name] = module\n        modules_orig[name].training = module.training\n\n    # Freeze the model by changing the class definition of every submodule to have a constant \"training\" attribute\n    for name, module in model.named_modules():\n        setattr(module, \"training\", module.training)\n        setattr(module, \"training\", torch.jit.Final(module.training))\n\n    # Yield to the context manager\n    yield\n\n    # Restore the model to its initial state\n    for name, module in model.named_modules():\n        module.training = modules_orig[name].training"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    if isinstance(model, torch.jit.ScriptModule):\n        # TorchScript models have no submodules.\n        yield\n        return\n\n    # Save the original values of the \"training\" attributes of each submodule.\n    original_submodule_training_values = {}\n    for name, submodule in model.named_modules():\n        if hasattr(submodule, \"training\") and submodule.training is not None:\n            original_submodule_training_values[name] = submodule.training\n\n    # Temporarily set the \"training\" attributes of every submodule to a constant value.\n    for name, submodule in model.named_modules():\n        if hasattr(submodule, \"training\") and submodule.training is not None:\n            submodule.training = False\n\n    # Perform the user's computation.\n    yield\n\n    # Restore the original values of the \"training\" attributes of each submodule.\n    for name, submodule in model.named_modules():\n        if name in original_submodule_training_values:\n            submodule.training = original_submodule_training_values[name]"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # Store original values of class attributes\n    training_attr_dict = {}\n    for name, module in model.named_modules():\n        if hasattr(module, \"training\"):\n            training_attr_dict[name] = module.training\n\n    # Temporarily set \"training\" attributes as constants\n    for name, module in model.named_modules():\n        if hasattr(module, \"training\"):\n            module.training = torch.jit.Attribute(training_attr_dict[name], bool)\n\n    # Yield to context manager\n    yield\n\n    # Revert back to original values of class attributes\n    for name, module in model.named_modules():\n        if hasattr(module, \"training\"):\n            module.training = training_attr_dict[name]\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # Save the original class definitions of the model and its submodules\n    original_classes = {}\n    for name, module in model.named_modules():\n        original_classes[name] = module.__class__\n\n    # Temporarily modify the \"training\" attributes of every submodule in the model to be a constant\n    for name, module in model.named_modules():\n        class NewClass(original_classes[name]):\n            # Make the \"training\" attribute a constant\n            training: bool = module.training\n\n            def __init__(self, training):\n                super().__init__()\n                self.training = training\n\n            # Make the \"training\" attribute a constant\n            @property\n            def training(self) -> bool:\n                return self._training\n\n            # Make the \"training\" attribute a constant\n            @training.setter\n            def training(self, value: bool):\n                self._training = value\n\n        # Set the class of the submodule to the modified class\n        module.__class__ = NewClass\n\n    # Yield to the context manager\n    yield\n\n    # Revert the class definitions of the model and its submodules to their original states\n    for name, module in model.named_modules():\n        module.__class__ = original_classes[name]"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # Store the original value of the \"training\" attribute of every submodule in a given model.\n    original_training_values = {}\n    for name, module in model.named_modules():\n        original_training_values[name] = module.training\n\n    # Temporarily set the \"training\" attribute of every submodule in a given model to a constant value.\n    for name, module in model.named_modules():\n        if isinstance(module, torch.jit.ScriptModule):\n            # If the submodule is a ScriptModule, then set the \"training\" attribute to a constant value.\n            module.training = torch.jit.Attribute(module.training, bool)\n        else:\n            # If the submodule is not a ScriptModule, then use the \"freeze_module\" function to set the \"training\" attribute to a constant value.\n            freeze_module(module, \"training\", module.training)\n\n    yield\n\n    # Revert the \"training\" attribute of every submodule in a given model to their original values.\n    for name, module in model.named_modules():\n        if isinstance(module, torch.jit.ScriptModule):\n            # If the submodule is a ScriptModule, then revert the \"training\" attribute to its original value.\n            module.training = original_training_values[name]\n        else:\n            # If the submodule is not a ScriptModule, then use the \"unfreeze_module\" function to revert the \"training\" attribute to its original value.\n            unfreeze_module(module, \"training\")\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # Store original training mode values to be restored later\n    training_modes = {}\n    for name, module in model.named_modules():\n        training_modes[name] = getattr(module, \"training\", True)\n\n    # Temporarily set training mode to False\n    for name, module in model.named_modules():\n        module.training = False\n\n    # Yield to context manager\n    yield\n\n    # Restore original training mode values\n    for name, module in model.named_modules():\n        module.training = training_modes[name]\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    def _freeze_module(module):\n        \"\"\"\n        This function temporarily sets the \"training\" attribute of a given submodule to a constant value, allowing for optimization by meta-compilation.\n        Input-Output Arguments\n        :param module: The submodule whose \"training\" attribute is to be temporarily annotated as a constant. It is used to modify the class definition.\n        :return: No return values. This function operates by side effects, modifying the class definition of the submodule.\n        \"\"\"\n\n        if isinstance(module, torch.jit.ScriptModule):\n            return\n\n        if hasattr(module, \"training\"):\n            module.training = torch.jit.Attribute(module.training, bool)\n\n        for name, child in module.named_children():\n            _freeze_module(child)\n\n    _freeze_module(model)\n    yield\n    _freeze_module(model)\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # Store the current training mode of the model's submodules.\n    training_modes = {}\n    for name, module in model.named_modules():\n        training_modes[name] = getattr(module, \"training\", True)\n\n    # Temporarily set the training mode of every submodule to a constant value.\n    for name, module in model.named_modules():\n        module.training = False\n\n    # Yield to the context manager.\n    yield\n\n    # Restore the original training modes of the submodules.\n    for name, module in model.named_modules():\n        module.training = training_modes[name]\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    try:\n        for name, module in model.named_modules():\n            if hasattr(module, \"training\") and module.training:\n                module.training = torch.jit.Final[bool](module.training)\n        yield\n    finally:\n        for name, module in model.named_modules():\n            if hasattr(module, \"training\") and isinstance(module.training, torch.jit.Final):\n                delattr(module, \"training\")\n\n"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[Any]]) -> Dict[str, List[Any]]:\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, Any]) -> Dict[str, Any]:\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Check if the shape of field1 equals the shape of field2.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Check if shape of field1 equals shape of field2.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shapes of field1 and field2 match.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[Any]]) -> Dict[str, List[Any]]:\n        \"\"\"Check if shape of field1 equals shape of field2.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Check if the shapes of field1 and field2 are equal.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if shape of field1 equals shape of field2.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[Any]]) -> Dict[str, List[Any]]:\n        \"\"\"Check if the shapes of field1 and field2 are equal.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[Any]]) -> Dict[str, List[Any]]:\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[Any]]) -> Dict[str, List[Any]]:\n        \"\"\"Check if shape(field1) equals shape(field2).\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Check if the two specified fields have the same shape.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[Any]]) -> Dict[str, List[Any]]:\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shape of field1 equals the shape of field2.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[Any]]) -> Dict[str, List[Any]]:\n        \"\"\"Check if shape of field1 equals shape of field2.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[Any]]) -> Dict[str, List[Any]]:\n        \"\"\"Check if the shapes of field1 and field2 are equal.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Check if the shape of field1 equals the shape of field2.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[Any]]) -> Dict[str, List[Any]]:\n        \"\"\"Check if field1 and field2 have the same shape.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Check if the shapes of field1 and field2 match.\n        \"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Check if the shapes of field1 and field2 match.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if metrics is None:\n        return [], []\n\n    if not isinstance(metrics, list):\n        raise TypeError(f\"Argument 'metrics' must be a list. Got {type(metrics)}\")\n\n    if len(metrics) == 0:\n        return [], []\n\n    if isinstance(metrics[0], str):\n        return metrics, [{}] * len(metrics)\n\n    if isinstance(metrics[0], dict):\n        return [metric[\"name\"] for metric in metrics], metrics\n\n    raise TypeError(f\"Argument 'metrics' must be a list of strings or dictionaries. Got {type(metrics[0])}\")\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if metrics is None:\n        return [], []\n\n    if not isinstance(metrics, list):\n        raise TypeError(\"Metrics must be a list.\")\n\n    if len(metrics) == 0:\n        return [], []\n\n    if isinstance(metrics[0], str):\n        return metrics, [{metric: {}} for metric in metrics]\n\n    if isinstance(metrics[0], dict):\n        metric_names = [metric for metric in metrics]\n        metric_params = metrics\n        return metric_names, metric_params\n\n    raise TypeError(\"Metrics must be a list of strings or dictionaries.\")\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # Check if metrics is a list\n    if not isinstance(metrics, list):\n        raise TypeError(\"Argument 'metrics' must be a list\")\n\n    # Check if metrics is a list of strings or dictionaries\n    if not all(isinstance(m, str) or isinstance(m, dict) for m in metrics):\n        raise TypeError(\"Argument 'metrics' must be a list of strings or dictionaries\")\n\n    # Check if all dictionaries in metrics have the same keys\n    if isinstance(metrics[0], dict):\n        metric_keys = metrics[0].keys()\n        if not all(metric_keys == m.keys() for m in metrics):\n            raise ValueError(\"All dictionaries in argument 'metrics' must have the same keys\")\n\n    # Check if all dictionaries in metrics have the same keys\n    if isinstance(metrics[0], dict):\n        metric_keys = metrics[0].keys()\n        if not all(metric_keys == m.keys() for m in metrics):\n            raise ValueError(\"All dictionaries in argument 'metrics' must have the same keys\")\n\n    # Check if all dictionaries in metrics have the same keys\n    if isinstance(metrics[0], dict):\n        metric_keys = metrics[0].keys()\n        if not all(metric_keys == m.keys() for m in metrics):\n            raise ValueError(\"All dictionaries in argument 'metrics' must have the same keys\")\n\n    # Check if all dictionaries in metrics have the same keys\n    if isinstance(metrics[0], dict):\n        metric_keys = metrics[0].keys()\n        if not all(metric_keys == m.keys() for m in metrics):\n            raise ValueError(\"All dictionaries in argument 'metrics' must have the same keys\")\n\n    # Check if all dictionaries in metrics have the same keys\n    if isinstance(metrics[0], dict):\n        metric_keys = metrics[0].keys()\n        if not all(metric_keys == m.keys() for m in metrics):\n            raise ValueError(\"All dictionaries in argument 'metrics' must have the same keys\")"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if isinstance(metrics, str):\n        metrics = [metrics]\n\n    if isinstance(metrics, list):\n        if isinstance(metrics[0], str):\n            metrics = [{'metric': metric} for metric in metrics]\n        elif isinstance(metrics[0], dict):\n            metrics = metrics\n        else:\n            raise ValueError('Metrics must be either a list of strings or a list of dictionaries.')\n\n    metric_names = [metric['metric'] for metric in metrics]\n    metric_params = [metric for metric in metrics]\n\n    return metric_names, metric_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # Define a list of metric names and a list of metric parameters\n    metric_names = []\n    metric_parameters = []\n\n    # Process the input metrics\n    for metric in metrics:\n\n        # If the metric is a string, it is assumed that it is a metric name\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_parameters.append({})\n\n        # If the metric is a dictionary, it is assumed that it contains metric parameters\n        elif isinstance(metric, dict):\n            metric_names.append(metric[\"name\"])\n            metric_parameters.append(metric)\n\n    # Return the list of metric names and the list of metric parameters\n    return metric_names, metric_parameters\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if isinstance(metrics, list):\n        if all(isinstance(metric, str) for metric in metrics):\n            metrics = [{\"name\": metric} for metric in metrics]\n        elif all(isinstance(metric, dict) for metric in metrics):\n            metrics = metrics\n        else:\n            raise TypeError(\"All elements in the metrics list must be either strings or dictionaries.\")\n    else:\n        raise TypeError(\"The metrics argument must be a list.\")\n\n    metric_names = [metric[\"name\"] for metric in metrics]\n    metric_params = [metric for metric in metrics]\n\n    return metric_names, metric_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if metrics is None:\n        return [], []\n\n    if isinstance(metrics, list):\n        if all(isinstance(metric, str) for metric in metrics):\n            return metrics, [{} for _ in range(len(metrics))]\n        elif all(isinstance(metric, dict) for metric in metrics):\n            return [metric[\"name\"] for metric in metrics], metrics\n        else:\n            raise ValueError(f\"Metrics must be a list of strings or a list of dictionaries. Received {metrics}\")\n    else:\n        raise ValueError(f\"Metrics must be a list of strings or a list of dictionaries. Received {metrics}\")\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if metrics is None:\n        metrics = []\n\n    if not isinstance(metrics, list):\n        raise TypeError(f\"Argument 'metrics' should be a list, but is {type(metrics)} instead\")\n\n    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n\n        elif isinstance(metric, dict):\n            if \"name\" not in metric:\n                raise ValueError(f\"Metric dictionary does not contain a 'name' key\")\n            metric_names.append(metric[\"name\"])\n            metric_params.append(deepcopy(metric))\n            del metric_params[-1][\"name\"]\n\n        else:\n            raise TypeError(f\"Metric '{metric}' should be a string or dictionary, but is {type(metric)} instead\")\n\n    return metric_names, metric_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # If the metrics are strings, cast them into dictionaries with the name as the only parameter\n    if isinstance(metrics[0], str):\n        metrics = [{\"name\": metric} for metric in metrics]\n\n    # Extract the metric names\n    metric_names = [metric[\"name\"] for metric in metrics]\n\n    # Return the metrics\n    return metric_names, metrics\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # Check if metrics is a list\n    if not isinstance(metrics, list):\n        raise TypeError(\"'metrics' must be a list.\")\n\n    # Check if all elements in metrics are strings or dictionaries\n    if not all(isinstance(metric, (str, dict)) for metric in metrics):\n        raise TypeError(\"'metrics' must contain only strings or dictionaries.\")\n\n    # Check if all elements in metrics are dictionaries\n    if all(isinstance(metric, dict) for metric in metrics):\n\n        # Check if all dictionaries have the same keys\n        if not all(metric.keys() == metrics[0].keys() for metric in metrics):\n            raise ValueError(\"All dictionaries in 'metrics' must have the same keys.\")\n\n        # Check if all dictionaries have the required keys\n        if not all(\n            all(key in metric for key in [\"name\", \"parameters\"]) for metric in metrics\n        ):\n            raise ValueError(\n                \"All dictionaries in 'metrics' must have 'name' and 'parameters' as keys.\"\n            )\n\n        # Check if all metric names are strings\n        if not all(isinstance(metric[\"name\"], str) for metric in metrics):\n            raise TypeError(\"'name' in 'metrics' must be a string.\")\n\n        # Check if all metric parameters are dictionaries\n        if not all(isinstance(metric[\"parameters\"], dict) for metric in metrics):\n            raise TypeError(\"'parameters' in 'metrics' must be a dictionary.\")\n\n        # Check if all metric names are unique\n        if len(metrics) != len(set([metric[\"name\"] for metric in metrics])):\n            raise ValueError(\"All metric names in 'metrics' must be unique.\")\n\n        # Check if all metric parameters have the same keys\n        if not all(\n            metric[\"parameters\"].keys() == metrics[0][\"parameters\"].keys()\n            for metric in metrics\n        ):\n            raise ValueError(\n                \"All metric parameters in 'metrics' must have the same keys.\"\n            )\n\n        # Check if all metric parameters have the required keys\n        if not all(\n            all(key in metric[\"parameters\"]"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # Check if metrics are in the correct format\n    if not isinstance(metrics, list):\n        raise TypeError(f\"'metrics' must be a list. Got {type(metrics)}\")\n\n    # Check if each metric is in the correct format\n    for metric in metrics:\n        if not isinstance(metric, (str, dict)):\n            raise TypeError(f\"Each metric must be either a string or a dictionary. Got {type(metric)}\")\n\n    # Check if each metric is a string\n    if all([isinstance(metric, str) for metric in metrics]):\n        return metrics, [{} for _ in range(len(metrics))]\n\n    # Check if each metric is a dictionary\n    if all([isinstance(metric, dict) for metric in metrics]):\n        metric_names = [metric[\"name\"] for metric in metrics]\n        metric_params = [metric for metric in metrics]\n        return metric_names, metric_params\n\n    # If the metrics are not in the correct format, raise an error\n    raise TypeError(f\"Each metric must be either a string or a dictionary. Got {[type(metric) for metric in metrics]}\")\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # if metrics is None, return empty lists\n    if metrics is None:\n        return [], []\n\n    # if metrics is a list of strings, convert it to a list of dictionaries\n    if isinstance(metrics, list) and isinstance(metrics[0], str):\n        metrics = [{\"name\": metric} for metric in metrics]\n\n    # check if metrics is a list of dictionaries\n    if not isinstance(metrics, list) or not isinstance(metrics[0], dict):\n        raise TypeError(\"Argument 'metrics' must be a list of dictionaries or strings.\")\n\n    # check if all dictionaries have a 'name' key\n    if not all(\"name\" in metric for metric in metrics):\n        raise ValueError(\"All metric dictionaries must contain a 'name' key.\")\n\n    # extract metric names and parameters\n    names, parameters = zip(*[(metric[\"name\"], deepcopy(metric)) for metric in metrics])\n\n    # remove 'name' key from parameters\n    for parameter in parameters:\n        del parameter[\"name\"]\n\n    # return metric names and parameters\n    return list(names), list(parameters)\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if isinstance(metrics, str):\n        metrics = [metrics]\n    elif isinstance(metrics, list):\n        if not all(isinstance(metric, str) for metric in metrics):\n            raise TypeError(\"The metrics argument must be a list of strings.\")\n    else:\n        raise TypeError(\"The metrics argument must be a list of strings.\")\n\n    metrics_names = []\n    metrics_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metrics_names.append(metric)\n            metrics_params.append({})\n        elif isinstance(metric, dict):\n            if \"name\" not in metric:\n                raise ValueError(\"The metrics argument must be a list of strings or dictionaries containing at least a 'name' key.\")\n            metrics_names.append(metric[\"name\"])\n            metrics_params.append({k: v for k, v in metric.items() if k != \"name\"})\n        else:\n            raise TypeError(\"The metrics argument must be a list of strings or dictionaries.\")\n\n    return metrics_names, metrics_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # Check if metrics is a list.\n    if not isinstance(metrics, list):\n        raise TypeError(\"Argument 'metrics' must be a list.\")\n\n    # Check if metrics is empty.\n    if len(metrics) == 0:\n        raise ValueError(\"Argument 'metrics' must not be empty.\")\n\n    # Check if metrics contains both string and dictionaries.\n    if not all(isinstance(metric, str) for metric in metrics) and not all(isinstance(metric, dict) for metric in metrics):\n        raise TypeError(\"Argument 'metrics' must contain only strings or dictionaries.\")\n\n    # Check if metrics contains dictionaries.\n    if any(isinstance(metric, dict) for metric in metrics):\n\n        # Check if metrics dictionaries contain 'name' key.\n        if not all(isinstance(metric, dict) and 'name' in metric for metric in metrics):\n            raise KeyError(\"Argument 'metrics' dictionaries must contain 'name' key.\")\n\n        # Check if metrics dictionaries contain 'parameters' key.\n        if not all(isinstance(metric, dict) and 'parameters' in metric for metric in metrics):\n            raise KeyError(\"Argument 'metrics' dictionaries must contain 'parameters' key.\")\n\n        # Check if metrics dictionaries contain 'parameters' key.\n        if not all(isinstance(metric['parameters'], dict) for metric in metrics):\n            raise TypeError(\"Argument 'metrics' dictionaries 'parameters' key must be a dictionary.\")\n\n    # If metrics is a list of strings, convert to list of dictionaries.\n    if all(isinstance(metric, str) for metric in metrics):\n        metrics = [{'name': metric, 'parameters': {}} for metric in metrics]\n\n    # Extract metric names.\n    metric_names = [metric['name'] for metric in metrics]\n\n    # Extract metric parameters.\n    metric_parameters = [metric['parameters'] for metric in metrics]\n\n    return metric_names, metric_parameters\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # Check if metrics is a list\n    if not isinstance(metrics, list):\n        raise TypeError(\"The metrics argument must be a list.\")\n\n    # Check if metrics is empty\n    if len(metrics) == 0:\n        raise ValueError(\"The metrics argument must contain at least one metric.\")\n\n    # Check if metrics is a list of strings\n    if isinstance(metrics[0], str):\n        return metrics, [{}] * len(metrics)\n\n    # Check if metrics is a list of dictionaries\n    elif isinstance(metrics[0], dict):\n\n        # Check if metrics is a list of dictionaries with correct keys\n        if not all([\"name\" in metric for metric in metrics]):\n            raise ValueError(\"The metrics argument must contain dictionaries with a 'name' key.\")\n\n        # Check if metrics is a list of dictionaries with correct keys\n        if not all([\"parameters\" in metric for metric in metrics]):\n            raise ValueError(\"The metrics argument must contain dictionaries with a 'parameters' key.\")\n\n        # Check if metrics is a list of dictionaries with correct types\n        if not all([isinstance(metric[\"name\"], str) for metric in metrics]):\n            raise TypeError(\"The metrics argument must contain dictionaries with a 'name' key of type str.\")\n\n        # Check if metrics is a list of dictionaries with correct types\n        if not all([isinstance(metric[\"parameters\"], dict) for metric in metrics]):\n            raise TypeError(\"The metrics argument must contain dictionaries with a 'parameters' key of type dict.\")\n\n        # Return metrics\n        return [metric[\"name\"] for metric in metrics], [metric[\"parameters\"] for metric in metrics]\n\n    # Raise TypeError if metrics is not a list of strings or dictionaries\n    else:\n        raise TypeError(\"The metrics argument must be a list of strings or dictionaries.\")\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # Check if metrics is a list\n    if not isinstance(metrics, list):\n        raise TypeError(f\"Metrics must be a list. Got {type(metrics)} instead.\")\n\n    # Check if metrics is empty\n    if len(metrics) == 0:\n        raise ValueError(\"Metrics list must not be empty.\")\n\n    # Check if metrics is a list of strings or dictionaries\n    if not all([isinstance(m, str) or isinstance(m, dict) for m in metrics]):\n        raise TypeError(\"Metrics must be a list containing either strings or dictionaries.\")\n\n    # If metrics is a list of strings, convert it to a list of dictionaries\n    if all([isinstance(m, str) for m in metrics]):\n        metrics = [{\"name\": m} for m in metrics]\n\n    # Check if metrics is a list of dictionaries\n    if not all([isinstance(m, dict) for m in metrics]):\n        raise TypeError(\"Metrics must be a list containing either strings or dictionaries.\")\n\n    # Check if metrics dictionaries have the \"name\" key\n    if not all([isinstance(m[\"name\"], str) for m in metrics]):\n        raise TypeError(\"Metrics dictionaries must have a 'name' key containing a string.\")\n\n    # Check if metrics dictionaries have the \"parameters\" key\n    if not all([isinstance(m.get(\"parameters\", None), dict) for m in metrics]):\n        raise TypeError(\"Metrics dictionaries must have a 'parameters' key containing a dictionary.\")\n\n    # Check if metrics dictionaries have the \"weight\" key\n    if not all([isinstance(m.get(\"weight\", None), (int, float)) for m in metrics]):\n        raise TypeError(\"Metrics dictionaries must have a 'weight' key containing an integer or float.\")\n\n    # Check if metrics dictionaries have the \"mode\" key\n    if not all([isinstance(m.get(\"mode\", None), str) for m in metrics]):\n        raise TypeError(\"Metrics dictionaries must have a 'mode' key containing a string.\")\n\n    # Check if metrics dictionaries have the \"min_val\""}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if not isinstance(metrics, list):\n        raise TypeError(\"The metrics argument must be a list.\")\n\n    if not all(isinstance(metric, (str, dict)) for metric in metrics):\n        raise TypeError(\"The metrics argument must contain only strings or dictionaries.\")\n\n    metric_names = []\n    metric_params = []\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric[\"name\"])\n            metric_params.append(metric)\n\n    return metric_names, metric_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # Check that the metrics input is a list\n    if not isinstance(metrics, list):\n        raise TypeError(\"The metrics argument must be a list\")\n\n    # Check that the list is not empty\n    if len(metrics) == 0:\n        raise ValueError(\"The metrics argument must contain at least one element\")\n\n    # Check that the metrics list contains only strings and dictionaries\n    if not all(isinstance(m, (str, dict)) for m in metrics):\n        raise TypeError(\"The metrics argument must be a list of strings and dictionaries\")\n\n    # Check that the dictionaries contain only strings and dictionaries\n    if isinstance(metrics[0], dict):\n        if not all(isinstance(m, (str, dict)) for m in metrics[0].values()):\n            raise TypeError(\"The metrics argument must be a list of strings and dictionaries\")\n\n    # Initialize the metric names and metric parameters lists\n    metric_names = []\n    metric_params = []\n\n    # Iterate over the metrics list\n    for m in metrics:\n\n        # If the metric is a string, add it to the metric names list and initialize the metric parameters dictionary\n        if isinstance(m, str):\n            metric_names.append(m)\n            metric_params.append({})\n\n        # If the metric is a dictionary, add the name to the metric names list and the dictionary to the metric parameters list\n        else:\n            metric_names.append(list(m.keys())[0])\n            metric_params.append(m[metric_names[-1]])\n\n    return metric_names, metric_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # Check that metrics is a list\n    if not isinstance(metrics, list):\n        raise TypeError(\"The metrics parameter must be a list.\")\n\n    # Check that metrics is not empty\n    if len(metrics) == 0:\n        raise ValueError(\"The metrics parameter must not be empty.\")\n\n    # Check that metrics contains only strings or dictionaries\n    if not all(isinstance(metric, str) or isinstance(metric, dict) for metric in metrics):\n        raise TypeError(\"The metrics parameter must contain only strings or dictionaries.\")\n\n    # Check that all dictionaries have the correct format\n    if any(not all(key in metric for key in [\"name\", \"parameters\"]) for metric in metrics if isinstance(metric, dict)):\n        raise KeyError(\"All dictionaries in the metrics parameter must contain the keys 'name' and 'parameters'.\")\n\n    # Check that all dictionaries have the correct format\n    if any(not all(isinstance(key, str) for key in metric[\"parameters\"]) for metric in metrics if isinstance(metric, dict)):\n        raise TypeError(\"All keys in the 'parameters' dictionary must be strings.\")\n\n    # Create a list of metric names\n    metric_names = [metric if isinstance(metric, str) else metric[\"name\"] for metric in metrics]\n\n    # Create a list of metric parameters\n    metric_parameters = [{} if isinstance(metric, str) else metric[\"parameters\"] for metric in metrics]\n\n    # Return metric names and parameters\n    return metric_names, metric_parameters\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if metrics is None:\n        return [], []\n\n    if isinstance(metrics, str):\n        metrics = [metrics]\n\n    if isinstance(metrics, list):\n        if all(isinstance(m, str) for m in metrics):\n            return metrics, [{}] * len(metrics)\n        if all(isinstance(m, dict) for m in metrics):\n            return [m[\"name\"] for m in metrics], metrics\n\n    raise ValueError(f\"Metrics must be a list of strings or dictionaries, but got {metrics}\")\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    if fn == jnp.exp:\n      fn_inv = jnp.log\n    elif fn == jnp.sinh:\n      fn_inv = jnp.arcsinh\n    elif fn == jnp.tanh:\n      fn_inv = jnp.arctanh\n    else:\n      raise ValueError(f'No inverse mapping for {fn} is currently supported.')\n\n  def t_to_s(t):\n    \"\"\"\n    Maps distances in the metric space to normalized distances in the range [0, 1].\n    \"\"\"\n    t = jnp.clip(t, t_near, t_far)\n    return (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n  def s_to_t(s):\n    \"\"\"\n    Maps normalized distances in the range [0, 1] to distances in the metric space.\n    \"\"\"\n    return fn_inv(fn(t_near) + s * (fn(t_far) - fn(t_near)))\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    fn_inv = _INVERSE_FN_MAP.get(fn, None)\n    if fn_inv is None:\n      raise ValueError(f'No inverse found for function {fn}.')\n\n  def t_to_s(t):\n    \"\"\"\n    Maps metric distances to normalized distances in the range [0, 1].\n\n    Input Arguments:\n    :param t: Tensor. Represents the metric distances.\n    :return: Tensor. Represents the normalized distances.\n    \"\"\"\n    t = jnp.clip(t, t_near, t_far)\n    return (t - t_near) / (t_far - t_near)\n\n  def s_to_t(s):\n    \"\"\"\n    Maps normalized distances to metric distances.\n\n    Input Arguments:\n    :param s: Tensor. Represents the normalized distances.\n    :return: Tensor. Represents the metric distances.\n    \"\"\"\n    return fn_inv(s) * (t_far - t_near) + t_near\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    fn_inv = {\n        jnp.exp: jnp.log,\n        jnp.sinh: jnp.arcsinh,\n        jnp.tanh: jnp.arctanh,\n        jnp.sin: jnp.arcsin,\n        jnp.cos: jnp.arccos,\n        jnp.tan: jnp.arctan,\n    }.get(fn)\n    if fn_inv is None:\n      raise ValueError(f'No known inverse for function {fn.__name__}.')\n\n  def t_to_s(t):\n    return jnp.clip((t - t_near) / (t_far - t_near), 0, 1)\n\n  def s_to_t(s):\n    return jnp.clip(s * (t_far - t_near) + t_near, t_near, t_far)\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  # If no inverse function is provided, try to automatically determine it.\n  if fn_inv is None:\n    if fn == jnp.exp:\n      fn_inv = jnp.log\n    elif fn == jnp.sinh:\n      fn_inv = jnp.arcsinh\n    elif fn == jnp.tanh:\n      fn_inv = jnp.arctanh\n    else:\n      raise ValueError(f'No inverse function for {fn} is available.')\n\n  # Define the forward and inverse mapping functions.\n  def t_to_s(t):\n    return (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n  def s_to_t(s):\n    return fn_inv(fn(t_near) + s * (fn(t_far) - fn(t_near)))\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    fn_inv = {\n        jnp.exp: jnp.log,\n        jnp.sinh: jnp.arcsinh,\n        jnp.tanh: jnp.arctanh,\n    }.get(fn, None)\n    if fn_inv is None:\n      raise ValueError(f'No inverse mapping for function {fn}')\n\n  def t_to_s(t):\n    \"\"\"Maps distances in the metric space to normalized distances in the range [0, 1].\"\"\"\n    t = jnp.clip(t, t_near, t_far)\n    return (fn(t) + 1) / 2\n\n  def s_to_t(s):\n    \"\"\"Maps normalized distances in the range [0, 1] to distances in the metric space.\"\"\"\n    return fn_inv(2 * s - 1)\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    if fn == jnp.exp:\n      fn_inv = jnp.log\n    elif fn == jnp.sinh:\n      fn_inv = jnp.arcsinh\n    elif fn == jnp.tanh:\n      fn_inv = jnp.arctanh\n    else:\n      raise ValueError(f'No inverse mapping available for {fn}.')\n\n  def t_to_s(t):\n    return jnp.clip(fn(t) / fn(t_far), 0, 1)\n\n  def s_to_t(s):\n    return jnp.clip(fn_inv(s * fn(t_far)), t_near, t_far)\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    if fn == jnp.exp:\n      fn_inv = jnp.log\n    elif fn == jnp.sinh:\n      fn_inv = jnp.arcsinh\n    else:\n      raise ValueError(f'No inverse function found for {fn.__name__}.')\n\n  def t_to_s(t):\n    t_clipped = jnp.clip(t, t_near, t_far)\n    return (fn(t_clipped) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n  def s_to_t(s):\n    return fn_inv(s * fn(t_far) + (1 - s) * fn(t_near))\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  # If no inverse function is provided, try to automatically determine it.\n  if fn_inv is None:\n    fn_inv = _INVERSE_FN_MAP.get(fn, None)\n\n  # If no inverse function is available, raise an error.\n  if fn_inv is None:\n    raise ValueError(f'Could not automatically determine inverse of {fn}.')\n\n  # Define the forward mapping from metric to normalized distances.\n  def t_to_s(t):\n    t = jnp.clip(t, t_near, t_far)\n    return (t - t_near) / (t_far - t_near)\n\n  # Define the inverse mapping from normalized to metric distances.\n  def s_to_t(s):\n    return fn_inv(s * (t_far - t_near) + t_near)\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    fn_inv = {\n        jnp.exp: jnp.log,\n        jnp.sinh: jnp.arcsinh,\n        jnp.tanh: jnp.arctanh,\n        jnp.sin: jnp.arcsin,\n        jnp.cos: jnp.arccos,\n        jnp.tan: jnp.arctan,\n        jnp.arccos: jnp.cos,\n        jnp.arcsin: jnp.sin,\n        jnp.arctan: jnp.tan,\n        jnp.arctanh: jnp.tanh,\n        jnp.arcsinh: jnp.sinh,\n        jnp.log: jnp.exp,\n    }.get(fn)\n\n  if fn_inv is None:\n    raise ValueError(f'No inverse for {fn} found.')\n\n  def t_to_s(t):\n    return jnp.clip(fn(t) / fn(t_far), 0, 1)\n\n  def s_to_t(s):\n    return jnp.clip(fn_inv(s * fn(t_far)), t_near, t_far)\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    fn_inv = INVERTIBLE_FN_INV.get(fn, None)\n    if fn_inv is None:\n      raise ValueError(f'No inverse found for {fn}.')\n\n  def t_to_s(t):\n    \"\"\"Maps metric distances to normalized distances in the range [0, 1].\"\"\"\n    t = jnp.clip(t, t_near, t_far)\n    return (t - t_near) / (t_far - t_near)\n\n  def s_to_t(s):\n    \"\"\"Maps normalized distances in the range [0, 1] to metric distances.\"\"\"\n    return fn_inv(s) * (t_far - t_near) + t_near\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    fn_inv = {\n        jnp.sinh: jnp.arcsinh,\n        jnp.tanh: jnp.arctanh,\n        jnp.sin: jnp.arcsin,\n        jnp.tan: jnp.arctan,\n        jnp.arccos: jnp.cos,\n        jnp.cosh: jnp.arccosh,\n        jnp.cos: jnp.acos,\n        jnp.exp: jnp.log,\n        jnp.log: jnp.exp,\n        jnp.sqrt: lambda x: x**2,\n    }.get(fn)\n    if fn_inv is None:\n      raise ValueError(f'No inverse found for {fn}.')\n\n  # Forward mapping from metric to normalized distances.\n  t_to_s = lambda t: (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n  # Inverse mapping from normalized to metric distances.\n  s_to_t = lambda s: fn_inv(fn(t_near) + s * (fn(t_far) - fn(t_near)))\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    fn_inv = _INVERSE_FN_MAP.get(fn)\n    if fn_inv is None:\n      raise ValueError(f'No inverse function found for {fn}.')\n\n  def t_to_s(t):\n    \"\"\"\n    Maps distances in metric space to normalized distances in the range [0, 1].\n\n    Input Arguments:\n    :param t: Tensor. The metric distances to be mapped to normalized distances.\n    :return: Tensor. The normalized distances.\n    \"\"\"\n\n    # Clip distances to ensure they fall within the valid range.\n    t = jnp.clip(t, t_near, t_far)\n\n    # Compute the normalized distances.\n    return (t - t_near) / (t_far - t_near)\n\n  def s_to_t(s):\n    \"\"\"\n    Maps normalized distances to metric distances.\n\n    Input Arguments:\n    :param s: Tensor. The normalized distances to be mapped to metric distances.\n    :return: Tensor. The metric distances.\n    \"\"\"\n\n    # Compute the metric distances.\n    return fn_inv(s) * (t_far - t_near) + t_near\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    fn_inv = {\n        jnp.sinh: jnp.arcsinh,\n        jnp.tanh: jnp.arctanh,\n        contract: inv_contract,\n    }.get(fn, None)\n\n  if fn_inv is None:\n    raise ValueError(f'No inverse found for {fn}.')\n\n  def t_to_s(t):\n    t = jnp.clip(t, t_near, t_far)\n    return (t - t_near) / (t_far - t_near)\n\n  def s_to_t(s):\n    s = jnp.clip(s, 0, 1)\n    return s * (t_far - t_near) + t_near\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  # Determine the inverse of the provided function if not provided.\n  if fn_inv is None:\n    fn_inv = INVERSE_FN_MAPPING.get(fn)\n    if fn_inv is None:\n      raise ValueError(f'Could not find inverse of function {fn}')\n\n  # Define the forward and backward mappings.\n  def t_to_s(t):\n    return (t - t_near) / (t_far - t_near)\n\n  def s_to_t(s):\n    return s * (t_far - t_near) + t_near\n\n  # Return the mappings.\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    fn_inv = {\n        jnp.exp: jnp.log,\n        jnp.sinh: jnp.arcsinh,\n        jnp.tanh: jnp.arctanh,\n        jnp.sin: jnp.arcsin,\n        jnp.cos: jnp.arccos,\n    }.get(fn, None)\n    if fn_inv is None:\n      raise ValueError(\n          'No known inverse for function {}. Please provide an inverse as `fn_inv`.'\n          .format(fn.__name__)\n      )\n\n  def t_to_s(t):\n    \"\"\"Normalize distances to [0, 1].\"\"\"\n    t = jnp.clip(t, t_near, t_far)\n    return (t - t_near) / (t_far - t_near)\n\n  def s_to_t(s):\n    \"\"\"Un-normalize distances to metric space.\"\"\"\n    return s * (t_far - t_near) + t_near\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    fn_inv = {\n        jnp.exp: jnp.log,\n        jnp.sinh: jnp.arcsinh,\n        jnp.tanh: jnp.arctanh,\n    }.get(fn, None)\n    if fn_inv is None:\n      raise ValueError(f'No inverse found for function {fn}.')\n\n  def t_to_s(t):\n    t = jnp.clip(t, t_near, t_far)\n    return (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n  def s_to_t(s):\n    return fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    fn_inv = _INVERSE_FN_MAP[fn]\n\n  def t_to_s(t):\n    return (t - t_near) / (t_far - t_near)\n\n  def s_to_t(s):\n    return t_near + s * (t_far - t_near)\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    fn_inv = {\n        jnp.exp: jnp.log,\n        jnp.sinh: jnp.arcsinh,\n        jnp.tanh: jnp.arctanh,\n        jnp.sin: jnp.arcsin,\n        jnp.cos: jnp.arccos,\n    }.get(fn)\n    if fn_inv is None:\n      raise ValueError(f'No inverse found for function {fn}.')\n  # Clamping to 1 produces correct scale inside |x| < 1\n  t_near = jnp.maximum(1, t_near)\n  t_far = jnp.maximum(1, t_far)\n  t_mean = (t_near + t_far) / 2\n  t_scale = t_far - t_near\n  s_mean = fn(t_mean)\n  s_scale = t_scale * jnp.abs(fn(t_mean + t_scale) - s_mean)\n  # Scaling by 1000 to prevent float32 rounding errors.\n  s_scale = jnp.where(s_scale == 0, 1e-3, s_scale) * 1000\n  t_to_s = lambda t: (fn(t) - s_mean) / s_scale\n  s_to_t = lambda s: fn_inv((s * s_scale + s_mean) / 1000)\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  # If no inverse function is provided, try to find it automatically.\n  if fn_inv is None:\n    fn_inv = _INVERSE_FN_MAPPING.get(fn, None)\n    if fn_inv is None:\n      raise ValueError(f'No inverse function found for {fn}.')\n\n  # Clamp the near and far plane distances to ensure they fall within a valid range.\n  t_near = jnp.maximum(1e-6, t_near)\n  t_far = jnp.maximum(1e-6, t_far)\n\n  def t_to_s(t):\n    \"\"\"Maps metric distances to normalized distances in the range [0, 1].\"\"\"\n    t = jnp.clip(t, t_near, t_far)\n    return (jnp.log(t) - jnp.log(t_near)) / (jnp.log(t_far) - jnp.log(t_near))\n\n  def s_to_t(s):\n    \"\"\"Maps normalized distances to metric distances.\"\"\"\n    return fn_inv(t_near * (1.0 - s) + t_far * s)\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  # If `fn_inv` is not provided, try to automatically determine it based on the\n  # mapping of functions to their inverses.\n  if fn_inv is None:\n    fn_inv = {\n        jnp.sinh: jnp.arcsinh,\n        jnp.tanh: jnp.arctan,\n        contract: inv_contract,\n    }.get(fn, None)\n    if fn_inv is None:\n      raise ValueError(f'No inverse found for function {fn}.')\n\n  def t_to_s(t):\n    \"\"\"Maps distances in the metric space to normalized distances in [0, 1].\"\"\"\n    t = jnp.clip(t, t_near, t_far)\n    return (fn(t) + 1) / 2\n\n  def s_to_t(s):\n    \"\"\"Maps normalized distances in [0, 1] to distances in the metric space.\"\"\"\n    return fn_inv(2 * s - 1)\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.array([x, y, z])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.array([x, y, z])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n\n  return jnp.array([x, y, z])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.array([x, y, z])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.array([x, y, z])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  return jnp.array([\n      r * jnp.sin(theta) * jnp.cos(phi),\n      r * jnp.sin(theta) * jnp.sin(phi),\n      r * jnp.cos(theta)\n  ])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.array([x, y, z])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n\n  return x, y, z\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n\n  return jnp.array([x, y, z])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  return jnp.array([\n    r * jnp.sin(theta) * jnp.cos(phi),\n    r * jnp.sin(theta) * jnp.sin(phi),\n    r * jnp.cos(theta)\n  ])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  return jnp.array([\n      r * jnp.sin(theta) * jnp.cos(phi),\n      r * jnp.sin(theta) * jnp.sin(phi),\n      r * jnp.cos(theta),\n  ])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.array([x, y, z])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.array([x, y, z])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  return jnp.array([\n    r * jnp.sin(theta) * jnp.cos(phi),\n    r * jnp.sin(theta) * jnp.sin(phi),\n    r * jnp.cos(theta)\n  ])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  # Convert to radians\n  theta = theta * jnp.pi / 180\n  phi = phi * jnp.pi / 180\n\n  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n\n  return jnp.array([x, y, z])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  # Convert the elevation angle from radians to degrees.\n  theta = theta * 180 / jnp.pi\n\n  # Convert the azimuth angle from radians to degrees.\n  phi = phi * 180 / jnp.pi\n\n  # Convert the elevation angle from degrees to radians.\n  theta = theta * jnp.pi / 180\n\n  # Convert the azimuth angle from degrees to radians.\n  phi = phi * jnp.pi / 180\n\n  # Calculate the cartesian coordinates.\n  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n\n  return x, y, z\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n\n  return jnp.stack([x, y, z], axis=-1)\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  # Convert the elevation and azimuth angles to radians.\n  theta = theta * jnp.pi / 180.0\n  phi = phi * jnp.pi / 180.0\n\n  # Calculate the cartesian coordinates.\n  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n\n  return jnp.array([x, y, z])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n\n  return jnp.array([x, y, z])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  # Convert the elevation angle from radians to degrees.\n  theta = theta * 180 / jnp.pi\n\n  # Convert the azimuth angle from radians to degrees.\n  phi = phi * 180 / jnp.pi\n\n  # Calculate the cartesian coordinates.\n  x = r * jnp.cos(theta) * jnp.cos(phi)\n  y = r * jnp.cos(theta) * jnp.sin(phi)\n  z = r * jnp.sin(theta)\n\n  return jnp.array([x, y, z])\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return math.trapezoid(t, w)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return math.trapezoid(t, w)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.sum(0.5 * (w[1:] + w[:-1]) * (t[1:] - t[:-1]))\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.sum(0.5 * (w[..., 1:] + w[..., :-1]) * (t[..., 1:] - t[..., :-1]))\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Normalize scores\n    norm_scores = []\n    for i in range(len(scores)):\n        norm_scores.append([score / max(scores[i]) for score in scores[i]])\n\n    # Calculate weighted sum of scores\n    weighted_sum = []\n    for i in range(len(norm_scores)):\n        weighted_sum.append([norm_scores[i][j] * weights[i] for j in range(len(norm_scores[i]))])\n\n    # Calculate weighted sum of scores for each ID\n    id_weighted_sum = {}\n    for i in range(len(ids)):\n        for j in range(len(ids[i])):\n            if ids[i][j] in id_weighted_sum:\n                id_weighted_sum[ids[i][j]] += weighted_sum[i][j]\n            else:\n                id_weighted_sum[ids[i][j]] = weighted_sum[i][j]\n\n    # Sort IDs by weighted sum\n    sorted_ids = sorted(id_weighted_sum.items(), key=lambda x: x[1], reverse=True)\n\n    # Return top K IDs and their corresponding weighted sum\n    return [sorted_ids[i][0] for i in range(top_k)], [sorted_ids[i][1] for i in range(top_k)]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Calculate the weighted sum of scores for each ID\n    for i in range(len(ids)):\n        for j in range(len(ids[i])):\n            scores[i][j] *= weights[i]\n\n    # Normalize the scores\n    for i in range(len(ids)):\n        max_score = max(scores[i])\n        for j in range(len(ids[i])):\n            scores[i][j] /= max_score\n\n    # Calculate the weighted sum of scores for each ID\n    for i in range(len(ids)):\n        for j in range(len(ids[i])):\n            scores[i][j] *= weights[i]\n\n    # Calculate the weighted sum of scores for each ID\n    for i in range(len(ids)):\n        for j in range(len(ids[i])):\n            scores[i][j] *= weights[i]\n\n    # Normalize the scores\n    for i in range(len(ids)):\n        max_score = max(scores[i])\n        for j in range(len(ids[i])):\n            scores[i][j] /= max_score\n\n    # Calculate the weighted sum of scores for each ID\n    for i in range(len(ids)):\n        for j in range(len(ids[i])):\n            scores[i][j] *= weights[i]\n\n    # Normalize the scores\n    for i in range(len(ids)):\n        max_score = max(scores[i])\n        for j in range(len(ids[i])):\n            scores[i][j] /= max_score\n\n    # Calculate the weighted sum"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores) == len(weights), \"The length of ids, scores, and weights must be the same.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Calculate weighted sum of scores for each ID\n    weighted_scores = {id: 0 for id in ids[0]}\n    for i in range(len(ids)):\n        for j in range(len(ids[i])):\n            weighted_scores[ids[i][j]] += scores[i][j] * weights[i]\n\n    # Normalize weighted scores\n    for id in weighted_scores:\n        weighted_scores[id] /= sum(weights)\n\n    # Sort IDs by weighted scores\n    sorted_weighted_scores = sorted(weighted_scores.items(), key=lambda x: x[1], reverse=True)\n\n    # Return top K IDs and their corresponding weighted scores\n    return [id[0] for id in sorted_weighted_scores[:top_k]], [id[1] for id in sorted_weighted_scores[:top_k]]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Normalize the scores across all categories or groups.\n    normalized_scores = []\n    for i in range(len(scores)):\n        normalized_scores.append([score / weights[i] for score in scores[i]])\n\n    # Calculate the weighted sum of scores for each ID.\n    id_score_dict = {}\n    for i in range(len(ids[0])):\n        id_score_dict[ids[0][i]] = sum([normalized_scores[j][i] for j in range(len(ids))])\n\n    # Sort the IDs by their weighted sum in descending order.\n    sorted_ids = sorted(id_score_dict, key=id_score_dict.get, reverse=True)\n\n    # Return the top K IDs and their corresponding weighted sum.\n    return sorted_ids[:top_k], [id_score_dict[id] for id in sorted_ids[:top_k]]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Calculate weighted sum of scores for each ID\n    weighted_sum = {}\n    for i in range(len(ids)):\n        for j in range(len(ids[i])):\n            if ids[i][j] in weighted_sum:\n                weighted_sum[ids[i][j]] += scores[i][j] * weights[i]\n            else:\n                weighted_sum[ids[i][j]] = scores[i][j] * weights[i]\n\n    # Normalize scores\n    for key in weighted_sum.keys():\n        weighted_sum[key] = weighted_sum[key] / sum(weights)\n\n    # Sort by weighted sum in descending order\n    weighted_sum = dict(sorted(weighted_sum.items(), key=lambda item: item[1], reverse=True))\n\n    # Return top k IDs and their corresponding weighted sum\n    return list(weighted_sum.keys())[:top_k], list(weighted_sum.values())[:top_k]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores) == len(weights), \"The length of ids, scores, and weights must be the same.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Calculate weighted sum of scores for each ID\n    scores_df = pd.DataFrame({f'score_{i}': score_list for i, score_list in enumerate(scores)})\n    scores_df['weighted_score'] = scores_df[[f'score_{i}' for i in range(len(scores))]].multiply(weights).sum(axis=1)\n    scores_df['id'] = ids[0]\n    scores_df['weighted_score'] = scores_df['weighted_score'] / scores_df['weighted_score'].sum()\n\n    # Return top K IDs and their corresponding weighted sum\n    return scores_df.sort_values(by='weighted_score', ascending=False).head(top_k)['id'].tolist(), scores_df.sort_values(by='weighted_score', ascending=False).head(top_k)['weighted_score'].tolist()"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    # Checking for valid inputs\n    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Calculating the weighted sum of scores for each ID\n    id_dict = {}\n    for id_list, score_list, weight in zip(ids, scores, weights):\n        for id, score in zip(id_list, score_list):\n            if id not in id_dict:\n                id_dict[id] = 0\n            id_dict[id] += score * weight\n\n    # Normalizing the scores\n    min_score = min(id_dict.values())\n    max_score = max(id_dict.values())\n    for id in id_dict:\n        id_dict[id] = (id_dict[id] - min_score) / (max_score - min_score)\n\n    # Returning the top K IDs and their corresponding scores based on the weighted sum\n    return sorted(id_dict, key=id_dict.get, reverse=True)[:top_k], \\\n           [id_dict[id] for id in sorted(id_dict, key=id_dict.get, reverse=True)[:top_k]]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Normalize the scores for each category or group\n    norm_scores = []\n    for score in scores:\n        norm_scores.append([score[i] / sum(score) for i in range(len(score))])\n\n    # Weighted sum of scores for each ID\n    weighted_scores = []\n    for i in range(len(norm_scores[0])):\n        weighted_scores.append(sum([norm_scores[j][i] * weights[j] for j in range(len(norm_scores))]))\n\n    # Sort IDs by weighted sum of scores\n    sorted_weighted_scores = sorted(weighted_scores, reverse=True)\n    sorted_ids = sorted([(ids[j][i], weighted_scores[i]) for i in range(len(weighted_scores)) for j in range(len(ids))],\n                        key=lambda x: x[1], reverse=True)\n\n    # Return top K IDs and their corresponding weighted sum of scores\n    return [sorted_ids[i][0] for i in range(top_k)], [sorted_weighted_scores[i] for i in range(top_k)]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    # Check that the number of IDs, scores, and weights are the same\n    assert len(ids) == len(scores) == len(weights), \"The number of IDs, scores, and weights must be the same.\"\n\n    # Check that the weights sum to 1\n    assert round(sum(weights), 1) == 1, \"The weights must sum to 1.\"\n\n    # Check that top_k is greater than 0\n    assert top_k > 0, \"top_k must be greater than 0.\"\n\n    # Check that the number of IDs is greater than top_k\n    assert len(ids) > top_k, \"The number of IDs must be greater than top_k.\"\n\n    # Check that the number of IDs is greater than the number of categories\n    assert len(ids) >= len(weights), \"The number of IDs must be greater than or equal to the number of categories.\"\n\n    # Check that the number of IDs is greater than 1\n    assert len(ids) > 1, \"The number of IDs must be greater than 1.\"\n\n    # Check that the number of IDs is greater than 1\n    assert len(ids) > 1, \"The number of IDs must be greater than 1.\"\n\n    # Check that the number of IDs is greater than 1\n    assert len(ids) > 1, \"The number of IDs must be greater than 1.\"\n\n    # Check that the number of IDs is greater than 1\n    assert len(ids) > 1, \"The number of IDs must be greater than 1.\"\n\n    # Check that the number of IDs is greater than 1\n    assert len(ids) > 1, \"The number of IDs must be greater than 1.\"\n\n    # Check that the number of IDs is greater than 1\n    assert len(ids) > 1, \"The number of IDs must be greater than 1.\"\n\n    # Check that the number of IDs is greater than 1\n    assert len(ids) > 1, \"The number of IDs must be greater than 1.\"\n\n    # Check that the number of IDs is greater than 1\n    assert len(ids"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Normalize scores\n    normalized_scores = []\n    for score_list in scores:\n        normalized_scores.append(list(map(lambda x: x / sum(score_list), score_list)))\n\n    # Weighted sum of scores\n    weighted_sum = []\n    for i in range(len(normalized_scores[0])):\n        weighted_sum.append([ids[0][i]])\n        weighted_sum[-1].append(sum([normalized_scores[j][i] * weights[j] for j in range(len(ids))]))\n\n    # Sort weighted sum\n    weighted_sum = sorted(weighted_sum, key=lambda x: x[1], reverse=True)\n\n    # Return top k\n    return [weighted_sum[i][0] for i in range(top_k)], [weighted_sum[i][1] for i in range(top_k)]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Calculate weighted sum of scores for each ID.\n    df = pd.DataFrame({f'id_{i}': ids[i] for i in range(len(ids))})\n    df = df.assign(**{f'score_{i}': scores[i] for i in range(len(scores))})\n    df = df.assign(**{f'weighted_score_{i}': weights[i] * df[f'score_{i}'] for i in range(len(weights))})\n    df = df.assign(weighted_score=df[[f'weighted_score_{i}' for i in range(len(weights))]].sum(axis=1))\n\n    # Normalize the weighted scores.\n    df['weighted_score'] = df['weighted_score'] / df['weighted_score'].sum()\n\n    # Get the top K IDs based on the weighted scores.\n    df = df.sort_values(by='weighted_score', ascending=False)\n    df = df.head(top_k)\n\n    # Return the top K IDs and their corresponding weighted scores.\n    return df['id'].tolist(), df['weighted_score'].tolist()"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    # Assert that the length of the IDs tuple is equal to the length of the scores tuple.\n    assert len(ids) == len(scores), \"The length of the IDs tuple must be equal to the length of the scores tuple.\"\n\n    # Assert that the length of the IDs tuple is equal to the length of the weights tuple.\n    assert len(ids) == len(weights), \"The length of the IDs tuple must be equal to the length of the weights tuple.\"\n\n    # Assert that the length of the weights tuple is equal to the length of the scores tuple.\n    assert len(weights) == len(scores), \"The length of the weights tuple must be equal to the length of the scores tuple.\"\n\n    # Assert that the weights sum to 1.\n    assert round(sum(weights), 3) == 1, \"The weights must sum to 1.\"\n\n    # Assert that the top_k value is greater than 0.\n    assert top_k > 0, \"The top_k value must be greater than 0.\"\n\n    # Assert that the length of the IDs tuple is greater than 1.\n    assert len(ids) > 1, \"The length of the IDs tuple must be greater than 1.\"\n\n    # Calculate the weighted sum of scores for each ID.\n    df = pd.DataFrame()\n    for i in range(len(ids)):\n        df[f'id_{i}'] = ids[i]\n        df[f'score_{i}'] = scores[i]\n        df[f'weighted_score_{i}'] = df[f'score_{i}'] * weights[i]\n\n    # Normalize the weighted scores.\n    df['weighted_score'] = df[[f'weighted_score_{i}' for i in range(len(ids))]].sum(axis=1)\n    df['weighted_score'] = df['weighted_score'] / df['weighted_score'].max()\n\n    # Sort the IDs by their weighted scores in descending order.\n    df = df.sort_values(by=['weighted_score'], ascending=False)\n\n    # Return the top"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    # Check that the length of the ids, scores, and weights tuples match\n    assert len(ids) == len(scores) == len(weights), \"The lengths of the 'ids', 'scores', and 'weights' tuples do not match.\"\n\n    # Check that the weights sum to 1\n    assert round(sum(weights), 3) == 1, \"The weights do not sum to 1.\"\n\n    # Check that the top_k is greater than 0\n    assert top_k > 0, \"The 'top_k' value must be greater than 0.\"\n\n    # Check that the top_k is less than the number of IDs in each category\n    for id_list in ids:\n        assert top_k < len(id_list), \"The 'top_k' value must be less than the number of IDs in each category.\"\n\n    # Calculate the weighted sum of scores for each ID\n    weighted_sums = {}\n    for i in range(len(ids)):\n        for j in range(len(ids[i])):\n            if ids[i][j] in weighted_sums:\n                weighted_sums[ids[i][j]] += scores[i][j] * weights[i]\n            else:\n                weighted_sums[ids[i][j]] = scores[i][j] * weights[i]\n\n    # Sort the weighted sums in descending order\n    sorted_weighted_sums = sorted(weighted_sums.items(), key=lambda x: x[1], reverse=True)\n\n    # Return the top K IDs and their corresponding weighted sums\n    return [sorted_weighted_sums[i][0] for i in range(top_k)], [sorted_weighted_sums[i][1] for i in range(top_k)]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Normalize scores\n    scores_normalized = []\n    for score_list in scores:\n        score_list_normalized = [score / sum(score_list) for score in score_list]\n        scores_normalized.append(score_list_normalized)\n\n    # Calculate weighted sum of scores\n    weighted_sum = []\n    for i in range(len(scores[0])):\n        weighted_sum_list = []\n        for j in range(len(scores)):\n            weighted_sum_list.append(scores_normalized[j][i] * weights[j])\n        weighted_sum.append(weighted_sum_list)\n\n    # Sort IDs and weighted sum based on weighted sum\n    weighted_sum_sorted = sorted(weighted_sum, key=lambda x: x[0], reverse=True)\n    ids_sorted = []\n    for i in range(len(ids)):\n        ids_sorted.append([ids[i][j] for j in range(len(ids[i]))])\n\n    weighted_sum_sorted_ids = []\n    for i in range(len(weighted_sum_sorted)):\n        weighted_sum_sorted_ids.append([weighted_sum_sorted[i][j] for j in range(len(weighted_sum_sorted[i]))])\n\n    # Get top K IDs and weighted sum\n    ids_top_k = []\n    weighted_sum_top_k = []\n    for i in range(top_k):\n        ids_top_k.append(weighted_sum_sorted"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    # Normalize the scores\n    normalized_scores = []\n    for score_list in scores:\n        min_score = min(score_list)\n        max_score = max(score_list)\n        if max_score - min_score > 0:\n            normalized_scores.append([(score - min_score) / (max_score - min_score) for score in score_list])\n        else:\n            normalized_scores.append([1 for _ in range(len(score_list))])\n\n    # Calculate the weighted sum of scores for each ID\n    id_scores = []\n    for i in range(len(ids[0])):\n        id_scores.append(sum([normalized_scores[j][i] * weights[j] for j in range(len(ids))]))\n\n    # Sort IDs by weighted sum\n    sorted_ids = sorted(list(zip(ids[0], id_scores)), key=lambda x: x[1], reverse=True)\n\n    # Return the top K IDs and their corresponding scores\n    return [sorted_ids[i][0] for i in range(top_k)], [sorted_ids[i][1] for i in range(top_k)]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    # Check if the number of IDs and scores are the same\n    assert len(ids) == len(scores), \"The number of IDs and scores must be the same.\"\n    # Check if the number of weights is the same as the number of IDs and scores\n    assert len(weights) == len(ids), \"The number of weights must be the same as the number of IDs and scores.\"\n    # Check if the weights sum to 1\n    assert round(sum(weights), 4) == 1, \"The weights must sum to 1.\"\n\n    # Convert the tuples to dataframes\n    ids_df = pd.DataFrame({f'id_{i}': id_list for i, id_list in enumerate(ids)})\n    scores_df = pd.DataFrame({f'score_{i}': score_list for i, score_list in enumerate(scores)})\n    # Merge the two dataframes\n    df = pd.concat([ids_df, scores_df], axis=1)\n\n    # Calculate the weighted sum of scores for each ID\n    df['weighted_score'] = df.apply(lambda x: sum([x[f'score_{i}'] * weights[i] for i in range(len(ids))]), axis=1)\n    # Normalize the weighted scores\n    df['weighted_score'] = df['weighted_score'] / df['weighted_score'].sum()\n    # Sort the IDs by their weighted scores in descending order\n    df.sort_values(by=['weighted_score'], ascending=False, inplace=True)\n    # Return the top K IDs and their corresponding weighted scores\n    return df['id_0'].tolist()[:top_k], df['weighted_score'].tolist()[:top_k]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    # Check that the number of IDs and scores are the same\n    assert len(ids) == len(scores), \"The number of IDs and scores must be the same.\"\n    # Check that the number of weights is the same as the number of IDs\n    assert len(weights) == len(ids), \"The number of weights must be the same as the number of IDs.\"\n    # Check that the weights sum to 1\n    assert round(sum(weights), 1) == 1, \"The weights must sum to 1.\"\n\n    # Convert the tuple of lists of IDs and scores into a DataFrame\n    df = pd.DataFrame({f'id_{i}': id_list for i, id_list in enumerate(ids)})\n    df[['score_' + str(i) for i in range(len(scores))]] = pd.DataFrame({f'score_{i}': score_list for i, score_list in enumerate(scores)})\n\n    # Apply the weights to the scores\n    for i in range(len(scores)):\n        df['score_' + str(i)] = df['score_' + str(i)] * weights[i]\n\n    # Sum the weighted scores for each ID\n    df['score_sum'] = df[[f'score_{i}' for i in range(len(scores))]].sum(axis=1)\n\n    # Normalize the weighted scores\n    df['score_sum'] = df['score_sum'] / df['score_sum'].max()\n\n    # Sort the IDs by the weighted scores\n    df = df.sort_values(by=['score_sum'], ascending=False).reset_index(drop=True)\n\n    # Return the top K IDs and their corresponding weighted scores\n    return df['id_0'].head(top_k).tolist(), df['score_sum'].head(top_k).tolist()"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    # Check that the length of the tuples are equal\n    assert len(ids) == len(scores) == len(weights), \"The length of the 'ids', 'scores', and 'weights' tuples must be equal.\"\n\n    # Check that the weights sum to 1\n    assert round(sum(weights), 2) == 1, \"The weights must sum to 1.\"\n\n    # Check that the top_k is positive\n    assert top_k > 0, \"The 'top_k' value must be greater than 0.\"\n\n    # Check that the length of each list in the 'ids' tuple is equal\n    for i in range(len(ids)):\n        assert len(ids[0]) == len(ids[i]), \"The length of each list within the 'ids' tuple must be equal.\"\n\n    # Check that the length of each list in the 'scores' tuple is equal\n    for i in range(len(scores)):\n        assert len(scores[0]) == len(scores[i]), \"The length of each list within the 'scores' tuple must be equal.\"\n\n    # Check that the length of the 'weights' tuple is equal to the length of the 'ids' tuple\n    assert len(weights) == len(ids), \"The length of the 'weights' tuple must be equal to the length of the 'ids' tuple.\"\n\n    # Apply weights to the scores\n    weighted_scores = []\n    for i in range(len(scores)):\n        weighted_scores.append([scores[i][j] * weights[i] for j in range(len(scores[i]))])\n\n    # Calculate the weighted sum of the scores for each ID\n    weighted_sums = []\n    for i in range(len(weighted_scores[0])):\n        weighted_sums.append(sum([weighted_scores[j][i] for j in range(len(weighted_scores))]))\n\n    # Sort the IDs and weighted sums based on the weighted sum\n    sorted_sums_ids = sorted(zip(weighted_"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    # Check that the lengths of the ids, scores, and weights tuples are all the same\n    assert len(ids) == len(scores) == len(weights), \"The lengths of the IDs, scores, and weights tuples are not the same.\"\n\n    # Check that the weights sum to 1\n    assert sum(weights) == 1, \"The weights do not sum to 1.\"\n\n    # Check that top_k is greater than 0\n    assert top_k > 0, \"top_k must be greater than 0.\"\n\n    # Check that the length of the ids and scores tuples are greater than 1\n    assert len(ids) > 1, \"There must be more than one set of IDs and scores.\"\n\n    # Create a dictionary to store the weighted sum of each ID's scores\n    weighted_sum_dict = {}\n\n    # Iterate over each set of IDs and scores\n    for id_list, score_list, weight in zip(ids, scores, weights):\n\n        # Iterate over each ID and score\n        for id, score in zip(id_list, score_list):\n\n            # If the ID is already in the dictionary, add the weighted score to the existing value\n            if id in weighted_sum_dict:\n                weighted_sum_dict[id] += weight * score\n\n            # Otherwise, add the ID to the dictionary and set the weighted score as the value\n            else:\n                weighted_sum_dict[id] = weight * score\n\n    # Convert the dictionary to a list of tuples\n    weighted_sum_list = list(weighted_sum_dict.items())\n\n    # Sort the list of tuples in descending order by the weighted score\n    weighted_sum_list.sort(key=lambda x: x[1], reverse=True)\n\n    # Return the top k IDs and their corresponding weighted scores\n    return [x[0] for x in weighted_sum_list[:top_k]], [x[1] for x in weighted_sum_list[:top_k]]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    # Check that the lengths of the ids, scores, and weights tuples are the same\n    assert len(ids) == len(scores) == len(weights), \"The length of ids, scores, and weights must be the same.\"\n    # Check that the weights sum to 1\n    assert round(sum(weights), 1) == 1.0, \"The weights must sum to 1.\"\n\n    # Check that the lengths of each list in the ids and scores tuples are the same\n    for id_list, score_list in zip(ids, scores):\n        assert len(id_list) == len(score_list), \"The length of the ids and scores lists must be the same.\"\n\n    # Create a list of tuples with the ids, scores, and weighted scores\n    id_score_weight_tuples = []\n    for id_list, score_list in zip(ids, scores):\n        id_score_weight_tuples.extend(list(zip(id_list, score_list, [score * weight for score in score_list])))\n\n    # Sort the list of tuples by the weighted scores\n    sorted_id_score_weight_tuples = sorted(id_score_weight_tuples, key=lambda x: x[2], reverse=True)\n\n    # Extract the top K ids and their weighted scores\n    top_k_ids = [x[0] for x in sorted_id_score_weight_tuples[:top_k]]\n    top_k_weighted_scores = [x[2] for x in sorted_id_score_weight_tuples[:top_k]]\n\n    return top_k_ids, top_k_weighted_scores"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function at the mean\n  jac = jax.jacfwd(fn)(mean)\n\n  # Compute the covariance of the function at the mean\n  cov_mean = jnp.einsum('...i,...ij,...j->...ij', jac, cov, jac)\n\n  # Compute the transformed means and covariances\n  fn_mean = fn(mean)\n  fn_cov = cov_mean\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # The linearization of the function is given by the Jacobian matrix.\n  jac = jax.jacobian(fn)(mean)\n\n  # The covariance is transformed using the Jacobian matrix.\n  fn_cov = jnp.einsum('...ij,...jk,...lk->...il', jac, cov, jac, optimize='optimal')\n\n  # The mean is transformed using the Jacobian matrix.\n  fn_mean = fn(mean)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # fn_mean: Tensor. A tensor of transformed means, where the last axis represents the dimension of the means.\n  fn_mean = fn(mean)\n\n  # jacobian: Tensor. A tensor of Jacobians, where the last two axes represent the dimensions of the Jacobians.\n  jacobian = jax.jacfwd(fn)(mean)\n\n  # fn_cov: Tensor. A tensor of transformed covariances, where the last two axes represent the dimensions of the covariances.\n  fn_cov = jnp.einsum('...ij,...jk->...ik', jacobian, cov)\n  fn_cov = jnp.einsum('...ij,...jk->...ik', jacobian, fn_cov)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function at the mean.\n  jacobian = jax.jacfwd(fn)(mean)\n\n  # Compute the transformed means.\n  fn_mean = fn(mean)\n\n  # Compute the transformed covariances.\n  fn_cov = jnp.einsum('...ij,...jk,...lk->...il', jacobian, cov, jacobian)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian\n  jac = jax.jacobian(fn)(mean)\n\n  # Compute the covariance of the Jacobian\n  jac_cov = jnp.einsum('...ij,...ik->...jk', jac, jac)\n\n  # Compute the transformed mean\n  fn_mean = fn(mean)\n\n  # Compute the transformed covariance\n  fn_cov = jnp.einsum('...ij,...jk->...ik', jac, jnp.einsum('...ij,...jk->...ik', jac_cov, jac)) + jnp.einsum('...ij,...ik->...jk', jac, jnp.einsum('...ij,...jk->...ik', cov, jac))\n\n  # Return the transformed mean and covariance\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function around the mean\n  jacobian = jax.jacfwd(fn)(mean)\n\n  # Compute the covariances of the function around the mean\n  cov_fn = jnp.einsum('...ij,...jk->...ik', jacobian, cov)\n  cov_fn = jnp.einsum('...ij,...jk->...ik', cov_fn, jacobian)\n\n  # Compute the means of the function around the mean\n  mean_fn = fn(mean)\n\n  return mean_fn, cov_fn\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Get the number of dimensions of the mean and covariance.\n  dim = mean.shape[-1]\n\n  # Compute the Jacobian of the function around the mean.\n  jacobian = jax.jacfwd(fn)(mean)\n\n  # Compute the Jacobian of the function around the mean.\n  jacobian = jnp.expand_dims(jacobian, axis=-1)\n\n  # Compute the Jacobian of the function around the mean.\n  jacobian = jnp.tile(jacobian, (1, 1, dim))\n\n  # Compute the Jacobian of the function around the mean.\n  jacobian = jnp.transpose(jacobian, axes=(0, 2, 1, 3))\n\n  # Compute the Jacobian of the function around the mean.\n  jacobian = jnp.reshape(jacobian, (-1, dim, dim))\n\n  # Compute the Jacobian of the function around the mean.\n  jacobian_t = jnp.transpose(jacobian, axes=(0, 2, 1))\n\n  # Compute the Jacobian of the function around the mean.\n  jacobian_prod = jnp.matmul(jacobian, jacobian_t)\n\n  # Compute the Jacobian of the function around the mean.\n  jacobian_prod = jnp.expand_dims(jacobian_prod, axis=0)\n\n  # Compute the Jacobian of the function around the mean.\n  jacobian_prod = jnp.tile(jacobian_prod, (cov.shape[0], 1, 1, 1))\n\n  # Compute the Jacobian of the function around the mean.\n  jacobian_prod = jnp.reshape(jacobian_prod, (-1, dim, dim))\n\n  # Compute the Jacobian of the function around the mean.\n  jacobian_prod = jnp.expand_dims(jacob"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function at the given mean\n  jacobian = jax.jacfwd(fn)(mean)\n\n  # Compute the covariance of the function at the given mean\n  cov_fn = jnp.einsum('...ij,...jk->...ik', jacobian, cov)\n\n  # Apply the function to the mean\n  fn_mean = fn(mean)\n\n  return fn_mean, cov_fn\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function at the mean.\n  jac = jax.jacfwd(fn)(mean)\n\n  # Compute the covariance of the function's output.\n  fn_cov = jnp.einsum('...ij,...jk,...lk->...il', jac, cov, jac, optimize='optimal')\n\n  # Compute the mean of the function's output.\n  fn_mean = fn(mean)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Get the dimensions of the mean and covariance\n  dim = mean.shape[-1]\n  # Get the Jacobian matrix of the function around the mean\n  jacobian = jax.jacfwd(fn)(mean)\n  # Get the covariance matrix of the function around the mean\n  cov_mat = jnp.tile(cov, [1, 1, dim, 1])\n  jacobian_mat = jnp.tile(jacobian, [1, 1, 1, dim])\n  fn_cov = jnp.matmul(jnp.matmul(jacobian_mat, cov_mat), jnp.transpose(jacobian_mat, [0, 1, 3, 2]))\n  # Get the mean of the function around the mean\n  fn_mean = fn(mean)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function at the mean\n  jacobian = jax.jacfwd(fn)(mean)\n\n  # Compute the linearized function\n  fn_mean = fn(mean)\n\n  # Compute the linearized covariance\n  fn_cov = jnp.einsum(\"...ij,...jk,...lk->...il\", jacobian, cov, jacobian)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Linearize the function around the mean.\n  fn_mean = fn(mean)\n\n  # Compute the Jacobian of the function.\n  jacobian = jax.jacobian(fn)(mean)\n\n  # Transform the covariances according to the Jacobian.\n  fn_cov = jnp.einsum('...ij,...jk,...lk->...il', jacobian, cov, jacobian)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function at the mean.\n  jacobian = jax.jacfwd(fn)(mean)\n\n  # Compute the covariance of the function at the mean.\n  cov_mean = jnp.einsum('...ij,...kj->...ik', jacobian, cov)\n\n  # Apply the function to the mean.\n  fn_mean = fn(mean)\n\n  # Compute the covariance of the function.\n  fn_cov = jnp.einsum('...ij,...kj->...ik', jacobian, cov_mean)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # The linearized function is fn(x) = fn(mean) + dfn/dx(mean)*(x - mean).\n  fn_mean = fn(mean)\n  dfn_dx = jax.jacobian(fn)(mean)\n  fn_cov = jnp.einsum('...i,...ij,...j->...ij', dfn_dx, cov, dfn_dx)\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Linearize the function around the mean\n  fn_mean = fn(mean)\n\n  # Compute the Jacobian of the function at the mean\n  jacobian = jax.jacfwd(fn)(mean)\n\n  # Transform the covariances using the Jacobian\n  fn_cov = jnp.einsum('...ij,...jk,...lk', jacobian, cov, jacobian)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function at the mean\n  jacobian = jax.jacfwd(fn)(mean)\n  jacobian_t = jnp.swapaxes(jacobian, -1, -2)\n\n  # Compute the covariance of the function at the mean\n  cov_mean = jnp.matmul(jacobian, jnp.matmul(cov, jacobian_t))\n\n  # Compute the transformed means and covariances\n  fn_mean = fn(mean)\n  fn_cov = cov_mean + jnp.matmul(jacobian, jnp.matmul(cov, jacobian_t))\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # The linearization of the function around the mean is given by:\n  # fn_mean = fn(mean)\n  # fn_cov = J(mean)^T cov J(mean)\n  # where J(mean) is the Jacobian of the function around the mean.\n\n  # The Jacobian of the function around the mean is given by:\n  # J(mean) = [dfn/dx_1(mean), dfn/dx_2(mean), ..., dfn/dx_n(mean)]\n  # where n is the dimension of the means.\n\n  # The Jacobian is computed using automatic differentiation.\n  jacobian = jax.jacobian(fn)(mean)\n\n  # The covariance is transformed using the Jacobian.\n  fn_cov = jnp.einsum(\n      '...i,...ij,...j->...ij', jacobian, cov, jacobian, optimize='optimal')\n\n  # The means are transformed using the Jacobian.\n  fn_mean = jnp.einsum('...i,...i->...i', jacobian, mean)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function at the given mean\n  jacobian = jax.jacfwd(fn)(mean)\n\n  # Compute the covariance of the function's output\n  fn_cov = jnp.einsum(\"...ij,...jk->...ik\", jacobian, cov)\n  fn_cov = jnp.einsum(\"...ij,...kj->...ik\", jacobian, fn_cov)\n\n  # Compute the mean of the function's output\n  fn_mean = fn(mean)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function around the mean\n  jacobian = jax.jacfwd(fn)(mean)\n\n  # Compute the transformed means\n  fn_mean = fn(mean)\n\n  # Compute the transformed covariances\n  fn_cov = jnp.einsum(\n    '...ij,...jk,...lk->...il', jacobian, cov, jacobian, optimize='optimal')\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian matrix\n  jacobian = jax.jacfwd(fn)(mean)\n\n  # Compute the covariance of the function's output\n  fn_cov = jnp.einsum('...ij,...jk->...ik', jacobian, jnp.einsum('...ij,...jk->...ik', cov, jacobian.transpose((0, 2, 1))))\n\n  # Compute the mean of the function's output\n  fn_mean = fn(mean)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if len(arr) > 1:\n            yield [arr[: len(arr) // 2], arr[len(arr) // 2 :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in x:\n        if i.size > 1:\n            yield [i[: len(i) // 2], i[len(i) // 2 :]]\n        else:\n            yield [i]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in x:\n        if i.size > 1:\n            yield i[: len(i) // 2], i[len(i) // 2 :]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if len(arr) > 1:\n            yield [arr[: len(arr) // 2], arr[len(arr) // 2 :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in x:\n        if i.size > 1:\n            yield i[: len(i) // 2], i[len(i) // 2 :]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for array in x:\n        if array.size > 1:\n            yield [array[:len(array)//2], array[len(array)//2:]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    # Check if the input is a list of numpy arrays.\n    if not isinstance(x, list):\n        raise TypeError(\"The input must be a list of numpy arrays.\")\n    # Check if the input list contains numpy arrays.\n    if not all(isinstance(array, np.ndarray) for array in x):\n        raise TypeError(\"The input must be a list of numpy arrays.\")\n\n    # Iterate through the input list.\n    for array in x:\n        # Check if the array has more than one element.\n        if array.size > 1:\n            # If the array has more than one element, bisect it.\n            yield array[: len(array) // 2], array[len(array) // 2 :]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in x:\n        if len(i) > 1:\n            yield [i[:len(i)//2], i[len(i)//2:]]\n        else:\n            yield [i]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    # Iterate through the list of arrays\n    for i in x:\n        # If the array has more than one element\n        if len(i) > 1:\n            # Bisect the array into two halves\n            # The first half is the first half of the array\n            # The second half is the second half of the array\n            yield [i[:len(i) // 2], i[len(i) // 2:]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in range(len(x)):\n        if len(x[i]) > 1:\n            yield [x[i][: len(x[i]) // 2], x[i][len(x[i]) // 2 :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in range(len(x)):\n        if len(x[i]) > 1:\n            yield x[i][: len(x[i]) // 2], x[i][len(x[i]) // 2 :]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in x:\n        if len(i) > 1:\n            yield [i[: len(i) // 2], i[len(i) // 2 :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for array in x:\n        if len(array) > 1:\n            yield [array[: len(array) // 2], array[len(array) // 2 :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    # Iterate through the list of arrays\n    for array in x:\n        # If the array has more than one element\n        if array.size > 1:\n            # Bisect the array\n            yield [array[:len(array) // 2], array[len(array) // 2:]]\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in x:\n        if len(i) > 1:\n            yield [i[: len(i) // 2], i[len(i) // 2 :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for array in x:\n        if len(array) > 1:\n            yield [array[:len(array) // 2], array[len(array) // 2:]]\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for array in x:\n        if len(array) > 1:\n            midpoint = int(len(array) / 2)\n            yield [array[:midpoint], array[midpoint:]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in x:\n        if i.size > 1:\n            yield [i[:i.size // 2], i[i.size // 2 :]]\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in x:\n        if len(i) > 1:\n            yield [i[: len(i) // 2], i[len(i) // 2 :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for array in x:\n        if len(array) > 1:\n            yield [array[: len(array) // 2], array[len(array) // 2 :]]\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\n            \"The matrix is not square. Please provide a square matrix.\"\n        )\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix is not square\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The input matrix is not square.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix is not square.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"Matrix must be square\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix is not square.\")\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix is not square.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(f\"The matrix is not square. The matrix shape is {x.shape}\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(f\"The matrix should be square, but the shape is {x.shape}.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix is not square.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(f\"Matrix is not square. Shape: {x.shape}\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if not (x.shape[0] == x.shape[1]):\n        raise ValueError(\n            \"The matrix is not square. Please provide a square matrix.\"\n        )\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if not (x.shape[0] == x.shape[1]):\n        raise ValueError(\"The matrix must be square\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix is not square.\")\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix is not square.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"Matrix must be square.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix is not square.\")\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded_x = jnp.concatenate([jnp.sin(scaled_x), jnp.cos(scaled_x)], axis=-1)\n  if append_identity:\n    encoded_x = jnp.concatenate([x, encoded_x], axis=-1)\n  return encoded_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded_x = jnp.concatenate([jnp.sin(scaled_x), jnp.cos(scaled_x)], axis=-1)\n  if append_identity:\n    encoded_x = jnp.concatenate([x, encoded_x], axis=-1)\n  return encoded_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded_x = jnp.concatenate([jnp.sin(scaled_x), jnp.cos(scaled_x)], axis=-1)\n  if append_identity:\n    encoded_x = jnp.concatenate([x, encoded_x], axis=-1)\n  return encoded_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n\n  sin_x = jnp.sin(scaled_x)\n  cos_x = jnp.cos(scaled_x)\n\n  if append_identity:\n    return jnp.concatenate([x, sin_x, cos_x], axis=-1)\n  else:\n    return jnp.concatenate([sin_x, cos_x], axis=-1)\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded_x = jnp.concatenate([jnp.sin(scaled_x), jnp.cos(scaled_x)], axis=-1)\n\n  if append_identity:\n    encoded_x = jnp.concatenate([encoded_x, x], axis=-1)\n\n  return encoded_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded_x = jnp.concatenate([jnp.sin(scaled_x), jnp.cos(scaled_x)], axis=-1)\n\n  if append_identity:\n    encoded_x = jnp.concatenate([encoded_x, x], axis=-1)\n\n  return encoded_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n\n  return jnp.concatenate([\n      jnp.sin(scaled_x),\n      jnp.cos(scaled_x),\n      x,\n  ], axis=-1) if append_identity else jnp.concatenate([\n      jnp.sin(scaled_x),\n      jnp.cos(scaled_x),\n  ], axis=-1)\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n\n  encoded = jnp.concatenate([\n      jnp.sin(scaled_x),\n      jnp.cos(scaled_x),\n      jnp.ones_like(scaled_x)\n  ], axis=-1)\n\n  if append_identity:\n    encoded = jnp.concatenate([encoded, x], axis=-1)\n\n  return encoded\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded_x = jnp.concatenate([jnp.sin(scaled_x), jnp.cos(scaled_x)], axis=-1)\n  if append_identity:\n    encoded_x = jnp.concatenate([encoded_x, x], axis=-1)\n  return encoded_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  scaled_x = jnp.concatenate([scaled_x, scaled_x + 0.5 * jnp.pi], axis=-1)\n  encoded_x = jnp.concatenate([jnp.sin(scaled_x), jnp.cos(scaled_x)], axis=-1)\n\n  if append_identity:\n    encoded_x = jnp.concatenate([x, encoded_x], axis=-1)\n\n  return encoded_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded = jnp.concatenate([jnp.sin(scaled_x), jnp.cos(scaled_x)], axis=-1)\n\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n\n  return encoded\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded_x = jnp.concatenate([jnp.sin(scaled_x), jnp.cos(scaled_x)], axis=-1)\n  if append_identity:\n    encoded_x = jnp.concatenate([x, encoded_x], axis=-1)\n  return encoded_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n\n  pos_enc = jnp.concatenate([jnp.sin(scaled_x), jnp.cos(scaled_x)], axis=-1)\n\n  if append_identity:\n    pos_enc = jnp.concatenate([x, pos_enc], axis=-1)\n\n  return pos_enc\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded_x = jnp.concatenate([jnp.sin(scaled_x), jnp.cos(scaled_x)], axis=-1)\n\n  if append_identity:\n    encoded_x = jnp.concatenate([x, encoded_x], axis=-1)\n\n  return encoded_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded_x = jnp.concatenate([jnp.sin(scaled_x), jnp.cos(scaled_x)], axis=-1)\n\n  if append_identity:\n    encoded_x = jnp.concatenate([x, encoded_x], axis=-1)\n\n  return encoded_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded_x = jnp.concatenate([jnp.sin(scaled_x), jnp.cos(scaled_x)], axis=-1)\n\n  if append_identity:\n    encoded_x = jnp.concatenate([x, encoded_x], axis=-1)\n\n  return encoded_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded = jnp.concatenate([jnp.sin(scaled_x), jnp.cos(scaled_x)], axis=-1)\n  if append_identity:\n    encoded = jnp.concatenate([encoded, x], axis=-1)\n  return encoded\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded_x = jnp.concatenate([jnp.sin(scaled_x), jnp.cos(scaled_x)], axis=-1)\n  if append_identity:\n    encoded_x = jnp.concatenate([encoded_x, x], axis=-1)\n  return encoded_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded_x = jnp.concatenate([jnp.sin(scaled_x), jnp.cos(scaled_x)], axis=-1)\n\n  if append_identity:\n    encoded_x = jnp.concatenate([encoded_x, x], axis=-1)\n\n  return encoded_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded_x = jnp.concatenate([jnp.sin(scaled_x), jnp.cos(scaled_x)], axis=-1)\n  if append_identity:\n    encoded_x = jnp.concatenate([x, encoded_x], axis=-1)\n  return encoded_x\n\n"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                             f\"resp. {len(values[field1])} and {len(values[field2])}\")\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                                 f\"resp. {values[field1][i].shape} and {values[field2][i].shape}\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                             f\"resp. {len(values[field1])} and {len(values[field2])}\")\n        for arr1, arr2 in zip(values[field1], values[field2]):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                             f\"resp. {len(values[field1])} and {len(values[field2])}\")\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                                 f\"resp. {values[field1][i].shape} and {values[field2][i].shape}\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                             f\"resp. {len(values[field1])} and {len(values[field2])}\")\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch at index {i}\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                             f\"resp. {len(values[field1])} and {len(values[field2])}\")\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch at index {i}, \"\n                                 f\"resp. {values[field1][i].shape} and {values[field2][i].shape}\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                             f\"resp. {len(values[field1])} and {len(values[field2])}\")\n        for array1, array2 in zip(values[field1], values[field2]):\n            if array1.shape != array2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                                 f\"resp. {array1.shape} and {array2.shape}\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                             f\"resp. {len(values[field1])} and {len(values[field2])}\")\n        for array1, array2 in zip(values[field1], values[field2]):\n            if array1.shape != array2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if field1 and field2 have the same length and if each corresponding pair of arrays within these lists has the same shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                             f\"resp. {len(values[field1])} and {len(values[field2])}\")\n        for arr1, arr2 in zip(values[field1], values[field2]):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                                 f\"resp. {arr1.shape} and {arr2.shape}\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                             f\"resp. {len(values[field1])} and {len(values[field2])}\")\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch at index {i}.\")\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                             f\"resp. {len(values[field1])} and {len(values[field2])}\")\n        for array1, array2 in zip(values[field1], values[field2]):\n            if array1.shape != array2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"\n        This function checks if two lists of numpy arrays have the same length and if each corresponding pair of arrays has the same shape.\n\n        Input-Output Arguments\n        :param cls: type. The class type.\n        :param values: Dict[str, List[np.ndarray]]. A dictionary of values.\n        :return: Dict[str, List[np.ndarray]]. The validated values.\n\n        \"\"\"\n\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                             f\"resp. {len(values[field1])} and {len(values[field2])}\")\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                                 f\"resp. {values[field1][i].shape} and {values[field2][i].shape}\")\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                             f\"resp. {len(values[field1])} and {len(values[field2])}\")\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch at index {i}.\")\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n\n        \"\"\"\n        This function checks if two lists of numpy arrays (specified by field names) have the same length and if each corresponding pair of arrays within these lists has the same shape.\n\n        Input-Output Arguments\n        :param cls: type. The class type.\n        :param values: Dict[str, np.ndarray]. A dictionary of values.\n        :return: Dict[str, np.ndarray]. The validated values.\n        \"\"\"\n\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                             f\"resp. {len(values[field1])} and {len(values[field2])}\")\n\n        for array1, array2 in zip(values[field1], values[field2]):\n            if array1.shape != array2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                             f\"resp. {len(values[field1])} and {len(values[field2])}\")\n\n        for array1, array2 in zip(values[field1], values[field2]):\n            if array1.shape != array2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n\n        \"\"\"\n        This function checks if two lists of numpy arrays (specified by field names) have the same length and if each corresponding pair of arrays within these lists has the same shape.\n\n        Input-Output Arguments:\n        :param cls: Class type. The class to be validated.\n        :param values: Dict[str, List[np.ndarray]]. A dictionary of values to be validated.\n        :return: Dict[str, List[np.ndarray]]. The validated values.\n\n        \"\"\"\n\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                             f\"resp. {len(values[field1])} and {len(values[field2])}\")\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                                 f\"resp. {values[field1][i].shape} and {values[field2][i].shape}\")\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n\n        \"\"\"\n        This function checks if two lists of numpy arrays have the same length and if each corresponding pair of arrays has the same shape.\n\n        Input-Output Arguments\n        :param cls: type. The class type to be validated.\n        :param values: Dict[str, List[np.ndarray]]. A dictionary of values to be validated. It must contain two fields with the names specified by field1 and field2.\n        :return: Dict[str, List[np.ndarray]]. The validated values.\n\n        \"\"\"\n\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                             f\"resp. {len(values[field1])} and {len(values[field2])}\")\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch at index {i}.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if field1 and field2 have the same length and if each corresponding pair of arrays within these lists has the same shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                             f\"resp. {len(values[field1])} and {len(values[field2])}\")\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch at index {i}.\")\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"\n        This function checks if two lists of numpy arrays (specified by field names) have the same length and if each corresponding pair of arrays within these lists has the same shape.\n\n        Input-Output Arguments:\n        :param cls: type. The class type.\n        :param values: Dict[str, List[np.ndarray]]. A dictionary of values.\n        :return: Dict[str, List[np.ndarray]]. The validated values.\n        \"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                             f\"resp. {len(values[field1])} and {len(values[field2])}\")\n\n        for array1, array2 in zip(values[field1], values[field2]):\n            if array1.shape != array2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                                 f\"resp. {array1.shape} and {array2.shape}\")\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"\n        This function checks if two lists of numpy arrays (specified by field names) have the same length and if each corresponding pair of arrays within these lists has the same shape.\n\n        Input-Output Arguments\n        :param cls: type. The class type.\n        :param values: Dict[str, List[np.ndarray]]. A dictionary of values to be validated. It contains two keys, each one corresponding to one of the two lists of numpy arrays to be validated for shape equality.\n        :return: Dict[str, List[np.ndarray]]. The validated values.\n\n        \"\"\"\n\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                             f\"resp. {len(values[field1])} and {len(values[field2])}\")\n\n        for arr1, arr2 in zip(values[field1], values[field2]):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n\n        \"\"\"\n        This function checks if two lists of numpy arrays (specified by field names) have the same length and if each corresponding pair of arrays within these lists has the same shape.\n\n        Input-Output Arguments\n        :param cls: type. The class type.\n        :param values: Dict[str, List[np.ndarray]]. A dictionary of values.\n        :return: Dict[str, List[np.ndarray]]. The validated values.\n        \"\"\"\n\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, resp. {len(values[field1])} and {len(values[field2])}\")\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch, resp. {values[field1][i].shape} and {values[field2][i].shape}\")\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context\n        eglctx.resize(camera.width, camera.height)\n\n        # Clear the color and depth buffers\n        gl.glClear(gl.GL_COLOR_BUFFER_BIT | gl.GL_DEPTH_BUFFER_BIT)\n\n        # Set the OpenGL state\n        gl.glEnable(gl.GL_DEPTH_TEST)\n        gl.glDisable(gl.GL_CULL_FACE)\n        gl.glEnable(gl.GL_BLEND)\n        gl.glBlendFunc(gl.GL_SRC_ALPHA, gl.GL_ONE_MINUS_SRC_ALPHA)\n\n        # Set the projection and view matrices\n        gl.glUniformMatrix4fv(self.uniforms.proj_matrix, 1, gl.GL_FALSE, camera.proj_matrix)\n        gl.glUniformMatrix4fv(self.uniforms.view_matrix, 1, gl.GL_FALSE, camera.view_matrix)\n\n        # Set the vertex data\n        gl.glBindBuffer(gl.GL_ARRAY_BUFFER, self.vbo)\n        gl.glVertexAttribPointer(0, 3, gl.GL_FLOAT, gl.GL_FALSE, 0, ctypes.c_void_p(0))\n        gl.glEnableVertexAttribArray(0)\n\n        # Set the normal data\n        gl.glBindBuffer(gl.GL_ARRAY_BUFFER, self.nbo)\n        gl.glVertexAttribPointer(1, 3, gl.GL_FLOAT, gl.GL_FALSE, 0, ctypes.c_void_p(0))\n        gl.glEnableVertexAttribArray(1)\n\n        # Set the color data\n        gl.glBindBuffer(gl.GL_ARRAY_BUFFER, self.cbo)\n        gl.glVertexAttribPointer(2, 3, gl.GL_FLOAT, gl.GL_FALSE, 0, ctypes.c_void_p(0))\n        gl.glEnableVertexAtt"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context\n        eglctx.set_dims(*camera.size)\n\n        # Update the uniforms\n        self.uniforms.model_matrix = camera.model_matrix\n        self.uniforms.view_matrix = camera.view_matrix\n        self.uniforms.proj_matrix = camera.proj_matrix\n        self.uniforms.cam_pos = camera.position\n        self.uniforms.light_pos = camera.position\n        self.uniforms.light_color = camera.light_color\n        self.uniforms.ambient_color = camera.ambient_color\n        self.uniforms.diffuse_color = camera.diffuse_color\n        self.uniforms.specular_color = camera.specular_color\n        self.uniforms.specular_exp = camera.specular_exp\n        self.uniforms.light_color = camera.light_color\n        self.uniforms.ambient_color = camera.ambient_color\n        self.uniforms.diffuse_color = camera.diffuse_color\n        self.uniforms.specular_color = camera.specular_color\n        self.uniforms.specular_exp = camera.specular_exp\n        self.uniforms.light_pos = camera.position\n        self.uniforms.light_color = camera.light_color\n        self.uniforms.ambient_color = camera.ambient_color\n        self.uniforms.diffuse_color = camera.diffuse_color\n        self.uniforms.specular_color = camera.specular_color\n        self.uniforms.specular_exp = camera.specular_exp\n        self.uniforms.light_pos = camera.position\n        self.uniforms.light_color = camera.light_color\n        self.uniforms.ambient_color = camera.ambient_color\n        self.uniforms.diffuse_color = camera.diffuse_color\n        self.uniforms.specular_color = camera.specular_color\n        self.uniforms.specular_exp = camera.specular_exp\n        self.uniforms.light_pos = camera"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context\n        eglctx.resize(camera.width, camera.height)\n\n        # Update the uniforms\n        self.uniforms.eye = camera.eye\n        self.uniforms.center = camera.center\n        self.uniforms.up = camera.up\n        self.uniforms.fovy = camera.fovy\n        self.uniforms.aspect = camera.aspect\n        self.uniforms.znear = camera.znear\n        self.uniforms.zfar = camera.zfar\n        self.uniforms.proj_mat = camera.proj_mat\n        self.uniforms.view_mat = camera.view_mat\n        self.uniforms.model_mat = camera.model_mat\n\n        # Bind the buffers\n        gl.glBindVertexArray(self.vao)\n        gl.glBindBuffer(gl.GL_ARRAY_BUFFER, self.vbo)\n        gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, self.ibo)\n\n        # Set the uniforms\n        for k, v in self.uniforms.items():\n            if isinstance(v, torch.Tensor):\n                v = v.detach().cpu().numpy()\n            gl.glUniform1f(self.uniforms_loc[k], v)\n\n        # Render the mesh\n        gl.glDrawElements(self.render_type.value, self.n_faces, gl.GL_UNSIGNED_INT, None)\n\n        # Unbind the buffers\n        gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, 0)\n        gl.glBindBuffer(gl.GL_ARRAY_BUFFER, 0)\n        gl.glBindVertexArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context\n        eglctx.resize(camera.width, camera.height)\n\n        # Set the camera settings\n        self.uniforms['mvp'] = camera.mvp\n        self.uniforms['inv_mvp'] = camera.inv_mvp\n        self.uniforms['camera_pos'] = camera.pos\n\n        # Render the mesh\n        self.render(eglctx)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the mesh\n        with eglctx.makeCurrent(), eglctx.set_current() as ctx:\n            # Setup the viewport\n            gl.glViewport(0, 0, camera.width, camera.height)\n\n            # Setup the projection matrix\n            gl.glMatrixMode(gl.GL_PROJECTION)\n            gl.glLoadIdentity()\n            gl.glLoadMatrixf(camera.get_projection().T.numpy())\n\n            # Setup the modelview matrix\n            gl.glMatrixMode(gl.GL_MODELVIEW)\n            gl.glLoadIdentity()\n            gl.glLoadMatrixf(camera.get_modelview().T.numpy())\n\n            # Render the mesh\n            self.render()\n\n            # Get the rendering result\n            image = gl.glReadPixels(0, 0, camera.width, camera.height, gl.GL_RGB, gl.GL_UNSIGNED_BYTE)\n\n        return image\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Setup the projection matrix\n        # NOTE: We assume the camera's intrinsics are already in the OpenGL format\n        # NOTE: We assume the camera's extrinsics are already in the OpenGL format\n        # NOTE: We assume the camera's intrinsics is a 4x4 matrix\n        # NOTE: We assume the camera's extrinsics is a 4x4 matrix\n        # NOTE: We assume the camera's near plane is the OpenGL default\n        # NOTE: We assume the camera's far plane is the OpenGL default\n        # NOTE: We assume the camera's image is not mirrored\n        # NOTE: We assume the camera's image is not mirrored\n        # NOTE: We assume the camera's image is not mirrored\n        # NOTE: We assume the camera's image is not mirrored\n        # NOTE: We assume the camera's image is not mirrored\n        # NOTE: We assume the camera's image is not mirrored\n        # NOTE: We assume the camera's image is not mirrored\n        # NOTE: We assume the camera's image is not mirrored\n        # NOTE: We assume the camera's image is not mirrored\n        # NOTE: We assume the camera's image is not mirrored\n        # NOTE: We assume the camera's image is not mirrored\n        # NOTE: We assume the camera's image is not mirrored\n        # NOTE: We assume the camera's image is not mirrored\n        # NOTE: We assume the camera's image is not mirrored\n        # NOTE: We assume the camera's image is not mirrored\n        # NOTE: We assume the camera's image is not mirrored\n        # NOTE: We assume the camera's image is not mirrored\n        # NOTE: We assume the camera's image is not mirrored\n        # NOTE: We assume the camera's image is not mirrored\n        # NOTE: We assume the camera's"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Set up the rendering context\n        eglctx.set_current()\n        gl.glViewport(0, 0, camera.width, camera.height)\n        gl.glClearColor(0.0, 0.0, 0.0, 1.0)\n        gl.glClear(gl.GL_COLOR_BUFFER_BIT | gl.GL_DEPTH_BUFFER_BIT)\n\n        # Set up the shader program\n        gl.glUseProgram(self.mesh_program)\n        gl.glUniformMatrix4fv(0, 1, gl.GL_FALSE, camera.P.ravel().astype(np.float32))\n        gl.glUniformMatrix4fv(1, 1, gl.GL_FALSE, camera.V.ravel().astype(np.float32))\n\n        # Render the mesh\n        if self.render_type == Mesh.RenderType.POINTS:\n            # Render points\n            gl.glUniformMatrix4fv(2, 1, gl.GL_FALSE, camera.MV.ravel().astype(np.float32))\n            gl.glUniform1f(3, self.point_radius)\n            gl.glEnable(gl.GL_DEPTH_TEST)\n            gl.glEnable(gl.GL_BLEND)\n            gl.glBlendFunc(gl.GL_SRC_ALPHA, gl.GL_ONE_MINUS_SRC_ALPHA)\n            gl.glEnable(gl.GL_POINT_SPRITE)\n            gl.glEnable(gl.GL_VERTEX_PROGRAM_POINT_SIZE)\n            gl.glEnable(gl.GL_POINT_SPRITE_NV)\n            gl.glEnableClientState(gl.GL_VERTEX_ARRAY)\n            gl.glVertexPointerf(self.verts_data)\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n            gl.glDisableClientState(gl."}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Update the rendering context\n        eglctx.set_dims(*camera.dims)\n\n        # Update the uniforms\n        self.uniforms.projection = camera.projection\n        self.uniforms.view = camera.view\n        self.uniforms.cam_pos = camera.position\n\n        # Update the uniforms\n        self.uniforms.projection = camera.projection\n        self.uniforms.view = camera.view\n        self.uniforms.cam_pos = camera.position\n\n        # Render the mesh\n        self.render(eglctx, self.uniforms)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Prepare uniforms\n        self.uniforms.projection = camera.projection_matrix\n        self.uniforms.view = camera.view_matrix\n        self.uniforms.model = camera.model_matrix\n\n        # Render the mesh\n        self.render(eglctx)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the mesh using the camera's settings\n        self.render(eglctx, camera)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context\n        eglctx.resize(camera.width, camera.height)\n\n        # Rendering\n        with eglctx.makeCurrent():\n            # Prepare OpenGL\n            gl.glViewport(0, 0, camera.width, camera.height)\n            gl.glClear(gl.GL_COLOR_BUFFER_BIT | gl.GL_DEPTH_BUFFER_BIT)\n            gl.glClearColor(*camera.bg_color)\n            gl.glEnable(gl.GL_DEPTH_TEST)\n            gl.glEnable(gl.GL_CULL_FACE)\n            gl.glCullFace(gl.GL_BACK)\n            gl.glEnable(gl.GL_BLEND)\n            gl.glBlendFunc(gl.GL_SRC_ALPHA, gl.GL_ONE_MINUS_SRC_ALPHA)\n\n            # Prepare shaders\n            use_gl_program(self.mesh_program)\n            gl.glUniformMatrix4fv(0, 1, gl.GL_FALSE, camera.P.T().numpy())\n            gl.glUniformMatrix4fv(1, 1, gl.GL_FALSE, camera.V.T().numpy())\n\n            # Prepare vertex buffer objects\n            gl.glBindVertexArray(self.vao)\n            gl.glBindBuffer(gl.GL_ARRAY_BUFFER, self.vbo)\n            gl.glBufferData(gl.GL_ARRAY_BUFFER, self.n_verts_bytes, self.verts_data, gl.GL_STATIC_DRAW)\n            for i, (name, gl_type) in enumerate(zip(self.vert_names, self.vert_gl_types)):\n                loc = gl.glGetAttribLocation(self.mesh_program, name)\n                gl.glEnableVertexAttribArray(loc)\n                gl.glVertexAttribPointer(loc, self.vert_sizes[i], gl_type, gl.GL_FALSE, 0, ctypes.c_void_"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Update the renderer's context to match the camera's width and height\n        eglctx.set_context(width=camera.width, height=camera.height)\n\n        # Render the mesh\n        self.render(camera)\n\n        # Return the rendered image\n        return eglctx.read_buffer()\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Prepare the OpenGL context\n        gl.glClearColor(0.0, 0.0, 0.0, 1.0)\n        gl.glClear(gl.GL_COLOR_BUFFER_BIT)\n\n        # Prepare the shader program\n        gl.glUseProgram(self.mesh_program)\n\n        # Prepare the vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # Prepare the projection matrix\n        gl.glUniformMatrix4fv(self.proj_matrix_loc, 1, gl.GL_FALSE, camera.proj_matrix.ravel())\n\n        # Prepare the view matrix\n        gl.glUniformMatrix4fv(self.view_matrix_loc, 1, gl.GL_FALSE, camera.view_matrix.ravel())\n\n        # Prepare the model matrix\n        gl.glUniformMatrix4fv(self.model_matrix_loc, 1, gl.GL_FALSE, self.model_matrix.ravel())\n\n        # Prepare the lighting\n        gl.glUniform3fv(self.light_loc, 1, self.light_dir)\n\n        # Prepare the vertex colors\n        gl.glBindBuffer(gl.GL_ARRAY_BUFFER, self.color_vbo)\n        gl.glEnableVertexAttribArray(self.color_loc)\n        gl.glVertexAttribPointer(self.color_loc, self.vert_sizes[1], gl.GL_FLOAT, gl.GL_FALSE, 0, None)\n\n        # Prepare the vertex normals\n        gl.glBindBuffer(gl.GL_ARRAY_BUFFER, self.normal_vbo)\n        gl.glEnableVertexAttribArray(self.normal_loc)\n        gl.glVertexAttribPointer(self.normal_loc, self.vert_sizes[2], gl.GL_FLO"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the context to match the camera's width and height\n        eglctx.set_dims(*camera.get_dims())\n\n        # Prepare the uniforms\n        self.uniforms.camera = camera.get_uniform_camparams()\n        self.uniforms.model_matrix = torch.eye(4, dtype=self.verts.dtype, device=self.compute_device)\n        self.uniforms.light_pos = torch.tensor([0.0, 0.0, 1.0], dtype=self.verts.dtype, device=self.compute_device)\n        self.uniforms.light_color = torch.tensor([1.0, 1.0, 1.0], dtype=self.verts.dtype, device=self.compute_device)\n        self.uniforms.ambient_coefficient = torch.tensor(0.5, dtype=self.verts.dtype, device=self.compute_device)\n        self.uniforms.diffuse_coefficient = torch.tensor(0.8, dtype=self.verts.dtype, device=self.compute_device)\n        self.uniforms.specular_coefficient = torch.tensor(0.5, dtype=self.verts.dtype, device=self.compute_device)\n        self.uniforms.specular_exponent = torch.tensor(16.0, dtype=self.verts.dtype, device=self.compute_device)\n        self.uniforms.model_matrix[:3, :3] = camera.get_rotation_matrix()\n        self.uniforms.model_matrix[:3, 3] = camera.get_position()\n\n        # Prepare the shaders\n        if self.render_type == Mesh.RenderType.TRIS:\n            if self.shade_flat:\n                shader_program = self.mesh_program\n            else:\n                shader_program = self.mesh_program\n        elif self.render_type == Mesh.RenderType.POINTS:\n            shader_program ="}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Setup the viewport\n        gl.glViewport(0, 0, camera.width, camera.height)\n\n        # Clear the color and depth buffers\n        gl.glClearColor(0.0, 0.0, 0.0, 1.0)\n        gl.glClearDepth(1.0)\n        gl.glClear(gl.GL_COLOR_BUFFER_BIT | gl.GL_DEPTH_BUFFER_BIT)\n\n        # Set the projection matrix\n        gl.glMatrixMode(gl.GL_PROJECTION)\n        gl.glLoadIdentity()\n        gl.glLoadMatrixf(camera.P.T.numpy())\n\n        # Set the model view matrix\n        gl.glMatrixMode(gl.GL_MODELVIEW)\n        gl.glLoadIdentity()\n        gl.glLoadMatrixf(camera.V.T.numpy())\n\n        # Draw the mesh\n        self.draw(eglctx)\n\n        # Read the color buffer to a numpy array\n        gl.glReadBuffer(gl.GL_COLOR_ATTACHMENT0)\n        frame = gl.glReadPixels(0, 0, camera.width, camera.height, gl.GL_RGB, gl.GL_UNSIGNED_BYTE)\n\n        # Resize the rendering context back to the original size\n        eglctx.resize(self.width, self.height)\n\n        # Reset the viewport\n        gl.glViewport(0, 0, self.width, self.height)\n\n        # Return the frame\n        return frame\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize context\n        eglctx.set_dimensions(camera.width, camera.height)\n\n        # Setup camera\n        self.uniforms['mvp'] = camera.mvp\n        self.uniforms['mv'] = camera.mv\n        self.uniforms['cam_pos'] = camera.pos\n        self.uniforms['cam_front'] = camera.front\n        self.uniforms['cam_up'] = camera.up\n\n        # Render\n        self.render(eglctx)\n\n        # Resize context\n        eglctx.set_dimensions(1280, 720)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the EGL context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Use the camera's settings to render the mesh\n        self.render(eglctx, camera, None, None)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Update the render context size to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Setup the OpenGL environment\n        gl.glViewport(0, 0, camera.width, camera.height)\n        gl.glClearColor(0.0, 0.0, 0.0, 1.0)\n        gl.glClear(gl.GL_COLOR_BUFFER_BIT | gl.GL_DEPTH_BUFFER_BIT)\n        gl.glEnable(gl.GL_DEPTH_TEST)\n        gl.glDisable(gl.GL_BLEND)\n        gl.glBlendFunc(gl.GL_SRC_ALPHA, gl.GL_ONE_MINUS_SRC_ALPHA)\n        gl.glEnable(gl.GL_CULL_FACE)\n        gl.glCullFace(gl.GL_BACK)\n        gl.glEnable(gl.GL_MULTISAMPLE)\n\n        # Setup the camera projection and modelview matrices\n        gl.glMatrixMode(gl.GL_PROJECTION)\n        gl.glLoadMatrixf(camera.get_projection_matrix())\n        gl.glMatrixMode(gl.GL_MODELVIEW)\n        gl.glLoadMatrixf(camera.get_modelview_matrix())\n\n        # Render the mesh\n        if self.visible:\n            self.render()\n\n        # Read the rendering results\n        eglctx.swapBuffers()\n        rgb = eglctx.read_pixels(0, 0, camera.width, camera.height)\n\n        return rgb\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's width and height\n        eglctx.set_dims(*camera.get_dims())\n\n        # Prepare the OpenGL environment\n        gl.glViewport(0, 0, *camera.get_dims())\n        gl.glClear(gl.GL_COLOR_BUFFER_BIT | gl.GL_DEPTH_BUFFER_BIT)\n        gl.glEnable(gl.GL_DEPTH_TEST)\n\n        # Render the Mesh instance using the camera's settings\n        self.render(camera)\n\n        # Read the rendered image from the framebuffer\n        # TODO: Currently only supports color images\n        color_img = gl.glReadPixels(0, 0, *camera.get_dims(), gl.GL_RGB, gl.GL_UNSIGNED_BYTE)\n        color_img = np.frombuffer(color_img, dtype=np.uint8).reshape(camera.get_dims()[::-1] + (3,))\n\n        return color_img\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Prepare the rendering context\n        gl.glClearColor(0, 0, 0, 1)\n        gl.glClear(gl.GL_COLOR_BUFFER_BIT | gl.GL_DEPTH_BUFFER_BIT)\n        gl.glEnable(gl.GL_DEPTH_TEST)\n        gl.glEnable(gl.GL_BLEND)\n        gl.glBlendFunc(gl.GL_SRC_ALPHA, gl.GL_ONE_MINUS_SRC_ALPHA)\n\n        # Render the mesh\n        self.render(camera)\n\n        # Get the rendered image\n        # NOTE: This is not the most efficient way to do this, but it's the simplest for now\n        # NOTE: We need to flip the image vertically since OpenGL maps (0,0) to the bottom-left corner\n        # NOTE: We need to transpose the image since OpenGL treats the axes as (y,x) instead of (x,y)\n        # NOTE: We also need to convert the image to uint8 since OpenGL doesn't support float32\n        img = np.flipud(np.transpose(eglctx.read_pixels(0, 0, camera.width, camera.height, gl.GL_RGB, gl.GL_FLOAT)))\n        img = (img * 255).astype(np.uint8)\n\n        return img\n"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        pad_token_id=bert_config.pad_token_id,\n        gradient_checkpointing=bert_config.gradient_checkpointing,\n        position_embedding_type=bert_config.position_embedding_type,\n        use_cache=bert_config.use_cache,\n        num_labels=bert_config.num_labels,\n        output_attentions=bert_config.output_attentions,\n        output_hidden_states=bert_config.output_hidden_states,\n        torchscript=bert_config.torchscript,\n        conv_kernel_size=bert_config.conv_kernel_size,\n        num_conv_layers=bert_config.num_conv_layers,\n        num_feedforward_layers=bert_config.num_feedforward_layers,\n        num_2d_layers=bert_config.num_2d_layers,\n        num_2d_kernel_sizes=bert_config.num_2d_kernel_sizes,\n        num_2d_conv_layers=bert_config.num_2d_conv_layers,"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Convert BertConfig to NomicBertConfig\n    nomic_config = NomicBertConfig.from_dict(bert_config.to_dict())\n\n    # Add new attributes\n    nomic_config.num_items = 100\n    nomic_config.num_resources = 10\n    nomic_config.num_resource_unit_types = 10\n    nomic_config.num_agents = 10\n    nomic_config.num_locations = 10\n    nomic_config.max_steps = 100\n    nomic_config.max_agents = 10\n    nomic_config.max_items = 100\n    nomic_config.max_resources = 100\n    nomic_config.max_resource_unit_types = 100\n    nomic_config.max_locations = 100\n    nomic_config.max_actions = 100\n    nomic_config.max_action_arguments = 100\n    nomic_config.max_action_roles = 100\n    nomic_config.max_action_target_types = 100\n    nomic_config.max_action_targets = 100\n    nomic_config.max_action_obs = 100\n    nomic_config.max_obs_items = 100\n    nomic_config.max_obs_resources = 100\n    nomic_config.max_obs_resource_unit_types = 100\n    nomic_config.max_obs_agents = 100\n    nomic_config.max_obs_locations = 100\n    nomic_config.max_obs_actions = 100\n    nomic_config.max_obs_action_arguments = 100\n    nomic_config.max_obs_action_roles = 100\n    nomic_config.max_obs_action_target_types = 100\n    nomic_config.max_obs_"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        pad_token_id=bert_config.pad_token_id,\n        gradient_checkpointing=bert_config.gradient_checkpointing,\n        position_embedding_type=bert_config.position_embedding_type,\n        use_cache=bert_config.use_cache,\n        classifier_dropout=None,\n        num_labels=None,\n        num_choices=None,\n        scope=bert_config.scope,\n        # The following attributes are not present in the original BertConfig class\n        num_object_types=bert_config.num_object_types,\n        num_action_types=bert_config.num_action_types,\n        num_object_features=bert_config.num_object_features,\n        num_action_features=bert_config.num_action_features,\n        num_objects=bert_config.num_objects,\n        num_players=bert_config.num_players,\n        num_subtasks=bert_config.num_subtasks,\n        num_prev_action_types=bert_config.num_prev_action_types,\n       "}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Initialize a new configuration object\n    config = NomicBertConfig()\n\n    # Copy the attributes from the original configuration object to the new one\n    for attr in bert_config.__dict__:\n        if attr == \"hidden_act\":\n            setattr(config, \"hidden_act\", \"relu\")\n        elif attr == \"hidden_dropout_prob\":\n            setattr(config, \"hidden_dropout_prob\", bert_config.attention_probs_dropout_prob)\n        elif attr == \"layer_norm_eps\":\n            setattr(config, \"layer_norm_eps\", 1e-12)\n        elif attr == \"initializer_range\":\n            setattr(config, \"initializer_range\", 0.02)\n        elif attr == \"vocab_size\":\n            setattr(config, \"vocab_size\", bert_config.vocab_size)\n        elif attr == \"hidden_size\":\n            setattr(config, \"hidden_size\", bert_config.hidden_size)\n        elif attr == \"num_attention_heads\":\n            setattr(config, \"num_attention_heads\", bert_config.num_attention_heads)\n        elif attr == \"num_hidden_layers\":\n            setattr(config, \"num_hidden_layers\", bert_config.num_hidden_layers)\n        elif attr == \"max_position_embeddings\":\n            setattr(config, \"max_position_embeddings\", bert_config.max_position_embeddings)\n        elif attr == \"type_vocab_size\":\n            setattr(config, \"type_vocab_size\", bert_config.type_vocab_size)\n        elif attr == \"is_decoder\":\n            setattr(config, \"is_decoder\", bert_config.is_decoder)\n        elif attr == \"add_cross_attention\":\n            setattr(config, \"add_cross_attention\", bert_config.add_cross_attention)\n        else:\n            setattr(config,"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Create a new dictionary with the new arguments\n    new_config_dict = OrderedDict()\n    new_config_dict[\"num_labels\"] = bert_config.num_labels\n    new_config_dict[\"num_choices\"] = bert_config.num_choices\n    new_config_dict[\"num_decoder_layers\"] = bert_config.num_decoder_layers\n    new_config_dict[\"num_decoder_attention_heads\"] = bert_config.num_decoder_attention_heads\n    new_config_dict[\"decoder_ffn_dim\"] = bert_config.decoder_ffn_dim\n    new_config_dict[\"decoder_attention_head_size\"] = bert_config.decoder_attention_head_size\n    new_config_dict[\"max_position_embeddings\"] = bert_config.max_position_embeddings\n    new_config_dict[\"max_decoder_position_embeddings\"] = bert_config.max_position_embeddings\n    new_config_dict[\"max_source_length\"] = bert_config.max_position_embeddings\n    new_config_dict[\"max_target_length\"] = bert_config.max_position_embeddings\n    new_config_dict[\"min_target_length\"] = bert_config.min_target_length\n    new_config_dict[\"max_length\"] = bert_config.max_position_embeddings\n    new_config_dict[\"max_full_decoder_length\"] = bert_config.max_position_embeddings\n    new_config_dict[\"max_full_encoder_length\"] = bert_config.max_position_embeddings\n    new_config_dict[\"max_num_decoder_steps\"] = bert_config.max_position_embeddings\n    new_config_dict[\"max_num_decoder_steps_unique\"] = bert_config.max_position_embeddings\n    new_config_dict[\"min_num_decoder_steps\"] = bert_"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig()\n\n    # Inherit the BERT model configuration attributes\n    for key, value in bert_config.__dict__.items():\n        nomic_config.__dict__[key] = value\n\n    # Add the new attributes specific to the Nomic model\n    nomic_config.num_items = 200\n    nomic_config.num_resources = 40\n    nomic_config.num_tokens = 10\n    nomic_config.num_features = 7\n    nomic_config.num_turns = 20\n    nomic_config.num_players = 4\n    nomic_config.num_k = 3\n    nomic_config.num_a = 2\n    nomic_config.num_b = 2\n    nomic_config.num_c = 2\n    nomic_config.num_d = 2\n    nomic_config.num_e = 2\n    nomic_config.num_f = 2\n    nomic_config.num_g = 2\n    nomic_config.num_h = 2\n    nomic_config.num_i = 2\n    nomic_config.num_j = 2\n    nomic_config.num_k = 2\n    nomic_config.num_l = 2\n    nomic_config.num_m = 2\n    nomic_config.num_n = 2\n    nomic_config.num_o = 2\n    nomic_config.num_p = 2\n    nomic_config.num_q = 2\n    nomic_config.num_r = 2\n    nomic_config.num_s = 2\n    nomic_config.num_t = 2\n    nomic_config.num_u = 2\n    nomic_config.num_v = 2\n    nomic_config.num_w = 2\n    nomic_config.num_x = 2\n    nomic_config.num_y = 2\n    nomic_config"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Initialize the new config object\n    nomic_config = NomicBertConfig()\n\n    # Copy the original configuration settings from the original config object\n    for attr in bert_config.__dict__:\n        setattr(nomic_config, attr, getattr(bert_config, attr))\n\n    # Add new attributes specific to the Nomic model\n    nomic_config.num_labels = 1\n    nomic_config.num_scenarios = 1\n    nomic_config.num_players = 1\n    nomic_config.num_tokens = 1\n    nomic_config.num_resources = 1\n    nomic_config.num_locations = 1\n    nomic_config.num_max_resource_costs = 1\n    nomic_config.num_max_location_costs = 1\n    nomic_config.num_max_init_resources = 1\n    nomic_config.num_max_steps = 1\n    nomic_config.num_max_cards_in_hand = 1\n    nomic_config.num_max_cards_in_deck = 1\n    nomic_config.num_max_cards_in_discard = 1\n    nomic_config.num_max_cards_in_play = 1\n    nomic_config.num_max_reserved_cards = 1\n    nomic_config.num_max_excluded_cards = 1\n    nomic_config.num_max_target_tokens = 1\n    nomic_config.num_max_target_resources = 1\n    nomic_config.num_max_target_locations = 1\n    nomic_config.num_max_possible_actions = 1\n    nomic_config.num_max_resource_costs = 1\n    nomic_config.num_max_location_costs = 1\n    nomic_config.num_max_cards_to_reveal = 1\n    nomic_config.num_max_cards_to_choose = 1\n    nomic_config."}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Create new configuration object\n    nomic_config = NomicBertConfig()\n\n    # Copy values from the original configuration\n    for key, value in bert_config.__dict__.items():\n        nomic_config.__dict__[key] = value\n\n    # Add new attributes\n    nomic_config.num_labels = 1\n    nomic_config.num_objectives = 1\n    nomic_config.num_objective_regressors = 1\n    nomic_config.num_action_choices = 1\n    nomic_config.num_players = 1\n    nomic_config.num_tokens = 1\n    nomic_config.num_turns = 1\n    nomic_config.num_resources = 1\n    nomic_config.num_locations = 1\n    nomic_config.num_cards = 1\n    nomic_config.num_event_cards = 1\n    nomic_config.num_special_cards = 1\n    nomic_config.max_card_types = 1\n    nomic_config.max_card_usages = 1\n    nomic_config.max_card_effects = 1\n    nomic_config.max_card_costs = 1\n    nomic_config.max_card_attack_range = 1\n    nomic_config.max_card_hp = 1\n    nomic_config.max_card_actions = 1\n    nomic_config.max_card_rewards = 1\n    nomic_config.max_card_conversions = 1\n    nomic_config.max_card_victory_points = 1\n    nomic_config.max_card_actions_and_reactions = 1\n    nomic_config.max_card_buys = 1\n    nomic_config.max_card_coin_costs = 1\n    nomic_config.max_card_coin_gains = 1\n    nomic_config.max_card_coin_cost_types = 1\n    nom"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Convert the configuration object from BERT to Nomic\n    nomic_config = NomicBertConfig.from_dict(bert_config.to_dict())\n\n    # Add some additional attributes to the configuration object\n    nomic_config.num_labels = 1\n    nomic_config.num_choices = 1\n    nomic_config.num_decoder_layers = 0\n    nomic_config.num_decoder_attention_heads = 0\n    nomic_config.max_position_embeddings = 1024\n    nomic_config.max_turns = 10\n    nomic_config.max_length = 1024\n    nomic_config.max_turn_length = 128\n    nomic_config.max_actions = 100\n    nomic_config.max_action_steps = 100\n    nomic_config.max_action_arguments = 100\n    nomic_config.max_action_argument_length = 100\n    nomic_config.max_action_argument_items = 100\n    nomic_config.max_action_argument_roles = 10\n    nomic_config.max_action_argument_role_length = 100\n    nomic_config.max_action_argument_role_items = 10\n    nomic_config.max_action_roles = 10\n    nomic_config.max_action_role_length = 100\n    nomic_config.max_action_role_items = 10\n    nomic_config.max_action_roles_per_argument = 10\n    nomic_config.max_action_roles_per_role = 10\n    nomic_config.max_action_roles_per_action = 10\n    nomic_config.max_action_roles_per_action_argument = 10\n    nomic_config.max_action_roles_per_action_role = 10\n    nomic_config.max"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Create a new dictionary with the same keys as the original config, but different values.\n    new_config_dict = dict(bert_config.to_dict())\n\n    # Add the new arguments to the dictionary.\n    new_config_dict['num_items'] = 240\n    new_config_dict['num_resources'] = 240\n    new_config_dict['num_agents'] = 10\n    new_config_dict['num_heuristics'] = 24\n\n    # Convert the dictionary to a new config object.\n    new_config = NomicBertConfig(**new_config_dict)\n\n    return new_config\n\n"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig.from_dict(bert_config.to_dict())\n\n    # Adaptations to the original BertConfig\n    nomic_config.hidden_act = \"gelu\"\n    nomic_config.hidden_dropout_prob = 0.1\n    nomic_config.layer_norm_eps = 1e-12\n    nomic_config.initializer_range = 0.02\n    nomic_config.vocab_size = 512\n    nomic_config.type_vocab_size = 2\n    nomic_config.max_position_embeddings = 512\n    nomic_config.num_attention_heads = 8\n    nomic_config.num_hidden_layers = 12\n    nomic_config.intermediate_size = 3072\n    nomic_config.hidden_size = 768\n    nomic_config.attention_probs_dropout_prob = 0.1\n\n    # Additional configurations\n    nomic_config.num_object_types = 5\n    nomic_config.num_action_types = 5\n    nomic_config.num_object_features = 128\n    nomic_config.num_action_features = 128\n    nomic_config.num_player_features = 128\n    nomic_config.num_turn_features = 128\n    nomic_config.num_game_features = 128\n    nomic_config.num_game_id_features = 128\n    nomic_config.num_strings = 1024\n    nomic_config.num_strings_per_player = 1024\n    nomic_config.num_locations = 1024\n    nomic_config.num_locations_per_player = 1024\n    nomic_config.num_cards = 1024\n    nomic_config.num_cards_per_player = 1024\n   "}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Copy the configuration object\n    nomic_config = BertConfig(**bert_config.__dict__)\n\n    # Add the new attributes\n    nomic_config.num_board_tokens = 101\n    nomic_config.num_status_tokens = 101\n    nomic_config.num_resource_tokens = 101\n    nomic_config.num_hand_tokens = 101\n    nomic_config.num_card_tokens = 101\n    nomic_config.num_tokens = nomic_config.num_board_tokens + nomic_config.num_status_tokens + nomic_config.num_resource_tokens + nomic_config.num_hand_tokens + nomic_config.num_card_tokens\n    nomic_config.max_position_embeddings = nomic_config.num_tokens\n    nomic_config.type_vocab_size = 3\n    nomic_config.num_labels = 3\n    nomic_config.pad_token_id = 0\n    nomic_config.board_token_id = 1\n    nomic_config.status_token_id = 2\n    nomic_config.resource_token_id = 3\n    nomic_config.hand_token_id = 4\n    nomic_config.card_token_id = 5\n    nomic_config.num_attention_heads = 12\n    nomic_config.num_hidden_layers = 12\n    nomic_config.hidden_size = 768\n    nomic_config.intermediate_size = 3072\n    nomic_config.hidden_dropout_prob = 0.1\n    nomic_config.attention_probs_dropout_prob = 0.1\n    nomic_config.max_position_embeddings = 512\n    nomic_config.initializer_range = 0.02\n    nomic_config.layer_norm_eps = 1e-12"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Create a new config object\n    nomic_config = NomicBertConfig()\n\n    # Copy all the attributes of the original config object\n    for attr in dir(bert_config):\n        if not callable(getattr(bert_config, attr)) and not attr.startswith(\"__\"):\n            setattr(nomic_config, attr, getattr(bert_config, attr))\n\n    # Set the new attributes\n    nomic_config.num_labels = 1\n    nomic_config.num_assets = 36\n    nomic_config.num_markets = 36\n    nomic_config.num_turns = 4\n    nomic_config.num_players = 4\n    nomic_config.num_tokens = 10\n    nomic_config.num_features = 10\n    nomic_config.max_length = 1024\n    nomic_config.max_turns = 4\n    nomic_config.max_players = 4\n    nomic_config.max_tokens = 10\n    nomic_config.max_features = 10\n    nomic_config.max_actions = 10\n    nomic_config.max_assets = 36\n    nomic_config.max_markets = 36\n    nomic_config.max_positions = 36\n    nomic_config.max_values = 1000\n    nomic_config.max_shares = 1000\n    nomic_config.max_price = 1000\n    nomic_config.max_actions = 10\n    nomic_config.max_input_length = 1024\n    nomic_config.max_output_length = 1024\n    nomic_config.max_input_actions = 10\n    nomic_config.max_output_actions = 10\n    nomic_config.max_input_assets = 36\n    nomic_config.max_input_markets = 36\n    nomic_"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Convert BertConfig object to dictionary\n    bert_config_dict = bert_config.to_dict()\n\n    # Create new NomicBertConfig object\n    nomic_config = NomicBertConfig()\n\n    # Add new attributes to NomicBertConfig object\n    nomic_config.num_labels = 2\n    nomic_config.num_object_labels = 30\n    nomic_config.num_action_labels = 10\n    nomic_config.num_object_types = 12\n    nomic_config.num_action_types = 2\n    nomic_config.num_subtasks = 10\n    nomic_config.num_subtask_levels = 1\n    nomic_config.num_subtask_steps = 1\n    nomic_config.num_subtask_steps_completed = 1\n    nomic_config.num_subtask_steps_info = 1\n    nomic_config.num_subtask_progress = 1\n    nomic_config.num_subtask_progress_info = 1\n    nomic_config.num_subtask_reward = 1\n    nomic_config.num_subtask_reward_info = 1\n    nomic_config.num_subtask_time = 1\n    nomic_config.num_subtask_time_info = 1\n    nomic_config.num_subtask_action = 1\n    nomic_config.num_subtask_action_info = 1\n    nomic_config.num_subtask_object_reward = 1\n    nomic_config.num_subtask_object_reward_info = 1\n    nomic_config.num_subtask_object_steps = 1\n    nomic_config.num_subtask_object_steps_info = 1\n    nomic_config.num_subtask_object_time = 1\n    nomic_config.num_subtask_object_time_info = 1\n    nomic_config.num_subtask_object_action = 1"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Define the new configuration object\n    nomic_config = NomicBertConfig()\n\n    # Inherit all the settings from the original configuration\n    nomic_config.__dict__ = {k: v for k, v in bert_config.__dict__.items()}\n\n    # Add new attributes\n    nomic_config.num_items = 25\n    nomic_config.num_resources = 10\n    nomic_config.num_resource_categories = 5\n    nomic_config.num_event_categories = 5\n    nomic_config.num_event_features = 5\n    nomic_config.num_player_categories = 5\n    nomic_config.num_game_categories = 5\n    nomic_config.num_actions = 15\n    nomic_config.num_players = 10\n    nomic_config.num_games = 10\n    nomic_config.num_items_per_game = 25\n    nomic_config.num_resources_per_game = 10\n    nomic_config.num_resource_categories_per_game = 5\n    nomic_config.num_event_categories_per_game = 5\n    nomic_config.num_event_features_per_game = 5\n    nomic_config.num_player_categories_per_game = 5\n    nomic_config.num_game_categories_per_game = 5\n    nomic_config.num_actions_per_game = 15\n    nomic_config.num_players_per_game = 10\n    nomic_config.num_games_per_game = 10\n    nomic_config.num_items_per_player = 25\n    nomic_config.num_resources_per_player = 10\n    nomic_config.num_resource_categories_per_player = 5\n    nomic_config.num_event_categories_per_player = 5\n    nomic_config.num_event_features_per_player = 5\n    nom"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Setup new configuration object\n    nomic_config = NomicBertConfig()\n\n    # Copy all attributes from the original configuration object\n    for attr in bert_config.__dict__:\n        if attr in [\"_name_or_path\", \"finetuning_task\"]:\n            continue\n        setattr(nomic_config, attr, getattr(bert_config, attr))\n\n    # Set additional parameters\n    nomic_config.num_labels = 1\n    nomic_config.num_object_labels = 10\n    nomic_config.num_action_labels = 5\n    nomic_config.num_object_types = 10\n    nomic_config.num_action_types = 5\n    nomic_config.num_subject_labels = 10\n    nomic_config.num_subject_types = 10\n    nomic_config.num_predicate_labels = 10\n    nomic_config.num_predicate_types = 10\n    nomic_config.num_action_predicates = 10\n    nomic_config.num_object_predicates = 10\n    nomic_config.num_subject_predicates = 10\n    nomic_config.num_object_roles = 10\n    nomic_config.num_action_roles = 10\n    nomic_config.num_subject_roles = 10\n    nomic_config.num_object_types_roles = 10\n    nomic_config.num_action_types_roles = 10\n    nomic_config.num_subject_types_roles = 10\n    nomic_config.num_object_types_labels = 10\n    nomic_config.num_action_types_labels = 10\n    nomic_config.num_subject_types_labels = 10\n    nomic_config.num_object_predicates_roles = 10\n    nomic_config.num_action_predicates_roles = 10\n   "}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Convert BertConfig object to dictionary\n    bert_config_dict = bert_config.to_dict()\n\n    # Remove unnecessary attributes\n    bert_config_dict.pop(\"type_vocab_size\")\n    bert_config_dict.pop(\"initializer_range\")\n    bert_config_dict.pop(\"layer_norm_eps\")\n\n    # Add new attributes\n    bert_config_dict[\"num_players\"] = 2\n    bert_config_dict[\"num_tokens\"] = 50\n    bert_config_dict[\"num_resources\"] = 10\n    bert_config_dict[\"num_locations\"] = 20\n    bert_config_dict[\"num_cards\"] = 30\n    bert_config_dict[\"max_actions\"] = 10\n    bert_config_dict[\"max_resources\"] = 10\n    bert_config_dict[\"max_builds\"] = 10\n    bert_config_dict[\"max_other_players\"] = 10\n    bert_config_dict[\"max_in_hand\"] = 10\n    bert_config_dict[\"max_in_deck\"] = 10\n    bert_config_dict[\"max_reserved\"] = 10\n    bert_config_dict[\"max_cost\"] = 10\n    bert_config_dict[\"max_turns\"] = 10\n    bert_config_dict[\"max_start_turn\"] = 10\n    bert_config_dict[\"max_players\"] = 10\n    bert_config_dict[\"max_prev_actions\"] = 10\n\n    # Convert dictionary to a NomicBertConfig object\n    nomic_config = NomicBertConfig(**bert_config_dict)\n\n    return nomic_config\n\n"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Make sure the input configuration is a BertConfig instance\n    assert isinstance(bert_config, BertConfig)\n\n    # Create the new configuration object\n    nomic_config = NomicBertConfig()\n\n    # Copy the attributes that are present in both configuration objects\n    for attribute_name in NomicBertConfig.__dict__.keys():\n        if attribute_name in BertConfig.__dict__.keys():\n            setattr(nomic_config, attribute_name, getattr(bert_config, attribute_name))\n\n    # Set the new attributes that are not present in the original configuration object\n    nomic_config.num_labels = 1\n    nomic_config.num_choices = 1\n    nomic_config.num_decoder_layers = 0\n    nomic_config.num_attention_heads = 0\n    nomic_config.num_hidden_layers = 0\n    nomic_config.hidden_size = 0\n    nomic_config.intermediate_size = 0\n    nomic_config.hidden_act = \"gelu\"\n    nomic_config.hidden_dropout_prob = 0.1\n    nomic_config.attention_probs_dropout_prob = 0.1\n    nomic_config.max_position_embeddings = 0\n    nomic_config.type_vocab_size = 0\n    nomic_config.initializer_range = 0.02\n    nomic_config.layer_norm_eps = 1e-12\n    nomic_config.gradient_checkpointing = False\n    nomic_config.use_cache = False\n    nomic_config.is_encoder_decoder = False\n    nomic_config.pad_token_id = 0\n    nomic_config.bos_token_id = 1\n    nomic_config.eos_token_id = 2\n    nomic_config.sep_token_id = 3\n    nomic_config.decoder_start_token_id = 0\n    nomic_config.vocab_size = 0"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Initialize the new configuration object\n    nomic_config = NomicBertConfig()\n\n    # Copy the attributes from the original configuration to the new configuration\n    for attr in bert_config.__dict__:\n        setattr(nomic_config, attr, getattr(bert_config, attr))\n\n    # Add new attributes\n    nomic_config.num_labels = 2\n    nomic_config.num_object_types = 3\n    nomic_config.num_object_subtypes = 11\n    nomic_config.num_object_actions = 12\n    nomic_config.num_object_properties = 13\n    nomic_config.num_object_locations = 14\n    nomic_config.num_object_states = 15\n    nomic_config.num_object_values = 16\n    nomic_config.num_features = 17\n    nomic_config.num_turns = 18\n    nomic_config.num_players = 19\n    nomic_config.num_games = 20\n    nomic_config.num_game_status = 21\n    nomic_config.num_game_steps = 22\n    nomic_config.num_game_objects = 23\n    nomic_config.num_game_actions = 24\n    nomic_config.num_game_properties = 25\n    nomic_config.num_game_scores = 26\n    nomic_config.num_game_tokens = 27\n    nomic_config.num_game_hands = 28\n    nomic_config.num_game_last_actions = 29\n    nomic_config.num_game_last_turns = 30\n    nomic_config.num_game_stacks = 31\n    nomic_config.num_game_last_states = 32\n    nomic_config.num_game_cards = 33\n    nomic_config.num_game_tokens_seq = 3"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Create a new config object\n    nomic_config = NomicBertConfig()\n\n    # Fill in the new config object with the values from the original config object\n    for key in bert_config.__dict__:\n        nomic_config.__dict__[key] = bert_config.__dict__[key]\n\n    # Add some new attributes\n    nomic_config.num_labels = 3\n    nomic_config.num_scores = 1\n    nomic_config.num_turns = 2\n    nomic_config.num_items = 10\n    nomic_config.num_tokens = 2\n    nomic_config.num_cards = 10\n    nomic_config.num_players = 2\n    nomic_config.num_hands = 10\n    nomic_config.num_victory_tokens = 10\n    nomic_config.num_victory_points = 10\n    nomic_config.num_games = 10\n    nomic_config.num_actions = 10\n    nomic_config.num_scores_per_action = 10\n    nomic_config.num_players_per_team = 10\n    nomic_config.num_items_per_action = 10\n    nomic_config.num_cards_per_action = 10\n    nomic_config.num_players_per_action = 10\n    nomic_config.num_victory_tokens_per_action = 10\n    nomic_config.num_victory_points_per_action = 10\n    nomic_config.num_games_per_action = 10\n    nomic_config.num_actions_per_action = 10\n    nomic_config.num_scores_per_action_per_action = 10\n    nomic_config.num_players_per_team_per_action = 10\n    nomic_config.num_items_per_action_per"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        # Use the appropriate shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # Draw\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.faces.dtype == torch.int32:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_SHORT, ctypes.c_void_p(0))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.faces.dtype == torch.int32:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_SHORT, ctypes.c_void_p(0))\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if self.faces.dtype == torch.int32:\n                gl.glDrawElements(gl.GL_"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible: return\n\n        # Use the correct shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind VAO\n        gl.glBindVertexArray(self.vao)\n\n        # Draw\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.faces.dtype == torch.int32:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces), gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces), gl.GL_UNSIGNED_INT, self.faces)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.faces.dtype == torch.int32:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces), gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces), gl.GL_UNSIGNED_INT, self.faces)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if self.faces.dtype == torch.int32:\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces), gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawElements(gl."}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        # Select the correct shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # Draw\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.faces.dtype == torch.int64:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces), gl.GL_UNSIGNED_INT, self.faces)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.faces.dtype == torch.int64:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces), gl.GL_UNSIGNED_INT, self.faces)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if self.faces.dtype == torch.int64:\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces), gl.GL_UNSIGNED_INT, self."}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        # Bind shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind VAO\n        gl.glBindVertexArray(self.vao)\n\n        # Draw\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.faces.dtype == torch.int32:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, self.faces.data_ptr())\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.faces.dtype == torch.int32:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, self.faces.data_ptr())\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if self.faces.dtype == torch.int32:\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        # Setup the shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # Draw\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.faces.dtype == torch.int32:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces), gl.GL_UNSIGNED_INT, self.faces.data_ptr())\n            else:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces), gl.GL_UNSIGNED_INT, self.faces.data_ptr())\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.faces.dtype == torch.int32:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces), gl.GL_UNSIGNED_INT, self.faces.data_ptr())\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.faces))\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if self.faces.dtype == torch.int32:\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces), gl.GL_UNSIGNED_INT, self.faces.data_ptr())\n            else:\n                gl.glDrawArrays(gl.GL_QUADS, 0, len(self."}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        # Check visibility\n        if not self.visible:\n            return\n\n        # Select shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # Draw\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, self.n_verts)\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.has_faces:\n                gl.glDrawElements(gl.GL_LINES, 2 * self.n_faces, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_LINES, 0, 2 * self.n_verts)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.has_faces:\n                gl.glDrawElements(gl.GL_TRIANGLES, 3 * self.n_faces, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, 3 * self.n_verts)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if self.has_faces:\n                gl.glDrawElements(gl.GL_QUADS, 4 * self.n_faces, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_QUADS, 0, 4 * self.n_verts)\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            if self.has_faces:\n                gl"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible: return\n\n        # Select shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # Draw\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, self.n_verts)\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.faces.dtype == torch.int64:\n                gl.glDrawElements(gl.GL_LINES, 2 * self.n_faces, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawElements(gl.GL_LINES, 2 * self.n_faces, gl.GL_UNSIGNED_INT, self.faces_data)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.faces.dtype == torch.int64:\n                gl.glDrawElements(gl.GL_TRIANGLES, 3 * self.n_faces, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawElements(gl.GL_TRIANGLES, 3 * self.n_faces, gl.GL_UNSIGNED_INT, self.faces_data)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if self.faces.dtype == torch.int64:\n                gl.glDrawElements(gl.GL_QUADS, 4 * self.n_faces, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawElements(gl.GL_QUADS, 4 * self."}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        # Bind the appropriate shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind the vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # Draw the mesh\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, self.n_verts)\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.faces.dtype == torch.int64:\n                gl.glDrawElements(gl.GL_LINES, self.n_faces, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawElements(gl.GL_LINES, self.n_faces, gl.GL_UNSIGNED_SHORT, None)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.faces.dtype == torch.int64:\n                gl.glDrawElements(gl.GL_TRIANGLES, self.n_faces, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawElements(gl.GL_TRIANGLES, self.n_faces, gl.GL_UNSIGNED_SHORT, None)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if self.faces.dtype == torch.int64:\n                gl.glDrawElements(gl.GL_QUADS, self.n_faces, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawElements(gl.GL_QUADS, self.n_faces, gl.GL_UNSIGNED_SHORT,"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible: return\n\n        # Set up the shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n        else:\n            use_gl_program(self.mesh_program)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind the VAO\n        gl.glBindVertexArray(self.vao)\n\n        # Draw\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.faces.dtype == torch.int32:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces), gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces), gl.GL_UNSIGNED_INT, self.faces)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.faces.dtype == torch.int32:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces), gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces), gl.GL_UNSIGNED_INT, self.faces)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if self.faces.dtype == torch.int32:\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces), gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawElements(gl."}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        # Select the shader program based on the render type\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        # Upload the uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind the VAO\n        gl.glBindVertexArray(self.vao)\n\n        # Draw the mesh\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.has_index:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.has_index:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if self.has_index:\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawArrays(gl.GL_QUADS, 0, len(self"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible: return\n\n        # Select shaders\n        if self.render_type == Mesh.RenderType.POINTS:\n            shader = self.point_program\n        else:\n            shader = self.mesh_program\n        gl.glUseProgram(shader)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # Draw\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.faces.dtype == torch.int32:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            elif self.faces.dtype == torch.int64:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_LONG, None)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.faces.dtype == torch.int32:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            elif self.faces.dtype == torch.int64:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_LONG, None)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if self.faces.dtype == torch.int32:\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces) * self"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        # Check visibility\n        if not self.visible:\n            return\n\n        # Use correct program\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind VAO\n        gl.glBindVertexArray(self.vao)\n\n        # Draw\n        if self.render_type == Mesh.RenderType.POINTS:\n            if self.faces is None:\n                gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n            else:\n                gl.glDrawElements(gl.GL_POINTS, len(self.faces), gl.GL_UNSIGNED_INT, self.faces)\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.faces is None:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n            else:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces), gl.GL_UNSIGNED_INT, self.faces)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.faces is None:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n            else:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces), gl.GL_UNSIGNED_INT, self.faces)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if self.faces is None:\n                gl.glDrawArrays(gl.GL_QUADS, 0, len(self.verts))\n            else:\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces), gl.GL_UNSIGNED_"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        # Select the shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            shader = self.point_program\n        else:\n            shader = self.mesh_program\n\n        # Use the shader program\n        use_gl_program(shader)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # Draw the mesh\n        if self.render_type == Mesh.RenderType.POINTS:\n            if self.faces is not None:\n                gl.glDrawElements(gl.GL_POINTS, len(self.faces), gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.faces is not None:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces), gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.faces is not None:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces), gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if self.faces is not None:\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces), gl.GL_"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        # Skip rendering if not visible\n        if not self.visible:\n            return\n\n        # Select the shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            shader = self.point_program\n        else:\n            shader = self.mesh_program\n        gl.glUseProgram(shader)\n\n        # Upload the uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind the vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # Draw the mesh\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.faces.dtype == torch.int32:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, self.faces_data)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.faces.dtype == torch.int32:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, self.faces_data)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if self.faces.dtype == torch.int32:\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces) * self.face_size"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        # Check visibility\n        if not self.visible:\n            return\n\n        # Select the shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind the vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # Draw the mesh\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, self.n_verts)\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.faces.dtype == torch.int32:\n                gl.glDrawElements(gl.GL_LINES, self.n_faces, gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            elif self.faces.dtype == torch.int64:\n                gl.glDrawElements(gl.GL_LINES, self.n_faces, gl.GL_UNSIGNED_LONG, ctypes.c_void_p(0))\n            else:\n                gl.glDrawElements(gl.GL_LINES, self.n_faces, gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.faces.dtype == torch.int32:\n                gl.glDrawElements(gl.GL_TRIANGLES, self.n_faces, gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            elif self.faces.dtype == torch.int64:\n                gl.glDrawElements(gl.GL_TRIANGLES, self.n_faces, gl.GL_UNSIGNED_LONG, ctypes.c_void_"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        # Select the appropriate shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            program = self.point_program\n        else:\n            program = self.mesh_program\n\n        # Set up the OpenGL state\n        use_gl_program(program)\n        self.upload_gl_uniforms(camera)\n        self.bind_gl_buffers()\n\n        # Issue the appropriate draw call\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.faces.dtype == torch.int32:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces), gl.GL_UNSIGNED_INT, self.faces.data_ptr())\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.faces.dtype == torch.int32:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces), gl.GL_UNSIGNED_INT, self.faces.data_ptr())\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if self.faces.dtype == torch.int32:\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces), gl.GL_UNSIGNED_INT, self"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        # Use the correct shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # Draw\n        if self.render_type == Mesh.RenderType.POINTS:\n            if self.faces is not None:\n                gl.glDrawElements(gl.GL_TRIANGLES, 3, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, 3)\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.faces is not None:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.faces))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.faces is not None:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.faces))\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if self.faces is not None:\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_QUADS, 0, len(self.faces))\n        elif self.render_type"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        # Check if the mesh is visible\n        if not self.visible:\n            return\n\n        # Select the appropriate shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            shader = self.point_program\n        else:\n            shader = self.mesh_program\n\n        # Bind the shader program\n        use_gl_program(shader)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind the VAO\n        gl.glBindVertexArray(self.vao)\n\n        # Draw\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, self.n_verts)\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.has_faces:\n                gl.glDrawElements(gl.GL_LINES, self.n_faces, gl.GL_UNSIGNED_INT, 0)\n            else:\n                gl.glDrawArrays(gl.GL_LINES, 0, self.n_verts)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.has_faces:\n                gl.glDrawElements(gl.GL_TRIANGLES, self.n_faces, gl.GL_UNSIGNED_INT, 0)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, self.n_verts)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if self.has_faces:\n                gl.glDrawElements(gl.GL_QUADS, self.n_faces, gl.GL_UNSIGNED_INT, 0)\n            else:\n                gl.glDrawArrays(gl.GL_QUADS, 0, self.n_verts)\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            if self.has_faces"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        # Early return if not visible\n        if not self.visible:\n            return\n\n        # Select the shader program based on the render type\n        if self.render_type == Mesh.RenderType.POINTS:\n            shader = self.point_program\n        else:\n            shader = self.mesh_program\n\n        # Set up OpenGL state\n        gl.glUseProgram(shader)\n        gl.glBindVertexArray(self.vao)\n        gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, self.ebo)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Draw\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.faces.dtype == torch.int32:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces), gl.GL_UNSIGNED_INT, self.faces.data_ptr)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.faces.dtype == torch.int32:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces), gl.GL_UNSIGNED_INT, self.faces.data_ptr)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if self.faces.dtype == torch.int32:\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces), gl."}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n        else:\n            use_gl_program(self.mesh_program)\n\n        self.upload_gl_uniforms(camera)\n\n        gl.glBindVertexArray(self.vao)\n        if self.faces.dtype == torch.int32:\n            gl.glDrawElements(self.render_type.value, self.n_faces, self.faces.dtype, ctypes.c_void_p(0))\n        else:\n            gl.glDrawArrays(self.render_type.value, 0, self.n_verts)\n        gl.glBindVertexArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not self.use_quad_cuda:\n            self.upload_to_texture(ptr)\n            return\n\n        if not hasattr(self, 'cu_tex'):\n            self.init_texture()\n\n        # assert self.use_quad_cuda, \"Need to enable cuda-opengl interop to copy from device to device, check creation of this Quad\"\n        w = w or self.W\n        h = h or self.H\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        from cuda import cudart\n        kind = cudart.cudaMemcpyKind.cudaMemcpyHostToDevice\n        CHECK_CUDART_ERROR(cudart.cudaGraphicsMapResources(1, self.cu_tex, torch.cuda.current_stream().cuda_stream))\n        cu_tex_arr = CHECK_CUDART_ERROR(cudart.cudaGraphicsSubResourceGetMappedArray(self.cu_tex, 0, 0))\n\n        if self.compose:\n            \"\"\"\n            Blit current framebuffer to this texture (self.tex)\n            Read content of this texture into a cuda buffer\n            Perform alpha blending based on the frame's alpha channel\n            Copy the blended image back into the texture (self.tex)\n            \"\"\"\n            old = gl.glGetInteger(gl.GL_DRAW_FRAMEBUFFER_BINDING)\n            gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, self.fbo)  # read buffer defaults to 0\n            gl.glBlitFramebuffer(x, y, w, h,\n                                 x, y, w, h,\n                                 gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # now self.tex contains the content of the already rendered frame\n            gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, old)\n\n            buffer = np.empty_like(ptr)\n            CHECK_C"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not self.use_quad_cuda:\n            self.upload_to_texture(image)\n            return\n\n        if not hasattr(self, 'cu_tex'):\n            self.init_texture()\n\n        # assert self.use_quad_cuda, \"Need to enable cuda-opengl interop to copy from device to device, check creation of this Quad\"\n        w = w or self.W\n        h = h or self.H\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n        if ptr.shape[-1] == 3:\n            ptr = np.concatenate([ptr, np.ones(ptr.shape[:-1] + (1,), dtype=ptr.dtype) * 255], axis=-1)  # add alpha channel\n\n        from cuda import cudart\n        kind = cudart.cudaMemcpyKind.cudaMemcpyHostToDevice\n        CHECK_CUDART_ERROR(cudart.cudaGraphicsMapResources(1, self.cu_tex, torch.cuda.current_stream().cuda_stream))\n        cu_tex_arr = CHECK_CUDART_ERROR(cudart.cudaGraphicsSubResourceGetMappedArray(self.cu_tex, 0, 0))\n\n        CHECK_CUDART_ERROR(cudart.cudaMemcpy2DToArrayAsync(cu_tex_arr,\n                                                           x * 4 * ptr.itemsize,\n                                                           y,\n                                                           ptr.ctypes.data,\n                                                           w * 4 * ptr.itemsize,  # differently sized\n                                                           w * 4 * ptr.itemsize,  # rgba, should do a composition first\n                                                           h,\n                                                           kind,\n                                                           torch.cuda.current_stream().cuda_stream))\n        CHECK_CUDART_ERROR(cudart.cudaGraphicsUnmapResources(1, self.cu_tex, torch.cuda.current_stream"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not self.use_quad_cuda:\n            self.upload_to_texture(ptr)\n            return\n\n        if not hasattr(self, 'cu_tex'):\n            self.init_texture()\n\n        # assert self.use_quad_cuda, \"Need to enable cuda-opengl interop to copy from device to device, check creation of this Quad\"\n        w = w or self.W\n        h = h or self.H\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n        if ptr.shape[-1] == 3:\n            ptr = np.concatenate([ptr, np.ones((h, w, 1), dtype=ptr.dtype) * 255], axis=-1)  # add alpha channel\n        ptr = ptr.astype(np.uint8)\n\n        from cuda import cudart\n        kind = cudart.cudaMemcpyKind.cudaMemcpyHostToDevice\n        CHECK_CUDART_ERROR(cudart.cudaGraphicsMapResources(1, self.cu_tex, torch.cuda.current_stream().cuda_stream))\n        cu_tex_arr = CHECK_CUDART_ERROR(cudart.cudaGraphicsSubResourceGetMappedArray(self.cu_tex, 0, 0))\n\n        CHECK_CUDART_ERROR(cudart.cudaMemcpy2DToArrayAsync(cu_tex_arr,\n                                                           x * 4 * ptr.itemsize,\n                                                           y,\n                                                           ptr.ctypes.data,\n                                                           w * 4 * ptr.itemsize,  # differently sized\n                                                           w * 4 * ptr.itemsize,  # rgba, should do a composition first\n                                                           h,\n                                                           kind,\n                                                           torch.cuda.current_stream().cuda_stream))\n        CHECK_CUDART_ERROR(cudart.cudaGraphicsUnmapResources(1, self.cu_tex, tor"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not self.use_quad_cuda:\n            self.upload_to_texture(ptr)\n            return\n\n        if not hasattr(self, 'cu_tex'):\n            self.init_texture()\n\n        # assert self.use_quad_cuda, \"Need to enable cuda-opengl interop to copy from device to device, check creation of this Quad\"\n        w = w or self.W\n        h = h or self.H\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        from cuda import cudart\n        kind = cudart.cudaMemcpyKind.cudaMemcpyHostToDevice\n        CHECK_CUDART_ERROR(cudart.cudaGraphicsMapResources(1, self.cu_tex, torch.cuda.current_stream().cuda_stream))\n        cu_tex_arr = CHECK_CUDART_ERROR(cudart.cudaGraphicsSubResourceGetMappedArray(self.cu_tex, 0, 0))\n        CHECK_CUDART_ERROR(cudart.cudaMemcpy2DToArrayAsync(cu_tex_arr,\n                                                           x * 4 * ptr.itemsize,\n                                                           y,\n                                                           ptr.ctypes.data,\n                                                           w * 4 * ptr.itemsize,  # differently sized\n                                                           w * 4 * ptr.itemsize,  # rgba, should do a composition first\n                                                           h,\n                                                           kind,\n                                                           torch.cuda.current_stream().cuda_stream))\n        CHECK_CUDART_ERROR(cudart.cudaGraphicsUnmapResources(1, self.cu_tex, torch.cuda.current_stream().cuda_stream))\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not self.use_quad_cuda:\n            self.upload_to_texture(image)\n            return\n\n        if not hasattr(self, 'cu_tex'):\n            self.init_texture()\n\n        # assert self.use_quad_cuda, \"Need to enable cuda-opengl interop to copy from device to device, check creation of this Quad\"\n        w = w or self.W\n        h = h or self.H\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n        if ptr.shape[-1] == 3:\n            ptr = np.concatenate([ptr, np.ones((h, w, 1), dtype=ptr.dtype) * 255], axis=-1)  # add alpha channel\n        ptr = ptr.astype(np.uint8)\n\n        from cuda import cudart\n        kind = cudart.cudaMemcpyKind.cudaMemcpyHostToDevice\n        CHECK_CUDART_ERROR(cudart.cudaGraphicsMapResources(1, self.cu_tex, torch.cuda.current_stream().cuda_stream))\n        cu_tex_arr = CHECK_CUDART_ERROR(cudart.cudaGraphicsSubResourceGetMappedArray(self.cu_tex, 0, 0))\n\n        CHECK_CUDART_ERROR(cudart.cudaMemcpy2DToArrayAsync(cu_tex_arr,\n                                                           x * 4 * ptr.itemsize,\n                                                           y,\n                                                           ptr.ctypes.data,\n                                                           w * 4 * ptr.itemsize,  # differently sized\n                                                           w * 4 * ptr.itemsize,  # rgba, should do a composition first\n                                                           h,\n                                                           kind,\n                                                           torch.cuda.current_stream().cuda_stream))\n        CHECK_CUDART_ERROR(cudart.cudaGraphicsUnmapResources(1, self.cu_tex,"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not self.use_quad_cuda:\n            self.upload_to_texture(image)\n            return\n\n        if not hasattr(self, 'cu_tex'):\n            self.init_texture()\n\n        # assert self.use_quad_cuda, \"Need to enable cuda-opengl interop to copy from device to device, check creation of this Quad\"\n        w = w or self.W\n        h = h or self.H\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        from cuda import cudart\n        kind = cudart.cudaMemcpyKind.cudaMemcpyHostToDevice\n        CHECK_CUDART_ERROR(cudart.cudaGraphicsMapResources(1, self.cu_tex, torch.cuda.current_stream().cuda_stream))\n        cu_tex_arr = CHECK_CUDART_ERROR(cudart.cudaGraphicsSubResourceGetMappedArray(self.cu_tex, 0, 0))\n        CHECK_CUDART_ERROR(cudart.cudaMemcpy2DToArrayAsync(cu_tex_arr,\n                                                           x * 4 * ptr.itemsize,\n                                                           y,\n                                                           ptr.ctypes.data,\n                                                           w * 4 * ptr.itemsize,  # differently sized\n                                                           w * 4 * ptr.itemsize,  # rgba, should do a composition first\n                                                           h,\n                                                           kind,\n                                                           torch.cuda.current_stream().cuda_stream))\n        CHECK_CUDART_ERROR(cudart.cudaGraphicsUnmapResources(1, self.cu_tex, torch.cuda.current_stream().cuda_stream))\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not self.use_quad_cuda:\n            self.upload_to_texture(image)\n            return\n\n        if not hasattr(self, 'cu_tex'):\n            self.init_texture()\n\n        # assert self.use_quad_cuda, \"Need to enable cuda-opengl interop to copy from device to device, check creation of this Quad\"\n        w = w or self.W\n        h = h or self.H\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        from cuda import cudart\n        kind = cudart.cudaMemcpyKind.cudaMemcpyHostToDevice\n        CHECK_CUDART_ERROR(cudart.cudaGraphicsMapResources(1, self.cu_tex, torch.cuda.current_stream().cuda_stream))\n        cu_tex_arr = CHECK_CUDART_ERROR(cudart.cudaGraphicsSubResourceGetMappedArray(self.cu_tex, 0, 0))\n        CHECK_CUDART_ERROR(cudart.cudaMemcpy2DToArrayAsync(cu_tex_arr,\n                                                           x * 4 * ptr.itemsize,\n                                                           y,\n                                                           ptr,\n                                                           w * 4 * ptr.itemsize,  # differently sized\n                                                           w * 4 * ptr.itemsize,  # rgba, should do a composition first\n                                                           h,\n                                                           kind,\n                                                           torch.cuda.current_stream().cuda_stream))\n        CHECK_CUDART_ERROR(cudart.cudaGraphicsUnmapResources(1, self.cu_tex, torch.cuda.current_stream().cuda_stream))\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        # Convert to numpy array if it is a PyTorch tensor\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        # Convert to numpy array if it is a PyTorch tensor\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        # Convert to numpy array if it is a PyTorch tensor\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        # Convert to numpy array if it is a PyTorch tensor\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        # Convert to numpy array if it is a PyTorch tensor\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        # Convert to numpy array if it is a PyTorch tensor\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        # Convert to numpy array if it is a PyTorch tensor\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        # Convert to numpy array if it is a PyTorch tensor\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        # Convert to numpy array if it is a PyTorch tensor\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        # Convert to numpy array if it is a PyTorch tensor\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        # Convert to numpy array if it is a PyTorch tensor\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        # Convert to numpy array if it is a PyTorch tensor\n        if isinstance(ptr, torch."}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not self.use_quad_cuda:\n            self.upload_to_texture(ptr)\n            return\n\n        if not hasattr(self, 'cu_tex'):\n            self.init_texture()\n\n        # assert self.use_quad_cuda, \"Need to enable cuda-opengl interop to copy from device to device, check creation of this Quad\"\n        w = w or self.W\n        h = h or self.H\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        from cuda import cudart\n        kind = cudart.cudaMemcpyKind.cudaMemcpyDeviceToDevice\n        CHECK_CUDART_ERROR(cudart.cudaGraphicsMapResources(1, self.cu_tex, torch.cuda.current_stream().cuda_stream))\n        cu_tex_arr = CHECK_CUDART_ERROR(cudart.cudaGraphicsSubResourceGetMappedArray(self.cu_tex, 0, 0))\n        CHECK_CUDART_ERROR(cudart.cudaMemcpy2DToArrayAsync(cu_tex_arr,\n                                                           x * 4 * ptr.itemsize,\n                                                           y,\n                                                           ptr,\n                                                           w * 4 * ptr.itemsize,  # differently sized\n                                                           w * 4 * ptr.itemsize,  # rgba, should do a composition first\n                                                           h,\n                                                           kind,\n                                                           torch.cuda.current_stream().cuda_stream))\n        CHECK_CUDART_ERROR(cudart.cudaGraphicsUnmapResources(1, self.cu_tex, torch.cuda.current_stream().cuda_stream))\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not self.use_quad_cuda:\n            self.upload_to_texture(ptr)\n            return\n\n        if not hasattr(self, 'cu_tex'):\n            self.init_texture()\n\n        # assert self.use_quad_cuda, \"Need to enable cuda-opengl interop to copy from device to device, check creation of this Quad\"\n        w = w or self.W\n        h = h or self.H\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        from cuda import cudart\n        kind = cudart.cudaMemcpyKind.cudaMemcpyHostToDevice\n        CHECK_CUDART_ERROR(cudart.cudaGraphicsMapResources(1, self.cu_tex, torch.cuda.current_stream().cuda_stream))\n        cu_tex_arr = CHECK_CUDART_ERROR(cudart.cudaGraphicsSubResourceGetMappedArray(self.cu_tex, 0, 0))\n\n        CHECK_CUDART_ERROR(cudart.cudaMemcpy2DToArrayAsync(cu_tex_arr,\n                                                           x * 4 * ptr.itemsize,\n                                                           y,\n                                                           ptr.ctypes.data,\n                                                           w * 4 * ptr.itemsize,  # differently sized\n                                                           w * 4 * ptr.itemsize,  # rgba\n                                                           h,\n                                                           kind,\n                                                           torch.cuda.current_stream().cuda_stream))\n        CHECK_CUDART_ERROR(cudart.cudaGraphicsUnmapResources(1, self.cu_tex, torch.cuda.current_stream().cuda_stream))\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not self.use_quad_cuda:\n            self.upload_to_texture(ptr)\n            return\n\n        if not hasattr(self, 'cu_tex'):\n            self.init_texture()\n\n        # assert self.use_quad_cuda, \"Need to enable cuda-opengl interop to copy from device to device, check creation of this Quad\"\n        w = w or self.W\n        h = h or self.H\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        from cuda import cudart\n        kind = cudart.cudaMemcpyKind.cudaMemcpyHostToDevice\n        CHECK_CUDART_ERROR(cudart.cudaGraphicsMapResources(1, self.cu_tex, torch.cuda.current_stream().cuda_stream))\n        cu_tex_arr = CHECK_CUDART_ERROR(cudart.cudaGraphicsSubResourceGetMappedArray(self.cu_tex, 0, 0))\n        CHECK_CUDART_ERROR(cudart.cudaMemcpy2DToArrayAsync(cu_tex_arr,\n                                                           x * 4 * ptr.itemsize,\n                                                           y,\n                                                           ptr.ctypes.data,\n                                                           w * 4 * ptr.itemsize,  # differently sized\n                                                           w * 4 * ptr.itemsize,  # rgba, should do a composition first\n                                                           h,\n                                                           kind,\n                                                           torch.cuda.current_stream().cuda_stream))\n        CHECK_CUDART_ERROR(cudart.cudaGraphicsUnmapResources(1, self.cu_tex, torch.cuda.current_stream().cuda_stream))\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not self.use_quad_cuda:\n            self.upload_to_texture(ptr)\n            return\n\n        if not hasattr(self, 'cu_tex'):\n            self.init_texture()\n\n        # assert self.use_quad_cuda, \"Need to enable cuda-opengl interop to copy from device to device, check creation of this Quad\"\n        w = w or self.W\n        h = h or self.H\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n        ptr = np.ascontiguousarray(ptr)\n\n        from cuda import cudart\n        kind = cudart.cudaMemcpyKind.cudaMemcpyHostToDevice\n        CHECK_CUDART_ERROR(cudart.cudaGraphicsMapResources(1, self.cu_tex, torch.cuda.current_stream().cuda_stream))\n        cu_tex_arr = CHECK_CUDART_ERROR(cudart.cudaGraphicsSubResourceGetMappedArray(self.cu_tex, 0, 0))\n\n        CHECK_CUDART_ERROR(cudart.cudaMemcpy2DToArrayAsync(cu_tex_arr,\n                                                           x * 4 * ptr.itemsize,\n                                                           y,\n                                                           ptr.ctypes.data,\n                                                           w * 4 * ptr.itemsize,  # differently sized\n                                                           w * 4 * ptr.itemsize,  # rgba\n                                                           h,\n                                                           kind,\n                                                           torch.cuda.current_stream().cuda_stream))\n        CHECK_CUDART_ERROR(cudart.cudaGraphicsUnmapResources(1, self.cu_tex, torch.cuda.current_stream().cuda_stream))\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not self.use_quad_cuda:\n            self.upload_to_texture(ptr)\n            return\n\n        if not hasattr(self, 'cu_tex'):\n            self.init_texture()\n\n        # assert self.use_quad_cuda, \"Need to enable cuda-opengl interop to copy from device to device, check creation of this Quad\"\n        w = w or self.W\n        h = h or self.H\n\n        if isinstance(ptr, np.ndarray):\n            if ptr.dtype == np.uint8:\n                kind = cudart.cudaMemcpyKind.cudaMemcpyHostToDevice\n            elif ptr.dtype == np.float32:\n                kind = cudart.cudaMemcpyKind.cudaMemcpyHostToDevice\n            else:\n                raise RuntimeError(f'Unsupported data type: {ptr.dtype}')\n            buffer = to_cuda(ptr)\n        elif isinstance(ptr, torch.Tensor):\n            if ptr.dtype == torch.uint8:\n                kind = cudart.cudaMemcpyKind.cudaMemcpyHostToDevice\n            elif ptr.dtype == torch.float32:\n                kind = cudart.cudaMemcpyKind.cudaMemcpyHostToDevice\n            else:\n                raise RuntimeError(f'Unsupported data type: {ptr.dtype}')\n            buffer = to_cuda(ptr)\n        else:\n            raise RuntimeError(f'Unsupported data type: {type(ptr)}')\n\n        from cuda import cudart\n        CHECK_CUDART_ERROR(cudart.cudaGraphicsMapResources(1, self.cu_tex, torch.cuda.current_stream().cuda_stream))\n        cu_tex_arr = CHECK_CUDART_ERROR(cudart.cudaGraphicsSubResourceGetMappedArray(self.cu_tex, 0, 0))\n\n        CHECK_CUDART_ERROR(cudart.cudaMemcpy2DToArrayAsync(cu"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not self.use_quad_cuda:\n            self.upload_to_texture(ptr)\n            return\n\n        if not hasattr(self, 'cu_tex'):\n            self.init_texture()\n\n        # assert self.use_quad_cuda, \"Need to enable cuda-opengl interop to copy from device to device, check creation of this Quad\"\n        w = w or self.W\n        h = h or self.H\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        from cuda import cudart\n        kind = cudart.cudaMemcpyKind.cudaMemcpyHostToDevice\n        CHECK_CUDART_ERROR(cudart.cudaGraphicsMapResources(1, self.cu_tex, torch.cuda.current_stream().cuda_stream))\n        cu_tex_arr = CHECK_CUDART_ERROR(cudart.cudaGraphicsSubResourceGetMappedArray(self.cu_tex, 0, 0))\n        CHECK_CUDART_ERROR(cudart.cudaMemcpy2DToArrayAsync(cu_tex_arr,\n                                                           x * 4 * ptr.itemsize,\n                                                           y,\n                                                           ptr,\n                                                           w * 4 * ptr.itemsize,  # differently sized\n                                                           w * 4 * ptr.itemsize,  # rgba, should do a composition first\n                                                           h,\n                                                           kind,\n                                                           torch.cuda.current_stream().cuda_stream))\n        CHECK_CUDART_ERROR(cudart.cudaGraphicsUnmapResources(1, self.cu_tex, torch.cuda.current_stream().cuda_stream))\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not self.use_quad_cuda:\n            self.upload_to_texture(ptr)\n            return\n\n        if not hasattr(self, 'cu_tex'):\n            self.init_texture()\n\n        # assert self.use_quad_cuda, \"Need to enable cuda-opengl interop to copy from device to device, check creation of this Quad\"\n        w = w or self.W\n        h = h or self.H\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n        if ptr.shape[-1] == 3:\n            ptr = np.concatenate([ptr, np.ones((ptr.shape[0], ptr.shape[1], 1))], axis=-1) * 255\n        elif ptr.shape[-1] == 1:\n            ptr = np.concatenate([ptr, np.ones((ptr.shape[0], ptr.shape[1], 2))], axis=-1) * 255\n\n        from cuda import cudart\n        kind = cudart.cudaMemcpyKind.cudaMemcpyHostToDevice\n        CHECK_CUDART_ERROR(cudart.cudaGraphicsMapResources(1, self.cu_tex, torch.cuda.current_stream().cuda_stream))\n        cu_tex_arr = CHECK_CUDART_ERROR(cudart.cudaGraphicsSubResourceGetMappedArray(self.cu_tex, 0, 0))\n\n        CHECK_CUDART_ERROR(cudart.cudaMemcpy2DToArrayAsync(cu_tex_arr,\n                                                           x * 4 * ptr.itemsize,\n                                                           y,\n                                                           ptr.ctypes.data,\n                                                           w * 4 * ptr.itemsize,  # differently sized\n                                                           w * 4 * ptr.itemsize,  # rgba\n                                                           h,\n                                                           kind,\n                                                           torch.cuda.current_stream().cuda_stream"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        # Convert the input tensor to a numpy array\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        # If the width and height are not provided, use the default values\n        w = w or self.W\n        h = h or self.H\n\n        # Upload the texture to the GPU\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        # Convert the input data to a numpy array\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        # If width and height are not provided, use the object's default dimensions\n        w = w or self.W\n        h = h or self.H\n\n        # Upload the texture data to the GPU\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        # Convert PyTorch tensors to numpy arrays\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        # Default values\n        w = w or self.W\n        h = h or self.H\n\n        # Convert numpy arrays to PyTorch tensors\n        ptr = torch.as_tensor(ptr)\n\n        # Upload the texture to the GPU\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        # assert isinstance(ptr, np.ndarray), \"Only numpy arrays or PyTorch tensors can be uploaded to the texture\"\n        assert ptr.shape[-1] == 4, \"Only RGBA images are supported\"\n\n        w = w or self.W\n        h = h or self.H\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        w = w or self.W\n        h = h or self.H\n\n        # Convert the input to a numpy array if it is a PyTorch tensor\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        # Handle the case where the input is a grayscale image\n        if len(ptr.shape) == 2:\n            ptr = ptr[:, :, None]\n\n        # Flip the image along the y-axis\n        ptr = ptr[::-1]\n\n        # Convert the input to a float32 numpy array\n        ptr = ptr.astype(np.float32)\n\n        # Upload the data to the texture\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_FLOAT, ptr)\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    if not isinstance(R, torch.Tensor):\n        raise TypeError(f\"Expected input R to be of type torch.Tensor. Got {type(R)}\")\n    if not isinstance(tvec, torch.Tensor):\n        raise TypeError(f\"Expected input tvec to be of type torch.Tensor. Got {type(tvec)}\")\n    if not isinstance(camera_matrix, torch.Tensor):\n        raise TypeError(f\"Expected input camera_matrix to be of type torch.Tensor. Got {type(camera_matrix)}\")\n    if not isinstance(image_size, torch.Tensor):\n        raise TypeError(f\"Expected input image_size to be of type torch.Tensor. Got {type(image_size)}\")\n    if not isinstance(znear, float):\n        raise TypeError(f\"Expected input znear to be of type float. Got {type(znear)}\")\n\n    if R.device != tvec.device:\n        raise ValueError(f\"Expected input R and tvec to be on the same device. Got {R.device} and {tvec.device}.\")\n    if R.device != camera_matrix.device:\n        raise ValueError(\n            f\"Expected input R and camera_matrix to be on the same device. Got {R.device} and {camera_matrix.device}.\"\n        )\n    if R.device != image_size.device:\n        raise ValueError(\n            f\"Expected input R and image_size to be on the same device. Got {R.device} and {image_size.device}.\"\n        )\n    if R.dtype != tvec.dtype:\n        raise ValueError(f\"Expected input R and tvec to have the same dtype. Got {R.dtype} and {tvec.dtype}.\")\n    if R.dtype != camera_matrix.dtype:\n        raise ValueError(\n            f\"Expected input R and camera_matrix to have the same dtype. Got {R.dtype} and {camera_matrix.dtype}.\"\n        )\n    if"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    if not isinstance(R, torch.Tensor):\n        raise TypeError(f\"Expected input R to be of type torch.Tensor. Got {type(R)}\")\n    if not isinstance(tvec, torch.Tensor):\n        raise TypeError(f\"Expected input tvec to be of type torch.Tensor. Got {type(tvec)}\")\n    if not isinstance(camera_matrix, torch.Tensor):\n        raise TypeError(f\"Expected input camera_matrix to be of type torch.Tensor. Got {type(camera_matrix)}\")\n    if not isinstance(image_size, torch.Tensor):\n        raise TypeError(f\"Expected input image_size to be of type torch.Tensor. Got {type(image_size)}\")\n    if not isinstance(znear, float):\n        raise TypeError(f\"Expected input znear to be of type float. Got {type(znear)}\")\n\n    if R.device != tvec.device:\n        raise ValueError(f\"Expected R and tvec to be on the same device. Got {R.device} and {tvec.device}.\")\n    if R.device != camera_matrix.device:\n        raise ValueError(f\"Expected R and camera_matrix to be on the same device. Got {R.device} and {camera_matrix.device}.\")\n    if R.device != image_size.device:\n        raise ValueError(f\"Expected R and image_size to be on the same device. Got {R.device} and {image_size.device}.\")\n\n    if R.dtype != tvec.dtype:\n        raise ValueError(f\"Expected R and tvec to have the same dtype. Got {R.dtype} and {tvec.dtype}.\")\n    if R.dtype != camera_matrix.dtype:\n        raise ValueError(f\"Expected R and camera_matrix to have the same dtype. Got {R.dtype} and {camera_matrix.dtype}.\")\n    if R.dtype != image_size.dtype:\n        raise ValueError(f"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    if not isinstance(R, torch.Tensor):\n        raise TypeError(f\"Expected input R to be of type torch.Tensor. Got {type(R)} instead.\")\n    if not isinstance(tvec, torch.Tensor):\n        raise TypeError(f\"Expected input tvec to be of type torch.Tensor. Got {type(tvec)} instead.\")\n    if not isinstance(camera_matrix, torch.Tensor):\n        raise TypeError(f\"Expected input camera_matrix to be of type torch.Tensor. Got {type(camera_matrix)} instead.\")\n    if not isinstance(image_size, torch.Tensor):\n        raise TypeError(f\"Expected input image_size to be of type torch.Tensor. Got {type(image_size)} instead.\")\n    if not isinstance(znear, float):\n        raise TypeError(f\"Expected input znear to be of type float. Got {type(znear)} instead.\")\n\n    if R.ndim != 3 or R.shape[-2:] != (3, 3):\n        raise ValueError(f\"Expected input R to have the shape (N, 3, 3). Got {R.shape} instead.\")\n    if tvec.ndim != 2 or tvec.shape[-1] != 3:\n        raise ValueError(f\"Expected input tvec to have the shape (N, 3). Got {tvec.shape} instead.\")\n    if camera_matrix.ndim != 3 or camera_matrix.shape[-2:] != (3, 3):\n        raise ValueError(f\"Expected input camera_matrix to have the shape (N, 3, 3). Got {camera_matrix.shape} instead.\")\n    if image_size.ndim != 2 or image_size.shape[-1] != 2:\n        raise ValueError(f\"Expected input image_size to have the shape (N, 2). Got {image_size.shape} instead.\")\n\n    if R.shape[0] != tvec.shape[0] or tvec.shape[0] != camera_matrix.shape"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    if not isinstance(R, torch.Tensor):\n        raise TypeError(f\"Expected input R to be of type torch.Tensor. Got {type(R)}\")\n    if not isinstance(tvec, torch.Tensor):\n        raise TypeError(f\"Expected input tvec to be of type torch.Tensor. Got {type(tvec)}\")\n    if not isinstance(camera_matrix, torch.Tensor):\n        raise TypeError(f\"Expected input camera_matrix to be of type torch.Tensor. Got {type(camera_matrix)}\")\n    if not isinstance(image_size, torch.Tensor):\n        raise TypeError(f\"Expected input image_size to be of type torch.Tensor. Got {type(image_size)}\")\n\n    if R.shape[-2:] != (3, 3):\n        raise ValueError(f\"Expected input R to have shape (..., 3, 3). Got {R.shape}.\")\n    if tvec.shape[-1] != 3:\n        raise ValueError(f\"Expected input tvec to have shape (..., 3). Got {tvec.shape}.\")\n    if camera_matrix.shape[-2:] != (3, 3):\n        raise ValueError(f\"Expected input camera_matrix to have shape (..., 3, 3). Got {camera_matrix.shape}.\")\n    if image_size.shape[-1] != 2:\n        raise ValueError(f\"Expected input image_size to have shape (..., 2). Got {image_size.shape}.\")\n\n    if R.dtype != tvec.dtype != camera_matrix.dtype != image_size.dtype:\n        raise TypeError(\n            f\"Expected input R, tvec, camera_matrix, and image_size to have the same dtype. \"\n            f\"Got {R.dtype}, {tvec.dtype}, {camera_matrix.dtype}, {image_size.dtype}.\"\n        )\n    dtype = R.dtype\n\n    if not torch.all(image_size > 0"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate inputs\n    if not isinstance(R, torch.Tensor):\n        raise TypeError(f\"Expected input R to be of type torch.Tensor, but it is {type(R)}.\")\n    if not isinstance(tvec, torch.Tensor):\n        raise TypeError(f\"Expected input tvec to be of type torch.Tensor, but it is {type(tvec)}.\")\n    if not isinstance(camera_matrix, torch.Tensor):\n        raise TypeError(f\"Expected input camera_matrix to be of type torch.Tensor, but it is {type(camera_matrix)}.\")\n    if not isinstance(image_size, torch.Tensor):\n        raise TypeError(f\"Expected input image_size to be of type torch.Tensor, but it is {type(image_size)}.\")\n    if not isinstance(znear, float):\n        raise TypeError(f\"Expected input znear to be of type float, but it is {type(znear)}.\")\n\n    if R.dtype != torch.float32:\n        raise TypeError(f\"Expected input R to have dtype float32, but it is {R.dtype}.\")\n    if tvec.dtype != torch.float32:\n        raise TypeError(f\"Expected input tvec to have dtype float32, but it is {tvec.dtype}.\")\n    if camera_matrix.dtype != torch.float32:\n        raise TypeError(f\"Expected input camera_matrix to have dtype float32, but it is {camera_matrix.dtype}.\")\n    if image_size.dtype != torch.float32:\n        raise TypeError(f\"Expected input image_size to have dtype float32, but it is {image_size.dtype}.\")\n\n    if R.shape[-1] != 3 or R.shape[-2] != 3:\n        raise ValueError(f\"Expected input R to have shape (*, 3, 3), but it is {R.shape}.\")\n    if tvec.shape[-1] != 3:"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate arguments\n    if not isinstance(R, torch.Tensor):\n        raise TypeError(f\"Expected input R to be torch.Tensor. Got {type(R)}\")\n    if not isinstance(tvec, torch.Tensor):\n        raise TypeError(f\"Expected input tvec to be torch.Tensor. Got {type(tvec)}\")\n    if not isinstance(camera_matrix, torch.Tensor):\n        raise TypeError(f\"Expected input camera_matrix to be torch.Tensor. Got {type(camera_matrix)}\")\n    if not isinstance(image_size, torch.Tensor):\n        raise TypeError(f\"Expected input image_size to be torch.Tensor. Got {type(image_size)}\")\n    if not isinstance(znear, float):\n        raise TypeError(f\"Expected input znear to be float. Got {type(znear)}\")\n\n    # Ensure all inputs are batched\n    R = R.unsqueeze(0) if R.ndimension() == 2 else R\n    tvec = tvec.unsqueeze(0) if tvec.ndimension() == 1 else tvec\n    camera_matrix = camera_matrix.unsqueeze(0) if camera_matrix.ndimension() == 2 else camera_matrix\n    image_size = image_size.unsqueeze(0) if image_size.ndimension() == 1 else image_size\n\n    # Validate shapes\n    if R.shape[-2:] != (3, 3):\n        raise ValueError(f\"Expected input R to have shape (..., 3, 3). Got {R.shape}\")\n    if tvec.shape[-1] != 3:\n        raise ValueError(f\"Expected input tvec to have shape (..., 3). Got {tvec.shape}\")\n    if camera_matrix.shape[-2:] != (3, 3):\n        raise ValueError(f\"Expected input camera_matrix to have shape (..., 3, 3). Got {camera_matrix.shape}\")\n   "}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate the inputs\n    if not isinstance(R, torch.Tensor):\n        raise TypeError(f\"Expected input R to be of type torch.Tensor, got {type(R)}\")\n    if not isinstance(tvec, torch.Tensor):\n        raise TypeError(f\"Expected input tvec to be of type torch.Tensor, got {type(tvec)}\")\n    if not isinstance(camera_matrix, torch.Tensor):\n        raise TypeError(f\"Expected input camera_matrix to be of type torch.Tensor, got {type(camera_matrix)}\")\n    if not isinstance(image_size, torch.Tensor):\n        raise TypeError(f\"Expected input image_size to be of type torch.Tensor, got {type(image_size)}\")\n    if not isinstance(znear, float):\n        raise TypeError(f\"Expected input znear to be of type float, got {type(znear)}\")\n\n    # Ensure that all inputs are batched\n    if R.dim() == 2:\n        R = R[None]\n    if tvec.dim() == 1:\n        tvec = tvec[None]\n    if camera_matrix.dim() == 2:\n        camera_matrix = camera_matrix[None]\n    if image_size.dim() == 1:\n        image_size = image_size[None]\n\n    # Validate the shapes\n    if R.dim() != 3:\n        raise ValueError(f\"Expected input R to be of size Bx3x3, got {R.size()}\")\n    if tvec.size(1) != 3:\n        raise ValueError(f\"Expected input tvec to be of size Bx3, got {tvec.size()}\")\n    if camera_matrix.size(1) != 3 or camera_matrix.size(2) != 3:\n        raise ValueError(f\"Expected input camera_matrix to be of size Bx3x3, got {camera_matrix.size()}\")\n    if image_size.size(1) != "}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    if R.shape[-2:] != (3, 3):\n        raise ValueError(\n            \"Input R must be of shape (*, 3, 3), but got {}.\".format(R.shape)\n        )\n    if tvec.shape[-2:] != (3, 1):\n        raise ValueError(\n            \"Input tvec must be of shape (*, 3, 1), but got {}.\".format(tvec.shape)\n        )\n    if camera_matrix.shape[-2:] != (3, 3):\n        raise ValueError(\n            \"Input camera_matrix must be of shape (*, 3, 3), but got {}.\".format(\n                camera_matrix.shape\n            )\n        )\n    if image_size.shape[-1] != 2:\n        raise ValueError(\n            \"Input image_size must be of shape (*, 2), but got {}.\".format(\n                image_size.shape\n            )\n        )\n    if R.shape[:-2] != tvec.shape[:-2] or tvec.shape[:-2] != camera_matrix.shape[:-2]:\n        raise ValueError(\n            \"Inputs R, tvec, and camera_matrix must have the same batch size, but got {}, {}, {}.\".format(\n                R.shape[:-2], tvec.shape[:-2], camera_matrix.shape[:-2]\n            )\n        )\n    if image_size.shape[:-1] != tvec.shape[:-2]:\n        raise ValueError(\n            \"Inputs tvec and image_size must have the same batch size, but got {} and {}.\".format(\n                tvec.shape[:-2], image_size.shape[:-1]\n            )\n        )\n\n    # get focal length\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    if not torch.allclose(fx, fy, atol=0.01):\n        warn_once_about_pulsar_fxfy()\n    f = (fx +"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    assert R.shape[-2:] == (3, 3), \"Expected R to have shape (*, 3, 3), got %s\" % repr(R.shape)\n    assert tvec.shape[-2:] == (3, 1), \"Expected tvec to have shape (*, 3, 1), got %s\" % repr(tvec.shape)\n    assert camera_matrix.shape[-2:] == (3, 3), \"Expected camera_matrix to have shape (*, 3, 3), got %s\" % repr(\n        camera_matrix.shape\n    )\n    assert image_size.shape[-1] == 2, \"Expected image_size to have shape (*, 2), got %s\" % repr(image_size.shape)\n\n    # make sure all inputs are at least 1-dimensional\n    R = torch.atleast_1d(R)\n    tvec = torch.atleast_1d(tvec)\n    camera_matrix = torch.atleast_1d(camera_matrix)\n    image_size = torch.atleast_1d(image_size)\n\n    # make sure all inputs have same batch dimension\n    assert (\n        R.shape[0] == tvec.shape[0] == camera_matrix.shape[0] == image_size.shape[0]\n    ), \"Inconsistent batch dimension between R (%s), tvec (%s), camera_matrix (%s), and image_size (%s)\" % (\n        repr(R.shape),\n        repr(tvec.shape),\n        repr(camera_matrix.shape),\n        repr(image_size.shape),\n    )\n\n    # make sure all inputs have same device\n    assert (\n        R.device == tvec.device == camera_matrix.device == image_size.device\n    ), \"Inconsistent device between R (%s), tvec (%s), camera_matrix (%s), and image_size (%s)\" % (\n        repr(R.device),\n        repr(tvec.device),\n        repr(camera_matrix.device),"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    if not isinstance(R, torch.Tensor):\n        raise TypeError(f\"Expected input R to be of type torch.Tensor, but instead got {type(R)}.\")\n\n    if not isinstance(tvec, torch.Tensor):\n        raise TypeError(f\"Expected input tvec to be of type torch.Tensor, but instead got {type(tvec)}.\")\n\n    if not isinstance(camera_matrix, torch.Tensor):\n        raise TypeError(f\"Expected input camera_matrix to be of type torch.Tensor, but instead got {type(camera_matrix)}.\")\n\n    if not isinstance(image_size, torch.Tensor):\n        raise TypeError(f\"Expected input image_size to be of type torch.Tensor, but instead got {type(image_size)}.\")\n\n    if not (R.device == tvec.device == camera_matrix.device == image_size.device):\n        raise ValueError(\n            f\"Expected input tensors to have device {R.device}, but instead got R of device {R.device}, tvec of device {tvec.device}, camera_matrix of device {camera_matrix.device}, and image_size of device {image_size.device}.\"\n        )\n\n    if not (R.dtype == tvec.dtype == camera_matrix.dtype == image_size.dtype):\n        raise ValueError(\n            f\"Expected input tensors to have dtype {R.dtype}, but instead got R of dtype {R.dtype}, tvec of dtype {tvec.dtype}, camera_matrix of dtype {camera_matrix.dtype}, and image_size of dtype {image_size.dtype}.\"\n        )\n\n    if not (R.shape == tvec.shape and len(R.shape) == 3):\n        raise ValueError(\n            f\"Expected input R to have shape (B, 3, 3), but instead got {R.shape}.\"\n        )\n\n    if not (tvec.shape[1] == 3 and len(tvec.shape) == 3):"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    if not isinstance(R, torch.Tensor):\n        raise TypeError(f\"Expected input R to be of type torch.Tensor. Got {type(R)}\")\n\n    if not isinstance(tvec, torch.Tensor):\n        raise TypeError(f\"Expected input tvec to be of type torch.Tensor. Got {type(tvec)}\")\n\n    if not isinstance(camera_matrix, torch.Tensor):\n        raise TypeError(\n            f\"Expected input camera_matrix to be of type torch.Tensor. Got {type(camera_matrix)}\"\n        )\n\n    if not isinstance(image_size, torch.Tensor):\n        raise TypeError(\n            f\"Expected input image_size to be of type torch.Tensor. Got {type(image_size)}\"\n        )\n\n    if not (R.device == tvec.device == camera_matrix.device == image_size.device):\n        raise ValueError(\n            f\"Expected input tensors to have device {R.device}. Got {tvec.device}, {camera_matrix.device}, {image_size.device}\"\n        )\n\n    if R.shape[-2:] != (3, 3):\n        raise ValueError(f\"Expected R to have shape (*, 3, 3). Got {R.shape}\")\n\n    if tvec.shape[-2:] != (3, 1):\n        raise ValueError(f\"Expected tvec to have shape (*, 3, 1). Got {tvec.shape}\")\n\n    if camera_matrix.shape[-2:] != (3, 3):\n        raise ValueError(\n            f\"Expected camera_matrix to have shape (*, 3, 3). Got {camera_matrix.shape}\"\n        )\n\n    if image_size.shape[-1] != 2:\n        raise ValueError(f\"Expected image_size to have shape (*, 2). Got {image_size.shape}\")\n\n    # batch size\n    B = tvec.shape[0]\n\n    # camera center in world coordinates\n    cam_center"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    assert (\n        R.shape[-2:] == (3, 3)\n    ), f\"R must be of shape (*, 3, 3), but got {R.shape}\"\n    assert (\n        tvec.shape[-2:] == (3, 1)\n    ), f\"tvec must be of shape (*, 3, 1), but got {tvec.shape}\"\n    assert (\n        camera_matrix.shape[-2:] == (3, 3)\n    ), f\"camera_matrix must be of shape (*, 3, 3), but got {camera_matrix.shape}\"\n    assert (\n        image_size.shape[-1] == 2\n    ), f\"image_size must be of shape (*, 2), but got {image_size.shape}\"\n\n    # We need to ensure that all inputs are at least 2D.\n    R = R.unsqueeze(-3)\n    tvec = tvec.unsqueeze(-3)\n    camera_matrix = camera_matrix.unsqueeze(-3)\n    image_size = image_size.unsqueeze(-3)\n\n    # We need to ensure that all inputs have the same batch dimension.\n    assert (\n        R.shape[0] == tvec.shape[0]\n    ), f\"R and tvec must have the same batch dimension, but got {R.shape[0]} and {tvec.shape[0]}\"\n    assert (\n        R.shape[0] == camera_matrix.shape[0]\n    ), f\"R and camera_matrix must have the same batch dimension, but got {R.shape[0]} and {camera_matrix.shape[0]}\"\n    assert (\n        R.shape[0] == image_size.shape[0]\n    ), f\"R and image_size must have the same batch dimension, but got {R.shape[0]} and {image_size.shape[0]}\"\n\n    # We need to ensure that all inputs have the same number of batch dimensions.\n    if R.ndim == 2:\n        R = R.unsqueeze(0)\n        tvec"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    if R.shape[-2:] != (3, 3):\n        raise ValueError(\n            \"Input R must be a batch of 3x3 rotation matrices, but it is of shape {}.\".format(\n                R.shape\n            )\n        )\n    if tvec.shape[-1] != 3:\n        raise ValueError(\n            \"Input tvec must be a batch of translation vectors, but it is of shape {}.\".format(\n                tvec.shape\n            )\n        )\n    if camera_matrix.shape[-2:] != (3, 3):\n        raise ValueError(\n            \"Input camera_matrix must be a batch of 3x3 intrinsic matrices, but it is of shape {}.\".format(\n                camera_matrix.shape\n            )\n        )\n    if image_size.shape[-1] != 2:\n        raise ValueError(\n            \"Input image_size must be a batch of image sizes, but it is of shape {}.\".format(\n                image_size.shape\n            )\n        )\n\n    # Convert to pulsar camera convention.\n    R = R.transpose(-1, -2)\n    tvec = -R @ tvec[..., None]\n    R = R.transpose(-1, -2)\n    tvec = tvec[..., 0]\n\n    # Extract focal length and sensor width.\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    fxfy = (fx + fy) / 2\n    sensor_width = fxfy * 2\n    if not torch.allclose(fx, fy):\n        warn_once_about_pulsar_fxfy()\n\n    # Extract principal point.\n    px = camera_matrix[..., 0, 2]\n    py = camera_matrix[..., 1, 2]\n    px_py = (px + py) / 2\n\n    # Extract image size.\n    image_width = image_size[..., 0]\n    image_height = image_size[...,"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # validate inputs\n    assert R.shape[-2:] == (3, 3), \"R must have shape (*, 3, 3)\"\n    assert tvec.shape[-1] == 3, \"tvec must have shape (*, 3)\"\n    assert camera_matrix.shape[-2:] == (3, 3), \"camera_matrix must have shape (*, 3, 3)\"\n    assert image_size.shape[-1] == 2, \"image_size must have shape (*, 2)\"\n\n    # batch shapes\n    batch_shape = R.shape[:-2]\n    output_shape = (*batch_shape, 12)\n\n    # expand inputs\n    R = R.expand(output_shape)\n    tvec = tvec.expand(output_shape)\n    camera_matrix = camera_matrix.expand(output_shape)\n    image_size = image_size.expand(output_shape)\n\n    # camera position\n    cam_pos = -torch.bmm(R.transpose(-1, -2), tvec[..., None])[..., 0]\n\n    # camera rotation\n    rot = matrix_to_rotation_6d(R)\n\n    # camera intrinsics\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    fxfy = (fx + fy) / 2\n    if not torch.allclose(fx, fy):\n        warn_once_about_pulsar_fxfy()\n    fx = fxfy\n    fy = fxfy\n    px = camera_matrix[..., 0, 2]\n    py = camera_matrix[..., 1, 2]\n    sensor_width = (image_size[..., 0] / image_size[..., 1]) * fy * znear / fx\n\n    # normalize\n    focal_length = fx / (image_size[..., 0] / 2.0)\n    px = px / (image_size[..., 0] / 2.0)"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    if R.shape[-2:] != (3, 3):\n        raise ValueError(\"R must be of shape (*, 3, 3)!\")\n    if tvec.shape[-2:] != (3, 1):\n        raise ValueError(\"tvec must be of shape (*, 3, 1)!\")\n    if camera_matrix.shape[-2:] != (3, 3):\n        raise ValueError(\"camera_matrix must be of shape (*, 3, 3)!\")\n    if image_size.shape[-1] != 2:\n        raise ValueError(\"image_size must be of shape (*, 2)!\")\n    if R.shape[:-2] != tvec.shape[:-2] != camera_matrix.shape[:-2] != image_size.shape[:-1]:\n        raise ValueError(\"All inputs must have same batch dimension.\")\n\n    # Get focal length\n    fx = camera_matrix[:, 0, 0]\n    fy = camera_matrix[:, 1, 1]\n    fxfy = (fx + fy) / 2.0\n    if not torch.allclose(fx, fy, atol=1e-3):\n        warn_once_about_pulsar_fxfy()\n    f = fxfy.unsqueeze(-1)\n\n    # Get sensor width\n    sensor_width = (\n        (camera_matrix[:, 0, 0] + camera_matrix[:, 1, 1]) / 2.0\n    ) * image_size[..., 0]\n\n    # Get principal point\n    px = camera_matrix[:, 0, 2] * image_size[..., 0]\n    py = camera_matrix[:, 1, 2] * image_size[..., 1]\n    p = torch.stack([px, py], dim=-1)\n\n    # Get camera position\n    C = -R.transpose(-1, -2) @ tvec\n\n    # Get camera rotation\n    R = matrix_to_rotation_6d(R)\n\n    return torch.cat(["}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    assert R.shape[-2:] == (3, 3), \"Input R must be of shape (*, 3, 3)!\"\n    assert tvec.shape[-2:] == (3, 1), \"Input tvec must be of shape (*, 3, 1)!\"\n    assert camera_matrix.shape[-2:] == (3, 3), \"Input camera_matrix must be of shape (*, 3, 3)!\"\n    assert image_size.shape[-1] == 2, \"Input image_size must be of shape (*, 2)!\"\n    assert znear > 0, \"Input znear must be positive!\"\n\n    device = R.device\n    dtype = R.dtype\n\n    # Validate the inputs\n    R = R.double()\n    tvec = tvec.double()\n    camera_matrix = camera_matrix.double()\n    image_size = image_size.double()\n    znear = torch.tensor(znear, device=device, dtype=dtype)\n\n    # Compute the camera position\n    tvec = tvec.reshape(tvec.shape[:-2] + (3,))\n    cam_pos = -torch.bmm(R.transpose(-1, -2), tvec).reshape(tvec.shape[:-2] + (3,))\n\n    # Compute the camera rotation in a different representation\n    rot = matrix_to_rotation_6d(R)\n\n    # Compute the focal length\n    focal_length = camera_matrix[..., 0, 0]\n    focal_length = focal_length / (0.5 * image_size[..., 0])\n    focal_length = focal_length.unsqueeze(-1)\n\n    # Compute the sensor width\n    sensor_width = camera_matrix[..., 1, 1]\n    sensor_width = sensor_width / (0.5 * image_size[..., 1])\n    sensor_width = sensor_width.unsqueeze(-1)\n\n    # Compute the principal points\n    principal_point = camera_matrix[...,"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    assert R.shape == tvec.shape\n    assert R.shape[-2:] == (3, 3)\n    assert tvec.shape[-1] == 3\n    assert camera_matrix.shape == tvec.shape\n    assert camera_matrix.shape[-2:] == (3, 3)\n    assert image_size.shape == tvec.shape[:-1]\n    assert image_size.shape[-1] == 2\n\n    # Extract focal length and sensor width from camera intrinsic matrix\n    focal_length = camera_matrix[..., 0, 0]\n    sensor_width = camera_matrix[..., 1, 1] * image_size[..., 0]\n\n    # Adjust focal length by znear\n    focal_length = focal_length / znear\n\n    # Normalize focal length by image width\n    focal_length = focal_length / image_size[..., 0]\n\n    # Compute intrinsic parameters for pulsar\n    fx = focal_length\n    fy = focal_length\n    px = image_size[..., 0] / 2\n    py = image_size[..., 1] / 2\n\n    # Convert rotation matrix to 6D representation\n    rot = matrix_to_rotation_6d(R)\n\n    # Compute camera position\n    cam_pos = -torch.bmm(R.transpose(-1, -2), tvec[..., None])[..., 0]\n\n    # Compute camera parameters for pulsar\n    cam_params = torch.cat([cam_pos, rot, fx, fy, px, py], dim=-1)\n\n    return cam_params\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    assert (\n        R.shape[-2:] == (3, 3)\n    ), \"R must be of shape (*, 3, 3), where * is zero or more batch dimensions.\"\n    assert (\n        tvec.shape[-2:] == (3, 1)\n    ), \"tvec must be of shape (*, 3, 1), where * is zero or more batch dimensions.\"\n    assert (\n        camera_matrix.shape[-2:] == (3, 3)\n    ), \"camera_matrix must be of shape (*, 3, 3), where * is zero or more batch dimensions.\"\n    assert (\n        image_size.shape[-1] == 2\n    ), \"image_size must be of shape (*, 2), where * is zero or more batch dimensions.\"\n    assert (\n        znear > 0.0\n    ), \"znear must be positive.\"\n\n    # check batch shapes\n    assert (\n        R.shape[:-2] == tvec.shape[:-2]\n    ), \"R and tvec must have the same batch shape.\"\n    assert (\n        R.shape[:-2] == camera_matrix.shape[:-2]\n    ), \"R and camera_matrix must have the same batch shape.\"\n    assert (\n        R.shape[:-2] == image_size.shape[:-1]\n    ), \"R and image_size must have the same batch shape.\"\n\n    # check image_size\n    assert (\n        image_size.min() > 0.0\n    ).all(), \"image_size values must be positive.\"\n\n    # check camera matrix\n    # check that the camera matrix is square\n    assert (\n        camera_matrix.shape[-2] == camera_matrix.shape[-1]\n    ), \"camera_matrix must be a square matrix.\"\n    # check that the camera matrix is invertible\n    assert torch.allclose(\n        camera_matrix @ torch.inverse(camera_matrix),\n        torch.eye(3, device=camera_matrix.device, dtype=camera_matrix.dtype),\n        atol=1e-6,\n    ), \"camera_"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    if R.shape[-2:] != (3, 3):\n        raise ValueError(f\"R must be of shape (*, 3, 3), but got shape {R.shape}.\")\n    if tvec.shape[-2:] != (3, 1):\n        raise ValueError(f\"tvec must be of shape (*, 3, 1), but got shape {tvec.shape}.\")\n    if camera_matrix.shape[-2:] != (3, 3):\n        raise ValueError(f\"camera_matrix must be of shape (*, 3, 3), but got shape {camera_matrix.shape}.\")\n    if image_size.shape[-1] != 2:\n        raise ValueError(f\"image_size must be of shape (*, 2), but got shape {image_size.shape}.\")\n\n    if R.shape[:-2] != tvec.shape[:-2] or tvec.shape[:-2] != camera_matrix.shape[:-2] or camera_matrix.shape[:-2] != image_size.shape[:-1]:\n        raise ValueError(f\"R, tvec, camera_matrix, and image_size must have the same batch shape.\")\n\n    if not (camera_matrix[..., 0, 0] == camera_matrix[..., 1, 1]).all():\n        warn_once_about_pulsar_fxfy()\n\n    # Set up the camera parameters\n    # Camera position\n    camera_position = -torch.bmm(R.transpose(-1, -2), tvec).view(R.shape[:-2] + (3,))\n    # Camera rotation\n    camera_rotation = matrix_to_rotation_6d(R)\n    # Camera focal length\n    fx = camera_matrix[..., 0, 0].mean(-1, keepdim=True)\n    fy = camera_matrix[..., 1, 1].mean(-1, keepdim=True)\n    fx = fx / (image_size[..., 0] / 2.)\n    fy = fy / (image_size[..., 1]"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Ensure that all inputs are batched\n    batch_size = R.shape[0]\n    if R.ndim == 2:\n        R = R.unsqueeze(0)\n    if tvec.ndim == 1:\n        tvec = tvec.unsqueeze(0)\n    if camera_matrix.ndim == 2:\n        camera_matrix = camera_matrix.unsqueeze(0)\n    if image_size.ndim == 1:\n        image_size = image_size.unsqueeze(0)\n\n    # Validate the shapes of the inputs\n    assert R.shape[0] == tvec.shape[0] == camera_matrix.shape[0] == image_size.shape[0]\n    assert R.shape[1:3] == (3, 3)\n    assert tvec.shape[1] == 3\n    assert camera_matrix.shape[1:3] == (3, 3)\n    assert image_size.shape[1] == 2\n\n    # Validate the values of the inputs\n    assert torch.all(R.det() > 0)\n    assert torch.all(camera_matrix[:, 2, 2] > 0)\n    assert torch.all(image_size > 0)\n\n    # Compute the camera parameters\n    Rt = torch.cat([R, tvec], dim=-1)\n    K = camera_matrix[:, :3, :3]\n    Rt_K_inv = torch.inverse(Rt) @ torch.inverse(K)\n    focal_length = torch.sqrt(\n        (Rt_K_inv[..., 0, 0] ** 2 + Rt_K_inv[..., 1, 1] ** 2) / (Rt_K_inv[..., 2, 0] ** 2 + Rt_K_inv[..., 2, 1] ** 2)\n    )\n    sensor_width = 36.0 * (image_size / torch.Tensor([[[320"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.draw_blit(x, y, w, h)\n            return\n\n        w = w or self.W\n        h = h or self.H\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor_box = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n        gl.glUseProgram(self.quad_program)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n        gl.glBindVertexArray(0)\n        gl.glUseProgram(0)\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor_box)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.draw_blit(x, y, w, h)\n            return\n\n        w = w or self.W\n        h = h or self.H\n\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        gl.glUseProgram(self.quad_program)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n        gl.glBindVertexArray(0)\n\n        gl.glUseProgram(0)\n\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n            return\n\n        w = w or self.W\n        h = h or self.H\n\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        gl.glUseProgram(self.quad_program)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n        gl.glBindVertexArray(0)\n        gl.glUseProgram(0)\n\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n            return\n\n        w = w or self.W\n        h = h or self.H\n\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        gl.glUseProgram(self.quad_program)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n        gl.glBindVertexArray(0)\n\n        gl.glUseProgram(0)\n\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glBegin(gl.GL_QUADS)\n            gl.glTexCoord2f(0, 0)\n            gl.glVertex2f(x, y)\n            gl.glTexCoord2f(1, 0)\n            gl.glVertex2f(x + w, y)\n            gl.glTexCoord2f(1, 1)\n            gl.glVertex2f(x + w, y + h)\n            gl.glTexCoord2f(0, 1)\n            gl.glVertex2f(x, y + h)\n            gl.glEnd()\n            gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n            return\n\n        w = w or self.W\n        h = h or self.H\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, 0)\n        gl.glUseProgram(self.quad_program)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glUniform1i(self.uniforms.tex, 0)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n        gl.glBindVertexArray(0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n        gl.glUseProgram(0)\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.draw_blit(x, y, w, h)\n            return\n\n        w = w or self.W\n        h = h or self.H\n\n        # Set up a viewport and scissor box for rendering\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        # Activate a shader program\n        gl.glUseProgram(self.quad_program)\n\n        # Bind a texture\n        gl.glActiveTexture(gl.GL_TEXTURE0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Draw the quadrilateral\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        # Restore the viewport and scissor box to their original sizes\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.draw_blit(x, y, w, h)\n            return\n\n        w = w or self.W\n        h = h or self.H\n\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        gl.glUseProgram(self.quad_program)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n        gl.glBindVertexArray(0)\n\n        gl.glUseProgram(0)\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.draw_blit(x, y, w, h)\n            return\n\n        w = w or self.W\n        h = h or self.H\n\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        gl.glUseProgram(self.quad_program)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindVertexArray(self.vao)\n\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        gl.glBindVertexArray(0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n        gl.glUseProgram(0)\n\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glEnable(gl.GL_TEXTURE_2D)\n            gl.glBegin(gl.GL_QUADS)\n            gl.glTexCoord2f(0, 0)\n            gl.glVertex3f(x, y, 0)\n            gl.glTexCoord2f(1, 0)\n            gl.glVertex3f(x + w, y, 0)\n            gl.glTexCoord2f(1, 1)\n            gl.glVertex3f(x + w, y + h, 0)\n            gl.glTexCoord2f(0, 1)\n            gl.glVertex3f(x, y + h, 0)\n            gl.glEnd()\n            gl.glDisable(gl.GL_TEXTURE_2D)\n            return\n\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n        gl.glEnable(gl.GL_SCISSOR_TEST)\n        gl.glUseProgram(self.quad_program)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glUniform1i(gl.glGetUniformLocation(self.quad_program, 'tex'), 0)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n        gl.glBindVertexArray(0)\n        gl.glUseProgram(0)\n\n        gl.glDisable(gl.GL_SCISSOR_TEST)\n        gl.glViewport(*old_viewport)\n        gl."}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        w = w or self.W\n        h = h or self.H\n        if not self.use_quad_draw:\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glBegin(gl.GL_QUADS)\n            gl.glTexCoord2f(0, 0)\n            gl.glVertex2f(x, y)\n            gl.glTexCoord2f(1, 0)\n            gl.glVertex2f(x + w, y)\n            gl.glTexCoord2f(1, 1)\n            gl.glVertex2f(x + w, y + h)\n            gl.glTexCoord2f(0, 1)\n            gl.glVertex2f(x, y + h)\n            gl.glEnd()\n            return\n\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n        gl.glEnable(gl.GL_SCISSOR_TEST)\n        gl.glUseProgram(self.quad_program)\n        gl.glBindVertexArray(self.vao)\n        gl.glActiveTexture(gl.GL_TEXTURE0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glUniform1i(self.uniforms.tex, 0)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n        gl.glBindVertexArray(0)\n        gl.glUseProgram(0)\n        gl.glDisable(gl.GL_SCISSOR_TEST)\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.draw_blit(x, y, w, h)\n            return\n\n        w = w or self.W\n        h = h or self.H\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n        gl.glEnable(gl.GL_SCISSOR_TEST)\n\n        gl.glUseProgram(self.quad_program)\n        gl.glUniform1i(gl.glGetUniformLocation(self.quad_program, \"tex\"), 0)\n        gl.glActiveTexture(gl.GL_TEXTURE0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n        gl.glBindVertexArray(0)\n\n        gl.glUseProgram(0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n        gl.glBindVertexArray(0)\n        gl.glDisable(gl.GL_SCISSOR_TEST)\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glBegin(gl.GL_QUADS)\n            gl.glTexCoord2f(0, 0)\n            gl.glVertex2f(x, y)\n            gl.glTexCoord2f(1, 0)\n            gl.glVertex2f(x + w, y)\n            gl.glTexCoord2f(1, 1)\n            gl.glVertex2f(x + w, y + h)\n            gl.glTexCoord2f(0, 1)\n            gl.glVertex2f(x, y + h)\n            gl.glEnd()\n            return\n\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n        gl.glEnable(gl.GL_SCISSOR_TEST)\n\n        gl.glUseProgram(self.quad_program)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glUniform1i(gl.glGetUniformLocation(self.quad_program, 'tex'), 0)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n        gl.glBindVertexArray(0)\n\n        gl.glUseProgram(0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n        gl.glDisable(gl.GL_SCISSOR_TEST)\n\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.draw_blit(x, y, w, h)\n            return\n\n        w = w or self.W\n        h = h or self.H\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n        gl.glViewport(x, y, w, h)  # set viewport to quad size\n        gl.glScissor(x, y, w, h)  # set scissor to quad size\n\n        gl.glUseProgram(self.quad_program)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n        gl.glBindVertexArray(0)\n        gl.glUseProgram(0)\n\n        gl.glViewport(*old_viewport)  # restore viewport\n        gl.glScissor(*old_scissor)  # restore scissor\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.draw_blit(x, y, w, h)\n            return\n\n        w = w or self.W\n        h = h or self.H\n\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(0, 0, w, h)\n\n        gl.glUseProgram(self.quad_program)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n        gl.glBindVertexArray(0)\n\n        gl.glUseProgram(0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        w = w or self.W\n        h = h or self.H\n        if not self.use_quad_draw:\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glEnable(gl.GL_TEXTURE_2D)\n            gl.glBegin(gl.GL_QUADS)\n            gl.glTexCoord2f(0, 0)\n            gl.glVertex2f(x, y)\n            gl.glTexCoord2f(1, 0)\n            gl.glVertex2f(x + w, y)\n            gl.glTexCoord2f(1, 1)\n            gl.glVertex2f(x + w, y + h)\n            gl.glTexCoord2f(0, 1)\n            gl.glVertex2f(x, y + h)\n            gl.glEnd()\n            gl.glDisable(gl.GL_TEXTURE_2D)\n        else:\n            old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n            old_scissor_box = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n            gl.glUseProgram(self.quad_program)\n            gl.glBindVertexArray(self.vao)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glViewport(x, y, w, h)\n            gl.glScissor(x, y, w, h)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n            gl.glBindVertexArray(0)\n            gl.glUseProgram(0)\n            gl.glViewport(*old_viewport)\n            gl.glScissor(*old_scissor_box)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glEnable(gl.GL_BLEND)\n            gl.glBlendFunc(gl.GL_SRC_ALPHA, gl.GL_ONE_MINUS_SRC_ALPHA)\n            gl.glBlitFramebuffer(x, y, w or self.W, h or self.H, 0, 0, self.W, self.H, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n            return\n\n        # Set up a specific viewport and scissor box for rendering\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n        gl.glViewport(x, y, w or self.W, h or self.H)\n        gl.glScissor(x, y, w or self.W, h or self.H)\n\n        # Activate a shader program\n        gl.glUseProgram(self.quad_program)\n\n        # Bind a texture\n        gl.glActiveTexture(gl.GL_TEXTURE0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Draw the quadrilateral using vertex data\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n        gl.glBindVertexArray(0)\n\n        # Restore the viewport and scissor box to their original sizes\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glBegin(gl.GL_QUADS)\n            gl.glTexCoord2f(0, 0)\n            gl.glVertex3f(x, y, -0.5)\n            gl.glTexCoord2f(1, 0)\n            gl.glVertex3f(x + w, y, -0.5)\n            gl.glTexCoord2f(1, 1)\n            gl.glVertex3f(x + w, y + h, -0.5)\n            gl.glTexCoord2f(0, 1)\n            gl.glVertex3f(x, y + h, -0.5)\n            gl.glEnd()\n            return\n\n        gl.glUseProgram(self.quad_program)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindVertexArray(self.vao)\n\n        # Set up viewport and scissor box\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        # Draw\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        # Restore viewport and scissor box\n        gl.glScissor(*old_scissor)\n        gl.glViewport(*old_viewport)\n\n        gl.glBindVertexArray(0)\n        gl.glUseProgram(0)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glEnable(gl.GL_BLEND)\n            gl.glBlendFunc(gl.GL_SRC_ALPHA, gl.GL_ONE_MINUS_SRC_ALPHA)\n            gl.glBlitFramebuffer(x, y, w, h, 0, 0, self.W, self.H, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n            gl.glDisable(gl.GL_BLEND)\n            return\n\n        w = w or self.W\n        h = h or self.H\n\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        gl.glUseProgram(self.quad_program)\n        gl.glUniform1i(gl.glGetUniformLocation(self.quad_program, 'tex'), 0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n        gl.glBindVertexArray(0)\n        gl.glUseProgram(0)\n\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n            return\n\n        w = w or self.W\n        h = h or self.H\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glViewport(x, y, w, h)\n\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n        gl.glScissor(x, y, w, h)\n\n        gl.glUseProgram(self.quad_program)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        gl.glBindVertexArray(0)\n        gl.glUseProgram(0)\n\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            # This is a fallback method, which is not as accurate as the method below.\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glBegin(gl.GL_QUADS)\n            gl.glTexCoord2f(0, 0)\n            gl.glVertex2f(x, y)\n            gl.glTexCoord2f(1, 0)\n            gl.glVertex2f(x + w, y)\n            gl.glTexCoord2f(1, 1)\n            gl.glVertex2f(x + w, y + h)\n            gl.glTexCoord2f(0, 1)\n            gl.glVertex2f(x, y + h)\n            gl.glEnd()\n            return\n\n        w = w or self.W\n        h = h or self.H\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        gl.glUseProgram(self.quad_program)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n        gl.glBindVertexArray(0)\n\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor)\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R.mT  # !: transpose\n    T = -batch.R.mT @ batch.T  # !: transpose\n    C = -batch.R.mT @ batch.T  # !: transpose\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    # Adjust R and T to match PyTorch3D's conventions\n    R = R.mT\n    T = -R @ C\n    # Recalculate K for NDC\n    K = K.clone()\n    K[..., 0, 0] = 2.0 / W\n    K[..., 1, 1] = 2.0 / H\n    K[..., 0, 2] = -1.0\n    K[..., 1, 2] = -1.0\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    # Adjust R and T to match PyTorch3D's requirements\n    R = R.mT\n    T = -R @ C\n    # Recalculate K for NDC\n    K = K.clone()\n    K[:, :2, :3] = K[:, :2, :3] / W * 2.0\n    K[:, :2, 2] = -K[:, :2, 2]\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    # Adjust R and T to match PyTorch3D's coordinate system.\n    R = R.mT\n    T = -R @ C\n    # Recalculate K for NDC.\n    K = K.clone()\n    K[:, 0, 0] = K[:, 0, 0] / W\n    K[:, 1, 1] = K[:, 1, 1] / H\n    K[:, 0, 2] = 0.0\n    K[:, 1, 2] = 0.0\n    K[:, 2, 0] = 0.0\n    K[:, 2, 1] = 0.0\n    K[:, 2, 2] = 1.0\n    K[:, 0, 1] = 0.0\n    K[:, 0, 2] = 0.0\n    K[:, 1, 0] = 0.0\n    K[:, 1, 2] = 0.0\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    # R and T are applied on the right (requires a transposed R from OpenCV camera format)\n    # Coordinate system is different from that of OpenCV (cv: right down front, 3d: left up front)\n    # However, the correction has to be down on both T and R... (instead of just R)\n    R = R.permute(0, 2, 1)\n    T = -R @ T\n    # Compute the intrinsic matrix for NDC\n    K = torch.cat(\n        [\n            K[:, 0:1, :] / (W / 2),\n            K[:, 1:2, :] / (H / 2),\n            K[:, 2:3, :] / (W / 2),\n            K[:, 3:4, :] / (H / 2),\n        ],\n        dim=1,\n    )\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    # Adjust R and T to match PyTorch3D's conventions.\n    R = R.permute(0, 2, 1)\n    T = -R @ C\n    # Recalculate K for NDC.\n    K = torch.cat(\n        [\n            K[:, 0:1, :] / (W / 2),\n            K[:, 1:2, :] / (H / 2),\n            K[:, 2:3, :] / 2,\n            K[:, 3:4, :] / 1,\n        ],\n        dim=1,\n    )\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    # Convert to pytorch3d camera format\n    # R and T are applied on the right (requires a transposed R from OpenCV camera format)\n    # Coordinate system is different from that of OpenCV (cv: right down front, 3d: left up front)\n    # However, the correction has to be down on both T and R... (instead of just R)\n    R = R.mT\n    T = -R @ T\n    K = torch.cat([K[:, 0:2, :] / K[:, 0, 0:1], K[:, 2:3, :]], dim=1)  # adjust K for NDC\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    # Adjust for coordinate system and camera convention.\n    R = R.permute(0, 2, 1)  # B, 3, 3\n    T = T.mT  # B, 1, 3\n    # Adjust intrinsic matrix for NDC.\n    K = K.clone()\n    K[:, 0, 0] = K[:, 0, 0] / W\n    K[:, 1, 1] = K[:, 1, 1] / H\n    K[:, 0, 2] = 2 * K[:, 0, 2] / W - 1\n    K[:, 1, 2] = 2 * K[:, 1, 2] / H - 1\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    # Adjust R and T to match PyTorch3D's conventions.\n    R = R.mT\n    T = -R @ C\n    # Recalculate the intrinsic matrix for NDC.\n    K = get_ndc_camera_params(H, W, K)\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    # Adjust R and T to match PyTorch3D's conventions.\n    R = R.mT\n    T = -R @ C\n    # Recalculate K to match PyTorch3D's conventions.\n    K = get_ndc_camera_params(H, W, 1.0, 1.0)[1]\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    # Adjust R and T to PyTorch3D's coordinate system.\n    R = R.permute(0, 2, 1)\n    T = -R @ C\n    # Recalculate K for NDC.\n    K = torch.cat(\n        [\n            K[:, 0:1, :] / W * 2.0,\n            K[:, 1:2, :] / H * 2.0,\n            torch.ones_like(K[:, :1, :])\n            - 2.0 * K[:, 0:1, :] / W,\n            -torch.ones_like(K[:, :1, :])\n            + 2.0 * K[:, 1:2, :] / H,\n            K[:, 2:3, :],\n        ],\n        dim=1,\n    )\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    # Adjust R and T to match PyTorch3D's coordinate system and conventions.\n    R = R.mT\n    T = -R @ C\n    # Recalculate K to match PyTorch3D's coordinate system and conventions.\n    K = torch.stack(\n        [\n            K[:, 0, 0] / W,\n            K[:, 1, 1] / H,\n            -K[:, 0, 2] / W,\n            -K[:, 1, 2] / H,\n        ],\n        dim=-1,\n    ).reshape(-1, 4, 4)\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    # Adjust R and T to match PyTorch3D's requirements\n    R = R.permute(0, 2, 1)  # R: B, 3, 3\n    T = T.mT  # T: B, 3, 1\n    # Recalculate K for NDC\n    focal_length = K[:, 0, 0]\n    sensor_width = K[:, 1, 1]\n    cx = K[:, 0, 2]\n    cy = K[:, 1, 2]\n    focal_length_px = focal_length / W\n    f = (focal_length_px * W) / (0.5 * W - cx)\n    cx = -(cx - W / 2)\n    cy = cy - H / 2\n    K = torch.zeros_like(K)\n    K[:, 0, 0] = f\n    K[:, 1, 1] = f\n    K[:, 0, 2] = cx\n    K[:, 1, 2] = cy\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R.mT\n    T = -batch.R.mT @ batch.T\n    C = batch.C\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    # Adjust R and T to match PyTorch3D's coordinate system and conventions.\n    # 1. Adjust R to match PyTorch3D's coordinate system and conventions.\n    R = R.permute(0, 2, 1)  # (B, 3, 3) -> (B, 3, 3)\n    # 2. Adjust T to match PyTorch3D's coordinate system and conventions.\n    T = T.permute(0, 2, 1)  # (B, 3, 1) -> (B, 1, 3)\n    T = -torch.bmm(R, T)  # (B, 3, 3) @ (B, 3, 1) -> (B, 3, 1)\n    # Compute the camera center in the camera's coordinate system.\n    C = -R.permute(0, 2, 1) @ T  # (B, 3, 3) -> (B, 3, 3)\n    # Compute the intrinsic matrix for NDC.\n    K = get_ndc_camera_params(H, W, K)\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    # Adjust R and T to match PyTorch3D's conventions.\n    # R: OpenCV to PyTorch3D: rotate around x by 180 deg (pi radians)\n    # T: OpenCV to PyTorch3D: negate x and y\n    R = R.rotation_around_x(torch.tensor(np.pi))\n    T[..., 0] *= -1\n    T[..., 1] *= -1\n    # Compute the intrinsic matrix for NDC.\n    # K: PyTorch3D to OpenCV: swap y and z axes, negate x and y axes\n    K = K.clone()\n    K[..., 0, 0] *= -1\n    K[..., 1, 1] *= -1\n    K[..., 0, 1] = 0\n    K[..., 1, 0] = 0\n    K[..., 0, 2] = W / 2\n    K[..., 1, 2] = H / 2\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R.mT\n    T = -batch.R.mT @ batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    R = R.permute(0, 2, 1)  # B, 3, 3\n    T = T.mT  # B, 3\n    K = get_ndc_camera_params(H, W, K)\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    # Adjust for PyTorch3D's coordinate system.\n    # Flip the axes of the translation and rotation matrices.\n    R = R.flip(-1)\n    T = T.flip(-1)\n    # Flip the axis of the focal length.\n    K[..., 0] *= -1\n    # Compute the adjusted intrinsic matrix.\n    K = get_ndc_camera_params(H, W, K)[0]\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        old_fbo = gl.glGetInteger(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(0, 0, self.W, self.H, x, y, w, h, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_fbo)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        _, _, W, H = gl.glGetIntegerv(gl.GL_VIEWPORT)\n\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)\n        gl.glBlitFramebuffer(x, y, w, h, x, y, w, h, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, 0)\n\n        gl.glViewport(0, 0, W, H)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        _, _, W, H = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)  # only render in this small region of the viewport\n\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(0, 0, self.W, self.H, 0, 0, w, h, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, 0)\n\n        # Some house keepings\n        gl.glViewport(0, 0, W, H)\n        gl.glScissor(0, 0, W, H)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        _, _, W, H = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)  # only render in this small region of the viewport\n\n        # Temporarily bind the Quad instance's framebuffer object (FBO) as the read framebuffer\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)\n\n        # Perform the pixel copy operation\n        gl.glBlitFramebuffer(0, 0, w, h, 0, 0, w, h, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n\n        # Restore the previously bound read framebuffer\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, 0)\n\n        # Some house keeping\n        gl.glViewport(0, 0, W, H)\n        gl.glScissor(0, 0, W, H)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n\n        old_read_fbo = gl.glGetIntegerv(gl.GL_READ_FRAMEBUFFER_BINDING)\n        old_draw_fbo = gl.glGetIntegerv(gl.GL_DRAW_FRAMEBUFFER_BINDING)\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glReadBuffer(gl.GL_COLOR_ATTACHMENT0)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, old_read_fbo)\n        gl.glDrawBuffer(gl.GL_BACK)\n        gl.glBlitFramebuffer(x, y, w, h, x, y, w, h, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_read_fbo)\n        gl.glDrawFramebuffer(old_draw_fbo)\n        gl.glViewport(old_viewport)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        _, _, W, H = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)  # only render in this small region of the viewport\n\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)\n        gl.glBlitFramebuffer(0, 0, w, h, 0, 0, w, h, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, 0)\n\n        # Some house keepings\n        gl.glViewport(0, 0, W, H)\n        gl.glScissor(0, 0, W, H)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        _, _, W, H = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glReadBuffer(gl.GL_COLOR_ATTACHMENT0)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)\n        gl.glDrawBuffer(gl.GL_BACK)\n        gl.glBlitFramebuffer(x, y, w, h, 0, 0, W, H, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, 0)\n        gl.glReadBuffer(gl.GL_COLOR_ATTACHMENT0)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)\n        gl.glDrawBuffer(gl.GL_BACK)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        _, _, W, H = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)\n        gl.glBlitFramebuffer(x, y, w, h, x, y, w, h, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, 0)\n        gl.glViewport(0, 0, W, H)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        old_read_fbo = gl.glGetIntegerv(gl.GL_READ_FRAMEBUFFER_BINDING)\n        old_draw_fbo = gl.glGetIntegerv(gl.GL_DRAW_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, old_draw_fbo)\n        gl.glBlitFramebuffer(x, y, w, h, x, y, w, h, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_read_fbo)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        _, _, W, H = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)  # only render in this small region of the viewport\n\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)  # bind the fbo for reading\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)  # bind the default fbo for writing\n\n        gl.glBlitFramebuffer(0, 0, self.W, self.H,  # source rectangle\n                             0, 0, w, h,  # destination rectangle\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, 0)\n\n        # Some house keepings\n        gl.glViewport(0, 0, W, H)\n        gl.glScissor(0, 0, W, H)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        old = gl.glGetInteger(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(0, 0, self.W, self.H, x, y, w, h, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        old_fbo = gl.glGetInteger(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)  # read buffer defaults to 0\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, old_fbo)\n        gl.glBlitFramebuffer(x, y, w, h, x, y, w, h, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # to gpu, might slow down?\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_fbo)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        _, _, W, H = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)  # only render in this small region of the viewport\n\n        # Temporarily bind the Quad instance's framebuffer object (FBO) as the read framebuffer\n        old = gl.glGetInteger(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n\n        # Perform the pixel copy operation\n        gl.glBlitFramebuffer(0, 0, self.W, self.H,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_LINEAR)\n\n        # Restore the previously bound read framebuffer\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old)\n\n        # Some house keeping\n        gl.glViewport(0, 0, W, H)\n        gl.glScissor(0, 0, W, H)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n\n        old_read_fb = gl.glGetInteger(gl.GL_READ_FRAMEBUFFER_BINDING)\n        old_draw_fb = gl.glGetInteger(gl.GL_DRAW_FRAMEBUFFER_BINDING)\n\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, old_draw_fb)\n        gl.glBlitFramebuffer(x, y, x + w, y + h, x, y, x + w, y + h, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_read_fb)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, old_draw_fb)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        old_fbo = gl.glGetInteger(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)  # read buffer defaults to 0\n        gl.glBlitFramebuffer(0, 0, self.W, self.H, x, y, w, h, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # to gpu, might slow down?\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_fbo)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        # Ensure that the dimensions of the pixel block to be copied are valid\n        w = w or self.W\n        h = h or self.H\n\n        # Temporarily bind the Quad instance's framebuffer object (FBO) as the read framebuffer\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n\n        # Copy the pixel block\n        gl.glBlitFramebuffer(x, y, x + w, y + h, x, y, x + w, y + h, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n\n        # Restore the previously bound read framebuffer\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, 0)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        _, _, W, H = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)  # only render in this small region of the viewport\n\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)  # temporarily bind the FBO as the read FBO\n        gl.glBlitFramebuffer(0, 0, w, h, 0, 0, w, h, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # perform the pixel copy operation\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, 0)  # restore the previous read FBO\n\n        gl.glViewport(0, 0, W, H)\n        gl.glScissor(0, 0, W, H)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        old_fbo = gl.glGetIntegerv(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(x, y, x + w, y + h, x, y, x + w, y + h, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_fbo)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        old_fbo = gl.glGetInteger(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(0, 0, self.W, self.H, x, y, w, h, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_fbo)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        # Set the dimensions of the pixel block to be copied\n        w = w or self.W\n        h = h or self.H\n\n        # Get the currently bound read framebuffer\n        old_read_fbo = gl.glGetIntegerv(gl.GL_READ_FRAMEBUFFER_BINDING)\n\n        # Temporarily bind the Quad instance's FBO as the read framebuffer\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n\n        # Copy the pixel block to the currently bound draw framebuffer\n        gl.glBlitFramebuffer(x, y, x + w, y + h, x, y, x + w, y + h, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n\n        # Restore the previously bound read framebuffer\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_read_fbo)\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # check if t0 is a scalar\n    if t0.ndim == 0:\n        t0 = t0.unsqueeze(0)\n\n    # check if t1 is a scalar\n    if t1.ndim == 0:\n        t1 = t1.unsqueeze(0)\n\n    # check if y1 is a scalar\n    if y1.ndim == 0:\n        y1 = y1.unsqueeze(0)\n\n    # check if t0 and t1 have the same shape\n    if t0.shape != t1.shape:\n        raise ValueError(\"t0 and t1 must have the same shape.\")\n\n    # check if t0 and y1 have the same shape\n    if t0.shape != y1.shape:\n        raise ValueError(\"t0 and y1 must have the same shape.\")\n\n    # check if t0 and t1 are sorted\n    if not torch.all(t0[:-1] <= t0[1:]):\n        raise ValueError(\"t0 must be sorted.\")\n\n    # check if t1 and t1 are sorted\n    if not torch.all(t1[:-1] <= t1[1:]):\n        raise ValueError(\"t1 must be sorted.\")\n\n    # check if t0 and t1 have the same number of elements\n    if t0.numel() != t1.numel():\n        raise ValueError(\"t0 and t1 must have the same number of elements.\")\n\n    # check if t0 and y1 have the same number of elements\n    if t0.numel() != y1.numel():\n        raise ValueError(\"t0 and y1 must have the same number of elements.\")\n\n    # check if t0 and t1 have the same number of dimensions\n    if t0.ndim != t1.ndim:\n        raise ValueError(\"t0 and t1 must have the same number of dimensions.\")\n\n    # check if t0 and y1 have the same number of dimensions\n    if t0.ndim != y1.ndim:\n        raise ValueError(\"t0 and y1 must have the same"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    t0 = t0.view(-1, 1)\n    t1 = t1.view(-1, 1)\n\n    # Compute the inner measure\n    inner = torch.sum((t1 - t0) * y1, dim=0) / torch.sum((t1 - t0) * (t1 - t0), dim=0)\n\n    # Compute the outer measure\n    outer = torch.sum((t0 - t1) * y1, dim=0) / torch.sum((t0 - t1) * (t0 - t1), dim=0)\n\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    t1 = t1.to(t0.device)\n    y1 = y1.to(t0.device)\n\n    # Construct the inner and outer measures\n    inner = torch.sum((t1 - t0) * y1)\n    outer = torch.sum(y1)\n\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Compute the difference between the source and target times\n    dt = t0 - t1\n\n    # Compute the outer measure\n    y0_outer = y1 - 0.5 * dt * (y1[..., 2:, :] - y1[..., :-2, :])\n\n    # Compute the inner measure\n    y0_inner = y1 + 0.5 * dt * (y1[..., 2:, :] - y1[..., :-2, :])\n\n    return y0_inner, y0_outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Check that t0 is a tensor\n    if not torch.is_tensor(t0):\n        raise TypeError(\"t0 must be a tensor.\")\n\n    # Check that t1 is a tensor\n    if not torch.is_tensor(t1):\n        raise TypeError(\"t1 must be a tensor.\")\n\n    # Check that y1 is a tensor\n    if not torch.is_tensor(y1):\n        raise TypeError(\"y1 must be a tensor.\")\n\n    # Check that t0 and t1 are single-dimensional tensors\n    if len(t0.shape) != 1:\n        raise ValueError(\"t0 must be a single-dimensional tensor.\")\n    if len(t1.shape) != 1:\n        raise ValueError(\"t1 must be a single-dimensional tensor.\")\n\n    # Check that t0 and t1 have the same number of elements\n    if t0.shape[0] != t1.shape[0]:\n        raise ValueError(\"t0 and t1 must have the same number of elements.\")\n\n    # Check that t0 and t1 are sorted in ascending order\n    if not torch.all(t0[1:] > t0[:-1]):\n        raise ValueError(\"t0 must be sorted in ascending order.\")\n    if not torch.all(t1[1:] > t1[:-1]):\n        raise ValueError(\"t1 must be sorted in ascending order.\")\n\n    # Check that t0 and t1 have the same number of elements\n    if t0.shape[0] != y1.shape[0]:\n        raise ValueError(\"t0 and y1 must have the same number of elements.\")\n\n    # Check that t0 and t1 are single-dimensional tensors\n    if len(y1.shape) != 1:\n        raise ValueError(\"y1 must be a single-dimensional tensor.\")\n\n    # Check that t0 and t1 are monotonically increasing\n    if not torch.all(t0[1:] > t0[:-1]):\n        raise ValueError(\"t0 must be monotonically increasing.\")\n    if not torch.all(t1"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Compute the differences between the source and target times\n    t1_minus_t0 = t1 - t0\n    t0_minus_t1 = t0 - t1\n\n    # Compute the differences between the source and target values\n    y1_minus_y0 = y1[:, 1:, :] - y1[:, :-1, :]\n    y0_minus_y1 = y1[:, :-1, :] - y1[:, 1:, :]\n\n    # Compute the differences between the source and target times\n    t1_minus_t0_minus_1 = t1_minus_t0[:, 1:, :] - t1_minus_t0[:, :-1, :]\n    t0_minus_t1_minus_1 = t0_minus_t1[:, :-1, :] - t0_minus_t1[:, 1:, :]\n\n    # Compute the inner measure\n    y0_minus_y1_div_t0_minus_t1 = y0_minus_y1 / t0_minus_t1_minus_1\n    y0_minus_y1_div_t0_minus_t1_times_t1_minus_t0 = y0_minus_y1_div_t0_minus_t1 * t1_minus_t0_minus_1\n    y0_minus_y1_div_t0_minus_t1_times_t1_minus_t0_plus_y1 = y0_minus_y1_div_t0_minus_t1_times_t1_minus_t0 + y1[:, :-1, :]\n    y0_div_t0_minus_t1_plus_y1_minus_y0_div_t0_minus_t1_times_t1_minus_t0 = y1[:, :-1, :] - y0_minus_y1_div_t0_minus_t1 * t0_minus_t1\n    y0_div_t0_minus_t1_plus_y1_minus"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Compute the inner measure\n    inner = torch.zeros_like(t0)\n    for i in range(t0.shape[0]):\n        if t0[i] < t1[0]:\n            inner[i] = y1[0]\n        elif t0[i] > t1[-1]:\n            inner[i] = y1[-1]\n        else:\n            idx = searchsorted(t1, t0[i])\n            inner[i] = y1[idx - 1] + (y1[idx] - y1[idx - 1]) * (t0[i] - t1[idx - 1]) / (t1[idx] - t1[idx - 1])\n\n    # Compute the outer measure\n    outer = torch.zeros_like(t0)\n    for i in range(t0.shape[0]):\n        if t0[i] < t1[0]:\n            outer[i] = y1[0]\n        elif t0[i] > t1[-1]:\n            outer[i] = y1[-1]\n        else:\n            idx = searchsorted(t1, t0[i])\n            outer[i] = y1[idx] + (y1[idx] - y1[idx - 1]) * (t0[i] - t1[idx]) / (t1[idx] - t1[idx - 1])\n\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Construct the inner measure\n    t1_min = t1.min()\n    t1_max = t1.max()\n    t1_mean = t1.mean()\n    t1_std = t1.std()\n\n    t0_min = t0.min()\n    t0_max = t0.max()\n    t0_mean = t0.mean()\n    t0_std = t0.std()\n\n    # Compute the inner measure\n    inner = y1 * (t0 - t0_mean) / t0_std + (t1_mean - t0_mean) / t0_std\n\n    # Compute the outer measure\n    outer = y1 * (t0 - t0_mean) / t0_std + (t1_mean - t1_mean) / t1_std\n\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Compute the difference between the source and target times\n    dt = t1 - t0\n\n    # Compute the differences between the source time and the target times\n    dtt = t1 - t0.unsqueeze(-1)\n\n    # Compute the differences between the target times\n    dttt = t0.unsqueeze(-1) - t0.unsqueeze(-2)\n\n    # Compute the inner measure\n    inner = torch.sum(dtt * y1.unsqueeze(-1), -2) / dt\n\n    # Compute the outer measure\n    outer = torch.sum(dttt * (y1.unsqueeze(-1) - inner.unsqueeze(-1)), -2) / dttt\n\n    return inner, outer\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Check if the target time (t0) is smaller than the source time (t1).\n    if (t0 <= t1).all():\n        # If so, compute the inner measure.\n        inner = (t0 - t1) * y1\n        # Compute the outer measure.\n        outer = t0 - inner\n        # Return the inner and outer measures.\n        return inner, outer\n    else:\n        # If not, compute the outer measure.\n        outer = (t0 - t1) * y1\n        # Compute the inner measure.\n        inner = t0 - outer\n        # Return the inner and outer measures.\n        return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # compute the inner measure\n    t0 = t0.unsqueeze(1)\n    t1 = t1.unsqueeze(1)\n    y1 = y1.unsqueeze(1)\n    inner = torch.sum((t0 - t1) * y1, dim=0) / torch.sum((t0 - t1) * (t0 - t1), dim=0)\n\n    # compute the outer measure\n    outer = torch.sum(y1, dim=0) / torch.sum((t1 < t0.expand_as(t1)), dim=0)\n\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Compute the differences between the target time and the source times\n    t_diff = t0 - t1\n\n    # Compute the inner measure\n    inner_measure = y1 * (t0 - t1)\n\n    # Compute the outer measure\n    outer_measure = (t0 - t1) * (t0 - t1 - 1)\n\n    # Compute the outer measure for the last time point\n    outer_measure[-1] = 0\n\n    return inner_measure, outer_measure\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # find the nearest source time to the target time\n    t1_ind = searchsorted(t1, t0)\n\n    # if the target time is before the first source time\n    if t1_ind == 0:\n        # return the first source time as both the inner and outer measures\n        return y1[0], y1[0]\n\n    # if the target time is after the last source time\n    elif t1_ind == t1.size(0):\n        # return the last source time as both the inner and outer measures\n        return y1[-1], y1[-1]\n\n    # otherwise\n    else:\n        # get the inner and outer measures\n        y0_in = y1[t1_ind - 1]\n        y0_out = y1[t1_ind]\n\n        # return the inner and outer measures\n        return y0_in, y0_out\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Check if t0 and t1 are scalars or lists\n    if isinstance(t0, list):\n        t0 = torch.tensor(t0)\n    if isinstance(t1, list):\n        t1 = torch.tensor(t1)\n\n    # Check if t0 and t1 are scalars\n    if torch.numel(t0) == 1 and torch.numel(t1) == 1:\n        # Check if t0 and t1 are equal\n        if t0 == t1:\n            return y1, y1\n        # Check if t0 < t1\n        elif t0 < t1:\n            # Get index of t1\n            idx = torch.searchsorted(t1, t0)\n            # Check if t0 is equal to the last time\n            if idx == len(t1):\n                idx = idx - 1\n            # Get inner measure\n            y0_inner = y1[idx - 1] + (y1[idx] - y1[idx - 1]) * (t0 - t1[idx - 1]) / (t1[idx] - t1[idx - 1])\n            # Get outer measure\n            y0_outer = y1[idx] + (y1[idx] - y1[idx - 1]) * (t0 - t1[idx]) / (t1[idx] - t1[idx - 1])\n            return y0_inner, y0_outer\n        # Check if t0 > t1\n        elif t0 > t1:\n            # Get index of t1\n            idx = torch.searchsorted(t1, t0)\n            # Check if t0 is equal to the last time\n            if idx == len(t1):\n                idx = idx - 1\n            # Get inner measure\n            y0_inner = y1[idx] + (y1[idx] - y1[idx - 1]) * (t0 - t1[idx]) / (t1[idx] - t1[idx - 1])\n            # Get outer measure\n            y0_outer = y1[idx +"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Compute the difference between the source time (t1) and the target time (t0).\n    t1_t0 = t1 - t0\n\n    # Compute the cumulative sum of the source time (t1) and the target time (t0).\n    t1_cumsum = torch.cumsum(t1_t0, dim=1)\n    t0_cumsum = torch.cumsum(t0, dim=1)\n\n    # Compute the difference between the cumulative sum of the source time (t1) and the target time (t0).\n    t1_cumsum_t0_cumsum = t1_cumsum - t0_cumsum\n\n    # Find the indices for the source time (t1) that are closest to the target time (t0).\n    t1_cumsum_t0_cumsum_indices = torch.searchsorted(t1_cumsum, t0_cumsum)\n\n    # Initialize the inner measure.\n    inner = torch.zeros_like(t0_cumsum)\n\n    # Initialize the outer measure.\n    outer = torch.zeros_like(t0_cumsum)\n\n    # Loop over the indices for the source time (t1) that are closest to the target time (t0).\n    for i in range(t1_cumsum_t0_cumsum_indices.shape[0]):\n        for j in range(t1_cumsum_t0_cumsum_indices.shape[1]):\n\n            # Find the index for the source time (t1) that is closest to the target time (t0).\n            t1_cumsum_t0_cumsum_index = t1_cumsum_t0_cumsum_indices[i, j]\n\n            # Find the value for the source time (t1) that is closest to the target time (t0).\n            t1_cumsum_t0_cumsum_value = t1_cumsum_t0_cumsum[i"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Compute the differences between the source and target times\n    dt = t1 - t0\n\n    # Compute the differences between the source times\n    dt_diff = t1[1:] - t1[:-1]\n\n    # Compute the cumulative sums\n    dt_sum = dt.cumsum(0)\n    dt_diff_sum = dt_diff.cumsum(0)\n\n    # Compute the inner measure\n    inner_measure = torch.empty_like(t0)\n    inner_measure[0] = y1[0]\n    inner_measure[1:] = y1[1:] - (dt_diff_sum / dt_diff_sum[-1]) * (dt[1:] - dt[:-1])\n\n    # Compute the outer measure\n    outer_measure = torch.empty_like(t0)\n    outer_measure[0:-1] = (dt_diff_sum / dt_diff_sum[-1]) * (dt[1:] - dt[:-1]) + y1[:-1]\n    outer_measure[-1] = y1[-1]\n\n    return inner_measure, outer_measure\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # t0: (B, T)\n    # t1: (B, T)\n    # y1: (B, T)\n\n    # (B, T)\n    t0_ = t0.unsqueeze(1)\n    t1_ = t1.unsqueeze(1)\n    # (B, 1, T)\n    t0__ = t0_.unsqueeze(1)\n    t1__ = t1_.unsqueeze(1)\n    # (B, T, 1)\n\n    # (B, T)\n    t0_t1 = t0_ - t1_\n    # (B, T, T)\n    t0_t1_ = t0__ - t1__\n    # (B, T, T)\n    t0_t1_abs = torch.abs(t0_t1_)\n    # (B, T, T)\n    t0_t1_abs_recip = 1 / t0_t1_abs\n\n    # (B, T, T)\n    t0_t1_abs_recip_sum = torch.cumsum(t0_t1_abs_recip, dim=2)\n    # (B, T, T)\n    t0_t1_abs_recip_cumsum = torch.cumsum(t0_t1_abs_recip, dim=2)\n\n    # (B, T, T)\n    t0_t1_abs_recip_sum_prod = t0_t1_abs_recip_sum * t0_t1_abs_recip_cumsum\n    # (B, T, T)\n    t0_t1_abs_recip_sum_cumsum = torch.cumsum(t0_t1_abs_recip_sum, dim=2)\n    # (B, T, T)\n    t0_t1_abs_recip_sum_prod_sum = t0_t1_abs_recip_sum_prod + t0_t1_abs_"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Ensure that the target time (t0) is not less than the source time (t1).\n    assert torch.all(t0 >= t1), \"Target time (t0) cannot be less than the source time (t1).\"\n\n    # Compute the inner measure.\n    t0_t1 = t0[:, None] - t1[None, :]\n    y0_y1 = torch.cumsum(y1, dim=1)\n    y0_y1_t0 = searchsorted(t0_t1, y0_y1)\n    y0_t0 = y0_y1_t0[:, -1]\n    y0_t0 = y0_t0[:, None]\n    inner = y0_t0\n\n    # Compute the outer measure.\n    y0_t0_y1 = torch.cumsum(y0_t0, dim=1)\n    y0_t0_y1_t0 = searchsorted(t0_t1, y0_t0_y1)\n    y0_t0_y1_t0 = y0_t0_y1_t0[:, -1]\n    y0_t0_y1_t0 = y0_t0_y1_t0[:, None]\n    outer = y0_t0_y1_t0\n\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # check for monotonicity in t1\n    if not torch.all(t1[:-1] <= t1[1:]):\n        raise Exception('t1 must be monotonic')\n\n    # check that t0 is within bounds\n    if not (t0 > t1[0] and t0 < t1[-1]):\n        raise Exception('t0 must be between t1[0] and t1[-1]')\n\n    # check for monotonicity in y1\n    if not torch.all(y1[:-1] <= y1[1:]):\n        raise Exception('y1 must be monotonic')\n\n    # check that t0 is within bounds\n    if not (t0 > t1[0] and t0 < t1[-1]):\n        raise Exception('t0 must be between t1[0] and t1[-1]')\n\n    # check for same shape\n    if not t0.shape == t1.shape == y1.shape:\n        raise Exception('shapes must match')\n\n    # check for one dimensional input\n    if not t0.ndim == 1:\n        raise Exception('inputs must be one dimensional')\n\n    # check for single point input\n    if not t0.numel() > 1:\n        raise Exception('inputs must have more than one element')\n\n    # check for two dimensional input\n    if not t0.ndim == 1:\n        raise Exception('inputs must be one dimensional')\n\n    # check for single point input\n    if not t0.numel() > 1:\n        raise Exception('inputs must have more than one element')\n\n    # check for two dimensional input\n    if not t0.ndim == 1:\n        raise Exception('inputs must be one dimensional')\n\n    # check for single point input\n    if not t0.numel() > 1:\n        raise Exception('inputs must have more than one element')\n\n    # check for two dimensional input\n    if not t0.ndim == 1:\n        raise Exception('inputs must be one dimensional')\n\n    # check for single point input\n    if"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Compute the inner measure\n    t0_inner = t0.unsqueeze(-1) - t1.unsqueeze(-2)\n    t0_inner = t0_inner.clamp(min=0)\n    t0_inner = t0_inner.unsqueeze(-1)\n    y0_inner = t0_inner * y1.unsqueeze(-2)\n    y0_inner = y0_inner.sum(-2)\n\n    # Compute the outer measure\n    t0_outer = t1.unsqueeze(-1) - t0.unsqueeze(-2)\n    t0_outer = t0_outer.clamp(min=0)\n    t0_outer = t0_outer.unsqueeze(-1)\n    y0_outer = t0_outer * y1.unsqueeze(-2)\n    y0_outer = y0_outer.sum(-2)\n\n    return y0_inner, y0_outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # calculate the inner and outer measures\n    w_inner, w_outer = inner_outer(t, t_env, w_env)\n\n    # calculate the loss\n    loss = (w * w_inner + w_outer * w_outer) / (w + w_outer + eps)\n\n    return loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # calculate the inner and outer weights\n    w_inner, w_outer = inner_outer(t, t_env, w_env)\n\n    # calculate the loss\n    loss = (w_inner + w_outer) / 2\n    loss = loss.sum(dim=-1)\n    loss = loss / (w.sum(dim=-1) + eps)\n    loss = loss.mean()\n\n    return loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # Calculate the envelope weights\n    w_env_inner, w_env_outer = inner_outer(t, t_env, w_env)\n\n    # Calculate the inner and outer weights\n    w_inner, w_outer = inner_outer(t, t, w)\n\n    # Calculate the loss\n    return F.relu(w_inner / (w_env_inner + eps)) ** 2 + F.relu(w_outer / (w_env_outer + eps)) ** 2\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # calculate the weights of the upper envelope\n    _, w_env_outer = inner_outer(t_env, t_env, w_env)\n\n    # calculate the weights of the proposal\n    _, w_outer = inner_outer(t, t, w)\n\n    # calculate the loss\n    return (w_outer / (w_env_outer + eps)).mean()\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # Calculate the envelope weights.\n    w_env_inner, w_env_outer = inner_outer(t, t_env, w_env)\n\n    # Calculate the loss.\n    w_diff = w - w_env_outer\n    loss = w_diff**2 / (w_env_inner + w_env_outer + eps)\n\n    return loss\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # assert t.shape[-1] == w.shape[-1] + 1\n    # assert t_env.shape[-1] == w_env.shape[-1] + 1\n\n    # calculate the inner and outer weights\n    w_inner, w_outer = inner_outer(t, t_env, w_env)\n\n    # calculate the loss\n    loss = (w_inner / (w + eps) - 1) ** 2 - w_outer / (w + eps)\n\n    # return the loss\n    return loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # calculate the upper envelope\n    w_env_inner, w_env_outer = inner_outer(t, t_env, w_env)  # 128, 127\n    w_env_inner = torch.cat([torch.zeros_like(w_env_inner[..., :1]), w_env_inner], dim=-1)  # 129\n\n    # calculate the loss\n    w_diff = w_env_outer - w  # 128, 128\n    w_diff = torch.where(w_diff < 0, 0, w_diff)  # 128, 128\n    w_diff = torch.where(w_diff > 0, w_diff, 0)  # 128, 128\n    w_diff = w_diff * (w_env_inner / (w_env_inner + eps))  # 128, 128\n\n    return w_diff\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # Get the inner and outer envelopes\n    w_inner, w_outer = inner_outer(t, t_env, w_env)\n\n    # Get the inner and outer envelopes\n    w_inner, w_outer = inner_outer(t, t_env, w_env)\n\n    # Calculate the loss\n    loss = torch.sum(w * (w_outer + w_inner) / 2.0, dim=-1) / (torch.sum(w, dim=-1) + eps)\n\n    return loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # assert t.shape[-1] == w.shape[-1] + 1\n    # assert t_env.shape[-1] == w_env.shape[-1] + 1\n\n    # calculate the weights of the proposal\n    w_env_inner, w_env_outer = inner_outer(t, t_env, w_env)\n    w_env_inner = torch.where(w_env_inner < 0, torch.zeros_like(w_env_inner), w_env_inner)\n    w_env_outer = torch.where(w_env_outer < 0, torch.zeros_like(w_env_outer), w_env_outer)\n    w_env_inner = torch.where(w_env_inner > w_env, w_env, w_env_inner)\n    w_env_outer = torch.where(w_env_outer > w_env, w_env, w_env_outer)\n    w_env = w_env_inner + w_env_outer\n\n    # calculate the weights of the target\n    w_inner, w_outer = inner_outer(t, t, w)\n    w_inner = torch.where(w_inner < 0, torch.zeros_like(w_inner), w_inner)\n    w_outer = torch.where(w_outer < 0, torch.zeros_like(w_outer), w_outer)\n    w = w_inner + w_outer\n\n    # calculate the loss\n    w_diff = w_env - w\n    w_diff = torch.where(w_diff < 0, torch.zeros_like(w_diff), w_diff)\n    loss = w_diff ** 2 / (w_env + eps)\n    return loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # assert t.shape[-1] == w.shape[-1] + 1\n    assert t.shape[-1] == w_env.shape[-1] + 1\n\n    w_env_inner, w_env_outer = inner_outer(t, t_env, w_env)\n    w_env_inner = torch.where(w_env_inner < 0, torch.zeros_like(w_env_inner), w_env_inner)\n    w_env_outer = torch.where(w_env_outer < 0, torch.zeros_like(w_env_outer), w_env_outer)\n\n    w_env_inner = torch.where(w_env_inner < eps, eps * torch.ones_like(w_env_inner), w_env_inner)\n    w_env_outer = torch.where(w_env_outer < eps, eps * torch.ones_like(w_env_outer), w_env_outer)\n\n    w_env_inner_cumsum = torch.cumsum(w_env_inner, dim=-1)\n    w_env_outer_cumsum = torch.cumsum(w_env_outer, dim=-1)\n\n    w_inner = torch.take_along_dim(w_env_inner_cumsum, idx_lo, dim=-1)\n    w_outer = torch.take_along_dim(w_env_outer_cumsum, idx_hi, dim=-1)\n\n    w_inner = torch.where(idx_hi[..., :-1] <= idx_lo[..., 1:], w_env_outer_cumsum[..., 1:] - w_env_inner_cumsum[..., :-1], w_inner)\n\n    w_inner = torch.where(w_inner < eps, eps * torch.ones_like(w_inner), w_inner)\n    w_outer = torch.where(w_outer < eps, eps * torch.ones_like("}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    t_env = t_env.unsqueeze(-1)\n    w_env = w_env.unsqueeze(-1)\n\n    t_env = t_env.expand(t_env.shape[:-2] + (t.shape[-1],))\n    w_env = w_env.expand(w_env.shape[:-2] + (w.shape[-1],))\n\n    y1_env = w_env / (t_env[..., 1:] - t_env[..., :-1] + eps)\n    y1_env = torch.cat(\n        [y1_env[..., [0]], 0.5 * (y1_env[..., 1:] + y1_env[..., :-1]), y1_env[..., [-1]]], dim=-1)\n\n    y1_target = w / (t[..., 1:] - t[..., :-1] + eps)\n    y1_target = torch.cat(\n        [y1_target[..., [0]], 0.5 * (y1_target[..., 1:] + y1_target[..., :-1]), y1_target[..., [-1]]], dim=-1)\n\n    y0_inner, y0_outer = inner_outer(t, t_env, y1_env)\n    y1_inner, y1_outer = inner_outer(t, t, y1_target)\n\n    y0_inner = torch.clamp(y0_inner, min=0)\n    y0_outer = torch.clamp(y0_outer, min=0)\n    y1_inner = torch.clamp(y1_inner, min=0)\n    y1_outer = torch.clamp(y1_outer, min=0)\n\n    y0_inner_loss = torch.sum(y0_inner * y1_inner, dim=-1)\n    y0_outer_loss = torch.sum(y0_outer * y1_outer, dim=-1)\n\n    y0_loss = 0.5 * (y0_"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # Calculate the inner and outer envelope weights\n    w_env_inner, w_env_outer = inner_outer(t, t_env, w_env)\n\n    # Calculate the inner and outer proposal weights\n    w_inner, w_outer = inner_outer(t, t, w)\n\n    # Calculate the loss\n    loss = (w_inner * w_env_inner + w_outer * w_env_outer) / (w_inner + w_outer + eps)\n    return loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # calculate the weights of the upper envelope\n    w_env_inner, w_env_outer = inner_outer(t_env, t_env, w_env)\n    w_env_inner = torch.cumsum(w_env_inner, dim=-1)\n    w_env_outer = torch.cumsum(w_env_outer, dim=-1)\n    w_env_inner_outer = torch.cat([w_env_inner, w_env_outer[..., -1:]], dim=-1)\n    w_env_upper = torch.where(w_env_inner_outer < w_env, w_env_inner_outer, w_env)\n\n    # calculate the weights of the proposal\n    w_inner, w_outer = inner_outer(t, t, w)\n    w_inner = torch.cumsum(w_inner, dim=-1)\n    w_outer = torch.cumsum(w_outer, dim=-1)\n    w_inner_outer = torch.cat([w_inner, w_outer[..., -1:]], dim=-1)\n    w_upper = torch.where(w_inner_outer < w, w_inner_outer, w)\n\n    # calculate the loss\n    w_diff = w_upper - w_env_upper\n    w_diff_abs = torch.abs(w_diff)\n    w_diff_abs_scaled = w_diff_abs / (w_env_upper + eps)\n    w_diff_abs_scaled_sq = w_diff_abs_scaled ** 2\n    w_diff_abs_scaled_q = w_diff_abs_scaled_sq / (w_diff_abs_scaled_sq + 1)\n    w_diff_abs_scaled_q_sum = torch.sum(w_diff_abs_scaled_q, dim=-1)\n\n    return w_diff_abs_scaled_q_sum\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # t.shape[-1] == w.shape[-1] + 1\n    # t_env.shape[-1] == w_env.shape[-1] + 1\n    assert t.shape[-1] == w.shape[-1] + 1\n    assert t_env.shape[-1] == w_env.shape[-1] + 1\n\n    t_env = torch.cat([t_env, t_env[..., -1:]], dim=-1)\n    w_env = torch.cat([w_env, torch.zeros_like(w_env[..., :1])], dim=-1)\n\n    w_env_inner, w_env_outer = inner_outer(t, t_env, w_env)\n    w_env_inner = w_env_inner.clamp(min=0)\n    w_env_outer = w_env_outer.clamp(min=0)\n    w_env_outer = w_env_outer + w_env_inner\n\n    w_inner, w_outer = inner_outer(t, t, w)\n    w_inner = w_inner.clamp(min=0)\n    w_outer = w_outer.clamp(min=0)\n    w_outer = w_outer + w_inner\n\n    w_outer = w_outer.clamp(min=eps)\n    w_env_outer = w_env_outer.clamp(min=eps)\n\n    w_outer_log = w_outer.log()\n    w_env_outer_log = w_env_outer.log()\n\n    loss = w_outer_log - w_env_outer_log\n    loss = loss.sum(-1)\n    return loss\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # Calculate the upper envelope weights\n    w_env_inner, w_env_outer = inner_outer(t_env, t, w_env)\n    w_env_inner = torch.cumsum(w_env_inner, dim=-1)\n    w_env_outer = torch.cumsum(w_env_outer, dim=-1)\n    w_env_upper = w_env_inner + w_env_outer\n\n    # Calculate the inner and outer weights for the proposal\n    w_inner, w_outer = inner_outer(t, t, w)\n    w_inner = torch.cumsum(w_inner, dim=-1)\n    w_outer = torch.cumsum(w_outer, dim=-1)\n    w_upper = w_inner + w_outer\n\n    # Calculate the loss\n    w_upper = torch.cat([torch.zeros_like(w_upper[..., :1]), w_upper], dim=-1)\n    w_env_upper = torch.cat([torch.zeros_like(w_env_upper[..., :1]), w_env_upper], dim=-1)\n    loss = 0.5 * torch.sum(w_upper / (w_env_upper + eps) + torch.log(w_env_upper + eps), dim=-1)\n\n    return loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # Calculate the inner and outer weights\n    w_env_inner, w_env_outer = inner_outer(t, t_env, w_env)\n    w_inner, w_outer = inner_outer(t, t, w)\n\n    # Calculate the loss\n    loss = 0.5 * (w_outer / (w_env_outer + eps) + 1) ** 2 + 0.5 * (w_inner / (w_env_inner + eps) - 1) ** 2\n\n    return loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    assert t.shape[-1] == w.shape[-1] + 1\n    assert t.shape[-1] == t_env.shape[-1]\n    assert t.shape[-1] == w_env.shape[-1] + 1\n\n    t_inner, t_outer = inner_outer(t, t_env, w_env)\n    w_inner, w_outer = inner_outer(t, t, w)\n\n    # scaled half-quadratic loss\n    return (w_outer * (t_outer - t_inner) ** 2).sum() / (w_inner.sum() + eps)\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # t, w: [B, N, 128]\n    # t_env, w_env: [B, 129]\n\n    # w_env: [B, 129]\n    w_env = w_env[..., :-1]\n\n    # w_env_inner: [B, 128]\n    _, w_env_outer = inner_outer(t_env, t_env, w_env)\n\n    # w_env_inner: [B, 128]\n    # w_env_outer: [B, 127]\n    w_env_outer = F.pad(w_env_outer, (1, 0), value=0)\n\n    # w_env_inner, w_env_outer: [B, 128]\n    w_env_inner, w_env_outer = w_env_inner.unsqueeze(-2), w_env_outer.unsqueeze(-2)\n\n    # w_inner, w_outer: [B, N, 128]\n    w_inner, w_outer = inner_outer(t, t, w)\n\n    # w_inner, w_outer: [B, N, 128]\n    w_inner, w_outer = w_inner.unsqueeze(-3), w_outer.unsqueeze(-3)\n\n    # w_env_inner, w_env_outer: [B, 1, 128]\n    w_env_inner, w_env_outer = w_env_inner.unsqueeze(-3), w_env_outer.unsqueeze(-3)\n\n    # w_inner, w_outer, w_env_inner, w_env_outer: [B, N, 128]\n    return (w_inner * w_env_inner + w_outer * w_env_outer) / (w_inner + w_outer + eps)\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # Calculate the inner and outer measures\n    w_env_inner, w_env_outer = inner_outer(t, t_env, w_env)\n\n    # Calculate the envelope\n    w_env = torch.where(w_env_outer > 0, w_env_inner / w_env_outer, w_env_inner)\n\n    # Calculate the loss\n    w_env = torch.where(w_env >= 0, w_env, torch.zeros_like(w_env))\n    return 0.5 * (w ** 2) * (w_env ** 2)\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # calculate the inner and outer weights\n    w_inner, w_outer = inner_outer(t, t_env, w_env)\n\n    # calculate the inner and outer positions\n    t_inner, t_outer = inner_outer(t, t_env, t_env)\n\n    # calculate the scaled loss\n    return torch.sum(w * (w_inner / (w_outer + eps)) ** 2 + (w - 1) * (w_outer / (w_inner + eps)) ** 2)\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n\n    # Inter-interval loss\n    w_inner, w_outer = inner_outer(t, t, w)\n    w_inner = w_inner.clip(0.)\n    w_outer = w_outer.clip(0.)\n\n    loss_inter = (w_outer.pow(2) / (w_inner + w_outer + 1e-6)).mean()\n\n    # Intra-interval loss\n    w_inner, w_outer = inner_outer(t, t, w)\n    w_inner = w_inner.clip(0.)\n    w_outer = w_outer.clip(0.)\n\n    loss_intra = (w_inner.pow(2) / (w_inner + w_outer + 1e-6)).mean()\n\n    return loss_inter + loss_intra\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    # get the inner and outer measures\n    w_inner, w_outer = inner_outer(t, t, w)\n\n    # calculate the inter-interval and intra-interval losses\n    loss_inter = (w_inner.pow(2) / (w_outer + 1e-6)).mean()\n    loss_intra = (w_outer.pow(2) / (w_inner + 1e-6)).mean()\n\n    # return the total distortion loss\n    return loss_inter + loss_intra\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    # accepts t.shape[-1] = w.shape[-1] + 1\n    # Calculates the intra-interval loss.\n    t, w = matchup_channels(t, w)\n    w_inner, w_outer = inner_outer(t, t, w)\n    intra_loss = (w_outer.pow(2) / (w_inner + 1e-6)).mean()\n\n    # Calculates the inter-interval loss.\n    w_inner, w_outer = inner_outer(t, t, w)\n    inter_loss = (w_outer.pow(2) / (w_inner + 1e-6)).mean()\n\n    # Combines the intra- and inter-interval losses.\n    return intra_loss + inter_loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    # Calculate the inter-interval loss\n    w_outer = lossfun_outer(t, w, t, w)\n\n    # Calculate the intra-interval loss\n    t_outer, w_outer = matchup_channels(t, w)\n    t_outer, w_outer = t_outer[..., 1:-1], w_outer[..., 1:-1]\n    w_outer = w_outer / torch.clamp_min(t_outer[..., 1:] - t_outer[..., :-1], 1e-6)\n    w_outer = torch.clip(w_outer, min=0.)\n    assert (w_outer >= 0.0).all()\n    area = 0.5 * (w_outer[..., 1:] + w_outer[..., :-1]) * (t_outer[..., 1:] - t_outer[..., :-1])\n    cdf = torch.cat([torch.zeros_like(area[..., :1]), torch.cumsum(area, dim=-1)], dim=-1)\n    cdf_interp = sorted_interp_quad(t_outer, t_outer, w_outer, cdf)\n    w_s = torch.diff(cdf_interp, dim=-1)\n    w_s = torch.clip(w_s, min=0.)\n    assert (w_s >= 0.0).all()\n    w_inner = w_s\n    w_inner = w_inner / torch.clamp_min(t_outer[..., 1:] - t_outer[..., :-1], 1e-6)\n    w_inner = torch.clip(w_inner, min=0.)\n    assert (w_inner >= 0.0).all()\n    w_inner = w_inner / torch.clamp_min(t_outer[..., 1:] - t_outer[..., :-1], 1e-6)\n    w_inner = torch.clip(w_inner, min=0.)\n    assert (w_inner >= 0.0).all()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    # accepts t.shape[-1] = w.shape[-1] + 1\n\n    \"\"\"\n    Computes the distortion loss function for a given tensor of targets and weights. The function calculates both the inter-interval and intra-interval losses based on the provided tensors and combines them to produce the total distortion loss.\n\n    Input-Output Arguments\n    :param t: torch.Tensor. The target tensor for which the distortion loss is to be calculated. It is expected that the last dimension of 't' is one more than that of 'w'.\n    :param w: torch.Tensor. The weights tensor, used to weight the distortion loss calculation. The last dimension of 'w' should be one less than that of 't'.\n    :return: torch.Tensor. The calculated distortion loss as a tensor. This combines both inter-interval and intra-interval losses.\n    \"\"\"\n\n    # accepts t.shape[-1] = w.shape[-1] + 1\n\n    t, w = matchup_channels(t, w)\n\n    # Inter-interval loss\n    # Interval length\n    t_diff = t[..., 1:] - t[..., :-1]\n    # Interval weight\n    w_intra = w[..., :-1] + w[..., 1:]\n\n    # Intra-interval loss\n    # Interval length\n    t_intra = t[..., 1:] - t[..., :-1]\n    # Interval weight\n    w_intra = w[..., :-1] + w[..., 1:]\n\n    # Inter-interval loss\n    # Interval length\n    t_diff = t[..., 1:] - t[..., :-1]\n    # Interval weight\n    w_intra = w[..., :-1] + w[..., 1:]\n\n    # Intra-interval loss\n    # Interval length\n    t_intra = t[..., 1:] - t[..., :-1]\n    # Interval weight\n    w_intra = w[..., :-1] + w[..., 1:]\n\n    # Inter-interval loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    # Ensure that the last dimension of 't' is one more than that of 'w'\n    if t.shape[-1] != w.shape[-1] + 1:\n        raise ValueError(f\"The last dimension of 't' should be one more than that of 'w'.\")\n\n    # Ensure that the tensor 't' is sorted in ascending order\n    t = torch.sort(t, dim=-1).values\n\n    # Calculate the inter-interval and intra-interval losses\n    inter_loss = lossfun_outer(t, w, t, w)\n    intra_loss = lossfun_zip_outer(t, w, t, w, 0.005)\n\n    # Combine the inter-interval and intra-interval losses to produce the total distortion loss\n    return inter_loss + intra_loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    # Calculate the inter-interval and intra-interval losses\n    inter_interval_loss = lossfun_outer(t, w, t, w)\n    intra_interval_loss = lossfun_zip_outer(t, w, t, w, 0.1)\n\n    # Combine the inter-interval and intra-interval losses to produce the total distortion loss\n    return (inter_interval_loss + intra_interval_loss) / 2.0\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    # Calculate the inter-interval and intra-interval losses\n    inter_loss = lossfun_outer(t, w, t, w)\n    intra_loss = lossfun_zip_outer(t, w, t, w, 0.5)\n\n    # Combine the inter-interval and intra-interval losses\n    return inter_loss + intra_loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    # get the inner and outer measures\n    w_inner, w_outer = inner_outer(t, t, w)\n\n    # calculate the inter-interval loss\n    inter_loss = (w_outer.pow(2) / (w_inner + 1e-8)).mean()\n\n    # calculate the intra-interval loss\n    intra_loss = (w_inner.pow(2) / (w_outer + 1e-8)).mean()\n\n    # combine the inter and intra-interval losses\n    return inter_loss + intra_loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    # assert (w >= 0.).all()\n\n    # calculate the inter-interval loss\n    # t, w = matchup_channels(t, w)\n    # t_inner, t_outer = inner_outer(t, t, w)\n    # inter_loss = (t_outer - t_inner).pow(2).div(t_inner.clamp_min(1e-6))\n\n    # calculate the intra-interval loss\n    # t_inner, t_outer = inner_outer(t, t, w)\n    # intra_loss = (t_outer - t_inner).pow(2).div(t_outer.clamp_min(1e-6))\n\n    # return inter_loss.mean() + intra_loss.mean()\n\n    # calculate the inter-interval loss\n    t, w = matchup_channels(t, w)\n    t_inner, t_outer = inner_outer(t, t, w)\n    inter_loss = (t_outer - t_inner).pow(2).div(t_inner.clamp_min(1e-6))\n\n    # calculate the intra-interval loss\n    t_inner, t_outer = inner_outer(t, t, w)\n    intra_loss = (t_outer - t_inner).pow(2).div(t_outer.clamp_min(1e-6))\n\n    return inter_loss.mean() + intra_loss.mean()\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    # Get the inter-interval and intra-interval losses.\n    inter_loss = lossfun_outer(t, w, t, w)\n    intra_loss = lossfun_zip_outer(t, w, t, w, pulse_width=0.05)\n\n    # Combine the inter-interval and intra-interval losses.\n    return inter_loss + intra_loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n\n    # calculate the inter-interval loss\n    inter_interval_loss = inter_interval_lossfun(t, w)\n\n    # calculate the intra-interval loss\n    intra_interval_loss = intra_interval_lossfun(t, w)\n\n    # combine the inter-interval and intra-interval losses\n    distortion_loss = inter_interval_loss + intra_interval_loss\n\n    return distortion_loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    # Calculate the intra-interval loss.\n    # This is the difference between the target and weighted average of the surrounding intervals.\n    # The weighted average of the surrounding intervals is calculated by multiplying the weights of the surrounding intervals with the target values of the surrounding intervals and dividing by the sum of the weights of the surrounding intervals.\n    # The intra-interval loss is calculated by taking the square of the difference between the target and the weighted average of the surrounding intervals.\n    # The intra-interval loss is then averaged over the last dimension of 't'.\n    intra_interval_loss = (t[..., :-1] - (t[..., 1:] * w[..., :-1] + t[..., :-1] * w[..., 1:]) / (w[..., :-1] + w[..., 1:])).pow(2).mean(dim=-1)\n\n    # Calculate the inter-interval loss.\n    # This is the difference between the weighted average of the target values of the surrounding intervals and the weighted average of the weights of the surrounding intervals.\n    # The weighted average of the target values of the surrounding intervals is calculated by multiplying the weights of the surrounding intervals with the target values of the surrounding intervals and dividing by the sum of the weights of the surrounding intervals.\n    # The weighted average of the weights of the surrounding intervals is calculated by multiplying the weights of the surrounding intervals with the weights of the surrounding intervals and dividing by the sum of the weights of the surrounding intervals.\n    # The inter-interval loss is calculated by taking the square of the difference between the weighted average of the target values of the surrounding intervals and the weighted average of the weights of the surrounding intervals.\n    # The inter-interval loss is then averaged over the last dimension of 't'.\n    inter_interval_loss = ((t[..., 1:] * w[..., :-1] + t[..., :-1] * w[..., 1:]) / (w[..., :-1] + w[..., 1:]) - (w[..., :-1] * w[..., 1:]) / (w[..., :-1] + w[..., 1:])).pow(2).mean(dim=-1)"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    # Calculate the inter-interval and intra-interval losses\n    inter_loss = lossfun_outer(t, w, t, w)\n    intra_loss = lossfun_zip_outer(t, w, t, w, 0.01)\n\n    # Combine the inter-interval and intra-interval losses\n    return inter_loss + intra_loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    # assert t.shape[-1] == w.shape[-1] + 1\n    # assert t.shape[-1] >= 3\n\n    # Inter-interval loss\n    t_intra = t[..., :-1]\n    t_inter = t[..., 1:]\n    w_intra = w[..., :-1]\n    w_inter = w[..., 1:]\n\n    # Inter-interval loss\n    t_diff = t_inter - t_intra\n    w_diff = w_inter - w_intra\n    t_diff_sq = t_diff.square()\n    w_diff_sq = w_diff.square()\n    w_diff_sq_zero = (w_diff_sq == 0.).float()\n    inter_loss = (w_diff_sq * (t_diff_sq - 1.)).sum() / (w_diff_sq * (1. - w_diff_sq_zero)).sum()\n\n    # Intra-interval loss\n    t_intra_sq = t_intra.square()\n    t_inter_sq = t_inter.square()\n    w_intra_sq = w_intra.square()\n    w_inter_sq = w_inter.square()\n    w_intra_sq_zero = (w_intra_sq == 0.).float()\n    w_inter_sq_zero = (w_inter_sq == 0.).float()\n    intra_loss = (w_intra_sq * (t_intra_sq - t_inter_sq)).sum() / (w_intra_sq * (1. - w_intra_sq_zero)).sum()\n    intra_loss += (w_inter_sq * (t_inter_sq - t_intra_sq)).sum() / (w_inter_sq * (1. - w_inter_sq_zero)).sum()\n\n    return inter_loss + intra_loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    # assert t.shape[-1] == w.shape[-1] + 1\n    # assert len(t.shape) == len(w.shape)\n\n    # Calculate the inter-interval loss\n    t, w = matchup_channels(t, w)\n    # t_inter, w_inter = t[..., 1:], w[..., :-1]\n    # t_inter, w_inter = t[..., 1:], w[..., :-1]\n    # inter_loss = (w_inter * (t_inter[..., :-1] - t_inter[..., 1:]) ** 2).mean()\n    # inter_loss = (w_inter * (t_inter[..., :-1] - t_inter[..., 1:]) ** 2).mean()\n\n    # Calculate the intra-interval loss\n    # t_intra, w_intra = t[..., :-1], w[..., 1:]\n    # intra_loss = (w_intra * (t_intra[..., :-1] - t_intra[..., 1:]) ** 2).mean()\n\n    # Calculate the total distortion loss\n    # loss = inter_loss + intra_loss\n    # loss = inter_loss\n\n    # return loss\n\n    t_inter, w_inter = t[..., 1:], w[..., :-1]\n    inter_loss = (w_inter * (t_inter[..., :-1] - t_inter[..., 1:]) ** 2).mean()\n    return inter_loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n\n    # calculate the inter-interval loss\n    t_intra = t[..., :-1]\n    w_intra = w[..., :-1]\n    t_inter = t[..., 1:]\n    w_inter = w[..., 1:]\n\n    # calculate the inter-interval loss\n    inter_loss = (w_inter * (t_inter - t_intra) ** 2).mean()\n\n    # calculate the intra-interval loss\n    intra_loss = (w_intra * (t_inter - t_intra) ** 2).mean()\n\n    # return the total distortion loss\n    return inter_loss + intra_loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n\n    # Inter-interval loss\n    # The inter-interval loss is calculated by finding the difference between the intervals and weighting them based on the weights.\n    # The intervals are calculated by taking the difference between the target tensor and the cumulative sum of the weights tensor.\n    # The cumulative sum of the weights tensor is calculated by taking the cumulative sum of the weights tensor and appending a zero to the start of the tensor.\n    # The difference between the target tensor and the cumulative sum of the weights tensor is calculated by taking the difference between the target tensor and the cumulative sum of the weights tensor and appending a zero to the end of the tensor.\n    # The inter-interval loss is calculated by taking the absolute difference between the intervals and weighting them based on the weights.\n    # The inter-interval loss is averaged across the last dimension of the tensor.\n    inter_interval_loss = ((t[..., 1:] - t[..., :-1] - (w[..., 1:] + w[..., :-1]) / 2).abs() * w[..., :-1]).mean(-1)\n\n    # Intra-interval loss\n    # The intra-interval loss is calculated by finding the difference between the weights and weighting them based on the weights.\n    # The difference between the weights and weighting them based on the weights is calculated by taking the absolute difference between the weights and weighting them based on the weights.\n    # The intra-interval loss is averaged across the last dimension of the tensor.\n    intra_interval_loss = (w[..., 1:] - w[..., :-1]).abs().mean(-1)\n\n    # Distortion loss\n    # The distortion loss is calculated by adding the inter-interval loss and the intra-interval loss together.\n    distortion_loss = inter_interval_loss + intra_interval_loss\n\n    return distortion_loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n\n    # Inter-interval loss\n    # accepts t.shape[-1] = w.shape[-1] + 1\n    # Calculates the inter-interval loss using the given tensors.\n    # The inter-interval loss is calculated as the sum of the squared differences between the weights of consecutive intervals.\n    # The last element of the first dimension of 'w' is ignored.\n    inter_interval_loss = (w[..., :-1] - w[..., 1:]).pow(2)\n\n    # Intra-interval loss\n    # accepts t.shape[-1] = w.shape[-1] + 1\n    # Calculates the intra-interval loss using the given tensors.\n    # The intra-interval loss is calculated as the sum of the squared differences between the weights of consecutive points in each interval.\n    # The first element of the first dimension of 'w' is ignored.\n    intra_interval_loss = (w[..., 1:] - w[..., :-1]).pow(2)\n\n    # Combine the losses\n    # Calculates the total distortion loss as the sum of the inter-interval and intra-interval losses.\n    total_distortion_loss = inter_interval_loss + intra_interval_loss\n\n    return total_distortion_loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n\n    # Inter-interval loss\n    # Calculates the loss for each interval\n    # The loss is calculated as the square of the difference between the interval weights\n    # The interval weights are calculated as the product of the average weight over the interval and the length of the interval\n    # The average weight is calculated as the average of the weights in the interval\n    # The length of the interval is calculated as the difference of the end and start of the interval\n    inter_interval_loss = (w[..., 1:] * (t[..., 1:] - t[..., :-1]) - w[..., :-1] * (t[..., 1:] - t[..., :-1])) ** 2\n\n    # Intra-interval loss\n    # Calculates the loss for each point in the interval\n    # The loss is calculated as the square of the difference between the point weight and the interval weight\n    # The point weight is calculated as the weight of the point divided by the length of the interval\n    # The interval weight is calculated as the product of the average weight over the interval and the length of the interval\n    # The average weight is calculated as the average of the weights in the interval\n    # The length of the interval is calculated as the difference of the end and start of the interval\n    intra_interval_loss = (w / (t[..., 1:] - t[..., :-1]) - w[..., :-1] * (t[..., 1:] - t[..., :-1])) ** 2\n\n    # Combine the losses\n    # The combined loss is the sum of the inter-interval and intra-interval losses\n    # The combined loss is divided by the number of intervals\n    # The number of intervals is calculated as the product of the number of points in the interval and the number of intervals\n    # The number of points in the interval is calculated as the difference of the end and start of the interval\n    # The number of intervals is calculated as the difference of the end and start of the interval\n    combined_loss = (inter_interval_loss + intra_interval_loss).sum(dim=-1) / ((t[..., 1:] - t[..., :-1]) * (t["}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(torch.tensor(ps, device=t.device), cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(torch.tensor(ps, dtype=t.dtype, device=t.device), cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(torch.tensor(ps, dtype=t.dtype, device=t.device), cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(torch.tensor(ps, device=t.device), cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(torch.tensor(ps, device=t.device), cw[..., 0], cw)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(torch.tensor(ps, device=t.device), cw[..., :-1], t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(torch.tensor(ps, device=t.device), cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    # Match up the channels of the tensors\n    t, w = matchup_channels(t, w)\n\n    # Integrate the weights\n    cw = integrate_weights(w)\n\n    # Interpolate the integrated weights to find the weighted percentiles\n    t_interp = interpolate(torch.tensor(ps, device=t.device), cw[..., :-1], t[..., :-1])\n\n    return t_interp\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    cw = cw[..., 1:-1]\n    t = t[..., :-1]\n    return interpolate(ps, cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n\n    # Integrate weights\n    cw = integrate_weights(w)\n\n    # Interpolate\n    return interpolate(torch.tensor(ps, device=t.device), cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    t = torch.cat([t[..., :1], t], dim=-1)\n    cw = torch.cat([cw[..., :1], cw], dim=-1)\n    return interpolate(torch.tensor(ps, device=t.device), cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    t_pad = torch.cat([t.new_zeros(t.shape[:-1] + (1,)), t], dim=-1)\n    cw_pad = torch.cat([cw.new_zeros(cw.shape[:-1] + (1,)), cw], dim=-1)\n    return interpolate(ps, cw_pad, t_pad)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    t = t.unsqueeze(-1)\n    w = w.unsqueeze(-1)\n    cw = integrate_weights(w)\n    return interpolate(ps, cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(torch.tensor(ps, device=t.device), cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    # Match up the channels of the tensors.\n    t, w = matchup_channels(t, w)\n\n    # Integrate the weights.\n    cw = integrate_weights(w)\n\n    # Interpolate the integrated weights to find the weighted percentiles.\n    tp = interpolate(ps, cw, t)\n\n    return tp\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    t = t.unsqueeze(-1)\n    t = torch.cat([t, t.new_ones(t.shape[:-1] + (1,))], dim=-1)\n    return interpolate(torch.tensor(ps, dtype=w.dtype, device=w.device), cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n\n    cw = integrate_weights(w)\n    cw = cw.transpose(-1, -2)\n\n    return interpolate(ps, cw[..., 0], cw).transpose(-1, -2)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    ps = torch.tensor(ps, dtype=t.dtype, device=t.device)\n    return interpolate(ps, cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    t, w = t.unsqueeze(-2), w.unsqueeze(-2)\n\n    # Compute the integral of the weights\n    cw = integrate_weights(w)\n\n    # Interpolate the integral of the weights to find the weighted percentiles\n    ps = torch.tensor(ps, device=t.device)\n    ps = ps.reshape((1, 1, -1))\n    tp = interpolate(ps, cw, t)\n\n    return tp\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n\n    cw = integrate_weights(w)\n\n    # Compute the weighted percentiles.\n    ps = torch.tensor(ps, dtype=t.dtype, device=t.device)\n    ps = ps.reshape(ps.shape + (1,) * (t.ndim - 1))\n    ps = ps.expand(ps.shape[:-1] + t.shape[-1:])\n    ps = ps.reshape((-1,) + t.shape)\n    ps = ps.permute((2, 0, 1) + tuple(range(3, 2 + t.ndim)))\n    ps = ps.reshape((-1,) + t.shape[:-1])\n    ps = ps.flatten()\n    ps = ps[torch.argsort(ps)]\n    ps = torch.cat([torch.zeros_like(ps[..., :1]), ps], dim=-1)\n\n    return interpolate(ps, cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    t_new = invert_cdf(torch.rand(num_samples, *t.shape[:-1], device=t.device), t, w)\n    if perturb:\n        t_new += torch.rand_like(t_new)\n    if not single_jitter:\n        t_new += torch.rand_like(t_new)\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    # Sample from the CDF.\n    u = torch.rand(num_samples, *t.shape[:-1], device=t.device)\n    t_new = invert_cdf(u, t, w)\n    # Perturb the samples.\n    if perturb:\n        if single_jitter:\n            jitter = torch.randn(num_samples, 1, *t.shape[:-1], device=t.device)\n            t_new = t_new + jitter\n        else:\n            jitter = torch.randn(num_samples, *t.shape, device=t.device)\n            t_new = t_new + jitter\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Compute the CDF and PDF for each weight vector.\n    cw = integrate_weights(w)\n\n    # Generate samples according to the inverse CDF.\n    u = torch.rand(num_samples, device=w.device)\n    t_new = interpolate(u, cw, t)\n\n    # Apply perturbation to avoid sample clustering at bin boundaries.\n    if perturb:\n        t_new = t_new + torch.randn_like(t_new) * (t[1] - t[0]) / 2\n\n    # Apply jitter to avoid sample clustering.\n    if single_jitter:\n        t_new = t_new + torch.rand(1, device=w.device) * (t[1] - t[0]) / 2\n    else:\n        t_new = t_new + torch.rand_like(t_new) * (t[1] - t[0]) / 2\n\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    t = t.to(w)\n\n    # Compute the CDF.\n    cw = integrate_weights(w)\n\n    # Sample from the CDF.\n    u = torch.rand(cw.shape[:-1] + (num_samples,), device=w.device)\n    t_samples = interpolate(u, cw, t)\n\n    if perturb:\n        # Apply jitter to avoid clustering at bin boundaries.\n        t_samples = t_samples + torch.rand_like(t_samples)\n\n        if not single_jitter:\n            # Apply independent jitter to each sample.\n            t_samples = t_samples * torch.rand_like(t_samples)\n\n    return t_samples\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Compute the CDF.\n    cw = integrate_weights(w)\n\n    # Sample the CDF.\n    u = torch.rand(num_samples, *t.shape[:-1], 1, device=t.device)\n    t_new = interpolate(u, cw, t)\n\n    # Apply perturbation to the sampling process.\n    if perturb:\n        t_new = t_new + torch.randn_like(t_new) * 0.01\n\n    # Apply jitter.\n    if single_jitter:\n        jitter = torch.rand_like(t_new) * 0.01\n    else:\n        jitter = torch.randn_like(t_new) * 0.01\n    t_new = t_new + jitter\n\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    t_shape = t.shape\n    w_shape = w.shape\n    t = t.reshape(-1, t.shape[-1])\n    w = w.reshape(-1, w.shape[-1])\n\n    # Compute the PDF and CDF for each weight vector.\n    cw = integrate_weights(w)\n\n    # Sample from the CDF.\n    u = torch.rand(num_samples, t.shape[0], device=t.device)\n    t_new = interpolate(u, cw, t)\n\n    # Apply jitter to the samples.\n    if perturb:\n        jitter = torch.rand(t_new.shape, device=t.device) * (t_new[..., 1:] - t_new[..., :-1])\n        if single_jitter:\n            jitter = jitter.mean(dim=-1, keepdim=True)\n        t_new += jitter\n\n    return t_new.reshape(t_shape[:-1] + (num_samples,))\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Ensure that t and w are on the same device.\n    t, w = matchup_channels(t, w)\n\n    # Compute the CDF.\n    cw = integrate_weights(w)\n\n    # Sample the CDF.\n    u = torch.rand(num_samples, *w.shape[:-1], 1, device=w.device)\n    t_new = interpolate(u, cw, t)\n\n    # Apply perturbation.\n    if perturb:\n        # Compute the PDF.\n        delta = torch.cat([t[..., 1:] - t[..., :-1], t[..., -1:] - t[..., -1:]], -1)\n        pdf = w / delta\n\n        # Compute the CDF.\n        cdf = integrate_weights(pdf)\n\n        # Sample the CDF.\n        u = torch.rand(num_samples, *w.shape[:-1], 1, device=w.device)\n        t_new = interpolate(u, cdf, t)\n\n    # Apply jitter.\n    if single_jitter:\n        jitter = torch.rand_like(t_new)\n        t_new = t_new + jitter\n    else:\n        jitter = torch.rand_like(t_new)\n        t_new = t_new + jitter\n\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Validate input\n    assert t.ndim == 2\n    assert w.ndim == 2\n    assert t.shape[0] == w.shape[0]\n    assert t.shape[1] == w.shape[1] - 1\n    assert t.shape[0] == num_samples\n    assert t.dtype == w.dtype\n    assert t.dtype in [torch.float32, torch.float64]\n    assert isinstance(perturb, bool)\n    assert isinstance(single_jitter, bool)\n\n    # Generate samples\n    u = torch.rand(num_samples, device=t.device, dtype=t.dtype)\n    t_new = invert_cdf(u, t, w)\n\n    # Apply perturbation\n    if perturb:\n        t_new = perturb_sample(t_new, single_jitter)\n\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Compute the CDF.\n    cw = integrate_weights(w)\n    # Sample a set of u values from the CDF.\n    u = torch.rand(num_samples, *w.shape[:-1], device=w.device)\n    # Sample from the inverse CDF.\n    t_new = invert_cdf(u, t, w)\n    if perturb:\n        # Perturb the samples.\n        jitter = torch.rand(num_samples, *w.shape[:-1], device=w.device)\n        if single_jitter:\n            # Apply the same jitter to each sample.\n            jitter = jitter[..., None]\n        # Perturb the samples.\n        t_new = t_new + jitter * (t[..., 1:] - t[..., :-1])\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    # Compute the PDF and CDF for each weight vector.\n    cw = integrate_weights(w)\n    # Sample from the inverse CDF.\n    u = torch.rand(cw.shape[:-1] + (num_samples,), device=cw.device)\n    t_new = interpolate(u, cw, t)\n    if perturb:\n        # Perturb the samples.\n        if single_jitter:\n            # Apply the same jitter to all samples.\n            jitter = torch.randn(cw.shape[:-1] + (1,), device=cw.device)\n            t_new += jitter * (t[..., 1:] - t[..., :-1])\n        else:\n            # Apply independent jitter to each sample.\n            jitter = torch.randn(t_new.shape, device=cw.device)\n            t_new += jitter * (t[..., 1:] - t[..., :-1])\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Ensure that the inputs are tensors.\n    t = torch.as_tensor(t)\n    w = torch.as_tensor(w)\n\n    # Ensure that the weights sum to 1.\n    w = w / w.sum(dim=-1, keepdim=True)\n\n    # Get the number of dimensions.\n    num_dims = t.shape[-1]\n\n    # Get the number of bins.\n    num_bins = t.shape[-2]\n\n    # Ensure that the input tensors have the same number of dimensions.\n    if not t.ndim == w.ndim == num_dims:\n        raise ValueError(\n            f\"Input tensors must have the same number of dimensions. t.ndim = {t.ndim}, w.ndim = {w.ndim}, num_dims = {num_dims}.\"\n        )\n\n    # Ensure that the input tensors have the same shape.\n    if not t.shape[:-2] == w.shape[:-1]:\n        raise ValueError(\n            f\"Input tensors must have the same shape. t.shape = {t.shape}, w.shape = {w.shape}.\"\n        )\n\n    # Ensure that the input tensors have the same batch size.\n    if not t.shape[0] == w.shape[0]:\n        raise ValueError(\n            f\"Input tensors must have the same batch size. t.shape[0] = {t.shape[0]}, w.shape[0] = {w.shape[0]}.\"\n        )\n\n    # Ensure that the input tensors have the same number of bins.\n    if not t.shape[-2] == w.shape[-1]:\n        raise ValueError(\n            f\"Input tensors must have the same number of bins. t.shape[-2] = {t.shape[-2]}, w.shape[-1] = {w.shape[-1]}.\"\n        )\n\n    # Ensure that the number of samples is valid.\n    if not isinstance(num_samples, int) and num_samples >"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Ensure that the inputs are tensors.\n    t = torch.as_tensor(t, device=w.device)\n    w = torch.as_tensor(w, device=w.device)\n\n    # Ensure that the inputs have the same dtype.\n    t = t.type(w.dtype)\n\n    # Ensure that the input tensors have the same shape.\n    if t.shape != w.shape:\n        raise ValueError(\"t and w must have the same shape.\")\n\n    # Ensure that the inputs are one-dimensional.\n    if len(t.shape) != 1:\n        raise ValueError(\"t and w must be one-dimensional.\")\n\n    # Ensure that the number of samples is positive.\n    if num_samples < 1:\n        raise ValueError(\"num_samples must be positive.\")\n\n    # Ensure that the PDF is valid.\n    if not torch.all(w >= 0):\n        raise ValueError(\"The PDF is not valid because it contains negative weights.\")\n\n    # Ensure that the PDF is normalized.\n    if not torch.allclose(torch.sum(w, dim=-1), torch.tensor(1.0, device=w.device)):\n        raise ValueError(\"The PDF is not valid because it is not normalized.\")\n\n    # Ensure that the PDF is piecewise-constant.\n    if not torch.all(w[..., :-1] == w[..., 1:]):\n        raise ValueError(\"The PDF is not valid because it is not piecewise-constant.\")\n\n    # Ensure that the PDF is supported on the specified domain.\n    if not torch.all(t >= 0):\n        raise ValueError(\"The PDF is not valid because it is not supported on the specified domain.\")\n\n    # Ensure that the PDF is supported on the specified domain.\n    if not torch.all(t <= 1):\n        raise ValueError(\"The PDF is not valid because it is not supported on the specified domain.\")\n\n    # Ensure that the PDF is supported on the specified domain.\n    if not torch.all(t[..., 1:]"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Check that t and w are the same size.\n    if t.shape != w.shape:\n        raise ValueError('t and w must be the same size.')\n\n    # Check that t is sorted.\n    if not torch.all(t[:-1] <= t[1:]):\n        raise ValueError('t must be sorted.')\n\n    # Check that w is non-negative.\n    if torch.any(w < 0):\n        raise ValueError('w must be non-negative.')\n\n    # Check that num_samples is non-negative.\n    if num_samples < 0:\n        raise ValueError('num_samples must be non-negative.')\n\n    # Check that perturb is a boolean.\n    if not isinstance(perturb, bool):\n        raise ValueError('perturb must be a boolean.')\n\n    # Check that single_jitter is a boolean.\n    if not isinstance(single_jitter, bool):\n        raise ValueError('single_jitter must be a boolean.')\n\n    # Compute the CDF.\n    cw = integrate_weights(w)\n\n    # Sample the CDF.\n    u = torch.rand(num_samples, *t.shape, device=t.device)\n    t_new = interpolate(u, cw, t)\n\n    # Perturb the samples.\n    if perturb:\n        # Determine the perturbation size.\n        if single_jitter:\n            # Compute the perturbation size.\n            jitter = torch.randn(num_samples, device=t.device) * (t[1:] - t[:-1])\n            jitter = jitter[None, :, :]\n        else:\n            # Compute the perturbation size.\n            jitter = torch.randn_like(t_new) * (t[1:] - t[:-1])\n\n        # Perturb the samples.\n        t_new = t_new + jitter\n\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Check that t and w are compatible.\n    if t.shape[-1] != w.shape[-1] + 1:\n        raise ValueError('t and w must have the same length in the last dimension.')\n    if t.shape[:-1] != w.shape[:-1]:\n        raise ValueError('t and w must have the same shape in all but the last dimension.')\n\n    # Generate samples from the inverse CDF.\n    u = torch.rand(t.shape[:-1] + (num_samples,), device=t.device)\n    t_new = invert_cdf(u, t, w)\n\n    # Perturb the samples.\n    if perturb:\n        # Choose a perturbation scale.\n        if single_jitter:\n            jitter = torch.rand(1, device=t.device) * 0.5 / num_samples\n        else:\n            jitter = torch.rand(num_samples, device=t.device) * 0.5 / num_samples\n        # Perturb the samples.\n        t_new = t_new + jitter[None, None, :]\n\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Convert to torch.Tensor\n    t = torch.as_tensor(t, device=w.device, dtype=w.dtype)\n    w = torch.as_tensor(w, device=w.device, dtype=w.dtype)\n\n    # Validate input\n    if t.ndim != 2:\n        raise ValueError(f\"t must be a 2-dimensional tensor, but is {t.ndim}-dimensional.\")\n    if w.ndim != 2:\n        raise ValueError(f\"w must be a 2-dimensional tensor, but is {w.ndim}-dimensional.\")\n    if t.shape[0] != w.shape[0]:\n        raise ValueError(f\"The first dimension of t and w must be equal, but are {t.shape[0]} and {w.shape[0]}.\")\n    if t.shape[1] != w.shape[1] + 1:\n        raise ValueError(f\"The last dimension of t must be one larger than the second dimension of w, but are {t.shape[1]} and {w.shape[1]}.\")\n    if t.shape[1] < 2:\n        raise ValueError(f\"The last dimension of t must be at least 2, but is {t.shape[1]}.\")\n    if not torch.all(t[..., :-1] <= t[..., 1:]):\n        raise ValueError(f\"The elements of t must be sorted in ascending order.\")\n    if not torch.all(w >= 0):\n        raise ValueError(f\"The elements of w must be non-negative.\")\n    if not torch.all(w.sum(dim=-1) > 0):\n        raise ValueError(f\"The sum of the weights in each row of w must be positive.\")\n\n    # Compute CDF\n    cw = integrate_weights(w)\n\n    # Sample from CDF\n    u = torch.rand(num_samples, t.shape[0], device=t.device, dtype=t.dtype)\n    idx_lo, idx_hi = searchsorted("}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Check that the bin endpoints are sorted.\n    if not torch.all(t[:, 1:] >= t[:, :-1]):\n        raise ValueError('t must be sorted')\n\n    # Check that the weights are non-negative.\n    if torch.any(w < 0):\n        raise ValueError('w must be non-negative')\n\n    # Check that the weights sum to 1.\n    if not torch.allclose(w.sum(-1), torch.ones_like(w.sum(-1))):\n        raise ValueError('w must sum to 1')\n\n    # Check that the number of samples is non-negative.\n    if num_samples < 0:\n        raise ValueError('num_samples must be non-negative')\n\n    # Check that the perturbation parameter is in [0, 1).\n    if perturb and (perturb < 0 or perturb >= 1):\n        raise ValueError('perturb must be in [0, 1)')\n\n    # Check that the single_jitter parameter is a boolean.\n    if not isinstance(single_jitter, bool):\n        raise ValueError('single_jitter must be a boolean')\n\n    # Compute the bin widths.\n    t_widths = t[:, 1:] - t[:, :-1]\n\n    # Compute the CDF.\n    cw = integrate_weights(w)\n\n    # Generate samples.\n    u = torch.rand(num_samples, device=t.device)\n\n    # Apply perturbation.\n    if perturb:\n        u = u + perturb * (torch.rand(num_samples, device=t.device) - 0.5)\n\n    # Compute the inverse CDF.\n    t_samples = invert_cdf(u, t, w)\n\n    # Apply jitter.\n    if single_jitter:\n        t_samples = t_samples + (torch.rand(1, device=t.device) - 0.5) * t_widths\n    else:\n        t_samples = t_samples + (tor"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Determine the number of dimensions of the PDF.\n    num_dims = w.ndim\n\n    # Generate samples from the uniform distribution.\n    u = torch.rand(num_dims, num_samples, device=w.device)\n\n    # Invert the CDF to obtain samples from the PDF.\n    t_new = invert_cdf(u, t, w)\n\n    # Apply perturbation to the sampling process.\n    if perturb:\n        # Generate samples from the uniform distribution.\n        u = torch.rand(num_dims, num_samples, device=w.device)\n\n        # Determine the indices of the bins that correspond to each sample.\n        idx_lo, idx_hi = searchsorted(t, t_new)\n\n        # Generate jitter samples from the uniform distribution.\n        jitter = torch.rand(num_dims, num_samples, device=w.device)\n\n        # Apply jitter to samples.\n        if single_jitter:\n            # Apply the same jitter to every sample along each dimension.\n            jitter = jitter * (t[..., 1:] - t[..., :-1])\n        else:\n            # Apply independent jitter to each sample.\n            jitter = jitter * (t[idx_hi] - t[idx_lo])\n        t_new = t_new + jitter\n\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n\n    # If no weights are provided, use equal weights.\n    if w is None:\n        w = torch.ones_like(t)\n\n    # Generate samples for each bin.\n    cw = integrate_weights(w)\n    u = torch.rand(cw.shape[:-1] + (num_samples,), device=t.device)\n    t_new = interpolate(u, cw, t)\n\n    # Apply perturbation and/or jittering to the samples.\n    if perturb or not single_jitter:\n        t_new = invert_cdf(u, t, w)\n    if perturb:\n        t_new = t_new + torch.randn_like(t_new) * 0.001\n    if not single_jitter:\n        t_new = t_new + torch.randn_like(t_new) * 0.001\n\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Check that the inputs are valid.\n    assert t.ndim == 2\n    assert w.ndim == 2\n    assert t.shape[0] == w.shape[0]\n    assert t.shape[1] == w.shape[1]\n    assert t.shape[1] >= 2\n    assert 0 <= t.min()\n    assert t.max() <= 1\n    assert 0 <= w.min()\n    assert w.max() <= 1\n    assert 0 < num_samples\n\n    # Sample from the CDF.\n    u = torch.rand(num_samples, device=t.device)\n    t_new = invert_cdf(u, t, w)\n\n    # Perturb the samples.\n    if perturb:\n        # Sample jitter from a uniform distribution.\n        jitter = torch.rand(num_samples, t.shape[1], device=t.device)\n        # If we only want to use a single jitter for all dimensions, use the mean.\n        if single_jitter:\n            jitter = jitter - jitter.mean(dim=1, keepdim=True)\n        # Perturb the samples.\n        t_new = t_new + jitter\n\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Check that the weights sum to 1.\n    assert torch.allclose(w.sum(dim=-1), torch.ones_like(w[..., 0:1])), 'The weights must sum to 1.'\n\n    # Check that the bin endpoints are sorted.\n    assert torch.all(t[:, 1:] > t[:, :-1]), 'The bin endpoints must be sorted.'\n\n    # Check that the number of samples is valid.\n    assert isinstance(num_samples, int), 'The number of samples must be an integer.'\n    assert num_samples >= 1, 'The number of samples must be positive.'\n\n    # Check that perturb is valid.\n    assert isinstance(perturb, bool), 'Perturb must be a boolean.'\n\n    # Check that single_jitter is valid.\n    assert isinstance(single_jitter, bool), 'Single_jitter must be a boolean.'\n\n    # Compute the CDF.\n    cw = integrate_weights(w)\n\n    # Generate random samples.\n    u = torch.rand(cw.shape[:-1] + (num_samples,), device=cw.device)\n\n    # Apply importance sampling.\n    t_new = interpolate(u, cw, t)\n\n    # Apply perturbation.\n    if perturb:\n        # Generate random perturbations.\n        u_perturb = torch.rand(cw.shape[:-1] + (num_samples,), device=cw.device)\n\n        # Apply perturbation.\n        if single_jitter:\n            # Apply the same perturbation to all samples along each dimension.\n            t_new = t_new + (t_new - t_new.min(dim=-2, keepdim=True)[0]).mean(dim=-2, keepdim=True) * u_perturb\n        else:\n            # Apply independent perturbations to each sample.\n            t_new = t_new + (t_new - t_new.min(dim=-2, keepdim=True)[0]) * u_perturb\n\n    return"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n\n    t_dilated = torch.ceil(t / dilation) * dilation\n    t_dilated = torch.clamp(t_dilated, min=domain[0], max=domain[1])\n    w_dilated = weight_to_pdf(t_dilated, pdf_to_weight(t, w))\n\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # Ensure that the time steps are non-negative.\n    assert (t >= 0).all()\n\n    # Compute the dilated time steps.\n    t_dilated = torch.arange(domain[0], domain[1], dilation, device=t.device)\n\n    # Compute the weights associated with the dilated time steps.\n    w_dilated = weight_to_pdf(t, w)\n    w_dilated = pdf_to_weight(t_dilated, w_dilated)\n\n    # Ensure that the weights are non-negative.\n    assert (w_dilated >= 0).all()\n\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n    t = t.unsqueeze(0)\n    w = w.unsqueeze(0)\n    t = t.repeat(w.shape[1], 1, 1)\n    w = w.repeat(1, 1, 1)\n    dilated_t = torch.nn.functional.max_pool1d(t, dilation, dilation).squeeze(0)\n    dilated_w = torch.nn.functional.max_pool1d(w, dilation, dilation).squeeze(0)\n    dilated_t = dilated_t.clamp(domain[0], domain[1])\n    return dilated_t, dilated_w\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n\n    # Dilate the time steps.\n    t_dilated = torch.arange(domain[0], domain[1], dilation, device=t.device, dtype=t.dtype)\n\n    # Clip the dilated time steps to the domain.\n    t_dilated = t_dilated.clamp(min=domain[0], max=domain[1])\n\n    # Get the indices of the dilated time steps within the original time steps.\n    idx_dilated = torch.searchsorted(t[..., 1:], t_dilated, right=True)\n\n    # Get the dilated weights by indexing the original weights with the dilated indices.\n    w_dilated = w[..., 1:].gather(-1, idx_dilated)\n\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n    t_dilated = torch.arange(domain[0], domain[1], dilation, device=t.device, dtype=t.dtype)\n    w_dilated = torch.zeros_like(t_dilated)\n    t_dilated, t = matchup_channels(t_dilated, t)\n    t_dilated, w_dilated = matchup_channels(t_dilated, w_dilated)\n    t_dilated = t_dilated[..., None]\n    w_dilated = w_dilated[..., None]\n\n    t_dilated_indices = torch.searchsorted(t_dilated, t)\n    t_dilated_indices = torch.clamp(t_dilated_indices, 0, w_dilated.shape[-1] - 1)\n    w_dilated.scatter_add_(dim=-1, index=t_dilated_indices, src=w)\n\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n\n    t_dilated = torch.arange(domain[0], domain[1], dilation, device=t.device, dtype=t.dtype)\n    t_dilated = t_dilated[None, :, None].expand(t.shape[:-1] + (t_dilated.shape[-1],))\n\n    t_dilated_ = t[..., None, :]\n    w_dilated_ = w[..., None, :]\n\n    t_dilated_ = t_dilated_.expand(t_dilated_.shape[:-2] + (t_dilated.shape[-1],))\n    w_dilated_ = w_dilated_.expand(w_dilated_.shape[:-2] + (t_dilated.shape[-1],))\n\n    t_dilated, w_dilated = torch.max(\n        torch.cat([t_dilated_, w_dilated_], dim=-1), dim=-1)\n\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n    # Dilate the time steps.\n    t_dilated = t.unsqueeze(-1) + dilation * torch.arange(\n        t.shape[-1], device=t.device, dtype=t.dtype\n    )\n    # Clip the dilated time steps to the given domain.\n    t_dilated = t_dilated.clamp(min=domain[0], max=domain[1])\n    # Find the indices of the dilated time steps that are within the domain.\n    t_in_domain = (t_dilated >= domain[0]) & (t_dilated <= domain[1])\n    # Find the indices of the dilated time steps that are within the domain and the original time steps.\n    t_dilated_in_domain_and_t = t_in_domain & (t_dilated[:, None, :] == t.unsqueeze(-2))\n    # Find the indices of the dilated time steps that are within the domain and not in the original time steps.\n    t_dilated_in_domain_and_not_t = t_in_domain & ~t_dilated_in_domain_and_t.any(dim=-1)\n    # Find the indices of the dilated time steps that are not within the domain and in the original time steps.\n    t_dilated_not_in_domain_and_t = ~t_in_domain & (t_dilated[:, None, :] == t.unsqueeze(-2))\n    # Find the indices of the dilated time steps that are not within the domain and not in the original time steps.\n    t_dilated_not_in_domain_and_not_t = ~t_in_domain & ~t_dilated_not_in_domain_and_t.any(dim=-1)\n    # Find the indices of the dilated time steps that are within the domain and not in the original time steps and have the largest weight.\n    t_dilated_in_domain_and_not_"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # Ensure that the time steps are non-negative.\n    assert (t >= 0.0).all()\n\n    # Ensure that the dilation is positive.\n    assert dilation > 0.0\n\n    # Ensure that the domain is valid.\n    assert domain[0] < domain[1]\n\n    # Determine the number of time steps.\n    num_time_steps = t.shape[-1]\n\n    # Determine the number of dilation steps.\n    num_dilation_steps = int(math.ceil(num_time_steps / dilation))\n\n    # Determine the dilation steps.\n    dilations = torch.arange(num_dilation_steps, device=t.device) * dilation\n\n    # Determine the dilated time steps.\n    t_dilated = torch.take_along_dim(t, dilations[..., None], dim=-1).squeeze(-1)\n\n    # Clip the dilated time steps to the specified domain.\n    t_dilated = t_dilated.clamp(min=domain[0], max=domain[1])\n\n    # Determine the indices of the dilated time steps.\n    dilated_indices = torch.searchsorted(t, t_dilated)\n\n    # Determine the dilated weights.\n    w_dilated = torch.take_along_dim(w, dilated_indices[..., None], dim=-1).squeeze(-1)\n\n    # Return the dilated time steps and dilated weights.\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n\n    if dilation == 1:\n        return t, w\n\n    if dilation <= 0:\n        raise ValueError(f\"Dilation must be positive, got {dilation}\")\n\n    if len(t.shape) != 2:\n        raise ValueError(f\"t must be two dimensional, got {len(t.shape)}\")\n\n    if t.shape[1] != 1:\n        raise ValueError(f\"t must have a single channel, got {t.shape[1]}\")\n\n    if len(w.shape) != 2:\n        raise ValueError(f\"w must be two dimensional, got {len(w.shape)}\")\n\n    if w.shape[1] != 1:\n        raise ValueError(f\"w must have a single channel, got {w.shape[1]}\")\n\n    if t.shape[0] != w.shape[0]:\n        raise ValueError(f\"t and w must have the same batch size, got {t.shape[0]} and {w.shape[0]}\")\n\n    if t.shape[1] != w.shape[1]:\n        raise ValueError(f\"t and w must have the same number of time steps, got {t.shape[1]} and {w.shape[1]}\")\n\n    if t.dtype != w.dtype:\n        raise ValueError(f\"t and w must have the same dtype, got {t.dtype} and {w.dtype}\")\n\n    if t.dtype != torch.float32:\n        raise ValueError(f\"t and w must have dtype float32, got {t.dtype}\")\n\n    if not isinstance(domain, tuple) or len(domain) != 2:\n        raise ValueError(f\"domain must be a tuple of two floats, got {domain}\")\n\n    if domain[0] >= domain[1]:\n        raise ValueError(f\"domain must be a tuple of two floats, got {domain}\")\n\n    if domain[0] < -torch.inf:\n        raise"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # Check if the time steps are sorted.\n    assert (t[..., 1:] > t[..., :-1]).all()\n    # Check if the weights are non-negative.\n    assert (w >= 0).all()\n\n    # Compute the PDF and CDF for each weight vector.\n    cw = integrate_weights(w)\n    # Dilate the time steps.\n    t_dilated = t[..., None, :] * torch.ones_like(cw) + dilation\n    # Clip the dilated time steps to the domain.\n    t_dilated = t_dilated.clamp(min=domain[0], max=domain[1])\n    # Compute the weights corresponding to the dilated time steps.\n    w_dilated = pdf_to_weight(t_dilated, cw)\n    # Return the dilated time steps and weights.\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # Ensure that the time steps are non-negative.\n    assert (t >= 0.0).all()\n\n    # Ensure that the weights are non-negative.\n    assert (w >= 0.0).all()\n\n    # Ensure that the dilation is positive.\n    assert dilation > 0.0\n\n    # Ensure that the domain is valid.\n    assert domain[0] < domain[1]\n\n    # Compute the number of time steps.\n    num_time_steps = t.shape[-1]\n\n    # Determine the dilation amount in terms of the number of time steps.\n    dilation_amount = int(dilation * num_time_steps)\n\n    # Ensure that the dilation amount is valid.\n    assert dilation_amount > 0\n\n    # Determine the dilated time steps.\n    t_dilated = t.unfold(-1, dilation_amount, dilation_amount)\n\n    # Compute the maximum dilated time steps.\n    t_dilated = t_dilated.max(-1).values\n\n    # Clip the dilated time steps to the given domain.\n    t_dilated = t_dilated.clamp(min=domain[0], max=domain[1])\n\n    # Determine the dilated weights.\n    w_dilated = w.unfold(-1, dilation_amount, dilation_amount).max(-1).values\n\n    # Return the dilated time steps and dilated weights.\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # TODO: Add support for batching.\n    # TODO: Add support for dilation of non-uniformly sampled step functions.\n    # TODO: Add support for dilation of step functions with non-uniformly sampled weights.\n\n    # Validate the input arguments.\n    if not isinstance(t, torch.Tensor):\n        raise TypeError(\"The time steps must be a PyTorch Tensor.\")\n    if not isinstance(w, torch.Tensor):\n        raise TypeError(\"The weights must be a PyTorch Tensor.\")\n    if not isinstance(dilation, (int, float)):\n        raise TypeError(\"The dilation parameter must be a float.\")\n    if not isinstance(domain, tuple):\n        raise TypeError(\"The domain must be a tuple.\")\n    if not len(domain) == 2:\n        raise ValueError(\"The domain must be a tuple of two floats.\")\n    if not isinstance(domain[0], (int, float)):\n        raise TypeError(\"The first element of the domain must be a float.\")\n    if not isinstance(domain[1], (int, float)):\n        raise TypeError(\"The second element of the domain must be a float.\")\n    if not t.ndim == 2:\n        raise ValueError(\"The time steps must be two-dimensional.\")\n    if not w.ndim == 2:\n        raise ValueError(\"The weights must be two-dimensional.\")\n    if not t.shape[1] == w.shape[1]:\n        raise ValueError(\"The number of time steps must match the number of weights.\")\n    if not t.shape[1] > 1:\n        raise ValueError(\"There must be at least two time steps.\")\n    if not t.shape[1] == w.shape[1]:\n        raise ValueError(\"The number of time steps must match the number of weights.\")\n    if not t.shape[0] == w.shape[0]:\n        raise ValueError(\"The batch size must be the same for the time steps and weights.\")\n    if not t.dtype == w.dtype:\n        raise TypeError(\"The time steps and weights must have the same data type.\")\n    if not t.dtype"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # Check that the time steps and weights have the same shape.\n    if t.shape != w.shape:\n        raise ValueError(\"The shapes of the time steps and weights must match.\")\n\n    # Check that the time steps are non-negative.\n    if (t < 0).any():\n        raise ValueError(\"The time steps must be non-negative.\")\n\n    # Check that the dilation is a positive float.\n    if dilation <= 0:\n        raise ValueError(\"The dilation must be a positive float.\")\n\n    # Check that the domain is a tuple of two floats.\n    if (not isinstance(domain, tuple)) or (len(domain) != 2):\n        raise ValueError(\"The domain must be a tuple of two floats.\")\n\n    # Check that the domain is ordered correctly.\n    if domain[0] >= domain[1]:\n        raise ValueError(\"The first element of the domain must be less than the second element.\")\n\n    # Determine the number of time steps.\n    num_t = t.shape[-1]\n\n    # Determine the number of time steps to dilate by.\n    num_dilated_t = int(dilation * num_t)\n\n    # Determine the dilation factor.\n    dilate_factor = num_dilated_t / num_t\n\n    # Determine the dilation stride.\n    dilate_stride = 1 / dilate_factor\n\n    # Determine the dilation padding.\n    dilate_padding = (dilate_stride - (1 / num_t)) / 2\n\n    # Determine the dilation kernel size.\n    dilate_kernel_size = (1, num_t)\n\n    # Determine the dilation stride.\n    dilate_stride = (1, 1)\n\n    # Determine the dilation padding.\n    dilate_padding = (0, 0), (int(dilate_padding), int(dilate_padding))\n\n    # Determine the dilation dilation.\n    dilate_dilation = (1, "}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # get the time steps\n    t_dilated = t.clone()\n\n    # dilate the time steps\n    t_dilated = torch.cat((t_dilated[..., 0][..., None], (t_dilated[..., 1:] + t_dilated[..., :-1]) / 2, t_dilated[..., -1][..., None]), dim=-1)\n\n    # clip the dilated time steps\n    t_dilated = t_dilated.clamp(min=domain[0], max=domain[1])\n\n    # get the weights\n    w_dilated = w.clone()\n\n    # adjust the weights\n    w_dilated = torch.cat((w_dilated[..., 0][..., None], (w_dilated[..., 1:] + w_dilated[..., :-1]) / 2, w_dilated[..., -1][..., None]), dim=-1)\n\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # Ensure the time steps are non-negative.\n    assert (t >= 0).all()\n\n    # Ensure the weights are non-negative.\n    assert (w >= 0).all()\n\n    # Ensure the dilation is non-negative.\n    assert dilation > 0\n\n    # Ensure the domain is valid.\n    assert len(domain) == 2\n    assert domain[0] < domain[1]\n\n    # Ensure the time steps and weights are the same size.\n    assert t.shape[-1] == w.shape[-1]\n\n    # Ensure the time steps and weights are the same size.\n    assert t.shape[-1] == w.shape[-1]\n\n    # Ensure the time steps are sorted.\n    assert (t[..., 1:] > t[..., :-1]).all()\n\n    # Ensure the domain is valid.\n    assert domain[0] < domain[1]\n\n    # Ensure the dilation is non-negative.\n    assert dilation > 0\n\n    # Get the number of time steps.\n    num_time_steps = t.shape[-1]\n\n    # Get the number of dilated time steps.\n    num_dilated_time_steps = int(num_time_steps * dilation)\n\n    # Initialize the dilated time steps.\n    dilated_t = torch.linspace(domain[0], domain[1], num_dilated_time_steps, device=t.device, dtype=t.dtype)\n\n    # Get the indices of the dilated time steps within the original time steps.\n    idx = searchsorted(t, dilated_t)\n\n    # Clip the indices to be within the original time step bounds.\n    idx = idx.clamp(min=0, max=num_time_steps - 1)\n\n    # Get the dilated time steps.\n    dilated_t = t.gather(-1, idx)\n\n    # Get the dilated weights.\n    dilated_w = w.gather(-1, idx)\n\n    # Return the dilated time steps and dilated"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # Match the dimensions of the time steps and weights.\n    t, w = matchup_channels(t, w)\n\n    # Determine the number of time steps.\n    num_t = t.shape[-1]\n\n    # Determine the dilation factor.\n    dilation_factor = int(dilation)\n\n    # Determine the dilation stride.\n    dilation_stride = dilation_factor\n\n    # Determine the number of dilated time steps.\n    num_t_dilated = int(1 + (num_t - 1) * dilation_factor)\n\n    # Determine the dilated time steps.\n    t_dilated = torch.linspace(domain[0], domain[1], num_t_dilated, device=t.device, dtype=t.dtype)\n\n    # Determine the indices of the dilated time steps.\n    t_dilated_indices = torch.linspace(0, num_t - 1, num_t_dilated, device=t.device, dtype=torch.long)\n\n    # Determine the indices of the dilated time steps.\n    t_dilated_indices = t_dilated_indices.div(dilation_stride).floor().to(torch.long)\n\n    # Determine the dilated weights.\n    w_dilated = w.gather(-1, t_dilated_indices[..., None]).squeeze(-1)\n\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n\n    # Get the number of time steps in the step function.\n    num_time_steps = t.shape[-1]\n\n    # Get the indices of the dilated time steps.\n    dilated_indices = torch.arange(0, num_time_steps, dilation, device=t.device)\n\n    # Clip the dilated time steps to the given domain.\n    dilated_indices = torch.clamp(dilated_indices, min(domain), max(domain))\n\n    # Get the dilated time steps.\n    dilated_t = t[..., dilated_indices]\n\n    # Get the dilated weights.\n    dilated_w = w[..., dilated_indices - torch.arange(0, num_time_steps, device=t.device)[:, None]]\n\n    return dilated_t, dilated_w\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # t, w = matchup_channels(t, w)\n    # assert torch.all(t[..., 1:] >= t[..., :-1]), \"t must be strictly increasing\"\n    # assert torch.all(w >= 0), \"w must be non-negative\"\n    # assert t.shape[-1] == w.shape[-1] + 1, \"t must have one more element than w\"\n\n    # t = t.unsqueeze(-2)\n    # w = w.unsqueeze(-2)\n\n    # dilation_shape = torch.as_tensor((1, 1, 1, dilation))\n    # dilation_shape = dilation_shape.expand(t.shape)\n    # dilated_t = t.unsqueeze(-1).expand(*dilation_shape).flatten(-2)\n    # dilated_w = w.unsqueeze(-1).expand(*dilation_shape).flatten(-2)\n\n    # dilated_t = dilated_t.clamp(*domain)\n\n    # dilated_w = dilated_w * (dilated_t[..., 1:] - dilated_t[..., :-1])\n\n    # return dilated_t, dilated_w\n    raise NotImplementedError\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n\n    t = t.reshape(-1, t.shape[-1])\n    w = w.reshape(-1, w.shape[-1])\n\n    # Dilate the time steps.\n    t_dilated = t.unsqueeze(-1) + torch.arange(0, dilation, device=t.device, dtype=t.dtype)\n\n    # Clip the dilated time steps within the given domain.\n    t_dilated = t_dilated.clamp(min=domain[0], max=domain[1])\n\n    # Compute the adjusted weights corresponding to the dilated time steps.\n    w_dilated = torch.nn.functional.interpolate(w.unsqueeze(-1), t_dilated.shape[-1], mode='linear', align_corners=False).squeeze(-1)\n\n    # Make sure the weights are non-negative and sum to 1.\n    w_dilated = w_dilated.clamp(min=0)\n    w_dilated = w_dilated / w_dilated.sum(dim=-1, keepdim=True)\n\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # TODO: Make sure the inputs are valid.\n\n    # Find the width of each bin.\n    t_width = t[..., 1:] - t[..., :-1]\n\n    # Dilate the time steps.\n    t_dilated = t + dilation * t_width\n\n    # Clip the dilated time steps to the given domain.\n    t_dilated = t_dilated.clamp(min=domain[0], max=domain[1])\n\n    # Find the indices of the dilated time steps within the original time steps.\n    t_idx = torch.searchsorted(t[..., :-1], t_dilated)\n\n    # Find the width of the dilated time steps within the original time steps.\n    t_dilated_width = t_dilated - t[..., t_idx]\n\n    # Adjust the weights to account for the dilated time steps.\n    w_dilated = w * t_dilated_width / t_width\n\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    tq, t, y = matchup_channels(tq, t, y)\n\n    # We need to make sure that the query times are within the range of the step function.\n    tq = tq.clip(t[..., 0], t[..., -1])\n\n    # The query times are in the range of the step function, so we can use searchsorted.\n    # The query times are in the range of the step function, so we can use searchsorted.\n    # The query times are in the range of the step function, so we can use searchsorted.\n    # The query times are in the range of the step function, so we can use searchsorted.\n    # The query times are in the range of the step function, so we can use searchsorted.\n    # The query times are in the range of the step function, so we can use searchsorted.\n    # The query times are in the range of the step function, so we can use searchsorted.\n    # The query times are in the range of the step function, so we can use searchsorted.\n    # The query times are in the range of the step function, so we can use searchsorted.\n    # The query times are in the range of the step function, so we can use searchsorted.\n    # The query times are in the range of the step function, so we can use searchsorted.\n    # The query times are in the range of the step function, so we can use searchsorted.\n    # The query times are in the range of the step function, so we can use searchsorted.\n    # The query times are in the range of the step function, so we can use searchsorted.\n    # The query times are in the range of the step function, so we can use searchsorted.\n    # The query times are in the range of the step function, so we can use searchsorted.\n    # The query times are in the range of the step function, so we can use searchsorted.\n    # The query times are in the range of the step function, so we can use searchsorted.\n    # The query times are in the range of the step function, so we can use searchsorted.\n    # The query times are in the range of the step function"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    tq, t, y = matchup_channels(tq, t, y)\n    # If the query time matches a step change time, return the outside value.\n    y_query = torch.where(\n        tq[..., None, :] == t[..., None, :],\n        outside_value,\n        # Interpolate the value at the query time.\n        interpolate(tq, t, y))\n    return y_query\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # tq, t, y = matchup_channels(tq, t, y)\n    # sh = tq.shape[:-1]\n    # tq = tq.reshape(-1, tq.shape[-1])\n    # t = t.reshape(-1, t.shape[-1])\n    # y = y.reshape(-1, y.shape[-1])\n\n    # tq_idxs = torch.searchsorted(t, tq)\n    # tq_idxs_left = torch.clip(tq_idxs - 1, min=0)\n    # tq_idxs_right = torch.clip(tq_idxs, max=t.shape[-1] - 1)\n    # tq_left = torch.gather(t, -1, tq_idxs_left)\n    # tq_right = torch.gather(t, -1, tq_idxs_right)\n    # y_left = torch.gather(y, -1, tq_idxs_left)\n    # y_right = torch.gather(y, -1, tq_idxs_right)\n\n    # yq = torch.where(tq_left == tq_right, outside_value, y_left + (y_right - y_left) * (tq - tq_left) / (tq_right - tq_left))\n\n    # return yq.reshape(sh + (y.shape[-1],))\n\n    tq, t, y = matchup_channels(tq, t, y)\n    sh = tq.shape[:-1]\n    tq = tq.reshape(-1, tq.shape[-1])\n    t = t.reshape(-1, t.shape[-1])\n    y = y.reshape(-1, y.shape[-1])\n\n    tq_idxs = torch.searchsorted(t, tq)\n    tq_idxs_left = torch.clip(tq_idxs - 1, min"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # tq: [B, P, I, 1]\n    # t: [B, P, I]\n    # y: [B, P, I]\n\n    # sh: [B, P, I]\n    sh = tq.shape[:-1]\n\n    # tq_flat: [B*P*I, 1]\n    tq_flat = tq.reshape(-1, 1)\n\n    # t_flat: [B*P*I, I]\n    t_flat = t.reshape(-1, t.shape[-1])\n\n    # y_flat: [B*P*I, I]\n    y_flat = y.reshape(-1, y.shape[-1])\n\n    # idx_flat: [B*P*I, I]\n    idx_flat = searchsorted(t_flat, tq_flat)\n\n    # idx_flat: [B*P*I]\n    idx_flat = idx_flat.squeeze(-1)\n\n    # idx_flat: [B, P, I]\n    idx_flat = idx_flat.reshape(sh)\n\n    # t_flat: [B, P, I, I]\n    t_flat = t_flat.reshape(*sh, t.shape[-1])\n\n    # y_flat: [B, P, I, I]\n    y_flat = y_flat.reshape(*sh, y.shape[-1])\n\n    # idx_flat_mask: [B, P, I]\n    idx_flat_mask = idx_flat < t.shape[-1]\n\n    # idx_flat: [B, P, I]\n    idx_flat = idx_flat.masked_fill(~idx_flat_mask, t.shape[-1] - 1)\n\n    # t_flat: [B, P, I, 1]\n    t_flat = t_flat.gather(-1, idx_flat[..., None])\n\n    # y_flat: [B, P, I, 1]\n    y_flat = y_flat.gather"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Ensure that the query times are sorted.\n    tq = tq.sort(dim=-1)[0]\n\n    # Find the index of the first step change that occurs after each query time.\n    idx = torch.searchsorted(t, tq, right=True)\n\n    # Find the query times that exactly match a step change.\n    mask = tq[..., None] == t[..., None, :]\n\n    # Set the value of the step function at the query times that match a step change.\n    yq = torch.where(mask, y[..., None, :], outside_value)\n\n    # Find the indices of the previous step change for each query time.\n    idx_prev = idx - 1\n\n    # Find the indices of the next step change for each query time.\n    idx_next = idx + 1\n\n    # Find the query times that are outside the range of the step function.\n    mask = (idx == 0) | (idx == t.shape[-1])\n\n    # Set the value of the step function at the query times that are outside the range of the step function.\n    yq = torch.where(mask, outside_value, yq)\n\n    # Set the indices of the previous step change for the query times that are outside the range of the step function.\n    idx_prev = torch.where(mask, 0, idx_prev)\n\n    # Set the indices of the next step change for the query times that are outside the range of the step function.\n    idx_next = torch.where(mask, 1, idx_next)\n\n    # Find the query times that are between step changes.\n    mask = ~mask\n\n    # Find the value of the step function at the previous step change.\n    y0 = y[..., idx_prev, None]\n\n    # Find the value of the step function at the next step change.\n    y1 = y[..., idx_next, None]\n\n    # Find the time of the previous step change.\n    t0 = t[..., idx_prev, None]\n\n    # Find the time of the next step change.\n    t1 = t"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Compute the slope of the step function at each step.\n    slope = (y[..., 1:] - y[..., :-1]) / (t[..., 1:] - t[..., :-1]).clamp(min=1e-8)\n\n    # Find the indices of the steps that are closest to the query times.\n    idx = searchsorted(t[..., :-1], tq)\n\n    # Compute the value of the step function at the query times.\n    yq = torch.where(tq == t[..., :-1], outside_value, y[..., idx])\n    yq = yq + (tq - t[..., idx]) * slope[..., idx]\n\n    return yq\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Check that tq is a Tensor\n    if not torch.is_tensor(tq):\n        raise TypeError('The query times (tq) must be a Tensor.')\n    # Check that t is a Tensor\n    if not torch.is_tensor(t):\n        raise TypeError('The times (t) must be a Tensor.')\n    # Check that y is a Tensor\n    if not torch.is_tensor(y):\n        raise TypeError('The values (y) must be a Tensor.')\n    # Check that tq and t have the same type\n    if tq.dtype is not t.dtype:\n        raise TypeError('The query times (tq) and the times (t) must have the same type.')\n    # Check that tq and y have the same type\n    if tq.dtype is not y.dtype:\n        raise TypeError('The query times (tq) and the values (y) must have the same type.')\n    # Check that t and y have the same shape\n    if t.shape != y.shape:\n        raise ValueError('The times (t) and the values (y) must have the same shape.')\n    # Check that tq and t are one-dimensional\n    if tq.ndim != 1:\n        raise ValueError('The query times (tq) must be one-dimensional.')\n    if t.ndim != 1:\n        raise ValueError('The times (t) must be one-dimensional.')\n    # Check that tq and t are sorted in ascending order\n    if torch.any(tq < t[:-1]):\n        raise ValueError('The query times (tq) must be sorted in ascending order.')\n    if torch.any(t < t[1:]):\n        raise ValueError('The times (t) must be sorted in ascending order.')\n    # Check that tq and t have the same dtype\n    if tq.dtype is not t.dtype:\n        raise TypeError('The query times (tq) and the times (t) must have the same dtype.')\n    # Check that t"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # If tq is outside the domain of t, return the outside value.\n    if tq.min() < t.min() or tq.max() > t.max():\n        return outside_value\n\n    # If tq is inside the domain of t, return the step function value.\n    tq_idx = torch.searchsorted(t, tq)\n    return y[tq_idx]\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    tq, t, y = matchup_channels(tq, t, y)\n\n    # Find the indices of the query times that match the times of the step function.\n    indices = torch.searchsorted(t, tq)\n\n    # If a query time matches a step change time, return the outside value.\n    y_query = torch.where(tq[..., None] == t[..., None, :], outside_value, y)\n\n    # If a query time does not match a step change time, interpolate the step function.\n    indices = torch.clamp(indices, 1, len(t) - 1)\n    y_query = torch.where(tq[..., None] == t[..., None, :], outside_value, y)\n    y_query = y_query.gather(-1, indices)\n    t_low = t.index_select(-1, indices - 1)\n    t_high = t.index_select(-1, indices)\n    y_low = y.index_select(-1, indices - 1)\n    y_high = y.index_select(-1, indices)\n    y_query = y_low + (t_low - tq[..., None]) * (y_high - y_low) / (t_high - t_low + 1e-8)\n\n    return y_query"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Find the index of the first step change that occurs after the query time.\n    idx = torch.sum(tq[..., None] < t[..., None, :], dim=-1)\n\n    # If a query time exactly matches a step change, return the outside value.\n    yq = torch.where(tq[..., None] == t[..., None, :], outside_value, y)\n\n    # Interpolate between the query time and the previous step change time.\n    yq = yq.gather(-1, idx)\n\n    return yq\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # tq, t, y = matchup_channels(tq, t, y)\n\n    # Get the indices of the query times that match a step change time.\n    indices = searchsorted(t, tq) - 1\n    indices = torch.where(t[..., 1:] == tq[..., None], indices + 1, indices)\n\n    # Get the values of the step function at the query times.\n    yq = torch.gather(y, dim=-1, index=indices)\n\n    # Set the values of the query times that match a step change time to the outside value.\n    yq = torch.where(t[..., 1:] == tq[..., None], outside_value, yq)\n\n    return yq\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    tq, t, y = matchup_channels(tq, t, y)\n    # The number of query times and step function points must be the same.\n    assert tq.shape[-1] == t.shape[-1]\n\n    # If the query time is exactly equal to a step change time, return the outside value.\n    idx_exact = searchsorted(tq, t)\n    yq = torch.where(tq[..., None] == t[..., :, None], outside_value, y)\n\n    # Interpolate the value at the query time.\n    idx_below = idx_exact - 1\n    idx_above = idx_exact\n    idx_below = torch.where(idx_below < 0, 0, idx_below)\n    idx_above = torch.where(idx_above >= t.shape[-1], t.shape[-1] - 1, idx_above)\n    t_below = t[..., idx_below]\n    t_above = t[..., idx_above]\n    y_below = y[..., idx_below]\n    y_above = y[..., idx_above]\n    yq = y_below + (tq - t_below) * (y_above - y_below) / (t_above - t_below + 1e-8)\n    return yq\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Ensure that tq is a tensor.\n    tq = torch.as_tensor(tq, device=t.device)\n\n    # Ensure that tq is a float.\n    tq = tq.to(torch.float)\n\n    # Ensure that t and y are tensors.\n    t = torch.as_tensor(t, device=t.device)\n    y = torch.as_tensor(y, device=t.device)\n\n    # Ensure that t and y have the same dtype.\n    t = t.to(y.dtype)\n\n    # Ensure that t and y have the same shape.\n    if t.shape != y.shape:\n        raise ValueError('t and y must have the same shape.')\n\n    # Ensure that t and tq have the same number of dimensions.\n    if t.ndim != tq.ndim:\n        raise ValueError('t and tq must have the same number of dimensions.')\n\n    # Ensure that the last dimension of t and tq is 1.\n    if t.shape[-1] != 1:\n        raise ValueError('The last dimension of t and tq must be 1.')\n\n    # Ensure that t and tq are monotonically increasing.\n    if torch.any(torch.diff(t) <= 0):\n        raise ValueError('t must be monotonically increasing.')\n\n    # Ensure that t and tq have the same batch size.\n    if t.shape[:-1] != tq.shape[:-1]:\n        raise ValueError('The batch sizes of t and tq must be the same.')\n\n    # Ensure that the last element of t is greater than the last element of tq.\n    if t[..., -1] <= tq[..., -1]:\n        raise ValueError('The last element of t must be greater than the last element of tq.')\n\n    # Ensure that t and tq have the same dtype.\n    tq = tq.to(t.dtype)\n\n    # Ensure that tq is in the range"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # tq, t, y: [B, P, I, 1]\n    # outside_value: Numeric\n\n    # Find the indices of the step function intervals that contain the query times.\n    idx = searchsorted(t, tq)  # [B, P, I, 1]\n\n    # Mask for the indices that are out of bounds.\n    mask = (idx == 0) | (idx == t.shape[-1])  # [B, P, I, 1]\n\n    # Set the indices that are out of bounds to the first or last step function interval.\n    idx = idx.clip(1, t.shape[-1] - 1)  # [B, P, I, 1]\n\n    # Get the values of the step function at the query times.\n    yq = y.gather(-2, idx)  # [B, P, I, 1]\n\n    # Get the values of the step function at the query times.\n    tq = t.gather(-2, idx)  # [B, P, I, 1]\n\n    # Get the values of the step function at the next step function interval.\n    tp = t.gather(-2, idx + 1)  # [B, P, I, 1]\n\n    # Get the values of the step function at the previous step function interval.\n    tm = t.gather(-2, idx - 1)  # [B, P, I, 1]\n\n    # Compute the step function values at the query times.\n    yq = yq + (y.gather(-2, idx + 1) - yq) * (tq - tm) / (tp - tm)  # [B, P, I, 1]\n\n    # Set the values that are out of bounds to the outside value.\n    yq = torch.where(mask, outside_value, yq)  # [B, P, I, 1]\n\n    return yq\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Get the number of steps in the step function.\n    num_steps = t.shape[-1]\n\n    # Get the number of query times.\n    num_tq = tq.shape[-1]\n\n    # Get the indices of the query times that exactly match a step change time.\n    tq_idx = torch.searchsorted(t, tq, right=True)\n    tq_idx = torch.clamp(tq_idx, 0, num_steps - 1)\n\n    # Get the indices of the query times that do not exactly match a step change time.\n    tq_idx_outside = torch.searchsorted(t, tq, right=False)\n    tq_idx_outside = torch.clamp(tq_idx_outside, 0, num_steps - 1)\n\n    # Get the query times that exactly match a step change time.\n    tq_exact = t[tq_idx]\n\n    # Get the query times that do not exactly match a step change time.\n    tq_outside = t[tq_idx_outside]\n\n    # Get the values of the step function at the query times that exactly match a step change time.\n    y_exact = y[tq_idx]\n\n    # Get the values of the step function at the query times that do not exactly match a step change time.\n    y_outside = torch.where(tq_outside < t, outside_value, y[tq_idx_outside])\n\n    # Interpolate the values of the step function at the query times that do not exactly match a step change time.\n    y_outside = torch.where(tq_outside > t, outside_value,\n                            (y_exact * (tq_outside - t[tq_idx - 1]) +\n                             y[tq_idx + 1] * (tq_outside - t[tq_idx])) /\n                            (t[tq_idx + 1] - t[tq_idx - 1]))\n\n    # Return"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # If the query time matches a step change time, return the outside value.\n    # Otherwise, interpolate the step function.\n    # TODO: make this more numerically stable.\n    # TODO: make this work for batches of tq and t.\n    tq = tq[..., None]\n    t = t[..., None]\n    y = y[..., None]\n    idx = searchsorted(t, tq)\n    idx_prev = idx - 1\n    idx_next = idx + 1\n    idx_prev = torch.clamp(idx_prev, 0, t.shape[-2] - 1)\n    idx_next = torch.clamp(idx_next, 0, t.shape[-2] - 1)\n    t_prev = t[idx_prev]\n    t_next = t[idx_next]\n    t_diff = t_next - t_prev\n    t_diff = torch.where(t_diff < 1e-12, torch.ones_like(t_diff), t_diff)\n    w_prev = (t_next - tq) / t_diff\n    w_next = (tq - t_prev) / t_diff\n    y_prev = y[idx_prev]\n    y_next = y[idx_next]\n    y_interp = w_prev * y_prev + w_next * y_next\n    y_interp = torch.where(tq == t_prev, y_prev, y_interp)\n    y_interp = torch.where(tq == t_next, y_next, y_interp)\n    return y_interp\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Ensure the query times are monotonically increasing.\n    tq = tq.reshape(-1, tq.shape[-1])\n    tq = tq[..., 1:] - tq[..., :-1]\n    tq = torch.cumsum(tq, dim=-1)\n    tq = torch.cat([torch.zeros_like(tq[..., :1]), tq], dim=-1)\n\n    # Find the step change times that are closest to the query times.\n    t = t.reshape(-1, t.shape[-1])\n    t = t[..., 1:] - t[..., :-1]\n    t = torch.cumsum(t, dim=-1)\n    t = torch.cat([torch.zeros_like(t[..., :1]), t], dim=-1)\n    idx = searchsorted(t, tq)\n\n    # Find the query times that exactly match a step change time.\n    tq_match = tq == t[idx]\n\n    # Interpolate the values at the query times.\n    y = y.reshape(-1, y.shape[-1])\n    y = y[..., 1:] - y[..., :-1]\n    y = torch.cat([y[..., :1], y, y[..., -1:]], dim=-1)\n    yq = y[idx]\n    yq = yq * (tq - t[idx - 1]) / (t[idx] - t[idx - 1]) + y[idx - 1]\n\n    # Set the values at the query times that exactly match a step change time.\n    yq = torch.where(tq_match, outside_value, yq)\n    return yq\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Query times outside the domain of the step function should be assigned the outside value.\n    outside_value = torch.tensor(outside_value, dtype=y.dtype, device=y.device)\n    outside_mask = (tq < t[..., 0]) | (tq >= t[..., -1])\n\n    # Find the indices of the left and right values to interpolate between.\n    idx_l = torch.searchsorted(t, tq, right=True)\n    idx_r = idx_l - 1\n\n    # If the query time matches a step change time, return the outside value.\n    # Otherwise, interpolate between the left and right values.\n    tq_match = t[idx_l] == tq\n    y_out = torch.where(tq_match, outside_value, y[idx_l] + (tq - t[idx_r]) * (y[idx_l] - y[idx_r]) / (t[idx_l] - t[idx_r]))\n\n    # Assign the outside value to query times outside the domain of the step function.\n    y_out[outside_mask] = outside_value\n\n    return y_out\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Make sure t is strictly increasing.\n    t_increasing = torch.sort(t, dim=-1)[0]\n    if not torch.all(t_increasing[..., 1:] > t_increasing[..., :-1]):\n        raise ValueError(\"t must be strictly increasing.\")\n\n    # Make sure tq is within the range of t.\n    tq_clipped = torch.clip(tq, t[..., 0, None], t[..., -1, None])\n\n    # Make sure y is the same shape as t.\n    if y.shape != t.shape:\n        raise ValueError(\"y must have the same shape as t.\")\n\n    # Make sure outside_value is a number.\n    if not isinstance(outside_value, (int, float)):\n        raise ValueError(\"outside_value must be a number.\")\n\n    # Find the index of the first step change after tq.\n    t_index = searchsorted(t, tq_clipped)\n\n    # Find the query times that match a step change.\n    t_match = t_index == torch.arange(t.shape[-1], device=t.device, dtype=torch.long)\n\n    # Find the values of the step function at the query times.\n    y_query = torch.where(t_match[..., None], outside_value, y[..., t_index])\n\n    return y_query\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Check for invalid input.\n    if (t.ndim != 2) or (y.ndim != 2):\n        raise ValueError('The inputs must be matrices.')\n    if (t.shape[0] != y.shape[0]) or (t.shape[1] != y.shape[1]):\n        raise ValueError('The inputs must have the same number of rows and columns.')\n    if (tq.ndim != 2) or (tq.shape[1] != 1):\n        raise ValueError('The query times must be a column vector.')\n    if (tq.shape[0] != y.shape[0]):\n        raise ValueError('The query times must have the same number of rows as the step function.')\n\n    # Initialize output.\n    yq = torch.zeros_like(tq)\n\n    # Find query times that match step changes.\n    # This is a vector of logicals, which are converted to 0s and 1s.\n    # tq_match_idx = (tq[None, :, :] == t[:, None, :]).sum(dim=2) == 2\n    tq_match_idx = torch.eq(tq[None, :, :], t[:, None, :]).sum(dim=2) == 2\n\n    # Set the output to the outside value at the query times that match step changes.\n    yq[tq_match_idx] = outside_value\n\n    # Find the indices of the query times that do not match step changes.\n    # This is a vector of logicals, which are converted to 0s and 1s.\n    tq_idx = ~tq_match_idx\n\n    # Find the indices of the nearest step changes to the query times.\n    # This is a vector of indices.\n    t_idx = torch.argmin(torch.abs(tq[tq_idx] - t), dim=0)\n\n    # Find the indices of the nearest step changes to the query times that are not equal to the nearest step change.\n    # This is a vector of indices."}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # Ensure that the weights are non-negative.\n    w = torch.relu(w)\n\n    # Ensure that the weights sum to 1.\n    w = w / torch.sum(w, dim=-1, keepdim=True).clip(eps)\n\n    # Calculate the annealing effect.\n    anneal_effect = 1.0 - 1.0 / (1.0 + torch.exp(anneal_slope * (1.0 - train_frac)))\n\n    # Calculate the adjusted weights.\n    w_adjusted = w * anneal_effect\n\n    # Ensure that the adjusted weights sum to 1.\n    w_adjusted = w_adjusted / torch.sum(w_adjusted, dim=-1, keepdim=True).clip(eps)\n\n    # Calculate the adjusted weights.\n    w_adjusted = w_adjusted / torch.sum(w_adjusted, dim=-1, keepdim=True).clip(eps)\n\n    return w_adjusted"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # Calculate the adjusted weights\n    w_adjusted = (1.0 - torch.exp(-anneal_slope * (1.0 - train_frac))) * w\n\n    # Handle cases where adjacent intervals have zero distance\n    w_adjusted[..., 1:] = torch.where(\n        (t[..., 1:] - t[..., :-1]) < eps,\n        torch.zeros_like(w_adjusted[..., 1:]),\n        w_adjusted[..., 1:],\n    )\n\n    # Handle cases where the interval has zero distance\n    w_adjusted[..., 0] = torch.where(\n        (t[..., 0] - t[..., 1]) < eps,\n        torch.zeros_like(w_adjusted[..., 0]),\n        w_adjusted[..., 0],\n    )\n\n    # Handle cases where the interval has negative distance\n    w_adjusted[..., 0] = torch.where(\n        (t[..., 0] - t[..., 1]) < -eps,\n        torch.zeros_like(w_adjusted[..., 0]),\n        w_adjusted[..., 0],\n    )\n\n    # Normalize the adjusted weights\n    w_adjusted = w_adjusted / torch.sum(w_adjusted, dim=-1, keepdim=True)\n\n    return w_adjusted\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # Ensure that the weights and time tensors are the same shape.\n    t, w = matchup_channels(t, w)\n\n    # Calculate the weights to be adjusted by the training fraction and annealing slope.\n    adjusted_weights = (train_frac ** anneal_slope) * w\n\n    # Determine the distance between adjacent intervals.\n    t_diff = t[..., 1:] - t[..., :-1]\n\n    # Determine the weights to be adjusted by the training fraction and annealing slope.\n    adjusted_weights = (train_frac ** anneal_slope) * w\n\n    # Determine the distance between adjacent intervals.\n    t_diff = t[..., 1:] - t[..., :-1]\n\n    # Determine the adjusted weights by the training fraction and annealing slope.\n    adjusted_weights = (train_frac ** anneal_slope) * w\n\n    # Determine the adjusted weights by the training fraction and annealing slope.\n    adjusted_weights = (train_frac ** anneal_slope) * w\n\n    # Determine the adjusted weights by the training fraction and annealing slope.\n    adjusted_weights = (train_frac ** anneal_slope) * w\n\n    # Determine the adjusted weights by the training fraction and annealing slope.\n    adjusted_weights = (train_frac ** anneal_slope) * w\n\n    # Determine the adjusted weights by the training fraction and annealing slope.\n    adjusted_weights = (train_frac ** anneal_slope) * w\n\n    # Determine the adjusted weights by the training fraction and annealing slope.\n    adjusted_weights = (train_frac ** anneal_slope) * w\n\n    # Determine the adjusted weights by the training fraction and annealing slope.\n    adjusted_weights = (train_frac ** anneal_slope) * w\n\n   "}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    # Calculate the weights adjustment based on the training fraction and annealing slope.\n    w_adj = 1 / (1 + torch.exp(anneal_slope * (1 - train_frac)))\n    # Calculate the weights adjustment based on the time intervals.\n    w_adj = w_adj[..., None] * (t[..., 1:] - t[..., :-1])\n    # Calculate the adjusted weights by adjusting the weights tensor with the weights adjustment.\n    w_adj = w_adj + (w[..., None] * torch.log(w_adj + eps))\n    # Calculate the adjusted weights by applying a softmax operation to prevent NaN values.\n    w_adj = torch.nn.functional.softmax(w_adj, dim=-1)\n    return w_adj\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # Checking that the weights tensor has the same shape as the time tensor\n    assert t.shape[-1] == w.shape[-1] + 1\n\n    # Calculating the annealing effect using Schlick's bias function\n    anneal_effect = 1.0 - train_frac ** anneal_slope\n\n    # Calculating the adjusted weights\n    w_adjusted = w * anneal_effect\n\n    # Preventing NaN values by handling cases where adjacent intervals have zero distance\n    w_adjusted[..., 1:] = w_adjusted[..., 1:].clip(min=eps)\n    w_adjusted[..., :-1] = w_adjusted[..., :-1].clip(min=eps)\n\n    # Calculating the adjusted weights using a softmax operation to prevent NaN values\n    w_adjusted = torch.nn.functional.softmax(w_adjusted, dim=-1)\n\n    return w_adjusted\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    if t.ndim == w.ndim + 1:\n        t = t[..., 0]  # remove last dim\n\n    # preparing for size change\n    sh = *w.shape[:-1], w.shape[-1] + 1  # B, P, I\n    t = t.reshape(-1, t.shape[-1])\n    w = w.reshape(-1, w.shape[-1])\n\n    # assuming sampling in s space\n    if t.shape[-1] != w.shape[-1] + 1:\n        t = torch.cat([t, torch.ones_like(t[..., -1:])], dim=-1)\n\n    # eps = torch.finfo(torch.float32).eps\n    eps = 1e-8\n\n    # Compute the PDF and CDF for each weight vector.\n    cw = integrate_weights(w)\n\n    # Compute the annealed weights.\n    t_anneal = (t[..., 1:] + t[..., :-1]) / 2\n    w_anneal = (1 - 1 / (1 + (anneal_slope * train_frac) ** 2)) * w\n    w_anneal = w_anneal.clip(min=0)\n\n    # Interpolate into the inverse CDF.\n    t_new = interpolate(cw, t_anneal, t)\n\n    # preparing for size change\n    t_new = t_new.reshape(sh)\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # ensure that t and w are the same size\n    t, w = matchup_channels(t, w)\n\n    # ensure that the time tensor is sorted\n    t = torch.sort(t, dim=-1)[0]\n\n    # calculate the distance between each time bin\n    t_dists = t[..., 1:] - t[..., :-1]\n\n    # calculate the annealing effect based on the training fraction and annealing slope\n    anneal_effect = 1.0 / (1.0 + anneal_slope * (1.0 - train_frac))\n\n    # calculate the adjusted weights based on the annealing effect and the distance between time bins\n    w_adjusted = w * anneal_effect ** (t_dists.clamp(min=eps))\n\n    # calculate the adjusted weights based on the softmax function\n    w_adjusted = torch.nn.functional.softmax(w_adjusted, dim=-1)\n\n    return w_adjusted\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n\n    # 1. Calculate the weights that would be needed to create a uniform distribution of weights.\n    w_uniform = torch.ones_like(w)\n    w_uniform = w_uniform / torch.sum(w_uniform, dim=-1, keepdim=True)\n\n    # 2. Calculate the weights that would be needed to create a uniform distribution of weights, given the training fraction.\n    w_uniform_annealed = (1.0 - train_frac) ** anneal_slope * w_uniform\n\n    # 3. Calculate the weights that would be needed to create a uniform distribution of weights, given the training fraction, and adjust the weights accordingly.\n    w_adjusted = w / torch.sum(w, dim=-1, keepdim=True)\n    w_adjusted = w_adjusted * w_uniform_annealed\n\n    # 4. Prevent NaN values by using a softmax operation on the adjusted weights.\n    w_adjusted = w_adjusted / (torch.sum(w_adjusted, dim=-1, keepdim=True) + eps)\n\n    return w_adjusted\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    # Adjust weights based on training fraction.\n    w_adjusted = w * torch.sigmoid(anneal_slope * (1.0 - train_frac))\n    # Ensure stability in computation.\n    w_adjusted = w_adjusted.clip(min=eps)\n    # Normalize weights to sum to 1.\n    w_adjusted = w_adjusted / torch.sum(w_adjusted, dim=-1, keepdim=True)\n    return w_adjusted\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # ensure that t and w are the same size\n    t, w = matchup_channels(t, w)\n\n    # check to see if the anneal slope is valid\n    if anneal_slope <= 0:\n        raise ValueError(\"Anneal slope must be positive\")\n\n    # check to see if the training fraction is valid\n    if train_frac < 0 or train_frac > 1:\n        raise ValueError(\"Training fraction must be between 0 and 1\")\n\n    # calculate the annealing factor\n    anneal_factor = 1 / (1 + torch.exp(-anneal_slope * train_frac))\n\n    # calculate the adjusted weights\n    w_adj = w * anneal_factor\n\n    # ensure that the weights are valid\n    w_adj = w_adj.clamp(min=0.0, max=1.0)\n\n    # ensure that the weights are normalized\n    w_adj = w_adj / (w_adj.sum(dim=-1, keepdim=True) + eps)\n\n    # return the adjusted weights\n    return w_adj\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # get the weights tensor's shape\n    shape = w.shape\n\n    # get the time tensor's shape\n    t_shape = t.shape\n\n    # check if the time tensor's shape and weights tensor's shape are the same\n    if t_shape != shape:\n\n        # if they are not the same, reshape the time tensor to match the weights tensor's shape\n        t = t.reshape(shape)\n\n    # get the time tensor's last dimension\n    last_dim = t.shape[-1]\n\n    # get the time tensor's last dimension\n    last_dim_w = w.shape[-1]\n\n    # check if the time tensor's last dimension is the same as the weights tensor's last dimension plus 1\n    if last_dim != last_dim_w + 1:\n\n        # if they are not the same, reshape the weights tensor to match the time tensor's last dimension\n        w = w.reshape(shape)\n\n    # get the time tensor's last dimension\n    last_dim = t.shape[-1]\n\n    # check if the time tensor's last dimension is the same as the weights tensor's last dimension plus 1\n    if last_dim != last_dim_w + 1:\n\n        # if they are not the same, raise an error\n        raise ValueError(f\"Time tensor's last dimension {last_dim} must be the same as weights tensor's last dimension {last_dim_w} plus 1\")\n\n    # get the time tensor's shape\n    t_shape = t.shape\n\n    # get the weights tensor's shape\n    w_shape = w.shape\n\n    # check if the time tensor's shape and weights tensor's shape are the same\n    if t_shape != w_shape:\n\n        # if they are not the same, raise an error\n        raise ValueError(f\"Time tensor's shape {t_shape} must be the same as weights tensor's shape {w_shape}\")\n\n    # get the time tensor's last dimension\n    last_dim = t.shape[-1]\n\n   "}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    # Calculate the annealing effect on weights\n    # This is the Schlick function\n    anneal_factor = 1 / (1 + torch.exp(-anneal_slope * (1 - train_frac)))\n    # Calculate the adjusted weights\n    # This is the softmax function\n    w_adjusted = torch.softmax(anneal_factor * torch.log(w.clamp(min=eps)), dim=-1)\n    # Return the adjusted weights\n    return w_adjusted\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    assert t.shape[-1] == w.shape[-1] + 1, \"t.shape[-1] must be w.shape[-1] + 1\"\n    assert anneal_slope > 0, \"anneal_slope must be positive\"\n    assert train_frac >= 0 and train_frac <= 1, \"train_frac must be between 0 and 1\"\n\n    # get the distance between each time/interval\n    t_diff = t[..., 1:] - t[..., :-1]\n\n    # get the maximum distance between intervals\n    max_t_diff = t_diff.max(dim=-1, keepdim=True)[0]\n\n    # get the minimum distance between intervals\n    min_t_diff = t_diff.min(dim=-1, keepdim=True)[0]\n\n    # get the difference between maximum and minimum distance between intervals\n    diff_t_diff = max_t_diff - min_t_diff\n\n    # get the bias factor for the annealing process\n    bias_factor = 1 - torch.exp(-anneal_slope * train_frac)\n\n    # get the adjusted weights\n    w_adjusted = w * torch.exp(bias_factor * t_diff / diff_t_diff)\n\n    # get the adjusted weights after softmax\n    w_adjusted = w_adjusted / (w_adjusted.sum(dim=-1, keepdim=True) + eps)\n\n    return w_adjusted\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    # Calculate the weights adjustment\n    w_adjust = (anneal_slope * train_frac) ** 2\n    # Calculate the weights adjustment mask\n    w_adjust_mask = torch.where(torch.eq(t[..., :-1], t[..., 1:]), 0, 1)\n    # Apply the weights adjustment mask\n    w_adjust = w_adjust * w_adjust_mask\n    # Apply the weights adjustment\n    w = w * torch.exp(w_adjust)\n    # Calculate the weights normalization factor\n    w_normalization = torch.sum(w, dim=-1, keepdim=True)\n    # Normalize the weights\n    w = w / w_normalization.clip(eps)\n    return w\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # Check for validity of inputs\n    if train_frac < 0.0 or train_frac > 1.0:\n        raise ValueError(\"Training fraction must be in the range [0, 1].\")\n    if anneal_slope <= 0.0:\n        raise ValueError(\"Annealing slope must be greater than 0.\")\n\n    # Calculate the annealing effect on weights\n    anneal_effect = 1.0 - torch.exp(-anneal_slope * train_frac)\n\n    # Calculate the adjusted weights\n    adjusted_weights = w * anneal_effect\n\n    # Prevent NaN values by using a softmax operation on the adjusted weights\n    adjusted_weights = adjusted_weights / (torch.sum(adjusted_weights, dim=-1, keepdim=True) + eps)\n\n    return adjusted_weights\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n\n    # Get the time interval between each bin.\n    t_interval = t[..., 1:] - t[..., :-1]\n\n    # Create the adjustment vector.\n    anneal_vec = torch.ones_like(w)\n\n    # Get the indices of the intervals with zero distance.\n    zero_dist_idx = torch.where(t_interval < eps)\n\n    # Set the weights of intervals with zero distance to zero.\n    anneal_vec[zero_dist_idx] = 0.0\n\n    # Calculate the adjustment vector.\n    anneal_vec = 1.0 - torch.sigmoid(anneal_slope * (train_frac - t[zero_dist_idx]))\n\n    # Adjust the weights.\n    w_annealed = w * anneal_vec\n\n    # Prevent NaN values by using a softmax operation on the adjusted weights.\n    w_annealed = w_annealed / torch.sum(w_annealed, dim=-1, keepdim=True)\n\n    return w_annealed\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # assert t.shape[-1] == w.shape[-1] + 1\n    # assert anneal_slope >= 0\n\n    # Get the time intervals and the weights.\n    t0 = t[..., :-1]\n    t1 = t[..., 1:]\n    w0 = w[..., :-1]\n    w1 = w[..., 1:]\n\n    # Get the time difference and the normalized time difference.\n    dt = t1 - t0\n    dt_norm = dt / (t1 - t0).max(dim=-1, keepdim=True)[0]\n\n    # Get the annealed weights.\n    w_anneal = (1 - torch.exp(-(1 - train_frac) ** anneal_slope)) * (w1 - w0)\n\n    # Get the adjusted weights.\n    w_adj = w0 + w_anneal * dt_norm\n\n    # Get the adjusted weights.\n    w_adj = w_adj.softmax(dim=-1)\n\n    # Return the adjusted weights.\n    return w_adj\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # Ensure that the weights and time tensors have the same shape.\n    t, w = matchup_channels(t, w)\n\n    # Compute the weights adjustment based on the training fraction and annealing slope.\n    w_adj = torch.sigmoid(anneal_slope * (1.0 - train_frac))\n\n    # Compute the time differences between adjacent time points.\n    t_diff = t[..., 1:] - t[..., :-1]\n\n    # Compute the adjusted weights based on the weights adjustment and time differences.\n    w_adj = w_adj[..., None] * t_diff[..., None]\n\n    # Compute the adjusted weights by setting weights with zero time difference to zero.\n    w_adj = torch.where(t_diff > eps, w_adj, 0.0)\n\n    # Compute the adjusted weights by applying a softmax to ensure stability in the computation.\n    w_adj = torch.softmax(w_adj, dim=-1)\n\n    # Compute the adjusted weights by multiplying the weights with the adjusted weights.\n    w_adj = w[..., :-1] * w_adj\n\n    # Compute the adjusted weights by adding the adjusted weights to the next weights.\n    w_adj = w_adj + w[..., 1:]\n\n    return w_adj\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # Check for validity of the input arguments.\n    if t.shape[-1] != w.shape[-1] + 1:\n        raise ValueError(f\"Time dimension {t.shape[-1]} does not match weights dimension {w.shape[-1]} + 1\")\n    if train_frac < 0.0 or train_frac > 1.0:\n        raise ValueError(f\"Training fraction {train_frac} is not in the range of [0, 1]\")\n    if anneal_slope < 0.0:\n        raise ValueError(f\"Annealing slope {anneal_slope} is not in the range of [0, inf)\")\n\n    # Calculate the weights adjustment.\n    adjustment = 1.0 / (1.0 + torch.exp(-anneal_slope * (train_frac - 0.5)))\n\n    # Calculate the time difference between each time point and the next.\n    t_diff = t[..., 1:] - t[..., :-1]\n\n    # Calculate the adjusted weights.\n    w_adjusted = w * torch.where(t_diff > eps, t_diff, 0.0) * adjustment\n\n    # Prevent NaN values by using a softmax operation on the adjusted weights.\n    w_adjusted = torch.nn.functional.softmax(w_adjusted, dim=-1)\n\n    return w_adjusted\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    # Prevent NaN values\n    t = t.clamp(min=eps)\n    w = w.clamp(min=eps)\n\n    # Get the weights that will be adjusted\n    w_adjust = w.clone()\n\n    # Get the weighted PDF\n    p = weight_to_pdf(t, w)\n\n    # Get the weighted CDF\n    cw = integrate_weights(w)\n\n    # Get the weighted CDF at the endpoints of each interval\n    cw0 = cw[..., :-1]\n    cw1 = cw[..., 1:]\n\n    # Get the time at the endpoints of each interval\n    t0 = t[..., :-1]\n    t1 = t[..., 1:]\n\n    # Calculate the distance between the endpoints of each interval\n    dt = t1 - t0\n\n    # Calculate the adjustment to the weights\n    w_adjust_factor = 1 - torch.exp(-anneal_slope * train_frac * dt)\n\n    # Adjust the weights\n    w_adjust *= w_adjust_factor\n\n    # Get the indices of intervals that have zero distance\n    zero_dist_idx = torch.where(dt <= eps)\n\n    # Set the weights to zero for intervals with zero distance\n    w_adjust[zero_dist_idx] = 0\n\n    # Calculate the adjusted PDF\n    p_adjust = weight_to_pdf(t, w_adjust)\n\n    # Calculate the adjusted CDF\n    cw_adjust = integrate_weights(w_adjust)\n\n    # Calculate the adjusted CDF at the endpoints of each interval\n    cw0_adjust = cw_adjust[..., :-1]\n    cw1_adjust = cw_adjust[..., 1:]\n\n    # Calculate the adjusted time at the endpoints of each interval\n    t0_adjust = t[..., :-1] + (t1 - t0) *"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, list):\n        return [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, tuple):\n        return tuple([to_cuda(b, device, ignore_list) for b in batch])\n    elif isinstance(batch, dict):\n        if ignore_list:\n            return {k: to_cuda(b, device, ignore_list) for k, b in batch.items() if k != \"meta\"}\n        else:\n            return {k: to_cuda(b, device, ignore_list) for k, b in batch.items()}\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, dict):\n        if not ignore_list:\n            return {k: to_cuda(v, device, ignore_list=True) for k, v in batch.items()}\n        else:\n            return {k: v for k, v in batch.items()}\n    elif isinstance(batch, list):\n        if not ignore_list:\n            return [to_cuda(v, device, ignore_list=True) for v in batch]\n        else:\n            return batch\n    elif isinstance(batch, tuple):\n        if not ignore_list:\n            return tuple([to_cuda(v, device, ignore_list=True) for v in batch])\n        else:\n            return batch\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, dict):\n        if not ignore_list:\n            return {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n        else:\n            return {k: to_cuda(v, device, ignore_list) for k, v in batch.items() if k != \"meta\"}\n    elif isinstance(batch, list) or isinstance(batch, tuple):\n        return [to_cuda(v, device, ignore_list) for v in batch]\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, list):\n        return [to_cuda(elem, device, ignore_list) for elem in batch]\n    elif isinstance(batch, tuple):\n        return tuple([to_cuda(elem, device, ignore_list) for elem in batch])\n    elif isinstance(batch, dict):\n        if ignore_list:\n            return {k: to_cuda(v, device, ignore_list) for k, v in batch.items() if k != \"meta\"}\n        else:\n            return {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, list):\n        return [to_cuda(e, device, ignore_list) for e in batch]\n    elif isinstance(batch, tuple):\n        return tuple([to_cuda(e, device, ignore_list) for e in batch])\n    elif isinstance(batch, dict):\n        if ignore_list:\n            return {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n        else:\n            return {k: to_cuda(v, device, ignore_list) for k, v in batch.items() if k != \"meta\"}\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, list):\n        return [to_cuda(el, device, ignore_list) for el in batch]\n    elif isinstance(batch, tuple):\n        return tuple([to_cuda(el, device, ignore_list) for el in batch])\n    elif isinstance(batch, dict):\n        if ignore_list:\n            return {k: to_cuda(v, device, ignore_list) for k, v in batch.items() if k != \"meta\"}\n        else:\n            return {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, (list, tuple)):\n        return type(batch)([to_cuda(b, device, ignore_list) for b in batch])\n    elif isinstance(batch, dict):\n        if ignore_list:\n            return batch\n        return {k: to_cuda(b, device, ignore_list) for k, b in batch.items() if k != \"meta\"}\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, list):\n        return [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, tuple):\n        return tuple(to_cuda(b, device, ignore_list) for b in batch)\n    elif isinstance(batch, dict):\n        if ignore_list:\n            return {k: to_cuda(b, device, ignore_list) for k, b in batch.items()}\n        else:\n            return {k: to_cuda(b, device, ignore_list) for k, b in batch.items() if k != \"meta\"}\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, list):\n        return [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, tuple):\n        return tuple(to_cuda(b, device, ignore_list) for b in batch)\n    elif isinstance(batch, dict):\n        if ignore_list:\n            return batch\n        else:\n            return {k: to_cuda(b, device, ignore_list) for k, b in batch.items()}\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, dict):\n        if not ignore_list:\n            return {k: to_cuda(v, device) for k, v in batch.items()}\n        else:\n            if \"meta\" in batch:\n                return {k: to_cuda(v, device) for k, v in batch.items() if k != \"meta\"}\n            else:\n                return {k: to_cuda(v, device) for k, v in batch.items()}\n    elif isinstance(batch, list):\n        return [to_cuda(v, device) for v in batch]\n    elif isinstance(batch, tuple):\n        return tuple([to_cuda(v, device) for v in batch])\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device=device)\n    elif isinstance(batch, (list, tuple)):\n        return type(batch)(to_cuda(b, device, ignore_list) for b in batch)\n    elif isinstance(batch, dict):\n        if ignore_list:\n            return batch\n        else:\n            return type(batch)({k: to_cuda(v, device, ignore_list) for k, v in batch.items()})\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, dict):\n        if not ignore_list:\n            return {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n        else:\n            return {k: to_cuda(v, device, ignore_list) for k, v in batch.items() if k != \"meta\"}\n    elif isinstance(batch, list):\n        return [to_cuda(v, device, ignore_list) for v in batch]\n    elif isinstance(batch, tuple):\n        return tuple([to_cuda(v, device, ignore_list) for v in batch])\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, list) and not ignore_list:\n        return [to_cuda(element, device) for element in batch]\n    elif isinstance(batch, tuple):\n        return tuple(to_cuda(element, device) for element in batch)\n    elif isinstance(batch, dict):\n        return {key: to_cuda(value, device) for key, value in batch.items()}\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, dict):\n        if ignore_list:\n            return {k: to_cuda(v, device, ignore_list=True) for k, v in batch.items()}\n        else:\n            return {k: to_cuda(v, device) for k, v in batch.items()}\n    elif isinstance(batch, list):\n        return [to_cuda(v, device) for v in batch]\n    elif isinstance(batch, tuple):\n        return tuple([to_cuda(v, device) for v in batch])\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, list):\n        return [to_cuda(x, device, ignore_list) for x in batch]\n    elif isinstance(batch, tuple):\n        return tuple(to_cuda(x, device, ignore_list) for x in batch)\n    elif isinstance(batch, dict):\n        if ignore_list:\n            return {k: to_cuda(v, device, ignore_list) for k, v in batch.items() if k != \"meta\"}\n        else:\n            return {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, list):\n        return [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, tuple):\n        return tuple([to_cuda(b, device, ignore_list) for b in batch])\n    elif isinstance(batch, dict):\n        if not ignore_list:\n            return {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n        else:\n            if \"meta\" in batch:\n                return {k: to_cuda(v, device, ignore_list) for k, v in batch.items() if k != \"meta\"}\n            else:\n                return {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, (tuple, list)):\n        return [to_cuda(el, device=device, ignore_list=ignore_list) for el in batch]\n    elif isinstance(batch, dict):\n        if ignore_list:\n            return batch\n        else:\n            return {k: to_cuda(v, device=device, ignore_list=ignore_list) for k, v in batch.items()}\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, list):\n        return [to_cuda(e, device=device, ignore_list=True) for e in batch]\n    elif isinstance(batch, tuple):\n        return tuple([to_cuda(e, device=device, ignore_list=True) for e in batch])\n    elif isinstance(batch, dict):\n        if ignore_list:\n            return batch\n        else:\n            return {k: to_cuda(v, device=device, ignore_list=True) for k, v in batch.items()}\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, list) or isinstance(batch, tuple):\n        if ignore_list:\n            return batch\n        else:\n            return [to_cuda(item, device, ignore_list) for item in batch]\n    elif isinstance(batch, dict):\n        return {k: to_cuda(v, device, ignore_list) for k, v in batch.items() if k != \"meta\"}\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    # If the input is a torch.Tensor, move it to the specified CUDA device\n    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n\n    # If the input is a list, recursively handle each element\n    elif isinstance(batch, list):\n        return [to_cuda(b, device, ignore_list) for b in batch]\n\n    # If the input is a tuple, recursively handle each element\n    elif isinstance(batch, tuple):\n        return tuple(to_cuda(b, device, ignore_list) for b in batch)\n\n    # If the input is a dictionary, recursively handle each value, but ignore the meta data\n    elif isinstance(batch, dict):\n        return {k: to_cuda(v, device, True) if not ignore_list else v for k, v in batch.items()}\n\n    # Otherwise, return the input as it is\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # index will first be augmented to match the values' dimentionality at the back\n    # take care of batch dimension of, and acts like a linear indexing in the target dimention\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # index will first be augmented to match the values' dimentionality at the back\n    # take care of batch dimension of, and acts like a linear indexing in the target dimention\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    # we assume that the values's second to last dimension is"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # v: B, N, 3\n    # f: B, F, 3\n\n    # v: B, N, 3\n    # f: B, F, 3\n    # dim = -2\n\n    # v: B, N, 3\n    # f: B, F, 3\n    # dim = -1\n\n    # v: B, N, 3\n    # f: B, F, 3\n    # dim = 1\n\n    # v: B, N, 3\n    # f: B, F, 3\n    # dim = 2\n\n    # v: B, N, 3\n    # f: B, F, 3\n    # dim = 3\n\n    # v: B, N, 3\n    # f: B, F, 3\n    # dim = 4\n\n    # v: B, N, 3\n    # f: B, F, 3\n    # dim = 5\n\n    # v: B, N, 3\n    # f: B, F, 3\n    # dim = 6\n\n    # v: B, N, 3\n    # f: B, F, 3\n    # dim = 7\n\n    # v: B, N, 3\n    # f: B, F, 3\n    # dim = 8\n\n    # v: B, N, 3\n    # f: B, F, 3\n    # dim = 9\n\n    # v: B, N, 3\n    # f: B, F, 3\n    # dim = 10\n\n    # v: B, N, 3\n    # f: B, F, 3\n    # dim = 11\n\n    # v: B, N, 3\n    # f: B, F, 3\n    # dim = 12\n\n    # v: B, N, 3\n    # f: B, F, 3\n    # dim = 13\n\n    # v: B, N, 3\n    # f: B, F, 3"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # gathering the vertices of the triangles\n    triangles = multi_gather(v, f, dim=dim)\n\n    # computing the normals of the triangles\n    triangles_normals = torch.cross(triangles[..., 1] - triangles[..., 0], triangles[..., 2] - triangles[..., 0], dim=-1)\n\n    # reshaping the result to maintain the structure of the original faces tensor with additional dimensions for batch processing\n    triangles_normals = triangles_normals.view(*triangles.shape[:-1], 3)\n\n    return triangles_normals\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # v: B, P, 3, f: B, F, 3 -> B, F, 3, 3\n    if f.shape[-1] != 3:\n        raise ValueError('The faces tensor should contain triangles only.')\n    if v.shape[dim] != 3:\n        raise ValueError('The vertices tensor should contain 3D points.')\n    if f.shape[0] != v.shape[0]:\n        f = f.expand(v.shape[0], *f.shape[1:])\n    return multi_gather(v, f, dim)\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # Expand the faces tensor to match the batch dimension of the vertices tensor\n    if v.shape[0] != f.shape[0]:\n        f = f.expand(v.shape[0], *f.shape)\n\n    # Gather the triangles\n    tris = multi_gather(v, f, dim)\n\n    # Reshape the result to maintain the structure of the original faces tensor with additional dimensions for batch processing\n    tris = tris.view(*f.shape, 3, *v.shape[1:])\n\n    return tris\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    if f.shape[-1] != 3:\n        raise ValueError(f'Expected faces tensor to be of shape (..., 3), but got {f.shape} instead.')\n    if v.shape[dim] != f.shape[dim]:\n        f = f.expand(*v.shape[:dim], *f.shape[dim:])\n    return multi_gather(v, f, dim)\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # gather faces from vertices\n    # take care of batch dimension of vertices, and acts like a linear indexing in the target dimention\n    tri = multi_gather(v, f, dim)\n\n    # reshape to maintain the structure of the original faces tensor with additional dimensions for batch processing\n    tri = tri.view(*tri.shape[:dim], -1, 3, *tri.shape[dim + 2:])\n\n    return tri\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # dim: in terms of the index (mask)\n    if f.dtype != torch.long: f = f.long()\n    if f.ndim < 2: f = f.unsqueeze(-1)\n    if v.ndim < 2: v = v.unsqueeze(-2)\n    if f.shape[-1] != 3: f = f.view(*f.shape[:-1], -1, 3)\n    if v.shape[-2] != 3: v = v.view(*v.shape[:-2], -1, 3)\n    if v.shape[dim] != f.shape[dim]:\n        f = f.expand(*f.shape[:dim], v.shape[dim], *f.shape[dim + 1:])\n    return v.gather(dim, f)\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # check input tensor shape\n    if not isinstance(v, torch.Tensor):\n        raise TypeError(f\"Expected input v to be of type torch.Tensor, got {type(v)} instead.\")\n    if not isinstance(f, torch.Tensor):\n        raise TypeError(f\"Expected input f to be of type torch.Tensor, got {type(f)} instead.\")\n\n    # check input tensor device\n    if v.device != f.device:\n        raise RuntimeError(f\"Input tensors v and f must be on the same device, got {v.device} for v and {f.device} for f.\")\n\n    # check input tensor dimensions\n    if v.ndim < 2:\n        raise ValueError(f\"Input tensor v must have at least two dimensions, got {v.ndim} instead.\")\n    if f.ndim < 2:\n        raise ValueError(f\"Input tensor f must have at least two dimensions, got {f.ndim} instead.\")\n\n    # check input tensor shapes\n    if f.shape[-1] != 3:\n        raise ValueError(f\"Input tensor f must be of shape (*, 3), got {f.shape} instead.\")\n\n    # check input tensor devices\n    if v.device != f.device:\n        raise RuntimeError(f\"Input tensors v and f must be on the same device, got {v.device} for v and {f.device} for f.\")\n\n    # check input tensor devices\n    if v.device != f.device:\n        raise RuntimeError(f\"Input tensors v and f must be on the same device, got {v.device} for v and {f.device} for f.\")\n\n    # expand f to match batch dimension of v\n    if v.ndim != f.ndim:\n        f = f[(None,) * (v.ndim - f.ndim) + (slice(None),) * f.ndim]\n\n    # gather triangles\n    return multi_gather(v, f, dim=dim)\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # v: B, V, 3\n    # f: B, F, 3\n    # return: B, F, 3, 3\n\n    if f.shape[0] != v.shape[0]:\n        f = f.expand(v.shape[0], *f.shape[1:])\n    f = f.permute(0, 2, 1).contiguous()  # B, 3, F\n    f = f.view(-1, *f.shape[1:])  # Bx3, F\n    tri = multi_gather(v, f, dim=dim)  # Bx3, F, 3\n    return tri.view(*f.shape[:-1], 3, 3)  # B, 3, F, 3\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # adjust batch dimension of faces to match that of vertices\n    if v.ndim > f.ndim:\n        f = f[(None,) * (v.ndim - f.ndim) + (slice(None),) * (f.ndim - 1)]\n    # gather triangles\n    triangles = multi_gather(v, f, dim=dim)\n    # reshape to maintain the structure of the original faces tensor with additional dimensions for batch processing\n    triangles = triangles.reshape(v.shape[:dim] + (-1,) + f.shape[1:] + (3,) + v.shape[dim + 1:])\n    return triangles\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # check if batch dimension is present\n    if v.ndim > 2:\n        # check if faces batch dimension needs to be expanded\n        if f.ndim < v.ndim:\n            f = f[(None,) * (v.ndim - f.ndim) + (slice(None),) * f.ndim]\n\n        # gather triangles\n        tri = multi_gather(v, f, dim)\n\n        # reshape to maintain the structure of the original faces tensor with additional dimensions for batch processing\n        tri = tri.view(*f.shape[:-1], 3, *v.shape[1:])\n\n    else:\n        tri = multi_gather(v, f, dim)\n\n    return tri\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # get batch size\n    b = v.shape[0]\n\n    # get the number of vertices per batch\n    n = v.shape[1]\n\n    # get the number of faces per batch\n    m = f.shape[1]\n\n    # get the number of vertices per face\n    k = f.shape[2]\n\n    # check if faces need to be expanded to match the batch dimension of the vertices\n    if b > 1 and f.shape[0] == 1:\n        f = f.expand(b, m, k)\n\n    # gather the vertices of the faces\n    v_face = multi_gather(v, f, dim=dim)\n\n    # compute the face normals\n    normals = torch.cross(v_face[:, :, 1] - v_face[:, :, 0], v_face[:, :, 2] - v_face[:, :, 0], dim=-1)\n\n    # reshape the result to maintain the original faces structure with additional dimensions for batch processing\n    normals = normals.view(*f.shape[:-1], 3)\n\n    return normals\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # Adjust the batch dimension of the faces tensor to match the batch dimension of the vertices tensor if necessary\n    if v.ndim == f.ndim + 1:\n        f = f.unsqueeze(0)\n\n    # Gather the triangles from the vertices tensor\n    tri = multi_gather(v, f, dim=dim)\n\n    # Reshape the result to maintain the structure of the original faces tensor with additional dimensions for batch processing\n    tri = tri.permute(0, 1, 2, 4, 3, 5)\n    tri = tri.reshape(-1, *tri.shape[3:])\n\n    return tri\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # Get the batch size of the vertices tensor\n    B = v.shape[0]\n\n    # Expand the faces tensor to match the batch dimension of the vertices tensor if necessary\n    if f.shape[0] != B:\n        # Expand the faces tensor to match the batch dimension of the vertices tensor\n        f = f.expand(B, *f.shape)\n\n    # Gather the triangles\n    triangles = multi_gather(v, f, dim=dim)\n\n    # Reshape the result to maintain the original faces tensor structure with additional dimensions for batch processing\n    triangles = triangles.reshape(*f.shape, 3, *v.shape[2:])\n\n    return triangles\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # backward of multi_gather\n    if f.shape[dim] != 3:\n        raise ValueError(f'Expected the last dimension of the faces tensor to be 3, but got {f.shape[dim]}.')\n\n    # Adjust the batch dimension of faces to match the batch dimension of vertices\n    if v.shape[0] != f.shape[0]:\n        f = f.expand(v.shape[0], *f.shape[1:])\n\n    # Gather the vertices of each face\n    f = multi_gather(v, f, dim)\n\n    # Compute the normals of each face\n    f = torch.cross(f[..., 1] - f[..., 0], f[..., 2] - f[..., 0], dim=-1)\n\n    return f\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # v: B, P, 3\n    # f: B, F, 3\n    # return: B, F, 3, 3\n    # assert v.ndim == 3, 'vertices must be a tensor of dimension 3'\n    # assert f.ndim == 3, 'faces must be a tensor of dimension 3'\n    # assert v.shape[0] == f.shape[0], 'vertices and faces must have the same batch dimension'\n    # assert v.shape[1] >= f.shape[1], 'vertices must have at least as many points as faces'\n    # assert v.shape[2] == 3, 'vertices must be of size 3 in the last dimension'\n    # assert f.shape[2] == 3, 'faces must be of size 3 in the last dimension'\n\n    # if v.ndim == 2: v = v.unsqueeze(0)\n    # if f.ndim == 2: f = f.unsqueeze(0)\n    # if v.shape[0] == 1: v = v.expand(f.shape[0], -1, -1)\n    # if f.shape[0] == 1: f = f.expand(v.shape[0], -1, -1)\n    # assert v.shape[0] == f.shape[0], 'vertices and faces must have the same batch dimension'\n    # assert v.shape[1] >= f.shape[1], 'vertices must have at least as many points as faces'\n\n    # return v.gather(dim, f.unsqueeze(-1).expand(*f.shape, v.shape[-1])).squeeze(-2)\n    return multi_gather(v, f, dim=dim)\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # the batch dimension of the vertices tensor\n    v_batch_dim = v.shape[:dim]\n    # the batch dimension of the faces tensor\n    f_batch_dim = f.shape[:dim]\n    # the number of vertices per face\n    n_v = f.shape[dim]\n    # the number of faces per batch\n    n_f = f.shape[dim - 1]\n    # the number of vertices per batch\n    n_v_batch = v.shape[dim - 1]\n    # the number of batches\n    n_batch = len(v_batch_dim)\n\n    # expand the faces tensor to match the batch dimension of the vertices tensor\n    if f_batch_dim != v_batch_dim:\n        # pad the faces tensor to match the batch dimension of the vertices tensor\n        pad_size = len(v_batch_dim) - len(f_batch_dim)\n        f = f[(None,) * pad_size + (slice(None),) * (f.ndim - pad_size)]\n        # adjust the faces tensor shape to match the batch dimension of the vertices tensor\n        f = f.view(*v_batch_dim, *f.shape[pad_size:])\n\n    # gather the vertices of the faces\n    v_tris = multi_gather(v, f, dim)\n\n    # compute the normals of the faces\n    v_tris_0 = v_tris[:, 0]\n    v_tris_1 = v_tris[:, 1]\n    v_tris_2 = v_tris[:, 2]\n    v_tris_cross = torch.cross(v_tris_1 - v_tris_0, v_tris_2 - v_tris_0, dim=-1)\n    v_tris_norm = torch.norm(v_tris_cross, dim=-1, keepdim=True)\n    v_tris_norm = torch.where(v_tris_norm > 0, v_tris_norm, torch.ones_like(v_tris_norm))"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # TODO: support batched faces\n    if f.ndim != 2:\n        raise NotImplementedError(f'multi_gather_tris only supports batched vertices, but got f.ndim = {f.ndim}.')\n\n    # Expand the faces tensor to match the batch dimension of the vertices tensor\n    if v.ndim - f.ndim == 1:\n        f = f.expand(v.shape[0], *f.shape)\n\n    # Gather the triangles from the vertices\n    tri = multi_gather(v, f, dim)\n\n    # Reshape the result to maintain the structure of the original faces tensor with additional dimensions for batch processing\n    return tri.view(v.shape[0], *f.shape, 3, -1)\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch[None]\n    else:\n        batch = torch.as_tensor(batch)[None]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch[None]\n    else:\n        batch = torch.as_tensor(batch)[None]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch[None]\n    else:\n        batch = torch.as_tensor(batch)[None]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch[None]\n    else:\n        batch = torch.as_tensor(batch)[None]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch[None]\n    else:\n        batch = torch.as_tensor(batch)[None]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch[None, ...]\n    else:\n        batch = torch.as_tensor(batch)[None, ...]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch[None]\n    else:\n        batch = torch.as_tensor(batch)[None]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch[None]\n    else:\n        batch = torch.as_tensor(batch)[None]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch[None, ...]\n    else:\n        batch = torch.as_tensor(batch)[None, ...]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch[None]\n    else:\n        batch = torch.as_tensor(batch)[None]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch[None]\n    else:\n        batch = torch.as_tensor(batch)[None]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch[None]\n    else:\n        batch = torch.as_tensor(batch)[None]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch[None, ...]\n    else:\n        batch = torch.as_tensor(batch)[None, ...]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch[None, ...]\n    else:\n        batch = torch.as_tensor(batch)[None, ...]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch[None]\n    else:\n        batch = torch.as_tensor(batch)[None]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch[None]\n    else:\n        batch = torch.as_tensor(batch)[None]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch[None]\n    else:\n        batch = torch.as_tensor(batch)[None]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch[None, ...]\n    else:\n        batch = torch.as_tensor(batch)[None, ...]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch[None]\n    else:\n        batch = torch.as_tensor(batch)[None]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch[None, ...]\n    else:\n        batch = torch.as_tensor(batch)[None, ...]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Convert to batch\n        batch = dotdict({\n            'H': torch.tensor(self.H, dtype=torch.float32),\n            'W': torch.tensor(self.W, dtype=torch.float32),\n            'K': torch.tensor(self.K, dtype=torch.float32),\n            'R': torch.tensor(self.R, dtype=torch.float32),\n            'T': torch.tensor(self.T, dtype=torch.float32),\n            'n': torch.tensor(self.n, dtype=torch.float32),\n            'f': torch.tensor(self.f, dtype=torch.float32),\n            't': torch.tensor(self.t, dtype=torch.float32),\n            'v': torch.tensor(self.v, dtype=torch.float32),\n            'bounds': torch.tensor(self.bounds, dtype=torch.float32),\n            'origin': torch.tensor(self.origin, dtype=torch.float32),\n            'world_up': torch.tensor(self.world_up, dtype=torch.float32),\n            'movement_speed': torch.tensor(self.movement_speed, dtype=torch.float32),\n            'movement_force': torch.tensor(self.movement_force, dtype=torch.float32),\n            'drag_coeff_mult': torch.tensor(self.drag_coeff_mult, dtype=torch.float32),\n            'constant_drag': torch.tensor(self.constant_drag, dtype=torch.float32),\n            'mass': torch.tensor(self.mass, dtype=torch.float32),\n            'moment_of_inertia': torch.tensor(self.moment_of_inertia, dtype=torch.float32),\n            'angular_friction': torch.tensor(self.angular_friction, dtype=torch.float32"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.meta = dotdict()\n\n        batch.meta.H = self.H\n        batch.meta.W = self.W\n        batch.meta.K = to_tensor(self.K)\n        batch.meta.R = to_tensor(self.R)\n        batch.meta.T = to_tensor(self.T)\n        batch.meta.n = self.n\n        batch.meta.f = self.f\n        batch.meta.t = self.t\n        batch.meta.v = self.v\n        batch.meta.bounds = to_tensor(self.bounds)\n\n        batch.meta.origin = to_tensor(self.origin)\n        batch.meta.world_up = to_tensor(self.world_up)\n        batch.meta.movement_speed = self.movement_speed\n        batch.meta.movement_force = self.movement_force\n        batch.meta.drag_coeff_mult = self.drag_coeff_mult\n        batch.meta.constant_drag = self.constant_drag\n        batch.meta.mass = self.mass\n        batch.meta.moment_of_inertia = self.moment_of_inertia\n        batch.meta.movement_torque = self.movement_torque\n        batch.meta.angular_friction = self.angular_friction\n        batch.meta.constant_torque = self.constant_torque\n\n        batch.meta.is_dragging = self.is_dragging\n        batch.meta.is_panning = self.is_panning\n        batch.meta.about_origin = self.about_origin\n        batch.meta.drag_start = to_tensor(self.drag_start)\n        batch.meta.drag_start_front = to_tensor(self.drag_start_front)\n        batch.meta.drag_start_down = to_tensor(self.drag_start_down)\n        batch.meta.drag_start_right = to_tensor(self.drag_start_right)\n        batch.meta.drag_start_center = to_"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Convert camera parameters into tensors\n        batch = dotdict({\n            'H': torch.tensor(self.H, dtype=torch.float32),\n            'W': torch.tensor(self.W, dtype=torch.float32),\n            'K': torch.tensor(self.K, dtype=torch.float32),\n            'R': torch.tensor(self.R, dtype=torch.float32),\n            'T': torch.tensor(self.T, dtype=torch.float32),\n            'n': torch.tensor(self.n, dtype=torch.float32),\n            'f': torch.tensor(self.f, dtype=torch.float32),\n            't': torch.tensor(self.t, dtype=torch.float32),\n            'v': torch.tensor(self.v, dtype=torch.float32),\n            'bounds': torch.tensor(self.bounds, dtype=torch.float32),\n            'origin': torch.tensor(self.origin, dtype=torch.float32),\n            'world_up': torch.tensor(self.world_up, dtype=torch.float32),\n            'movement_speed': torch.tensor(self.movement_speed, dtype=torch.float32),\n            'movement_force': torch.tensor(self.movement_force, dtype=torch.float32),\n            'drag_coeff_mult': torch.tensor(self.drag_coeff_mult, dtype=torch.float32),\n            'constant_drag': torch.tensor(self.constant_drag, dtype=torch.float32),\n            'pause_physics': torch.tensor(self.pause_physics, dtype=torch.float32),\n            'min_interval': torch.tensor(self.min_interval, dtype=torch.float32),\n            'mass': torch.tensor(self.mass, dtype=torch.float32),\n            'moment_"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Convert camera parameters to tensors\n        batch = dotdict()\n        batch.H = torch.tensor(self.H, dtype=torch.float32)\n        batch.W = torch.tensor(self.W, dtype=torch.float32)\n        batch.K = torch.tensor(self.K, dtype=torch.float32)\n        batch.R = torch.tensor(self.R, dtype=torch.float32)\n        batch.T = torch.tensor(self.T, dtype=torch.float32)\n        batch.n = torch.tensor(self.n, dtype=torch.float32)\n        batch.f = torch.tensor(self.f, dtype=torch.float32)\n        batch.t = torch.tensor(self.t, dtype=torch.float32)\n        batch.v = torch.tensor(self.v, dtype=torch.float32)\n        batch.bounds = torch.tensor(self.bounds, dtype=torch.float32)\n\n        # Convert GUI related elements to tensors\n        batch.origin = torch.tensor(self.origin, dtype=torch.float32)\n        batch.world_up = torch.tensor(self.world_up, dtype=torch.float32)\n        batch.movement_speed = torch.tensor(self.movement_speed, dtype=torch.float32)\n        batch.drag_coeff_mult = torch.tensor(self.drag_coeff_mult, dtype=torch.float32)\n        batch.movement_force = torch.tensor(self.movement_force, dtype=torch.float32)\n        batch.constant_drag = torch.tensor(self.constant_drag, dtype=torch.float32)\n        batch.pause_physics = torch.tensor(self.pause_physics, dtype=torch.float32)\n        batch.min_interval = torch.tensor(self.min_interval, dtype=torch.float32)"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Convert camera parameters to batch\n        batch = dotdict({\n            'H': self.H,\n            'W': self.W,\n            'K': self.K,\n            'R': self.R,\n            'T': self.T,\n            'n': self.n,\n            'f': self.f,\n            't': self.t,\n            'v': self.v,\n            'bounds': self.bounds,\n            'origin': self.origin,\n            'world_up': self.world_up,\n            'movement_speed': self.movement_speed,\n            'movement_force': self.movement_force,\n            'drag_coeff_mult': self.drag_coeff_mult,\n            'constant_drag': self.constant_drag,\n            'mass': self.mass,\n            'moment_of_inertia': self.moment_of_inertia,\n            'movement_torque': self.movement_torque,\n            'angular_friction': self.angular_friction,\n            'constant_torque': self.constant_torque,\n            'min_interval': self.min_interval,\n            'pause_physics': self.pause_physics,\n        })\n\n        # Convert GUI related elements to batch\n        batch.meta = dotdict({\n            'is_dragging': self.is_dragging,\n            'is_panning': self.is_panning,\n            'about_origin': self.about_origin,\n            'drag_start': self.drag_start,\n            'drag_start_front': self.drag_start_front,\n            'drag_start_down': self.drag_start_down,\n            'drag_start_right': self.drag_start_right,\n            'drag_start_center': self.drag_start_center,\n            'drag_start_origin': self.drag_start_origin,\n            'drag_start_world_up': self.drag_start_world_up,\n            'drag_ymin': self.drag_ymin,\n            'drag"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Convert to tensors\n        batch = dotdict({\n            'H': torch.tensor(self.H),\n            'W': torch.tensor(self.W),\n            'K': torch.tensor(self.K),\n            'R': torch.tensor(self.R),\n            'T': torch.tensor(self.T),\n            'n': torch.tensor(self.n),\n            'f': torch.tensor(self.f),\n            't': torch.tensor(self.t),\n            'v': torch.tensor(self.v),\n            'bounds': torch.tensor(self.bounds),\n            'origin': torch.tensor(self.origin),\n            'world_up': torch.tensor(self.world_up),\n            'front': torch.tensor(self.front),\n            'right': torch.tensor(self.right),\n            'down': torch.tensor(self.down),\n            'center': torch.tensor(self.center),\n            'is_dragging': torch.tensor(self.is_dragging),\n            'about_origin': torch.tensor(self.about_origin),\n            'is_panning': torch.tensor(self.is_panning),\n            'drag_start': torch.tensor(self.drag_start),\n            'drag_start_front': torch.tensor(self.drag_start_front),\n            'drag_start_down': torch.tensor(self.drag_start_down),\n            'drag_start_right': torch.tensor(self.drag_start_right),\n            'drag_start_center': torch.tensor(self.drag_start_center),\n            'drag_start_origin': torch.tensor(self.drag_start_origin),\n            'drag_start_world_up': torch.tensor(self.drag_start_world_up),\n            'drag_ymin': torch.tensor(self.drag_ymin),\n            'drag_ymax': torch.tensor(self.drag_ymax),\n            'movement"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Convert camera parameters to tensors\n        batch = dotdict({\n            'H': torch.tensor(self.H, dtype=torch.float32),\n            'W': torch.tensor(self.W, dtype=torch.float32),\n            'K': torch.tensor(self.K, dtype=torch.float32),\n            'R': torch.tensor(self.R, dtype=torch.float32),\n            'T': torch.tensor(self.T, dtype=torch.float32),\n            'n': torch.tensor(self.n, dtype=torch.float32),\n            'f': torch.tensor(self.f, dtype=torch.float32),\n            't': torch.tensor(self.t, dtype=torch.float32),\n            'v': torch.tensor(self.v, dtype=torch.float32),\n            'bounds': torch.tensor(self.bounds, dtype=torch.float32),\n            'origin': torch.tensor(self.origin, dtype=torch.float32),\n            'world_up': torch.tensor(self.world_up, dtype=torch.float32),\n            'right': torch.tensor(self.right, dtype=torch.float32),\n            'down': torch.tensor(self.down, dtype=torch.float32),\n            'front': torch.tensor(self.front, dtype=torch.float32),\n            'center': torch.tensor(self.center, dtype=torch.float32),\n            'is_dragging': torch.tensor(self.is_dragging, dtype=torch.float32),\n            'is_panning': torch.tensor(self.is_panning, dtype=torch.float32),\n            'about_origin': torch.tensor(self.about_origin, dtype=torch.float32),\n            'drag_start': torch.tensor(self.drag_start, dtype=torch.float32"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.meta = dotdict()\n\n        batch.meta.H = self.H\n        batch.meta.W = self.W\n        batch.meta.K = self.K\n        batch.meta.R = self.R\n        batch.meta.T = self.T\n        batch.meta.n = self.n\n        batch.meta.f = self.f\n        batch.meta.t = self.t\n        batch.meta.v = self.v\n        batch.meta.bounds = self.bounds\n\n        batch.meta.origin = self.origin\n        batch.meta.world_up = self.world_up\n        batch.meta.movement_speed = self.movement_speed\n        batch.meta.movement_force = self.movement_force\n        batch.meta.drag_coeff_mult = self.drag_coeff_mult\n        batch.meta.constant_drag = self.constant_drag\n        batch.meta.mass = self.mass\n        batch.meta.moment_of_inertia = self.moment_of_inertia\n        batch.meta.movement_torque = self.movement_torque\n        batch.meta.angular_friction = self.angular_friction\n        batch.meta.constant_torque = self.constant_torque\n\n        batch.meta.pause_physics = self.pause_physics\n        batch.meta.min_interval = self.min_interval\n\n        batch.H = to_tensor(self.H)\n        batch.W = to_tensor(self.W)\n        batch.K = to_tensor(self.K)\n        batch.R = to_tensor(self.R)\n        batch.T = to_tensor(self.T)\n        batch.n = to_tensor(self.n)\n        batch.f = to_tensor(self.f)\n        batch.t = to_tensor(self.t)\n        batch.v = to_tensor(self.v)\n        batch.bounds = to_tensor(self.bounds)\n\n        batch.origin = to_tensor(self"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.meta = dotdict()\n\n        # Camera parameters\n        batch.meta.H = self.H\n        batch.meta.W = self.W\n        batch.meta.K = self.K\n        batch.meta.R = self.R\n        batch.meta.T = self.T\n        batch.meta.n = self.n\n        batch.meta.f = self.f\n        batch.meta.t = self.t\n        batch.meta.v = self.v\n        batch.meta.bounds = self.bounds\n\n        batch.meta.origin = self.origin\n        batch.meta.world_up = self.world_up\n        batch.meta.front = self.front\n        batch.meta.down = self.down\n        batch.meta.right = self.right\n        batch.meta.center = self.center\n\n        batch.meta.drag_start = self.drag_start\n        batch.meta.drag_start_front = self.drag_start_front\n        batch.meta.drag_start_down = self.drag_start_down\n        batch.meta.drag_start_right = self.drag_start_right\n        batch.meta.drag_start_center = self.drag_start_center\n        batch.meta.drag_start_origin = self.drag_start_origin\n        batch.meta.drag_start_world_up = self.drag_start_world_up\n\n        batch.meta.is_dragging = self.is_dragging\n        batch.meta.is_panning = self.is_panning\n        batch.meta.about_origin = self.about_origin\n\n        # GUI related elements\n        batch.meta.movement_speed = self.movement_speed\n        batch.meta.movement_force = self.movement_force\n        batch.meta.drag_coeff_mult = self.drag_coeff_mult\n        batch.meta.constant_drag = self.constant_drag\n        batch.meta.pause_physics = self.pause_physics\n        batch.meta.min_interval = self.min_interval\n\n       "}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Convert camera parameters to tensors\n        R = torch.from_numpy(self.R).float()\n        T = torch.from_numpy(self.T).float()\n        K = torch.from_numpy(self.K).float()\n        n = torch.tensor(self.n).float()\n        f = torch.tensor(self.f).float()\n        t = torch.tensor(self.t).float()\n        v = torch.tensor(self.v).float()\n        bounds = torch.from_numpy(self.bounds).float()\n\n        # Convert GUI related elements to tensors\n        origin = torch.from_numpy(self.origin).float()\n        world_up = torch.from_numpy(self.world_up).float()\n        movement_speed = torch.tensor(self.movement_speed).float()\n        drag_coeff_mult = torch.tensor(self.drag_coeff_mult).float()\n        mass = torch.tensor(self.mass).float()\n        moment_of_inertia = torch.tensor(self.moment_of_inertia).float()\n        movement_force = torch.tensor(self.movement_force).float()\n        angular_friction = torch.tensor(self.angular_friction).float()\n        constant_drag = torch.tensor(self.constant_drag).float()\n        movement_torque = torch.tensor(self.movement_torque).float()\n        constant_torque = torch.tensor(self.constant_torque).float()\n        pause_physics = torch.tensor(self.pause_physics).float()\n\n        # Convert camera parameters and GUI related elements into a structured dictionary\n        batch = dotdict({\n            'R': R,\n            'T': T,\n            'K': K,\n            'n': n,\n            'f': f,\n            't': t,\n            'v': v,\n            'bounds': bounds,\n            'origin': origin,\n            'world_up': world_up,\n            'movement"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Convert to tensors\n        H, W, K, R, T, n, f, t, v, bounds = to_tensor(self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds)\n        origin, world_up = to_tensor(self.origin, self.world_up)\n\n        # Store in batch\n        batch = dotdict()\n        batch.meta = dotdict()\n        batch.meta.H, batch.meta.W, batch.meta.K, batch.meta.R, batch.meta.T, batch.meta.n, batch.meta.f, batch.meta.t, batch.meta.v, batch.meta.bounds = H, W, K, R, T, n, f, t, v, bounds\n        batch.meta.origin, batch.meta.world_up = origin, world_up\n\n        batch.meta.is_dragging = self.is_dragging\n        batch.meta.is_panning = self.is_panning\n        batch.meta.about_origin = self.about_origin\n        batch.meta.drag_start = to_tensor(self.drag_start)\n        batch.meta.drag_start_front = to_tensor(self.drag_start_front)\n        batch.meta.drag_start_down = to_tensor(self.drag_start_down)\n        batch.meta.drag_start_right = to_tensor(self.drag_start_right)\n        batch.meta.drag_start_center = to_tensor(self.drag_start_center)\n        batch.meta.drag_start_origin = to_tensor(self.drag_start_origin)\n        batch.meta.drag_start_world_up = to_tensor(self.drag_start_world_up)\n        batch.meta.drag_ymin, batch.meta.drag_ymax = to_tensor(self.drag_ymin), to_tensor(self.drag_ymax)\n\n        batch.meta.mass, batch.meta.force, batch.meta."}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Convert all parameters to tensors\n        K = torch.from_numpy(self.K)\n        R = torch.from_numpy(self.R)\n        T = torch.from_numpy(self.T)\n        origin = torch.from_numpy(self.origin)\n        world_up = torch.from_numpy(self.world_up)\n        front = torch.from_numpy(self.front)\n        down = torch.from_numpy(self.down)\n        right = torch.from_numpy(self.right)\n        center = torch.from_numpy(self.center)\n        H = torch.tensor(self.H)\n        W = torch.tensor(self.W)\n        f = torch.tensor(self.f)\n        n = torch.tensor(self.n)\n        fx = torch.tensor(self.fx)\n        fy = torch.tensor(self.fy)\n        cx = torch.tensor(self.cx)\n        cy = torch.tensor(self.cy)\n        bounds = torch.from_numpy(self.bounds)\n        bounds_radius = torch.tensor(self.bounds_radius)\n        is_dragging = torch.tensor(self.is_dragging)\n        is_panning = torch.tensor(self.is_panning)\n        about_origin = torch.tensor(self.about_origin)\n        drag_start = torch.from_numpy(self.drag_start)\n        drag_start_front = torch.from_numpy(self.drag_start_front)\n        drag_start_down = torch.from_numpy(self.drag_start_down)\n        drag_start_right = torch.from_numpy(self.drag_start_right)\n        drag_start_center = torch.from_numpy(self.drag_start_center)\n        drag_start_origin = torch.from_numpy(self.drag_start_origin)\n        drag_start_world_up = torch.from_numpy(self.drag_start_"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Convert all the parameters to tensors\n        H, W, K, R, T, n, f, t, v, bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        K = torch.tensor(K, dtype=torch.float32)\n        R = torch.tensor(R, dtype=torch.float32)\n        T = torch.tensor(T, dtype=torch.float32)\n        n = torch.tensor(n, dtype=torch.float32)\n        f = torch.tensor(f, dtype=torch.float32)\n        t = torch.tensor(t, dtype=torch.float32)\n        v = torch.tensor(v, dtype=torch.float32)\n        bounds = torch.tensor(bounds, dtype=torch.float32)\n\n        # Create a batch of size 1\n        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = H, W, K, R, T, n, f, t, v, bounds\n        batch.meta = dotdict()\n        batch.meta.H, batch.meta.W, batch.meta.K, batch.meta.R, batch.meta.T, batch.meta.n, batch.meta.f, batch.meta.t, batch.meta.v, batch.meta.bounds = H, W, K, R, T, n, f, t, v, bounds\n\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.meta = dotdict()\n\n        batch.meta.H, batch.meta.W = self.H, self.W\n        batch.meta.K = torch.from_numpy(self.K).float()\n        batch.meta.R = torch.from_numpy(self.R).float()\n        batch.meta.T = torch.from_numpy(self.T).float()\n        batch.meta.origin = torch.from_numpy(self.origin).float()\n        batch.meta.world_up = torch.from_numpy(self.world_up).float()\n        batch.meta.front = torch.from_numpy(self.front).float()\n        batch.meta.right = torch.from_numpy(self.right).float()\n        batch.meta.down = torch.from_numpy(self.down).float()\n        batch.meta.center = torch.from_numpy(self.center).float()\n        batch.meta.bounds = torch.from_numpy(self.bounds).float()\n        batch.meta.n, batch.meta.f = self.n, self.f\n        batch.meta.movement_speed = self.movement_speed\n        batch.meta.movement_force = self.movement_force\n        batch.meta.drag_coeff_mult = self.drag_coeff_mult\n        batch.meta.constant_drag = self.constant_drag\n        batch.meta.mass = self.mass\n        batch.meta.moment_of_inertia = self.moment_of_inertia\n        batch.meta.movement_torque = self.movement_torque\n        batch.meta.angular_friction = self.angular_friction\n        batch.meta.constant_torque = self.constant_torque\n        batch.meta.pause_physics = self.pause_physics\n        batch.meta.min_interval = self.min_interval\n\n        batch.H, batch.W = self.H, self.W\n        batch.K = torch.from_numpy(self.K)."}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Convert all the camera parameters to tensors\n        K = torch.tensor(self.K)\n        R = torch.tensor(self.R)\n        T = torch.tensor(self.T)\n        H = torch.tensor(self.H)\n        W = torch.tensor(self.W)\n        n = torch.tensor(self.n)\n        f = torch.tensor(self.f)\n        t = torch.tensor(self.t)\n        v = torch.tensor(self.v)\n        bounds = torch.tensor(self.bounds)\n\n        # Convert all the GUI related elements to tensors\n        origin = torch.tensor(self.origin)\n        world_up = torch.tensor(self.world_up)\n        movement_speed = torch.tensor(self.movement_speed)\n        movement_force = torch.tensor(self.movement_force)\n        drag_coeff_mult = torch.tensor(self.drag_coeff_mult)\n        constant_drag = torch.tensor(self.constant_drag)\n        mass = torch.tensor(self.mass)\n        moment_of_inertia = torch.tensor(self.moment_of_inertia)\n        movement_torque = torch.tensor(self.movement_torque)\n        angular_friction = torch.tensor(self.angular_friction)\n        constant_torque = torch.tensor(self.constant_torque)\n        pause_physics = torch.tensor(self.pause_physics)\n        min_interval = torch.tensor(self.min_interval)\n\n        # Create a dotdict instance to store all the parameters and GUI related elements\n        batch = dotdict()\n\n        # Create a direct mapping of the parameters and GUI related elements\n        batch.K = K\n        batch.R = R\n        batch.T = T\n        batch.H = H\n        batch.W = W\n        batch.n = n\n        batch.f = f\n        batch.t = t\n        batch.v = v\n        batch."}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.meta = dotdict()\n\n        # Add camera parameters\n        batch.meta.K = torch.from_numpy(self.K).float()\n        batch.meta.R = torch.from_numpy(self.R).float()\n        batch.meta.T = torch.from_numpy(self.T).float()\n        batch.meta.n = torch.tensor(self.n).float()\n        batch.meta.f = torch.tensor(self.f).float()\n        batch.meta.T = torch.from_numpy(self.T).float()\n        batch.meta.origin = torch.from_numpy(self.origin).float()\n        batch.meta.world_up = torch.from_numpy(self.world_up).float()\n        batch.meta.center = torch.from_numpy(self.center).float()\n        batch.meta.front = torch.from_numpy(self.front).float()\n        batch.meta.down = torch.from_numpy(self.down).float()\n        batch.meta.right = torch.from_numpy(self.right).float()\n        batch.meta.bounds = torch.from_numpy(self.bounds).float()\n\n        # Add GUI related elements\n        batch.meta.H = torch.tensor(self.H).float()\n        batch.meta.W = torch.tensor(self.W).float()\n        batch.meta.is_dragging = torch.tensor(self.is_dragging).float()\n        batch.meta.is_panning = torch.tensor(self.is_panning).float()\n        batch.meta.about_origin = torch.tensor(self.about_origin).float()\n        batch.meta.drag_start = torch.from_numpy(self.drag_start).float()\n        batch.meta.drag_start_front = torch.from_numpy(self.drag_start_front).float()\n        batch.meta.drag_start_down = torch.from_numpy(self.drag_start_down).float()"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Convert to tensor\n        # The order of the parameters in the batch is important\n        batch = dotdict({\n            'H': torch.as_tensor(self.H),\n            'W': torch.as_tensor(self.W),\n            'K': torch.as_tensor(self.K),\n            'R': torch.as_tensor(self.R),\n            'T': torch.as_tensor(self.T),\n            'n': torch.as_tensor(self.n),\n            'f': torch.as_tensor(self.f),\n            't': torch.as_tensor(self.t),\n            'v': torch.as_tensor(self.v),\n            'bounds': torch.as_tensor(self.bounds),\n        })\n\n        # Add meta information\n        batch.meta = dotdict({\n            'H': torch.as_tensor(self.H),\n            'W': torch.as_tensor(self.W),\n            'K': torch.as_tensor(self.K),\n            'R': torch.as_tensor(self.R),\n            'T': torch.as_tensor(self.T),\n            'n': torch.as_tensor(self.n),\n            'f': torch.as_tensor(self.f),\n            't': torch.as_tensor(self.t),\n            'v': torch.as_tensor(self.v),\n            'bounds': torch.as_tensor(self.bounds),\n        })\n\n        # Return\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Convert camera parameters to tensors\n        # We use the 'dotdict' class to store the batch\n        batch = dotdict()\n        batch.meta = dotdict()\n        batch.meta.H = self.H\n        batch.meta.W = self.W\n        batch.meta.K = to_tensor(self.K)\n        batch.meta.R = to_tensor(self.R)\n        batch.meta.T = to_tensor(self.T)\n        batch.meta.n = to_tensor(self.n)\n        batch.meta.f = to_tensor(self.f)\n        batch.meta.t = to_tensor(self.t)\n        batch.meta.v = to_tensor(self.v)\n        batch.meta.bounds = to_tensor(self.bounds)\n        batch.meta.origin = to_tensor(self.origin)\n        batch.meta.world_up = to_tensor(self.world_up)\n        batch.meta.center = to_tensor(self.center)\n        batch.meta.front = to_tensor(self.front)\n        batch.meta.right = to_tensor(self.right)\n        batch.meta.down = to_tensor(self.down)\n        batch.meta.is_dragging = to_tensor(self.is_dragging)\n        batch.meta.is_panning = to_tensor(self.is_panning)\n        batch.meta.about_origin = to_tensor(self.about_origin)\n        batch.meta.drag_start = to_tensor(self.drag_start)\n        batch.meta.drag_start_front = to_tensor(self.drag_start_front)\n        batch.meta.drag_start_down = to_tensor(self.drag_start_down)\n        batch.meta.drag_start_right = to_tensor(self.drag_start_right)\n        batch.meta.drag_start_center = to_tensor(self.drag_start_center)\n        batch.meta.drag_start_origin = to_tensor(self.drag_start_origin)\n        batch.meta"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Convert camera parameters into tensors\n        H, W, K, R, T, n, f, t, v, bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        K, R, T, n, f, t, v, bounds = to_tensor(K), to_tensor(R), to_tensor(T), to_tensor(n), to_tensor(f), to_tensor(t), to_tensor(v), to_tensor(bounds)\n\n        # Store all camera parameters in a batch\n        batch = dotdict({\n            'H': H, 'W': W,\n            'K': K, 'R': R, 'T': T,\n            'n': n, 'f': f, 't': t, 'v': v,\n            'bounds': bounds,\n        })\n\n        # Store all camera parameters in a nested 'meta' dictionary\n        meta = dotdict({\n            'K': dotdict({'fx': K[0, 0], 'fy': K[1, 1], 'cx': K[2, 0], 'cy': K[2, 1]}),\n            'R': dotdict({'right': R[0, :], 'down': R[1, :], 'front': R[2, :]}),\n            'T': dotdict({'x': T[0], 'y': T[1], 'z': T[2]}),\n            'n': n, 'f': f, 't': t, 'v': v,\n            'bounds': dotdict({'min': bounds[0, :], 'max': bounds[1, :]}),\n        })\n\n        # Add 'meta' dictionary to batch\n        batch.meta = meta\n\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Convert all the parameters to torch tensors\n        H, W, K, R, T, n, f, t, v, bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        K, R, T, bounds = to_tensor(K), to_tensor(R), to_tensor(T), to_tensor(bounds)\n\n        # Create a dotdict and add the parameters to it\n        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = H, W, K, R, T, n, f, t, v, bounds\n\n        # Create a 'meta' dictionary and add the parameters to it\n        meta = dotdict()\n        meta.H, meta.W, meta.K, meta.R, meta.T, meta.n, meta.f, meta.t, meta.v, meta.bounds = H, W, K, R, T, n, f, t, v, bounds\n\n        # Add the 'meta' dictionary to the batch dictionary\n        batch.meta = meta\n\n        return batch\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working() and not agent.is_prime():\n            agent_serializer = AgentSerializer(agent)\n            serialized_agent = agent_serializer.serialize()\n            self.persistence.save_agent(serialized_agent)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working() and not agent.is_prime:\n            serialized_agent = AgentSerializer.serialize_agent(agent)\n            self.persistence.save_agent(serialized_agent)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent and not agent.is_prime_agent:\n            agent_state = AgentSerializer.serialize_agent(agent)\n            self.persistence.save_agent(agent.id, agent_state)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent and not agent.is_prime_agent:\n            agent_serializer = AgentSerializer(agent)\n            serialized_agent = agent_serializer.serialize_agent()\n            self.persistence.save_agent(serialized_agent)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serializer = AgentSerializer()\n            serialized_agent = serializer.serialize(agent)\n            self.persistence.save_agent(serialized_agent)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if not agent.is_prime_agent and agent.is_working_agent:\n            serializer = AgentSerializer(agent)\n            self.persistence.save_agent(serializer.to_json())\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if not agent.is_prime_agent and agent.is_working_agent:\n            self.persistence.save_agent(agent)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working and not agent.is_prime:\n            agent_serializer = AgentSerializer(agent)\n            agent_serializer.serialize_agent()\n            self.persistence.save_agent(agent_serializer.serialized_agent)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if not agent.is_prime_agent and agent.is_working_agent:\n            serialized_agent = AgentSerializer.serialize_agent(agent)\n            self.persistence.save_agent(serialized_agent)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            agent_serializer = AgentSerializer(agent)\n            agent_state = agent_serializer.serialize_agent()\n            self.persistence.save_agent(agent_state)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working and not agent.is_prime:\n            agent_serializer = AgentSerializer(agent)\n            agent_serializer.serialize()\n            self.persistence.save_agent(agent.id, agent_serializer.serialized_agent)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working() and not agent.is_prime:\n            serialized_agent = AgentSerializer.serialize_agent(agent)\n            self.persistence.save_agent(serialized_agent)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent and not agent.is_prime_agent:\n            serializer = AgentSerializer(agent)\n            self.persistence.save_agent(agent.id, serializer.serialize())\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent and not agent.is_prime_agent:\n            serializer = AgentSerializer()\n            serialized_agent = serializer.serialize(agent)\n            self.persistence.save_agent(serialized_agent)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working and not agent.is_prime:\n            serialized_agent = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(serialized_agent)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            agent_serializer = AgentSerializer()\n            agent_serializer.save_agent(agent, self.persistence)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent and not agent.is_prime_agent:\n            serializer = AgentSerializer()\n            serialized_agent = serializer.serialize(agent)\n            self.persistence.save_agent(serialized_agent)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent and not agent.is_prime_agent:\n            agent_state = AgentSerializer(agent)\n            self.persistence.save_agent(agent_state)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        # only save agents that are not prime agents\n        if not agent.is_prime_agent and agent.is_working_agent:\n            agent_data = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(agent_data)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if not agent.is_working_agent() or agent.is_prime_agent():\n            return\n        agent_dict = AgentSerializer(agent).to_dict()\n        self.persistence.save_agent(agent_dict)\n"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            highest_similarity = -np.inf\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([agent.purpose_embedding], [purpose_embedding])[0][0]\n                if similarity > highest_similarity:\n                    highest_similarity = similarity\n                    closest_agent = agent\n            return closest_agent, highest_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -np.inf"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if not purpose_embedding or len(purpose_embedding) == 0:\n                return None, -np.inf\n\n            max_similarity = -np.inf\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -np.inf"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            max_similarity = -np.inf\n            max_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([agent.purpose_embedding], [purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    max_agent = agent\n\n            return max_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -np.inf"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if len(self.agents) == 0:\n                return None, -np.inf\n\n            similarities = [cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0] for agent in self.agents]\n            if len(similarities) == 0:\n                return None, -np.inf\n\n            max_similarity = np.max(similarities)\n            max_similarity_index = np.argmax(similarities)\n            return self.agents[max_similarity_index], max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            max_similarity = -float(\"inf\")\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if not purpose_embedding:\n                return None, -np.inf\n\n            similarities = []\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarities.append(cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0])\n\n            if similarities:\n                return self.agents[np.argmax(similarities)], max(similarities)\n            else:\n                return None, -np.inf\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if len(self.agents) == 0:\n                return None, -np.inf\n\n            agent_similarities = []\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                agent_similarities.append((agent, cosine_similarity([agent.purpose_embedding], [purpose_embedding])[0][0]))\n\n            agent_similarities.sort(key=lambda x: x[1], reverse=True)\n            return agent_similarities[0]\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if len(self.agents) < 1:\n                return None, -np.inf\n\n            similarities = [cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0] for agent in self.agents]\n            if len(similarities) == 0:\n                return None, -np.inf\n\n            max_similarity = np.max(similarities)\n            if max_similarity < 0.9:\n                return None, -np.inf\n\n            max_index = np.argmax(similarities)\n            return self.agents[max_index], max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -np.inf"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            max_similarity = -float('inf')\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([agent.purpose_embedding], [purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -float('inf')\n\n"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if not purpose_embedding.any():\n                return None, -np.inf\n\n            similarities = [cosine_similarity([e], [purpose_embedding])[0][0] for e in [agent.purpose_embedding for agent in self.agents]]\n            max_similarity = max(similarities)\n            if max_similarity < 0.9:\n                return None, -np.inf\n\n            max_similarity_index = similarities.index(max_similarity)\n            return self.agents[max_similarity_index], max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -np.inf"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if len(self.agents) == 0:\n                return None, -np.inf\n            if len(self.agents) == 1:\n                return self.agents[0], 1\n\n            similarities = []\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n                similarities.append(cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0])\n\n            similarities = np.array(similarities)\n            return self.agents[np.argmax(similarities)], similarities.max()\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -np.inf"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if not purpose_embedding.any():\n                return None, -np.inf\n\n            highest_similarity = -np.inf\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > highest_similarity:\n                    highest_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, highest_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -np.inf\n"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if len(self.agents) == 0:\n                return None, -np.inf\n\n            if len(self.agents) == 1:\n                return self.agents[0], 1.0\n\n            similarities = [cosine_similarity([e1], [e2])[0][0] for e1 in self.agents for e2 in self.agents]\n            indices = np.argsort(similarities)[::-1]\n            best_agent_index = indices[0]\n            best_agent = self.agents[best_agent_index]\n            best_similarity = similarities[best_agent_index]\n\n            if best_similarity < 0.999:\n                return None, -np.inf\n\n            return best_agent, best_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -np.inf"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if purpose_embedding is None:\n                return None, -np.inf\n\n            if len(self.agents) == 0:\n                return None, -np.inf\n\n            similarities = [cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0] for agent in self.agents]\n            max_similarity = np.max(similarities)\n            if max_similarity < 0.999:\n                return None, -np.inf\n            else:\n                return self.agents[np.argmax(similarities)], max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -np.inf\n\n"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            closest_agent = None\n            highest_similarity = -np.inf\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([agent.purpose_embedding], [purpose_embedding])[0][0]\n                if similarity > highest_similarity:\n                    closest_agent = agent\n                    highest_similarity = similarity\n\n            return closest_agent, highest_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -np.inf\n"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            similarities = []\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([agent.purpose_embedding], [purpose_embedding])[0][0]\n                similarities.append((agent, similarity))\n\n            return max(similarities, key=lambda x: x[1]) if similarities else (None, -np.inf)\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")\n\n"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            highest_similarity = -np.inf\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([agent.purpose_embedding], [purpose_embedding])[0][0]\n                if similarity > highest_similarity:\n                    highest_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, highest_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")\n\n"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if len(self.agents) == 0:\n                return None, -np.inf\n\n            similarities = [cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0] for agent in self.agents]\n            max_idx = np.argmax(similarities)\n            return self.agents[max_idx], similarities[max_idx]\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -np.inf\n\n"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if not self.agents:\n                return None, -np.inf\n\n            if purpose_embedding is None:\n                return None, -np.inf\n\n            similarity_scores = [cosine_similarity([agent.purpose_embedding], [purpose_embedding])[0][0] for agent in self.agents]\n            if not similarity_scores:\n                return None, -np.inf\n\n            max_similarity_score = np.max(similarity_scores)\n            if max_similarity_score < 0.999:\n                return None, -np.inf\n\n            max_similarity_score_index = np.argmax(similarity_scores)\n            return self.agents[max_similarity_score_index], max_similarity_score\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -np.inf\n\n"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if len(self.agents) == 0:\n                return None, -np.inf\n\n            max_similarity = -np.inf\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([agent.purpose_embedding], [purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            unspecified_flag=True,\n            openai_api=self.openai_wrapper\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(PRIME_PROMPT, PRIME_NAME, PRIME_AGENT_WEIGHT, prime=True, unspecified_flag=True)\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            prime_only=True\n        )\n\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            prime_flag=True,\n            agent_persistence_manager=self.agent_persistence\n        )\n\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            is_prime=True,\n            is_engineering=False\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            prime_only=True,\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            prime_2=True\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            is_prime=True\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(PRIME_PROMPT, PRIME_NAME, PRIME_AGENT_WEIGHT, prime=True, unspecified=True)\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            name=PRIME_NAME,\n            prompt=PRIME_PROMPT,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            prime_agent=False,\n            agent_persistence_manager=self.agent_persistence\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(PRIME_PROMPT, PRIME_NAME, PRIME_AGENT_WEIGHT, True, True)\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            self.openai_wrapper,\n            PRIME_PROMPT,\n            PRIME_NAME,\n            PRIME_AGENT_WEIGHT,\n            prime=True,\n            prime_agent=False,\n            prime_engineer=False,\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            self.openai_wrapper,\n            PRIME_PROMPT,\n            PRIME_NAME,\n            PRIME_AGENT_WEIGHT,\n            prime=True,\n            is_active=True,\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            prime_agent=False,\n            agent_persistence=self.agent_persistence,\n            openai_wrapper=self.openai_wrapper,\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        self.agents.append(MicroAgent(PRIME_PROMPT, PRIME_NAME, PRIME_AGENT_WEIGHT, prime=True, prime_other=False))\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        self.agents.append(\n            MicroAgent(\n                prompt=PRIME_PROMPT,\n                name=PRIME_NAME,\n                weight=PRIME_AGENT_WEIGHT,\n                prime=True,\n                is_prime=True\n            )\n        )\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        self.agents.append(\n            MicroAgent(\n                self.openai_wrapper,\n                prompt=PRIME_PROMPT,\n                name=PRIME_NAME,\n                weight=PRIME_AGENT_WEIGHT,\n                prime=True,\n                prime_agent=True\n            )\n        )\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            prime_flag=True,\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            self.openai_wrapper,\n            PRIME_PROMPT,\n            PRIME_NAME,\n            PRIME_AGENT_WEIGHT,\n            prime=True,\n            engineered=False,\n            prime_example=EXAMPLES\n        )\n\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        self.agents.append(\n            MicroAgent(\n                self.openai_wrapper,\n                PRIME_PROMPT,\n                PRIME_NAME,\n                PRIME_AGENT_WEIGHT,\n                prime=True,\n                active=True,\n                prime_with_examples=True,\n                examples=EXAMPLES\n            )\n        )\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is None:\n            return None\n\n        return AgentSerializer.deserialize(\n            serialized_agent, agent_lifecycle, openai_wrapper\n        )"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is not None:\n            return AgentSerializer.deserialize(\n                serialized_agent, agent_lifecycle, openai_wrapper\n            )\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is None:\n            return None\n\n        return AgentSerializer.deserialize(\n            serialized_agent, agent_lifecycle, openai_wrapper\n        )"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n\n        if serialized_agent is not None:\n            return AgentSerializer.deserialize(\n                serialized_agent, agent_lifecycle, openai_wrapper\n            )\n\n        return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is None:\n            return None\n        return AgentSerializer.deserialize(\n            serialized_agent, agent_lifecycle, openai_wrapper\n        )"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        agent_data = self.persistence.load_agent(purpose)\n        if agent_data is None:\n            return None\n\n        return AgentSerializer.deserialize(\n            agent_data, agent_lifecycle, openai_wrapper\n        )"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with a specified purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agent to be loaded. It is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: An instance of the deserialized agent if found, otherwise None.\n        \"\"\"\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is None:\n            return None\n\n        return AgentSerializer.deserialize(\n            serialized_agent, agent_lifecycle, openai_wrapper\n        )"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with a specified purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agent to be loaded. It is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: An instance of the deserialized agent if found, otherwise None.\n        \"\"\"\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is None:\n            return None\n        return AgentSerializer.deserialize(\n            serialized_agent, agent_lifecycle, openai_wrapper\n        )"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        agent_data = self.persistence.load_agent(purpose)\n\n        if agent_data is not None:\n            return AgentSerializer.deserialize(\n                agent_data, agent_lifecycle, openai_wrapper\n            )\n\n        return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        agent_json = self.persistence.load_agent(purpose)\n        if agent_json is None:\n            return None\n        return AgentSerializer.deserialize(\n            agent_json, agent_lifecycle, openai_wrapper\n        )"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        agent = self.persistence.load_agent(purpose)\n        if agent is not None:\n            return AgentSerializer.deserialize(\n                agent, agent_lifecycle, openai_wrapper\n            )\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(\n        self,\n        purpose,\n        agent_lifecycle,\n        openai_wrapper,\n    ):\n        \"\"\"\n        Loads an agent with a specified purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agent to be loaded. It is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: An instance of the deserialized agent if found, otherwise None.\n        \"\"\"\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is not None:\n            return AgentSerializer.deserialize(\n                serialized_agent,\n                agent_lifecycle,\n                openai_wrapper,\n            )\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is None:\n            return None\n        return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is not None:\n            return AgentSerializer.deserialize(\n                serialized_agent, agent_lifecycle, openai_wrapper\n            )\n        else:\n            return None\n\n    def get_agent_ids(self):\n        return self.persistence.get_agent_ids()"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with a specified purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agent to be loaded. It is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: An instance of the deserialized agent if found, otherwise None.\n        \"\"\"\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is not None:\n            return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n        return None\n\n    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: A list of instances of the deserialized agents.\n        \"\"\"\n        serialized_agents = self.persistence.load_all_agents()\n        return [\n            AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n            for serialized_agent in serialized_agents\n        ]"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(\n        self,\n        purpose,\n        agent_lifecycle,\n        openai_wrapper,\n        **kwargs\n    ):\n        agent = self.persistence.load_agent(purpose)\n        if agent is not None:\n            return AgentSerializer.deserialize(\n                agent,\n                agent_lifecycle,\n                openai_wrapper,\n                **kwargs\n            )\n\n        return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is not None:\n            return AgentSerializer.deserialize(\n                serialized_agent, agent_lifecycle, openai_wrapper\n            )\n        else:\n            return None\n\n    def list_agents(self):\n        \"\"\"\n        Returns a list of all the agents in the database.\n        \"\"\"\n        return self.persistence.list_agents()"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        agent_data = self.persistence.load_agent(purpose)\n        if agent_data is not None:\n            return AgentSerializer.deserialize(\n                agent_data, agent_lifecycle, openai_wrapper\n            )\n\n    def save_agent_data(self, purpose, agent_data):\n        \"\"\"\n        Save the data of an agent with a specified purpose.\n        \"\"\"\n        self.persistence.save_agent_data(purpose, agent_data)\n\n    def load_agent_data(self, purpose):\n        \"\"\"\n        Load the data of an agent with a specified purpose.\n        \"\"\"\n        return self.persistence.load_agent_data(purpose)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with a specified purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agent to be loaded. It is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: An instance of the deserialized agent if found, otherwise None.\n        \"\"\"\n        serialized_agent = self.persistence.load_agent(purpose)\n\n        if serialized_agent is not None:\n            return AgentSerializer.deserialize(\n                serialized_agent, agent_lifecycle, openai_wrapper\n            )\n\n        return None\n\n    def save_agent_to_file(self, agent, filename):\n        \"\"\"\n        Serialize and save the agent state to a file.\n        \"\"\"\n        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.serialize(agent)\n            self.persistence.save_agent_to_file(serialized_agent, filename)\n\n    def load_agent_from_file(self, purpose, filename):\n        \"\"\"\n        Loads an agent with a specified purpose from a file. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agent to be loaded. It is used to identify the agent in the database.\n        :"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(\n        self,\n        purpose,\n        agent_lifecycle,\n        openai_wrapper,\n        agent_type,\n        agent_id,\n        agent_name,\n        agent_owner,\n        agent_description,\n        agent_class,\n        agent_function,\n        agent_parameters,\n        agent_version,\n        agent_is_alive,\n        agent_is_working,\n        agent_is_prime,\n    ):\n        serialized_agent = self.persistence.load_agent(agent_id)\n\n        if serialized_agent:\n            return AgentSerializer.deserialize(\n                serialized_agent,\n                agent_lifecycle,\n                openai_wrapper,\n                agent_type,\n                agent_id,\n                agent_name,\n                agent_owner,\n                agent_description,\n                agent_class,\n                agent_function,\n                agent_parameters,\n                agent_version,\n                agent_is_alive,\n                agent_is_working,\n                agent_is_prime,\n            )\n\n        return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    @memoize_to_sqlite\n    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database and returns a list of these agents if they are successfully loaded. Each agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param agent_lifecycle: The lifecycle manager for agents, used to manage the state and transitions of an agent throughout its lifecycle.\n        :param openai_wrapper: An interface or wrapper for OpenAI functionalities, used to interact with OpenAI services or models in the process of loading an agent.\n        :return: list. A list of agents that have been successfully loaded from the database.\n        \"\"\"\n        serialized_agents = self.persistence.fetch_all_agents()\n        agents = []\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(\n                serialized_agent, agent_lifecycle, openai_wrapper\n            )\n            if agent:\n                agents.append(agent)\n        return agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    @memoize_to_sqlite\n    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database and returns a list of these agents if they are successfully loaded. Each agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param agent_lifecycle: The lifecycle manager for agents, used to manage the state and transitions of an agent throughout its lifecycle.\n        :param openai_wrapper: An interface or wrapper for OpenAI functionalities, used to interact with OpenAI services or models in the process of loading an agent.\n        :return: list. A list of agents that have been successfully loaded from the database.\n        \"\"\"\n        serialized_agents = self.persistence.fetch_all_agents()\n        agents = []\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(\n                serialized_agent, agent_lifecycle, openai_wrapper\n            )\n            if agent:\n                agents.append(agent)\n        return agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    @memoize_to_sqlite\n    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database and returns a list of these agents if they are successfully loaded. Each agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param agent_lifecycle: The lifecycle manager for agents, used to manage the state and transitions of an agent throughout its lifecycle.\n        :param openai_wrapper: An interface or wrapper for OpenAI functionalities, used to interact with OpenAI services or models in the process of loading an agent.\n        :return: list. A list of agents that have been successfully loaded from the database.\n        \"\"\"\n        serialized_agents = self.persistence.fetch_all_agents()\n        agents = []\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(\n                serialized_agent, agent_lifecycle, openai_wrapper\n            )\n            if agent:\n                agents.append(agent)\n        return agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    @memoize_to_sqlite\n    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database and returns a list of these agents if they are successfully loaded. Each agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param agent_lifecycle: The lifecycle manager for agents, used to manage the state and transitions of an agent throughout its lifecycle.\n        :param openai_wrapper: An interface or wrapper for OpenAI functionalities, used to interact with OpenAI services or models in the process of loading an agent.\n        :return: list. A list of agents that have been successfully loaded from the database.\n        \"\"\"\n        serialized_agents = self.persistence.fetch_all_agents()\n        return [\n            AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            for serialized_agent in serialized_agents\n        ]"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    @memoize_to_sqlite\n    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database and returns a list of these agents if they are successfully loaded. Each agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param agent_lifecycle: The lifecycle manager for agents, used to manage the state and transitions of an agent throughout its lifecycle.\n        :param openai_wrapper: An interface or wrapper for OpenAI functionalities, used to interact with OpenAI services or models in the process of loading an agent.\n        :return: list. A list of agents that have been successfully loaded from the database.\n        \"\"\"\n        serialized_agents = self.persistence.fetch_all_agents()\n        return [\n            AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            for serialized_agent in serialized_agents\n        ]"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    @memoize_to_sqlite\n    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database and returns a list of these agents if they are successfully loaded. Each agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param agent_lifecycle: The lifecycle manager for agents, used to manage the state and transitions of an agent throughout its lifecycle.\n        :param openai_wrapper: An interface or wrapper for OpenAI functionalities, used to interact with OpenAI services or models in the process of loading an agent.\n        :return: list. A list of agents that have been successfully loaded from the database.\n        \"\"\"\n        serialized_agents = self.persistence.fetch_all_agents()\n        if serialized_agents:\n            return [\n                AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n                for serialized_agent in serialized_agents\n            ]\n        return []"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    @memoize_to_sqlite\n    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database and returns a list of these agents if they are successfully loaded. Each agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param agent_lifecycle: The lifecycle manager for agents, used to manage the state and transitions of an agent throughout its lifecycle.\n        :param openai_wrapper: An interface or wrapper for OpenAI functionalities, used to interact with OpenAI services or models in the process of loading an agent.\n        :return: list. A list of agents that have been successfully loaded from the database.\n        \"\"\"\n        serialized_agents = self.persistence.fetch_all_agents()\n        return [\n            AgentSerializer.from_dict(\n                serialized_agent, agent_lifecycle, openai_wrapper\n            )\n            for serialized_agent in serialized_agents\n        ]"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    @memoize_to_sqlite\n    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database and returns a list of these agents if they are successfully loaded. Each agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param agent_lifecycle: The lifecycle manager for agents, used to manage the state and transitions of an agent throughout its lifecycle.\n        :param openai_wrapper: An interface or wrapper for OpenAI functionalities, used to interact with OpenAI services or models in the process of loading an agent.\n        :return: list. A list of agents that have been successfully loaded from the database.\n        \"\"\"\n\n        serialized_agents = self.persistence.fetch_all_agents()\n        agents = []\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(\n                serialized_agent, agent_lifecycle, openai_wrapper\n            )\n            if agent:\n                agents.append(agent)\n        return agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database and returns a list of these agents if they are successfully loaded. Each agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param agent_lifecycle: The lifecycle manager for agents, used to manage the state and transitions of an agent throughout its lifecycle.\n        :param openai_wrapper: An interface or wrapper for OpenAI functionalities, used to interact with OpenAI services or models in the process of loading an agent.\n        :return: list. A list of agents that have been successfully loaded from the database.\n        \"\"\"\n        serialized_agents = self.persistence.fetch_all_agents()\n        return [\n            AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            for serialized_agent in serialized_agents\n        ]"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        serialized_agents = self.persistence.fetch_all_agents()\n        agents = []\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(\n                serialized_agent, agent_lifecycle, openai_wrapper\n            )\n            if agent:\n                agents.append(agent)\n        return agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        return [\n            AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            for serialized_agent in self.persistence.fetch_all_agents()\n        ]"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        serialized_agents = self.persistence.fetch_all_agents()\n        agents = []\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(\n                serialized_agent, agent_lifecycle, openai_wrapper\n            )\n            if agent:\n                agents.append(agent)\n        return agents\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    def load_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database and returns a list of these agents if they are successfully loaded. Each agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param agent_lifecycle: The lifecycle manager for agents, used to manage the state and transitions of an agent throughout its lifecycle.\n        :param openai_wrapper: An interface or wrapper for OpenAI functionalities, used to interact with OpenAI services or models in the process of loading an agent.\n        :return: list. A list of agents that have been successfully loaded from the database.\n        \"\"\"\n        serialized_agents = self.persistence.fetch_all_agents()\n        agents = []\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(\n                serialized_agent, agent_lifecycle, openai_wrapper\n            )\n            if agent:\n                agents.append(agent)\n        return agents\n\n    def save_agent_to_cache(self, agent):\n        \"\"\"\n        Serialize and save the agent state if it is a working agent and not a prime agent.\n        \"\"\"\n        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.serialize(agent)\n            self.persistence.save_agent_to_cache(serialized_agent)\n\n    def load_agent_from_cache(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Load an agent with the given purpose from the cache.\n        \"\"\"\n        serialized_agent = self.persistence.fetch_agent_from_cache(purpose)\n        if serialized_agent:\n            return AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n        return None\n\n    def load_agents_from_cache(self, agent_lifecycle, openai"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        serialized_agents = self.persistence.fetch_all_agents()\n        agents = []\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if agent:\n                agents.append(agent)\n        return agents\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        serialized_agents = self.persistence.fetch_all_agents()\n        agents = []\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(\n                serialized_agent, agent_lifecycle, openai_wrapper\n            )\n            if agent:\n                agents.append(agent)\n        return agents\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database and returns a list of these agents if they are successfully loaded. Each agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param agent_lifecycle: The lifecycle manager for agents, used to manage the state and transitions of an agent throughout its lifecycle.\n        :param openai_wrapper: An interface or wrapper for OpenAI functionalities, used to interact with OpenAI services or models in the process of loading an agent.\n        :return: list. A list of agents that have been successfully loaded from the database.\n        \"\"\"\n        serialized_agents = self.persistence.fetch_all_agents()\n        return [\n            AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            for serialized_agent in serialized_agents\n        ]\n\n    def load_agent_with_purpose(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with the given purpose from the database and returns this agent if it is successfully loaded. The agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str. The purpose of the agent, which is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle manager for agents, used to manage the state and transitions of an agent throughout its lifecycle.\n        :param openai_wrapper: An interface or wrapper for OpenAI functionalities, used to interact with OpenAI services or models in the process of loading an agent.\n        :return: Agent. The agent that has been successfully loaded from the database.\n        \"\"\"\n        serialized_agent = self.persistence.fetch_agent(purpose)\n        if serialized"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        serialized_agents = self.persistence.fetch_all_agents()\n        if serialized_agents:\n            return [\n                AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n                for serialized_agent in serialized_agents\n            ]\n\n        return []\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        serialized_agents = self.persistence.fetch_all_agents()\n        agents = []\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(\n                serialized_agent, agent_lifecycle, openai_wrapper\n            )\n            if agent:\n                agents.append(agent)\n\n        return agents\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        # load all agents\n        serialized_agents = self.persistence.fetch_all_agents()\n        agents = []\n        for serialized_agent in serialized_agents:\n            # try to load each agent\n            agent = AgentSerializer.from_dict(\n                serialized_agent, agent_lifecycle, openai_wrapper\n            )\n            if agent:\n                # if loading is successful, add the agent to the list\n                agents.append(agent)\n        return agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        serialized_agents = self.persistence.fetch_all_agents()\n        loaded_agents = []\n        for serialized_agent in serialized_agents:\n            try:\n                loaded_agent = AgentSerializer.from_dict(\n                    serialized_agent, agent_lifecycle, openai_wrapper\n                )\n                loaded_agents.append(loaded_agent)\n            except Exception as e:\n                print(e)\n                print(\n                    f\"Could not load agent with purpose {serialized_agent['purpose']}. Continuing...\"\n                )\n        return loaded_agents\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error saving agent: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error saving agent {agent.id}: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(\"Error saving agent: %s\", e)\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(\"Failed to save agent\", e)\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error saving agent: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error saving agent {agent.id} to the persistence mechanism. {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save(agent)\n        except Exception as e:\n            logger.error(f\"Error saving agent {agent.id}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error saving agent: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save(agent)\n        except Exception as e:\n            logger.exception(f\"Error saving agent: {agent.id}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Exception occurred while saving agent: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error saving agent: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error saving agent {agent.id}: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error saving agent: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error saving agent: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error saving agent: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error saving agent: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(\"An error occurred while saving the agent.\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Failed to save agent {agent.id}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error saving agent: {e}\")\n            raise\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error saving agent: {e}\")\n            raise\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(goal=goal, sample_input=sample_input)\n        try:\n            return PROMPT_ENGINEERING_TEMPLATE.format(prompt=prompt, examples=EXAMPLES)\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(\n                goal=goal,\n                examples=EXAMPLES.format(sample_input=sample_input)\n            )\n            return PROMPT_ENGINEERING_TEMPLATE.format(prompt=prompt)\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = \"\"\n        try:\n            prompt = PROMPT_ENGINEERING_TEMPLATE.format(\n                PROMPT_ENGINEERING_SYSTEM_PROMPT,\n                goal,\n                sample_input,\n                EXAMPLES\n            )\n            self.openai_wrapper.get_chat_completion(prompt)\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n        return prompt"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            return self.openai_wrapper.get_chat_completion(goal, sample_input)\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\"\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(\n                goal=goal,\n                sample_input=sample_input,\n                examples=EXAMPLES\n            )\n            return prompt\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            return self.openai_wrapper.get_chat_completion(goal, sample_input)\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\"\n\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            return self.openai_wrapper.get_chat_completion(goal, sample_input)\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\"\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            return self.openai_wrapper.get_chat_completion(goal, sample_input)\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\"\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT + PROMPT_ENGINEERING_TEMPLATE.format(goal=goal, sample_input=sample_input)\n            prompt += \"\\n\" + EXAMPLES + \"\\n\"\n            for i in range(len(self.agents)):\n                prompt += self.agents[i].prompt\n            return prompt\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(goal, sample_input)\n\n        try:\n            response = self.openai_wrapper.get_chat_completion(prompt)\n            prompt = PROMPT_ENGINEERING_TEMPLATE.format(goal, sample_input, response)\n            return prompt\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\"\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = \"\"\n        try:\n            prompt = self._generate_llm_prompt_from_goal(goal, sample_input)\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n        return prompt\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(\n            goal=goal,\n            examples=EXAMPLES.format(\n                sample_input=sample_input\n            )\n        )\n\n        try:\n            completion = self.openai_wrapper.get_completion(prompt)\n            return PROMPT_ENGINEERING_TEMPLATE.format(\n                prompt=prompt,\n                completion=completion\n            )\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\"\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.replace(\"<<GOAL>>\", goal)\n        prompt = prompt.replace(\"<<EXAMPLES>>\", EXAMPLES)\n        prompt = prompt.replace(\"<<INPUT>>\", sample_input)\n\n        try:\n            completion = self.openai_wrapper.get_completion(prompt)\n            return PROMPT_ENGINEERING_TEMPLATE.replace(\"<<PROMPT>>\", prompt).replace(\"<<CHAT>>\", completion)\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\"\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT + goal + PROMPT_ENGINEERING_TEMPLATE + sample_input\n\n        try:\n            return self.openai_wrapper.get_chat_completion(prompt)\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\"\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = PROMPT_ENGINEERING_TEMPLATE.format(\n                examples=EXAMPLES.format(goal=goal, sample_input=sample_input),\n                engineering_system_prompt=PROMPT_ENGINEERING_SYSTEM_PROMPT\n            )\n            return prompt\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\"\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(\n            goal=goal,\n            template=PROMPT_ENGINEERING_TEMPLATE,\n            examples=EXAMPLES\n        )\n\n        try:\n            return self.openai_wrapper.get_chat_completion(prompt, sample_input)\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\"\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(goal=goal, sample_input=sample_input)\n\n        try:\n            prompt = self.openai_wrapper.get_llm_chat_completion(prompt, engine=\"davinci\", temperature=0.7, max_tokens=100, top_p=1)\n        except Exception as e:\n            logger.exception(f\"Error in getting chat completion: {e}\")\n            return \"\"\n\n        return PROMPT_ENGINEERING_TEMPLATE.format(prompt=prompt)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(goal=goal, sample_input=sample_input)\n        try:\n            prompt = self.openai_wrapper.get_llm_prompt(prompt)\n            return prompt\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\"\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = self._generate_prompt_from_goal(goal, sample_input)\n            chat_completion = self.openai_wrapper.get_chat_completion(prompt)\n            return chat_completion\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\"\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = \"\"\n        try:\n            prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT + PROMPT_ENGINEERING_TEMPLATE.format(goal=goal, sample_input=sample_input) + EXAMPLES\n            prompt = self.openai_wrapper.get_chat_completion(prompt)\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n        return prompt\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"\"\"\n                INSERT OR REPLACE INTO agents (id, purpose, data) VALUES (?, ?, ?)\n            \"\"\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"\"\"\n                REPLACE INTO agents (id, purpose, data)\n                VALUES (?, ?, ?)\n            \"\"\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"\"\"\n                INSERT OR REPLACE INTO agents (id, purpose, data)\n                VALUES (:id, :purpose, :data)\n            \"\"\", agent_dict)\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"REPLACE INTO agents VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"\"\"\n                INSERT OR REPLACE INTO agents (id, purpose, data)\n                VALUES (:id, :purpose, :data)\n            \"\"\", agent_dict)\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"REPLACE INTO agents (id, purpose, data) VALUES (?, ?, ?)\",\n                         (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"\"\"\n                INSERT OR REPLACE INTO agents (id, purpose, data) VALUES (?, ?, ?)\n            \"\"\", (\n                agent_dict['id'],\n                agent_dict['purpose'],\n                json.dumps(agent_dict)\n            ))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"REPLACE INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"REPLACE INTO agents VALUES (:id, :purpose, :data)\", agent_dict)\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"\"\"\n                REPLACE INTO agents (id, purpose, data) VALUES (?, ?, ?)\n            \"\"\", (\n                agent_dict['id'],\n                agent_dict['purpose'],\n                json.dumps(agent_dict['data'])\n            ))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"\"\"\n                INSERT OR REPLACE INTO agents (id, purpose, data)\n                VALUES (?, ?, ?)\n            \"\"\", (\n                agent_dict[\"id\"],\n                agent_dict[\"purpose\"],\n                json.dumps(agent_dict)\n            ))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"REPLACE INTO agents VALUES (?, ?, ?)\",\n                         (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"REPLACE INTO agents VALUES (?, ?, ?)\",\n                         (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"DELETE FROM agents WHERE id = ?\", (agent_dict['id'],))\n            conn.execute(\"\"\"\n                INSERT INTO agents (id, purpose, data) VALUES (?, ?, ?)\n            \"\"\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"REPLACE INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"REPLACE INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict[\"id\"], agent_dict[\"purpose\"], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"\"\"\n                INSERT OR REPLACE INTO agents (id, purpose, data)\n                VALUES (?, ?, ?)\n            \"\"\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"\"\"\n                INSERT OR REPLACE INTO agents (id, purpose, data)\n                VALUES (?, ?, ?)\n            \"\"\", (agent_dict[\"id\"], agent_dict[\"purpose\"], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"REPLACE INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict[\"id\"], agent_dict[\"purpose\"], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"REPLACE INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict['data'])))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row is None:\n                return None\n            return json.loads(row[0])"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result is None:\n                return None\n            else:\n                return json.loads(result[0])"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row is None:\n                return None\n            return json.loads(row[0])"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result is None:\n                return None\n            return json.loads(result[0])"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result is None:\n                return None\n            return json.loads(result[0])"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row is None:\n                return None\n            else:\n                return json.loads(row[0])"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row is None:\n                return None\n            return json.loads(row[0])"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result is not None:\n                return json.loads(result[0])\n            return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result is None:\n                return None\n            else:\n                return json.loads(result[0])\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                return None\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row is None:\n                return None\n            agent_dict = json.loads(row[0])\n            return agent_dict\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cur = conn.cursor()\n            cur.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            result = cur.fetchone()\n            if result is not None:\n                return json.loads(result[0])\n            else:\n                return None\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row is None:\n                return None\n            return json.loads(row[0])\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row is None:\n                return None\n            return json.loads(row[0])\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row is None:\n                return None\n            else:\n                return json.loads(row[0])\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row is None:\n                return None\n            return json.loads(row[0])\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row is None:\n                return None\n            return json.loads(row[0])\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result is None:\n                return None\n            return json.loads(result[0])\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result is None:\n                return None\n            return json.loads(result[0])\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            row = cursor.fetchall()\n            return [item[0] for item in row]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.execute(\n            \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n        )\n        result = cursor.fetchone()\n        if result is None:\n            return None\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash=?\", (arg_hash,))\n        result = cursor.fetchone()\n        return json.loads(result[0]) if result is not None else None\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash=?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result is None:\n            return None\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash=?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result is None:\n            return None\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash = ?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result is None:\n            return None\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash = ?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result is None:\n            return None\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.execute(\"SELECT result FROM cache WHERE hash = ?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result is None:\n            return None\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.execute(\n            \"SELECT result FROM cache WHERE hash=?\", (arg_hash,)\n        )\n        row = cursor.fetchone()\n        if row is None:\n            return None\n        return json.loads(row[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash=?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result is None:\n            return None\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash = ?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result is None:\n            return None\n\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash=?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result is None:\n            return None\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash=?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result is None:\n            return None\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash=?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result is None:\n            return None\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash=?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result is None:\n            return None\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.execute(\n            \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n        )\n        result = cursor.fetchone()\n        if result is None:\n            return None\n\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash=?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result is None:\n            return None\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.execute(\"SELECT result FROM cache WHERE hash=?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result is None:\n            return None\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash = ?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result is None:\n            return None\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash = ?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result is not None:\n            return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash=?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result is not None:\n            result = json.loads(result[0])\n        return result\n"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result))\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result))\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result))\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache(hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result))\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result))\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        result_json = json.dumps(result)\n        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, result_json)\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        serialized_result = json.dumps(result)\n        self.connection.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, serialized_result)\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        result_json = json.dumps(result)\n        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, result_json)\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result))\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        result_json = json.dumps(result)\n        self.connection.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, result_json)\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()\n\n"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        result_as_json = json.dumps(result)\n        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache(hash, result) VALUES(?, ?)\",\n            (arg_hash, result_as_json),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters.\n    CONFIG.update_config(args)\n\n    # Redirect standard output to a file if quiet mode is enabled.\n    if quiet_mode:\n        with open(os.path.join(CONFIG.record_dir, 'output.txt'), 'w') as f:\n            with redirect_stdout(f):\n                CommandLine().execute()\n    else:\n        CommandLine().execute()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    CONFIG.update(vars(args))\n\n    # Redirect standard output to a file if quiet mode is enabled\n    if quiet_mode:\n        with open(os.path.join(CONFIG['record_dir'], 'stdout.txt'), 'w') as stdout:\n            with redirect_stdout(stdout):\n                CommandLine().execute()\n    else:\n        CommandLine().execute()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    global CONFIG, ARGS\n\n    CONFIG.update(args.__dict__)\n    ARGS = args\n\n    if quiet_mode:\n        with open(CONFIG['record_dir'] + '/output.txt', 'w') as f:\n            with redirect_stdout(f):\n                CommandLine(args).execute()\n    else:\n        CommandLine(args).execute()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    CONFIG.update_config(args)\n\n    # If quiet mode is enabled, redirect the standard output to a file\n    if quiet_mode:\n        with open(os.path.join(CONFIG.record_dir, 'stdout.txt'), 'w') as f:\n            with redirect_stdout(f):\n                CommandLine(args).execute()\n    else:\n        CommandLine(args).execute()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    if args.upload_files is not None:\n        CONFIG.upload_files = args.upload_files\n    if args.model is not None:\n        CONFIG.model = args.model\n    if args.record_dir is not None:\n        CONFIG.record_dir = args.record_dir\n    if args.mode is not None:\n        CONFIG.mode = args.mode\n    if args.quiet is not None:\n        CONFIG.quiet = args.quiet\n    if args.max_subtask_chain_length is not None:\n        CONFIG.max_subtask_chain_length = args.max_subtask_chain_length\n    if args.enable_ask_human_for_help is not None:\n        CONFIG.enable_ask_human_for_help = args.enable_ask_human_for_help\n    if args.max_plan_refine_chain_length is not None:\n        CONFIG.max_plan_refine_chain_length = args.max_plan_refine_chain_length\n    if args.max_plan_tree_depth is not None:\n        CONFIG.max_plan_tree_depth = args.max_plan_tree_depth\n    if args.max_plan_tree_width is not None:\n        CONFIG.max_plan_tree_width = args.max_plan_tree_width\n    if args.max_retry_times is not None:\n        CONFIG.max_retry_times = args.max_retry_times\n\n    # Redirect standard output to a file if quiet mode is enabled\n    if quiet_mode:\n        with open(os.devnull, 'w') as devnull:\n            with redirect_stdout(devnull):\n                CommandLine.execute_command_line_process(args.task)\n    else:\n        CommandLine.execute_command_line_process(args.task)\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters.\n    CONFIG.update_config(args)\n\n    # Redirect standard output to a file.\n    if quiet_mode:\n        with open(CONFIG.record_dir + '/log.txt', 'w') as f:\n            with redirect_stdout(f):\n                CommandLine.execute_command_line_process(args)\n    else:\n        CommandLine.execute_command_line_process(args)\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration with command line arguments\n    CONFIG.update_config(args)\n\n    # Redirect standard output to a file if quiet mode is enabled\n    if quiet_mode:\n        with open(os.path.join(CONFIG.record_dir, 'command_line.log'), 'w') as file:\n            with redirect_stdout(file):\n                CommandLine().execute()\n    else:\n        CommandLine().execute()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    if quiet_mode:\n        with open('log.txt', 'w') as f:\n            with redirect_stdout(f):\n                execute_command_line_process(args)\n    else:\n        if args.task == 'train':\n            CommandLine.execute(CommandLineParam.TRAIN, args)\n        elif args.task == 'test':\n            CommandLine.execute(CommandLineParam.TEST, args)\n        elif args.task == 'plan':\n            CommandLine.execute(CommandLineParam.PLAN, args)\n        elif args.task == 'plan-refine':\n            CommandLine.execute(CommandLineParam.PLAN_REFINE, args)\n        elif args.task == 'execute':\n            CommandLine.execute(CommandLineParam.EXECUTE, args)\n        elif args.task == 'execute-plan':\n            CommandLine.execute(CommandLineParam.EXECUTE_PLAN, args)\n        elif args.task == 'execute-plan-refine':\n            CommandLine.execute(CommandLineParam.EXECUTE_PLAN_REFINE, args)\n        elif args.task == 'help':\n            CommandLine.execute(CommandLineParam.HELP, args)\n        else:\n            print('Invalid task.')\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with command line arguments.\n    CONFIG.update(vars(args))\n\n    # If quiet mode is enabled, redirect the standard output to a file.\n    if quiet_mode:\n        with open(os.path.join(CONFIG.record_dir, 'output.log'), 'w') as f:\n            with redirect_stdout(f):\n                CommandLine(args).execute()\n    else:\n        CommandLine(args).execute()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update the global configuration parameters with the provided arguments.\n    CONFIG.update(args)\n\n    # If quiet mode is enabled, redirect the standard output to a file instead of displaying it in the terminal.\n    if quiet_mode:\n        with open(CONFIG.record_dir + '/stdout.log', 'w') as f:\n            with redirect_stdout(f):\n                CommandLine(CommandLineParam(CONFIG.task, CONFIG.upload_files, CONFIG.model, CONFIG.record_dir,\n                                            CONFIG.mode, CONFIG.quiet, CONFIG.max_subtask_chain_length,\n                                            CONFIG.enable_ask_human_for_help, CONFIG.max_plan_refine_chain_length,\n                                            CONFIG.max_plan_tree_depth, CONFIG.max_plan_tree_width,\n                                            CONFIG.max_retry_times, CONFIG.config_file)).run()\n    else:\n        CommandLine(CommandLineParam(CONFIG.task, CONFIG.upload_files, CONFIG.model, CONFIG.record_dir, CONFIG.mode,\n                                    CONFIG.quiet, CONFIG.max_subtask_chain_length, CONFIG.enable_ask_human_for_help,\n                                    CONFIG.max_plan_refine_chain_length, CONFIG.max_plan_tree_depth,\n                                    CONFIG.max_plan_tree_width, CONFIG.max_retry_times, CONFIG.config_file)).run()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    CONFIG.update_config_params(args)\n\n    # Redirect output to a file instead of printing it to the terminal if quiet mode is enabled\n    if quiet_mode:\n        with open(os.path.join(CONFIG.record_dir, 'output.txt'), 'w') as f:\n            with redirect_stdout(f):\n                CommandLine().execute_command_line_process(args)\n    else:\n        CommandLine().execute_command_line_process(args)\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    global CONFIG\n    global ARGS\n\n    ARGS = args\n\n    if quiet_mode:\n        # redirect standard output to a file\n        with open(os.path.join(ARGS.record_dir, 'command_line.log'), 'w') as f:\n            with redirect_stdout(f):\n                CommandLine(args).execute()\n    else:\n        CommandLine(args).execute()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update the configuration parameters with the provided arguments\n    update_config_with_args(args)\n\n    # If quiet mode is enabled, redirect the standard output to a file\n    if quiet_mode:\n        with open(os.path.join(CONFIG.RECORD_DIR, 'output.txt'), 'w') as f:\n            with redirect_stdout(f):\n                CommandLine(args).execute()\n    else:\n        CommandLine(args).execute()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments.\n    CONFIG['task'] = args.task\n    CONFIG['upload_files'] = args.upload_files\n    CONFIG['model'] = args.model\n    CONFIG['record_dir'] = args.record_dir\n    CONFIG['mode'] = args.mode\n    CONFIG['quiet'] = args.quiet\n    CONFIG['max_subtask_chain_length'] = args.max_subtask_chain_length\n    CONFIG['enable_ask_human_for_help'] = args.enable_ask_human_for_help\n    CONFIG['max_plan_refine_chain_length'] = args.max_plan_refine_chain_length\n    CONFIG['max_plan_tree_depth'] = args.max_plan_tree_depth\n    CONFIG['max_plan_tree_width'] = args.max_plan_tree_width\n    CONFIG['max_retry_times'] = args.max_retry_times\n    CONFIG['config_file'] = args.config_file\n\n    # If quiet mode is enabled, redirect the standard output to a file.\n    if quiet_mode:\n        with open(os.path.join(CONFIG['record_dir'], 'output.txt'), 'w') as f:\n            with redirect_stdout(f):\n                CommandLine().execute()\n    else:\n        CommandLine().execute()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    global CONFIG\n    global ARGS\n\n    ARGS = args\n\n    if quiet_mode:\n        with open('log.txt', 'w') as f:\n            with redirect_stdout(f):\n                execute_command_line_process(args)\n    else:\n        if args.task == 'plan':\n            CommandLine.execute_plan(args)\n        elif args.task == 'execute':\n            CommandLine.execute_execute(args)\n        elif args.task == 'plan-and-execute':\n            CommandLine.execute_plan_and_execute(args)\n        elif args.task == 'plan-and-execute-and-refine':\n            CommandLine.execute_plan_and_execute_and_refine(args)\n        elif args.task == 'plan-and-execute-and-refine-and-execute':\n            CommandLine.execute_plan_and_execute_and_refine_and_execute(args)\n        else:\n            raise Exception('Invalid task.')\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with command line arguments\n    CONFIG.task = args.task\n    CONFIG.model = args.model\n    CONFIG.record_dir = args.record_dir\n    CONFIG.mode = args.mode\n    CONFIG.quiet = args.quiet\n    CONFIG.max_subtask_chain_length = args.max_subtask_chain_length\n    CONFIG.enable_ask_human_for_help = args.enable_ask_human_for_help\n    CONFIG.max_plan_refine_chain_length = args.max_plan_refine_chain_length\n    CONFIG.max_plan_tree_depth = args.max_plan_tree_depth\n    CONFIG.max_plan_tree_width = args.max_plan_tree_width\n    CONFIG.max_retry_times = args.max_retry_times\n    CONFIG.config_file = args.config_file\n\n    # If quiet mode is enabled, redirect standard output to a file\n    if CONFIG.quiet:\n        with open(os.devnull, 'w') as devnull:\n            with redirect_stdout(devnull):\n                command_line_process()\n    else:\n        command_line_process()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    if quiet_mode:\n        with open('quiet_mode.log', 'w') as f:\n            with redirect_stdout(f):\n                execute_command_line_process(args, quiet_mode=False)\n    else:\n        # Update global configuration parameters.\n        for key, value in vars(args).items():\n            if value is not None:\n                CONFIG[key] = value\n\n        # Execute the command line process.\n        command_line = CommandLine(args)\n        command_line.execute()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    if quiet_mode:\n        with open(os.path.join(args.record_dir, 'log.txt'), 'w') as f:\n            with redirect_stdout(f):\n                execute_command_line_process(args, quiet_mode=False)\n    else:\n        if args.task == 'train':\n            CommandLine.train(args)\n        elif args.task == 'evaluate':\n            CommandLine.evaluate(args)\n        elif args.task == 'test':\n            CommandLine.test(args)\n        elif args.task == 'generate-dataset':\n            CommandLine.generate_dataset(args)\n        elif args.task == 'generate-dataset-from-file':\n            CommandLine.generate_dataset_from_file(args)\n        elif args.task == 'generate-dataset-from-folder':\n            CommandLine.generate_dataset_from_folder(args)\n        elif args.task == 'generate-dataset-from-webcam':\n            CommandLine.generate_dataset_from_webcam(args)\n        elif args.task == 'generate-dataset-from-video':\n            CommandLine.generate_dataset_from_video(args)\n        elif args.task == 'generate-dataset-from-images':\n            CommandLine.generate_dataset_from_images(args)\n        elif args.task == 'generate-dataset-from-video-frames':\n            CommandLine.generate_dataset_from_video_frames(args)\n        elif args.task == 'generate-dataset-from-video-frames-and-audio':\n            CommandLine.generate_dataset_from_video_frames_and_audio(args)\n        elif args.task == 'generate-dataset-from-video-segments':\n            CommandLine.generate_dataset_from_video_segments(args)\n        elif args.task == 'generate-dataset-from-video-segments-and-audio':\n            CommandLine.generate_dataset_from_video_segments_and_audio(args)\n        elif args.task == 'generate-dataset-from-video-segments-and-audio-and-subtitles':\n            CommandLine.generate"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update the global configuration with the provided arguments.\n    CONFIG.update(args)\n\n    # If quiet mode is enabled, redirect standard output to a file.\n    if quiet_mode:\n        with open(f'{CONFIG.record_dir}/output.txt', 'w') as output_file:\n            with redirect_stdout(output_file):\n                CommandLine().execute_command_line_process()\n    else:\n        CommandLine().execute_command_line_process()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    update_config(args)\n\n    # If quiet mode is enabled, redirect standard output to a file\n    if quiet_mode:\n        redirect_stdout(open(os.path.join(CONFIG.record_dir, 'log.txt'), 'w'))\n\n    # Execute the command line process\n    CommandLine(\n        CommandLineParam(\n            name='init',\n            description='Initialize the task execution environment.',\n            function=lambda: init(args.task, args.upload_files, args.model, args.record_dir, args.mode)\n        ),\n        CommandLineParam(\n            name='plan',\n            description='Generate a plan for executing the task.',\n            function=lambda: plan(args.max_subtask_chain_length, args.max_plan_refine_chain_length,\n                                  args.max_plan_tree_depth, args.max_plan_tree_width)\n        ),\n        CommandLineParam(\n            name='execute',\n            description='Execute the plan for executing the task.',\n            function=lambda: execute(args.max_retry_times, args.enable_ask_human_for_help)\n        ),\n        CommandLineParam(\n            name='cleanup',\n            description='Cleanup the task execution environment.',\n            function=lambda: cleanup()\n        )\n    ).run()\n\n"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_ap"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_ap"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_ap"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_ap"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_ap"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_ap"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_ap"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e.message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e.message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_ap"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e.message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e.message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (time() - self._last_time) > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (time() - self._last_time) > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (time() - self._last_time) > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (time() - self._last_time) > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (time() - self._last_time) > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (time() - self._last_time) > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (time() - self._last_time > self._refetch_interval):\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (time() - self._last_time) > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (time() - self._last_time) > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (time() - self._last_time) > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (time() - self._last_time) > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (time() - self._last_time) > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (time() - self._last_time) > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (time() - self._last_time > self._refetch_interval):\n            self._create_client()\n            self._last_time = time()\n\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (time() - self._last_time) > self._refetch_interval:\n            self._last_time = time()\n            self._create_client()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if not self._client:\n            self._create_client()\n            self._last_time = time()\n        elif time() - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if not self._client:\n            self._create_client()\n        elif self._last_time and (time() - self._last_time) > self._refetch_interval:\n            self._create_client()\n        self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (time() - self._last_time) > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client\n"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (time() - self._last_time) > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client\n"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (time() - self._last_time) > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"`state_dict` should be called from the main process, not the DataLoader worker processes.\")\n\n        if self.cache is None:\n            self.cache = self._create_cache(worker_env=_WorkerEnv.detect())\n\n        state = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path,\n            \"input_url\": self.input_dir.url,\n            \"item_loader_state\": self.cache._item_loader.state_dict(),\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise ValueError(\n                \"The `state_dict` method should be called from the main process, not the DataLoader workers.\"\n            )\n\n        return {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path,\n            \"input_url\": self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"`state_dict` should be called from the main process\")\n\n        state: Dict[str, Any] = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state_dict() if self.item_loader is not None else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The `state_dict` method should be called only from the main process. \"\n                \"To check if the code is running in the main process, use `lit.utilities.env.is_main_process`.\"\n            )\n\n        state: Dict[str, Any] = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state_dict() if self.item_loader is not None else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The state_dict method should be called from the main process. \"\n                \"You should not call it from within the DataLoader worker processes.\"\n            )\n\n        state = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir,\n            \"item_loader_state\": self.cache._item_loader.state_dict() if self.cache._item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The `state_dict` method should be called from the main process. \"\n                \"Do not call it from a DataLoader worker process.\"\n            )\n\n        state: Dict[str, Any] = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"`state_dict` must be called from the main process.\")\n\n        state = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path,\n            \"input_url\": self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state_dict() if self.item_loader is not None else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"`state_dict` should be called from the main process\")\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir,\n            \"item_loader\": self.item_loader,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n\n        if self.shuffle:\n            state_dict[\"shuffler\"] = self.shuffler.state_dict()\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"`state_dict` should be called only from the main process\")\n\n        state_dict: Dict[str, Any] = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state_dict() if self.item_loader is not None else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The `state_dict` method should be called from the main process. \"\n                \"You should not call `state_dict` from a worker process.\"\n            )\n\n        return {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The `state_dict` method must be called from the main process, not from within a DataLoader worker process.\"\n            )\n\n        self._state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path,\n            \"input_url\": self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n        return self._state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"`state_dict` should be called from the main process.\")\n\n        if self.cache is None:\n            self.worker_env = _WorkerEnv.detect()\n            self.cache = self._create_cache(worker_env=self.worker_env)\n            self.shuffler = self._create_shuffler(self.cache)\n\n        state: Dict[str, Any] = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir,\n            \"item_loader_state\": self.cache._item_loader.state_dict(),\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if not _is_in_dataloader_worker():\n            raise ValueError(\n                \"The `state_dict` method should only be called from within a DataLoader worker process.\"\n            )\n\n        state: Dict[str, Any] = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path,\n            \"input_url\": self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state_dict() if self.item_loader is not None else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The `state_dict` method cannot be called from a DataLoader worker process.\")\n\n        state: Dict[str, Any] = {}\n        state[\"num_samples_yielded\"] = num_samples_yielded\n        state[\"num_workers\"] = num_workers\n        state[\"batch_size\"] = batch_size\n        state[\"current_epoch\"] = self.current_epoch\n        state[\"input_dir\"] = self.input_dir.path\n        state[\"input_url\"] = self.input_dir.url\n        state[\"item_loader_state\"] = self.item_loader.state_dict() if self.item_loader else None\n        state[\"drop_last\"] = self.drop_last\n        state[\"seed\"] = self.seed\n        state[\"world_size\"] = self.distributed_env.world_size\n        state[\"shuffle\"] = self.shuffle\n\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise ValueError(\n                \"The `state_dict` method should be called from the main process, not from the DataLoader worker processes.\"\n            )\n\n        # Get the input directory path and URL.\n        input_dir_path = self.input_dir.path\n        input_dir_url = self.input_dir.url\n\n        # Get the item loader state.\n        item_loader_state = None\n        if self.item_loader is not None:\n            item_loader_state = self.item_loader.state_dict()\n\n        # Get the state dict.\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": input_dir_path,\n            \"input_dir_url\": input_dir_url,\n            \"item_loader_state\": item_loader_state,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if not _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The `state_dict` method should be called from a DataLoader worker process. \"\n                \"Please wrap the `DataLoader` in a `torch.utils.data.DataLoader` or `lit_data.DataLoader`.\"\n            )\n\n        return {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir,\n            \"item_loader_state\": self.item_loader.state_dict() if self.item_loader is not None else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The `state_dict` method should not be called from a DataLoader worker process. \"\n                \"Please call it from the main process.\"\n            )\n        self._state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir,\n            \"item_loader_state\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n        return self._state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The `state_dict` method should be called from the main process. \"\n                \"To access the state of the dataset from a DataLoader worker process, use `self.shuffler.state_dict`.\"\n            )\n\n        self._state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir,\n            \"item_loader_state\": self.item_loader.state_dict() if self.item_loader is not None else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n        return self._state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The `state_dict` method must be called from the main process. \"\n                \"Please use the `persist_state` argument to `StreamingDataset` \"\n                \"instead.\"\n            )\n\n        state: Dict[str, Any] = {}\n        state[\"num_samples_yielded\"] = num_samples_yielded\n        state[\"num_workers\"] = num_workers\n        state[\"batch_size\"] = batch_size\n        state[\"current_epoch\"] = self.current_epoch\n        state[\"input_dir\"] = self.input_dir.path\n        state[\"input_url\"] = self.input_dir.url\n        if self.item_loader is not None:\n            state[\"item_loader_state\"] = self.item_loader.state_dict()\n        state[\"drop_last\"] = self.drop_last\n        state[\"seed\"] = self.seed\n        state[\"world_size\"] = self.distributed_env.world_size\n        state[\"shuffle\"] = self.shuffle\n\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The `state_dict` method should be called from the main process, not the DataLoader workers.\"\n            )\n\n        state: Dict[str, Any] = {}\n        state[\"num_samples_yielded\"] = num_samples_yielded\n        state[\"num_workers\"] = num_workers\n        state[\"batch_size\"] = batch_size\n        state[\"current_epoch\"] = self.current_epoch\n        state[\"input_dir_path\"] = self.input_dir.path\n        state[\"input_dir_url\"] = self.input_dir.url\n        state[\"item_loader_state\"] = self.item_loader.state_dict() if self.item_loader is not None else None\n        state[\"drop_last\"] = self.drop_last\n        state[\"seed\"] = self.seed\n        state[\"world_size\"] = self.distributed_env.world_size\n        state[\"shuffle\"] = self.shuffle\n\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._validate_state_dict(state_dict)\n        self._state_dict = state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._validate_state_dict(state_dict)\n\n        self.current_epoch = state_dict[\"current_epoch\"]\n        self.input_dir = Dir(state_dict[\"input_dir_path\"], state_dict[\"input_dir_url\"])\n        self.item_loader = state_dict[\"item_loader\"]\n        self.drop_last = state_dict[\"drop_last\"]\n        self.seed = state_dict[\"seed\"]\n        self.shuffle = state_dict[\"shuffle\"]\n        self.distributed_env.world_size = state_dict[\"world_size\"]\n\n        self._state_dict = state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if not isinstance(state_dict, dict):\n            raise ValueError(f\"The argument `state_dict` has to be a dictionary. Found: {type(state_dict)}\")\n\n        if self._state_dict is not None:\n            raise RuntimeError(\"The state has already been set. This method should be called only once.\")\n\n        self._validate_state_dict(state_dict)\n\n        self._state_dict = state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict\n\n        self._validate_state_dict()\n        state: Dict[str, Any] = self._state_dict\n\n        # Check that the state_dict is for the same dataset\n        if self.input_dir.path != state[\"input_dir_path\"] or self.input_dir.url != state[\"input_dir_url\"]:\n            raise ValueError(\n                f\"The provided state_dict is for a different dataset. \"\n                f\"Expected input_dir_path: {self.input_dir.path}, \"\n                f\"Expected input_dir_url: {self.input_dir.url}, \"\n                f\"Found input_dir_path: {state['input_dir_path']}, \"\n                f\"Found input_dir_url: {state['input_dir_url']}\"\n            )\n\n        # Check that the state_dict is for the same shuffle\n        if self.shuffle != state[\"shuffle\"]:\n            raise ValueError(\n                f\"The provided state_dict is for a different shuffle. \"\n                f\"Expected shuffle: {self.shuffle}, \"\n                f\"Found shuffle: {state['shuffle']}\"\n            )\n\n        # Check that the state_dict is for the same seed\n        if self.seed != state[\"seed\"]:\n            raise ValueError(\n                f\"The provided state_dict is for a different seed. \"\n                f\"Expected seed: {self.seed}, \"\n                f\"Found seed: {state['seed']}\"\n            )\n\n        # Check that the state_dict is for the same drop_last\n        if self.drop_last != state[\"drop_last\"]:\n            raise ValueError(\n                f\"The provided state_dict is for a different drop_last. \"\n                f\"Expected drop_last: {self.drop_last}, \"\n                f\"Found drop_last: {state['drop_last']}\"\n            )\n\n        # Check that the state_dict is for the same number of workers\n        if self.worker_env.world_size != state[\"world_size"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n\n        self._validate_state_dict()\n\n        self._restore_state()\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict\n\n        # Validate the state_dict\n        self._validate_state_dict()\n\n        # Load the state dict\n        self._load_state_dict()\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n        self._validate_state_dict()\n\n        # reload the state\n        self.input_dir = Dir(\n            state_dict[\"input_dir_path\"],\n            state_dict[\"input_dir_url\"],\n        )\n        self.item_loader = state_dict[\"item_loader\"]\n        self.drop_last = state_dict[\"drop_last\"]\n        self.seed = state_dict[\"seed\"]\n        self.shuffle = state_dict[\"shuffle\"]\n        self.current_epoch = state_dict[\"current_epoch\"]\n        self.cache = self._create_cache(worker_env=_WorkerEnv.detect())\n        self.shuffler = self._create_shuffler(self.cache)\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict\n        self._validate_state_dict()\n        self._restore_state()\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        if self._state_dict is not None:\n            raise RuntimeError(\"The state has already been loaded.\")\n\n        self._state_dict = state_dict\n        self._validate_state_dict()\n\n        # Load the state\n        self.current_epoch = state_dict[\"current_epoch\"]\n        self.input_dir = Dir(state_dict[\"input_dir_path\"], state_dict[\"input_dir_url\"])\n        self.item_loader = state_dict[\"item_loader\"]\n        self.drop_last = state_dict[\"drop_last\"]\n        self.seed = state_dict[\"seed\"]\n        self.shuffle = state_dict[\"shuffle\"]\n\n        # Reset the state\n        self.cache = None\n        self.worker_env = None\n        self.worker_chunks = []\n        self.worker_intervals = []\n        self.current_indexes = []\n        self.chunk_index = 0\n        self.global_index = 0\n        self.index = 0\n        self.has_triggered_download = False\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._validate_state_dict(state_dict)\n\n        self._state_dict = state_dict\n\n        self.input_dir.path = state_dict[\"input_dir_path\"]\n        self.input_dir.url = state_dict[\"input_dir_url\"]\n\n        if state_dict[\"item_loader\"] is not None:\n            self.item_loader.load_state_dict(state_dict[\"item_loader\"])\n\n        self.drop_last = state_dict[\"drop_last\"]\n        self.seed = state_dict[\"seed\"]\n        self.shuffle = state_dict[\"shuffle\"]\n        self.current_epoch = state_dict[\"current_epoch\"]\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n\n        self._validate_state_dict()\n\n        state: Dict[str, Any] = self._state_dict\n\n        self.current_epoch = state[\"current_epoch\"]\n        self.input_dir.path = state[\"input_dir_path\"]\n        self.input_dir.url = state[\"input_dir_url\"]\n        self.item_loader = state[\"item_loader\"]\n        self.drop_last = state[\"drop_last\"]\n        self.seed = state[\"seed\"]\n        self.shuffle = state[\"shuffle\"]\n        self.distributed_env.world_size = state[\"world_size\"]\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        # validate the state_dict\n        self._validate_state_dict(state_dict)\n\n        # restore the state\n        self._state_dict = state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict\n\n        self._validate_state_dict()\n\n        self.current_epoch = state_dict[\"current_epoch\"]\n\n        self.input_dir = Dir(\n            path=state_dict[\"input_dir_path\"],\n            url=state_dict[\"input_dir_url\"],\n        )\n\n        if self.item_loader is None:\n            self.item_loader = state_dict[\"item_loader\"]\n        else:\n            self.item_loader.load_state_dict(state_dict[\"item_loader\"])\n\n        self.drop_last = state_dict[\"drop_last\"]\n        self.seed = state_dict[\"seed\"]\n        self.shuffle = state_dict[\"shuffle\"]\n\n        self.distributed_env = _DistributedEnv(state_dict[\"world_size\"])\n\n        self.worker_env = _WorkerEnv(state_dict[\"num_workers\"], state_dict[\"world_size\"])\n\n        self.cache = self._create_cache(self.worker_env)\n        self.shuffler = self._create_shuffler(self.cache)\n\n        chunks_per_replica, intervals_per_replica = self.shuffler.get_chunks_and_intervals_per_ranks(\n            self.distributed_env, self.current_epoch\n        )\n        chunks_replica = chunks_per_replica[self.distributed_env.global_rank % self.distributed_env.world_size]\n        intervals_replica = intervals_per_replica[self.distributed_env.global_rank % self.distributed_env.world_size]\n\n        self.worker_chunks, self.worker_intervals = _associate_chunks_to_workers(\n            self.worker_env.world_size, self.worker_env, chunks_replica, intervals_replica\n        )\n\n        self.num_chunks = len(self.worker_chunks)\n        self.chunk_index = 0\n        self.global_index"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n        self._validate_state_dict()\n\n        state: Dict[str, Any] = self._state_dict\n\n        self.current_epoch = state[\"current_epoch\"]\n        self.input_dir.path = state[\"input_dir_path\"]\n        self.input_dir.url = state[\"input_dir_url\"]\n        self.item_loader = state[\"item_loader\"]\n        self.drop_last = state[\"drop_last\"]\n        self.seed = state[\"seed\"]\n        self.shuffle = state[\"shuffle\"]\n        self.distributed_env.world_size = state[\"world_size\"]\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if self._state_dict is not None:\n            raise RuntimeError(\"The state dict has already been set.\")\n\n        self._state_dict = state_dict\n\n        self._validate_state_dict()\n        state: Dict[str, Any] = self._state_dict\n\n        self.input_dir.path = state[\"input_dir_path\"]\n        self.input_dir.url = state[\"input_dir_url\"]\n        self.cache = self._create_cache(worker_env=_WorkerEnv.detect())\n        self.shuffler = self._create_shuffler(self.cache)\n        self.shuffle = state[\"shuffle\"]\n        self.drop_last = state[\"drop_last\"]\n        self.seed = state[\"seed\"]\n        self.current_epoch = state[\"current_epoch\"]\n        self.item_loader = state[\"item_loader\"]\n        self.num_chunks = state[\"num_chunks\"]\n        self.chunk_index = state[\"chunk_index\"]\n        self.worker_chunks = state[\"worker_chunks\"]\n        self.worker_intervals = state[\"worker_intervals\"]\n        self.current_indexes = state[\"current_indexes\"]\n        self.global_index = state[\"global_index\"]\n        self.index = state[\"index\"]\n        self.has_triggered_download = state[\"has_triggered_download\"]\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        if not isinstance(state_dict, dict):\n            raise TypeError(f\"The argument `state_dict` has to be a dictionary. Found: {type(state_dict)}\")\n\n        if not all([key in state_dict for key in [\"num_samples_yielded\", \"num_workers\", \"batch_size\", \"current_epoch\"]]):\n            raise ValueError(\"The argument `state_dict` has to map the keys `num_samples_yielded`, `num_workers`, `batch_size` and `current_epoch`.\")\n\n        self._state_dict = state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n        self._validate_state_dict()\n        self._resume(\n            state_dict[\"worker_chunks\"],\n            state_dict[\"worker_intervals\"],\n        )\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if self._state_dict is not None:\n            raise RuntimeError(\"The state has already been loaded.\")\n\n        self._validate_state_dict(state_dict)\n\n        self._state_dict = state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        if self._state_dict is not None:\n            raise RuntimeError(\"The StreamingDataset instance already has a state dict.\")\n\n        # Check the state dict type\n        if not isinstance(state_dict, dict):\n            raise TypeError(f\"The state dict should be a dictionary. Found {type(state_dict)}\")\n\n        # Check the state dict keys\n        expected_keys = [\n            \"num_samples_yielded\",\n            \"num_workers\",\n            \"batch_size\",\n            \"current_epoch\",\n            \"input_dir_path\",\n            \"input_dir_url\",\n            \"item_loader\",\n            \"drop_last\",\n            \"seed\",\n            \"world_size\",\n            \"shuffle\",\n        ]\n        for key in state_dict:\n            if key not in expected_keys:\n                raise ValueError(f\"Unexpected key in the state dict. Found {key}\")\n\n        # Check the state dict values\n        for key in expected_keys:\n            if key not in state_dict:\n                raise ValueError(f\"Missing key in the state dict. Expected {key}\")\n\n        # Check the input dir\n        if state_dict[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The input dir of the StreamingDataset instance is different from the one in the state dict. \"\n                f\"Found {self.input_dir.path} and {state_dict['input_dir_path']}.\"\n            )\n        if state_dict[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The input dir url of the StreamingDataset instance is different from the one in the state dict. \"\n                f\"Found {self.input_dir.url} and {state_dict['input_dir_url']}.\"\n            )\n\n        # Check the item loader\n        if state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict\n        self._validate_state_dict()\n\n        if self.cache is not None:\n            self.cache.close()\n        self.cache = None\n\n        # reset index\n        self.chunk_index = 0\n        self.index = 0\n\n        # reset shuffle\n        self.shuffler = None\n\n        # reset cache\n        self.cache = None\n\n        # reset env\n        self.worker_env = None\n\n        # reset chunks\n        self.worker_chunks = []\n        self.worker_intervals = []\n\n        # reset current indexes\n        self.current_indexes = []\n\n        # reset global index\n        self.global_index = 0\n\n        # reset has_triggered_download\n        self.has_triggered_download = False\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        # validate the input state dictionary\n        if not isinstance(self._state_dict, dict):\n            raise ValueError(\"The state dictionary should be a dictionary.\")\n\n        # validate the input state dictionary\n        if not isinstance(self._state_dict, dict):\n            raise ValueError(\"The state dictionary should be a dictionary.\")\n\n        # validate the input state dictionary\n        if not isinstance(self._state_dict, dict):\n            raise ValueError(\"The state dictionary should be a dictionary.\")\n\n        # validate the input state dictionary\n        if not isinstance(self._state_dict, dict):\n            raise ValueError(\"The state dictionary should be a dictionary.\")\n\n        # validate the input state dictionary\n        if not isinstance(self._state_dict, dict):\n            raise ValueError(\"The state dictionary should be a dictionary.\")\n\n        # validate the input state dictionary\n        if not isinstance(self._state_dict, dict):\n            raise ValueError(\"The state dictionary should be a dictionary.\")\n\n        # validate the input state dictionary\n        if not isinstance(self._state_dict, dict):\n            raise ValueError(\"The state dictionary should be a dictionary.\")\n\n        # validate the input state dictionary\n        if not isinstance(self._state_dict, dict):\n            raise ValueError(\"The state dictionary should be a dictionary.\")\n\n        # validate the input state dictionary\n        if not isinstance(self._state_dict, dict):\n            raise ValueError(\"The state dictionary should be a dictionary.\")\n\n        # validate the input state dictionary\n        if not isinstance(self._state_dict, dict):\n            raise ValueError(\"The state dictionary should be a dictionary.\")\n\n        # validate the input state dictionary\n        if not isinstance(self._state_dict, dict):\n            raise ValueError(\"The state dictionary should be a dictionary.\")\n\n        # validate the input state dictionary\n        if not isinstance(self._state_dict, dict):\n            raise ValueError(\"The state dictionary should be a dictionary.\")\n\n        # validate the input state dictionary\n        if not isinstance(self._state_dict, dict):\n            raise ValueError(\"The state dictionary should be a dictionary.\")\n\n        # validate the"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state: Dict[str, Any] = self._state_dict\n        if self.worker_env.rank == 0:\n            if state[\"input_dir_path\"] != self.input_dir.path:\n                raise ValueError(\n                    f\"The input directory path in the state dictionary {state['input_dir_path']} does not match the current input directory path {self.input_dir.path}.\"\n                )\n            if state[\"input_dir_url\"] != self.input_dir.url:\n                raise ValueError(\n                    f\"The input directory URL in the state dictionary {state['input_dir_url']} does not match the current input directory URL {self.input_dir.url}.\"\n                )\n            if state[\"drop_last\"] != self.drop_last:\n                raise ValueError(\n                    f\"The drop_last flag in the state dictionary {state['drop_last']} does not match the current drop_last flag {self.drop_last}.\"\n                )\n            if state[\"shuffle\"] != self.shuffle:\n                raise ValueError(\n                    f\"The shuffle flag in the state dictionary {state['shuffle']} does not match the current shuffle flag {self.shuffle}.\"\n                )\n            if state[\"seed\"] != self.seed:\n                raise ValueError(\n                    f\"The seed in the state dictionary {state['seed']} does not match the current seed {self.seed}.\"\n                )\n            if state[\"world_size\"] != self.distributed_env.world_size:\n                raise ValueError(\n                    f\"The world size in the state dictionary {state['world_size']} does not match the current world size {self.distributed_env.world_size}.\"\n                )\n            if state[\"item_loader\"] != self.item_loader.state_dict() if self.item_loader else None:\n                raise ValueError(\n                    f\"The item loader in the state dictionary {state['item_loader']} does not match the current item loader {self.item_loader.state_dict() if self.item_loader else None}.\"\n                )"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        # Check if the input_dir_path in the state_dict matches the input_dir_path of the dataset.\n        if self._state_dict[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The input_dir_path in the state_dict {self._state_dict['input_dir_path']} does not match the input_dir_path of the dataset {self.input_dir.path}.\"\n            )\n\n        # Check if the input_dir_url in the state_dict matches the input_dir_url of the dataset.\n        if self._state_dict[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The input_dir_url in the state_dict {self._state_dict['input_dir_url']} does not match the input_dir_url of the dataset {self.input_dir.url}.\"\n            )\n\n        # Check if the shuffle in the state_dict matches the shuffle of the dataset.\n        if self._state_dict[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The shuffle in the state_dict {self._state_dict['shuffle']} does not match the shuffle of the dataset {self.shuffle}.\"\n            )\n\n        # Check if the drop_last in the state_dict matches the drop_last of the dataset.\n        if self._state_dict[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                f\"The drop_last in the state_dict {self._state_dict['drop_last']} does not match the drop_last of the dataset {self.drop_last}.\"\n            )\n\n        # Check if the seed in the state_dict matches the seed of the dataset.\n        if self._state_dict[\"seed\"] != self.seed:\n            raise ValueError(\n                f\"The seed in the state_dict {self._state_dict['seed']} does not match the seed of the dataset {self.seed}.\"\n            )\n\n        # Check if the item_loader in the"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state: Dict[str, Any] = self._state_dict\n\n        # check if the input directory path matches\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The input directory path in the state dict {state['input_dir_path']} does not match the current input directory path {self.input_dir.path}.\"\n            )\n\n        # check if the input directory url matches\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The input directory url in the state dict {state['input_dir_url']} does not match the current input directory url {self.input_dir.url}.\"\n            )\n\n        # check if the seed matches\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\n                f\"The seed in the state dict {state['seed']} does not match the current seed {self.seed}.\"\n            )\n\n        # check if the shuffle matches\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The shuffle in the state dict {state['shuffle']} does not match the current shuffle {self.shuffle}.\"\n            )\n\n        # check if the drop_last matches\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                f\"The drop_last in the state dict {state['drop_last']} does not match the current drop_last {self.drop_last}.\"\n            )\n\n        # check if the number of workers matches\n        if state[\"num_workers\"] != self.worker_env.world_size:\n            raise ValueError(\n                f\"The number of workers in the state dict {state['num_workers']} does not match the current number of workers {self.worker_env.world_size}.\"\n            )\n\n        # check if the batch size matches\n        if state[\"batch_size\"] != self.cache.batch_size:\n            raise ValueError(\n                f\"The batch size in the state dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state: Dict[str, Any] = self._state_dict\n\n        if self.worker_env.world_size != state[\"world_size\"]:\n            raise ValueError(\n                f\"The world size of the current dataset {self.worker_env.world_size} does not match the world size of the state {state['world_size']}.\"\n            )\n\n        if self.input_dir.path != state[\"input_dir_path\"]:\n            raise ValueError(\n                f\"The input directory path of the current dataset {self.input_dir.path} does not match the input directory path of the state {state['input_dir_path']}.\"\n            )\n\n        if self.input_dir.url != state[\"input_dir_url\"]:\n            raise ValueError(\n                f\"The input directory url of the current dataset {self.input_dir.url} does not match the input directory url of the state {state['input_dir_url']}.\"\n            )\n\n        if self.drop_last != state[\"drop_last\"]:\n            raise ValueError(\n                f\"The drop_last flag of the current dataset {self.drop_last} does not match the drop_last flag of the state {state['drop_last']}.\"\n            )\n\n        if self.shuffle != state[\"shuffle\"]:\n            raise ValueError(\n                f\"The shuffle flag of the current dataset {self.shuffle} does not match the shuffle flag of the state {state['shuffle']}.\"\n            )\n\n        if self.seed != state[\"seed\"]:\n            raise ValueError(\n                f\"The seed of the current dataset {self.seed} does not match the seed of the state {state['seed']}.\"\n            )\n\n        if self.cache is not None:\n            if self.cache._get_cache_path() != state[\"cache_path\"]:\n                raise ValueError(\n                    f\"The cache path of the current dataset {self.cache._get_cache_path()} does not match the cache path of the state {state['cache_path']}.\"\n                )\n\n        if self.cache is"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state: Dict[str, Any] = self._state_dict\n\n        # validate num_workers\n        if state[\"num_workers\"] != self.worker_env.world_size:\n            raise ValueError(\n                f\"The number of workers in the state_dict ({state['num_workers']}) does not match the current number of workers ({self.worker_env.world_size}).\"\n            )\n\n        # validate batch_size\n        if state[\"batch_size\"] != self.worker_env.batch_size:\n            raise ValueError(\n                f\"The batch size in the state_dict ({state['batch_size']}) does not match the current batch size ({self.worker_env.batch_size}).\"\n            )\n\n        # validate shuffle\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The shuffle in the state_dict ({state['shuffle']}) does not match the current shuffle ({self.shuffle}).\"\n            )\n\n        # validate drop_last\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                f\"The drop_last in the state_dict ({state['drop_last']}) does not match the current drop_last ({self.drop_last}).\"\n            )\n\n        # validate seed\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\n                f\"The seed in the state_dict ({state['seed']}) does not match the current seed ({self.seed}).\"\n            )\n\n        # validate item_loader\n        if state[\"item_loader\"] != self.item_loader.state_dict() if self.item_loader else None:\n            raise ValueError(\n                f\"The item_loader in the state_dict ({state['item_loader']}) does not match the current item_loader ({self.item_loader.state_dict() if self.item_loader else None}).\"\n            )\n\n        # validate input_dir_path\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\""}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict is None:\n            raise ValueError(\"The state dict is None. Please set the state dict first.\")\n\n        state: Dict[str, Any] = self._state_dict\n\n        if self.worker_env.world_size != state[\"world_size\"]:\n            raise ValueError(\n                f\"The world size of the current instance {self.worker_env.world_size} does not match the world size of the state dict {state['world_size']}.\"\n            )\n\n        if self.shuffle != state[\"shuffle\"]:\n            raise ValueError(\n                f\"The shuffle of the current instance {self.shuffle} does not match the shuffle of the state dict {state['shuffle']}.\"\n            )\n\n        if self.drop_last != state[\"drop_last\"]:\n            raise ValueError(\n                f\"The drop_last of the current instance {self.drop_last} does not match the drop_last of the state dict {state['drop_last']}.\"\n            )\n\n        if self.seed != state[\"seed\"]:\n            raise ValueError(\n                f\"The seed of the current instance {self.seed} does not match the seed of the state dict {state['seed']}.\"\n            )\n\n        if self.cache._get_cache_path() != state[\"input_dir_path\"]:\n            raise ValueError(\n                f\"The input_dir_path of the current instance {self.cache._get_cache_path()} does not match the input_dir_path of the state dict {state['input_dir_path']}.\"\n            )\n\n        if self.cache._get_cache_url() != state[\"input_dir_url\"]:\n            raise ValueError(\n                f\"The input_dir_url of the current instance {self.cache._get_cache_url()} does not match the input_dir_url of the state dict {state['input_dir_url']}.\"\n            )\n\n        if self.item_loader is not None and state[\"item_loader\"] is not None:\n            if self.item_loader.state_dict() != state[\""}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state: Dict[str, Any] = self._state_dict\n\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The input directory path {state['input_dir_path']} does not match the current input directory path {self.input_dir.path}.\"\n            )\n\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The input directory URL {state['input_dir_url']} does not match the current input directory URL {self.input_dir.url}.\"\n            )\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The shuffle value {state['shuffle']} does not match the current shuffle value {self.shuffle}.\"\n            )\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                f\"The drop_last value {state['drop_last']} does not match the current drop_last value {self.drop_last}.\"\n            )\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(f\"The seed {state['seed']} does not match the current seed {self.seed}.\")\n\n        if state[\"world_size\"] != self.distributed_env.world_size:\n            raise ValueError(\n                f\"The world size {state['world_size']} does not match the current world size {self.distributed_env.world_size}.\"\n            )\n\n        if state[\"item_loader\"] != self.item_loader.state_dict():\n            raise ValueError(\"The item loader state does not match the current item loader state.\")\n\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict is None:\n            raise ValueError(\"The state dictionary is None.\")\n\n        if self.worker_env is None:\n            raise ValueError(\"The worker environment is None.\")\n\n        if self.cache is None:\n            raise ValueError(\"The cache is None.\")\n\n        if self.shuffle is None:\n            raise ValueError(\"The shuffle flag is None.\")\n\n        state: Dict[str, Any] = self._state_dict\n\n        if self.cache._get_chunk_index_from_index(state[\"num_samples_yielded\"]) != state[\"current_chunk_index\"]:\n            raise ValueError(\n                f\"The current chunk index {state['current_chunk_index']} in the state dictionary does not match the current chunk index {self.cache._get_chunk_index_from_index(state['num_samples_yielded'])} in the StreamingDataset instance.\"\n            )\n\n        if self.worker_env.global_rank != state[\"global_rank\"]:\n            raise ValueError(\n                f\"The global rank {state['global_rank']} in the state dictionary does not match the current global rank {self.worker_env.global_rank} in the StreamingDataset instance.\"\n            )\n\n        if self.worker_env.world_size != state[\"world_size\"]:\n            raise ValueError(\n                f\"The world size {state['world_size']} in the state dictionary does not match the current world size {self.worker_env.world_size} in the StreamingDataset instance.\"\n            )\n\n        if self.cache.input_dir.path != state[\"input_dir_path\"]:\n            raise ValueError(\n                f\"The input directory path {state['input_dir_path']} in the state dictionary does not match the current input directory path {self.cache.input_dir.path} in the StreamingDataset instance.\"\n            )\n\n        if self.cache.input_dir.url != state[\"input_dir_url\"]:\n            raise ValueError(\n                f\"The input directory URL {state['input_dir_url']} in"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state: Dict[str, Any] = self._state_dict\n\n        # check if the state dict is consistent with the current state of the dataset\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The shuffle state of the dataset does not match the state of the dataset. \"\n                f\"Dataset shuffle: {self.shuffle}, State: {state['shuffle']}\"\n            )\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                f\"The drop_last state of the dataset does not match the state of the dataset. \"\n                f\"Dataset drop_last: {self.drop_last}, State: {state['drop_last']}\"\n            )\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\n                f\"The seed of the dataset does not match the state of the dataset. \"\n                f\"Dataset seed: {self.seed}, State: {state['seed']}\"\n            )\n\n        if state[\"num_workers\"] != self.worker_env.world_size:\n            raise ValueError(\n                f\"The num_workers of the dataset does not match the state of the dataset. \"\n                f\"Dataset num_workers: {self.worker_env.world_size}, State: {state['num_workers']}\"\n            )\n\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The input_dir_path of the dataset does not match the state of the dataset. \"\n                f\"Dataset input_dir_path: {self.input_dir.path}, State: {state['input_dir_path']}\"\n            )\n\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The input_dir_url of the dataset does not match the state of the dataset. \"\n                f\"Dataset input_dir_url: {self.input_dir.url}, State: {state['input_dir_url']}\"\n            )"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state: Dict[str, Any] = self._state_dict\n\n        if self.worker_env is not None:\n            if self.worker_env.world_size != state[\"world_size\"]:\n                raise ValueError(\n                    f\"The state dict was created with a different number of workers. \"\n                    f\"The current number of workers is {self.worker_env.world_size} but the state dict \"\n                    f\"has {state['world_size']} workers.\"\n                )\n\n        if self.cache is not None:\n            if self.cache._get_cache_path() != state[\"input_dir_path\"]:\n                raise ValueError(\n                    f\"The state dict was created with a different input directory. \"\n                    f\"The current input directory is {self.cache._get_cache_path()} but the state dict \"\n                    f\"has {state['input_dir_path']}.\"\n                )\n\n            if self.cache._get_cache_url() != state[\"input_dir_url\"]:\n                raise ValueError(\n                    f\"The state dict was created with a different input directory URL. \"\n                    f\"The current input directory URL is {self.cache._get_cache_url()} but the state dict \"\n                    f\"has {state['input_dir_url']}.\"\n                )\n\n        if self.shuffle != state[\"shuffle\"]:\n            raise ValueError(\n                f\"The state dict was created with a different shuffle option. \"\n                f\"The current shuffle option is {self.shuffle} but the state dict \"\n                f\"has {state['shuffle']}.\"\n            )\n\n        if self.drop_last != state[\"drop_last\"]:\n            raise ValueError(\n                f\"The state dict was created with a different drop_last option. \"\n                f\"The current drop_last option is {self.drop_last} but the state dict \"\n                f\"has {state['drop_last']}.\"\n            )\n\n        if self.seed != state[\"seed\"]:\n            raise ValueError(\n                f\"The state dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state: Dict[str, Any] = self._state_dict\n        if state is None:\n            raise ValueError(\"The state dict has not been set.\")\n\n        if self.worker_env.world_size != state[\"world_size\"]:\n            raise ValueError(\n                f\"The number of workers in the previous run was {state['world_size']} and the current run is {self.worker_env.world_size}.\"\n            )\n\n        if self.cache is None:\n            raise ValueError(\"The cache has not been created.\")\n\n        if self.cache._get_chunk_index_from_index(0) != state[\"chunk_index\"]:\n            raise ValueError(\n                f\"The first chunk index in the previous run was {state['chunk_index']} and the current run is {self.cache._get_chunk_index_from_index(0)}.\"\n            )\n\n        if self.cache.input_dir.path != state[\"input_dir_path\"]:\n            raise ValueError(\n                f\"The input directory path in the previous run was {state['input_dir_path']} and the current run is {self.cache.input_dir.path}.\"\n            )\n\n        if self.cache.input_dir.url != state[\"input_dir_url\"]:\n            raise ValueError(\n                f\"The input directory url in the previous run was {state['input_dir_url']} and the current run is {self.cache.input_dir.url}.\"\n            )\n\n        if self.shuffle != state[\"shuffle\"]:\n            raise ValueError(\n                f\"The shuffle in the previous run was {state['shuffle']} and the current run is {self.shuffle}.\"\n            )\n\n        if self.drop_last != state[\"drop_last\"]:\n            raise ValueError(\n                f\"The drop_last in the previous run was {state['drop_last']} and the current run is {self.drop_last}.\"\n            )\n\n        if self.seed != state[\"seed\"]:\n            raise ValueError(f\"The seed in the previous run was {state"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state: Dict[str, Any] = self._state_dict\n\n        if self.input_dir.path != state[\"input_dir_path\"]:\n            raise ValueError(\n                f\"The input directory path of the dataset has changed from `{state['input_dir_path']}` to `{self.input_dir.path}`.\"\n            )\n        if self.input_dir.url != state[\"input_dir_url\"]:\n            raise ValueError(\n                f\"The input directory URL of the dataset has changed from `{state['input_dir_url']}` to `{self.input_dir.url}`.\"\n            )\n        if self.item_loader.state_dict() != state[\"item_loader\"]:\n            raise ValueError(\"The item loader has changed.\")\n        if self.drop_last != state[\"drop_last\"]:\n            raise ValueError(f\"The drop last flag has changed from `{state['drop_last']}` to `{self.drop_last}`\")\n        if self.shuffle != state[\"shuffle\"]:\n            raise ValueError(f\"The shuffle flag has changed from `{state['shuffle']}` to `{self.shuffle}`\")\n        if self.seed != state[\"seed\"]:\n            raise ValueError(f\"The seed has changed from `{state['seed']}` to `{self.seed}`\")\n        if self.distributed_env.world_size != state[\"world_size\"]:\n            raise ValueError(\n                f\"The world size has changed from `{state['world_size']}` to `{self.distributed_env.world_size}`.\"\n            )\n\n        # TODO: Implement elastic sampling where the number of workers can change.\n        if self.worker_env.world_size != state[\"num_workers\"]:\n            raise ValueError(\n                f\"The number of workers has changed from `{state['num_workers']}` to `{self.worker_env.world_size}`.\"\n            )\n        if self.current_epoch != state[\"current_epoch\"]:\n            raise ValueError(\n                f\"The current epoch has changed from `{state['current_epoch']}` to `{"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict is None:\n            raise ValueError(\"The state_dict is not set. Please use the `load_state_dict` method to load the state dict before validating.\")\n\n        if self.worker_env is None:\n            raise ValueError(\"The worker_env is not set. Please use the `load_state_dict` method to load the state dict before validating.\")\n\n        if self.cache is None:\n            raise ValueError(\"The cache is not set. Please use the `load_state_dict` method to load the state dict before validating.\")\n\n        if self.shuffle is None:\n            raise ValueError(\"The shuffle is not set. Please use the `load_state_dict` method to load the state dict before validating.\")\n\n        if self._state_dict[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The input_dir_path from the state dict {self._state_dict['input_dir_path']} does not match the current input_dir_path {self.input_dir.path}.\"\n            )\n\n        if self._state_dict[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The input_dir_url from the state dict {self._state_dict['input_dir_url']} does not match the current input_dir_url {self.input_dir.url}.\"\n            )\n\n        if self._state_dict[\"seed\"] != self.seed:\n            raise ValueError(\n                f\"The seed from the state dict {self._state_dict['seed']} does not match the current seed {self.seed}.\"\n            )\n\n        if self._state_dict[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The shuffle from the state dict {self._state_dict['shuffle']} does not match the current shuffle {self.shuffle}.\"\n            )\n\n        if self._state_dict[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                f\"The drop_last from"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict is None:\n            raise ValueError(\"The state_dict is None. Please call `load_state_dict` to load the state_dict before validating.\")\n\n        state: Dict[str, Any] = self._state_dict\n        if self.worker_env is not None and self.worker_env.global_rank != state[\"global_rank\"]:\n            raise ValueError(\n                f\"The global rank of the state_dict {state['global_rank']} does not match the current global rank {self.worker_env.global_rank} of the StreamingDataset instance.\"\n            )\n\n        if self.cache is not None and self.cache.input_dir.path != state[\"input_dir_path\"]:\n            raise ValueError(\n                f\"The input directory path of the state_dict {state['input_dir_path']} does not match the current input directory path {self.cache.input_dir.path} of the StreamingDataset instance.\"\n            )\n\n        if self.cache is not None and self.cache.input_dir.url != state[\"input_dir_url\"]:\n            raise ValueError(\n                f\"The input directory URL of the state_dict {state['input_dir_url']} does not match the current input directory URL {self.cache.input_dir.url} of the StreamingDataset instance.\"\n            )\n\n        if self.shuffle != state[\"shuffle\"]:\n            raise ValueError(\n                f\"The shuffle of the state_dict {state['shuffle']} does not match the current shuffle {self.shuffle} of the StreamingDataset instance.\"\n            )\n\n        if self.drop_last != state[\"drop_last\"]:\n            raise ValueError(\n                f\"The drop_last of the state_dict {state['drop_last']} does not match the current drop_last {self.drop_last} of the StreamingDataset instance.\"\n            )\n\n        if self.seed != state[\"seed\"]:\n            raise ValueError(\n                f\"The seed of the state_dict {state['seed']} does not match the current seed {"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state: Dict[str, Any] = self._state_dict\n\n        # Check if the state_dict is valid for the current instance.\n        if self.worker_env.world_size != state[\"world_size\"]:\n            raise ValueError(\n                f\"The state_dict is not valid for the current instance. The state_dict was created for a dataset with world_size {state['world_size']} but the current instance has world_size {self.worker_env.world_size}.\"\n            )\n\n        if self.shuffle != state[\"shuffle\"]:\n            raise ValueError(\n                f\"The state_dict is not valid for the current instance. The state_dict was created for a dataset with shuffle {state['shuffle']} but the current instance has shuffle {self.shuffle}.\"\n            )\n\n        if self.drop_last != state[\"drop_last\"]:\n            raise ValueError(\n                f\"The state_dict is not valid for the current instance. The state_dict was created for a dataset with drop_last {state['drop_last']} but the current instance has drop_last {self.drop_last}.\"\n            )\n\n        if self.seed != state[\"seed\"]:\n            raise ValueError(\n                f\"The state_dict is not valid for the current instance. The state_dict was created for a dataset with seed {state['seed']} but the current instance has seed {self.seed}.\"\n            )\n\n        if self.cache is None:\n            raise ValueError(\n                f\"The state_dict is not valid for the current instance. The state_dict was created for a dataset with cache {state['cache']} but the current instance has cache {self.cache}.\"\n            )\n\n        if self.cache._get_cache_path() != state[\"input_dir_path\"]:\n            raise ValueError(\n                f\"The state_dict is not valid for the current instance. The state_dict was created for a dataset with input_dir_path {state['input_dir_path']} but the current instance has input_dir_path {self.cache._get_cache_path()}.\"\n            )"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self.cache is None:\n            raise RuntimeError(\"The cache has not been created yet. Please call __iter__() before calling load_state_dict().\")\n\n        if self.shuffle != self._state_dict[\"shuffle\"]:\n            raise ValueError(\n                f\"The shuffle parameter of the state dictionary does not match the current state of the StreamingDataset instance. \"\n                f\"State dictionary: {self._state_dict['shuffle']}, Current state: {self.shuffle}.\"\n            )\n\n        if self.drop_last != self._state_dict[\"drop_last\"]:\n            raise ValueError(\n                f\"The drop_last parameter of the state dictionary does not match the current state of the StreamingDataset instance. \"\n                f\"State dictionary: {self._state_dict['drop_last']}, Current state: {self.drop_last}.\"\n            )\n\n        if self.worker_env.global_rank != self._state_dict[\"world_size\"]:\n            raise ValueError(\n                f\"The world_size parameter of the state dictionary does not match the current state of the StreamingDataset instance. \"\n                f\"State dictionary: {self._state_dict['world_size']}, Current state: {self.worker_env.global_rank}.\"\n            )\n\n        if self.distributed_env.global_rank != self._state_dict[\"world_size\"]:\n            raise ValueError(\n                f\"The world_size parameter of the state dictionary does not match the current state of the StreamingDataset instance. \"\n                f\"State dictionary: {self._state_dict['world_size']}, Current state: {self.distributed_env.global_rank}.\"\n            )\n\n        if self.cache.input_dir.path != self._state_dict[\"input_dir_path\"]:\n            raise ValueError(\n                f\"The input_dir_path parameter of the state dictionary does not match the current state of the StreamingDataset instance. \"\n                f\"State dictionary: {self._state_dict['input_dir_path']}, Current state: {self.cache.input_dir."}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict is None:\n            raise ValueError(\"The state dict is None\")\n\n        state: Dict[str, Any] = self._state_dict\n        num_workers = state[\"num_workers\"]\n        batch_size = state[\"batch_size\"]\n\n        # Validate the state dictionary\n        if self.worker_env.world_size != state[\"world_size\"]:\n            raise ValueError(\n                f\"The world size has changed from {state['world_size']} to {self.worker_env.world_size}.\"\n            )\n\n        if self.cache is None:\n            raise ValueError(\"The cache is not initialized\")\n\n        if self.cache._get_cache_path() != state[\"input_dir_path\"]:\n            raise ValueError(\n                f\"The input directory has changed from {state['input_dir_path']} to {self.cache._get_cache_path()}.\"\n            )\n\n        if self.cache._get_cache_url() != state[\"input_dir_url\"]:\n            raise ValueError(\n                f\"The input directory url has changed from {state['input_dir_url']} to {self.cache._get_cache_url()}.\"\n            )\n\n        if self.shuffle != state[\"shuffle\"]:\n            raise ValueError(f\"The shuffle flag has changed from {state['shuffle']} to {self.shuffle}.\")\n\n        if self.drop_last != state[\"drop_last\"]:\n            raise ValueError(f\"The drop_last flag has changed from {state['drop_last']} to {self.drop_last}.\")\n\n        if self.seed != state[\"seed\"]:\n            raise ValueError(f\"The seed has changed from {state['seed']} to {self.seed}.\")\n\n        if self.cache._get_chunk_index_from_index(0) != state[\"current_epoch\"]:\n            raise ValueError(\n                f\"The current epoch has changed from {state['current_epoch']} to {self.cache._get_chunk_index_from_index(0)}.\""}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict is None:\n            raise ValueError(\"The state dictionary is None.\")\n\n        if self.worker_env is None:\n            raise ValueError(\"The worker environment is None.\")\n\n        if self.cache is None:\n            raise ValueError(\"The cache is None.\")\n\n        if self.shuffle is None:\n            raise ValueError(\"The shuffle flag is None.\")\n\n        if self.drop_last is None:\n            raise ValueError(\"The drop_last flag is None.\")\n\n        if self.seed is None:\n            raise ValueError(\"The seed is None.\")\n\n        if self.item_loader is None:\n            raise ValueError(\"The item_loader is None.\")\n\n        if self.cache._get_chunk_index_from_index(0) is None:\n            raise ValueError(\"The chunk index is None.\")\n\n        state: Dict[str, Any] = self._state_dict\n\n        # validate the input directory\n        if self.input_dir.path != state[\"input_dir_path\"]:\n            raise ValueError(\n                f\"The input directory path in the state dict does not match the current state. \"\n                f\"State dict: {state['input_dir_path']}, current state: {self.input_dir.path}\"\n            )\n\n        if self.input_dir.url != state[\"input_dir_url\"]:\n            raise ValueError(\n                f\"The input directory url in the state dict does not match the current state. \"\n                f\"State dict: {state['input_dir_url']}, current state: {self.input_dir.url}\"\n            )\n\n        # validate the shuffle flag\n        if self.shuffle != state[\"shuffle\"]:\n            raise ValueError(\n                f\"The shuffle flag in the state dict does not match the current state. \"\n                f\"State dict: {state['shuffle']}, current state: {self.shuffle}\"\n            )\n\n        # validate the drop_last flag\n        if self.drop_last != state[\"drop_last\"]:\n            raise ValueError(\n                f\"The drop_last flag in"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state = self._state_dict\n\n        if self.shuffle != state[\"shuffle\"]:\n            raise ValueError(\n                f\"The shuffle parameter of the dataset has changed from {state['shuffle']} to {self.shuffle} since the last checkpoint.\"\n            )\n\n        if self.distributed_env.world_size != state[\"world_size\"]:\n            raise ValueError(\n                f\"The world size has changed from {state['world_size']} to {self.distributed_env.world_size} since the last checkpoint.\"\n            )\n\n        if self.drop_last != state[\"drop_last\"]:\n            raise ValueError(\n                f\"The drop_last parameter of the dataset has changed from {state['drop_last']} to {self.drop_last} since the last checkpoint.\"\n            )\n\n        if self.cache is None:\n            raise ValueError(\n                \"The cache is not created yet. Please call the StreamingDataset instance at least once before calling the state_dict function.\"\n            )\n\n        if self.cache._get_config_hash() != state[\"cache_config_hash\"]:\n            raise ValueError(\n                \"The cache config has changed since the last checkpoint. Please re-optimize the dataset.\"\n            )\n\n        if self.cache._get_config_hash() != state[\"cache_config_hash\"]:\n            raise ValueError(\n                \"The cache config has changed since the last checkpoint. Please re-optimize the dataset.\"\n            )\n\n        if self.cache._get_state_hash() != state[\"cache_state_hash\"]:\n            raise ValueError(\"The cache state has changed since the last checkpoint.\")\n\n        if self.cache._get_index_hash() != state[\"cache_index_hash\"]:\n            raise ValueError(\"The index state has changed since the last checkpoint.\")\n\n        if self.cache._get_index_dir() != state[\"cache_index_dir\"]:\n            raise ValueError(\"The index directory has changed since the last checkpoint.\")\n\n        if self.cache._get_cache_dir() != state[\"cache_cache_"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.md5(input_dir.encode(\"utf-8\")).hexdigest())\n    if not os.path.exists(cache_dir):\n        try:\n            os.makedirs(cache_dir)\n        except Exception:\n            return None\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Hash the input directory\n    hash_object = hashlib.md5(input_dir.encode())\n    cache_dir_name = hash_object.hexdigest()\n\n    # Create the cache directory\n    if os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\") is not None:\n        cache_dir_path = os.path.join(os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"), cache_dir_name)\n    else:\n        cache_dir_path = os.path.join(_DEFAULT_CACHE_DIR, cache_dir_name)\n\n    try:\n        os.makedirs(cache_dir_path, exist_ok=True)\n    except:\n        cache_dir_path = None\n\n    return cache_dir_path\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Hash the input directory\n    cache_dir_name = hashlib.md5(input_dir.encode(\"utf-8\")).hexdigest()\n    cache_dir_path = os.path.join(_DEFAULT_CACHE_DIR, cache_dir_name)\n\n    # Create the cache directory\n    if not os.path.exists(cache_dir_path):\n        os.makedirs(cache_dir_path)\n\n    return cache_dir_path\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Hash the input directory to generate a unique cache directory name\n    cache_dir_name = hashlib.sha256(input_dir.encode(\"utf-8\")).hexdigest()\n\n    # Create the cache directory\n    if os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"):\n        cache_dir = os.path.join(os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"), cache_dir_name)\n    else:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, cache_dir_name)\n    os.makedirs(cache_dir, exist_ok=True)\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.md5(input_dir.encode(\"utf-8\")).hexdigest())\n\n    if not os.path.exists(cache_dir):\n        try:\n            os.makedirs(cache_dir, exist_ok=True)\n        except (OSError, IOError):\n            return None\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Hash the input directory and use it for creating a unique cache directory\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.md5(input_dir.encode()).hexdigest())\n\n    # Create the cache directory if it doesn't exist\n    if not os.path.exists(cache_dir):\n        try:\n            os.makedirs(cache_dir)\n        except:\n            return None\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Hash the input directory to generate a unique directory name\n    hash_input_dir = hashlib.md5(input_dir.encode()).hexdigest()\n    cache_dir = f\"{_DEFAULT_CACHE_DIR}/{hash_input_dir}\"\n\n    # Create the cache directory\n    if not os.path.exists(cache_dir):\n        os.makedirs(cache_dir)\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    if _DEFAULT_CACHE_DIR is None:\n        raise RuntimeError(\"The environment variable `LIGHTNING_DATA_CACHE_DIR` is not set.\")\n\n    # Generate a unique directory name based on the input directory.\n    cache_dir_name = hashlib.sha256(input_dir.encode(\"utf-8\")).hexdigest()\n    cache_dir_path = os.path.join(_DEFAULT_CACHE_DIR, cache_dir_name)\n\n    # Create the cache directory.\n    if not os.path.exists(cache_dir_path):\n        os.makedirs(cache_dir_path)\n\n    return cache_dir_path\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    # Create the cache directory based on the input directory\n    if input_dir is not None:\n        # Hash the input directory\n        input_dir_hash = hashlib.md5(input_dir.encode(\"utf-8\")).hexdigest()\n\n        # Create the cache directory\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, input_dir_hash)\n        if not os.path.exists(cache_dir):\n            os.makedirs(cache_dir)\n\n        return cache_dir\n\n    return None\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Create a unique directory name from the input directory path.\n    hash_name = hashlib.sha1(input_dir.encode(\"utf-8\")).hexdigest()[:10]\n    cache_dir = f\"{_DEFAULT_CACHE_DIR}/{hash_name}\"\n\n    # Create the cache directory.\n    if not os.path.exists(cache_dir):\n        os.makedirs(cache_dir)\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.md5(input_dir.encode(\"utf-8\")).hexdigest())\n    if not os.path.exists(cache_dir):\n        try:\n            os.makedirs(cache_dir)\n            logger.info(f\"Created cache directory at {cache_dir}\")\n        except Exception as e:\n            logger.warning(f\"Couldn't create cache directory at {cache_dir}. {e}\")\n            return None\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Hash the input directory path to generate a unique cache directory name.\n    hash_obj = hashlib.sha1(input_dir.encode())\n    hash_str = hash_obj.hexdigest()\n\n    # Create the cache directory.\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hash_str)\n    if not os.path.exists(cache_dir):\n        os.makedirs(cache_dir)\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Hash the input directory\n    cache_dir_name = hashlib.md5(input_dir.encode()).hexdigest()\n    # Create the cache directory\n    if os.getenv(\"LITHOPS_CACHE_DIR\"):\n        cache_dir = os.path.join(os.getenv(\"LITHOPS_CACHE_DIR\"), cache_dir_name)\n    else:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, cache_dir_name)\n    try:\n        os.makedirs(cache_dir, exist_ok=True)\n    except OSError:\n        return None\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Generate a unique directory name based on the input directory\n    input_dir_hash = hashlib.sha256(input_dir.encode(\"utf-8\")).hexdigest()\n\n    # If the environment variable is set, create the cache directory in the specified location\n    if os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"):\n        cache_dir = os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\")\n        cache_dir = os.path.join(cache_dir, input_dir_hash)\n        os.makedirs(cache_dir, exist_ok=True)\n        return cache_dir\n\n    # Otherwise, create the cache directory in the default location\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, input_dir_hash)\n    os.makedirs(cache_dir, exist_ok=True)\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    # Hash the input directory to create a unique cache directory.\n    if input_dir is None:\n        input_dir = \"\"\n    cache_dir_name = hashlib.sha1(input_dir.encode()).hexdigest()\n\n    # Create the cache directory.\n    if os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"):\n        cache_dir = os.path.join(os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"), cache_dir_name)\n    else:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, cache_dir_name)\n    if not os.path.exists(cache_dir):\n        try:\n            os.makedirs(cache_dir)\n        except Exception as e:\n            logger.warning(f\"Could not create the cache directory {cache_dir}. Reason: {e}\")\n            return None\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Hash the input directory\n    input_dir_hash = hashlib.md5(input_dir.encode(\"utf-8\")).hexdigest()\n\n    # Get the cache directory\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, input_dir_hash)\n\n    # Create the cache directory\n    if not os.path.exists(cache_dir):\n        try:\n            os.makedirs(cache_dir)\n        except Exception as e:\n            logger.warning(\n                f\"Cannot create the cache directory at {cache_dir} due to the following exception: {e}. \"\n                \"The dataset will be loaded from the original directory.\"\n            )\n            return None\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Hash the input directory to create a unique directory name\n    hash_name = hashlib.sha256(input_dir.encode(\"utf-8\")).hexdigest()\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hash_name)\n\n    # Create the cache directory\n    if not os.path.exists(cache_dir):\n        try:\n            os.makedirs(cache_dir)\n        except Exception as e:\n            logger.warning(\n                f\"Could not create the cache directory at {cache_dir}. \"\n                f\"Please check if you have the required permissions. \"\n                f\"Exception: {e}\"\n            )\n            return None\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Hash the input directory to create a unique cache directory name\n    cache_dir_name = hashlib.md5(input_dir.encode(\"utf-8\")).hexdigest()\n    cache_dir_path = os.path.join(_DEFAULT_CACHE_DIR, cache_dir_name)\n\n    # Create the cache directory if it doesn't exist\n    if not os.path.exists(cache_dir_path):\n        try:\n            os.makedirs(cache_dir_path)\n        except OSError:\n            logger.warn(\n                f\"The cache directory '{cache_dir_path}' cannot be created. \"\n                \"Please check if you have the permission to create a directory in the default cache directory.\"\n            )\n            return None\n\n    return cache_dir_path\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    input_dir_hash = hashlib.md5(input_dir.encode(\"utf-8\")).hexdigest()\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, input_dir_hash)\n\n    if os.path.isdir(cache_dir):\n        return cache_dir\n\n    if os.environ.get(\"LIT_OPTIMIZER_CACHE_DIR\") is not None:\n        cache_dir = os.path.join(os.environ[\"LIT_OPTIMIZER_CACHE_DIR\"], input_dir_hash)\n\n    try:\n        os.makedirs(cache_dir, exist_ok=True)\n    except OSError:\n        logger.warn(\n            f\"The cache directory '{cache_dir}' cannot be created. \"\n            \"Please ensure that the directory does not exist and that you have the necessary permissions.\"\n        )\n        return None\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    # Create a unique cache directory based on the input directory\n    if input_dir is None:\n        input_dir = \"\"\n    cache_dir_name = hashlib.md5(input_dir.encode(\"utf-8\")).hexdigest()\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, cache_dir_name)\n\n    # Create the cache directory if it doesn't exist\n    if not os.path.exists(cache_dir):\n        try:\n            os.makedirs(cache_dir)\n        except Exception as e:\n            logger.warning(\n                f\"Failed to create cache directory at {cache_dir}. The cache directory will not be used. \"\n                \"Please check the permissions and availability of the parent directory. \"\n                f\"Exception: {e}\"\n            )\n            cache_dir = None\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(\n                \"The remote file path must use the 's3' scheme. The given path uses the {} scheme.\".format(\n                    parsed_url.scheme\n                )\n            )\n\n        if os.path.exists(local_filepath):\n            return\n\n        lock_filepath = local_filepath + \".lock\"\n        lock = FileLock(lock_filepath)\n\n        try:\n            with lock.acquire(timeout=10):\n                if os.path.exists(local_filepath):\n                    return\n\n                if self._s5cmd_available:\n                    self._download_file_with_s5cmd(remote_filepath, local_filepath)\n                else:\n                    self._download_file_with_boto3(remote_filepath, local_filepath)\n        except Timeout:\n            raise Timeout(\n                \"The file lock could not be acquired within the specified timeout.\"\n            )\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if not remote_filepath.startswith(\"s3://\"):\n            raise ValueError(\"The remote file path must be an S3 URL.\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        parsed_url = parse.urlparse(remote_filepath)\n        scheme = parsed_url.scheme\n        bucket = parsed_url.netloc\n        key = parsed_url.path[1:]\n\n        if self._s5cmd_available:\n            self._download_file_with_s5cmd(scheme, bucket, key, local_filepath)\n        else:\n            self._download_file_with_boto3(scheme, bucket, key, local_filepath)\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(\"The remote file path must use the 's3' scheme\")\n\n        if os.path.isfile(local_filepath):\n            return\n\n        lock = FileLock(local_filepath + \".lock\")\n        try:\n            with lock.acquire(timeout=10):\n                if os.path.isfile(local_filepath):\n                    return\n                if self._s5cmd_available:\n                    self._download_file_with_s5cmd(remote_filepath, local_filepath)\n                else:\n                    self._download_file_with_boto3(remote_filepath, local_filepath)\n        except Timeout:\n            raise Timeout(\n                f\"Unable to acquire lock for file {local_filepath}. It is likely that another process is currently downloading the file.\"\n            )\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        # Check if the remote file path is an S3 URL\n        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(f\"The remote file path must use the s3 scheme. The given file path is {remote_filepath}\")\n\n        # Check if the local file already exists\n        if os.path.exists(local_filepath):\n            return\n\n        # Create the local file path if it does not exist\n        local_filepath_dir = os.path.dirname(local_filepath)\n        if not os.path.exists(local_filepath_dir):\n            os.makedirs(local_filepath_dir)\n\n        # Download the file using s5cmd if available\n        if self._s5cmd_available:\n            self._download_file_with_s5cmd(remote_filepath, local_filepath)\n            return\n\n        # Download the file using boto3\n        self._download_file_with_boto3(remote_filepath, local_filepath)\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(f\"Expected URL with scheme 's3', got '{parsed_url.scheme}'\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        with FileLock(local_filepath + \".lock\", timeout=120):\n            if not os.path.exists(local_filepath):\n                if self._s5cmd_available:\n                    subprocess.run(\n                        [\n                            \"s5cmd\",\n                            \"cp\",\n                            remote_filepath,\n                            local_filepath,\n                            \"--no-encrypt\",\n                            \"--no-sign-request\",\n                        ],\n                        check=True,\n                    )\n                else:\n                    self._client.download_file(\n                        parsed_url.netloc, parsed_url.path, local_filepath\n                    )\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if not remote_filepath.startswith(\"s3://\"):\n            raise ValueError(\"The remote file path must use the 's3' scheme.\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        parsed_url = parse.urlparse(remote_filepath)\n        scheme = parsed_url.scheme\n        netloc = parsed_url.netloc\n        path = parsed_url.path\n        remote_filepath = f\"{scheme}://{netloc}{path}\"\n\n        lock_filepath = local_filepath + \".lock\"\n\n        with FileLock(lock_filepath, timeout=120):\n            if not os.path.exists(local_filepath):\n                if self._s5cmd_available:\n                    cmd = f\"s5cmd get {remote_filepath} {local_filepath}\"\n                    subprocess.run(cmd, shell=True, check=True)\n                else:\n                    self._client.download_file(remote_filepath, local_filepath)\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_remote_filepath = parse.urlparse(remote_filepath)\n        if parsed_remote_filepath.scheme != \"s3\":\n            raise ValueError(\n                f\"The remote file path must use the s3 scheme, but the scheme of the given remote file path is {parsed_remote_filepath.scheme}.\"\n            )\n\n        if os.path.exists(local_filepath):\n            return\n\n        lock_filepath = local_filepath + \".lock\"\n        lock = FileLock(lock_filepath)\n        try:\n            lock.acquire(timeout=30)\n            if not os.path.exists(local_filepath):\n                if self._s5cmd_available:\n                    subprocess.run(\n                        [\n                            \"s5cmd\",\n                            \"cp\",\n                            \"--no-encrypt\",\n                            \"--no-progress\",\n                            remote_filepath,\n                            local_filepath,\n                        ]\n                    )\n                else:\n                    self._client.download_file(\n                        parsed_remote_filepath.netloc,\n                        parsed_remote_filepath.path,\n                        local_filepath,\n                    )\n        except Timeout:\n            raise Timeout(\n                f\"The lock file {lock_filepath} could not be acquired within the specified timeout.\"\n            )\n        finally:\n            lock.release()\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(\n                f\"The remote file path {remote_filepath} is not an S3 URL. The scheme must be 's3'.\"\n            )\n\n        if os.path.exists(local_filepath):\n            return\n\n        lock_path = local_filepath + \".lock\"\n        lock = FileLock(lock_path)\n\n        try:\n            with lock.acquire(timeout=60):\n                if os.path.exists(local_filepath):\n                    return\n\n                if self._s5cmd_available:\n                    subprocess.run(\n                        [\n                            \"s5cmd\",\n                            \"cp\",\n                            remote_filepath,\n                            local_filepath,\n                            \"--no-encrypt\",\n                            \"--no-sign-request\",\n                            \"--guess-mime-type\",\n                            \"--continue\",\n                        ],\n                        check=True,\n                    )\n                else:\n                    self._client.download_file(\n                        parsed_url.netloc, parsed_url.path[1:], local_filepath\n                    )\n        except Timeout:\n            raise Timeout(f\"The lock for {local_filepath} could not be acquired.\")\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        # Check if the remote file path is a valid S3 URL\n        parsed_remote_filepath = parse.urlparse(remote_filepath)\n        if parsed_remote_filepath.scheme != \"s3\":\n            raise ValueError(\"The remote file path must use the 's3' scheme.\")\n\n        # Check if the local file already exists\n        if os.path.exists(local_filepath):\n            return\n\n        # Create a file lock to prevent multiple processes from downloading the same file simultaneously\n        lock_filepath = local_filepath + \".lock\"\n        lock = FileLock(lock_filepath)\n        try:\n            with lock.acquire(timeout=120):\n                # Check if the local file already exists\n                if os.path.exists(local_filepath):\n                    return\n\n                # Download the file using s5cmd if available, otherwise use boto3\n                if self._s5cmd_available:\n                    self._download_file_with_s5cmd(remote_filepath, local_filepath)\n                else:\n                    self._download_file_with_boto3(remote_filepath, local_filepath)\n        except Timeout:\n            raise Timeout(\n                f\"Unable to acquire a file lock for the file '{local_filepath}'. Make sure no other process is currently downloading the same file.\"\n            )\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(f\"{remote_filepath} is not an S3 URL\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        lock_file = f\"{local_filepath}.lock\"\n        lock = FileLock(lock_file, timeout=10)\n        with lock:\n            if os.path.exists(local_filepath):\n                return\n            if self._s5cmd_available:\n                self._download_file_s5cmd(remote_filepath, local_filepath)\n            else:\n                self._download_file_boto3(remote_filepath, local_filepath)\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(\n                f\"Expected S3 URL, got {remote_filepath}. Please check the remote directory path.\"\n            )\n\n        if os.path.exists(local_filepath):\n            return\n\n        lock_filepath = local_filepath + \".lock\"\n        lock = FileLock(lock_filepath)\n        try:\n            with lock.acquire(timeout=60):\n                if os.path.exists(local_filepath):\n                    return\n\n                if self._s5cmd_available:\n                    subprocess.run(\n                        [\n                            \"s5cmd\",\n                            \"cp\",\n                            remote_filepath,\n                            local_filepath,\n                            \"--no-encrypt\",\n                            \"--no-progress\",\n                        ],\n                        check=True,\n                    )\n                else:\n                    self._client.download_file(\n                        parsed_url.netloc, parsed_url.path, local_filepath\n                    )\n        except Timeout:\n            raise Timeout(\n                f\"Failed to acquire file lock for {local_filepath}. Another process is likely downloading the same file.\"\n            )\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_remote_filepath = parse.urlparse(remote_filepath)\n        if parsed_remote_filepath.scheme != \"s3\":\n            raise ValueError(\n                \"Expected remote file path to have scheme s3, but found {}\".format(\n                    parsed_remote_filepath.scheme\n                )\n            )\n\n        if os.path.exists(local_filepath):\n            return\n\n        with FileLock(local_filepath + \".lock\", timeout=30):\n            if not os.path.exists(local_filepath):\n                if self._s5cmd_available:\n                    command = \"s5cmd get --no-progress {} {}\".format(\n                        remote_filepath, local_filepath\n                    )\n                    subprocess.run(command, shell=True, check=True)\n                else:\n                    self._client.download_file(\n                        parsed_remote_filepath.netloc,\n                        parsed_remote_filepath.path,\n                        local_filepath,\n                    )\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(\n                \"The remote file path must be an S3 URL with the 's3' scheme.\"\n            )\n\n        if os.path.exists(local_filepath):\n            return\n\n        with FileLock(f\"{local_filepath}.lock\", timeout=120):\n            if os.path.exists(local_filepath):\n                return\n\n            if self._s5cmd_available:\n                command = f\"s5cmd get --no-progress {remote_filepath} {local_filepath}\"\n                subprocess.run(command, shell=True, check=True)\n            else:\n                self._client.download_file(parsed_url.netloc, parsed_url.path, local_filepath)\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(\"Remote file path must use 's3' scheme\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        with FileLock(f\"{local_filepath}.lock\", timeout=300):\n            if not os.path.exists(local_filepath):\n                if self._s5cmd_available:\n                    self._download_file_with_s5cmd(remote_filepath, local_filepath)\n                else:\n                    self._download_file_with_boto3(remote_filepath, local_filepath)\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(\n                \"The remote file path must be an S3 URL. The scheme must be 's3'.\"\n            )\n\n        if os.path.exists(local_filepath):\n            return\n\n        lock_path = os.path.join(os.path.dirname(local_filepath), \".lock\")\n        lock = FileLock(lock_path)\n\n        try:\n            with lock.acquire(timeout=10):\n                if self._s5cmd_available:\n                    subprocess.run(\n                        [\"s5cmd\", \"get\", remote_filepath, local_filepath],\n                        check=True,\n                    )\n                else:\n                    self._client.download_file(\n                        parsed_url.netloc, parsed_url.path[1:], local_filepath\n                    )\n        except Timeout:\n            raise Timeout(\n                f\"Timeout while trying to acquire lock on {lock_path}. \"\n                \"Another process may be downloading the same file.\"\n            )\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        # parse the remote file path to get the bucket name and object key\n        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(f\"Expected remote_filepath to be an S3 URL, but got {remote_filepath}\")\n\n        # if the local file already exists, we don't need to download it\n        if os.path.isfile(local_filepath):\n            return\n\n        # if s5cmd is available, use it to download the file\n        if self._s5cmd_available:\n            # create a lock file to prevent multiple processes from attempting to download the same file simultaneously\n            lock_filepath = local_filepath + \".lock\"\n            lock = FileLock(lock_filepath)\n            try:\n                lock.acquire(timeout=10)\n                # download the file\n                subprocess.run(\n                    [\"s5cmd\", \"get\", remote_filepath, local_filepath],\n                    check=True,\n                    stdout=subprocess.PIPE,\n                    stderr=subprocess.PIPE,\n                )\n            except Timeout:\n                raise Timeout(f\"Failed to acquire lock on {lock_filepath}\")\n            finally:\n                lock.release(force=True)\n                os.remove(lock_filepath)\n\n        # otherwise, use boto3 to download the file\n        else:\n            self._client.download_file(parsed_url.netloc, parsed_url.path[1:], local_filepath)\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_remote_url = parse.urlparse(remote_filepath)\n        if parsed_remote_url.scheme != \"s3\":\n            raise ValueError(\n                f\"Expected an S3 URL as the remote file path, but got {remote_filepath}\"\n            )\n\n        if os.path.exists(local_filepath):\n            return\n\n        lock_filepath = local_filepath + \".lock\"\n        lock = FileLock(lock_filepath, timeout=120)\n        try:\n            lock.acquire()\n        except Timeout:\n            raise Timeout(\n                f\"Could not acquire lock on {lock_filepath} to download {remote_filepath} to {local_filepath}\"\n            )\n\n        if os.path.exists(local_filepath):\n            return\n\n        if self._s5cmd_available:\n            download_command = f\"s5cmd get --no-progress {remote_filepath} {local_filepath}\"\n            subprocess.run(download_command.split(\" \"))\n        else:\n            self._client.download_file(parsed_remote_url.netloc, parsed_remote_url.path, local_filepath)\n\n        lock.release()\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        # Check if the remote file path is an S3 URL.\n        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(f\"Expected an S3 URL, but got: {remote_filepath}\")\n\n        # Check if the local file already exists.\n        if os.path.exists(local_filepath):\n            return\n\n        # Use s5cmd to download the file if the tool is available.\n        if self._s5cmd_available:\n            # Create a file lock to prevent multiple processes from downloading the same file simultaneously.\n            lock = FileLock(local_filepath + \".lock\")\n            try:\n                lock.acquire(timeout=10)\n            except Timeout:\n                raise Timeout(f\"Could not acquire lock on {local_filepath} after 10 seconds.\")\n\n            # Download the file using s5cmd.\n            command = [\"s5cmd\", \"cp\", remote_filepath, local_filepath]\n            subprocess.run(command, check=True)\n\n            # Release the file lock.\n            lock.release()\n        else:\n            # Download the file using the boto3 library.\n            self._client.download_file(parsed_url.netloc, parsed_url.path.lstrip(\"/\"), local_filepath)\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if not remote_filepath.startswith(\"s3://\"):\n            raise ValueError(f\"Remote file path {remote_filepath} does not use the 's3' scheme\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        parsed_url = parse.urlparse(remote_filepath)\n        scheme = parsed_url.scheme\n        bucket = parsed_url.netloc\n        remote_path = parsed_url.path[1:]\n        local_dir = os.path.dirname(local_filepath)\n\n        if not os.path.exists(local_dir):\n            os.makedirs(local_dir)\n\n        if self._s5cmd_available:\n            s5cmd_command = f\"s5cmd get --no-encrypt --auth-file /home/ubuntu/.aws/credentials {remote_filepath} {local_filepath}\"\n            subprocess.run(s5cmd_command.split(\" \"))\n        else:\n            with FileLock(f\"{local_filepath}.lock\", timeout=60):\n                self._client.download_file(bucket, remote_path, local_filepath)\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        # Parse remote file path\n        parsed_url = parse.urlparse(remote_filepath)\n        bucket = parsed_url.netloc\n        remote_file = parsed_url.path[1:]\n\n        # Raise error if the remote file path does not use the \"s3\" scheme\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(f\"The remote file path {remote_filepath} does not use the 's3' scheme.\")\n\n        # If the local file already exists, return\n        if os.path.exists(local_filepath):\n            return\n\n        # Create a lock file to prevent multiple processes from downloading the same file simultaneously\n        lock_filepath = local_filepath + \".lock\"\n        lock = FileLock(lock_filepath)\n        try:\n            lock.acquire(timeout=1)\n        except Timeout:\n            raise Timeout(f\"The lock file {lock_filepath} could not be acquired within the specified timeout.\")\n\n        # Download the file using s5cmd if it is available\n        if self._s5cmd_available:\n            cmd = f\"s5cmd get --no-encrypt {remote_filepath} {local_filepath}\"\n            subprocess.run(cmd, shell=True, check=True)\n        # Download the file using the boto3 library if s5cmd is not available\n        else:\n            self._client.download_file(bucket, remote_file, local_filepath)\n\n        # Remove the lock file\n        os.remove(lock_filepath)\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    workers_chunks: Dict[int, List[int]] = {}\n    workers_intervals: Dict[int, List[Any]] = {}\n\n    # Distribute chunks and intervals across workers\n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n\n    # Distribute chunks and intervals across workers\n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n\n    # Distribute chunks and intervals across workers\n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n\n    # Distribute chunks and intervals across workers\n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n\n    # Distribute chunks and intervals across workers\n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n\n    # Distribute chunks and intervals across workers\n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n\n    # Distribute chunks and intervals across workers\n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n\n    # Distribute chunks and intervals across workers\n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n\n    # Distribute chunks and intervals across workers\n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n\n    # Distribute chunks and intervals across workers\n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n\n   "}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    chunks_per_worker = {}\n    intervals_per_worker = {}\n\n    # Distribute chunks and intervals across workers\n    for i in range(num_workers):\n        chunks_per_worker[i] = []\n        intervals_per_worker[i] = []\n\n    # Distribute chunks and intervals across workers\n    for i in range(num_workers):\n        chunks_per_worker[i] = []\n        intervals_per_worker[i] = []\n\n    # Distribute chunks and intervals across workers\n    for i in range(num_workers):\n        chunks_per_worker[i] = []\n        intervals_per_worker[i] = []\n\n    # Distribute chunks and intervals across workers\n    for i in range(num_workers):\n        chunks_per_worker[i] = []\n        intervals_per_worker[i] = []\n\n    # Distribute chunks and intervals across workers\n    for i in range(num_workers):\n        chunks_per_worker[i] = []\n        intervals_per_worker[i] = []\n\n    # Distribute chunks and intervals across workers\n    for i in range(num_workers):\n        chunks_per_worker[i] = []\n        intervals_per_worker[i] = []\n\n    # Distribute chunks and intervals across workers\n    for i in range(num_workers):\n        chunks_per_worker[i] = []\n        intervals_per_worker[i] = []\n\n    # Distribute chunks and intervals across workers\n    for i in range(num_workers):\n        chunks_per_worker[i] = []\n        intervals_per_worker[i] = []\n\n    # Distribute chunks and intervals across workers\n    for i in range(num_workers):\n        chunks_per_worker[i] = []\n        intervals_per_worker[i] = []\n\n    # Distribute chunks and intervals across workers\n    for i in range(num_workers):\n        chunks_per_worker[i] = []\n       "}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # TODO: Implement a more sophisticated algorithm to distribute chunks across workers.\n    workers_chunks = {}\n    workers_intervals = {}\n\n    # Distribute chunks to workers\n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n\n    # Distribute chunks to workers\n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n\n    # Distribute chunks to workers\n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n\n    # Distribute chunks to workers\n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n\n    # Distribute chunks to workers\n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n\n    # Distribute chunks to workers\n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n\n    # Distribute chunks to workers\n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n\n    # Distribute chunks to workers\n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n\n    # Distribute chunks to workers\n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n\n    # Distribute chunks to workers\n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n\n    # Distribute chunks to workers\n    for i in range(num_workers"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # Initialize a dictionary to store the mapping of workers to their assigned chunks\n    workers_chunks = {}\n\n    # Initialize a dictionary to store the mapping of workers to their assigned intervals\n    workers_intervals = {}\n\n    # Initialize a list to store the number of chunks that have been assigned to each worker\n    workers_num_chunks = [0] * num_workers\n\n    # Initialize a list to store the number of intervals that have been assigned to each worker\n    workers_num_intervals = [0] * num_workers\n\n    # Initialize a list to store the number of chunks that have been assigned to each worker\n    workers_chunks_index = [0] * num_workers\n\n    # Initialize a list to store the number of intervals that have been assigned to each worker\n    workers_intervals_index = [0] * num_workers\n\n    # Initialize a list to store the number of chunks that have been assigned to each worker\n    workers_chunks_index_replica = [0] * num_workers\n\n    # Initialize a list to store the number of intervals that have been assigned to each worker\n    workers_intervals_index_replica = [0] * num_workers\n\n    # Initialize a list to store the number of chunks that have been assigned to each worker\n    workers_chunks_index_replica_copy = [0] * num_workers\n\n    # Initialize a list to store the number of intervals that have been assigned to each worker\n    workers_intervals_index_replica_copy = [0] * num_workers\n\n    # Initialize a list to store the number of chunks that have been assigned to each worker\n    workers_chunks_index_replica_copy_copy = [0] * num_workers\n\n    # Initialize a list to store the number of intervals that have been assigned to each worker\n    workers_intervals_index_replica_copy_copy = [0] * num_workers\n\n    # Initialize a list to store the number of chunks that have been assigned to each worker\n    workers_chunks_index_replica_copy_copy_copy = [0] * num"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    assert num_workers > 0\n    assert len(chunks_replica) == len(intervals_replica)\n\n    # The number of chunks per worker\n    num_chunks_per_worker = len(chunks_replica) // num_workers\n\n    # The number of chunks per worker in the last worker\n    num_chunks_last_worker = len(chunks_replica) - num_chunks_per_worker * (num_workers - 1)\n\n    # The total number of chunks\n    num_chunks = len(chunks_replica)\n\n    # The number of chunks per worker in the first worker\n    num_chunks_first_worker = num_chunks - num_chunks_last_worker\n\n    # The number of chunks per worker in the last worker\n    num_chunks_last_worker = num_chunks - num_chunks_first_worker\n\n    # The number of chunks per worker in the last worker\n    num_chunks_last_worker = num_chunks - num_chunks_first_worker\n\n    # The number of chunks per worker in the last worker\n    num_chunks_last_worker = num_chunks - num_chunks_first_worker\n\n    # The number of chunks per worker in the last worker\n    num_chunks_last_worker = num_chunks - num_chunks_first_worker\n\n    # The number of chunks per worker in the last worker\n    num_chunks_last_worker = num_chunks - num_chunks_first_worker\n\n    # The number of chunks per worker in the last worker\n    num_chunks_last_worker = num_chunks - num_chunks_first_worker\n\n    # The number of chunks per worker in the last worker\n    num_chunks_last_worker = num_chunks - num_chunks_first_worker\n\n    # The number of chunks per worker in the last worker\n    num_chunks_last_worker = num_chunks - num_chunks_first_worker\n\n    # The"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # create a list of chunks and intervals\n    chunks = []\n    intervals = []\n    for chunk, interval in zip(chunks_replica, intervals_replica):\n        chunks.append(chunk)\n        intervals.append(interval)\n\n    # create a list of workers\n    workers = list(range(num_workers))\n\n    # create a list of workers that are not the current worker\n    workers_replica = workers.copy()\n    workers_replica.remove(worker_env.rank)\n\n    # create a list of chunks and intervals that are not assigned to the current worker\n    chunks_replica = chunks.copy()\n    intervals_replica = intervals.copy()\n    chunks_replica.pop(worker_env.index)\n    intervals_replica.pop(worker_env.index)\n\n    # create a list of chunks and intervals that are assigned to the current worker\n    chunks_local = [chunks[worker_env.index]]\n    intervals_local = [intervals[worker_env.index]]\n\n    # create a list of chunks and intervals that are assigned to the current worker\n    chunks_local = [chunks[worker_env.index]]\n    intervals_local = [intervals[worker_env.index]]\n\n    # create a list of workers that are not the current worker\n    workers_replica = workers.copy()\n    workers_replica.remove(worker_env.rank)\n\n    # create a list of chunks and intervals that are not assigned to the current worker\n    chunks_replica = chunks.copy()\n    intervals_replica = intervals.copy()\n    chunks_replica.pop(worker_env.index)\n    intervals_replica.pop(worker_env.index)\n\n    # create a list of chunks and intervals that are assigned to the current worker\n    chunks_local = [chunks[worker_env.index]]\n    intervals_local = [intervals[worker_env.index]]\n\n    # create a list of workers that are not the current worker\n    workers_replica = workers.copy()\n    workers_"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    workers_chunks = {}\n    workers_intervals = {}\n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n\n    # If the number of workers is greater than the number of chunks, we need to distribute the chunks across the workers.\n    if num_workers > len(chunks_replica):\n        for i in range(len(chunks_replica)):\n            workers_chunks[i % num_workers].append(chunks_replica[i])\n            workers_intervals[i % num_workers].append(intervals_replica[i])\n    # If the number of workers is less than the number of chunks, we need to distribute the chunks among the workers.\n    elif num_workers < len(chunks_replica):\n        # If the world size is greater than the number of chunks, then we need to distribute the chunks among the workers.\n        if worker_env.world_size > len(chunks_replica):\n            for i in range(len(chunks_replica)):\n                workers_chunks[i % num_workers].append(chunks_replica[i])\n                workers_intervals[i % num_workers].append(intervals_replica[i])\n        # If the world size is less than the number of chunks, then we need to distribute the chunks across the workers.\n        else:\n            for i in range(worker_env.world_size):\n                workers_chunks[i].append(chunks_replica[i])\n                workers_intervals[i].append(intervals_replica[i])\n            for i in range(worker_env.world_size, num_workers):\n                workers_chunks[i].append(chunks_replica[i])\n                workers_intervals[i].append(intervals_replica[i])\n    # If the number of workers and chunks are equal, then we can simply assign the chunks to the workers.\n    else:\n        for i in range(num_workers"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # The number of chunks to be distributed\n    num_chunks = len(chunks_replica)\n\n    # The number of chunks to be distributed per worker\n    chunks_per_worker = num_chunks // num_workers\n\n    # The number of chunks to be distributed per worker in case num_chunks is not divisible by num_workers\n    chunks_per_worker_remainder = num_chunks % num_workers\n\n    # A dictionary mapping worker indices to their assigned chunks\n    workers_chunks = {}\n\n    # A dictionary mapping worker indices to the intervals corresponding to their assigned chunks\n    workers_intervals = {}\n\n    # The index of the first chunk to be distributed to the current worker\n    chunk_index = 0\n\n    # The index of the first chunk to be distributed to the current worker in case num_chunks is not divisible by num_workers\n    chunk_index_remainder = 0\n\n    # The index of the first chunk to be distributed to the current worker\n    interval_index = 0\n\n    # The index of the first chunk to be distributed to the current worker in case num_chunks is not divisible by num_workers\n    interval_index_remainder = 0\n\n    # Distribute chunks and intervals across the workers\n    for worker in range(num_workers):\n\n        # The number of chunks to be distributed to the current worker\n        num_chunks_worker = chunks_per_worker\n\n        # The number of chunks to be distributed to the current worker in case num_chunks is not divisible by num_workers\n        num_chunks_worker_remainder = 0\n\n        # Distribute the chunks to the current worker\n        if worker < chunks_per_worker_remainder:\n            num_chunks_worker += 1\n            num_chunks_worker_remainder = 1\n            chunk_index_remainder = worker\n        workers_chunks[worker] = chunks_replica[chunk_index : chunk_index + num_chunks_worker]\n        chunk_index"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # Create a dictionary to store the mapping of workers to their assigned chunks\n    workers_chunks: Dict[int, List[int]] = {}\n\n    # Create a dictionary to store the mapping of workers to their assigned intervals\n    workers_intervals: Dict[int, List[Any]] = {}\n\n    # Create a dictionary to store the mapping of chunks to their intervals\n    chunks_intervals: Dict[int, Any] = {}\n\n    # Create a dictionary to store the mapping of chunks to their workers\n    chunks_workers: Dict[int, int] = {}\n\n    # Populate the chunks_intervals and chunks_workers dictionaries\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        chunks_intervals[chunk_index] = chunk_interval\n        chunks_workers[chunk_index] = i % num_workers\n\n    # Distribute chunks among the workers\n    for worker_index in range(num_workers):\n        # Create a list to store the chunks assigned to the current worker\n        chunks_assigned = []\n\n        # Create a list to store the intervals corresponding to the chunks assigned to the current worker\n        intervals_assigned = []\n\n        # Populate the chunks_assigned and intervals_assigned lists\n        for chunk_index in chunks_replica:\n            if chunks_workers[chunk_index] == worker_index:\n                chunks_assigned.append(chunk_index)\n                intervals_assigned.append(chunks_intervals[chunk_index])\n\n        # Populate the workers_chunks and workers_intervals dictionaries\n        workers_chunks[worker_index] = chunks_assigned\n        workers_intervals[worker_index] = intervals_assigned\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # get the number of chunks\n    num_chunks = len(chunks_replica)\n\n    # get the number of chunks per worker\n    chunks_per_worker = num_chunks // num_workers\n\n    # get the number of chunks that need to be distributed\n    num_chunks_to_distribute = num_chunks % num_workers\n\n    # get the number of chunks that each worker will have\n    num_chunks_per_worker = [chunks_per_worker] * num_workers\n\n    # assign chunks to each worker\n    for i in range(num_chunks_to_distribute):\n        num_chunks_per_worker[i] += 1\n\n    # get the cumulative sum of the chunks per worker\n    cumsum_chunks_per_worker = np.cumsum(num_chunks_per_worker)\n\n    # get the cumulative sum of the intervals per worker\n    cumsum_intervals_per_worker = [0] * num_workers\n    for i in range(1, num_workers):\n        cumsum_intervals_per_worker[i] = cumsum_intervals_per_worker[i - 1] + num_chunks_per_worker[i - 1]\n\n    # get the indices of the chunks per worker\n    chunks_index = [0] * num_workers\n    for i in range(1, num_workers):\n        chunks_index[i] = cumsum_chunks_per_worker[i - 1]\n\n    # get the indices of the intervals per worker\n    intervals_index = [0] * num_workers\n    for i in range(1, num_workers):\n        intervals_index[i] = cumsum_intervals_per_worker[i - 1]\n\n    # get the chunks and intervals per worker\n    workers_chunks = {}\n    workers_intervals = {}\n    for i in range(num_workers):\n        workers_chunks[i] = chunks_replica[chunks_index["}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    if num_workers > 1:\n        # Distribute chunks to workers\n        # We use the same logic as the one used in DistributedSampler\n        # https://github.com/pytorch/pytorch/blob/v1.10.0/torch/utils/data/distributed.py#L292\n        num_chunks = len(chunks_replica)\n        num_chunks_per_worker = num_chunks // num_workers\n        num_chunks_remainder = num_chunks % num_workers\n\n        workers_chunks = {}\n        workers_intervals = {}\n        if num_chunks_per_worker > 0:\n            for i in range(num_workers):\n                start = i * num_chunks_per_worker\n                end = (i + 1) * num_chunks_per_worker\n                workers_chunks[i] = chunks_replica[start:end]\n                workers_intervals[i] = intervals_replica[start:end]\n        if num_chunks_remainder > 0:\n            remainder = num_chunks_per_worker + num_chunks_remainder\n            worker_index = worker_env.global_rank % num_workers\n            if worker_index < remainder:\n                start = (num_chunks_per_worker + num_chunks_remainder) * worker_index\n                end = start + num_chunks_per_worker + 1\n                workers_chunks[worker_index] = chunks_replica[start:end]\n                workers_intervals[worker_index] = intervals_replica[start:end]\n\n    else:\n        workers_chunks = {0: chunks_replica}\n        workers_intervals = {0: intervals_replica}\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # create a dictionary mapping workers to their assigned chunks\n    workers_chunks = {}\n    # create a dictionary mapping workers to their assigned intervals\n    workers_intervals = {}\n    # create a dictionary mapping workers to their assigned chunk intervals\n    workers_chunks_intervals = {}\n\n    # iterate over all workers\n    for worker_index in range(num_workers):\n        # get the number of chunks to be assigned to the current worker\n        num_chunks_to_assign = _get_num_chunks_to_assign(\n            worker_index=worker_index,\n            num_workers=num_workers,\n            num_chunks=len(chunks_replica),\n            drop_last=False,\n        )\n\n        # get the chunks to be assigned to the current worker\n        chunks_to_assign = chunks_replica[\n            worker_index * num_chunks_to_assign : (worker_index + 1) * num_chunks_to_assign\n        ]\n\n        # get the intervals to be assigned to the current worker\n        intervals_to_assign = intervals_replica[\n            worker_index * num_chunks_to_assign : (worker_index + 1) * num_chunks_to_assign\n        ]\n\n        # add the chunks and intervals to the worker's dictionary\n        workers_chunks[worker_index] = chunks_to_assign\n        workers_intervals[worker_index] = intervals_to_assign\n        workers_chunks_intervals[worker_index] = list(zip(chunks_to_assign, intervals_to_assign))\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # TODO: Implement a more sophisticated strategy for distributing chunks and intervals across workers.\n    # For now, we simply distribute chunks and intervals across workers in a round-robin fashion.\n    workers_chunks = {}\n    workers_intervals = {}\n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n\n    for i in range(len(chunks_replica)):\n        if i % num_workers == worker_env.rank:\n            workers_chunks[worker_env.rank].append(chunks_replica[i])\n            workers_intervals[worker_env.rank].append(intervals_replica[i])\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # Initialize the dictionaries\n    workers_chunks = {}\n    workers_intervals = {}\n\n    # The number of chunks to be distributed among the workers\n    num_chunks = len(chunks_replica)\n\n    # The number of chunks to be assigned to each worker\n    chunks_per_worker = num_chunks // num_workers\n\n    # The remainder chunks that are left over after dividing the total number of chunks by the number of workers\n    remainder = num_chunks % num_workers\n\n    # The index of the first chunk that is to be assigned to each worker\n    start_index = 0\n\n    # The index of the last chunk that is to be assigned to each worker\n    end_index = chunks_per_worker\n\n    # The index of the worker to which the remainder chunks are assigned\n    remainder_worker_index = num_workers - remainder\n\n    # The index of the first chunk that is to be assigned to each worker, including the remainder chunks\n    start_index_remainder = 0\n\n    # The index of the last chunk that is to be assigned to each worker, including the remainder chunks\n    end_index_remainder = chunks_per_worker + 1\n\n    # Loop over the number of workers\n    for worker_index in range(num_workers):\n\n        # If the worker index is less than or equal to the remainder worker index\n        if worker_index <= remainder_worker_index:\n\n            # Assign the chunks and intervals to the worker\n            workers_chunks[worker_index] = chunks_replica[start_index:end_index]\n            workers_intervals[worker_index] = intervals_replica[start_index:end_index]\n\n            # Increment the start index\n            start_index = end_index\n\n            # Increment the end index\n            end_index = end_index_remainder\n\n            # Increment the end index remainder\n            end_index_remainder += 1\n\n        # If the worker index is greater than the remainder worker index\n        else:\n\n            # Assign the"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # associate chunks to workers\n    workers_chunks = {}\n    for i in range(num_workers):\n        workers_chunks[i] = []\n\n    for i in range(worker_env.global_rank, len(chunks_replica), worker_env.world_size):\n        workers_chunks[i % num_workers].append(chunks_replica[i])\n\n    # associate intervals to workers\n    workers_intervals = {}\n    for i in range(num_workers):\n        workers_intervals[i] = []\n\n    for i in range(worker_env.global_rank, len(intervals_replica), worker_env.world_size):\n        workers_intervals[i % num_workers].append(intervals_replica[i])\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # TODO: Implement this function\n\n    return {}, {}\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # initialize the dictionaries\n    workers_chunks = {worker_index: [] for worker_index in range(num_workers)}\n    workers_intervals = {worker_index: [] for worker_index in range(num_workers)}\n\n    # iterate over the chunks and intervals\n    for chunk_index, interval in zip(chunks_replica, intervals_replica):\n        # find the worker index\n        worker_index = (chunk_index + worker_env.rank) % num_workers\n        # append the chunk and interval to the worker's list\n        workers_chunks[worker_index].append(chunk_index)\n        workers_intervals[worker_index].append(interval)\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    assert num_workers > 0\n    assert worker_env\n    assert chunks_replica\n    assert intervals_replica\n\n    workers_chunks = {}\n    workers_intervals = {}\n\n    # If there is only one worker, then assign all chunks to this worker\n    if num_workers == 1:\n        workers_chunks[worker_env.rank] = chunks_replica\n        workers_intervals[worker_env.rank] = intervals_replica\n        return workers_chunks, workers_intervals\n\n    # If there are multiple workers, then distribute chunks across workers\n    num_chunks = len(chunks_replica)\n    num_chunks_per_worker = int(np.ceil(num_chunks / num_workers))\n    num_chunks_per_worker_remainder = num_chunks % num_workers\n\n    # Create a list of chunks to be distributed across workers\n    chunks_to_distribute = chunks_replica\n    chunks_distributed = []\n    num_chunks_to_distribute = len(chunks_to_distribute)\n    num_chunks_distributed = 0\n\n    # Distribute chunks across workers\n    for i in range(num_workers):\n        num_chunks_to_distribute_current_worker = num_chunks_per_worker\n        if num_chunks_per_worker_remainder > 0:\n            num_chunks_to_distribute_current_worker += 1\n            num_chunks_per_worker_remainder -= 1\n\n        # Distribute chunks across the current worker\n        chunks_to_distribute_current_worker = []\n        for j in range(num_chunks_to_distribute_current_worker):\n            if num_chunks_distributed == num_chunks_to_distribute:\n                break\n            chunks_to_distribute_current_worker.append(chunks_to_distribute[num_chunks_distributed])\n            num_chunks_distributed += 1"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # TODO: Implement a more sophisticated way to distribute chunks among the workers\n    # Currently, we are distributing chunks among the workers in a round-robin fashion\n    # based on their worker index and the total world size.\n\n    workers_chunks = {}\n    workers_intervals = {}\n\n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n\n    for i in range(num_workers):\n        for j in range(i, len(chunks_replica), num_workers):\n            workers_chunks[i].append(chunks_replica[j])\n            workers_intervals[i].append(intervals_replica[j])\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # TODO: Implement a better strategy for distributing chunks to workers.\n    # TODO: Add a proper docstring.\n\n    workers_chunks = {}\n    workers_intervals = {}\n\n    # Distribute chunks to workers\n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        worker_index = i % num_workers\n        workers_chunks[worker_index].append(chunk_index)\n        workers_intervals[worker_index].append(chunk_interval)\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[len(\"local:\") :]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[len(\"local:\") :]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[len(\"local:\") :]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[len(\"local:\") :]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[len(\"local:\") :]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[len(\"local:\") :]\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\")\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\")\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[len(\"local:\") :]\n\n        super().download_file(remote_filepath, local_filepath)\n\n"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if not os.path.exists(remote_filepath):\n            raise FileNotFoundError(f\"The provided remote_path doesn't exist: {remote_filepath}\")\n\n        if remote_filepath != local_filepath and not os.path.exists(local_filepath):\n            if remote_filepath.startswith(\"local:\"):\n                remote_filepath = remote_filepath[6:]\n            shutil.copy(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        # remove the \"local:\" prefix if present\n        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[len(\"local:\") :]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if not os.path.exists(remote_filepath):\n            raise FileNotFoundError(f\"The provided remote_path doesn't exist: {remote_filepath}\")\n\n        if remote_filepath != local_filepath and not os.path.exists(local_filepath):\n            if remote_filepath.startswith(\"local:\"):\n                remote_filepath = remote_filepath[len(\"local:\"):]\n            shutil.copy(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        # remove the prefix \"local:\" if present\n        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if not os.path.exists(remote_filepath):\n            raise FileNotFoundError(f\"The provided remote_path doesn't exist: {remote_filepath}\")\n\n        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\", 1)\n\n        if remote_filepath != local_filepath and not os.path.exists(local_filepath):\n            shutil.copy(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[len(\"local:\") :]\n\n        super().download_file(remote_filepath, local_filepath)\n\n"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[len(\"local:\") :]\n        super().download_file(remote_filepath, local_filepath)\n\n"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        # If the remote_filepath has a \"local:\" prefix, remove it.\n        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[len(\"local:\"):]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        buffer = io.BytesIO()\n        item.save(buffer, format=\"PNG\")\n        return buffer.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        buffer = io.BytesIO()\n        item.save(buffer, format=\"PNG\")\n        return buffer.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if not isinstance(item, Image.Image):\n            raise TypeError(f\"PILSerializer can only serialize PIL Images, not {type(item)}\")\n        buffer = io.BytesIO()\n        item.save(buffer, format=\"PNG\")\n        return buffer.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        buffer = io.BytesIO()\n        item.save(buffer, format=\"PNG\")\n        return buffer.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        with io.BytesIO() as buffer:\n            item.save(buffer, format=\"PNG\")\n            return buffer.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if not isinstance(item, Image.Image):\n            raise TypeError(f\"PILSerializer can only serialize PIL Images, not {type(item)}\")\n\n        buffer = io.BytesIO()\n        item.save(buffer, format=\"PNG\")\n        return buffer.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if not isinstance(item, Image.Image):\n            raise TypeError(f\"PILSerializer can only serialize PIL Image objects, not {type(item)}\")\n\n        buffer = io.BytesIO()\n        item.save(buffer, format=item.format)\n        buffer.seek(0)\n        return buffer.read(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        buffer = io.BytesIO()\n        item.save(buffer, format=\"PNG\")\n        return buffer.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        img_bytes = io.BytesIO()\n        item.save(img_bytes, format=item.format)\n        return img_bytes.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if not _PIL_AVAILABLE:\n            raise ModuleNotFoundError(\n                \"PIL is not installed on this system. Please install it with `pip install Pillow`.\"\n            )\n\n        if not isinstance(item, Image.Image):\n            raise TypeError(\n                f\"PILSerializer can only serialize PIL Image objects. Received item of type {type(item)}.\"\n            )\n\n        with io.BytesIO() as buffer:\n            item.save(buffer, format=\"PNG\")\n            return buffer.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        data = io.BytesIO()\n        item.save(data, format=item.format)\n        return data.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        # Extract the image's dimensions, mode length, and mode from the image object.\n        width, height = item.size\n        mode_length = len(item.mode)\n        mode = item.mode\n\n        # Create a bytes object containing the image's width, height, mode length, and mode.\n        header = bytes([width & 0xff, (width >> 8) & 0xff, height & 0xff, (height >> 8) & 0xff, mode_length & 0xff])\n\n        # Create a bytes object containing the image mode encoded in UTF-8, followed by the raw pixel data.\n        data = mode.encode() + item.tobytes()\n\n        # Return the serialized data as a tuple.\n        return header + data, None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        # Extract the image's mode, dimensions, and raw pixel data from the PIL Image object\n        mode = item.mode\n        width, height = item.size\n        raw_data = item.tobytes()\n\n        # Serialize the image's mode, dimensions, and raw pixel data into a bytes object\n        serialized_data = bytes(f\"{width},{height},{len(mode)},{mode},{raw_data}\", encoding=\"utf-8\")\n\n        # Return the serialized data as a tuple\n        return serialized_data, None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        buffer = io.BytesIO()\n        item.save(buffer, format=\"png\")\n        buffer.seek(0)\n        return buffer.read(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        # Get the image's mode, dimensions, and raw pixel data\n        mode = item.mode\n        width, height = item.size\n        data = item.tobytes()\n\n        # Serialize the image's mode, dimensions, and raw pixel data into a bytes object\n        header = f\"{width},{height},{mode},{len(data)}\".encode(\"utf-8\")\n        serialized = header + data\n\n        return serialized, None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if not isinstance(item, Image.Image):\n            raise TypeError(f\"PILSerializer can only serialize PIL Images. Received type {type(item)}.\")\n\n        buffer = io.BytesIO()\n        item.save(buffer, format=\"png\")\n        buffer.seek(0)\n        return buffer.read(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        # Get the image's mode and dimensions.\n        mode = item.mode\n        width, height = item.size\n\n        # Serialize the image's mode and dimensions.\n        mode_and_dims = bytes([width, height, len(mode)]) + mode.encode(\"utf-8\")\n\n        # Serialize the image's raw pixel data.\n        raw_pixel_data = item.tobytes()\n\n        # Serialize the image's mode and dimensions with the raw pixel data.\n        data = mode_and_dims + raw_pixel_data\n\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if not isinstance(item, Image.Image):\n            raise TypeError(f\"PILSerializer can only serialize PIL Image objects, not {type(item)}\")\n\n        buffer = io.BytesIO()\n        item.save(buffer, format=\"PNG\")\n        buffer.seek(0)\n        return buffer.read(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        with io.BytesIO() as buffer:\n            item.save(buffer, format=\"PNG\")\n            buffer.seek(0)\n            return buffer.read(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        # Get the image's mode and dimensions.\n        mode = item.mode\n        width, height = item.size\n\n        # Encode the image's mode as a bytes object.\n        mode_bytes = mode.encode(\"utf-8\")\n\n        # Encode the image's dimensions as a bytes object.\n        dimensions_bytes = bytes(np.array((width, height), dtype=\"uint16\"))\n\n        # Encode the image's raw pixel data as a bytes object.\n        pixels_bytes = item.tobytes()\n\n        # Combine the image's dimensions, mode, and raw pixel data into a bytes object.\n        image_bytes = dimensions_bytes + mode_bytes + pixels_bytes\n\n        return image_bytes, None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        elif isinstance(item, Image.Image):\n            with io.BytesIO() as buffer:\n                item.save(buffer, format=\"JPEG\")\n                return buffer.getvalue(), None\n        else:\n            raise TypeError(f\"Unsupported image type: {type(item)}\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        if not isinstance(item, Image.Image):\n            raise TypeError(f\"The item {item} is not a supported image type.\")\n        with io.BytesIO() as output:\n            item.save(output, format=\"JPEG\")\n            return output.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        if not isinstance(item, Image.Image):\n            raise TypeError(f\"Invalid image type {type(item)}\")\n        with io.BytesIO() as output:\n            item.save(output, format=\"JPEG\")\n            return output.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            if item.filename and os.path.exists(item.filename):\n                with open(item.filename, \"rb\") as f:\n                    return f.read(), None\n            else:\n                return item.tobytes(), None\n        elif _TORCH_VISION_AVAILABLE and isinstance(item, torch.Tensor):\n            return encode_jpeg(item), None\n        elif _PIL_AVAILABLE and isinstance(item, Image.Image):\n            return item.tobytes(), None\n        else:\n            raise TypeError(f\"Expected PIL.JpegImageFile or torch.Tensor, got {type(item)}\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        elif _TORCH_VISION_AVAILABLE and isinstance(item, torch.Tensor):\n            return encode_jpeg(item), None\n        elif isinstance(item, Image.Image):\n            with io.BytesIO() as buffer:\n                item.save(buffer, format=\"jpeg\")\n                return buffer.getvalue(), None\n        else:\n            raise TypeError(f\"JPEGSerializer can only serialize PIL.JpegImageFile and torch.Tensor, but got {type(item)}\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        elif _TORCH_VISION_AVAILABLE and isinstance(item, torch.Tensor):\n            return encode_jpeg(item), None\n        elif _PIL_AVAILABLE and isinstance(item, Image.Image):\n            with io.BytesIO() as buffer:\n                item.save(buffer, format=\"jpeg\")\n                return buffer.getvalue(), None\n        else:\n            raise TypeError(f\"Unsupported image type: {type(item)}\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            with open(item.filename, \"rb\") as f:\n                data = f.read()\n        elif _TORCH_VISION_AVAILABLE and isinstance(item, torch.Tensor):\n            data = decode_jpeg(item)\n        elif _TORCH_VISION_AVAILABLE and isinstance(item, np.ndarray):\n            data = decode_jpeg(torch.from_numpy(item))\n        else:\n            data = pil_to_tensor(item).numpy()\n            data = decode_jpeg(torch.from_numpy(data))\n        return data.tobytes(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            with item.fp as fp:\n                return fp.read(), None\n        if not isinstance(item, Image.Image):\n            raise TypeError(f\"Expecting a PIL.Image.Image, got {type(item)}\")\n        if item.mode != \"RGB\":\n            item = item.convert(\"RGB\")\n        with io.BytesIO() as buffer:\n            item.save(buffer, format=\"JPEG\")\n            return buffer.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        if not isinstance(item, Image.Image):\n            raise TypeError(\"JPEGSerializer can only serialize PIL Image types.\")\n        with io.BytesIO() as f:\n            item.save(f, format=\"JPEG\")\n            return f.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        elif _TORCH_VISION_AVAILABLE and isinstance(item, torch.Tensor):\n            return encode_jpeg(item), None\n        elif isinstance(item, Image.Image):\n            buffer = io.BytesIO()\n            item.save(buffer, format=\"jpeg\")\n            return buffer.getvalue(), None\n        else:\n            raise TypeError(f\"JPEGSerializer only accepts PIL.JpegImageFile, torch.Tensor, or PIL.Image.Image. Got {type(item)}\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            filename = item.filename\n            if filename and os.path.isfile(filename):\n                with open(filename, \"rb\") as f:\n                    return f.read(), None\n        if _TORCH_VISION_AVAILABLE:\n            return decode_jpeg(pil_to_tensor(item).numpy()), None\n        raise TypeError(f\"Item is not a JPEG image. Its type is {type(item)}.\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            if item.fp is not None:\n                item.fp.seek(0)\n                return item.fp.read(), None\n            else:\n                return item.tobytes(), None\n        elif not isinstance(item, Image.Image):\n            raise TypeError(\"JPEGSerializer can only serialize an image of type PIL.Image.Image or its subclasses.\")\n        else:\n            img_bytes = io.BytesIO()\n            item.save(img_bytes, format=\"JPEG\")\n            return img_bytes.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        elif not _TORCH_VISION_AVAILABLE:\n            raise TypeError(\"torchvision is not installed.\")\n        elif isinstance(item, Image.Image):\n            return pil_to_tensor(item).numpy().tobytes(), None\n        else:\n            raise TypeError(f\"Unsupported image type: {type(item)}.\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            if os.path.exists(item.filename):\n                with open(item.filename, \"rb\") as f:\n                    return f.read(), None\n        elif isinstance(item, Image.Image):\n            with io.BytesIO() as buffer:\n                item.save(buffer, format=\"JPEG\")\n                return buffer.getvalue(), None\n        else:\n            raise TypeError(f\"JPEGSerializer does not support item type {type(item)}\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            return item.filename, None\n        elif _TORCH_VISION_AVAILABLE and isinstance(item, torch.Tensor):\n            return io.BytesIO(decode_jpeg(item)), None\n        elif _PIL_AVAILABLE and isinstance(item, Image.Image):\n            buffer = io.BytesIO()\n            item.save(buffer, format=\"JPEG\")\n            return buffer.getvalue(), None\n        else:\n            raise TypeError(f\"Invalid item type: {type(item)}.\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            if os.path.exists(item.filename):\n                with open(item.filename, \"rb\") as f:\n                    return f.read(), None\n        if not isinstance(item, Image.Image):\n            raise TypeError(f\"JPEG serializer only accepts PIL Image.Image, but got {type(item)}\")\n        buffer = io.BytesIO()\n        item.save(buffer, format=\"JPEG\")\n        return buffer.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        if not _TORCH_VISION_AVAILABLE:\n            raise TypeError(\n                \"torchvision is not installed, so JPEGSerializer cannot serialize JPEG image.\"\n            )\n        if not isinstance(item, Image.Image):\n            raise TypeError(f\"Expected Image.Image but got {type(item)}\")\n        if item.mode != \"RGB\":\n            item = item.convert(\"RGB\")\n        return pil_to_tensor(item).numpy(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            if os.path.isfile(item.filename):\n                with open(item.filename, \"rb\") as f:\n                    return f.read(), None\n            else:\n                raise TypeError(\"JPEG image must have a defined filename.\")\n        elif isinstance(item, Image.Image):\n            with io.BytesIO() as output:\n                item.save(output, format=\"JPEG\")\n                return output.getvalue(), None\n        else:\n            raise TypeError(\"Image must be an instance of PIL.Image.Image or its subclasses.\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            if item.filename and os.path.exists(item.filename):\n                with open(item.filename, \"rb\") as f:\n                    return f.read(), None\n        if not _TORCH_VISION_AVAILABLE:\n            raise TypeError(\"TorchVision is not installed, but is required to serialize JPEG images.\")\n        if not isinstance(item, Image.Image):\n            raise TypeError(f\"Expected an Image.Image, but got {type(item)}\")\n        if not isinstance(item, (JpegImageFile, PngImageFile, WebPImageFile)):\n            item = pil_to_tensor(item)\n            item = decode_jpeg(item)\n        return item.tobytes(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if not isinstance(item, JpegImageFile):\n            raise TypeError(\"JPEGSerializer can only serialize JPEG images.\")\n        if not item.filename:\n            buffer = io.BytesIO()\n            item.save(buffer, format=\"JPEG\")\n            return buffer.getvalue(), None\n        return item.tobytes(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_len = ints[0], ints[1], ints[2]\n        mode = data[12 : 12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_len = ints[0], ints[1], ints[2]\n        mode = data[12 : 12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_len = ints[0], ints[1], ints[2]\n        mode = data[12:12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len:]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_len = ints[0], ints[1], ints[2]\n        mode = data[12: 12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len:]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_len = ints\n        mode = data[12:12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len:]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_len = ints\n        mode = data[12: 12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len:]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_len = ints\n        mode = data[12: 12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len:]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_len = ints[0], ints[1], ints[2]\n        mode = data[12: 12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len:]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_len = ints\n        mode = data[12: 12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len:]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_len = ints\n        mode = data[12 : 12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        mode = data[12 : 12 + ints[2]]\n        raw = data[12 + ints[2] :]\n        return Image.frombytes(mode.decode(\"utf-8\"), (ints[0], ints[1]), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        if not _PIL_AVAILABLE:\n            raise ImportError(\"Pillow is not installed.\")\n\n        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_len = ints[0], ints[1], ints[2]\n        mode = data[12 : 12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_len = ints\n        mode = data[12 : 12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        assert _PIL_AVAILABLE, \"PIL is not available\"\n        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_len = ints\n        mode = data[12 : 12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_len = ints\n        mode = data[12 : 12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_len = ints\n        mode = data[12:12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len:]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_len = ints\n        mode = data[12 : 12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        if not _PIL_AVAILABLE:\n            raise ModuleNotFoundError(\n                \"PIL is not installed on this system. Please install PIL with `pip install pillow`\"\n            )\n        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_len = ints[0], ints[1], ints[2]\n        mode = data[12: 12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len:]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_len = ints\n        mode = data[12 : 12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_length = ints\n        mode = data[12 : 12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = int(np.frombuffer(data[:4], np.uint32))\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        data = data[4:]\n        num_dims = int(np.frombuffer(data[:4], np.uint32))\n        data = data[4:]\n        shape = []\n        for _ in range(num_dims):\n            shape.append(int(np.frombuffer(data[:4], np.uint32)))\n            data = data[4:]\n        return torch.frombuffer(data, dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = int.from_bytes(data[:4], \"big\")\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        data = data[4:]\n        num_dims = int.from_bytes(data[:4], \"big\")\n        data = data[4:]\n        shape = []\n        for _ in range(num_dims):\n            shape.append(int.from_bytes(data[:4], \"big\"))\n            data = data[4:]\n        return torch.frombuffer(data, dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 0\n        dtype_indice = int(np.frombuffer(data[idx : idx + 4], dtype=np.uint32))\n        idx += 4\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        num_dims = int(np.frombuffer(data[idx : idx + 4], dtype=np.uint32))\n        idx += 4\n        shape = tuple(int(np.frombuffer(data[idx : idx + 4], dtype=np.uint32)) for _ in range(num_dims))\n        idx += 4 * num_dims\n        return torch.frombuffer(data[idx:], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 0\n        dtype_indice = np.frombuffer(data[idx : idx + 4], np.uint32)[0]\n        idx += 4\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        num_dims = np.frombuffer(data[idx : idx + 4], np.uint32)[0]\n        idx += 4\n        shape = tuple(np.frombuffer(data[idx : idx + 4 * num_dims], np.uint32))\n        idx += 4 * num_dims\n        raw_data = np.frombuffer(data[idx:], dtype=dtype)\n        return torch.from_numpy(raw_data.reshape(shape))\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 0\n        dtype_indice = np.frombuffer(data[idx : idx + 4], np.uint32)[0]\n        idx += 4\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape = []\n        for _ in range(np.frombuffer(data[idx : idx + 4], np.uint32)[0]):\n            shape.append(np.frombuffer(data[idx : idx + 4], np.uint32)[0])\n            idx += 4\n        return torch.frombuffer(data[idx:], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[:4], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        num_dims = np.frombuffer(data[4:8], np.uint32)[0]\n        shape = np.frombuffer(data[8 : 8 + 4 * num_dims], np.uint32)\n        raw_data = data[8 + 4 * num_dims :]\n        return torch.frombuffer(raw_data, dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 0\n        dtype_indice = int(np.frombuffer(data[idx : idx + 4], dtype=np.uint32)[0])\n        idx += 4\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_len = int(np.frombuffer(data[idx : idx + 4], dtype=np.uint32)[0])\n        idx += 4\n        shape = []\n        for _ in range(shape_len):\n            shape.append(int(np.frombuffer(data[idx : idx + 4], dtype=np.uint32)[0]))\n            idx += 4\n        return torch.frombuffer(data[idx:], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = int.from_bytes(data[:4], \"little\")\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        data = data[4:]\n        num_dims = int.from_bytes(data[:4], \"little\")\n        data = data[4:]\n        shape = []\n        for _ in range(num_dims):\n            shape.append(int.from_bytes(data[:4], \"little\"))\n            data = data[4:]\n        return torch.frombuffer(data, dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = int.from_bytes(data[:4], \"big\")\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        data = data[4:]\n        num_dims = int.from_bytes(data[:4], \"big\")\n        data = data[4:]\n        shape = []\n        for _ in range(num_dims):\n            shape.append(int.from_bytes(data[:4], \"big\"))\n            data = data[4:]\n        return torch.frombuffer(data, dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 0\n        dtype_indice = int(np.frombuffer(data[idx : idx + 4], dtype=np.uint32))\n        idx += 4\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape = []\n        for _ in range(int(np.frombuffer(data[idx : idx + 4], dtype=np.uint32))):\n            idx += 4\n            shape.append(int(np.frombuffer(data[idx : idx + 4], dtype=np.uint32)))\n            idx += 4\n        return torch.frombuffer(data[idx:], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 0\n        idx += 4\n        dtype_indice = int.from_bytes(data[idx : idx + 4], \"little\")\n        idx += 4\n        shape_length = int.from_bytes(data[idx : idx + 4], \"little\")\n        idx += 4\n        shape = []\n        for _ in range(shape_length):\n            shape.append(int.from_bytes(data[idx : idx + 4], \"little\"))\n            idx += 4\n        tensor = torch.frombuffer(data[idx:], dtype=_TORCH_DTYPES_MAPPING[dtype_indice]).reshape(shape)\n        return tensor\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 0\n        dtype_indice = np.frombuffer(data[idx : idx + 4], np.uint32)[0]\n        idx += 4\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        num_dims = np.frombuffer(data[idx : idx + 4], np.uint32)[0]\n        idx += 4\n        shape = tuple(np.frombuffer(data[idx : idx + 4 * num_dims], np.uint32))\n        idx += 4 * num_dims\n        return torch.frombuffer(data[idx:], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = int.from_bytes(data[:4], \"little\")\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        data = data[4:]\n        shape_len = int.from_bytes(data[:4], \"little\")\n        data = data[4:]\n        shape = []\n        for _ in range(shape_len):\n            dim = int.from_bytes(data[:4], \"little\")\n            data = data[4:]\n            shape.append(dim)\n        return torch.frombuffer(data, dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 0\n        # extract the dtype\n        dtype_indice = int(np.frombuffer(data[idx : idx + 4], np.uint32)[0])\n        idx += 4\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        # extract the shape\n        shape_size = int(np.frombuffer(data[idx : idx + 4], np.uint32)[0])\n        idx += 4\n        shape = []\n        for _ in range(shape_size):\n            dim = int(np.frombuffer(data[idx : idx + 4], np.uint32)[0])\n            idx += 4\n            shape.append(dim)\n        # extract the raw data\n        raw_data = data[idx:]\n        # reconstruct the tensor\n        tensor = torch.frombuffer(raw_data, dtype=dtype)\n        tensor = tensor.reshape(shape)\n        return tensor\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 0\n        idx += 4  # skip the length of the dtype_indices\n        indices = np.frombuffer(data[idx : idx + 4], dtype=np.uint32)\n        idx += 4\n        dtype_indice = int(indices[0])\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        idx += 4\n        shape = []\n        for _ in range(indices[1]):\n            shape.append(int(np.frombuffer(data[idx : idx + 4], dtype=np.uint32)[0]))\n            idx += 4\n        return torch.frombuffer(data[idx:], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice, data = data[:4], data[4:]\n        dtype_indice = np.frombuffer(dtype_indice, dtype=np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_length, data = data[:4], data[4:]\n        shape_length = np.frombuffer(shape_length, dtype=np.uint32)[0]\n        shape = []\n        for _ in range(shape_length):\n            dim, data = data[:4], data[4:]\n            dim = np.frombuffer(dim, dtype=np.uint32)[0]\n            shape.append(dim)\n        tensor = np.frombuffer(data, dtype=dtype).reshape(shape)\n        return torch.from_numpy(tensor)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[:4], dtype=np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape = torch.Size(np.frombuffer(data[4:12], dtype=np.uint32))\n        raw_data = data[12:]\n        return torch.frombuffer(raw_data, dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = int(np.frombuffer(data[:4], dtype=np.uint32))\n        shape_length = int(np.frombuffer(data[4:8], dtype=np.uint32))\n        shape = []\n        idx = 8\n        for i in range(shape_length):\n            shape.append(int(np.frombuffer(data[idx : idx + 4], dtype=np.uint32)))\n            idx += 4\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        return torch.frombuffer(data[idx:], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = int.from_bytes(data[0:4], \"little\")\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape = tuple(int(x) for x in np.frombuffer(data[4:4 + (4 * int(data[3]))], dtype=\"uint32\"))\n        return torch.frombuffer(data[4 + (4 * int(data[3])) :], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 0\n        dtype_indice = np.frombuffer(data[idx : idx + 4], np.uint32)[0]\n        idx += 4\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n\n        # extract the shape information\n        shape_length = np.frombuffer(data[idx : idx + 4], np.uint32)[0]\n        idx += 4\n        shape = []\n        for _ in range(shape_length):\n            dim = np.frombuffer(data[idx : idx + 4], np.uint32)[0]\n            idx += 4\n            shape.append(dim)\n\n        # reconstruct the tensor\n        tensor = np.frombuffer(data[idx:], dtype=dtype)\n        return torch.from_numpy(tensor.reshape(shape))\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_idx = self._dtype_to_indices[item.dtype]\n        shape = item.shape\n        data = item.tobytes()\n        return (dtype_idx, shape, data), None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_idx = self._dtype_to_indices[item.dtype]\n        shape = item.shape\n        data = item.tobytes()\n        return (dtype_idx, shape, data), None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = self._dtype_to_indices[item.dtype]\n        shape = item.shape\n        data = item.tobytes()\n        return (dtype, shape, data), None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        if not isinstance(item, torch.Tensor):\n            raise TypeError(f\"The input item should be a torch.Tensor. Found {type(item)}.\")\n\n        dtype_index = self._dtype_to_indices[item.dtype]\n        shape = item.shape\n        data = item.tobytes()\n        return dtype_index.to_bytes(1, \"little\") + shape.to_bytes(4, \"little\") + data, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        # get the dtype and shape of the tensor\n        dtype = self._dtype_to_indices[item.dtype]\n        shape = item.shape\n        # get the raw data of the tensor\n        data = item.tobytes()\n        # serialize the data\n        data = pickle.dumps(data)\n        # serialize the shape\n        shape = pickle.dumps(shape)\n        # serialize the dtype\n        dtype = pickle.dumps(dtype)\n        # return the serialized data\n        return data, shape, dtype\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_idx = self._dtype_to_indices[item.dtype]\n        shape = item.shape\n        data = item.data\n        return (dtype_idx, shape, data).__serialize__(), None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_idx = self._dtype_to_indices[item.dtype]\n        shape = item.shape\n        data = item.data.tobytes()\n        return dtype_idx.to_bytes(1, \"big\") + shape.to_bytes(4, \"big\") + data, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = self._dtype_to_indices[item.dtype]\n        shape = item.shape\n        data = item.tobytes()\n        return data, dtype + \":\" + \",\".join([str(x) for x in shape])\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        if not isinstance(item, torch.Tensor):\n            raise TypeError(f\"The item to be serialized should be a Tensor. Found {type(item)}\")\n\n        item_type = self._dtype_to_indices[item.dtype]\n        item_shape = item.shape\n        item_bytes = item.tobytes()\n\n        return item_type, item_shape, item_bytes\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        item = item.detach()\n        item_dtype = item.dtype\n        item_shape = item.shape\n        item_bytes = item.tobytes()\n        dtype_index = self._dtype_to_indices[item_dtype]\n        shape_bytes = pickle.dumps(item_shape)\n        return (\n            dtype_index.to_bytes(1, byteorder=\"big\") + shape_bytes + item_bytes,\n            None,\n        )\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = self._dtype_to_indices[item.dtype]\n        shape = item.shape\n        data = item.tobytes()\n        return data, dtype\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        # The serialization format is as follows:\n        # - 1 byte for the dtype code\n        # - 4 bytes for the number of dimensions\n        # - 4 bytes for each dimension size\n        # - the raw data bytes\n        dtype_code = self._dtype_to_indices[item.dtype]\n        num_dims = len(item.shape)\n        size_bytes = item.numel() * dtype_code.itemsize\n        header = np.array([dtype_code, num_dims, size_bytes], dtype=np.uint32).tobytes()\n        shape_bytes = item.shape.tobytes()\n        data_bytes = item.numpy().tobytes()\n        return header + shape_bytes + data_bytes, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        if not isinstance(item, torch.Tensor):\n            raise TypeError(f\"The input must be a torch.Tensor, but got {type(item)}\")\n\n        # dtype, shape, and raw data\n        dtype_idx = self._dtype_to_indices[item.dtype]\n        shape = item.shape\n        data = item.tobytes()\n        return (dtype_idx, shape, data), None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        if not isinstance(item, torch.Tensor):\n            raise TypeError(f\"The input should be a torch.Tensor. Found {type(item)}.\")\n\n        dtype = item.dtype\n        if dtype not in _TORCH_DTYPES_MAPPING.keys():\n            raise TypeError(f\"The input dtype is not supported. Found {dtype}.\")\n\n        dtype_index = self._dtype_to_indices[dtype]\n        shape = item.shape\n        num_elements = item.numel()\n        raw_data = item.tobytes()\n\n        # The first 4 bytes encode the dtype index\n        # The next 4 bytes encode the number of elements in the array\n        # The next 4 bytes encode the number of dimensions\n        # The rest of the bytes encode the raw data of the tensor\n        return (\n            dtype_index.to_bytes(4, \"big\")\n            + num_elements.to_bytes(4, \"big\")\n            + len(shape).to_bytes(4, \"big\")\n            + raw_data,\n            None,\n        )\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        if not isinstance(item, torch.Tensor):\n            raise TypeError(f\"The input item should be a torch.Tensor. Found {type(item)}.\")\n\n        item_dtype = self._dtype_to_indices[item.dtype]\n        item_shape = item.shape\n        item_raw_data = item.tobytes()\n        item_shape_raw_data = np.array(item_shape, dtype=np.uint32).tobytes()\n\n        serialized_data = item_dtype.encode(\"utf-8\") + item_shape_raw_data + item_raw_data\n\n        return serialized_data, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        # TODO: Add support for quantized tensors.\n        if not isinstance(item, torch.Tensor):\n            raise TypeError(f\"The input should be a torch.Tensor. Found {type(item)}\")\n        if item.is_complex():\n            raise TypeError(\"Complex tensors are not supported.\")\n        if item.is_sparse:\n            raise TypeError(\"Sparse tensors are not supported.\")\n        if item.is_quantized:\n            raise TypeError(\"Quantized tensors are not supported.\")\n\n        # dtype\n        dtype_id = self._dtype_to_indices[item.dtype]\n\n        # shape\n        shape = item.shape\n        shape_size = len(shape)\n\n        # data\n        data = item.data.to(torch.uint8)\n\n        # combine dtype, shape, and data\n        data_list = [dtype_id, shape_size] + list(shape) + list(data)\n        data_bytes = bytes(data_list)\n\n        return data_bytes, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        if not isinstance(item, torch.Tensor):\n            raise TypeError(f\"The input item should be a torch.Tensor. Found {type(item)}.\")\n        if item.dtype not in _TORCH_DTYPES_MAPPING:\n            raise TypeError(f\"The input item's dtype should be one of {_TORCH_DTYPES_MAPPING.keys()}. Found {item.dtype}.\")\n        if item.dtype.is_complex:\n            raise TypeError(\"Complex dtype is not supported.\")\n\n        dtype = self._dtype_to_indices[item.dtype]\n        shape = item.shape\n        raw_data = item.to(dtype=torch.uint8).numpy().tobytes()\n        return dtype.tobytes() + shape.tobytes() + raw_data, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        if not isinstance(item, torch.Tensor):\n            raise TypeError(f\"The input item is not a tensor, found {type(item)}\")\n\n        if item.is_floating_point():\n            item = item.float()\n\n        # serialize the dtype and shape\n        dtype_int = self._dtype_to_indices[item.dtype]\n        shape = item.shape\n        shape_str = \" \".join(str(s) for s in shape)\n\n        # serialize the raw data\n        # TODO: support other dtypes\n        if item.dtype == torch.float32:\n            item = item.numpy().tobytes()\n        elif item.dtype == torch.int64:\n            item = item.numpy().astype(np.int32).tobytes()\n        else:\n            raise ValueError(f\"Unsupported dtype {item.dtype}\")\n\n        # combine the dtype, shape, and raw data\n        return f\"{dtype_int} {shape_str}\".encode(\"utf-8\") + item, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        if not isinstance(item, torch.Tensor):\n            raise TypeError(f\"The input item should be a torch.Tensor. Found {type(item)}.\")\n\n        if item.dtype not in _TORCH_DTYPES_MAPPING:\n            raise TypeError(f\"The input item's dtype is not supported. Found {item.dtype}.\")\n\n        # Get the dtype and shape of the input tensor\n        dtype = self._dtype_to_indices[item.dtype]\n        shape = item.shape\n        shape_length = len(shape)\n\n        # Create a bytearray object to store the serialized data\n        # The serialization format is:\n        # dtype (int) | shape_length (int) | shape (ints) | data (raw bytes)\n        serialized_data = bytearray()\n\n        # Append the dtype and shape_length\n        serialized_data.extend(dtype.to_bytes(4, \"big\"))\n        serialized_data.extend(shape_length.to_bytes(4, \"big\"))\n\n        # Append the shape\n        for dim_size in shape:\n            serialized_data.extend(dim_size.to_bytes(4, \"big\"))\n\n        # Append the data\n        serialized_data.extend(item.numpy().tobytes())\n\n        return bytes(serialized_data), None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        if not isinstance(item, torch.Tensor):\n            raise TypeError(f\"The input item should be a torch.Tensor, but got {type(item)}\")\n\n        if item.is_complex():\n            raise TypeError(f\"TensorSerializer does not support complex dtypes (got {item.dtype}).\")\n\n        if item.is_quantized():\n            raise TypeError(f\"TensorSerializer does not support quantized dtypes (got {item.dtype}).\")\n\n        if item.layout != torch.strided:\n            raise TypeError(f\"TensorSerializer only supports strided layout (got {item.layout}).\")\n\n        if item.dtype.is_sparse:\n            raise TypeError(f\"TensorSerializer does not support sparse dtype (got {item.dtype}).\")\n\n        # TODO: Handle other dtypes\n        dtype_idx = self._dtype_to_indices.get(item.dtype, None)\n        if dtype_idx is None:\n            raise TypeError(f\"TensorSerializer does not support dtype {item.dtype}.\")\n\n        shape = item.shape\n        data = item.data.cpu().numpy().tobytes()\n        return (\n            np.array(\n                [dtype_idx, shape],\n                dtype=np.int64,\n            ).tobytes() + data,\n            None,\n        )\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except RuntimeError:\n                pass\n        image = Image.open(io.BytesIO(data))\n        if _TORCH_VISION_AVAILABLE:\n            return pil_to_tensor(image)\n        return image\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except RuntimeError:\n                # If the data is a PNG with a JPEG extension, this will fail.\n                pass\n\n        buff = io.BytesIO(data)\n        item = Image.open(buff)\n        if _TORCH_VISION_AVAILABLE:\n            return pil_to_tensor(item)\n        return item\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except RuntimeError:\n                # RuntimeError is raised if the data is not a valid JPEG.\n                pass\n\n        with io.BytesIO(data) as buff:\n            img = Image.open(buff)\n            if _TORCH_VISION_AVAILABLE:\n                return pil_to_tensor(img)\n            return img\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                image = decode_jpeg(data)\n            except RuntimeError:\n                image = Image.open(io.BytesIO(data))\n                if _TORCH_VISION_AVAILABLE:\n                    image = pil_to_tensor(image)\n                return image\n            return image\n        image = Image.open(io.BytesIO(data))\n        if _TORCH_VISION_AVAILABLE:\n            image = pil_to_tensor(image)\n        return image\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except RuntimeError:\n                pass\n\n        if _PIL_AVAILABLE:\n            return pil_to_tensor(Image.open(io.BytesIO(data)))\n\n        raise RuntimeError(\"Unable to decode the JPEG image data. Please install torchvision to enable JPEG decoding.\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except RuntimeError:\n                pass\n        image = Image.open(io.BytesIO(data))\n        if _TORCH_VISION_AVAILABLE:\n            return pil_to_tensor(image)\n        return image\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except RuntimeError:\n                pass\n\n        image = Image.open(io.BytesIO(data))\n        if _TORCH_VISION_AVAILABLE:\n            return pil_to_tensor(image)\n        else:\n            return image\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        try:\n            if _TORCH_VISION_AVAILABLE:\n                return decode_jpeg(data)\n            else:\n                return Image.open(io.BytesIO(data))\n        except RuntimeError:\n            return Image.open(io.BytesIO(data))\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except RuntimeError:\n                pass\n        image = Image.open(io.BytesIO(data))\n        if _TORCH_VISION_AVAILABLE:\n            return pil_to_tensor(image)\n        return image\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        try:\n            if _TORCH_VISION_AVAILABLE:\n                return decode_jpeg(data)\n        except RuntimeError:\n            pass\n\n        if _PIL_AVAILABLE:\n            return pil_to_tensor(Image.open(io.BytesIO(data)))\n\n        raise RuntimeError(\"Unable to deserialize the image data. Please install PIL to deserialize the image data.\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except RuntimeError:\n                pass\n        image = Image.open(io.BytesIO(data))\n        if _TORCH_VISION_AVAILABLE:\n            return pil_to_tensor(image)\n        return image\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except RuntimeError:\n                pass\n\n        # if torchvision is not available, fall back to PIL\n        image = Image.open(io.BytesIO(data))\n        if _TORCH_VISION_AVAILABLE:\n            return pil_to_tensor(image)\n        return image\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                img = decode_jpeg(data)\n                return img\n            except RuntimeError:\n                pass\n\n        img = Image.open(io.BytesIO(data))\n        if _TORCH_VISION_AVAILABLE:\n            return pil_to_tensor(img)\n        return img\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        try:\n            return decode_jpeg(data)\n        except RuntimeError:\n            # The data is a PNG with a JPEG extension, or something else.\n            # Try to read it with PIL and convert it to JPEG.\n            return pil_to_tensor(Image.open(io.BytesIO(data)))\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                img = decode_jpeg(data)\n                return img\n            except RuntimeError:\n                img = Image.open(io.BytesIO(data))\n                if _TORCH_VISION_AVAILABLE:\n                    return pil_to_tensor(img)\n                return img\n        else:\n            img = Image.open(io.BytesIO(data))\n            return img\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except RuntimeError:\n                pass\n\n        with tempfile.TemporaryDirectory() as tmpdirname:\n            with tempfile.NamedTemporaryFile(dir=tmpdirname) as f:\n                f.write(data)\n                f.seek(0)\n                img = Image.open(f)\n                if _TORCH_VISION_AVAILABLE:\n                    return pil_to_tensor(img)\n                else:\n                    return img\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except RuntimeError:\n                pass\n\n        image = Image.open(io.BytesIO(data))\n        if _TORCH_VISION_AVAILABLE:\n            return pil_to_tensor(image)\n        return image\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except RuntimeError:\n                pass\n\n        image = Image.open(io.BytesIO(data))\n        if _TORCH_VISION_AVAILABLE:\n            return pil_to_tensor(image)\n        return image\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except RuntimeError:\n                # torchvision failed to decode the image, we fallback to PIL\n                pass\n        with tempfile.TemporaryDirectory() as tmpdir:\n            filepath = os.path.join(tmpdir, \"tmp.jpg\")\n            with open(filepath, \"wb\") as f:\n                f.write(data)\n            with open(filepath, \"rb\") as f:\n                return Image.open(f)\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                # try to decode the data as a JPEG image\n                return decode_jpeg(data)\n            except RuntimeError:\n                # if decoding fails, use PIL to deserialize the data\n                return pil_to_tensor(Image.open(io.BytesIO(data)).convert(\"RGB\"))\n        else:\n            return Image.open(io.BytesIO(data)).convert(\"RGB\")\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[self._dtype]\n        return item.numpy().tobytes(order=\"C\"), f\"no_header_tensor:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[self._dtype]\n        data = item.numpy().tobytes(order=\"C\")\n        return data, f\"no_header_tensor:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[self._dtype]\n        return item.numpy().tobytes(order=\"C\"), f\"no_header_tensor:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[self._dtype]\n        data = item.numpy().tobytes(order=\"C\")\n        return data, f\"no_header_tensor:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[self._dtype]\n        data = item.numpy().tobytes(order=\"C\")\n        return data, f\"no_header_tensor:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[self._dtype]\n        data = item.numpy().tobytes(order=\"C\")\n        return data, f\"no_header_tensor:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"The data type of the tensor must be set before serialization.\")\n        dtype_indice = self._dtype_to_indices[self._dtype]\n        data = item.numpy().tobytes(order=\"C\")\n        return data, f\"no_header_tensor:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = item.numpy().tobytes(order=\"C\")\n        return data, f\"no_header_tensor:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[self._dtype]\n        return item.numpy().tobytes(order=\"C\"), f\"no_header_tensor:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        if self._dtype is None:\n            raise RuntimeError(\"The data type is not defined. Please call the setup method to define the data type.\")\n\n        data = item.numpy().tobytes(order=\"C\")\n        return data, f\"no_header_tensor:{self._dtype_to_indices[self._dtype]}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[self._dtype]\n        return item.numpy().tobytes(order=\"C\"), f\"no_header_tensor:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        if self._dtype is None:\n            raise RuntimeError(\"The data type of the serializer is not specified. Call the setup method to specify the data type.\")\n\n        dtype_indice = self._dtype_to_indices[self._dtype]\n        data = item.numpy().tobytes(order=\"C\")\n        return data, f\"no_header_tensor:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[self._dtype]\n        return item.numpy().tobytes(order=\"C\"), f\"no_header_tensor:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = item.numpy().tobytes(order=\"C\")\n        return data, f\"no_header_tensor:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"The data type is not specified. Call the setup method to specify the data type.\")\n        dtype_indice = self._dtype_to_indices[self._dtype]\n        return item.numpy().tobytes(order=\"C\"), f\"no_header_tensor:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[self._dtype]\n        data = item.numpy().tobytes(order=\"C\")\n        return data, f\"no_header_tensor:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        if not isinstance(item, torch.Tensor):\n            raise TypeError(f\"The input item should be a tensor, but received {type(item)}\")\n\n        if not self._dtype:\n            raise ValueError(\"The data type is not defined. Call setup(data_format) to define the data type.\")\n\n        if item.dtype != self._dtype:\n            raise TypeError(f\"The input tensor should be of type {self._dtype}, but received {item.dtype}\")\n\n        data = item.numpy().tobytes(order=\"C\")\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[self._dtype]\n        data = item.numpy().tobytes(order=\"C\")\n        return data, f\"no_header_tensor:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        if not self._dtype:\n            raise ValueError(\"The data type of the tensor to be serialized is not specified.\")\n        data = [item.numpy().tobytes(order=\"C\")]\n        return b\"\".join(data), f\"no_header_tensor:{self._dtype_to_indices[self._dtype]}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        if not isinstance(item, torch.Tensor):\n            raise TypeError(f\"The item to be serialized should be of type {torch.Tensor}. Found {type(item)}.\")\n\n        if len(item.shape) == 0:\n            raise ValueError(f\"The item cannot be a scalar. Received {item}.\")\n\n        dtype_indice = self._dtype_to_indices[self._dtype]\n        data = item.numpy().tobytes(order=\"C\")\n        return data, f\"no_header_tensor:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        tensor = torch.frombuffer(data, dtype=self._dtype)\n        return tensor\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        tensor = torch.frombuffer(data, dtype=self._dtype)\n        return tensor\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        tensor = torch.frombuffer(data, dtype=self._dtype)\n        return tensor\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        tensor = torch.frombuffer(data, dtype=self._dtype)\n        return tensor\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        assert self._dtype is not None, \"No data type is defined for the NoHeaderTensorSerializer instance.\"\n        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"No data type is specified for the NoHeaderTensorSerializer instance.\")\n        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"The data type is not specified in the instance.\")\n        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"The data type for the tensor is not specified. Please call the setup function to set the data type.\")\n\n        tensor = torch.frombuffer(data, dtype=self._dtype)\n        return tensor\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        if self._dtype is None:\n            raise RuntimeError(\"No data type specified in the serializer. Please call setup() before deserialize().\")\n\n        tensor = torch.frombuffer(data, dtype=self._dtype)\n        return tensor\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        if not self._dtype:\n            raise ValueError(\n                \"The NoHeaderTensorSerializer must have a predefined data type (_dtype) for the tensor. \"\n                \"Make sure to call the setup method before calling deserialize.\"\n            )\n        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        assert self._dtype\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{self._dtype_to_indices[self._dtype]}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[self._dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        assert self._dtype\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{self._dtype_to_indices[self._dtype]}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[self._dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[self._dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[self._dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[self._dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[self._dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        assert self._dtype\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{self._dtype_to_indices[self._dtype]}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        assert self._dtype\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{self._dtype_to_indices[self._dtype]}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        assert self._dtype\n        dtype_indice = self._dtype_to_indices[self._dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[self._dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype.type]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype.type]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype.type]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype.type]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        if not isinstance(item, np.ndarray):\n            raise TypeError(f\"The item to be serialized should be a NumPy array. Found {type(item)}.\")\n        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        else:\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        else:\n            return {\n                \"dataset\": {\n                    \"current_epoch\": self.current_epoch,\n                    \"num_samples_yielded\": self._num_samples_yielded_combined,\n                    \"latest_worker_idx\": self._latest_worker_idx,\n                },\n                \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state_dict: Dict[str, Any] = {}\n        state_dict[\"dataset\"] = self.dataset.state_dict()\n        state_dict[\"current_epoch\"] = self.current_epoch\n        state_dict[\"num_samples_yielded\"] = self._num_samples_yielded_streaming\n        state_dict[\"latest_worker_idx\"] = self._latest_worker_idx\n        if isinstance(self.dataset, CombinedStreamingDataset):\n            state_dict[\"num_samples_yielded_combined\"] = self._num_samples_yielded_combined\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state_dict: Dict[str, Any] = {}\n        state_dict[\"dataset\"] = self.dataset.state_dict()\n        state_dict[\"current_epoch\"] = self.current_epoch\n        state_dict[\"num_samples_yielded_streaming\"] = self._num_samples_yielded_streaming\n        state_dict[\"num_samples_yielded_combined\"] = self._num_samples_yielded_combined\n        state_dict[\"latest_worker_idx\"] = self._latest_worker_idx\n        state_dict[\"rng_state\"] = self.rng_state\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            return {\n                \"dataset\": deepcopy(self.dataset),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        else:\n            return {\n                \"dataset\": deepcopy(self.dataset),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        else:\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            state_dict = {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        else:\n            state_dict = {\n                \"dataset\": deepcopy(self.dataset),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            return {\n                \"dataset\": {\n                    \"state_dict\": self.dataset.state_dict(),\n                    \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                },\n                \"current_epoch\": self.current_epoch,\n                \"num_workers\": self.num_workers,\n                \"batch_size\": self.batch_size,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        else:\n            return {\n                \"dataset\": {\n                    \"state_dict\": self.dataset.state_dict(),\n                    \"num_samples_yielded\": self._num_samples_yielded_combined,\n                },\n                \"current_epoch\": self.current_epoch,\n                \"num_workers\": self.num_workers,\n                \"batch_size\": self.batch_size,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state_dict: Dict[str, Any] = {}\n        state_dict[\"dataset\"] = self.dataset.state_dict()\n        state_dict[\"current_epoch\"] = self.current_epoch\n        state_dict[\"num_samples_yielded_streaming\"] = self._num_samples_yielded_streaming\n        state_dict[\"num_samples_yielded_combined\"] = self._num_samples_yielded_combined\n        state_dict[\"latest_worker_idx\"] = self._latest_worker_idx\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state_dict = {}\n        state_dict[\"dataset\"] = self.dataset.state_dict()\n        state_dict[\"current_epoch\"] = self.current_epoch\n        state_dict[\"num_samples_yielded\"] = self._num_samples_yielded_streaming\n        state_dict[\"num_samples_yielded_combined\"] = self._num_samples_yielded_combined\n        state_dict[\"latest_worker_idx\"] = self._latest_worker_idx\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        else:\n            return {\n                \"dataset\": {\n                    \"__class__\": self.dataset.__class__.__name__,\n                    \"datasets\": [dataset.state_dict() for dataset in self.dataset.datasets],\n                    \"weights\": self.dataset.weights,\n                },\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state_dict: Dict[str, Any] = {}\n        state_dict[\"current_epoch\"] = self.current_epoch\n        state_dict[\"num_samples_yielded\"] = self._num_samples_yielded_streaming\n        state_dict[\"latest_worker_idx\"] = self._latest_worker_idx\n\n        if isinstance(self.dataset, StreamingDataset):\n            state_dict[\"dataset\"] = self.dataset.state_dict()\n        else:\n            state_dict[\"dataset\"] = {}\n            for dataset_idx in range(len(self.dataset.datasets)):\n                state_dict[\"dataset\"][dataset_idx] = self.dataset.datasets[dataset_idx].state_dict()\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state_dict = {}\n        state_dict[\"dataset\"] = self.dataset.state_dict()\n        state_dict[\"current_epoch\"] = self.current_epoch\n        state_dict[\"num_samples_yielded\"] = self._num_samples_yielded_streaming\n        state_dict[\"latest_worker_idx\"] = self._latest_worker_idx\n        state_dict[\"num_samples_yielded_combined\"] = self._num_samples_yielded_combined\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            state = {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        else:\n            state = {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n\n        return state\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            return {\n                \"dataset\": {\n                    \"state_dict\": self.dataset.state_dict(),\n                    \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                    \"current_epoch\": self.current_epoch,\n                    \"num_workers\": self.num_workers,\n                    \"batch_size\": self.batch_size,\n                    \"rng_state\": self.rng_state,\n                },\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        else:\n            return {\n                \"dataset\": {\n                    \"state_dict\": self.dataset.state_dict(),\n                    \"num_samples_yielded\": self._num_samples_yielded_combined,\n                    \"current_epoch\": self.current_epoch,\n                    \"num_workers\": self.num_workers,\n                    \"batch_size\": self.batch_size,\n                    \"rng_state\": self.rng_state,\n                },\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"dataset\": self.dataset.state_dict(),\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": self._num_samples_yielded_streaming,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n\n        if isinstance(self.dataset, CombinedStreamingDataset):\n            state[\"num_samples_yielded_combined\"] = self._num_samples_yielded_combined\n\n        return state\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state: Dict[str, Any] = {}\n        state[\"dataset\"] = self.dataset.state_dict()\n        state[\"current_epoch\"] = self.current_epoch\n        state[\"num_samples_yielded_streaming\"] = self._num_samples_yielded_streaming\n        state[\"num_samples_yielded_combined\"] = self._num_samples_yielded_combined\n        state[\"latest_worker_idx\"] = self._latest_worker_idx\n        return state\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state: Dict[str, Any] = {}\n        state[\"dataset\"] = self.dataset.state_dict()\n        state[\"current_epoch\"] = self.current_epoch\n        state[\"num_samples_yielded_streaming\"] = self._num_samples_yielded_streaming\n        state[\"num_samples_yielded_combined\"] = self._num_samples_yielded_combined\n        state[\"latest_worker_idx\"] = self._latest_worker_idx\n        return state\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            return {\n                \"dataset\": {\n                    \"dataset_name\": self.dataset.dataset_name,\n                    \"shuffle\": self.dataset.shuffle,\n                    \"current_epoch\": self.current_epoch,\n                    \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                    \"latest_worker_idx\": self._latest_worker_idx,\n                }\n            }\n        else:\n            return {\n                \"dataset\": {\n                    \"dataset_name\": self.dataset.dataset_name,\n                    \"shuffle\": self.dataset.shuffle,\n                    \"current_epoch\": self.current_epoch,\n                    \"num_samples_yielded\": self._num_samples_yielded_combined,\n                    \"latest_worker_idx\": self._latest_worker_idx,\n                }\n            }\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        return {\n            \"dataset\": self.dataset.state_dict(),\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": self._num_samples_yielded_combined\n            if isinstance(self.dataset, CombinedStreamingDataset)\n            else self._num_samples_yielded_streaming,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE:\n            raise ValueError(\"The torchvision library is not installed.\")\n        if not _AV_AVAILABLE:\n            raise ValueError(\"The av library is not installed.\")\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\") as f:\n            f.write(data)\n            return torchvision.io.read_video(f.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not (_TORCH_VISION_AVAILABLE and _AV_AVAILABLE):\n            raise ImportError(\n                \"To use the VideoSerializer, torchvision and av must be installed. \"\n                \"Please see the documentation for more information about installing these libraries.\"\n            )\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\") as f:\n            f.write(data)\n            f.seek(0)\n            return torchvision.io.read_video(f.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise ValueError(\"The torchvision module is not available, please install it to deserialize videos.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\") as f:\n            f.write(data)\n            f.seek(0)\n            return torchvision.io.read_video(f.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise RuntimeError(\"The torchvision module is required to deserialize videos.\")\n\n        # write the data to a temporary file\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\") as f:\n            f.write(data)\n            f.flush()\n            return torchvision.io.read_video(f.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not (_TORCH_VISION_AVAILABLE and _AV_AVAILABLE):\n            raise ImportError(\n                \"The VideoSerializer requires torchvision and av to be installed. Please see README for more instructions.\"\n            )\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\") as f:\n            f.write(data)\n            f.seek(0)\n            return torchvision.io.read_video(f.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not (_TORCH_VISION_AVAILABLE and _AV_AVAILABLE):\n            raise ValueError(\n                \"The torchvision and av packages are required to deserialize video files. Please install them first.\"\n            )\n        with tempfile.TemporaryFile() as f:\n            f.write(data)\n            f.seek(0)\n            return torchvision.io.read_video(f)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise ImportError(\"To use the VideoSerializer, you must have torchvision and av installed.\")\n        if not _TORCH_VISION_AVAILABLE:\n            raise ImportError(\"To use the VideoSerializer, you must have torchvision and av installed.\")\n        with tempfile.TemporaryDirectory() as tmpdirname:\n            tmp_file = os.path.join(tmpdirname, \"tmp_video.mp4\")\n            with open(tmp_file, \"wb\") as f:\n                f.write(data)\n            return torchvision.io.read_video(tmp_file)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise ImportError(\"The av library is not installed. Please install av using pip install av or conda install av.\")\n        if not _TORCH_VISION_AVAILABLE:\n            raise ImportError(\"The torchvision library is not installed. Please install torchvision using pip install torchvision or conda install torchvision.\")\n        with tempfile.TemporaryDirectory() as tmpdir:\n            tmp_file = os.path.join(tmpdir, \"tmp.mp4\")\n            with open(tmp_file, \"wb\") as f:\n                f.write(data)\n            return torchvision.io.read_video(tmp_file)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise ImportError(\"The torchvision library is required to deserialize videos. Please install it first.\")\n\n        if not _TORCH_VISION_AVAILABLE:\n            raise ImportError(\"The torchvision library is required to deserialize videos. Please install it first.\")\n\n        with tempfile.TemporaryDirectory() as tmpdirname:\n            tmp_file = os.path.join(tmpdirname, \"tmp_video.mp4\")\n            with open(tmp_file, \"wb\") as f:\n                f.write(data)\n            return torchvision.io.read_video(tmp_file)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise Exception(\"The torchvision module requires the av module to be installed. Please install it using pip install av.\")\n\n        if not _TORCH_VISION_AVAILABLE:\n            raise Exception(\"The torchvision module is not installed. Please install it using pip install torchvision.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\") as f:\n            f.write(data)\n            f.flush()\n            return torchvision.io.read_video(f.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not (_TORCH_VISION_AVAILABLE and _AV_AVAILABLE):\n            raise ValueError(\"TorchVision and AV are not installed. Please install TorchVision and AV to use the VideoSerializer\")\n        with tempfile.TemporaryDirectory() as tempdir:\n            temp_file_name = os.path.join(tempdir, \"temp.mp4\")\n            with open(temp_file_name, \"wb\") as f:\n                f.write(data)\n            return torchvision.io.read_video(temp_file_name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not (_TORCH_VISION_AVAILABLE and _AV_AVAILABLE):\n            raise ImportError(\n                \"The torchvision and av packages are required to use the VideoSerializer. \"\n                \"Please refer to the documentation for more information on how to install them.\"\n            )\n\n        with tempfile.TemporaryDirectory() as tmpdirname:\n            tmp_file_path = os.path.join(tmpdirname, \"tmp_video_file\")\n            with open(tmp_file_path, \"wb\") as f:\n                f.write(data)\n            return torchvision.io.read_video(tmp_file_path)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not (_TORCH_VISION_AVAILABLE and _AV_AVAILABLE):\n            raise ImportError(\"TorchVision and AV are required to deserialize video data.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\") as f:\n            f.write(data)\n            return torchvision.io.read_video(f.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not (_TORCH_VISION_AVAILABLE and _AV_AVAILABLE):\n            raise ImportError(\n                \"torchvision and av are required to deserialize video files. Please install them first.\"\n            )\n\n        with tempfile.NamedTemporaryFile(\"wb\") as f:\n            f.write(data)\n            f.flush()\n            return torchvision.io.read_video(f.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE:\n            raise Exception(\"The torchvision package is not available\")\n        if not _AV_AVAILABLE:\n            raise Exception(\"The av package is not available\")\n\n        with tempfile.TemporaryDirectory() as tmpdir:\n            tmp_filepath = os.path.join(tmpdir, \"tmp_video.mp4\")\n            with open(tmp_filepath, \"wb\") as f:\n                f.write(data)\n            return torchvision.io.read_video(tmp_filepath)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not (_AV_AVAILABLE and _TORCH_VISION_AVAILABLE):\n            raise ImportError(\n                \"To deserialize a video, please install torchvision and av. Please see the PyTorch documentation for more information on how to install these libraries.\"\n            )\n        with tempfile.TemporaryDirectory() as tmpdirname:\n            filepath = os.path.join(tmpdirname, \"tmp_video.mp4\")\n            with open(filepath, \"wb\") as f:\n                f.write(data)\n            video, _, _ = torchvision.io.read_video(filepath, pts_unit=\"sec\")\n        return video\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise Exception(\"The torchvision module is required to deserialize videos. Please install it first.\")\n\n        with tempfile.NamedTemporaryFile(suffix=f\".{self.file_extension}\") as f:\n            f.write(data)\n            f.flush()\n            return torchvision.io.read_video(f.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise Exception(\"The torchvision library is required to deserialize a video. Please install torchvision.\")\n\n        if not _TORCH_VISION_AVAILABLE:\n            raise Exception(\"The torchvision library is required to deserialize a video. Please install torchvision.\")\n\n        with tempfile.TemporaryDirectory() as tempdir:\n            temp_file = os.path.join(tempdir, \"temp.mp4\")\n            with open(temp_file, \"wb\") as f:\n                f.write(data)\n            return torchvision.io.read_video(temp_file)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        # Check if torchvision is installed\n        if not _TORCH_VISION_AVAILABLE:\n            raise ValueError(\"Torchvision is not installed. Please install torchvision if you wish to serialize videos.\")\n\n        # Check if av is installed\n        if not _AV_AVAILABLE:\n            raise ValueError(\"Av is not installed. Please install av if you wish to serialize videos.\")\n\n        # Write the data to a temporary file\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\") as f:\n            f.write(data)\n            f.flush()\n\n            # Use torchvision's read_video function to deserialize the video file into a video object\n            video, _, _ = torchvision.io.read_video(f.name, pts_unit=\"sec\")\n            return video\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not (_TORCH_VISION_AVAILABLE and _AV_AVAILABLE):\n            raise ValueError(\n                \"Torchvision and av are required for video deserialization. Please install torchvision and av and try again.\"\n            )\n        file_path = os.path.join(tempfile.gettempdir(), f\"{str(time.time())}.mp4\")\n        with open(file_path, \"wb\") as f:\n            f.write(data)\n        return torchvision.io.read_video(file_path)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self._is_done:\n            return []\n\n        # Write remaining chunks\n        while not self._is_done:\n            self.write_chunk()\n\n        # Write the index file\n        self.write_chunks_index()\n\n        # Mark the writer as done\n        self._is_done = True\n\n        # Return the list of chunks\n        return [os.path.join(self._cache_dir, f\"chunk-{self.rank}-{i}.bin\") for i in range(self._chunk_index)]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self._is_done:\n            return []\n\n        # Write the remaining chunks\n        while not self._should_write():\n            self.write_chunk()\n\n        # Write the index file\n        filepath = self.write_chunks_index()\n\n        # Mark the writing process as done\n        self._is_done = True\n\n        return [filepath]"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self._is_done:\n            return []\n\n        if len(self._serialized_items) > 0:\n            self.write_chunk(on_done=True)\n            self.write_chunks_index()\n\n        self._is_done = True\n        return [os.path.join(self._cache_dir, f\"chunk-{self.rank}-{self._chunk_index}.{self._compression}.bin\")]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self._is_done:\n            return []\n\n        if self._follow_tensor_dimension:\n            while self._should_write():\n                self.write_chunk()\n            self.write_chunk(on_done=True)\n        else:\n            while self._serialized_items:\n                self.write_chunk()\n\n        chunks = self.write_chunks_index()\n        self._is_done = True\n        return chunks\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self._is_done:\n            return []\n\n        # Write any remaining chunks\n        while not self._is_done:\n            self.write_chunk()\n\n        # Write the index file\n        self.write_chunks_index()\n\n        # Mark the writer as done\n        self._is_done = True\n\n        # Return the list of files\n        return [os.path.join(self._cache_dir, f\"chunk-{self.rank}-{i}.bin\") for i in range(self._chunk_index)]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self.filled:\n            return []\n\n        # Write any remaining chunks\n        while self._should_write():\n            self.write_chunk()\n\n        # Write the index\n        filepath = self.write_chunks_index()\n\n        # Mark the writer as done\n        self._is_done = True\n\n        return [filepath]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self.filled:\n            return []\n\n        # Write the last chunk if needed\n        if self._serialized_items:\n            self.write_chunk(on_done=True)\n\n        # Write the chunks index\n        chunks_index_file = self.write_chunks_index()\n\n        # Mark the writer as done\n        self._is_done = True\n\n        return [chunks_index_file]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self._is_done:\n            return []\n\n        # Write remaining chunks\n        while not self._is_done:\n            self.write_chunk()\n\n        # Write the chunks index\n        self.write_chunks_index()\n\n        self._is_done = True\n\n        return [os.path.join(self._cache_dir, f\"{self.rank}.{_INDEX_FILENAME}\")]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self._is_done:\n            return []\n\n        while not self._is_done:\n            self.add_item(self._chunk_index, {})\n\n        # Write the last chunk\n        self.write_chunk(on_done=True)\n\n        # Write the index file\n        filepath = self.write_chunks_index()\n\n        self._is_done = True\n        return [filepath]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        # Check if the writing process is already done\n        if self._is_done:\n            return []\n\n        # Write any remaining chunks to files\n        while not self._is_done:\n            self.write_chunk()\n\n        # Write the index file\n        self.write_chunks_index()\n\n        # Mark the writing process as complete\n        self._is_done = True\n\n        # Return the file paths to the written chunks\n        return [os.path.join(self._cache_dir, filename) for filename in os.listdir(self._cache_dir) if filename.endswith(\".bin\")]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self._is_done:\n            return []\n\n        filepaths = []\n\n        # Write remaining chunks of data\n        while not self._should_write():\n            filepath = self.write_chunk()\n            if filepath:\n                filepaths.append(filepath)\n\n        # Write the index file\n        filepath = self.write_chunks_index()\n        if filepath:\n            filepaths.append(filepath)\n\n        self._is_done = True\n        return filepaths\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self._is_done:\n            return []\n\n        # Write any remaining chunks\n        while not self.filled:\n            self.write_chunk()\n\n        # Write the index file\n        self.write_chunks_index()\n\n        # Mark the writer as done\n        self._is_done = True\n\n        # Return the list of chunks\n        return [os.path.join(self._cache_dir, f\"{self.rank}.{_INDEX_FILENAME}\")]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self.filled:\n            return []\n\n        if self._should_write():\n            self.write_chunk()\n\n        if self._should_write():\n            raise RuntimeError(\"The cache is not large enough to fit the dataset.\")\n\n        while self._should_write():\n            self.write_chunk()\n\n        return [self.write_chunks_index()]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self._is_done:\n            return []\n\n        filepaths = []\n        while not self.filled:\n            filepath = self.write_chunk()\n            if filepath:\n                filepaths.append(filepath)\n            else:\n                sleep(0.01)\n\n        filepath = self.write_chunks_index()\n        if filepath:\n            filepaths.append(filepath)\n\n        self._is_done = True\n        return filepaths\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        # If the writing process is already done, return an empty list.\n        if self._is_done:\n            return []\n\n        # If there are items in the internal buffer, write them to a chunk.\n        if self._serialized_items:\n            self.write_chunk()\n\n        # Write the index file.\n        filepath = self.write_chunks_index()\n\n        # Mark the writing process as complete.\n        self._is_done = True\n\n        return [filepath]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        # If the writing process is already done, return the list of written chunks\n        if self._is_done:\n            return [os.path.join(self._cache_dir, f\"{self.rank}.{_INDEX_FILENAME}\")]\n\n        # If there are items left to be written, write them to a file\n        while len(self._serialized_items) > 0:\n            self.write_chunk()\n\n        # Write the index file\n        filepath = self.write_chunks_index()\n\n        # Mark the writing process as complete\n        self._is_done = True\n\n        # Return the list of written chunks\n        return [filepath]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self._is_done:\n            return []\n\n        while not self._should_write():\n            sleep(1)\n\n        # Write the last chunk\n        self.write_chunk(on_done=True)\n        filepaths = [self.write_chunks_index()]\n\n        # Wait for the last chunk to be written\n        while True:\n            files = os.listdir(self._cache_dir)\n            filepaths.extend([os.path.join(self._cache_dir, f) for f in files if f.endswith(\".bin\")])\n            if len(filepaths) == self._distributed_env.world_size * self._worker_env.world_size:\n                break\n            sleep(1)\n\n        self._is_done = True\n\n        return filepaths\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self._is_done:\n            return []\n\n        # Write any remaining chunks of data to files\n        if self._serialized_items:\n            self.write_chunk(on_done=True)\n\n        # Generate an index file for these chunks\n        self.write_chunks_index()\n\n        # Mark the writing process as complete\n        self._is_done = True\n\n        return [os.path.join(self._cache_dir, f\"chunk-{self.rank}-{i}.bin\") for i in range(self._chunk_index)]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        # TODO: Implement this method\n        if self._is_done:\n            return []\n\n        if self._serialized_items:\n            self.write_chunk(on_done=True)\n\n        if self._is_done:\n            return []\n\n        self._is_done = True\n        return [self.write_chunks_index()]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self._is_done:\n            return []\n\n        while not self._is_done:\n            if self._should_write():\n                self.write_chunk()\n            else:\n                break\n\n        if self._is_done:\n            return []\n\n        self.write_chunk(on_done=True)\n        self._is_done = True\n        return [self.write_chunks_index()]\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.restore = True\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.restore = True\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.restore = True\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.restore = True\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n            self._worker_idx_iter = iter(self._worker_idx)\n            self.restore = True\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n            self._worker_idx_iter = iter(self._worker_idx)\n            self.restore = True\n        else:\n            raise RuntimeError(\n                \"The provided dataset is neither a StreamingDataset nor a CombinedStreamingDataset. The state cannot be loaded.\"\n            )\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.current_epoch = obj[\"current_epoch\"]\n        self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n        self._worker_idx_iter = iter(self._worker_idx)\n        self.restore = True\n\n        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(self._num_samples_yielded_streaming, self.num_workers, self.batch_size)\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            num_samples_yielded = [0 for _ in range(len(list(self._num_samples_yielded_combined.values())[0]))]\n            for worker_idx in self._num_samples_yielded_combined:\n                for dataset_idx, samples_yielded in enumerate(self._num_samples_yielded_combined[worker_idx]):\n                    num_samples_yielded[dataset_idx] += samples_yielded\n            self.dataset.load_state_dict(self.num_workers, self.batch_size, num_samples_yielded)\n        else:\n            raise RuntimeError(\"The provided dataset is neither a StreamingDataset nor a CombinedStreamingDataset.\")\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n            self._worker_idx_iter = iter(self._worker_idx)\n            self.restore = True\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n            self._worker_idx_iter = iter(self._worker_idx)\n            self.restore = True\n        else:\n            raise RuntimeError(\n                \"The provided dataset is not a StreamingDataset or a CombinedStreamingDataset. \"\n                \"This method is designed to be called from a non-worker process when resuming training.\"\n            )\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            assert self.batch_size\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.restore = True\n            self.dataset.load_state_dict(\n                obj[\"dataset\"], self.num_workers, self.batch_size, self._num_samples_yielded_streaming\n            )\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.current_epoch = obj[\"current_epoch\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self.restore = True\n            self.dataset.load_state_dict(\n                obj[\"dataset\"], self.num_workers, self.batch_size, self._num_samples_yielded_combined\n            )\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n            )\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.current_epoch = obj[\"current_epoch\"]\n        self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n        self._worker_idx_iter = iter(self._worker_idx)\n\n        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(\n                obj[\"dataset\"], self.num_workers, self.batch_size, self._num_samples_yielded_streaming\n            )\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            for dataset_idx in range(len(self.dataset.datasets)):\n                self.dataset.datasets[dataset_idx].load_state_dict(\n                    obj[\"dataset\"][dataset_idx],\n                    self.num_workers,\n                    self.batch_size,\n                    self._num_samples_yielded_combined[dataset_idx],\n                )\n        else:\n            raise RuntimeError(\"The provided dataset is not supported by the StreamingDataLoader.\")\n\n        self.restore = True\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            assert self.batch_size\n            self.dataset.load_state_dict(obj[\"dataset\"], self.num_workers, self.batch_size)\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n            self._worker_idx_iter = iter(self._worker_idx)\n            self.restore = True\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"], self.num_workers, self.batch_size)\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n            self._worker_idx_iter = iter(self._worker_idx)\n            self.restore = True\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n            )\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.restore = True\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.current_epoch = obj[\"current_epoch\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.restore = True\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            assert self.batch_size\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.dataset.load_state_dict(\n                self._num_samples_yielded_streaming, self.num_workers, self.batch_size\n            )\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.dataset._set_use_streaming_dataloader(True)\n            for dataset in self.dataset.datasets:\n                if isinstance(dataset, StreamingDataset):\n                    dataset.load_state_dict(self.num_workers, self.batch_size, self._num_samples_yielded_combined)\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )\n\n        self.restore = True\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            assert self.batch_size\n            self.dataset.load_state_dict(\n                obj[\"dataset\"], self.num_workers, self.batch_size, obj[\"num_samples_yielded\"]\n            )\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n            self._worker_idx_iter = iter(self._worker_idx)\n            self.restore = True\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"], self.num_workers)\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n            self._worker_idx_iter = iter(self._worker_idx)\n            self.restore = True\n        else:\n            raise RuntimeError(\n                \"The provided dataset is not a StreamingDataset or a CombinedStreamingDataset. The load_state_dict method is designed to be called from a non-worker process.\"\n            )\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"], self.num_workers, self.batch_size)\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"], self.num_workers, self.batch_size)\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )\n\n        self.restore = True\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.restore = True\n        self.current_epoch = obj[\"current_epoch\"]\n        self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n\n        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(self._num_samples_yielded_streaming, self.num_workers, self.batch_size)\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            for dataset in self.dataset.datasets:\n                if isinstance(dataset, StreamingDataset):\n                    dataset.load_state_dict(\n                        self._num_samples_yielded_combined[id(dataset)], self.num_workers, self.batch_size\n                    )\n        else:\n            raise RuntimeError(\n                \"The dataset type is not supported. Please provide a StreamingDataset or a CombinedStreamingDataset.\"\n            )\n\n        self._iterator = iter(self)\n        self._sampler_iter = iter(self._sampler)\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            assert self.batch_size\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n            self._worker_idx_iter = iter(self._worker_idx)\n            self.dataset.load_state_dict(\n                self._num_samples_yielded_streaming, self.num_workers, self.batch_size\n            )\n            self.restore = True\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n            self._worker_idx_iter = iter(self._worker_idx)\n            self.dataset.load_state_dict(self.num_workers, self.batch_size, self._num_samples_yielded_combined)\n            self.restore = True\n        else:\n            raise RuntimeError(\"The dataset is neither a StreamingDataset nor a CombinedStreamingDataset.\")\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            assert self.batch_size\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n            self._worker_idx_iter = iter(self._worker_idx)\n            self.dataset.load_state_dict(\n                self._num_samples_yielded_streaming, self.num_workers, self.batch_size\n            )\n\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.current_epoch = obj[\"current_epoch\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n            self._worker_idx_iter = iter(self._worker_idx)\n            self.dataset.load_state_dict(self.num_workers, self.batch_size, self._num_samples_yielded_combined)\n\n        else:\n            raise RuntimeError(\n                \"The provided dataset is neither a StreamingDataset nor a CombinedStreamingDataset. \"\n                \"The StreamingDataLoader does not support loading state for these datasets.\"\n            )\n\n        self.restore = True\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            assert self.batch_size\n            self.dataset.load_state_dict(obj[\"dataset\"], self.num_workers, self.batch_size)\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n            self._worker_idx_iter = iter(self._worker_idx)\n            self.restore = True\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"], self.num_workers, self.batch_size)\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.restore = True\n        else:\n            raise RuntimeError(\n                \"The provided dataset is neither a StreamingDataset nor a CombinedStreamingDataset. \"\n                \"Cannot load the state.\"\n            )\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.restore = True\n        self.current_epoch = obj[\"current_epoch\"]\n        self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n\n        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(\n                self._num_samples_yielded_streaming, self.num_workers, self.batch_size\n            )\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            for dataset_idx, dataset in enumerate(self.dataset.datasets):\n                if dataset_idx in self._num_samples_yielded_combined:\n                    dataset.load_state_dict(\n                        self.num_workers, self.batch_size, self._num_samples_yielded_combined[dataset_idx]\n                    )\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )\n\n        self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n        self._worker_idx_iter = iter(self._worker_idx)\n\n        # Prepare the DataLoader for resuming by adjusting internal iterators and flags.\n        if self.num_workers == 0:\n            self._sampler_iter = iter(self._sampler)\n        else:\n            self._rcvd_idx = 0\n            self._reorder_dict = {}\n            self._task_info = {}\n            self._tasks_outstanding = 0\n            self._workers_status = [True] * self.num_workers\n            self._worker_result_queue = self._make_results_queue()\n            self._worker_error_queue ="}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"], self.num_workers, self.batch_size)\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n            self._worker_idx_iter = iter(self._worker_idx)\n            self.restore = True\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"], self.num_workers, self.batch_size)\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n            self._worker_idx_iter = iter(self._worker_idx)\n            self.restore = True\n        else:\n            raise RuntimeError(\n                \"The provided dataset is neither a StreamingDataset or a CombinedStreamingDataset.\"\n                \" Please use a different method to load the state.\"\n            )\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            assert self.batch_size\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.dataset.load_state_dict(self._num_samples_yielded_streaming, self.num_workers, self.batch_size)\n            self.restore = True\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.dataset._set_use_streaming_dataloader(True)\n            self.dataset.load_state_dict(self.num_workers, self.batch_size, obj[\"num_samples_yielded\"])\n            self.restore = True\n        else:\n            raise RuntimeError(\"The provided dataset is neither a StreamingDataset nor a CombinedStreamingDataset.\")\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            assert self.batch_size\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.restore = True\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.restore = True\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        else:\n            raise RuntimeError(\"The provided dataset is not supported.\")\n\n        self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n        self._worker_idx_iter = iter(self._worker_idx)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                return {__NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded}\n        else:\n            return self._iterator.state_dict(num_workers, batch_size, num_samples_yielded)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                num_samples_yielded = num_samples_yielded\n        else:\n            num_samples_yielded = self._iterator.num_samples_yielded\n\n        state_dict = {\n            __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n            __SAMPLES_KEY__: [\n                dataset.state_dict(num_workers, batch_size) for dataset in self._datasets\n            ],\n        }\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is not None:\n                return {\n                    __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                    __SAMPLES_KEY__: [d.state_dict(num_workers, batch_size) for d in self._datasets],\n                }\n            else:\n                return {}\n        else:\n            return self._iterator.state_dict()\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        state = {}\n        if self._iterator is None:\n            if num_samples_yielded is None:\n                return state\n            else:\n                state[__NUM_SAMPLES_YIELDED_KEY__] = num_samples_yielded\n                return state\n\n        state[__NUM_SAMPLES_YIELDED_KEY__] = self._iterator.num_samples_yielded\n        state[__SAMPLES_KEY__] = self._iterator.samples\n        state[__NUM_WORKERS_KEY__] = num_workers\n        state[__BATCH_SIZE_KEY__] = batch_size\n        return state\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                self._num_samples_yielded = num_samples_yielded\n\n        return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if self._iterator is None:\n            return {\n                __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                __SAMPLES_KEY__: [\n                    dataset.state_dict(num_workers, batch_size)\n                    for dataset in self._datasets\n                ],\n            }\n\n        return self._iterator.state_dict()\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                return {__NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded}\n        else:\n            return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                self._num_samples_yielded = num_samples_yielded\n\n        state_dict = {}\n        state_dict[__NUM_SAMPLES_YIELDED_KEY__] = self._iterator.num_samples_yielded\n        state_dict[__SAMPLES_KEY__] = self._iterator.samples\n        return state_dict\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if self._iterator is None:\n            state_dict = {\n                __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                __SAMPLES_KEY__: [0] * len(self._datasets),\n            }\n        else:\n            state_dict = self._iterator.state_dict(num_workers, batch_size)\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is not None:\n                return {__NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded}\n            else:\n                return {}\n        else:\n            return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                self._num_samples_yielded = num_samples_yielded\n\n        return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if self._iterator is not None:\n            return self._iterator.state_dict(num_workers, batch_size)\n\n        assert num_samples_yielded is not None\n\n        return {\n            __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n            __SAMPLES_KEY__: [d.state_dict(num_workers, batch_size) for d in self._datasets],\n        }\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        state_dict = {}\n        if self._iterator is None and num_samples_yielded is None:\n            return state_dict\n\n        if self._iterator is not None:\n            state_dict = self._iterator.state_dict()\n        else:\n            state_dict = {\n                __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                __SAMPLES_KEY__: [\n                    {\n                        \"dataset_id\": dataset_id,\n                        \"dataset_state_dict\": dataset.state_dict(num_workers, batch_size),\n                    }\n                    for dataset_id, dataset in enumerate(self._datasets)\n                ],\n            }\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                self._num_samples_yielded = num_samples_yielded\n\n        return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                self._num_samples_yielded = num_samples_yielded\n\n        if self._iterator is not None:\n            return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                self._num_samples_yielded = num_samples_yielded\n\n        return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                num_samples_yielded = num_samples_yielded\n        else:\n            num_samples_yielded = self._iterator.num_samples_yielded\n\n        state_dict = {\n            __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n            __SAMPLES_KEY__: [\n                dataset.state_dict(num_workers, batch_size) for dataset in self._datasets\n            ],\n        }\n        return state_dict\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                self._num_samples_yielded = num_samples_yielded\n\n        return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                num_samples_yielded = num_samples_yielded\n        else:\n            num_samples_yielded = self._iterator.num_samples_yielded\n\n        state = {\n            __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n            __SAMPLES_KEY__: [\n                {\n                    \"num_samples_yielded\": num_samples_yielded[i],\n                    \"samples\": self._datasets[i].state_dict(num_workers, batch_size),\n                }\n                for i in range(len(self._datasets))\n            ],\n        }\n\n        return state\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        # Return an empty state dict if the internal iterator is None and `num_samples_yielded` is not provided.\n        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        # Return the state dict from the internal iterator if it is not None.\n        if self._iterator is not None:\n            return self._iterator.state_dict(num_workers, batch_size)\n\n        # Return a state dict based on `num_samples_yielded` if it is provided.\n        assert num_samples_yielded is not None\n\n        return {\n            __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n            __SAMPLES_KEY__: [\n                dataset.state_dict(num_workers, batch_size) for dataset in self._datasets\n            ],\n        }\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if not self._use_streaming_dataloader:\n            return\n\n        if not state_dict:\n            return\n\n        if self._iterator is None:\n            self._num_samples_yielded = state_dict.get(__NUM_SAMPLES_YIELDED_KEY__)\n            return\n\n        self._iterator.load_state_dict(state_dict)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            if __NUM_SAMPLES_YIELDED_KEY__ in state_dict:\n                self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n            return\n        self._iterator.load_state_dict(state_dict)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            if state_dict:\n                self._num_samples_yielded = state_dict.get(__NUM_SAMPLES_YIELDED_KEY__, None)\n            return\n        self._iterator.load_state_dict(state_dict)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            if __NUM_SAMPLES_YIELDED_KEY__ in state_dict:\n                self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n            return\n\n        self._iterator.load_state_dict(state_dict)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if not state_dict:\n            return\n\n        if self._num_samples_yielded is None:\n            self._num_samples_yielded = [0] * len(self._datasets)\n\n        num_samples_yielded = state_dict.get(__NUM_SAMPLES_YIELDED_KEY__, None)\n        if num_samples_yielded is not None:\n            self._num_samples_yielded = num_samples_yielded\n\n        for i, dataset in enumerate(self._datasets):\n            dataset.load_state_dict(state_dict.get(__SAMPLES_KEY__ + str(i), {}))\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if not state_dict:\n            return\n\n        if self._iterator is not None:\n            self._iterator.load_state_dict(state_dict)\n            return\n\n        self._num_samples_yielded = state_dict.get(__NUM_SAMPLES_YIELDED_KEY__)\n        self._check_num_samples_yielded(self._num_samples_yielded)\n\n        for dataset, num_samples_yielded in zip(self._datasets, self._num_samples_yielded):\n            dataset.load_state_dict(state_dict[__SAMPLES_KEY__][num_samples_yielded])\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if not state_dict:\n            return\n\n        if self._iterator is not None:\n            self._iterator.load_state_dict(state_dict)\n\n        for dataset in self._datasets:\n            dataset.load_state_dict(state_dict)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if not state_dict:\n            return\n\n        if self._num_samples_yielded is None:\n            self._num_samples_yielded = [0] * len(self._datasets)\n\n        for dataset in self._datasets:\n            dataset.load_state_dict(state_dict)\n\n        num_samples_yielded = state_dict.get(__NUM_SAMPLES_YIELDED_KEY__)\n        if num_samples_yielded is not None:\n            self._num_samples_yielded = num_samples_yielded\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if not state_dict:\n            return\n\n        for dataset_idx, dataset in enumerate(self._datasets):\n            dataset.load_state_dict(state_dict[f\"dataset_{dataset_idx}\"])\n\n        if not self._use_streaming_dataloader:\n            return\n\n        num_samples_yielded = state_dict.get(__NUM_SAMPLES_YIELDED_KEY__, None)\n        if num_samples_yielded is not None:\n            self._num_samples_yielded = num_samples_yielded\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if not state_dict:\n            return\n\n        self._num_samples_yielded = state_dict.get(__NUM_SAMPLES_YIELDED_KEY__)\n        if self._num_samples_yielded is None:\n            return\n\n        self._check_datasets(self._datasets)\n        for dataset in self._datasets:\n            dataset.load_state_dict(state_dict[__SAMPLES_KEY__][dataset.name])\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if not self._use_streaming_dataloader:\n            return\n\n        if state_dict:\n            self._num_samples_yielded = state_dict.get(__NUM_SAMPLES_YIELDED_KEY__)\n            for dataset in self._datasets:\n                dataset.load_state_dict(state_dict.get(dataset.name))\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if not self._use_streaming_dataloader:\n            return\n\n        if not state_dict:\n            return\n\n        self._num_samples_yielded = state_dict.get(__NUM_SAMPLES_YIELDED_KEY__)\n        samples = state_dict.get(__SAMPLES_KEY__)\n\n        if samples is not None:\n            for dataset, sample in zip(self._datasets, samples):\n                dataset.load_state_dict(sample)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            return\n        self._iterator.load_state_dict(state_dict)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if not state_dict:\n            return\n\n        if self._iterator is not None:\n            self._iterator.load_state_dict(state_dict)\n        else:\n            self._num_samples_yielded = state_dict.get(__NUM_SAMPLES_YIELDED_KEY__)\n\n        for dataset in self._datasets:\n            dataset.load_state_dict(state_dict)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            self._num_samples_yielded = state_dict.get(__NUM_SAMPLES_YIELDED_KEY__)\n            for dataset in self._datasets:\n                dataset.load_state_dict(state_dict[__SAMPLES_KEY__][dataset.name])\n        else:\n            self._iterator.load_state_dict(state_dict)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if not isinstance(state_dict, dict):\n            raise TypeError(\n                f\"The state_dict argument must be of type dict, but is of type {type(state_dict)}.\"\n            )\n\n        if self._iterator is None:\n            if __NUM_SAMPLES_YIELDED_KEY__ in state_dict:\n                self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n            else:\n                self._num_samples_yielded = None\n        else:\n            self._iterator.load_state_dict(state_dict)\n\n        for dataset in self._datasets:\n            dataset.set_epoch(self._current_epoch)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if not isinstance(state_dict, dict):\n            raise TypeError(f\"State dict must be a dictionary but is {type(state_dict)}\")\n\n        if not self._datasets:\n            raise ValueError(\"No datasets available for state restoration\")\n\n        if not self._iterator:\n            raise RuntimeError(\"The iterator has not been initialized\")\n\n        if len(state_dict) == 0:\n            return\n\n        if __NUM_SAMPLES_YIELDED_KEY__ not in state_dict:\n            raise ValueError(\"Missing key: '__NUM_SAMPLES_YIELDED__'\")\n\n        if __SAMPLES_KEY__ not in state_dict:\n            raise ValueError(\"Missing key: '__SAMPLES__'\")\n\n        if len(state_dict[__SAMPLES_KEY__]) != len(self._datasets):\n            raise ValueError(\n                f\"Expected {len(self._datasets)} samples but got {len(state_dict[__SAMPLES_KEY__])}\"\n            )\n\n        if len(state_dict[__NUM_SAMPLES_YIELDED_KEY__]) != len(self._datasets):\n            raise ValueError(\n                f\"Expected {len(self._datasets)} num_samples_yielded but got {len(state_dict[__NUM_SAMPLES_YIELDED_KEY__])}\"\n            )\n\n        self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n        self._iterator.load_state_dict(state_dict)\n\n        for dataset_idx, dataset in enumerate(self._datasets):\n            dataset.set_epoch(self._current_epoch)\n            dataset.set_shuffle(False)\n            dataset.set_num_samples_yielded(self._num_samples_yielded[dataset_idx])\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            if state_dict:\n                self._num_samples_yielded = state_dict.get(__NUM_SAMPLES_YIELDED_KEY__)\n                for dataset in self._datasets:\n                    dataset.load_state_dict(state_dict[__SAMPLES_KEY__][dataset.name])\n            return\n        self._iterator.load_state_dict(state_dict)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            raise RuntimeError(\n                \"The CombinedStreamingDataset must be iterated before its state_dict can be loaded.\"\n            )\n        self._iterator.load_state_dict(state_dict)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            return\n\n        self._iterator.load_state_dict(state_dict)\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if not isinstance(dir_path, str):\n        raise ValueError(f\"Invalid directory path type: {type(dir_path)}\")\n\n    dir_path = dir_path.strip()\n\n    if not dir_path:\n        return Dir()\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"/\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"gs://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"https://studio.lightning.net\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"https://app.lightning.net\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"https://studio.lightning.com\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"https://app.lightning.com\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"https://studio.lightning.fast.app\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"https://app.lightning.fast.app\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"https://studio.lightning.dev\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"https://app.lightning.dev\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"https://studio.lightning.fast.pro\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"https://app.lightning.fast.pro\"):\n        return Dir(url=dir_path"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    dir_path = dir_path.strip()\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(path=None, url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=None, url=dir_path)\n\n    if dir_path.startswith(\"/\"):\n        return Dir(path=dir_path, url=None)\n\n    if dir_path.startswith(\"~\"):\n        return Dir(path=os.path.expanduser(dir_path), url=None)\n\n    if dir_path.startswith(\"$\"):\n        return Dir(path=os.path.expandvars(dir_path), url=None)\n\n    if dir_path.startswith(\"${\"):\n        return Dir(path=os.path.expandvars(dir_path), url=None)\n\n    if dir_path.startswith(\"file://\"):\n        return Dir(path=parse.unquote(parse.urlparse(dir_path).path), url=None)\n\n    if dir_path.startswith(\"https://studio.lightning.net/\") or dir_path.startswith(\"https://studio.lightning.ai/\"):\n        return Dir(path=None, url=dir_path)\n\n    if dir_path.startswith(\"https://app.lightning.net/\") or dir_path.startswith(\"https://app.lightning.ai/\"):\n        return Dir(path=None, url=dir_path)\n\n    if dir_path.startswith(\"https://studio.lightning.com/\"):\n        return Dir(path=None, url=dir_path)\n\n    if dir_path.startswith(\"https://app.lightning.com/\"):\n        return Dir(path=None, url=dir_path)\n\n    if dir_path.startswith(\"https://studio.lightning.fast.app/\"):\n        return Dir(path=None, url"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, str):\n        dir_path = Dir(dir_path)\n\n    # If the dir_path is a URL, return it as is.\n    if dir_path.url is not None:\n        return dir_path\n\n    # If the dir_path is a local path, return it as is.\n    if dir_path.path is not None and dir_path.path.startswith(\"/\"):\n        return dir_path\n\n    # If the dir_path is a local path, return it as is.\n    if dir_path.path is not None and dir_path.path.startswith(\"\\\\\"):\n        return dir_path\n\n    # If the dir_path is a local path, return it as is.\n    if dir_path.path is not None and not dir_path.path.startswith(\"/\"):\n        return dir_path\n\n    # If the dir_path is a local path, return it as is.\n    if dir_path.path is not None and not dir_path.path.startswith(\"\\\\\"):\n        return dir_path\n\n    # If the dir_path is a project path, return it as is.\n    if dir_path.path is not None and dir_path.path.startswith(\"project://\"):\n        return dir_path\n\n    # If the dir_path is a S3 URL, return it as is.\n    if dir_path.path is not None and dir_path.path.startswith(\"s3://\"):\n        return dir_path\n\n    # If the dir_path is a S3 URL, return it as is.\n    if dir_path.path is not None and dir_path.path.startswith(\"https://\"):\n        return dir_path\n\n    # If the dir_path is a S3 URL, return it as is.\n    if dir_path.path is not None and dir_path.path.startswith(\"http://\"):\n        return dir_path\n\n    # If the dir_path is a S3 URL, return it as is.\n    if dir"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    # Check if the input directory path is a Dir object. If so, return it.\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    # If the input directory path is None, return an empty Dir object.\n    if dir_path is None:\n        return Dir()\n\n    # If the input directory path is a string, check if it is a local path or a URL.\n    if isinstance(dir_path, str):\n\n        # If the input directory path is a local path, return a Dir object with the path set to the local path.\n        if os.path.exists(dir_path):\n            return Dir(path=dir_path)\n\n        # If the input directory path is a URL, return a Dir object with the URL set to the URL.\n        if dir_path.startswith(\"http\"):\n            return Dir(url=dir_path)\n\n        # If the input directory path is a Lightning project path, return a Dir object with the URL set to the URL.\n        if dir_path.startswith(\"lightning://\"):\n            return Dir(url=dir_path)\n\n        # If the input directory path is a S3 URL, return a Dir object with the URL set to the URL.\n        if dir_path.startswith(\"s3://\"):\n            return Dir(url=dir_path)\n\n        # If the input directory path is a S3 URL, return a Dir object with the URL set to the URL.\n        if dir_path.startswith(\"gs://\"):\n            return Dir(url=dir_path)\n\n        # If the input directory path is a S3 URL, return a Dir object with the URL set to the URL.\n        if dir_path.startswith(\"az://\"):\n            return Dir(url=dir_path)\n\n        # If the input directory path is a S3 URL, return a Dir object with the URL set to the URL.\n        if dir_path.startswith(\"sftp://\"):\n            return Dir(url=dir_path)\n\n        # If the input directory path is a S3 URL, return a Dir object with the URL set to the URL.\n       "}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    # If the input is a Dir object, return it as is.\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    # If the input is a string, create a new Dir object and return it.\n    if isinstance(dir_path, str):\n        return Dir(dir_path)\n\n    # If the input is None, return an empty Dir object.\n    if dir_path is None:\n        return Dir()\n\n    # If the input is not a string or a Dir object, raise an error.\n    raise TypeError(f\"dir_path must be of type str or Dir, not {type(dir_path)}\")\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    dir_path = dir_path.strip()\n\n    # If the path is a URL, return it as the URL and leave the path unset.\n    if dir_path.startswith(\"s3://\") or dir_path.startswith(\"https://\"):\n        return Dir(url=dir_path)\n\n    # If the path is a local path, return it as the path and leave the URL unset.\n    if os.path.exists(dir_path):\n        return Dir(path=dir_path)\n\n    # If the path is a project path, return it as the path and set the URL to the project's default bucket.\n    if dir_path.startswith(\"projects/\"):\n        return Dir(path=dir_path, url=f\"s3://{dir_path}\")\n\n    # If the path is a relative path, return it as the path and set the URL to the default bucket.\n    if dir_path.startswith(\"./\") or dir_path.startswith(\"../\"):\n        return Dir(path=dir_path, url=f\"s3://{dir_path}\")\n\n    # If the path is a bucket path, return it as the path and set the URL to the default bucket.\n    if dir_path.startswith(\"s3://\"):\n        return Dir(path=dir_path, url=f\"s3://{dir_path}\")\n\n    # If the path is a relative path, return it as the path and set the URL to the default bucket.\n    if dir_path.startswith(\"/\"):\n        return Dir(path=dir_path, url=f\"s3://{dir_path}\")\n\n    # If the path is a relative path, return it as the path and set the URL to the default bucket.\n    if dir_path.startswith(\"~/\"):\n        return Dir(path=dir_path, url=f\"s3://{dir_path}\")\n\n    # If the path is a relative path, return it as the path and set the URL"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    # Resolve the directory path into a Dir object.\n    if isinstance(dir_path, str):\n\n        # Parse the directory path.\n        parsed_dir_path = parse.urlparse(dir_path)\n\n        # If the directory path is a local path, return a Dir object with the local path.\n        if parsed_dir_path.scheme == \"\":\n            return Dir(path=dir_path)\n\n        # If the directory path is an S3 URL, return a Dir object with the S3 URL.\n        elif parsed_dir_path.scheme == \"s3\":\n            return Dir(url=dir_path)\n\n        # If the directory path is a project path, return a Dir object with the project path.\n        elif parsed_dir_path.scheme == \"lightning\" and parsed_dir_path.netloc == \"studio\":\n            return Dir(path=parsed_dir_path.path)\n\n        # If the directory path is a project path, return a Dir object with the project path.\n        elif parsed_dir_path.scheme == \"lightning\" and parsed_dir_path.netloc == \"cloud\":\n            return Dir(url=dir_path)\n\n        # If the directory path is a project path, return a Dir object with the project path.\n        elif parsed_dir_path.scheme == \"lightning\" and parsed_dir_path.netloc == \"\":\n            return Dir(path=parsed_dir_path.path)\n\n        # If the directory path is a project path, return a Dir object with the project path.\n        elif parsed_dir_path.scheme == \"lightning\":\n            return Dir(path=parsed_dir_path.path)\n\n        # If the directory path is a project path, return a Dir object with the project path.\n        elif parsed_dir_path.scheme == \"file\":\n            return Dir(path=parsed_dir_path.path)\n\n        # If the directory path is a project path, return a Dir object with the project path.\n        elif parsed_dir_path.scheme == \"https\":\n            return Dir(url=dir_path)"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, str):\n        dir_path = dir_path.strip()\n\n        if dir_path.startswith(\"s3://\"):\n            return Dir(url=dir_path)\n\n        if dir_path.startswith(\"/\"):\n            return Dir(path=dir_path)\n\n        if dir_path.startswith(\"projects://\"):\n            dir_path = dir_path.replace(\"projects://\", \"\")\n            dir_path = dir_path.replace(\"/\", os.path.sep)\n            return Dir(path=dir_path)\n\n        if dir_path.startswith(\"project://\"):\n            dir_path = dir_path.replace(\"project://\", \"\")\n            dir_path = dir_path.replace(\"/\", os.path.sep)\n            return Dir(path=dir_path)\n\n        if dir_path.startswith(\"file://\"):\n            dir_path = dir_path.replace(\"file://\", \"\")\n            dir_path = dir_path.replace(\"/\", os.path.sep)\n            return Dir(path=dir_path)\n\n        if dir_path.startswith(\"file://\"):\n            dir_path = dir_path.replace(\"file://\", \"\")\n            dir_path = dir_path.replace(\"/\", os.path.sep)\n            return Dir(path=dir_path)\n\n        return Dir(path=dir_path)\n\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    raise ValueError(f\"Invalid dir_path type: {type(dir_path)}\")\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n    if dir_path is None:\n        return Dir()\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n    if dir_path.startswith(\"http://\") or dir_path.startswith(\"https://\"):\n        return Dir(url=dir_path)\n    if dir_path.startswith(\"/\"):\n        return Dir(path=dir_path)\n    if dir_path.startswith(\"~/\") or dir_path.startswith(\"~/\"):\n        return Dir(path=os.path.expanduser(dir_path))\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path.replace(\"lightning://\", \"\"))\n    if dir_path.startswith(\"lightning-studio://\"):\n        return Dir(path=dir_path.replace(\"lightning-studio://\", \"\"))\n    if dir_path.startswith(\"lightning-hub://\"):\n        return Dir(path=dir_path.replace(\"lightning-hub://\", \"\"))\n    if dir_path.startswith(\"lightning-cloud://\"):\n        return Dir(path=dir_path.replace(\"lightning-cloud://\", \"\"))\n    if dir_path.startswith(\"lightning-local://\"):\n        return Dir(path=dir_path.replace(\"lightning-local://\", \"\"))\n    if dir_path.startswith(\"lightning-data://\"):\n        return Dir(path=dir_path.replace(\"lightning-data://\", \"\"))\n    if dir_path.startswith(\"lightning-models://\"):\n        return Dir(path=dir_path.replace(\"lightning-models://\", \"\"))\n    if dir_path.startswith(\"lightning-artifacts://\"):\n        return Dir(path=dir_path.replace(\"lightning-artifacts://\", \"\"))\n    if dir_path.startswith(\"lightning-outputs://\"):\n        return Dir(path=dir_path.replace(\"lightning-outputs://\","}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n    elif isinstance(dir_path, Dir):\n        return dir_path\n    else:\n        dir_path = str(dir_path)\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n    elif dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n    elif dir_path.startswith(\"https://studio.lightning.net/projects/\"):\n        return Dir(url=dir_path)\n    elif dir_path.startswith(\"/\"):\n        return Dir(path=dir_path)\n    else:\n        return Dir(path=os.path.join(os.getcwd(), dir_path))\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    # If dir_path is already a Dir object, just return it.\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    # If dir_path is None, return an empty Dir object.\n    if dir_path is None:\n        return Dir()\n\n    # If dir_path is a string, create a new Dir object and set its path attribute to dir_path.\n    if isinstance(dir_path, str):\n        dir = Dir()\n        dir.path = dir_path\n        return dir\n\n    raise ValueError(f\"Invalid dir_path type: {type(dir_path)}\")\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    dir_path = dir_path.strip()\n\n    if not dir_path:\n        return Dir()\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"file://\"):\n        return Dir(path=parse.unquote(parse.urlparse(dir_path).path))\n\n    if dir_path.startswith(\"http://\") or dir_path.startswith(\"https://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"/\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"~\"):\n        return Dir(path=os.path.expanduser(dir_path))\n\n    if dir_path.startswith(\"$\"):\n        return Dir(path=os.path.expandvars(dir_path))\n\n    if dir_path.startswith(\".\"):\n        return Dir(path=os.path.abspath(dir_path))\n\n    if dir_path.startswith(\"..\"):\n        return Dir(path=os.path.abspath(dir_path))\n\n    if dir_path.startswith(\"\\\\\"):\n        return Dir(path=os.path.abspath(dir_path))\n\n    if dir_path.startswith(\"lightning-studio://\"):\n        return Dir(path=_get_project_path(dir_path))\n\n    return Dir(path=dir_path)\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if not dir_path:\n        return Dir()\n\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"/\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"~\"):\n        return Dir(path=os.path.expanduser(dir_path))\n\n    if dir_path.startswith(\".\"):\n        return Dir(path=os.path.join(os.getcwd(), dir_path))\n\n    if dir_path.startswith(\"$\"):\n        return Dir(path=os.getenv(dir_path.replace(\"$\", \"\")))\n\n    if dir_path.startswith(\"lightning-\"):\n        return Dir(path=os.path.join(os.getenv(\"LIGHTNING_HOME\"), dir_path))\n\n    if dir_path.startswith(\"~/\"):\n        return Dir(path=os.path.expanduser(dir_path))\n\n    if dir_path.startswith(\"$/\"):\n        return Dir(path=os.path.join(os.getenv(\"LIGHTNING_HOME\"), dir_path.replace(\"$/\", \"\")))\n\n    return Dir(path=dir_path)\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    # If the input is already a Dir object, return it.\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    # If the input is None, return an empty Dir object.\n    if dir_path is None:\n        return Dir()\n\n    # If the input is a string, create a Dir object with the string as its path.\n    if isinstance(dir_path, str):\n        return Dir(path=dir_path)\n\n    # If the input is not a string, raise an error.\n    raise ValueError(f\"Invalid directory path: {dir_path}\")\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    # Check if dir_path is a local path.\n    if os.path.exists(dir_path):\n        return Dir(path=dir_path)\n\n    # Check if dir_path is a S3 URL.\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n\n    # Check if dir_path is a project path.\n    if dir_path.startswith(\"projects://\"):\n        return Dir(url=dir_path)\n\n    # Check if dir_path is a project path.\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    # Check if dir_path is a local path.\n    if os.path.exists(dir_path):\n        return Dir(path=dir_path)\n\n    # Check if dir_path is a S3 URL.\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n\n    raise ValueError(f\"Invalid dir_path: {dir_path}\")\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n    elif isinstance(dir_path, Dir):\n        return dir_path\n    else:\n        dir_path = dir_path.strip()\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n    elif dir_path.startswith(\"https://studio.lightning.net/\"):\n        return Dir(url=dir_path)\n    elif dir_path.startswith(\"/\"):\n        return Dir(path=dir_path)\n    elif dir_path.startswith(\"projects/\"):\n        return Dir(path=f\"/data/projects/{dir_path}\")\n    elif dir_path.startswith(\"shared/\"):\n        return Dir(path=f\"/data/shared/{dir_path}\")\n    else:\n        return Dir(path=f\"/data/projects/projects/{dir_path}\")\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    dir_path = dir_path.strip()\n\n    if dir_path == \"\":\n        return Dir()\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"https://studio.lightning.net/projects/\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"projects/\"):\n        dir_path = dir_path.replace(\"projects/\", \"\")\n\n    if dir_path.startswith(\"lightning-\"):\n        dir_path = dir_path.replace(\"lightning-\", \"\")\n\n    if dir_path.startswith(\"~\"):\n        dir_path = os.path.expanduser(dir_path)\n\n    if dir_path.startswith(\"./\"):\n        dir_path = dir_path.replace(\"./\", \"\")\n\n    if dir_path.startswith(\"/\"):\n        dir_path = dir_path.replace(\"/\", \"\")\n\n    if dir_path.startswith(\".\"):\n        dir_path = dir_path.replace(\".\", \"\")\n\n    return Dir(path=dir_path)\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    dir = Dir()\n    if dir_path is None:\n        return dir\n    if isinstance(dir_path, str):\n        dir.path = dir_path\n        if dir_path.startswith(\"s3://\"):\n            dir.url = dir_path\n    elif isinstance(dir_path, Dir):\n        dir.path = dir_path.path\n        dir.url = dir_path.url\n    return dir\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if not dir_path:\n        return Dir()\n\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if not isinstance(dir_path, str):\n        raise TypeError(f\"dir_path must be a str, not {type(dir_path)}\")\n\n    # Handle S3 URLs.\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n\n    # Handle project paths.\n    if dir_path == \"local\":\n        return Dir(path=\".\")\n\n    if dir_path == \"local-input\":\n        return Dir(path=os.getenv(\"AWS_BATCH_JOB_MAIN_FILE_S3_LOCATION\", \".\"))\n\n    if dir_path == \"local-output\":\n        return Dir(path=os.getenv(\"AWS_BATCH_JOB_MAIN_OUTPUT_FILE_S3_LOCATION\", \".\"))\n\n    # Handle local paths.\n    if os.path.isdir(dir_path):\n        return Dir(path=dir_path)\n\n    raise ValueError(f\"Invalid dir_path: {dir_path}\")\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    # Check if the input is a Dir object.\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    # Handle the case where the path is None.\n    if dir_path is None:\n        return Dir()\n\n    # Handle the case where the path is a string.\n    if isinstance(dir_path, str):\n\n        # Handle the case where the path is an S3 URL.\n        if dir_path.startswith(\"s3://\"):\n            return Dir(url=dir_path)\n\n        # Handle the case where the path is a project path.\n        if dir_path.startswith(\"projects/\"):\n            return Dir(url=f\"https://studio.lightning.bolt.ai/{dir_path}\")\n\n        # Handle the case where the path is a local path.\n        return Dir(path=dir_path)\n\n    # Handle the case where the path is not a string or Dir object.\n    raise TypeError(f\"dir_path must be a str or Dir, not {type(dir_path)}\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"The output directory must be a `Dir` object, but got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The output directory must be an S3 bucket, but got: {output_dir}\")\n\n    if not append and not overwrite:\n        if _dir_exists(output_dir):\n            raise ValueError(f\"The output directory already exists. Please set `append` or `overwrite` to True.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise TypeError(f\"The `output_dir` must be a Dir object, got: {type(output_dir)}\")\n\n    if not output_dir.path.startswith(\"s3://\"):\n        raise ValueError(f\"The `output_dir` must be an S3 directory, got: {output_dir.path}\")\n\n    if append:\n        raise NotImplementedError(\"Appending data to the directory is not supported yet.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in the directory is not supported yet.\")\n\n    if _is_dir_empty(output_dir):\n        return\n\n    raise RuntimeError(f\"The directory {output_dir.path} already contains data. Please use a different directory.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"The `output_dir` must be a `Dir` object, got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The `output_dir` must be an S3 directory, got: {output_dir}\")\n\n    if append:\n        raise NotImplementedError(\"Appending data to an S3 directory is not supported yet.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in an S3 directory is not supported yet.\")\n\n    if _BOTO3_AVAILABLE:\n        s3_client = boto3.client(\"s3\")\n        try:\n            s3_client.head_object(Bucket=output_dir.url.split(\"/\")[2], Key=\"/\".join(output_dir.url.split(\"/\")[3:]))\n            raise ValueError(f\"The S3 directory {output_dir} is not empty.\")\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                pass\n            else:\n                raise e\n    else:\n        raise ValueError(\"Boto3 is not available, please install it.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise TypeError(f\"The `output_dir` should be an instance of the Dir class, but it is {type(output_dir)}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The `output_dir` should be an S3 directory, but it is {output_dir.url}\")\n\n    if append:\n        raise NotImplementedError(\"Appending data to the directory is currently not supported.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in the directory is currently not supported.\")\n\n    if _BOTO3_AVAILABLE:\n        s3_client = boto3.client(\"s3\")\n        try:\n            s3_client.list_objects_v2(Bucket=output_dir.url[5:].split(\"/\")[0], Prefix=output_dir.url[5:].split(\"/\", 1)[1])\n        except botocore.client.ClientError as error:\n            if error.response[\"Error\"][\"Code\"] == \"NoSuchBucket\":\n                raise ValueError(f\"The `output_dir` does not exist: {output_dir.url}\")\n            elif error.response[\"Error\"][\"Code\"] == \"AccessDenied\":\n                raise ValueError(f\"The `output_dir` is not accessible: {output_dir.url}\")\n            elif error.response[\"Error\"][\"Code\"] == \"NoSuchKey\":\n                pass\n            else:\n                raise\n        else:\n            raise ValueError(f\"The `output_dir` is not empty: {output_dir.url}\")\n    else:\n        raise ImportError(\"The `boto3` library is required to check the S3 directory.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise TypeError(f\"The `output_dir` must be a `Dir` object, got: {type(output_dir)}.\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The `output_dir` must be an S3 directory, got: {output_dir}.\")\n\n    if not overwrite and not append:\n        raise ValueError(\n            f\"The directory {output_dir} is not empty. Please specify `append` or `overwrite` to be True.\"\n        )\n\n    if _BOTO3_AVAILABLE:\n        s3_client = boto3.client(\"s3\")\n        try:\n            s3_client.head_object(Bucket=output_dir.url[5:].split(\"/\")[0], Key=\"/\".join(output_dir.url[5:].split(\"/\")[1:]))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                return\n            else:\n                raise e\n        else:\n            raise ValueError(f\"The directory {output_dir} is not empty. Please specify `append` or `overwrite` to be True.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"The `output_dir` must be a `Dir` object. Got: {output_dir}.\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The `output_dir` must be an S3 location. Got: {output_dir}.\")\n\n    if append:\n        raise NotImplementedError(\"Appending data to an S3 location is not currently supported.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in an S3 location is not currently supported.\")\n\n    if _BOTO3_AVAILABLE:\n        try:\n            s3_client = boto3.client(\"s3\")\n            s3_client.head_object(Bucket=output_dir.url[5:].split(\"/\")[0], Key=\"/\".join(output_dir.url[5:].split(\"/\")[1:]))\n            raise RuntimeError(f\"The directory `{output_dir}` already contains data.\")\n        except botocore.exceptions.ClientError:\n            pass\n    else:\n        raise ModuleNotFoundError(\"The `boto3` library was not found. Please install it using `pip install boto3`.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise TypeError(f\"The `output_dir` must be an instance of the Dir class, but is {type(output_dir)}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The `output_dir` must start with `s3://`, but is {output_dir.url}\")\n\n    if not append and output_dir.url.endswith(\"/\"):\n        raise ValueError(f\"The `output_dir` must not end with `/`, but is {output_dir.url}\")\n\n    if not overwrite:\n        raise ValueError(\"Currently, this function does not support overwriting data in the directory.\")\n\n    if not append:\n        raise ValueError(\"Currently, this function does not support appending data to the directory.\")\n\n    if _BOTO3_AVAILABLE:\n        s3_client = boto3.client(\"s3\")\n\n        try:\n            s3_client.list_objects_v2(Bucket=output_dir.url[5:].split(\"/\")[0], Prefix=\"/\".join(output_dir.url[5:].split(\"/\")[1:]))\n            raise ValueError(f\"The `output_dir` is not empty: {output_dir.url}\")\n        except botocore.client.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                pass\n            else:\n                raise e\n    else:\n        raise ImportError(\"The `boto3` package is not available.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise TypeError(f\"The output directory must be a `Dir` object, got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The output directory must be an S3 location, got: {output_dir}\")\n\n    if _BOTO3_AVAILABLE:\n        s3_client = boto3.client(\"s3\")\n        try:\n            s3_client.head_object(Bucket=output_dir.url.split(\"/\")[2], Key=\"/\".join(output_dir.url.split(\"/\")[3:]))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                return\n            else:\n                raise e\n        except Exception as e:\n            raise e\n\n        raise RuntimeError(\n            f\"The output directory: {output_dir} is not empty. Please use an empty directory or use `append` or `overwrite`.\"\n        )\n    else:\n        raise RuntimeError(\n            \"The `boto3` library is not installed. Please install it using `pip install boto3`.\"\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"The `output_dir` must be a Dir object, got: {type(output_dir)}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The `output_dir` must be an S3 path, got: {output_dir.url}\")\n\n    if append is True:\n        raise NotImplementedError(\"Appending data to the directory is currently not supported.\")\n\n    if overwrite is True:\n        raise NotImplementedError(\"Overwriting data in the directory is currently not supported.\")\n\n    if output_dir.url.endswith(\"/\"):\n        output_dir_url = output_dir.url[:-1]\n    else:\n        output_dir_url = output_dir.url\n\n    s3_client = boto3.client(\"s3\")\n\n    try:\n        s3_client.head_object(Bucket=output_dir_url.split(\"/\")[2], Key=\"/\".join(output_dir_url.split(\"/\")[3:]))\n        raise ValueError(f\"The `output_dir` is not empty. Please specify a different directory, got: {output_dir.url}\")\n    except botocore.exceptions.ClientError as e:\n        if e.response[\"Error\"][\"Code\"] == \"404\":\n            pass\n        else:\n            raise\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    # Check if the directory is a Dir object\n    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"The output directory is not a `Dir` object. Got: {output_dir}\")\n\n    # Check if the directory is in S3\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The output directory is not in S3. Got: {output_dir}\")\n\n    # Check if the directory is empty\n    if output_dir.url.startswith(\"s3://\"):\n        # Check if the directory exists\n        s3_client = boto3.client(\"s3\")\n        bucket, prefix = _split_s3_path(output_dir.url)\n        response = s3_client.list_objects_v2(Bucket=bucket, Prefix=prefix)\n        if response[\"KeyCount\"] > 0:\n            raise ValueError(f\"The output directory is not empty. Got: {output_dir}\")\n\n    # Check if appending is allowed\n    if append:\n        raise NotImplementedError(\"Appending data to the directory is currently not implemented.\")\n\n    # Check if overwriting is allowed\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in the directory is currently not implemented.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise TypeError(f\"The `output_dir` must be an instance of the Dir class, but is {type(output_dir)}.\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The `output_dir` must start with `s3://`, but is {output_dir.url}.\")\n\n    if _BOTO3_AVAILABLE:\n        s3_client = boto3.client(\"s3\")\n        bucket_name = output_dir.url[5:].split(\"/\")[0]\n        prefix = \"/\".join(output_dir.url[5:].split(\"/\")[1:])\n\n        try:\n            response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n            if response[\"KeyCount\"] > 0:\n                if not append and not overwrite:\n                    raise ValueError(\n                        f\"The `output_dir` already contains data. Please set `append` or `overwrite` to True to proceed.\"\n                    )\n                elif append:\n                    raise ValueError(\n                        f\"The `output_dir` already contains data. Appending data is currently not supported.\"\n                    )\n                elif overwrite:\n                    raise ValueError(\n                        f\"The `output_dir` already contains data. Overwriting data is currently not supported.\"\n                    )\n        except botocore.exceptions.ClientError as error:\n            if error.response[\"Error\"][\"Code\"] == \"NoSuchBucket\":\n                raise ValueError(\n                    f\"The `output_dir` contains a bucket that does not exist. Please check the URL.\"\n                )\n            else:\n                raise error\n    else:\n        raise ImportError(\n            f\"The `boto3` library is not available. Please install it using `pip install boto3`.\"\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"The `output_dir` must be a `Dir` object. Got {type(output_dir)}\")\n\n    if not output_dir.path.startswith(\"s3://\"):\n        raise ValueError(f\"The `output_dir` must start with `s3://`. Got {output_dir.path}\")\n\n    if output_dir.path.endswith(\"/\"):\n        output_dir.path = output_dir.path[:-1]\n\n    if output_dir.url is not None and output_dir.url.endswith(\"/\"):\n        output_dir.url = output_dir.url[:-1]\n\n    if _BOTO3_AVAILABLE:\n        s3_client = boto3.client(\"s3\")\n\n        bucket_name, prefix = _get_bucket_name_and_prefix(output_dir.path)\n\n        if not append and not overwrite:\n            try:\n                s3_client.head_object(Bucket=bucket_name, Key=prefix)\n            except botocore.exceptions.ClientError as e:\n                if e.response[\"Error\"][\"Code\"] != \"404\":\n                    raise ValueError(\n                        f\"The `output_dir` already contains data. Set `overwrite=True` to overwrite the data. Got {output_dir.path}\"\n                    )\n            else:\n                raise ValueError(\n                    f\"The `output_dir` already contains data. Set `overwrite=True` to overwrite the data. Got {output_dir.path}\"\n                )\n\n        if append:\n            raise NotImplementedError(\n                f\"Appending data to the `output_dir` is not currently supported. Set `append=False`. Got {output_dir.path}\"\n            )\n\n        if overwrite:\n            raise NotImplementedError(\n                f\"Overwriting data in the `output_dir` is not currently supported. Set `overwrite=False`. Got {output_dir.path}\"\n            )\n\n    else:\n        raise ImportError"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise TypeError(f\"The `output_dir` argument must be an instance of the Dir class, got: {type(output_dir)}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The `output_dir` argument must start with 's3://', got: {output_dir.url}\")\n\n    if _BOTO3_AVAILABLE:\n        parsed_url = parse.urlparse(output_dir.url)\n        bucket = parsed_url.netloc\n        key = parsed_url.path.lstrip(\"/\")\n\n        s3 = boto3.resource(\"s3\")\n        bucket = s3.Bucket(bucket)\n\n        for _ in bucket.objects.filter(Prefix=key):\n            raise RuntimeError(f\"The specified directory `{output_dir.url}` already contains data.\")\n\n    else:\n        raise ImportError(\n            \"The `boto3` package is not available. Please install it using `pip install lightning-flash[serve]` \"\n            \"to enable data export to S3.\"\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    # Check if the output_dir is a Dir object\n    if not isinstance(output_dir, Dir):\n        raise TypeError(\n            f\"The `output_dir` must be a `Dir` object, but instead it is a {type(output_dir)} object.\"\n        )\n\n    # Check if the output_dir is an S3 bucket\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(\n            f\"The `output_dir` must be an S3 bucket, but instead it is: {output_dir.url}\"\n        )\n\n    # Check if the output_dir is empty\n    if not overwrite and not append:\n        if output_dir.url.endswith(\"/\"):\n            output_dir_url = output_dir.url[:-1]\n        else:\n            output_dir_url = output_dir.url\n\n        output_dir_url_split = parse.urlsplit(output_dir_url)\n\n        bucket_name = output_dir_url_split.netloc\n        prefix = output_dir_url_split.path\n\n        if _BOTO3_AVAILABLE:\n            s3_client = boto3.client(\"s3\")\n            try:\n                s3_client.head_object(Bucket=bucket_name, Key=prefix)\n                raise ValueError(\n                    f\"The `output_dir` already contains data. Please set `overwrite=True` to overwrite the data in the `output_dir`.\"\n                )\n            except botocore.exceptions.ClientError:\n                pass\n        else:\n            raise ImportError(\n                \"The `boto3` library is not installed. Please install it using `pip install boto3`.\"\n            )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"The `output_dir` must be an instance of the Dir class. Got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The `output_dir` must be an S3 directory. Got: {output_dir}\")\n\n    if _BOTO3_AVAILABLE:\n        s3_client = boto3.client(\"s3\")\n        bucket_name, prefix = output_dir.url[5:].split(\"/\", 1)\n        response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n        if response.get(\"KeyCount\") > 0:\n            if overwrite:\n                print(\n                    f\"The directory {output_dir.url} already contains data. Overwriting is currently not supported. \"\n                    f\"Please delete the contents of the directory manually and try again.\"\n                )\n                sys.exit(1)\n            elif not append:\n                raise ValueError(\n                    f\"The directory {output_dir.url} already contains data. Appending is currently not supported. \"\n                    f\"Please delete the contents of the directory manually and try again.\"\n                )\n    else:\n        raise ImportError(\n            f\"The `boto3` library is not available. Please install the `boto3` library to use this feature.\"\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    # Check if the directory is a Dir object\n    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"The directory must be a `Dir` object, got: {output_dir}\")\n\n    # Check if the directory is in the local file system\n    if output_dir.path is not None and output_dir.path.startswith(\"/\"):\n        if not append and not overwrite:\n            if os.listdir(output_dir.path):\n                raise ValueError(\n                    f\"The output directory `{output_dir.path}` is not empty. Please use `overwrite=True` to overwrite the data in this directory.\"\n                )\n        elif not append:\n            raise ValueError(\n                f\"The output directory `{output_dir.path}` is not empty. Please use `overwrite=True` to overwrite the data in this directory.\"\n            )\n        elif not overwrite:\n            if os.listdir(output_dir.path):\n                raise ValueError(\n                    f\"The output directory `{output_dir.path}` is not empty. Please use `append=True` to append the data to this directory.\"\n                )\n        else:\n            # The directory is not empty, but we can append or overwrite the data\n            return\n\n    # Check if the directory is in S3\n    if output_dir.url is not None and output_dir.url.startswith(\"s3://\"):\n        if not append and not overwrite:\n            if _list_s3_directory(output_dir.url):\n                raise ValueError(\n                    f\"The output directory `{output_dir.url}` is not empty. Please use `overwrite=True` to overwrite the data in this directory.\"\n                )\n        elif not append:\n            raise ValueError(\n                f\"The output directory `{output_dir.url}` is not empty. Please use `overwrite=True` to overwrite the data in this directory.\"\n            )\n        elif not overwrite:\n            if _list_s3_directory(output_dir.url):\n                raise ValueError(\n                    f\"The output directory `{output_dir.url}` is not empty. Please use `append="}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise TypeError(f\"The `output_dir` should be a `Dir` object, but got: {output_dir}\")\n\n    if not output_dir.path.startswith(\"s3://\"):\n        raise ValueError(f\"The `output_dir` should be an S3 directory, but got: {output_dir}\")\n\n    if not append and not overwrite:\n        if _check_s3_dir_exists(output_dir.path):\n            raise ValueError(f\"The `output_dir` already exists and is not empty: {output_dir}\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise TypeError(f\"The `output_dir` must be an instance of the Dir class, but got {output_dir}.\")\n\n    if not output_dir.path.startswith(\"s3://\"):\n        raise ValueError(f\"The `output_dir` must be an S3 path, but got {output_dir}.\")\n\n    if not append and not overwrite:\n        if output_dir.path.startswith(\"s3://\"):\n            if _BOTO3_AVAILABLE:\n                s3_client = boto3.client(\"s3\")\n\n                bucket, prefix = output_dir.path[5:].split(\"/\", 1)\n\n                try:\n                    response = s3_client.list_objects_v2(Bucket=bucket, Prefix=prefix)\n                    if \"Contents\" in response:\n                        raise ValueError(\n                            f\"The `output_dir` already contains data. Please set `overwrite=True` to overwrite the data in the directory.\"\n                        )\n                except botocore.exceptions.ClientError as e:\n                    if e.response[\"Error\"][\"Code\"] == \"NoSuchBucket\":\n                        raise ValueError(f\"The `output_dir` does not exist. Please create the directory first.\")\n                    else:\n                        raise e\n            else:\n                raise ValueError(\"The `boto3` library is required to interact with S3.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"The `output_dir` should be an instance of the Dir class, got {output_dir}.\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The `output_dir` should be an S3 directory, got {output_dir}.\")\n\n    if _BOTO3_AVAILABLE:\n        s3_client = boto3.client(\"s3\")\n        try:\n            s3_client.head_object(Bucket=output_dir.url.split(\"/\")[2], Key=\"/\".join(output_dir.url.split(\"/\")[3:]))\n            raise ValueError(f\"The `output_dir` already contains data, got {output_dir}.\")\n        except botocore.exceptions.ClientError:\n            pass\n    else:\n        raise ImportError(\"boto3 is not installed. Please install it to use this feature.\")\n\n    if append:\n        raise NotImplementedError(\"Appending data to an S3 directory is not yet implemented.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in an S3 directory is not yet implemented.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"The `output_dir` must be a `Dir` object, got: {output_dir}\")\n\n    if not output_dir.path.startswith(\"s3://\"):\n        raise ValueError(f\"The `output_dir` must start with `s3://`, got: {output_dir}\")\n\n    if _BOTO3_AVAILABLE:\n        s3_client = boto3.client(\"s3\")\n        bucket_name = output_dir.url.split(\"/\")[2]\n        prefix = \"/\".join(output_dir.url.split(\"/\")[3:])\n        response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n        if \"Contents\" in response:\n            raise ValueError(f\"The `output_dir` already contains data, got: {output_dir}\")\n\n    if not append and not overwrite:\n        raise ValueError(\"The `output_dir` already contains data, and both `append` and `overwrite` are `False`.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # We aren't alloweing to add more data\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains data and datasets are meant to be immutable.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # Check for index.json file\n    if \"Contents\" in objects:\n        for obj in objects[\"Contents\"]:\n            if obj[\"Key\"].split(\"/\")[-1] == \"index.json\":\n                raise ValueError(\n                    f\"The provided output_dir `{output_dir.path}` already contains an index file and datasets are meant to be immutable.\"\n                    \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n                )\n\n    # Delete all objects within the specified prefix in the bucket\n    if objects[\"KeyCount\"] > 0:\n        s3.delete_objects(\n            Bucket=obj.netloc,\n            Delete={\n                \"Objects\": [{\"Key\": obj[\"Key\"]} for obj in objects[\"Contents\"]],\n                \"Quiet\": True,\n            },\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if objects[\"KeyCount\"] > 0:\n        if \"Contents\" in objects:\n            for obj in objects[\"Contents\"]:\n                s3.delete_object(Bucket=obj.netloc, Key=obj.key)\n        else:\n            raise RuntimeError(\n                f\"The provided output_dir `{output_dir.path}` already contains data and datasets are meant to be immutable.\"\n                \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n            )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # If there is no index.json, we need to delete all objects within the specified prefix in the bucket.\n    if objects[\"KeyCount\"] > 0:\n        if \"Contents\" not in objects:\n            raise RuntimeError(\n                f\"The provided output_dir `{output_dir.path}` already contains data and datasets are meant to be immutable.\"\n                \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n            )\n\n        for obj in objects[\"Contents\"]:\n            s3.delete_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\" + obj.key)\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if \"Contents\" not in objects:\n        return\n\n    for obj in objects[\"Contents\"]:\n        if obj[\"Key\"].endswith(\"index.json\"):\n            raise RuntimeError(\n                f\"The provided output_dir `{output_dir.path}` already contains an index file and datasets are meant to be immutable.\"\n                \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n            )\n\n    s3.delete_objects(\n        Bucket=obj.netloc,\n        Delete={\n            \"Objects\": [{\"Key\": content[\"Key\"]} for content in objects[\"Contents\"]],\n        },\n    )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # If the index file exists, return\n    if \"Contents\" in objects and \"index.json\" in [x[\"Key\"].split(\"/\")[-1] for x in objects[\"Contents\"]]:\n        return\n\n    # If the index file does not exist, delete all objects in the directory\n    if \"Contents\" in objects:\n        s3.delete_objects(\n            Bucket=obj.netloc,\n            Delete={\n                \"Objects\": [{\"Key\": x[\"Key\"]} for x in objects[\"Contents\"]],\n            },\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # If the directory contains an index file, raise an error.\n    if any(object[\"Key\"] == obj.path.lstrip(\"/\").rstrip(\"/\") + \"/index.json\" for object in objects[\"Contents\"]):\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains an index file. Please delete it and try again.\"\n        )\n\n    # If the directory does not contain an index file, delete all objects within the specified prefix in the bucket.\n    else:\n        for object in objects[\"Contents\"]:\n            s3.delete_object(Bucket=obj.netloc, Key=object[\"Key\"])\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if objects[\"KeyCount\"] > 0:\n        if \"Contents\" in objects:\n            if any(obj[\"Key\"].endswith(\"index.json\") for obj in objects[\"Contents\"]):\n                raise RuntimeError(\n                    f\"The provided output_dir `{output_dir.path}` already contains an index file and datasets are meant to be immutable.\"\n                    \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n                )\n            else:\n                for obj in objects[\"Contents\"]:\n                    s3.delete_object(Bucket=obj.netloc, Key=obj[\"Key\"])\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # If index.json is not found, delete all objects within the specified prefix.\n    if not any([obj[\"Key\"].endswith(\"index.json\") for obj in objects.get(\"Contents\", [])]):\n        for obj in objects.get(\"Contents\", []):\n            s3.delete_object(Bucket=obj.netloc, Key=obj[\"Key\"])\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # If the index.json file exists, then we do not need to do anything.\n    if \"Contents\" in objects and any(obj.key == \"index.json\" for obj in objects[\"Contents\"]):\n        return\n\n    # If the index.json file does not exist, we need to delete all objects within the specified prefix.\n    if \"Contents\" in objects:\n        s3.delete_objects(\n            Bucket=obj.netloc,\n            Delete={\n                \"Objects\": [{\"Key\": obj.key} for obj in objects[\"Contents\"]],\n                \"Quiet\": True,\n            },\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if objects[\"KeyCount\"] > 0:\n        if \"Contents\" not in objects:\n            raise RuntimeError(\n                f\"The provided output_dir `{output_dir.path}` already contains an index file and is not empty.\"\n                \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n            )\n\n        # If an index file is not found, delete all objects within the specified prefix in the bucket.\n        if not any(\n            [\n                content[\"Key\"].endswith(\"index.json\")\n                for content in objects[\"Contents\"]\n            ]\n        ):\n            s3.delete_objects(\n                Bucket=obj.netloc,\n                Delete={\n                    \"Objects\": [\n                        {\n                            \"Key\": content[\"Key\"]\n                        }\n                        for content in objects[\"Contents\"]\n                    ]\n                }\n            )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if objects[\"KeyCount\"] == 0:\n        return\n\n    # If there are objects in the bucket, then we check if there is an index.json file.\n    # If there is an index.json file, then we raise an error.\n    # If there is not an index.json file, then we delete all objects in the bucket.\n    for obj in objects[\"Contents\"]:\n        if obj[\"Key\"].endswith(\"index.json\"):\n            raise RuntimeError(\n                f\"The provided output_dir `{output_dir.path}` already contains an index file and datasets are meant to be immutable.\"\n                \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n            )\n\n    # Delete all objects in the bucket.\n    for obj in objects[\"Contents\"]:\n        s3.delete_object(Bucket=obj.netloc, Key=obj[\"Key\"])\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # If index.json is found, return\n    if \"Contents\" in objects and \"index.json\" in [obj[\"Key\"] for obj in objects[\"Contents\"]]:\n        return\n\n    # If index.json is not found, delete all objects in the prefix\n    if \"Contents\" in objects:\n        s3.delete_objects(\n            Bucket=obj.netloc,\n            Delete={\n                \"Objects\": [\n                    {\"Key\": obj[\"Key\"]} for obj in objects[\"Contents\"]\n                ],\n                \"Quiet\": True,\n            },\n        )\n\n    # If index.json is not found, raise an error\n    raise RuntimeError(\n        f\"The provided output_dir `{output_dir.path}` does not contain an index.json file. HINT: Did you forget to add an index.json file to the specified directory?\"\n    )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    # Check if the index.json file exists in the specified prefix.\n    index_file_exists = False\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n    for obj in objects.get(\"Contents\", []):\n        if obj[\"Key\"].endswith(\"index.json\"):\n            index_file_exists = True\n            break\n\n    if index_file_exists:\n        return\n\n    # If the index.json file does not exist, delete all objects in the specified prefix.\n    try:\n        s3.delete_objects(\n            Bucket=obj.netloc,\n            Delete={\n                \"Objects\": [{\"Key\": obj[\"Key\"]} for obj in objects[\"Contents\"]],\n                \"Quiet\": True,\n            },\n        )\n    except botocore.exceptions.ClientError as error:\n        if error.response[\"Error\"][\"Code\"] == \"404\":\n            return\n        else:\n            raise error\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # If there is no index.json file in the directory, delete all objects in the directory\n    if \"Contents\" not in objects or not any([obj[\"Key\"].endswith(\"index.json\") for obj in objects[\"Contents\"]]):\n        s3.delete_objects(\n            Bucket=obj.netloc,\n            Delete={\n                \"Objects\": [{\"Key\": obj[\"Key\"]} for obj in objects[\"Contents\"]],\n                \"Quiet\": True,\n            },\n        )\n\n    # If there is an index.json file in the directory, raise an error\n    else:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains an index.json file and datasets are meant to be immutable.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # Check if there is an index.json file in the specified prefix.\n    if objects[\"KeyCount\"] > 0:\n        index_exists = False\n        for obj in objects[\"Contents\"]:\n            if obj[\"Key\"].endswith(\"index.json\"):\n                index_exists = True\n                break\n        if index_exists:\n            raise RuntimeError(\n                f\"The provided output_dir `{output_dir.path}` already contains an index.json file.\"\n                \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n            )\n        else:\n            # Delete all objects in the specified prefix.\n            for obj in objects[\"Contents\"]:\n                s3.delete_object(Bucket=obj.netloc, Key=obj[\"Key\"])\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # If index.json exists, return\n    for obj in objects.get(\"Contents\", []):\n        if obj[\"Key\"].endswith(\"index.json\"):\n            return\n\n    # If index.json does not exist, delete all objects in the prefix\n    if objects[\"KeyCount\"] > 0:\n        s3.delete_objects(\n            Bucket=obj.netloc,\n            Delete={\n                \"Objects\": [{\"Key\": obj[\"Key\"]} for obj in objects[\"Contents\"]],\n                \"Quiet\": True,\n            },\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # Check for index.json file\n    if \"Contents\" in objects:\n        for obj in objects[\"Contents\"]:\n            if obj[\"Key\"].split(\"/\")[-1] == \"index.json\":\n                raise ValueError(\n                    f\"The provided output_dir `{output_dir.path}` already contains an index.json file. Please consider using a different output_dir.\"\n                )\n\n    # Delete all objects within the specified prefix\n    if objects[\"KeyCount\"] > 0:\n        print(\n            f\"The provided output_dir `{output_dir.path}` already contains data. All data will be deleted before the new dataset is uploaded.\"\n        )\n\n        s3.delete_objects(\n            Bucket=obj.netloc,\n            Delete={\n                \"Objects\": [{\"Key\": obj[\"Key\"]} for obj in objects[\"Contents\"]],\n                \"Quiet\": True,\n            },\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # If there are no objects, the directory is empty.\n    if objects[\"KeyCount\"] == 0:\n        return\n\n    # If there are objects, check if there is an index.json file.\n    has_index_file = False\n    for obj in objects[\"Contents\"]:\n        if obj[\"Key\"].endswith(\"index.json\"):\n            has_index_file = True\n            break\n\n    # If there is an index file, the directory is not empty.\n    if has_index_file:\n        return\n\n    # If there is no index file, delete all objects in the directory.\n    s3.delete_objects(\n        Bucket=obj.netloc,\n        Delete={\n            \"Objects\": [{\"Key\": obj[\"Key\"]} for obj in objects[\"Contents\"]],\n            \"Quiet\": True,\n        },\n    )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # If index.json file is not found, we delete all objects within the specified prefix in the bucket.\n    if \"Contents\" not in objects or not any(obj[\"Key\"].endswith(\"index.json\") for obj in objects[\"Contents\"]):\n        for obj in objects[\"Contents\"]:\n            s3.delete_object(Bucket=obj.netloc, Key=obj[\"Key\"])\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` does not contain an index.json file.\"\n            \" HINT: Did you forget to run the `upload_data` function?\"\n        )\n\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # Wait for all index parts to be available\n        while len(os.listdir(self._cache_dir)) < num_workers:\n            sleep(1)\n\n        # Merge only if the current node is the master node\n        if node_rank != 0:\n            return\n\n        # Load all index parts\n        index_parts = []\n        for filename in os.listdir(self._cache_dir):\n            if filename.endswith(_INDEX_FILENAME):\n                with open(os.path.join(self._cache_dir, filename), \"r\") as f:\n                    index_parts.append(json.load(f))\n\n        # Merge all index parts\n        merged_index = {\"chunks\": [], \"config\": {}}\n        for index_part in index_parts:\n            merged_index[\"chunks\"] += index_part[\"chunks\"]\n            merged_index[\"config\"] = index_part[\"config\"]\n\n        # Write the merged index\n        with open(os.path.join(self._cache_dir, _INDEX_FILENAME), \"w\") as f:\n            json.dump(merged_index, f, sort_keys=True)\n\n        # Wait for the merged index to be available\n        while not os.path.exists(os.path.join(self._cache_dir, _INDEX_FILENAME)):\n            sleep(1)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # The function is only executed by the master node.\n        if node_rank is not None and node_rank != 0:\n            return\n\n        # Wait until all index parts are available.\n        while len(os.listdir(self._cache_dir)) != num_workers + 1:\n            sleep(1)\n\n        # Merge all index parts.\n        index_parts = []\n        for filename in os.listdir(self._cache_dir):\n            if filename.endswith(_INDEX_FILENAME):\n                with open(os.path.join(self._cache_dir, filename), \"r\") as in_file:\n                    index_parts.append(json.load(in_file))\n        merged_index = {\"chunks\": [], \"config\": index_parts[0][\"config\"]}\n        for index_part in index_parts:\n            merged_index[\"chunks\"].extend(index_part[\"chunks\"])\n        with open(os.path.join(self._cache_dir, _INDEX_FILENAME), \"w\") as out_file:\n            json.dump(merged_index, out_file, sort_keys=True)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if not self._is_done:\n            raise RuntimeError(\"The writer is not done.\")\n\n        if self._distributed_env.world_size > 1:\n            if node_rank is None:\n                node_rank = self._distributed_env.rank\n\n            if node_rank == 0:\n                self._merge_chunks_index(num_workers)\n\n            while True:\n                if os.path.exists(os.path.join(self._cache_dir, f\"{self.rank}.{_INDEX_FILENAME}\")):\n                    break\n                sleep(1)\n\n        if self._distributed_env.world_size > 1 and node_rank != 0:\n            while True:\n                if os.path.exists(os.path.join(self._cache_dir, f\"{self.rank}.{_INDEX_FILENAME}\")):\n                    break\n                sleep(1)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # Wait until all workers have finished writing their chunks\n        while len(os.listdir(self._cache_dir)) < num_workers:\n            sleep(1)\n\n        # Wait until the master node has finished writing its chunks\n        if node_rank is not None and node_rank != 0:\n            while not os.path.exists(os.path.join(self._cache_dir, f\"{0}.{_INDEX_FILENAME}\")):\n                sleep(1)\n\n        # Merge the index files from all workers\n        if node_rank is None or node_rank == 0:\n            chunks_info = []\n            for worker_rank in range(num_workers):\n                with open(os.path.join(self._cache_dir, f\"{worker_rank}.{_INDEX_FILENAME}\")) as in_file:\n                    chunks_info.extend(json.load(in_file)[\"chunks\"])\n            with open(os.path.join(self._cache_dir, f\"{_INDEX_FILENAME}\"), \"w\") as out_file:\n                json.dump({\"chunks\": chunks_info}, out_file, sort_keys=True)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = 0\n\n        # Wait until all workers have finished writing their chunks\n        while len(os.listdir(self._cache_dir)) < num_workers:\n            sleep(1)\n\n        # Wait until the master node has finished writing its chunks\n        if node_rank == 0:\n            while len(os.listdir(self._cache_dir)) < num_workers + 1:\n                sleep(1)\n\n            # Merge all the chunks into a single index file\n            chunks = []\n            for file in os.listdir(self._cache_dir):\n                if file.endswith(_INDEX_FILENAME):\n                    with open(os.path.join(self._cache_dir, file), \"r\") as f:\n                        chunks.append(json.load(f))\n\n            merged_chunks = {\n                \"chunks\": [item for chunk in chunks for item in chunk[\"chunks\"]],\n                \"config\": chunks[0][\"config\"],\n            }\n\n            with open(os.path.join(self._cache_dir, _INDEX_FILENAME), \"w\") as f:\n                json.dump(merged_chunks, f, sort_keys=True)\n\n            # Wait until the merged index file is available\n            while not os.path.exists(os.path.join(self._cache_dir, _INDEX_FILENAME)):\n                sleep(1)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if self._is_done:\n            return\n\n        if node_rank is None:\n            node_rank = get_worker_rank()\n\n        if node_rank is None:\n            raise ValueError(\"The node rank needs to be provided.\")\n\n        if node_rank == 0:\n            # Wait for all workers to finish\n            while len(os.listdir(self._cache_dir)) < num_workers:\n                sleep(0.1)\n\n            # Merge all chunks\n            chunks_info: List[Dict[str, Any]] = []\n            for filename in os.listdir(self._cache_dir):\n                if filename.endswith(_INDEX_FILENAME):\n                    with open(os.path.join(self._cache_dir, filename), \"r\") as in_f:\n                        chunks_info.extend(json.load(in_f)[\"chunks\"])\n\n            # Sort the chunks by filename\n            chunks_info = sorted(chunks_info, key=lambda chunk: chunk[\"filename\"])\n\n            # Write the merged chunks\n            for chunk in chunks_info:\n                with open(os.path.join(self._cache_dir, chunk[\"filename\"]), \"rb\") as in_f:\n                    self.write_chunk_to_file(in_f.read(), chunk[\"filename\"])\n\n            # Write the merged index\n            self.write_chunks_index()\n\n        else:\n            # Wait for the merged index to be available\n            while not os.path.exists(os.path.join(self._cache_dir, f\"{node_rank}.{_INDEX_FILENAME}\")):\n                sleep(0.1)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = get_worker_rank()\n        if node_rank is None:\n            raise ValueError(\"The node rank must be provided.\")\n\n        # Wait for all index parts to be available\n        while len(os.listdir(self._cache_dir)) < num_workers:\n            sleep(1)\n\n        # Merge only if the node is the master node (rank 0)\n        if node_rank == 0:\n            # Read all index parts\n            chunks_info: List[Dict[str, Any]] = []\n            for filename in os.listdir(self._cache_dir):\n                if filename.endswith(_INDEX_FILENAME):\n                    with open(os.path.join(self._cache_dir, filename), \"r\") as f:\n                        chunks_info.extend(json.load(f)[\"chunks\"])\n\n            # Merge all index parts\n            chunks_info.sort(key=lambda x: x[\"filename\"])\n            merged_chunks_info = []\n            for i in range(0, len(chunks_info), num_workers):\n                merged_chunks_info.append(\n                    {\n                        \"chunk_bytes\": sum(x[\"chunk_bytes\"] for x in chunks_info[i : i + num_workers]),\n                        \"chunk_size\": sum(x[\"chunk_size\"] for x in chunks_info[i : i + num_workers]),\n                        \"filename\": chunks_info[i][\"filename\"],\n                        \"dim\": chunks_info[i][\"dim\"],\n                    }\n                )\n\n            # Write the merged index\n            with open(os.path.join(self._cache_dir, _INDEX_FILENAME), \"w\") as f:\n                json.dump({\"chunks\": merged_chunks_info, \"config\": self.get_config()}, f, sort_keys=True)\n\n        # Wait until the merged index is available\n        while not os.path.exists(os.path.join(self._cache_dir, _INDEX_FILENAME)):"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is not None and node_rank != 0:\n            while True:\n                if os.path.exists(os.path.join(self._cache_dir, f\"{0}.{_INDEX_FILENAME}\")):\n                    break\n                sleep(0.5)\n            return\n\n        # Wait for all index files to be available\n        while len(os.listdir(self._cache_dir)) < num_workers:\n            sleep(0.5)\n\n        # Merge the index files\n        chunks: List[Dict[str, Any]] = []\n        for index_file in os.listdir(self._cache_dir):\n            if index_file.endswith(_INDEX_FILENAME):\n                with open(os.path.join(self._cache_dir, index_file), \"r\") as f:\n                    chunks.extend(json.load(f)[\"chunks\"])\n\n        # Write the merged index\n        with open(os.path.join(self._cache_dir, \"index.json\"), \"w\") as out:\n            json.dump({\"chunks\": chunks}, out, sort_keys=True)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = get_worker_rank()\n\n        if node_rank != 0:\n            # Wait until the master node has completed the merge\n            while not os.path.exists(os.path.join(self._cache_dir, f\"{0}.{_INDEX_FILENAME}\")):\n                sleep(1)\n            return\n\n        # Wait until all index parts are available\n        while len(os.listdir(self._cache_dir)) < num_workers:\n            sleep(1)\n\n        # Merge all index parts\n        chunks_info: List[Dict[str, Any]] = []\n        for rank in range(num_workers):\n            with open(os.path.join(self._cache_dir, f\"{rank}.{_INDEX_FILENAME}\"), \"r\") as f:\n                chunks_info.extend(json.load(f)[\"chunks\"])\n\n        # Sort the chunks by filename\n        chunks_info = sorted(chunks_info, key=lambda chunk: chunk[\"filename\"])\n\n        # Write the merged index\n        with open(os.path.join(self._cache_dir, _INDEX_FILENAME), \"w\") as out:\n            json.dump({\"chunks\": chunks_info}, out, sort_keys=True)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # Wait until all parts are available\n        while len(os.listdir(self._cache_dir)) < (num_workers + 1):\n            sleep(1)\n\n        # Wait until the master node is ready\n        if node_rank is not None and node_rank != 0:\n            while not os.path.isfile(os.path.join(self._cache_dir, \"0.\" + _INDEX_FILENAME)):\n                sleep(1)\n\n        # Merge only the master node\n        if node_rank is None or node_rank == 0:\n            with open(os.path.join(self._cache_dir, \"0.\" + _INDEX_FILENAME), \"r\") as f:\n                chunks_info = json.load(f)[\"chunks\"]\n\n            for chunk in chunks_info:\n                with open(os.path.join(self._cache_dir, chunk[\"filename\"]), \"rb\") as f:\n                    data = f.read()\n                if self._compression:\n                    data = self._compressor.decompress(data)\n                with open(os.path.join(self._cache_dir, chunk[\"filename\"]), \"wb\") as f:\n                    f.write(data)\n\n            # Write the merged index file\n            with open(os.path.join(self._cache_dir, _INDEX_FILENAME), \"w\") as f:\n                json.dump({\"chunks\": chunks_info, \"config\": self.get_config()}, f, sort_keys=True)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = get_worker_rank()\n\n        if node_rank is not None and node_rank != 0:\n            # Wait until the master node is done writing the index\n            while not os.path.exists(os.path.join(self._cache_dir, f\"{0}.{_INDEX_FILENAME}\")):\n                sleep(1)\n            return\n\n        # Wait until all workers are done writing their index files\n        while len(os.listdir(self._cache_dir)) < num_workers:\n            sleep(1)\n\n        # Merge all index files\n        chunks_info: List[Dict[str, Any]] = []\n        for i in range(num_workers):\n            with open(os.path.join(self._cache_dir, f\"{i}.{_INDEX_FILENAME}\"), \"r\") as f:\n                chunks_info.extend(json.load(f)[\"chunks\"])\n\n        # Write the merged index file\n        with open(os.path.join(self._cache_dir, f\"{_INDEX_FILENAME}\"), \"w\") as f:\n            json.dump({\"chunks\": chunks_info}, f, sort_keys=True)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # Wait until all workers have finished writing their chunks.\n        while len(os.listdir(self._cache_dir)) < (num_workers + 1) * (self._distributed_env.world_size * self._worker_env.world_size):\n            sleep(1)\n\n        # Wait until the master node has finished writing the index.\n        if node_rank is not None and node_rank != 0:\n            while not os.path.exists(os.path.join(self._cache_dir, f\"{self.rank}.{_INDEX_FILENAME}\")):\n                sleep(1)\n\n        # Merge only the master node.\n        if node_rank is None or node_rank == 0:\n\n            # Collect all index files.\n            index_files = [\n                os.path.join(self._cache_dir, f)\n                for f in os.listdir(self._cache_dir)\n                if f.endswith(_INDEX_FILENAME)\n            ]\n\n            # Read all index files.\n            chunks_info = []\n            for index_file in index_files:\n                with open(index_file, \"r\") as f:\n                    chunks_info.extend(json.load(f)[\"chunks\"])\n\n            # Sort the index by the chunk index.\n            chunks_info = sorted(chunks_info, key=lambda c: c[\"filename\"])\n\n            # Write the merged index file.\n            with open(os.path.join(self._cache_dir, _INDEX_FILENAME), \"w\") as out:\n                json.dump({\"chunks\": chunks_info}, out, sort_keys=True)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # If the node_rank is not provided, assume the current node is the master node (rank 0).\n        if node_rank is None:\n            node_rank = 0\n\n        # Wait until all parts of the index are ready for merging.\n        while len(os.listdir(self._cache_dir)) < num_workers:\n            sleep(1)\n\n        # If the node is the master node (rank 0), proceed with the merge operation.\n        if node_rank == 0:\n            # Create a list of all index files in the cache directory.\n            index_files = [\n                os.path.join(self._cache_dir, f)\n                for f in os.listdir(self._cache_dir)\n                if f.endswith(_INDEX_FILENAME)\n            ]\n\n            # Create a list of all index parts to be merged.\n            index_parts = []\n            for index_file in index_files:\n                with open(index_file, \"r\") as in_file:\n                    index_parts.append(json.load(in_file))\n\n            # Merge all index parts into a single index.\n            merged_index = {\n                \"chunks\": [\n                    chunk\n                    for index_part in index_parts\n                    for chunk in index_part[\"chunks\"]\n                ],\n                \"config\": index_parts[0][\"config\"],\n            }\n\n            # Write the merged index to a JSON file.\n            with open(os.path.join(self._cache_dir, _INDEX_FILENAME), \"w\") as out_file:\n                json.dump(merged_index, out_file, sort_keys=True)\n\n        # If the node is not the master node, wait until the merged index file is available.\n        while not os.path.exists(os.path.join(self._cache_dir, _INDEX_FILENAME)):\n            sleep(1)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = get_worker_rank()\n\n        if node_rank == 0:\n            # Wait until all index parts are available\n            while len(os.listdir(self._cache_dir)) < (num_workers + 1):\n                sleep(1)\n\n            # Merge all index parts\n            self.merge_index()\n\n            # Wait until the merged index is available\n            while not os.path.exists(os.path.join(self._cache_dir, f\"{node_rank}.{_INDEX_FILENAME}\")):\n                sleep(1)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if self._distributed_env.world_size == 1:\n            return\n\n        if node_rank is None:\n            node_rank = get_worker_rank()\n\n        if node_rank is None:\n            raise ValueError(\n                \"The node rank is not available. Please provide the node_rank argument.\"\n            )\n\n        # Wait for all parts to be available\n        while len(os.listdir(self._cache_dir)) < num_workers:\n            sleep(1)\n\n        if node_rank == 0:\n            # Merge all parts\n            merged_index = []\n            for part in range(num_workers):\n                with open(os.path.join(self._cache_dir, f\"{part}.{_INDEX_FILENAME}\"), \"r\") as f:\n                    merged_index.extend(json.load(f)[\"chunks\"])\n\n            # Write the merged index\n            with open(os.path.join(self._cache_dir, _INDEX_FILENAME), \"w\") as f:\n                json.dump({\"chunks\": merged_index}, f, sort_keys=True)\n\n        # Wait for the master node to finish the merge\n        while not os.path.exists(os.path.join(self._cache_dir, _INDEX_FILENAME)):\n            sleep(1)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if not self.filled:\n            raise RuntimeError(\n                \"The caching phase is not done. Please make sure you called `done` after the caching phase is complete.\"\n            )\n\n        if node_rank is not None and node_rank != 0:\n            while not os.path.exists(os.path.join(self._cache_dir, f\"0.{_INDEX_FILENAME}\")):\n                sleep(1)\n            return\n\n        # Wait until all index parts are available\n        for i in range(num_workers):\n            while not os.path.exists(os.path.join(self._cache_dir, f\"{i}.{_INDEX_FILENAME}\")):\n                sleep(1)\n\n        # Merge the index parts\n        index_parts = []\n        for i in range(num_workers):\n            with open(os.path.join(self._cache_dir, f\"{i}.{_INDEX_FILENAME}\"), \"r\") as index_part:\n                index_parts.append(json.load(index_part))\n\n        merged_index = {\n            \"chunks\": sum([index_part[\"chunks\"] for index_part in index_parts], []),\n            \"config\": index_parts[0][\"config\"],\n        }\n\n        # Write the merged index\n        with open(os.path.join(self._cache_dir, f\"{_INDEX_FILENAME}\"), \"w\") as merged_index_file:\n            json.dump(merged_index, merged_index_file, sort_keys=True)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # If the environment is distributed, wait until all workers have finished\n        # their part of the indexing process\n        if node_rank is not None:\n            while len(os.listdir(self._cache_dir)) < num_workers:\n                sleep(1)\n\n        # If the environment is non-distributed, or the current node is the master,\n        # proceed with the merge process\n        if node_rank is None or node_rank == 0:\n\n            # If the merge is already done, return\n            if self._is_done:\n                return\n\n            # Wait until all index parts are available\n            while len(os.listdir(self._cache_dir)) < num_workers:\n                sleep(1)\n\n            # Merge the index parts\n            self.done()\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is not None and node_rank != 0:\n            while not os.path.exists(os.path.join(self._cache_dir, f\"0.{_INDEX_FILENAME}\")):\n                sleep(1)\n            return\n\n        # Wait for all parts to be ready\n        for i in range(num_workers):\n            while not os.path.exists(os.path.join(self._cache_dir, f\"{i}.{_INDEX_FILENAME}\")):\n                sleep(1)\n\n        # Merge all parts\n        parts: List[Dict[str, Any]] = []\n        for i in range(num_workers):\n            with open(os.path.join(self._cache_dir, f\"{i}.{_INDEX_FILENAME}\"), \"r\") as f:\n                parts.append(json.load(f))\n        merged_chunks = [item for part in parts for item in part[\"chunks\"]]\n        merged_config = {**parts[0][\"config\"], **parts[1][\"config\"]}\n\n        # Write the merged index\n        with open(os.path.join(self._cache_dir, f\"{_INDEX_FILENAME}\"), \"w\") as out:\n            json.dump({\"chunks\": merged_chunks, \"config\": merged_config}, out, sort_keys=True)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = get_worker_rank()\n\n        if node_rank is None:\n            raise ValueError(\n                \"The node rank was not provided and couldn't be determined. Please provide the rank in the function call.\"\n            )\n\n        # Wait for all parts to be ready\n        while len(os.listdir(self._cache_dir)) < num_workers:\n            sleep(1)\n\n        # Wait for the master node to finish writing\n        if node_rank != 0:\n            while not os.path.exists(os.path.join(self._cache_dir, f\"{node_rank}.{_INDEX_FILENAME}\")):\n                sleep(1)\n\n        # Merge all parts\n        if node_rank == 0:\n            chunks_info: List[Dict[str, Any]] = []\n            for rank in range(num_workers):\n                with open(os.path.join(self._cache_dir, f\"{rank}.{_INDEX_FILENAME}\"), \"r\") as f:\n                    chunks_info.extend(json.load(f)[\"chunks\"])\n\n            with open(os.path.join(self._cache_dir, _INDEX_FILENAME), \"w\") as out:\n                json.dump({\"chunks\": chunks_info, \"config\": self.get_config()}, out, sort_keys=True)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # Wait for all workers to finish writing their index files\n        while len(os.listdir(self._cache_dir)) < num_workers:\n            sleep(1)\n\n        # Wait for the master node to finish writing the merged index file\n        if node_rank != 0:\n            while not os.path.exists(os.path.join(self._cache_dir, f\"{node_rank}.{_INDEX_FILENAME}\")):\n                sleep(1)\n\n        # Merge all index files into a single one\n        if node_rank == 0:\n            index_files = sorted([f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)])\n            merged_index = {}\n            for index_file in index_files:\n                with open(os.path.join(self._cache_dir, index_file), \"r\") as f:\n                    index = json.load(f)\n                for chunk in index[\"chunks\"]:\n                    merged_index[chunk[\"filename\"]] = chunk\n            with open(os.path.join(self._cache_dir, _INDEX_FILENAME), \"w\") as f:\n                json.dump({\"chunks\": list(merged_index.values())}, f, sort_keys=True)\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\n            \"The Lightning SDK is not available. Please install it by running `pip install lightning-sdk`.\"\n        )\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && python -m lightning_cloud.execute\"\n\n    studio = Studio()\n\n    job = studio.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command,\n    )\n\n    print(f\"Job created at {job.url}.\")\n\n    while job.status == \"PENDING\":\n        sleep(10)\n        job = studio.get_job(job_id=job.id)\n\n    if job.status == \"FAILED\":\n        raise RuntimeError(f\"The job failed with status {job.status}.\")\n\n    print(f\"Job started at {job.url}.\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available.\")\n\n    if machine is None:\n        machine = Machine.get_default()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {sys.executable} -m lightning_equipment.main\"\n\n    studio = Studio()\n    job = studio.job_service.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command,\n    )\n\n    print(f\"Job created: {job.url}\")\n\n    while True:\n        job = studio.job_service.get_job(job.id)\n\n        if job.status == \"running\":\n            print(f\"Job started: {job.url}\")\n            break\n        elif job.status == \"failed\":\n            raise RuntimeError(f\"Job failed: {job.url}\")\n        elif job.status == \"stopped\":\n            raise RuntimeError(f\"Job stopped: {job.url}\")\n        elif job.status == \"queued\":\n            print(f\"Job queued: {job.url}\")\n        else:\n            print(f\"Job status: {job.status}\")\n\n        sleep(10)"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install it with `pip install lightning-sdk`.\")\n\n    if machine is None:\n        machine = Machine.get_default()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {sys.executable} -m lightning_cloud.execute\"\n\n    # Create a job\n    job = Studio.create_job(\n        name=name,\n        command=command,\n        num_nodes=num_nodes,\n        machine=machine,\n    )\n\n    # Wait for the job to start\n    print(f\"Job created: {job.url}\")\n    while job.status == \"PENDING\":\n        sleep(5)\n        job = Studio.get_job(job.id)\n        print(f\"Waiting for the job to start...\")\n\n    if job.status == \"FAILED\":\n        raise RuntimeError(f\"The job failed: {job.url}\")\n\n    print(f\"Job started: {job.url}\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise ImportError(\"The Lightning SDK is not available.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = \" \".join(sys.argv)\n\n    job = Studio.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command,\n    )\n\n    print(f\"Job created at {job.url}\")\n\n    while True:\n        job = job.refresh()\n        if job.status in [\"running\", \"succeeded\"]:\n            print(f\"Job started at {job.url}\")\n            break\n        elif job.status in [\"failed\", \"stopped\"]:\n            raise RuntimeError(f\"Job failed with status {job.status}.\")\n        sleep(1)"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install it with `pip install lightning-sdk`\")\n\n    if machine is None:\n        machine = Machine.get_default()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {sys.executable} -m lightning_utils.remote.execute\"\n\n    # Create a new job\n    job = Studio.new_job(name=name, machine=machine)\n\n    # Start the job\n    job.start(command=command)\n\n    # Wait for the job to start\n    job.wait_for_status(status=\"RUNNING\")\n\n    # Print the job URL\n    print(f\"Job started: {job.url}\")\n\n    # Wait for the job to finish\n    job.wait_for_completion()\n\n    # Print the job URL\n    print(f\"Job finished: {job.url}\")\n\n    # Raise an exception if the job failed\n    if job.status != \"SUCCEEDED\":\n        raise RuntimeError(f\"Job failed with status: {job.status}\")\n\n    # Print the job URL\n    print(f\"Job succeeded: {job.url}\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise ImportError(\"The `lightning_sdk` module is not available.\")\n\n    if machine is None:\n        machine = Machine.from_env()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {sys.executable} -m lightning_cloud.execute\"\n\n    job = Studio.get_instance().job_service.create_job(\n        name=name,\n        machine=machine,\n        command=command,\n        num_nodes=num_nodes,\n    )\n\n    print(f\"Job {job.name} created.\")\n    print(f\"Job URL: {job.url}\")\n\n    while True:\n        job = Studio.get_instance().job_service.get_job(job.id)\n        if job.status == \"running\":\n            print(f\"Job {job.name} is running.\")\n            print(f\"Job URL: {job.url}\")\n            break\n        elif job.status == \"failed\":\n            raise RuntimeError(f\"Job {job.name} failed.\")\n        else:\n            print(f\"Job {job.name} is {job.status}.\")\n            sleep(1)"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\n            \"The Lightning SDK is not available. Please install it using `pip install lightning-sdk`.\"\n        )\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('SHELL', '/bin/bash')} -c 'env'\"\n\n    studio = Studio()\n    job = studio.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command,\n    )\n\n    while True:\n        job = studio.get_job(job.id)\n        if job.url is not None:\n            print(f\"Job is available at {job.url}.\")\n            break\n\n        sleep(1)\n\n    while True:\n        job = studio.get_job(job.id)\n        if job.status == \"FAILED\":\n            raise RuntimeError(f\"Job failed with status: {job.status}.\")\n        elif job.status == \"SUCCEEDED\":\n            print(f\"Job succeeded with status: {job.status}.\")\n            break\n\n        sleep(1)"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available.\")\n\n    if machine is None:\n        machine = Machine.get_default()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('SHELL', '/bin/bash')} -l -c 'env; ls -lha; printenv; {sys.argv[0]} --local'\"\n\n    job = Studio.get_default_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command,\n    )\n\n    job_id = job.execute()\n\n    print(f\"Job ID: {job_id}\")\n\n    print(\"Waiting for the job to start...\")\n\n    while True:\n        job = Studio.get_job(job_id)\n        if job.status == \"running\":\n            print(f\"Job URL: {_get_lightning_cloud_url() + '/' + job.url}\")\n            break\n        elif job.status == \"failed\":\n            raise RuntimeError(f\"The job failed with the following error: {job.error}\")\n        sleep(1)\n\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install it with `pip install lightning-sdk`\")\n\n    if not Studio.is_active():\n        raise RuntimeError(\"The Lightning Studio is not active. Please run `studio activate`\")\n\n    if not Studio.is_authenticated():\n        raise RuntimeError(\"The Lightning Studio is not authenticated. Please run `studio authenticate`\")\n\n    if machine is None:\n        machine = Machine.from_env()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_ENV', '')}\"\n\n    job = Studio.job_create(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command,\n    )\n\n    print(f\"Job {job.id} has been created.\")\n\n    print(\"Waiting for the job to start...\")\n\n    while job.status in [\"pending\", \"running\"]:\n        sleep(5)\n        job = Studio.job_get(job.id)\n\n    if job.status != \"running\":\n        raise RuntimeError(f\"Job {job.id} failed with status {job.status}\")\n\n    print(f\"Job {job.id} has started.\")\n    print(f\"Job URL: {job.url}\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install it using `pip install lightning-sdk`.\")\n\n    if machine is None:\n        machine = Machine.from_standard_machine_type(\"p3.2xlarge\")\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {sys.executable} -m lightning_cloud.execute\"\n\n    try:\n        studio = Studio.from_host(host=_get_lightning_cloud_url())\n        job = studio.jobs.create(\n            name=name,\n            num_nodes=num_nodes,\n            machine=machine,\n            command=command,\n        )\n        print(f\"Job URL: {job.url}\")\n    except Exception as e:\n        print(f\"Error while creating job: {e}\")\n        raise e\n\n    while True:\n        try:\n            job = studio.jobs.get(job.id)\n        except Exception as e:\n            print(f\"Error while getting job: {e}\")\n            raise e\n\n        if job.status == \"running\":\n            print(f\"Job URL: {job.url}\")\n            break\n        elif job.status == \"failed\":\n            print(f\"Job failed: {job.status_message}\")\n            raise RuntimeError(f\"Job failed: {job.status_message}\")\n        else:\n            print(f\"Job status: {job.status}\")\n            sleep(10)"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\n            \"The Lightning SDK is not available. Please make sure you have installed the Lightning SDK.\"\n        )\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\n            \"The boto3 SDK is not available. Please make sure you have installed the boto3 SDK.\"\n        )\n\n    if machine is None:\n        machine = Machine.from_local()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.environ.get('SHELL', '/bin/bash')} -l\"\n\n    studio = Studio()\n    job = studio.jobs.create(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command,\n        project_id=os.getenv(\"LIGHTNING_CLOUD_PROJECT_ID\", None),\n        cluster_id=os.getenv(\"LIGHTNING_CLUSTER_ID\", None),\n    )\n\n    print(f\"Job URL: {_get_lightning_cloud_url()}/jobs/{job.id}\")\n\n    while job.status not in [\"SUCCEEDED\", \"FAILED\", \"CANCELED\"]:\n        sleep(10)\n        job = studio.jobs.get(job.id)\n\n    if job.status != \"SUCCEEDED\":\n        raise RuntimeError(f\"Job {job.id} failed with status {job.status}\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise ImportError(\n            \"The Lightning SDK is not available. Please install the Lightning SDK to use this function.\"\n        )\n\n    if machine is None:\n        machine = Machine.get_default()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && export PATH=$PATH:{os.getenv('PATH')} && export PYTHONPATH=$PYTHONPATH:{os.getenv('PYTHONPATH')} && {sys.executable} -m lightning_utils.cli.execute\"\n\n    studio = Studio.get_studio()\n\n    job = studio.create_data_preparation_job(\n        name=name,\n        machine=machine,\n        command=command,\n        num_nodes=num_nodes,\n    )\n\n    print(f\"Job created at {job.url}\")\n\n    while job.status not in (\"succeeded\", \"failed\"):\n        sleep(5)\n        job = studio.get_data_preparation_job(job.id)\n\n    if job.status == \"failed\":\n        raise RuntimeError(f\"Job failed. See {job.url} for details.\")\n\n    print(f\"Job completed. See {job.url} for details.\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available.\")\n\n    if machine is None:\n        machine = Machine.from_local()\n\n    if command is None:\n        command = f\"python -m lightning_utils.remote.execute --working-dir={os.getcwd()} --env={os.environ}\"\n\n    if not machine.is_valid():\n        raise RuntimeError(\"The machine configuration is not valid.\")\n\n    studio = Studio()\n\n    job = studio.jobs.create(\n        name=name,\n        machine=machine,\n        command=command,\n        num_nodes=num_nodes,\n    )\n\n    print(f\"Job created: {job.url}\")\n\n    print(\"Waiting for the job to start...\")\n\n    while job.status == \"Pending\":\n        sleep(5)\n        job.refresh()\n\n    if job.status != \"Running\":\n        raise RuntimeError(f\"The job failed to start with status {job.status}.\")\n\n    print(f\"Job started: {job.url}\")\n\n    print(\"Waiting for the job to finish...\")\n\n    while job.status == \"Running\":\n        sleep(5)\n        job.refresh()\n\n    if job.status != \"Completed\":\n        raise RuntimeError(f\"The job failed to complete with status {job.status}.\")\n\n    print(f\"Job completed: {job.url}\")\n\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise ImportError(\n            \"Lightning SDK is not available. Please install it with `pip install lightning-sdk`.\"\n        )\n\n    if not isinstance(name, str):\n        raise TypeError(f\"The `name` argument must be a string, got {type(name)}.\")\n\n    if not isinstance(num_nodes, int):\n        raise TypeError(f\"The `num_nodes` argument must be an integer, got {type(num_nodes)}.\")\n\n    if machine is not None and not isinstance(machine, Machine):\n        raise TypeError(f\"The `machine` argument must be a `Machine` object, got {type(machine)}.\")\n\n    if command is not None and not isinstance(command, str):\n        raise TypeError(f\"The `command` argument must be a string, got {type(command)}.\")\n\n    if machine is None:\n        machine = Machine.get_default()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && . ~/.profile && {sys.executable} -m lightning_utils.remote_executor\"\n\n    studio = Studio(\n        url=_get_lightning_cloud_url(),\n        email=os.getenv(\"LIGHTNING_CLOUD_USERNAME\", None),\n        password=os.getenv(\"LIGHTNING_CLOUD_PASSWORD\", None),\n    )\n\n    job = studio.job_create(\n        name=name,\n        machine=machine,\n        command=command,\n        num_nodes=num_nodes,\n    )\n\n    print(f\"Job created: {job.url}\")\n\n    print(\"Waiting for job to start...\")\n\n    while True:\n        job = studio.job_get(job_id=job.id)\n        if job.status == \"running\":\n            break\n        if job.status == \"failed\":\n            raise RuntimeError(f\"Job failed: {job.url}\")\n        sleep(1)\n\n    print(f\"Job started: {job"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\n            \"The `lightning_sdk` module isn't available. Please install the `lightning-sdk` package.\"\n        )\n\n    if machine is None:\n        machine = Machine.get_default()\n\n    if command is None:\n        command = f\"cd {os.getcwd()};\"\n\n        for key, value in os.environ.items():\n            if key.startswith(\"LIGHTNING_\") or key.startswith(\"AWS_\"):\n                command += f\"export {key}={value};\"\n\n        command += \"python -m lightning_modules.entrypoint\"\n\n    job = Studio.get_active_job()\n    if job is None:\n        raise RuntimeError(\"No active job found. Please run this function inside a job.\")\n\n    job.execute(\n        name=name,\n        machine=machine,\n        command=command,\n        num_nodes=num_nodes,\n    )\n\n    while True:\n        job = Studio.get_active_job()\n        if job is None:\n            raise RuntimeError(\"No active job found. Please run this function inside a job.\")\n\n        if job.status == \"running\":\n            print(f\"Job is running: {job.url}\")\n            break\n\n        if job.status == \"failed\":\n            raise RuntimeError(f\"Job failed: {job.url}\")\n\n        sleep(5)"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\n            \"The Lightning SDK is not installed. Please install it using `pip install lightning-sdk`.\"\n        )\n\n    if machine is None:\n        machine = Machine.get_default()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('SHELL', '/bin/bash')} -c 'printenv && sleep infinity'\"\n\n    if Studio.is_available():\n        job = Studio.get_current_job()\n        job.set_name(name)\n        job.set_command(command)\n        job.set_machine(machine)\n        job.set_num_nodes(num_nodes)\n        job.run()\n\n        print(f\"Job started: {job.get_url()}\")\n\n        job.wait_for_running()\n        job.wait_for_stopped()\n\n        if not job.is_success():\n            raise RuntimeError(f\"Job failed: {job.get_url()}\")\n\n        return\n\n    client = LightningClient(max_tries=2)\n    job_id = client.job_service_create_job(\n        name=name,\n        command=command,\n        machine=machine,\n        num_nodes=num_nodes,\n    )\n\n    print(f\"Job started: {_get_lightning_cloud_url()}/jobs/{job_id}\")\n\n    while True:\n        job = client.job_service_get_job(job_id)\n\n        if job.status == \"running\":\n            print(f\"Job running: {_get_lightning_cloud_url()}/jobs/{job_id}\")\n            break\n\n        if job.status == \"failed\":\n            raise RuntimeError(f\"Job failed: {_get_lightning_cloud_url()}/jobs/{job_id}\")\n\n        sleep(5)\n\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install it using `pip install lightning-sdk`\")\n\n    if machine is None:\n        machine = Machine.from_dict(\n            {\n                \"cpu\": 2,\n                \"gpu\": 0,\n                \"memory_gb\": 8,\n                \"gpu_memory_gb\": 0,\n                \"disk_size_gb\": 10,\n            }\n        )\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('SHELL', '/bin/bash')} -c 'printenv && {sys.executable} -m lightning_cloud.execute'\"\n\n    try:\n        studio = Studio(url=_get_lightning_cloud_url())\n        job = studio.data_prep_jobs.create(\n            name=name,\n            num_nodes=num_nodes,\n            machine=machine,\n            command=command,\n        )\n        print(f\"Job created: {job.url}\")\n\n        while job.status == \"PENDING\":\n            print(\"Job pending...\")\n            sleep(5)\n            job = studio.data_prep_jobs.get(id=job.id)\n\n        if job.status == \"SUCCEEDED\":\n            print(f\"Job succeeded: {job.url}\")\n        else:\n            print(f\"Job failed: {job.url}\")\n            raise RuntimeError(f\"The job failed with status {job.status}\")\n    except Exception as e:\n        print(f\"Exception: {e}\")\n        raise RuntimeError(f\"The job failed with status {job.status}\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise ImportError(\n            \"The Lightning SDK is not installed. Please install it using `pip install lightning-sdk`.\"\n        )\n\n    if machine is None:\n        machine = Machine.get_default()\n\n    if command is None:\n        command = (\n            f\"cd {os.getcwd()} &&\"\n            f\"export PYTHONPATH={os.getcwd()}:${{PYTHONPATH}} &&\"\n            f\"export PATH={os.getcwd()}:${{PATH}} &&\"\n            f\"export PIP_TARGET={os.getcwd()}:${{PIP_TARGET}} &&\"\n            f\"export LD_LIBRARY_PATH={os.getcwd()}:${{LD_LIBRARY_PATH}} &&\"\n            f\"export PYTHONPATH={os.getcwd()}:${{PYTHONPATH}} &&\"\n            f\"export PIP_TARGET={os.getcwd()}:${{PIP_TARGET}} &&\"\n            f\"export PIP_DISABLE_PIP_VERSION_CHECK=1 &&\"\n            f\"export PIP_NO_WARN_SCRIPT_LOCATION=1 &&\"\n            f\"export PIP_NO_CACHE_DIR=off &&\"\n            f\"export PIP_NO_DEPS=1 &&\"\n            f\"export PIP_NO_BUILD_ISOLATION=1 &&\"\n            f\"export PIP_NO_USE_PEP517=1 &&\"\n            f\"export PIP_NO_INPUT=1 &&\"\n            f\"export PIP_IGNORE_INSTALLED=1 &&\"\n            f\"pip install -e .\"\n        )\n\n    if os.getenv(\"LIGHTNING_PROJECT_ID\") is None:\n        raise ValueError(\n            \"The `LIGHTNING_PROJECT_ID` environment variable is not set. Please set it to the Lightning project ID.\"\n        )\n\n    if os"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install it with `pip install lightning-sdk`.\")\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\"The boto3 SDK is not available. Please install it with `pip install boto3`.\")\n\n    if not Studio.is_available():\n        raise RuntimeError(\n            \"The Studio is not available. Please check your internet connection and make sure you are logged in with `lightning login`.\"\n        )\n\n    if machine is None:\n        machine = Machine.default()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('SHELL', '/bin/bash')} -l -c 'printenv && {sys.argv[0]} {sys.argv[1]}'\"\n\n    job = Studio.create_job(name=name, num_nodes=num_nodes, machine=machine, command=command)\n\n    print(f\"Job {job.id} is being executed.\")\n\n    while job.status not in [\"running\", \"failed\", \"succeeded\"]:\n        print(f\"Job {job.id} is {job.status}.\")\n        sleep(10)\n        job = Studio.get_job(job.id)\n\n    if job.status == \"failed\":\n        raise RuntimeError(f\"Job {job.id} failed. Please check the logs at {job.url}.\")\n\n    print(f\"Job {job.id} is {job.status}.\")\n    print(f\"You can check the logs at {job.url}.\")\n\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\n            \"The `lightning_sdk` package is not installed. Please install it using `pip install lightning-sdk`.\"\n        )\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\n            \"The `boto3` package is not installed. Please install it using `pip install boto3`.\"\n        )\n\n    if machine is None:\n        machine = Machine.from_local()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && export PYTHONPATH=$PYTHONPATH:{os.getcwd()} && export PYTHONPATH=$PYTHONPATH:{os.path.dirname(sys.argv[0])} && export PYTHONPATH=$PYTHONPATH:${os.getenv('PYTHONPATH', '')} && export PYTHONPATH=$PYTHONPATH:${os.getenv('LIGHTNING_SRC_DIR', '')} && {sys.argv[0]} {sys.argv[1]}\"\n\n    if not os.path.exists(machine.key_file):\n        raise RuntimeError(f\"The key file {machine.key_file} doesn't exist.\")\n\n    studio = Studio(url=_get_lightning_cloud_url())\n\n    job = studio.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command,\n    )\n\n    print(f\"Job URL: {job.url}\")\n\n    while job.status not in (\"running\", \"failed\", \"succeeded\", \"cancelled\"):\n        sleep(10)\n        job = studio.get_job(job.id)\n        print(f\"Job status: {job.status}\")\n\n    if job.status == \"failed\":\n        raise RuntimeError(f\"The job {job.id} failed.\")\n\n    if job.status == \"cancelled\":\n        raise RuntimeError(f\"The job {job.id} was cancelled.\")"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        config = ChunksConfig(\n            cache_dir=self._cache_dir,\n            remote_input_dir=self._remote_input_dir,\n            compression=self._compression,\n            serializers=self._serializers,\n            item_loader=self._item_loader,\n        )\n\n        if config.exists():\n            self._config = config\n            return config\n\n        return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        config = ChunksConfig(\n            cache_dir=self._cache_dir,\n            serializers=self._serializers,\n            remote_input_dir=self._remote_input_dir,\n            item_loader=self._item_loader,\n        )\n\n        if config.load():\n            self._config = config\n            return config\n\n        return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Load the config\n        config = ChunksConfig(\n            cache_dir=self._cache_dir,\n            remote_input_dir=self._remote_input_dir,\n            compression=self._compression,\n            serializers=self._serializers,\n        )\n\n        # Check whether the config is valid\n        if config.is_valid():\n            self._config = config\n            return config\n\n        return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Load the chunks configuration\n        config = ChunksConfig(\n            cache_dir=self._cache_dir,\n            remote_input_dir=self._remote_input_dir,\n            serializers=self._serializers,\n            compression=self._compression,\n            item_loader=self._item_loader,\n        )\n\n        # Check whether the chunks configuration is valid\n        if config.is_valid():\n            self._config = config\n            return config\n\n        return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        if self._config is None:\n            self._config = ChunksConfig(\n                cache_dir=self._cache_dir,\n                remote_input_dir=self._remote_input_dir,\n                serializers=self._serializers,\n                compression=self._compression,\n                item_loader=self._item_loader,\n            )\n\n        if self._config.is_ready():\n            return self._config\n\n        return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        config = ChunksConfig(\n            cache_dir=self._cache_dir,\n            remote_input_dir=self._remote_input_dir,\n            serializers=self._serializers,\n            compression=self._compression,\n        )\n        if config.load():\n            self._config = config\n            return config\n        return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        config = ChunksConfig(\n            cache_dir=self._cache_dir,\n            serializers=self._serializers,\n            remote_input_dir=self._remote_input_dir,\n            item_loader=self._item_loader,\n        )\n\n        if config.load(self._compression):\n            self._config = config\n            return config\n\n        return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        config = ChunksConfig(\n            cache_dir=self._cache_dir,\n            serializers=self._serializers,\n            remote_input_dir=self._remote_input_dir,\n            item_loader=self._item_loader,\n        )\n        if config.is_ready():\n            self._config = config\n            return config\n        return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Try to load the chunks configuration\n        try:\n            self._config = ChunksConfig(\n                cache_dir=self._cache_dir,\n                remote_input_dir=self._remote_input_dir,\n                serializers=self._serializers,\n                item_loader=self._item_loader,\n            )\n        except FileNotFoundError:\n            return None\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Load the chunks configuration\n        config = ChunksConfig(\n            cache_dir=self._cache_dir,\n            remote_input_dir=self._remote_input_dir,\n            compression=self._compression,\n            serializers=self._serializers,\n            item_loader=self._item_loader,\n        )\n\n        # Check if the index files exist\n        if config.has_index():\n            self._config = config\n            return config\n\n        return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        config = ChunksConfig(\n            cache_dir=self._cache_dir,\n            remote_input_dir=self._remote_input_dir,\n            compression=self._compression,\n            serializers=self._serializers,\n            item_loader=self._item_loader,\n        )\n\n        if config.exists():\n            self._config = config\n            return config\n\n        return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        try:\n            self._config = ChunksConfig(\n                cache_dir=self._cache_dir,\n                remote_input_dir=self._remote_input_dir,\n                serializers=self._serializers,\n                compression=self._compression,\n                item_loader=self._item_loader,\n            )\n            return self._config\n        except FileNotFoundError:\n            return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Load the chunks configuration\n        config = ChunksConfig(\n            cache_dir=self._cache_dir,\n            remote_input_dir=self._remote_input_dir,\n            serializers=self._serializers,\n            compression=self._compression,\n            item_loader=self._item_loader,\n        )\n\n        # If the chunks configuration could be loaded, return the configuration\n        if config.exists():\n            self._config = config\n            return config\n\n        # Otherwise, return None\n        return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        try:\n            self._config = ChunksConfig(\n                cache_dir=self._cache_dir,\n                serializers=self._serializers,\n                remote_input_dir=self._remote_input_dir,\n                item_loader=self._item_loader,\n            )\n            return self._config\n        except Exception:\n            return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Load the config\n        config = ChunksConfig(\n            cache_dir=self._cache_dir,\n            remote_input_dir=self._remote_input_dir,\n            compression=self._compression,\n            serializers=self._serializers,\n            item_loader=self._item_loader,\n        )\n\n        # Check if the index files are available\n        if config.is_index_available():\n            self._config = config\n            return config\n        return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        config = ChunksConfig(\n            cache_dir=self._cache_dir,\n            remote_input_dir=self._remote_input_dir,\n            serializers=self._serializers,\n            item_loader=self._item_loader,\n        )\n        if config.load():\n            self._config = config\n            return config\n        return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Try to load the chunks configuration\n        config = ChunksConfig(\n            cache_dir=self._cache_dir,\n            remote_input_dir=self._remote_input_dir,\n            serializers=self._serializers,\n            compression=self._compression,\n            item_loader=self._item_loader,\n        )\n\n        if config.load():\n            self._config = config\n            return config\n\n        return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Load the chunks config\n        config = ChunksConfig(\n            cache_dir=self._cache_dir,\n            remote_input_dir=self._remote_input_dir,\n            serializers=self._serializers,\n            compression=self._compression,\n        )\n\n        # Check whether the index files are available\n        if not config.is_index_available():\n            return None\n\n        # Update the instance's config\n        self._config = config\n\n        # Load the intervals\n        self._intervals = config.get_intervals()\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        try:\n            self._config = ChunksConfig(\n                cache_dir=self._cache_dir,\n                remote_input_dir=self._remote_input_dir,\n                serializers=self._serializers,\n                compression=self._compression,\n            )\n            return self._config\n        except FileNotFoundError:\n            return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Load the chunks config\n        config = ChunksConfig(\n            cache_dir=self._cache_dir,\n            serializers=self._serializers,\n            remote_input_dir=self._remote_input_dir,\n            item_loader=self._item_loader,\n        )\n\n        # If the config is empty, we don't have the index files.\n        if config.num_chunks == 0:\n            return None\n\n        # Update the reader's configuration\n        self._config = config\n        self._intervals = self._config.intervals\n        self._last_chunk_index = self._config.num_chunks - 1\n\n        return config\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        self._to_download_queue.put(chunk_indexes)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        self._to_download_queue.put(chunk_indexes)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            if chunk_index not in self._chunks_index_to_be_deleted:\n                self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        # We need to make sure that we do not download a chunk twice\n        # This can happen if we have multiple processes on the same node\n        # and the same chunks are assigned to multiple processes\n        # We need to make sure that only one process downloads the chunk\n        # and the others wait for the chunk to be downloaded\n        # and then use it from the cache\n        self._to_download_queue.put(chunk_indexes)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        if self._has_exited:\n            return\n\n        for chunk_index in chunk_indexes:\n            if self._has_exited:\n                return\n\n            if self._distributed_env.rank == 0:\n                self._to_download_queue.put(chunk_index)\n            else:\n                # Wait for the first node to enqueue the chunk\n                self._to_download_queue.get()\n\n        if self._distributed_env.rank == 0:\n            # Wait for the last chunk to be processed\n            self._to_download_queue.join()\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        # This is a threaded function, so we need to catch all exceptions.\n        try:\n            # If the thread has already exited, we should not enter it.\n            if self._has_exited:\n                return\n\n            # Add the chunks to the download queue\n            for chunk_index in chunk_indexes:\n                self._to_download_queue.put(chunk_index)\n\n            # We also need to delete some chunks if the cache size is too large.\n            if self._delete_chunks_when_processed:\n                self._chunks_index_to_be_deleted.extend(self._config.chunks_indexes)\n\n        except Exception as e:\n            # If the thread has already exited, we should not enter it.\n            if self._has_exited:\n                return\n            logger.error(f\"Exception in PrepareChunksThread: {e}\")\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not defined.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not set.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not set.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not set yet.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not set.\")\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not defined. Please define it before accessing it.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not set.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not set.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not set yet.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not set.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not defined.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The config is not defined.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\n                \"The configuration is not set. Please call the `set_index` method to set the index before accessing it.\"\n            )\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not set.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not defined.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not defined yet.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\n                \"The configuration is not set. You need to call the `set_index` function before accessing the configuration.\"\n            )\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not defined.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not set. Please use the `load_config` method to set the configuration.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not defined.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The index must be an instance of ChunkedIndex, not {type(index)}.\")\n\n        if self._config is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Check that the chunk is available locally\n        if self._config.is_chunk_available_locally(index):\n            return self._item_loader.load_item(index, self._config[index])\n\n        # Check that the chunk is available in memory\n        if self._config.is_chunk_available_in_memory(index):\n            return self._item_loader.load_item(index, self._config[index])\n\n        # Check that the chunk is available in the cache\n        if self._config.is_chunk_available_in_cache(index):\n            self._config.load_chunk_from_cache(index)\n            return self._item_loader.load_item(index, self._config[index])\n\n        # Check that the chunk is available remotely\n        if self._config.is_chunk_available_remotely(index):\n            self._config.download_chunk_from_remote(index)\n            return self._item_loader.load_item(index, self._config[index])\n\n        # Check that the chunk is available in the prepare thread\n        if self._prepare_thread is not None:\n            assert self._prepare_thread._has_exited, \"The prepare thread is not running.\"\n\n        # Check that the chunk is available in the prepare thread\n        if self._prepare_thread is not None:\n            assert self._prepare_thread._has_exited, \"The prepare thread is not running.\"\n\n        # Check that the chunk is available in the prepare thread\n        if self._prepare_thread is not None:\n            assert self._prepare_thread._has_exited, \"The prepare thread is not running.\"\n\n        # Check that the chunk is available in the prepare thread\n        if self._prepare_thread is not None:\n            assert self._prepare_thread._has_exited, \"The prepare thread is not running.\"\n\n       "}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index should be an instance of ChunkedIndex.\")\n\n        if self._config is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Check if the chunk is already loaded\n        if index.chunk_index in self._item_loader.loaded_chunks:\n            return self._item_loader.get_item(index)\n\n        # Check if the chunk is available locally\n        chunk_filepath, _, _ = self._config[index]\n        if os.path.exists(chunk_filepath):\n            return self._item_loader.load_chunk(index)\n\n        # Check if the chunk is available in the cache\n        chunk_filepath, _, _ = self._config[index]\n        chunk_filepath = os.path.join(self._cache_dir, chunk_filepath)\n        if os.path.exists(chunk_filepath):\n            return self._item_loader.load_chunk(index)\n\n        # Check if the chunk is available remotely\n        if self._remote_input_dir is not None:\n            chunk_filepath = os.path.join(self._remote_input_dir, chunk_filepath)\n            if os.path.exists(chunk_filepath):\n                return self._item_loader.load_chunk(index)\n\n        # Check if the chunk is available in the cache\n        if os.path.exists(chunk_filepath):\n            return self._item_loader.load_chunk(index)\n\n        # Check if the chunk is available remotely\n        if self._remote_input_dir is not None:\n            chunk_filepath = os.path.join(self._remote_input_dir, chunk_filepath)\n            if os.path.exists(chunk_filepath):\n                return self._item_loader.load_chunk(index)\n\n        # Check if the chunk is available in the cache\n        if os.path.exists(chunk_filepath):\n            return self._item_loader.load_chunk(index)\n\n        # Check if the chunk is available remot"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The provided index must be an instance of ChunkedIndex. Found {index}.\")\n\n        if self._config is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread should be defined.\")\n\n        # Get the chunk index from the global index\n        chunk_index = self._get_chunk_index_from_index(index.index)\n\n        # Load the chunk if it isn't already loaded\n        if self._prepare_thread.is_chunk_loaded(chunk_index) is False:\n            self._prepare_thread.download(chunk_index)\n\n        # Load the item from the chunk\n        return self._item_loader.load_item(index, self._config[index])\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The provided index is not an instance of ChunkedIndex. Found {type(index)}\")\n\n        if self._config is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Check whether the chunk is already loaded\n        chunk_index = self._config._get_chunk_index_from_index(index.index)\n        if chunk_index != self._last_chunk_index:\n            self._prepare_thread._pre_load_chunk(chunk_index)\n            self._last_chunk_index = chunk_index\n\n        return self._item_loader.load_item(index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The provided index {index} is not an instance of ChunkedIndex.\")\n\n        # Load the config containing the index\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Check if the chunk is available locally\n        chunk_index = self._config._get_chunk_index_from_index(index.index)\n        chunk_filepath, _, _ = self._config[chunk_index]\n        if os.path.exists(chunk_filepath):\n            return self._item_loader.load_item(chunk_index, index.item_index)\n\n        # Check if the chunk is available in memory\n        if self._prepare_thread is not None:\n            assert self._prepare_thread is not None\n            if self._prepare_thread._item_loader.is_chunk_available(chunk_index):\n                return self._item_loader.load_item(chunk_index, index.item_index)\n\n        # If not, initiate the download\n        if self._prepare_thread is None:\n            self._prepare_thread = PrepareChunksThread(\n                self._config, self._item_loader, self._distributed_env, self._max_cache_size\n            )\n            self._prepare_thread.start()\n\n        self._prepare_thread.download([chunk_index])\n        return self._item_loader.load_item(chunk_index, index.item_index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The index must be an instance of ChunkedIndex, but got {type(index)}\")\n\n        if self._config is None:\n            raise Exception(\"The config should be defined.\")\n\n        # Get the chunk index from the index\n        chunk_index = self._get_chunk_index_from_index(index.index)\n\n        # Get the chunk filepath\n        chunk_filepath, _, _ = self._config[index]\n\n        # Download the chunk if needed\n        if not self._config.is_chunk_cached(chunk_index):\n            self._prepare_thread.download([chunk_index])\n\n        # Load the chunk\n        return self._item_loader.load_item(chunk_index, chunk_filepath, index.index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The index should be a ChunkedIndex.\")\n\n        # Load the config containing the index\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Check whether the chunk is available locally\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        chunk_filepath, _, _ = self._config[index]\n        if not os.path.exists(chunk_filepath):\n            # Check whether the chunk is available in memory\n            if chunk_index not in self._prepare_thread._item_loader._chunks_in_memory:  # type: ignore\n                # Download the chunk\n                self._prepare_thread.download([chunk_index])  # type: ignore\n\n        # Load the item\n        item = self._item_loader.load_item(index, chunk_filepath)\n\n        # Check whether the chunk is fully consumed\n        if chunk_index in self._prepare_thread._item_loader._chunks_in_memory:  # type: ignore\n            # Delete the chunk if it is fully consumed\n            self._prepare_thread._item_loader.delete(chunk_index, chunk_filepath)  # type: ignore\n\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The index must be an instance of ChunkedIndex but got {index}.\")\n\n        if self._config is None:\n            raise Exception(\"The config should be defined.\")\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread should be defined.\")\n\n        # Get the chunk index from the index\n        chunk_index = self._get_chunk_index_from_index(index.index)\n\n        # Check whether the chunk is available locally\n        if self._config.is_chunk_available_locally(chunk_index):\n            return self._config[index]\n\n        # Check whether the chunk is available in memory\n        if self._config.is_chunk_available_in_memory(chunk_index):\n            return self._config[index]\n\n        # Check whether the chunk is already being downloaded\n        if chunk_index in self._prepare_thread._chunks_index_to_be_deleted:\n            # Wait for the chunk to be downloaded\n            while chunk_index in self._prepare_thread._chunks_index_to_be_deleted:\n                pass\n\n            # The chunk is now available locally\n            return self._config[index]\n\n        # Check whether the chunk is being downloaded\n        if chunk_index in self._prepare_thread._to_download_queue._queue:\n            # Wait for the chunk to be downloaded\n            while chunk_index in self._prepare_thread._to_download_queue._queue:\n                pass\n\n            # The chunk is now available locally\n            return self._config[index]\n\n        # Check whether the chunk is already being pre-loaded\n        if chunk_index in self._prepare_thread._to_delete_queue._queue:\n            # Wait for the chunk to be pre-loaded\n            while chunk_index in self._prepare_thread._to_delete_queue._queue:\n                pass\n\n            # The chunk is now available locally\n            return self._config[index]\n\n        # Check whether the chunk is being pre-loaded\n        if chunk_index in self._prepare_thread._chunks_index_"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        # Check if the index is valid\n        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index is not a ChunkedIndex.\")\n\n        # Check if the config is defined\n        if self._config is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Check if the prepare thread is running\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread isn't running.\")\n\n        # Get the chunk index\n        chunk_index = self._get_chunk_index_from_index(index.index)\n\n        # Check if the chunk is already loaded\n        if chunk_index in self._prepare_thread._item_loader._chunks_in_memory:\n            return self._prepare_thread._item_loader.load(index)\n\n        # Check if the chunk is available locally\n        chunk_filepath = self._config[index]\n        if os.path.exists(chunk_filepath):\n            # Load the chunk\n            self._prepare_thread._item_loader.load_chunk(chunk_index, chunk_filepath)\n            return self._prepare_thread._item_loader.load(index)\n\n        # Check if the chunk is available in the cache\n        chunk_filepath = os.path.join(self._cache_dir, os.path.basename(chunk_filepath))\n        if os.path.exists(chunk_filepath):\n            # Load the chunk\n            self._prepare_thread._item_loader.load_chunk(chunk_index, chunk_filepath)\n            return self._prepare_thread._item_loader.load(index)\n\n        # Check if the chunk is available remotely\n        chunk_filepath = os.path.join(self._remote_input_dir, os.path.basename(chunk_filepath))\n        if os.path.exists(chunk_filepath):\n            # Load the chunk\n            self._prepare_thread._item_loader.load_chunk(chunk_index, chunk_filepath)\n            return self._prepare_thread._item_loader.load(index)\n\n        # Check if the chunk is in"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index should be an instance of ChunkedIndex.\")\n\n        # Load the config containing the index\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Check if the chunk is already loaded\n        if self._item_loader.is_chunk_loaded(index.chunk_index):\n            return self._item_loader.read(index)\n\n        # Check if the chunk is available locally\n        chunk_filepath, _, _ = self._config[index]\n        if not os.path.exists(chunk_filepath):\n            self._prepare_thread.download(index.chunk_index)\n\n        # Check if the chunk is available in memory\n        if self._item_loader.is_chunk_loaded(index.chunk_index):\n            return self._item_loader.read(index)\n\n        # If not, load the chunk\n        self._config.download_chunk_from_index(index.chunk_index)\n        self._item_loader.load_chunk(index.chunk_index, chunk_filepath)\n\n        return self._item_loader.read(index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        # Check that the index is of the correct type\n        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\n                f\"The index must be an instance of ChunkedIndex but got {index} of type {type(index)}.\"\n            )\n\n        # Check that the config is defined\n        if self._config is None:\n            raise Exception(\"The config must be defined.\")\n\n        # Check that the prepare thread is defined\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread must be defined.\")\n\n        # Check if the chunk is available locally\n        chunk_index = self._config._get_chunk_index_from_index(index.index)\n        chunk_filepath, _, _ = self._config[chunk_index]\n        if os.path.exists(chunk_filepath):\n            return self._item_loader.load(index, chunk_filepath)\n\n        # Check if the chunk is available in memory\n        if self._prepare_thread._item_loader.is_chunk_available(chunk_index, chunk_filepath):\n            return self._item_loader.load(index, chunk_filepath)\n\n        # Check if the chunk is available remotely\n        if self._remote_input_dir is not None:\n            remote_chunk_filepath = os.path.join(self._remote_input_dir, os.path.basename(chunk_filepath))\n            if os.path.exists(remote_chunk_filepath):\n                self._config.download_chunk_from_index(chunk_index)\n                return self._item_loader.load(index, chunk_filepath)\n\n        # Check if the chunk is available in the cache\n        if self._cache_dir is not None:\n            cache_chunk_filepath = os.path.join(self._cache_dir, os.path.basename(chunk_filepath))\n            if os.path.exists(cache_chunk_filepath):\n                self._config.download_chunk_from_index(chunk_index)\n                return self._item_loader.load(index, chunk_filepath)\n\n        # Check"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The index must be an instance of ChunkedIndex, but got {index}.\")\n\n        if self._config is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread isn't defined.\")\n\n        # Check whether the chunk is already downloaded\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        chunk_filepath, _, _ = self._config[index]\n        chunk_is_available = os.path.exists(chunk_filepath)\n\n        # Download the chunk if it's not available\n        if not chunk_is_available:\n            self._prepare_thread.download([chunk_index])\n\n        # Load the item\n        return self._item_loader.load_item(index, chunk_filepath)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The index must be an instance of ChunkedIndex.\")\n\n        if self._config is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread is not defined.\")\n\n        # Get the chunk index from the index\n        chunk_index = self._get_chunk_index_from_index(index.index)\n\n        # Check if the chunk is available locally\n        if self._config.is_chunk_cached(chunk_index):\n            return self._item_loader.load_item(index, self._config[index])\n\n        # Check if the chunk is available in memory\n        if self._config.is_chunk_loaded(chunk_index):\n            return self._item_loader.load_item(index, self._config[index])\n\n        # Check if the chunk is available remotely\n        if self._config.is_chunk_remote(chunk_index):\n            self._config.download_chunk_from_index(chunk_index)\n\n        # Check if the chunk is available in the download queue\n        if self._prepare_thread._to_download_queue.qsize() > 0:\n            self._prepare_thread._to_download_queue.put(chunk_index)\n\n        # Wait for the chunk to be available locally\n        while not self._config.is_chunk_cached(chunk_index):\n            pass\n\n        # Load the item\n        return self._item_loader.load_item(index, self._config[index])\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        # Check the type of the index\n        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The index should be an instance of ChunkedIndex but got {type(index)}.\")\n\n        # Check whether the index is defined\n        if self._config is None:\n            raise Exception(\"The config should be defined.\")\n\n        # Check whether the prepare thread is defined\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread should be defined.\")\n\n        # Check if the chunk is already loaded\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        if self._config.is_chunk_loaded(chunk_index):\n            return self._item_loader.load_item(chunk_index, index.item)\n\n        # Check if the chunk is available locally\n        chunk_filepath, chunk_index, chunk_size = self._config[index]\n        if os.path.exists(chunk_filepath):\n            # Load the chunk\n            self._config.load_chunk_from_index(chunk_index)\n            return self._item_loader.load_item(chunk_index, index.item)\n\n        # Check if the chunk is available in the cache\n        chunk_filepath, chunk_index, chunk_size = self._config[index]\n        if os.path.exists(chunk_filepath):\n            # Load the chunk\n            self._config.load_chunk_from_index(chunk_index)\n            return self._item_loader.load_item(chunk_index, index.item)\n\n        # Check if the chunk is available remotely\n        chunk_filepath, chunk_index, chunk_size = self._config[index]\n        if self._remote_input_dir is not None and os.path.exists(chunk_filepath):\n            # Load the chunk\n            self._config.load_chunk_from_index(chunk_index)\n            return self._item_loader.load_item(chunk_index, index.item)\n\n        # Download the chunk\n        self._prepare_thread.download([chunk_index])\n\n        # Load"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The index must be an instance of ChunkedIndex.\")\n\n        if self._config is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Get the chunk index from the index\n        chunk_index = self._get_chunk_index_from_index(index.index)\n\n        # Ensure the chunk is available either locally or in memory\n        if not self._config.is_chunk_available(chunk_index):\n            self._prepare_thread.download([chunk_index])\n\n        # Get the item from the chunk\n        item = self._item_loader.load(index, self._config[index])\n\n        # Handle the lifecycle of chunks\n        if self._config.is_chunk_fully_consumed(chunk_index):\n            # If the chunk is fully consumed, delete it\n            self._prepare_thread.delete([chunk_index])\n\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        # Check the index type\n        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\n                f\"The index must be an instance of ChunkedIndex, but got {type(index)}.\"\n            )\n\n        # Check the config\n        if self._config is None:\n            raise Exception(\"The config should be defined.\")\n\n        # Check the prepare thread\n        assert self._prepare_thread is not None, \"The prepare thread should be defined.\"\n\n        # Get the chunk index from the index\n        chunk_index = self._get_chunk_index_from_index(index.index)\n\n        # Check whether the chunk is available locally\n        if not self._config.is_chunk_available_locally(chunk_index):\n            # If not, check whether the chunk is available in memory\n            if not self._config.is_chunk_available_in_memory(chunk_index):\n                # If not, download the chunk\n                self._prepare_thread.download([chunk_index])\n\n            # Load the chunk\n            self._config.load_chunk_from_index(chunk_index)\n\n        # Get the item\n        item = self._item_loader.load_item(index)\n\n        # Check whether the chunk is fully consumed\n        if self._config.is_chunk_consumed(chunk_index):\n            # If so, delete it\n            self._prepare_thread.delete([chunk_index])\n\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The index must be an instance of ChunkedIndex, but got {index}.\")\n\n        # If the config is not defined, we cannot read anything\n        if self._config is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # If the chunk is not available, we need to download it\n        if not self._config.is_chunk_available(index.chunk_index):\n            self._download_chunk(index.chunk_index)\n\n        # If the chunk is available, we need to load it\n        if not self._config.is_chunk_loaded(index.chunk_index):\n            self._load_chunk(index.chunk_index)\n\n        # If the chunk is loaded, we need to load the item\n        if not self._config.is_item_loaded(index):\n            self._load_item(index)\n\n        # If the item is loaded, we can return it\n        if self._config.is_item_loaded(index):\n            return self._config[index]\n\n        raise Exception(\"The item should be loaded.\")\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The index {index} is not a valid ChunkedIndex.\")\n\n        # Check whether the config is defined\n        if self._config is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Get the chunk index from the global index\n        chunk_index = self._get_chunk_index_from_index(index.index)\n\n        # If the chunk is already loaded, return the item\n        if self._item_loader.is_chunk_loaded(chunk_index):\n            return self._item_loader.load(index, self._config)\n\n        # If the chunk is not loaded, load it\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread is not defined.\")\n\n        # Load the chunk\n        self._prepare_thread.download([chunk_index])\n\n        # Return the item\n        return self._item_loader.load(index, self._config)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The provided index is not an instance of ChunkedIndex. Received: {index}\")\n\n        # Ensure the config is available\n        if self._config is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Check if the chunk is available locally\n        if self._config.is_chunk_available_locally(index.chunk_index):\n            return self._config.read_item(index)\n\n        # Check if the chunk is available in memory\n        if self._config.is_chunk_available_in_memory(index.chunk_index):\n            return self._config.read_item(index)\n\n        # Check if the chunk is available remotely\n        if self._config.is_chunk_available_remotely(index.chunk_index):\n            self._config.download_chunk_from_index(index.chunk_index)\n            return self._config.read_item(index)\n\n        # Check if the chunk is available in cache\n        if self._config.is_chunk_available_in_cache(index.chunk_index):\n            self._config.download_chunk_from_index(index.chunk_index)\n            return self._config.read_item(index)\n\n        # If the chunk is not available locally, download it.\n        # The chunk is downloaded in a separate thread.\n        # We first check if the thread is available, if not, we create it.\n        if self._prepare_thread is None:\n            self._prepare_thread = PrepareChunksThread(\n                self._config,\n                self._item_loader,\n                self._distributed_env,\n                max_cache_size=self._max_cache_size,\n                max_pre_download=self._worker_env.world_size,\n            )\n            self._prepare_thread.start()\n\n        # The thread is available, we download the chunk\n        self._prepare_thread.download([index.chunk_index])\n\n        # We read the item\n        return self._config.read_item(index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The index must be a ChunkedIndex, but got {type(index)}\")\n\n        if self._config is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n\n        # The chunk is already loaded\n        if chunk_index in self._config.loaded_chunks:\n            return self._item_loader.load(index, self._config.loaded_chunks[chunk_index])\n\n        # The chunk is not loaded, but it is available locally\n        if chunk_index in self._config.available_chunks:\n            self._config.load_chunk_from_index(chunk_index)\n            return self._item_loader.load(index, self._config.loaded_chunks[chunk_index])\n\n        # The chunk is not loaded, but it is available remotely\n        if chunk_index in self._config.remote_chunks:\n            self._config.download_chunk_from_index(chunk_index)\n            return self._item_loader.load(index, self._config.loaded_chunks[chunk_index])\n\n        # The chunk is not loaded, and it is not available locally or remotely\n        if chunk_index not in self._config.available_chunks:\n            # If the chunk is not available locally, we need to download it\n            self._prepare_thread.download(chunk_index)\n\n        # The chunk is not loaded, but it is available in the cache\n        if chunk_index in self._config.cache_chunks:\n            self._config.load_chunk_from_index(chunk_index)\n            return self._item_loader.load(index, self._config.loaded_chunks[chunk_index])\n\n        # The chunk is not loaded, and it is not available locally, remotely or in the cache\n        # If the chunk is not available locally, we need to download it\n        self._prepare_thread.download(chunk_index)\n\n        # If the chunk is not available locally, we"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    try:\n        return _immutable_distributed_map.set_and_get(key, obj)\n    except (RuntimeError, requests.exceptions.ConnectionError, urllib3.exceptions.MaxRetryError):\n        return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if not os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\"):\n        return obj\n\n    distributed_map = _ImmutableDistributedMap()\n    return distributed_map.set_and_get(key, obj)\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    try:\n        return _IMMUTABLE_DISTRIBUTED_MAP.set_and_get(key, obj)\n    except (requests.exceptions.ConnectionError, urllib3.exceptions.MaxRetryError):\n        return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    try:\n        return _immutable_distributed_map.set_and_get(key, obj)\n    except (RuntimeError, requests.exceptions.ConnectionError, urllib3.exceptions.MaxRetryError):\n        return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is None:\n        return obj\n\n    if os.getenv(\"LIGHTNING_APP_STATE_URL\") is None:\n        raise RuntimeError(\"The `LIGHTNING_APP_STATE_URL` should be set.\")\n\n    return _ImmutableDistributedMap().set_and_get(key, obj)\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    distributed_map = _ImmutableDistributedMap()\n    return distributed_map.set_and_get(key, obj)\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    try:\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    except (RuntimeError, requests.exceptions.ConnectionError, urllib3.exceptions.MaxRetryError):\n        return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    distributed_map = _ImmutableDistributedMap()\n    return distributed_map.set_and_get(key, obj)\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    # If the environment variable is set, we are in a distributed environment.\n    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is not None:\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    else:\n        return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    try:\n        distributed_map = _ImmutableDistributedMap()\n        return distributed_map.set_and_get(key, obj)\n    except (requests.exceptions.ConnectionError, urllib3.exceptions.MaxRetryError):\n        # not in a distributed environment\n        return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    try:\n        return _IMMUTABLE_DISTRIBUTED_MAP.set_and_get(key, obj)\n    except RuntimeError:\n        return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    distributed_map = _ImmutableDistributedMap()\n    return distributed_map.set_and_get(key, obj)\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    try:\n        return _IMMUTABLE_DISTRIBUTED_MAP.set_and_get(key, obj)\n    except requests.exceptions.ConnectionError:\n        # not in a distributed environment\n        return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if _get_token() is None:\n        return obj\n\n    return _ImmutableDistributedMap().set_and_get(key, obj)\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    try:\n        immutable_distributed_map = _ImmutableDistributedMap()\n        return immutable_distributed_map.set_and_get(key, obj)\n    except (requests.exceptions.ConnectionError, urllib3.exceptions.MaxRetryError):\n        # Not running in a distributed environment\n        return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    # If the LIGHTNING_APP_EXTERNAL_URL environment variable is not set, we are not in a distributed environment.\n    # So we can simply return the object as is.\n    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is None:\n        return obj\n\n    # If we are in a distributed environment, we use the _ImmutableDistributedMap to broadcast the object.\n    else:\n        immutable_distributed_map = _ImmutableDistributedMap()\n        return immutable_distributed_map.set_and_get(key, obj)\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is None:\n        return obj\n\n    return _ImmutableDistributedMap().set_and_get(key, obj)\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    # try to use the distributed map\n    try:\n        distributed_map = _ImmutableDistributedMap()\n        return distributed_map.set_and_get(key, obj)\n    except (RuntimeError, requests.exceptions.ConnectionError, urllib3.exceptions.MaxRetryError):\n        # fallback to the original object\n        return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if not _is_running_in_a_distributed_environment():\n        return obj\n\n    return _IMMUTABLE_DISTRIBUTED_MAP.set_and_get(key, obj)\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    # TODO: we should use the distributed map for all the cases (not just in the distributed environment)\n    # so that we can use it for debugging purposes\n    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is None:\n        return obj\n\n    # TODO: we should use a cache here to avoid querying the distributed map every time\n    # the broadcast is called.\n    distributed_map = _ImmutableDistributedMap()\n    return distributed_map.set_and_get(key, obj)\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Get the number of chunks assigned to each node\n    chunks_per_node = [len(chunks) for chunks in chunks_per_ranks]\n\n    # Get the number of chunks assigned to each rank\n    chunks_per_rank = [len(chunks) for chunks in chunks_per_ranks[distributed_env.rank]]\n\n    # Get the number of chunks assigned to each node\n    chunks_per_node = [len(chunks) for chunks in chunks_per_ranks]\n\n    # Get the number of chunks assigned to each rank\n    chunks_per_rank = [len(chunks) for chunks in chunks_per_ranks[distributed_env.rank]]\n\n    # Get the number of chunks assigned to each node\n    chunks_per_node = [len(chunks) for chunks in chunks_per_ranks]\n\n    # Get the number of chunks assigned to each rank\n    chunks_per_rank = [len(chunks) for chunks in chunks_per_ranks[distributed_env.rank]]\n\n    # Get the number of chunks assigned to each node\n    chunks_per_node = [len(chunks) for chunks in chunks_per_ranks]\n\n    # Get the number of chunks assigned to each rank\n    chunks_per_rank = [len(chunks) for chunks in chunks_per_ranks[distributed_env.rank]]\n\n    # Get the number of chunks assigned to each node\n    chunks_per_node = [len(chunks) for chunks in chunks_per_ranks]\n\n    # Get the number of chunks assigned to each rank\n    chunks_per_rank = [len(chunks) for chunks in chunks_per_ranks[distributed_env.rank]]\n\n    # Get the number of chunks assigned to each node\n    chunks_per_node = [len(chunks) for chunks in chunks_per_ranks]\n\n    # Get the number of chunks assigned to each rank"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # get the world size\n    world_size = distributed_env.world_size\n\n    # get the rank\n    rank = distributed_env.rank\n\n    # get the number of chunks assigned to the current node\n    chunks_per_node = len(chunks_per_ranks[rank])\n\n    # get the number of chunks assigned to each rank\n    chunks_per_rank = [len(chunks_per_ranks[i]) for i in range(world_size)]\n\n    # get the number of chunks assigned to each node\n    chunks_per_node = [chunks_per_rank[i] for i in range(world_size) if i % world_size == rank]\n\n    # get the number of chunks assigned to each node\n    chunks_per_node = np.array(chunks_per_node)\n\n    # get the number of chunks assigned to each node\n    chunks_per_node = np.array(chunks_per_node)\n\n    # get the number of chunks assigned to each node\n    chunks_per_node = np.array(chunks_per_node)\n\n    # get the number of chunks assigned to each node\n    chunks_per_node = np.array(chunks_per_node)\n\n    # get the number of chunks assigned to each node\n    chunks_per_node = np.array(chunks_per_node)\n\n    # get the number of chunks assigned to each node\n    chunks_per_node = np.array(chunks_per_node)\n\n    # get the number of chunks assigned to each node\n    chunks_per_node = np.array(chunks_per_node)\n\n    # get the number of chunks assigned to each node\n    chunks_per_node = np.array(chunks_per_node)\n\n    # get the number of chunks assigned to each node\n    chunks_per_node = np.array(chunks_per_node)\n\n    # get the number of chunks assigned to each node\n    chunks_per_node = np."}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # set seed for reproducibility\n    np.random.seed(seed + current_epoch)\n\n    # shuffle chunk indexes\n    shuffled_chunks = []\n    for rank_chunks in chunks_per_ranks:\n        shuffled_chunks.extend(np.random.permutation(rank_chunks).tolist())\n\n    # return shuffled chunks\n    return shuffled_chunks\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Get the number of chunks assigned to each node\n    chunks_per_node = np.array(\n        [len(chunks_per_ranks[rank]) for rank in range(distributed_env.world_size)]\n    )\n\n    # Get the number of chunks assigned to each rank in the node\n    chunks_per_rank = np.array(\n        [len(chunks_per_ranks[rank]) for rank in distributed_env.ranks_in_node]\n    )\n\n    # Get the number of chunks assigned to each rank in the node\n    chunks_per_rank = np.array(\n        [len(chunks_per_ranks[rank]) for rank in distributed_env.ranks_in_node]\n    )\n\n    # Get the number of chunks assigned to each rank in the node\n    chunks_per_rank = np.array(\n        [len(chunks_per_ranks[rank]) for rank in distributed_env.ranks_in_node]\n    )\n\n    # Get the number of chunks assigned to each rank in the node\n    chunks_per_rank = np.array(\n        [len(chunks_per_ranks[rank]) for rank in distributed_env.ranks_in_node]\n    )\n\n    # Get the number of chunks assigned to each rank in the node\n    chunks_per_rank = np.array(\n        [len(chunks_per_ranks[rank]) for rank in distributed_env.ranks_in_node]\n    )\n\n    # Get the number of chunks assigned to each rank in the node\n    chunks_per_rank = np.array(\n        [len(chunks_per_ranks[rank]) for rank in distributed_env.ranks_in_node]\n    )\n\n    # Get the number of chunks assigned to each rank in the node\n    chunks_per_rank = np.array(\n        [len(chunks_per_ranks[rank]) for rank in distributed_env.ranks_in_node]\n    )\n\n    # Get the number"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # get the chunk indexes assigned to the current node\n    chunk_indexes = chunks_per_ranks[distributed_env.rank]\n\n    # shuffle the chunk indexes\n    np.random.seed(seed + current_epoch)\n    np.random.shuffle(chunk_indexes)\n\n    # return the shuffled chunk indexes\n    return chunk_indexes\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # get the number of chunks per rank\n    chunks_per_rank = [len(chunks_per_ranks[i]) for i in range(distributed_env.world_size)]\n\n    # get the number of chunks per node\n    chunks_per_node = [chunks_per_rank[i] // distributed_env.num_nodes for i in range(distributed_env.world_size)]\n\n    # get the number of chunks per node for the current rank\n    chunks_per_node_current_rank = chunks_per_node[distributed_env.rank]\n\n    # get the number of chunks per node for the current node\n    chunks_per_node_current_node = chunks_per_node_current_rank // distributed_env.num_nodes_current_node\n\n    # get the number of chunks per node for the current node for the current rank\n    chunks_per_node_current_node_current_rank = chunks_per_node_current_node // distributed_env.num_ranks_current_node\n\n    # get the number of chunks per node for the current node for the current rank\n    chunks_per_node_current_node_current_rank = chunks_per_node_current_node // distributed_env.num_ranks_current_node\n\n    # get the number of chunks per node for the current node for the current rank\n    chunks_per_node_current_node_current_rank = chunks_per_node_current_node // distributed_env.num_ranks_current_node\n\n    # get the number of chunks per node for the current node for the current rank\n    chunks_per_node_current_node_current_rank = chunks_per_node_current_node // distributed_env.num_ranks_current_node\n\n    # get the number of chunks per node for the current node for the current rank\n    chunks_per_node_current_node_current_rank = chunks_per_node_current_node // distributed_env.num_ranks_current_node\n\n    # get"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # get the chunk indexes assigned to each node\n    chunks_per_node = [chunks_per_ranks[rank] for rank in range(distributed_env.node_rank * distributed_env.ranks_per_node, (distributed_env.node_rank + 1) * distributed_env.ranks_per_node)]\n\n    # flatten the list of chunk indexes assigned to each node\n    chunks_per_node = [chunk for sublist in chunks_per_node for chunk in sublist]\n\n    # shuffle the chunks assigned to each node\n    np.random.seed(seed + current_epoch)\n    np.random.shuffle(chunks_per_node)\n\n    return chunks_per_node\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Get the number of chunks assigned to the current node\n    num_chunks = len(chunks_per_ranks[distributed_env.rank])\n\n    # Get the number of chunks assigned to the current node\n    num_chunks = len(chunks_per_ranks[distributed_env.rank])\n\n    # Create a random permutation of the chunk indexes\n    np.random.seed(seed + current_epoch)\n    chunk_indexes = np.arange(num_chunks)\n    np.random.shuffle(chunk_indexes)\n\n    # Get the number of chunks assigned to the current node\n    num_chunks = len(chunks_per_ranks[distributed_env.rank])\n\n    # Create a random permutation of the chunk indexes\n    np.random.seed(seed + current_epoch)\n    chunk_indexes = np.arange(num_chunks)\n    np.random.shuffle(chunk_indexes)\n\n    # Get the number of chunks assigned to the current node\n    num_chunks = len(chunks_per_ranks[distributed_env.rank])\n\n    # Create a random permutation of the chunk indexes\n    np.random.seed(seed + current_epoch)\n    chunk_indexes = np.arange(num_chunks)\n    np.random.shuffle(chunk_indexes)\n\n    # Return the shuffled chunk indexes\n    return chunk_indexes\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # get the number of chunks per node\n    chunks_per_node = [len(chunks_per_ranks[rank]) for rank in range(distributed_env.world_size)]\n\n    # get the number of chunks per rank\n    chunks_per_rank = [len(chunks_per_ranks[rank]) for rank in range(distributed_env.world_size)]\n\n    # get the total number of chunks\n    total_chunks = sum(chunks_per_rank)\n\n    # get the number of chunks per node\n    chunks_per_node = [len(chunks_per_ranks[rank]) for rank in range(distributed_env.world_size)]\n\n    # get the total number of chunks\n    total_chunks = sum(chunks_per_rank)\n\n    # get the seed for the current epoch\n    seed = seed + current_epoch\n\n    # get the chunk indexes for the current node\n    node_chunk_indexes = chunks_per_ranks[distributed_env.rank]\n\n    # get the number of chunks per node\n    chunks_per_node = [len(chunks_per_ranks[rank]) for rank in range(distributed_env.world_size)]\n\n    # get the total number of chunks\n    total_chunks = sum(chunks_per_rank)\n\n    # get the seed for the current epoch\n    seed = seed + current_epoch\n\n    # get the chunk indexes for the current node\n    node_chunk_indexes = chunks_per_ranks[distributed_env.rank]\n\n    # get the number of chunks per node\n    chunks_per_node = [len(chunks_per_ranks[rank]) for rank in range(distributed_env.world_size)]\n\n    # get the total number of chunks\n    total_chunks = sum(chunks_per_rank)\n\n    # get the seed for the current epoch\n    seed = seed + current_epoch\n\n    # get the chunk indexes for the current node\n   "}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # get the number of chunks assigned to each node\n    chunks_per_node = [len(chunks_per_ranks[rank]) for rank in range(distributed_env.world_size)]\n\n    # get the number of chunks assigned to each rank\n    chunks_per_rank = [chunks_per_ranks[rank][chunk] for rank in range(distributed_env.world_size) for chunk in range(chunks_per_node[rank])]\n\n    # shuffle the chunks based on the seed and the epoch number\n    np.random.seed(seed + current_epoch)\n    np.random.shuffle(chunks_per_rank)\n\n    # get the chunk indexes for each node\n    chunks_per_nodes = [chunks_per_rank[node::distributed_env.world_size] for node in range(distributed_env.world_size)]\n\n    # flatten the list of chunk indexes\n    return [chunk for chunks in chunks_per_nodes for chunk in chunks]\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Set the seed for random number generation\n    np.random.seed(seed + current_epoch)\n\n    # Create a list of chunk indexes assigned to this node\n    chunk_indexes = [chunk_index for chunk_indexes in chunks_per_ranks for chunk_index in chunk_indexes if chunk_indexes[0] == distributed_env.rank]\n\n    # Shuffle the chunk indexes\n    shuffled_chunk_indexes = np.random.permutation(chunk_indexes)\n\n    # Return the shuffled chunk indexes\n    return shuffled_chunk_indexes\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Get the number of chunks assigned to the current node\n    num_chunks = len(chunks_per_ranks[distributed_env.rank])\n\n    # Create a shuffled list of chunk indexes based on the provided seed and the current epoch\n    np.random.seed(seed + current_epoch)\n    shuffled_chunk_indexes = np.arange(num_chunks)\n    np.random.shuffle(shuffled_chunk_indexes)\n\n    # Create a list of shuffled chunk indexes across all nodes\n    shuffled_chunk_indexes = np.array_split(shuffled_chunk_indexes, distributed_env.world_size)\n    shuffled_chunk_indexes = np.concatenate(shuffled_chunk_indexes, axis=None)\n\n    # Return the shuffled chunk indexes\n    return shuffled_chunk_indexes\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Get the number of nodes\n    num_nodes = distributed_env.num_nodes\n\n    # Get the node index\n    node_index = distributed_env.node_index\n\n    # Get the world size\n    world_size = distributed_env.world_size\n\n    # Get the chunk index assigned to this node\n    chunks_per_node = chunks_per_ranks[node_index]\n\n    # Get the number of chunks assigned to this node\n    num_chunks_per_node = len(chunks_per_node)\n\n    # Get the number of chunks assigned to each node\n    num_chunks_per_rank = [len(chunks_per_ranks[rank_index]) for rank_index in range(num_nodes)]\n\n    # Get the number of chunks assigned to each rank\n    num_chunks_per_rank = np.array(num_chunks_per_rank)\n\n    # Get the number of chunks assigned to each rank\n    num_chunks_per_rank = num_chunks_per_rank[num_chunks_per_rank > 0]\n\n    # Get the number of chunks assigned to each rank\n    min_chunks_per_rank = num_chunks_per_rank.min()\n\n    # Get the number of chunks assigned to each rank\n    max_chunks_per_rank = num_chunks_per_rank.max()\n\n    # Get the number of chunks assigned to each rank\n    mean_chunks_per_rank = num_chunks_per_rank.mean()\n\n    # Get the number of chunks assigned to each rank\n    std_chunks_per_rank = num_chunks_per_rank.std()\n\n    # Get the number of chunks assigned to each rank\n    num_chunks_per_rank = num_chunks_per_rank.tolist()\n\n    # Get the number of chunks assigned to each rank\n    num_chunks_per_rank = [num_chunks_per_rank[rank_index] for rank_index in range(num_nodes)]\n\n   "}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # get the rank of the current node\n    rank = distributed_env.get_rank()\n\n    # get the number of nodes\n    world_size = distributed_env.get_world_size()\n\n    # get the number of chunks assigned to the current node\n    num_chunks = len(chunks_per_ranks[rank])\n\n    # create a seed for the current node\n    node_seed = seed + current_epoch\n\n    # create a random permutation of the chunks assigned to the current node\n    node_permutation = np.random.RandomState(seed=node_seed).permutation(num_chunks)\n\n    # get the chunk indexes assigned to each node\n    chunk_indexes = [chunks_per_ranks[rank][i] for i in node_permutation]\n\n    # flatten the chunk indexes across all nodes\n    chunk_indexes = [\n        item for sublist in chunks_per_ranks for item in sublist\n    ]  # flatten\n\n    return chunk_indexes\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # get the current rank\n    rank = distributed_env.rank\n\n    # get the number of ranks\n    world_size = distributed_env.world_size\n\n    # get the chunk indexes assigned to the current rank\n    chunks_per_rank = chunks_per_ranks[rank]\n\n    # get the number of chunks assigned to the current rank\n    num_chunks = len(chunks_per_rank)\n\n    # get the seed for the current epoch\n    seed = seed + current_epoch\n\n    # generate a random permutation of chunk indexes for the current rank\n    np.random.seed(seed)\n    perm = np.random.permutation(num_chunks)\n\n    # get the number of chunks assigned to each node\n    chunks_per_node = num_chunks // world_size\n\n    # get the number of chunks assigned to the current node\n    num_chunks_node = chunks_per_rank.size\n\n    # get the chunk indexes assigned to the current node\n    chunks_per_node = chunks_per_rank[perm[:num_chunks_node]]\n\n    # return the shuffled chunk indexes\n    return chunks_per_node\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Get the number of nodes and the current node\n    num_nodes = distributed_env.num_nodes\n    current_node = distributed_env.current_node\n\n    # Get the number of chunks and the number of chunks per node\n    num_chunks = len(chunks_per_ranks)\n    chunks_per_node = len(chunks_per_ranks[0])\n\n    # Get the seed for the current epoch\n    seed = seed + current_epoch\n\n    # Shuffle the chunks across nodes\n    chunk_indexes = list(range(num_chunks))\n    chunk_indexes = np.array(chunk_indexes)\n    np.random.seed(seed)\n    np.random.shuffle(chunk_indexes)\n\n    # Get the chunk indexes assigned to the current node\n    node_chunk_indexes = chunk_indexes[\n        current_node * chunks_per_node : (current_node + 1) * chunks_per_node\n    ]\n\n    # Get the chunk indexes assigned to the current node\n    node_chunk_indexes = chunk_indexes[\n        current_node * chunks_per_node : (current_node + 1) * chunks_per_node\n    ]\n\n    # Get the chunk indexes assigned to the current node\n    node_chunk_indexes = chunk_indexes[\n        current_node * chunks_per_node : (current_node + 1) * chunks_per_node\n    ]\n\n    # Shuffle the chunks across nodes\n    chunk_indexes = list(range(num_chunks))\n    chunk_indexes = np.array(chunk_indexes)\n    np.random.seed(seed)\n    np.random.shuffle(chunk_indexes)\n\n    # Get the chunk indexes assigned to the current node\n    node_chunk_indexes = chunk_indexes[\n        current_node * chunks_per_node : (current_node + 1) * chunks_per_node\n    ]\n\n    # Return the chunk indexes assigned to the current node\n    return node"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # get the node index\n    node_index = distributed_env.node_rank\n\n    # get the total number of nodes\n    total_nodes = distributed_env.world_size\n\n    # get the chunk index for the current node\n    chunk_index = chunks_per_ranks[node_index]\n\n    # shuffle the chunks for the current node\n    np.random.seed(seed + current_epoch)\n    np.random.shuffle(chunk_index)\n\n    # get the total number of chunks\n    total_chunks = len(chunk_index)\n\n    # get the chunk index for the current node\n    chunk_index = chunks_per_ranks[node_index]\n\n    # get the total number of chunks\n    total_chunks = len(chunk_index)\n\n    # get the chunk index for the current node\n    chunk_index = chunks_per_ranks[node_index]\n\n    # get the total number of chunks\n    total_chunks = len(chunk_index)\n\n    # create a list of chunk indexes for all nodes\n    chunk_index_all_nodes = []\n    for rank in range(total_nodes):\n        chunk_index_all_nodes += chunks_per_ranks[rank]\n\n    # shuffle the chunks for all nodes\n    np.random.seed(seed + current_epoch)\n    np.random.shuffle(chunk_index_all_nodes)\n\n    # return the shuffled chunk indexes for the current node\n    return chunk_index_all_nodes[:total_chunks]\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # get the current rank\n    rank = distributed_env.rank\n\n    # get the number of ranks\n    world_size = distributed_env.world_size\n\n    # get the number of chunks assigned to the current rank\n    num_chunks = len(chunks_per_ranks[rank])\n\n    # get the number of chunks assigned to the current rank\n    num_chunks = len(chunks_per_ranks[rank])\n\n    # get the seed for the current epoch\n    seed = seed + current_epoch\n\n    # generate a random permutation of the chunks assigned to the current rank\n    random_permutation = np.random.RandomState(seed=seed).permutation(num_chunks)\n\n    # flatten the list of chunk indexes assigned to each rank\n    chunks_per_ranks_flattened = [\n        item for sublist in chunks_per_ranks for item in sublist\n    ]\n\n    # shuffle the chunk indexes across all ranks\n    chunks_per_ranks_flattened = [\n        chunks_per_ranks_flattened[i] for i in random_permutation\n    ]\n\n    # split the chunk indexes into a list for each rank\n    chunks_per_ranks = np.array_split(chunks_per_ranks_flattened, world_size)\n\n    # return the shuffled chunk indexes for the current rank\n    return chunks_per_ranks[rank].tolist()\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Get the number of nodes\n    num_nodes = distributed_env.num_nodes\n\n    # Get the current rank\n    rank = distributed_env.rank\n\n    # Get the number of chunks assigned to each node\n    num_chunks_per_node = len(chunks_per_ranks[0])\n\n    # Get the number of chunks assigned to the current node\n    num_chunks_per_rank = len(chunks_per_ranks[rank])\n\n    # Get the seed\n    seed = seed + current_epoch\n\n    # Create a list of shuffled chunk indexes\n    shuffled_chunk_indexes = []\n\n    # Loop over the chunks assigned to the current node\n    for chunk_index in range(num_chunks_per_rank):\n\n        # Get the chunk index for the current rank\n        chunk_index_for_rank = chunks_per_ranks[rank][chunk_index]\n\n        # Get the chunk index for the current rank and node\n        chunk_index_for_node = chunk_index_for_rank % num_chunks_per_node\n\n        # Get the chunk index for the current rank and node, considering the current epoch\n        chunk_index_for_node_and_epoch = chunk_index_for_node + seed\n\n        # Get the chunk index for the current rank and node, considering the current epoch, and the current node\n        chunk_index_for_node_and_epoch_and_node = chunk_index_for_node_and_epoch % num_chunks_per_node\n\n        # Get the chunk index for the current rank and node, considering the current epoch, the current node, and the current node\n        chunk_index_for_node_and_epoch_and_node_and_node = chunk_index_for_node_and_epoch_and_node % num_nodes\n\n        # Get the chunk index for the current rank and node, considering the current epoch, the current node, the current node, and the current node\n        chunk_index_for_node_and_epoch_and_node_and_node"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Get the number of nodes and the world size\n    num_nodes = distributed_env.num_nodes\n    world_size = distributed_env.world_size\n\n    # Get the rank of the current node\n    current_rank = distributed_env.current_rank\n\n    # Get the chunk indexes assigned to the current node\n    chunks_per_rank = chunks_per_ranks[current_rank]\n\n    # Get the number of chunks assigned to the current node\n    num_chunks_per_rank = len(chunks_per_rank)\n\n    # Get the number of chunks assigned to each node\n    chunks_per_node = int(num_chunks_per_rank / num_nodes)\n\n    # Get the remainder chunks\n    remainder_chunks = num_chunks_per_rank % num_nodes\n\n    # Initialize the chunk indexes\n    chunk_indexes = []\n\n    # Get the seed for the current epoch\n    seed = seed + current_epoch\n\n    # Get the seed for the current node\n    node_seed = seed + current_rank\n\n    # Create a list of random numbers for each node\n    random_numbers = np.random.RandomState(node_seed).randint(\n        0, num_chunks_per_rank, num_nodes\n    )\n\n    # Add the remainder chunks to the current node\n    if current_rank < remainder_chunks:\n        random_numbers[current_rank] = random_numbers[current_rank] + current_rank\n\n    # For each node\n    for node in range(num_nodes):\n\n        # Get the number of chunks assigned to the current node\n        chunks_per_node = int(num_chunks_per_rank / num_nodes)\n\n        # Get the remainder chunks\n        remainder_chunks = num_chunks_per_rank % num_nodes\n\n        # Get the number of chunks assigned to the current node\n        if node < remainder_chunks:\n            chunks_per_node = chunks_per_node + 1\n\n        # Get the chunk indexes assigned to the current node"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if len(indexed_paths) == 0:\n        return None\n\n    if len(indexed_paths) > 1:\n        first_path = indexed_paths[list(indexed_paths.keys())[0]]\n        second_path = indexed_paths[list(indexed_paths.keys())[1]]\n        if not os.path.samefile(first_path, second_path):\n            raise ValueError(\n                f\"Found inconsistent file paths in inputs: {first_path} and {second_path}.\"\n            )\n\n    path = indexed_paths[list(indexed_paths.keys())[0]]\n    return _resolve_dir(path)\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if len(indexed_paths) == 0:\n        return None\n\n    if len(indexed_paths) > 1:\n        first_path = indexed_paths[0]\n        for path in indexed_paths.values():\n            if not os.path.samefile(path, first_path):\n                raise ValueError(\n                    f\"Inconsistent file paths found: {first_path} and {path}.\"\n                )\n\n    first_path = next(iter(indexed_paths.values()))\n    input_dir = _resolve_dir(first_path)\n\n    return input_dir\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths_0 = _get_indexed_paths(inputs[0])\n    indexed_paths_1 = _get_indexed_paths(inputs[1])\n\n    if not indexed_paths_0 and not indexed_paths_1:\n        return None\n\n    if indexed_paths_0 and indexed_paths_1:\n        if indexed_paths_0 != indexed_paths_1:\n            raise ValueError(\n                \"Inconsistent file paths found in the inputs: \"\n                f\"{list(indexed_paths_0.values())} and {list(indexed_paths_1.values())}.\"\n            )\n\n    indexed_paths = indexed_paths_0 if indexed_paths_0 else indexed_paths_1\n\n    input_dir = _resolve_dir(list(indexed_paths.values())[0])\n\n    return input_dir\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if not indexed_paths:\n        return None\n\n    if len(indexed_paths) > 1:\n        file_paths = list(indexed_paths.values())\n        _assert_dir_has_index_file(file_paths)\n\n    return _resolve_dir(list(indexed_paths.values())[0])\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    # Extract indexed paths from inputs\n    indexed_paths = _get_indexed_paths(inputs)\n\n    # Return None if no valid file paths are found\n    if not indexed_paths:\n        return None\n\n    # Check if indexed paths are consistent\n    first_path = indexed_paths[0]\n    for path in indexed_paths.values():\n        if path != first_path:\n            raise ValueError(f\"Inconsistent file paths found in inputs: {first_path} and {path}\")\n\n    # Resolve input directory\n    input_dir = _resolve_dir(first_path, depth=1)\n\n    return input_dir\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = {}\n    for input_ in inputs:\n        indexed_paths.update(_get_indexed_paths(input_))\n\n    if not indexed_paths:\n        return None\n\n    if len(indexed_paths) > 1:\n        raise ValueError(\n            f\"Inconsistent file paths found in the inputs: {indexed_paths}. Please make sure that all file paths are either relative to the project root or to the same directory.\"\n        )\n\n    input_dir = os.path.dirname(indexed_paths[0])\n    input_dir = _resolve_dir(input_dir, _IS_IN_STUDIO)\n\n    return input_dir\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = {}\n    for input_ in inputs:\n        indexed_paths.update(_get_indexed_paths(input_))\n\n    if len(indexed_paths) == 0:\n        return None\n\n    if len(indexed_paths) > 1:\n        raise ValueError(\n            f\"Inconsistent file paths found in inputs. \"\n            f\"Expected one root directory, found {len(indexed_paths)}: \"\n            f\"{[path for path in indexed_paths.values()]}\"\n        )\n\n    path = list(indexed_paths.values())[0]\n    return _resolve_dir(path)\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if len(indexed_paths) == 0:\n        return None\n\n    if len(indexed_paths) > 1:\n        first_path = indexed_paths[0]\n        for path in indexed_paths.values():\n            if os.path.dirname(path) != os.path.dirname(first_path):\n                raise ValueError(\n                    \"Inconsistent file paths found. Please ensure all file paths are in the same directory.\"\n                )\n\n    input_dir = os.path.dirname(indexed_paths[0])\n    input_dir = _resolve_dir(input_dir, depth=0)\n\n    return input_dir\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if len(indexed_paths) == 0:\n        return None\n\n    if len(indexed_paths) == 1:\n        return _resolve_dir(list(indexed_paths.values())[0])\n\n    if len(indexed_paths) > 2:\n        raise ValueError(\n            \"Inconsistent file paths found. Please ensure that all inputs are file paths with the same parent directory.\"\n        )\n\n    if not all(\n        os.path.dirname(indexed_paths[0]) == os.path.dirname(indexed_paths[i])\n        for i in range(1, len(indexed_paths))\n    ):\n        raise ValueError(\n            \"Inconsistent file paths found. Please ensure that all inputs are file paths with the same parent directory.\"\n        )\n\n    return _resolve_dir(os.path.dirname(indexed_paths[0]))\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if len(indexed_paths) == 0:\n        return None\n\n    input_dir = _resolve_dir(indexed_paths[0])\n\n    for index in indexed_paths:\n        if input_dir != _resolve_dir(indexed_paths[index]):\n            raise ValueError(\n                f\"Inconsistent input directories found: {input_dir} and {_resolve_dir(indexed_paths[index])}\"\n            )\n\n    return input_dir\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = {}\n\n    for input_ in inputs:\n        indexed_paths.update(_get_indexed_paths(input_))\n\n    if not indexed_paths:\n        return None\n\n    paths = list(indexed_paths.values())\n    _assert_dir_has_index_file(paths)\n    _assert_dir_is_empty(paths)\n\n    input_dir = _resolve_dir(paths, _IS_IN_STUDIO)\n\n    return input_dir\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if len(indexed_paths) == 0:\n        return None\n\n    if len(indexed_paths) > 2:\n        raise ValueError(\n            \"Inconsistent input paths found. Please check the inputs for valid file paths.\"\n        )\n\n    first_path = indexed_paths[0]\n    second_path = indexed_paths[1] if len(indexed_paths) > 1 else first_path\n\n    if not os.path.exists(first_path):\n        raise FileNotFoundError(\n            f\"The input path {first_path} does not exist. Please check the inputs for valid file paths.\"\n        )\n\n    if not os.path.exists(second_path):\n        raise FileNotFoundError(\n            f\"The input path {second_path} does not exist. Please check the inputs for valid file paths.\"\n        )\n\n    if first_path != second_path:\n        raise ValueError(\n            \"Inconsistent input paths found. Please check the inputs for valid file paths.\"\n        )\n\n    input_dir = os.path.dirname(first_path)\n\n    return input_dir\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if len(indexed_paths) == 0:\n        return None\n\n    if len(indexed_paths) > 1:\n        first_path = indexed_paths[list(indexed_paths.keys())[0]]\n        second_path = indexed_paths[list(indexed_paths.keys())[1]]\n\n        if not os.path.isfile(first_path) or not os.path.isfile(second_path):\n            raise ValueError(\n                f\"Inconsistent file paths found in inputs: {first_path} and {second_path}.\"\n            )\n\n        first_path_resolved = _resolve_dir(first_path)\n        second_path_resolved = _resolve_dir(second_path)\n\n        if first_path_resolved != second_path_resolved:\n            raise ValueError(\n                f\"Inconsistent file paths found in inputs: {first_path} and {second_path}.\"\n            )\n\n    input_dir = _resolve_dir(indexed_paths[list(indexed_paths.keys())[0]])\n\n    return input_dir\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = {}\n\n    for input_ in inputs:\n        indexed_paths.update(_get_indexed_paths(input_))\n\n    if not indexed_paths:\n        return None\n\n    paths = [indexed_paths[0]]\n    for path in indexed_paths:\n        if indexed_paths[path] != paths[0]:\n            raise ValueError(\n                \"Inconsistent file paths found in inputs: \"\n                f\"{indexed_paths[path]} and {paths[0]}.\"\n            )\n\n    return _resolve_dir(paths[0])\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    # Get indexed paths from the inputs\n    indexed_paths = _get_indexed_paths(inputs)\n\n    # If no indexed paths are found, return None\n    if not indexed_paths:\n        return None\n\n    # Get the first path and check if the path exists\n    first_path = indexed_paths[0]\n    if not os.path.exists(first_path):\n        raise ValueError(f\"The path {first_path} does not exist.\")\n\n    # Get the absolute path to the first path\n    first_path = os.path.abspath(first_path)\n\n    # If the first path is a directory, return it\n    if os.path.isdir(first_path):\n        return first_path\n\n    # Get the absolute path to the parent directory of the first path\n    parent_dir = os.path.abspath(os.path.dirname(first_path))\n\n    # If the parent directory is a directory, return it\n    if os.path.isdir(parent_dir):\n        return parent_dir\n\n    # If the parent directory is a file, return the directory containing the parent directory\n    return os.path.abspath(os.path.dirname(parent_dir))\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    # Get indexed paths from the inputs\n    indexed_paths = _get_indexed_paths(inputs)\n\n    # Check if there are any indexed paths\n    if not indexed_paths:\n        return None\n\n    # Get the path to the first indexed file\n    first_path = indexed_paths[0]\n\n    # Check if the first indexed path is a directory\n    if os.path.isdir(first_path):\n        # Resolve the directory to the project root or a specified depth\n        first_path = _resolve_dir(first_path)\n\n    # Check if the first indexed path is a file\n    elif os.path.isfile(first_path):\n        # Get the absolute path to the directory containing the file\n        first_path = os.path.dirname(os.path.abspath(first_path))\n\n        # Resolve the directory to the project root or a specified depth\n        first_path = _resolve_dir(first_path)\n\n    # Check if there are any additional indexed paths\n    if len(indexed_paths) > 1:\n        # Get the path to the second indexed file\n        second_path = indexed_paths[1]\n\n        # Check if the second indexed path is a directory\n        if os.path.isdir(second_path):\n            # Resolve the directory to the project root or a specified depth\n            second_path = _resolve_dir(second_path)\n\n        # Check if the second indexed path is a file\n        elif os.path.isfile(second_path):\n            # Get the absolute path to the directory containing the file\n            second_path = os.path.dirname(os.path.abspath(second_path))\n\n            # Resolve the directory to the project root or a specified depth\n            second_path = _resolve_dir(second_path)\n\n        # Check if the first and second indexed paths are consistent\n        if first_path != second_path:\n            raise ValueError(f\"Inconsistent paths found: {first_path} and {second_path}\")\n\n    return first_path\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if len(indexed_paths) > 0:\n        input_dirs = set([os.path.dirname(path) for path in indexed_paths.values()])\n        if len(input_dirs) > 1:\n            raise ValueError(\n                f\"Inconsistent input directories found: {input_dirs}. Please ensure that all inputs are from the same directory.\"\n            )\n        input_dir = input_dirs.pop()\n        return _resolve_dir(input_dir)\n\n    return None\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths_0 = _get_indexed_paths(inputs[0])\n    indexed_paths_1 = _get_indexed_paths(inputs[1])\n\n    if len(indexed_paths_0) > 0 and len(indexed_paths_1) > 0:\n        if indexed_paths_0 != indexed_paths_1:\n            raise ValueError(\n                \"Inconsistent file paths found in input sequences. Please check that the first two elements of the inputs are consistent.\"\n            )\n\n        if len(indexed_paths_0) == 1:\n            path = indexed_paths_0[0]\n        else:\n            path = list(indexed_paths_0.values())[0]\n    elif len(indexed_paths_0) > 0:\n        path = list(indexed_paths_0.values())[0]\n    elif len(indexed_paths_1) > 0:\n        path = list(indexed_paths_1.values())[0]\n    else:\n        return None\n\n    return _resolve_dir(path)\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if len(indexed_paths) == 0:\n        return None\n\n    # Assert that all paths are equal\n    if len(set(indexed_paths.values())) > 1:\n        raise ValueError(\n            f\"Inconsistent file paths found in inputs: {list(indexed_paths.values())}\"\n        )\n\n    # Get the path to the input directory\n    input_path = indexed_paths[0]\n    input_path = _resolve_dir(input_path)\n\n    return input_path\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    # Determine the input directory from the inputs.\n    indexed_paths: Dict[int, str] = {}\n\n    for input in inputs:\n        indexed_paths.update(_get_indexed_paths(input))\n\n    if not indexed_paths:\n        return None\n\n    # Ensure that all paths are consistent.\n    paths = set(indexed_paths.values())\n    if len(paths) > 1:\n        raise ValueError(\n            f\"Inconsistent file paths found in inputs: {paths}. Please ensure that all file paths are consistent.\"\n        )\n\n    # Resolve the input directory.\n    input_dir: str = _resolve_dir(paths.pop())\n\n    return input_dir\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if not _IS_IN_STUDIO:\n        yield\n        return\n\n    try:\n        if enable:\n            Popen([\"sudo\", \"systemctl\", \"enable\", \"systemd-resolved\"], stdout=DEVNULL, stderr=DEVNULL)\n            Popen([\"sudo\", \"systemctl\", \"restart\", \"systemd-resolved\"], stdout=DEVNULL, stderr=DEVNULL)\n        else:\n            Popen([\"sudo\", \"systemctl\", \"disable\", \"systemd-resolved\"], stdout=DEVNULL, stderr=DEVNULL)\n            Popen([\"sudo\", \"systemctl\", \"restart\", \"systemd-resolved\"], stdout=DEVNULL, stderr=DEVNULL)\n        yield\n    finally:\n        Popen([\"sudo\", \"systemctl\", \"disable\", \"systemd-resolved\"], stdout=DEVNULL, stderr=DEVNULL)\n        Popen([\"sudo\", \"systemctl\", \"restart\", \"systemd-resolved\"], stdout=DEVNULL, stderr=DEVNULL)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        Popen([\"sudo\", \"sysctl\", \"-w\", \"net.ipv6.conf.all.disable_ipv6=0\"], stdout=DEVNULL, stderr=DEVNULL)\n    else:\n        Popen([\"sudo\", \"sysctl\", \"-w\", \"net.ipv6.conf.all.disable_ipv6=1\"], stdout=DEVNULL, stderr=DEVNULL)\n    try:\n        yield\n    finally:\n        Popen([\"sudo\", \"sysctl\", \"-w\", \"net.ipv6.conf.all.disable_ipv6=1\"], stdout=DEVNULL, stderr=DEVNULL)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        Popen([\"sudo\", \"sysctl\", \"net.ipv6.conf.all.disable_ipv6=0\"], stdout=DEVNULL)\n        Popen([\"sudo\", \"sysctl\", \"net.ipv6.conf.default.disable_ipv6=0\"], stdout=DEVNULL)\n        Popen([\"sudo\", \"sysctl\", \"net.ipv6.conf.lo.disable_ipv6=0\"], stdout=DEVNULL)\n    else:\n        Popen([\"sudo\", \"sysctl\", \"net.ipv6.conf.all.disable_ipv6=1\"], stdout=DEVNULL)\n        Popen([\"sudo\", \"sysctl\", \"net.ipv6.conf.default.disable_ipv6=1\"], stdout=DEVNULL)\n        Popen([\"sudo\", \"sysctl\", \"net.ipv6.conf.lo.disable_ipv6=1\"], stdout=DEVNULL)\n\n    try:\n        yield\n    finally:\n        Popen([\"sudo\", \"sysctl\", \"net.ipv6.conf.all.disable_ipv6=1\"], stdout=DEVNULL)\n        Popen([\"sudo\", \"sysctl\", \"net.ipv6.conf.default.disable_ipv6=1\"], stdout=DEVNULL)\n        Popen([\"sudo\", \"sysctl\", \"net.ipv6.conf.lo.disable_ipv6=1\"], stdout=DEVNULL)\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if not _IS_IN_STUDIO:\n        yield\n        return\n\n    if enable:\n        # Enable DNS optimization\n        cmd = [\"sudo\", \"sysctl\", \"-w\", \"net.ipv6.conf.all.disable_ipv6=0\"]\n    else:\n        # Disable DNS optimization\n        cmd = [\"sudo\", \"sysctl\", \"-w\", \"net.ipv6.conf.all.disable_ipv6=1\"]\n\n    with Popen(cmd, stdout=DEVNULL, stderr=DEVNULL) as process:\n        process.wait()\n        yield\n\n    cmd = [\"sudo\", \"sysctl\", \"-w\", \"net.ipv6.conf.all.disable_ipv6=1\"]\n    with Popen(cmd, stdout=DEVNULL, stderr=DEVNULL) as process:\n        process.wait()"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        os.environ[\"LIGHTNING_CLOUD_DNS_OPTIMIZATION\"] = \"1\"\n    else:\n        os.environ[\"LIGHTNING_CLOUD_DNS_OPTIMIZATION\"] = \"0\"\n\n    try:\n        yield\n    finally:\n        os.environ[\"LIGHTNING_CLOUD_DNS_OPTIMIZATION\"] = \"0\"\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        Popen([\"sudo\", \"sysctl\", \"net.ipv6.conf.all.disable_ipv6=0\"], stdout=DEVNULL, stderr=DEVNULL)\n        Popen([\"sudo\", \"sysctl\", \"net.ipv6.conf.default.disable_ipv6=0\"], stdout=DEVNULL, stderr=DEVNULL)\n        Popen([\"sudo\", \"sysctl\", \"net.ipv6.conf.lo.disable_ipv6=0\"], stdout=DEVNULL, stderr=DEVNULL)\n    else:\n        Popen([\"sudo\", \"sysctl\", \"net.ipv6.conf.all.disable_ipv6=1\"], stdout=DEVNULL, stderr=DEVNULL)\n        Popen([\"sudo\", \"sysctl\", \"net.ipv6.conf.default.disable_ipv6=1\"], stdout=DEVNULL, stderr=DEVNULL)\n        Popen([\"sudo\", \"sysctl\", \"net.ipv6.conf.lo.disable_ipv6=1\"], stdout=DEVNULL, stderr=DEVNULL)\n    yield\n    Popen([\"sudo\", \"sysctl\", \"net.ipv6.conf.all.disable_ipv6=1\"], stdout=DEVNULL, stderr=DEVNULL)\n    Popen([\"sudo\", \"sysctl\", \"net.ipv6.conf.default.disable_ipv6=1\"], stdout=DEVNULL, stderr=DEVNULL)\n    Popen([\"sudo\", \"sysctl\", \"net.ipv6.conf.lo.disable_ipv6=1\"], stdout=DEVNULL, stderr=DEVNULL)\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        Popen([\"sudo\", \"sysctl\", \"net.ipv6.conf.all.disable_ipv6=0\"], stdout=DEVNULL)\n\n    try:\n        yield\n    finally:\n        Popen([\"sudo\", \"sysctl\", \"net.ipv6.conf.all.disable_ipv6=1\"], stdout=DEVNULL)\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        # Enable DNS optimization\n        Popen([\"/usr/lib/x86_64-linux-gnu/libnss-resolve/resolvectl\", \"enable\"], stdout=DEVNULL, stderr=DEVNULL)\n    else:\n        # Disable DNS optimization\n        Popen([\"/usr/lib/x86_64-linux-gnu/libnss-resolve/resolvectl\", \"disable\"], stdout=DEVNULL, stderr=DEVNULL)\n\n    try:\n        yield\n    finally:\n        # Disable DNS optimization\n        Popen([\"/usr/lib/x86_64-linux-gnu/libnss-resolve/resolvectl\", \"disable\"], stdout=DEVNULL, stderr=DEVNULL)\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    # Save current state of DNS optimization\n    current_state = _IS_IN_STUDIO\n\n    # Set DNS optimization to the desired state\n    _IS_IN_STUDIO = enable\n\n    try:\n        # Execute the context\n        yield\n    finally:\n        # Reset DNS optimization to the original state\n        _IS_IN_STUDIO = current_state\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        Popen([\"sudo\", \"sysctl\", \"-w\", \"net.ipv6.conf.all.disable_ipv6=0\"], stdout=DEVNULL, stderr=DEVNULL)\n    else:\n        Popen([\"sudo\", \"sysctl\", \"-w\", \"net.ipv6.conf.all.disable_ipv6=1\"], stdout=DEVNULL, stderr=DEVNULL)\n    try:\n        yield\n    finally:\n        Popen([\"sudo\", \"sysctl\", \"-w\", \"net.ipv6.conf.all.disable_ipv6=1\"], stdout=DEVNULL, stderr=DEVNULL)\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if not _IS_IN_STUDIO:\n        yield\n        return\n\n    if enable:\n        os.environ[\"LIGHTNING_CLOUD_DNS_OPTIMIZATION\"] = \"1\"\n    else:\n        os.environ[\"LIGHTNING_CLOUD_DNS_OPTIMIZATION\"] = \"0\"\n\n    try:\n        yield\n    finally:\n        os.environ[\"LIGHTNING_CLOUD_DNS_OPTIMIZATION\"] = \"0\"\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        # Enable DNS optimization\n        Popen([\"sudo\", \"sysctl\", \"-w\", \"net.ipv6.conf.all.disable_ipv6=0\"], stdout=DEVNULL)\n        Popen([\"sudo\", \"sysctl\", \"-w\", \"net.ipv6.conf.default.disable_ipv6=0\"], stdout=DEVNULL)\n    else:\n        # Disable DNS optimization\n        Popen([\"sudo\", \"sysctl\", \"-w\", \"net.ipv6.conf.all.disable_ipv6=1\"], stdout=DEVNULL)\n        Popen([\"sudo\", \"sysctl\", \"-w\", \"net.ipv6.conf.default.disable_ipv6=1\"], stdout=DEVNULL)\n    yield\n    # Ensure DNS optimization is disabled after the context\n    Popen([\"sudo\", \"sysctl\", \"-w\", \"net.ipv6.conf.all.disable_ipv6=1\"], stdout=DEVNULL)\n    Popen([\"sudo\", \"sysctl\", \"-w\", \"net.ipv6.conf.default.disable_ipv6=1\"], stdout=DEVNULL)\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        os.system(\"sudo sysctl -w net.ipv6.conf.all.disable_ipv6=0\")\n    else:\n        os.system(\"sudo sysctl -w net.ipv6.conf.all.disable_ipv6=1\")\n\n    try:\n        yield\n    finally:\n        os.system(\"sudo sysctl -w net.ipv6.conf.all.disable_ipv6=1\")\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        Popen([\"sudo\", \"sysctl\", \"-w\", \"net.ipv6.conf.all.disable_ipv6=0\"])\n    else:\n        Popen([\"sudo\", \"sysctl\", \"-w\", \"net.ipv6.conf.all.disable_ipv6=1\"])\n    try:\n        yield\n    finally:\n        Popen([\"sudo\", \"sysctl\", \"-w\", \"net.ipv6.conf.all.disable_ipv6=1\"])\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if _IS_IN_STUDIO:\n        return\n\n    if enable:\n        os.system(\"echo nameserver 127.0.0.1 | sudo tee -a /etc/resolv.conf\")\n        os.system(\"sudo resolctl enable systemd-resolved\")\n        os.system(\"sudo resolctl restart\")\n        os.system(\"sudo systemctl restart systemd-resolved\")\n\n    try:\n        yield\n    finally:\n        os.system(\"echo nameserver 127.0.0.53 | sudo tee -a /etc/resolv.conf\")\n        os.system(\"sudo resolctl disable systemd-resolved\")\n        os.system(\"sudo resolctl restart\")\n        os.system(\"sudo systemctl restart systemd-resolved\")\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        # Enable DNS optimization\n        # This is a no-op if DNS optimization is already enabled\n        Popen([\"sudo\", \"sysctl\", \"-w\", \"net.ipv6.conf.all.disable_ipv6=0\"], stdout=DEVNULL, stderr=DEVNULL)\n        Popen([\"sudo\", \"sysctl\", \"-w\", \"net.ipv6.conf.default.disable_ipv6=0\"], stdout=DEVNULL, stderr=DEVNULL)\n\n    # Execute code block\n    try:\n        yield\n    finally:\n        # Disable DNS optimization\n        # This is a no-op if DNS optimization is already disabled\n        Popen([\"sudo\", \"sysctl\", \"-w\", \"net.ipv6.conf.all.disable_ipv6=1\"], stdout=DEVNULL, stderr=DEVNULL)\n        Popen([\"sudo\", \"sysctl\", \"-w\", \"net.ipv6.conf.default.disable_ipv6=1\"], stdout=DEVNULL, stderr=DEVNULL)\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        # Enable DNS optimization.\n        os.environ[\"LIGHTNING_DNS_OPTIMIZE\"] = \"1\"\n    else:\n        # Disable DNS optimization.\n        os.environ[\"LIGHTNING_DNS_OPTIMIZE\"] = \"0\"\n\n    try:\n        yield\n    finally:\n        # Reset to disable DNS optimization.\n        os.environ[\"LIGHTNING_DNS_OPTIMIZE\"] = \"0\"\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        # Enable DNS optimization\n        os.environ[\"LIGHTNING_CLOUD_DISABLE_DNS_OPTIMIZATION\"] = \"0\"\n    else:\n        # Disable DNS optimization\n        os.environ[\"LIGHTNING_CLOUD_DISABLE_DNS_OPTIMIZATION\"] = \"1\"\n\n    try:\n        yield\n    finally:\n        # Ensure that DNS optimization is disabled\n        os.environ[\"LIGHTNING_CLOUD_DISABLE_DNS_OPTIMIZATION\"] = \"1\"\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        # Enable DNS optimization\n        original_dns_state = _IS_IN_STUDIO\n        _IS_IN_STUDIO = True\n        yield\n        # Disable DNS optimization\n        _IS_IN_STUDIO = original_dns_state\n    else:\n        # Disable DNS optimization\n        original_dns_state = _IS_IN_STUDIO\n        _IS_IN_STUDIO = False\n        yield\n        # Ensure DNS optimization is disabled\n        _IS_IN_STUDIO = original_dns_state\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    # Check if the DNS optimization is already disabled\n    if os.getenv(\"PYTHON_DNS_MASS_RESOLVER_ENABLED\") == \"1\":\n        # DNS optimization is already enabled, so disable it\n        os.environ[\"PYTHON_DNS_MASS_RESOLVER_ENABLED\"] = \"0\"\n\n    try:\n        # Enable or disable DNS optimization\n        if enable:\n            os.environ[\"PYTHON_DNS_MASS_RESOLVER_ENABLED\"] = \"1\"\n        yield\n    finally:\n        # Ensure that DNS optimization is disabled\n        os.environ[\"PYTHON_DNS_MASS_RESOLVER_ENABLED\"] = \"0\"\n\n"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items to be processed by each rank\n    num_items_per_rank = (\n        len(indexes) // distributed_env.world_size\n        if drop_last\n        else (len(indexes) + distributed_env.world_size - 1) // distributed_env.world_size\n    )\n\n    # calculate the number of items to be processed by each rank\n    num_chunks_per_rank = (\n        len(chunk_intervals) // distributed_env.world_size\n        if drop_last\n        else (len(chunk_intervals) + distributed_env.world_size - 1) // distributed_env.world_size\n    )\n\n    # distribute chunks and their corresponding intervals across different ranks\n    chunks_per_ranks = [\n        indexes[rank * num_items_per_rank : (rank + 1) * num_items_per_rank]\n        for rank in range(distributed_env.world_size)\n    ]\n    chunk_intervals_per_ranks = [\n        chunk_intervals[rank * num_chunks_per_rank : (rank + 1) * num_chunks_per_rank]\n        for rank in range(distributed_env.world_size)\n    ]\n\n    return chunks_per_ranks, chunk_intervals_per_ranks\n\n"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items each rank should process based on the total items and the world size of the distributed environment\n    num_items_per_rank = (\n        len(indexes) // distributed_env.world_size\n        if drop_last\n        else (len(indexes) + distributed_env.world_size - 1) // distributed_env.world_size\n    )\n\n    # assign chunks and their intervals to each rank accordingly\n    chunks_per_ranks = [\n        indexes[i * num_items_per_rank : (i + 1) * num_items_per_rank]\n        if i < distributed_env.world_size - 1\n        else indexes[i * num_items_per_rank:]\n        for i in range(distributed_env.world_size)\n    ]\n\n    chunk_intervals_per_ranks = [\n        chunk_intervals[i * num_items_per_rank : (i + 1) * num_items_per_rank]\n        if i < distributed_env.world_size - 1\n        else chunk_intervals[i * num_items_per_rank:]\n        for i in range(distributed_env.world_size)\n    ]\n\n    return chunks_per_ranks, chunk_intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items each rank should process\n    num_items_per_rank = (\n        len(indexes) // distributed_env.world_size\n        if drop_last\n        else (len(indexes) + distributed_env.world_size - 1) // distributed_env.world_size\n    )\n\n    # assign chunks and intervals to each rank\n    chunks_per_ranks = [\n        indexes[rank * num_items_per_rank : (rank + 1) * num_items_per_rank]\n        if drop_last\n        else indexes[rank * num_items_per_rank :]\n        for rank in range(distributed_env.world_size)\n    ]\n    chunk_intervals_per_ranks = [\n        chunk_intervals[rank * num_items_per_rank : (rank + 1) * num_items_per_rank]\n        if drop_last\n        else chunk_intervals[rank * num_items_per_rank :]\n        for rank in range(distributed_env.world_size)\n    ]\n\n    return chunks_per_ranks, chunk_intervals_per_ranks\n\n"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of chunks to be distributed to each rank\n    num_chunks = len(indexes)\n    num_chunks_per_rank = [num_chunks // distributed_env.world_size for _ in range(distributed_env.world_size)]\n    for i in range(num_chunks % distributed_env.world_size):\n        num_chunks_per_rank[i] += 1\n\n    # assign chunks and their intervals to each rank\n    chunks_per_ranks: List[List[int]] = [[] for _ in range(distributed_env.world_size)]\n    chunk_intervals_per_ranks: List[List[Any]] = [[] for _ in range(distributed_env.world_size)]\n    start_index = 0\n    for rank in range(distributed_env.world_size):\n        end_index = start_index + num_chunks_per_rank[rank]\n        if drop_last and end_index > num_chunks:\n            end_index = num_chunks\n        chunks_per_ranks[rank] = indexes[start_index:end_index]\n        chunk_intervals_per_ranks[rank] = chunk_intervals[start_index:end_index]\n        start_index = end_index\n\n    return chunks_per_ranks, chunk_intervals_per_ranks\n\n"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of chunks each rank should process\n    num_chunks_per_rank = (\n        len(indexes) // distributed_env.world_size\n        if drop_last\n        else (len(indexes) + distributed_env.world_size - 1) // distributed_env.world_size\n    )\n\n    # distribute chunks and their corresponding intervals across different ranks\n    chunks_per_ranks = [\n        indexes[rank * num_chunks_per_rank : (rank + 1) * num_chunks_per_rank]\n        for rank in range(distributed_env.world_size)\n    ]\n    chunk_intervals_per_ranks = [\n        chunk_intervals[rank * num_chunks_per_rank : (rank + 1) * num_chunks_per_rank]\n        for rank in range(distributed_env.world_size)\n    ]\n\n    return chunks_per_ranks, chunk_intervals_per_ranks\n\n"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of chunks each rank should process\n    num_chunks = len(indexes)\n    num_chunks_per_rank = [num_chunks // distributed_env.world_size for _ in range(distributed_env.world_size)]\n    num_chunks_per_rank[0] += num_chunks - distributed_env.world_size * num_chunks_per_rank[0]\n\n    # associate the chunks and their intervals to each rank\n    chunks_per_ranks: List[List[int]] = [[] for _ in range(distributed_env.world_size)]\n    chunk_intervals_per_ranks: List[List[Any]] = [[] for _ in range(distributed_env.world_size)]\n    for rank in range(distributed_env.world_size):\n        for i in range(num_chunks_per_rank[rank]):\n            chunks_per_ranks[rank].append(indexes[i])\n            chunk_intervals_per_ranks[rank].append(chunk_intervals[i])\n\n        if drop_last and rank == distributed_env.world_size - 1:\n            chunks_per_ranks[rank] = chunks_per_ranks[rank][:-1]\n            chunk_intervals_per_ranks[rank] = chunk_intervals_per_ranks[rank][:-1]\n\n    return chunks_per_ranks, chunk_intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items each rank should process based on the total items and the world size of the distributed environment\n    num_items_per_rank = [\n        int(\n            len(indexes)\n            * distributed_env.world_size\n            // distributed_env.num_nodes\n            // distributed_env.world_size\n            + (\n                i\n                < len(indexes)\n                * distributed_env.world_size\n                // distributed_env.num_nodes\n                % distributed_env.world_size\n            )\n        )\n        for i in range(distributed_env.world_size)\n    ]\n\n    # assign chunks and their intervals to each rank accordingly\n    chunks_per_ranks = [\n        indexes[\n            sum(num_items_per_rank[:rank]) : sum(num_items_per_rank[: rank + 1])\n            if not drop_last or rank != distributed_env.world_size - 1\n            else len(indexes)\n        ]\n        for rank in range(distributed_env.world_size)\n    ]\n\n    chunk_intervals_per_ranks = [\n        chunk_intervals[\n            sum(num_items_per_rank[:rank]) : sum(num_items_per_rank[: rank + 1])\n            if not drop_last or rank != distributed_env.world_size - 1\n            else len(indexes)\n        ]\n        for rank in range(distributed_env.world_size)\n    ]\n\n    return chunks_per_ranks, chunk_intervals_per_ranks\n\n"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items to be processed by each rank\n    num_items_per_rank = (\n        len(indexes) // distributed_env.world_size\n        if drop_last\n        else (len(indexes) + distributed_env.world_size - 1) // distributed_env.world_size\n    )\n\n    # distribute the chunks and their corresponding intervals across the ranks\n    chunks_per_ranks: List[List[int]] = []\n    chunk_intervals_per_ranks: List[List[Any]] = []\n    for rank in range(distributed_env.world_size):\n        chunks_per_ranks.append(\n            indexes[\n                rank * num_items_per_rank : (rank + 1) * num_items_per_rank\n                if rank != distributed_env.world_size - 1\n                else len(indexes)\n            ]\n        )\n        chunk_intervals_per_ranks.append(\n            chunk_intervals[\n                rank * num_items_per_rank : (rank + 1) * num_items_per_rank\n                if rank != distributed_env.world_size - 1\n                else len(indexes)\n            ]\n        )\n\n    return chunks_per_ranks, chunk_intervals_per_ranks\n\n"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items each rank should process\n    num_items_per_rank = [\n        len(indexes) // distributed_env.world_size for _ in range(distributed_env.world_size)\n    ]\n    for i in range(len(indexes) % distributed_env.world_size):\n        num_items_per_rank[i] += 1\n\n    # assign chunks and their corresponding intervals to each rank\n    chunks_per_ranks = [[] for _ in range(distributed_env.world_size)]\n    chunk_intervals_per_ranks = [[] for _ in range(distributed_env.world_size)]\n    rank = 0\n    for i, index in enumerate(indexes):\n        if len(chunks_per_ranks[rank]) == num_items_per_rank[rank]:\n            rank += 1\n        chunks_per_ranks[rank].append(index)\n        chunk_intervals_per_ranks[rank].append(chunk_intervals[i])\n\n    # drop the last items\n    if drop_last:\n        for rank in range(distributed_env.world_size - 1):\n            chunks_per_ranks[rank].pop()\n            chunk_intervals_per_ranks[rank].pop()\n\n    return chunks_per_ranks, chunk_intervals_per_ranks\n\n"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items to be processed by each rank\n    num_items_per_rank = _calculate_num_items_per_rank(distributed_env.world_size, len(indexes), drop_last)\n\n    # distribute the chunks and their intervals across different ranks\n    chunks_per_ranks: Any = [[] for _ in range(distributed_env.world_size)]\n    chunk_intervals_per_ranks: Any = [[] for _ in range(distributed_env.world_size)]\n    for rank in range(distributed_env.world_size):\n        for i in range(num_items_per_rank[rank]):\n            chunks_per_ranks[rank].append(indexes[i])\n            chunk_intervals_per_ranks[rank].append(chunk_intervals[i])\n\n    return chunks_per_ranks, chunk_intervals_per_ranks\n\n"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of chunks each rank should process\n    num_chunks_per_rank: List[int] = [\n        int(len(indexes) // distributed_env.world_size) for _ in range(distributed_env.world_size)\n    ]\n    if drop_last:\n        num_chunks_per_rank = num_chunks_per_rank[:-1]\n        num_chunks_per_rank[-1] = num_chunks_per_rank[-1] + len(indexes) - sum(num_chunks_per_rank)\n\n    # distribute the chunks and their corresponding intervals across the ranks\n    chunks_per_ranks: List[List[int]] = [[] for _ in range(distributed_env.world_size)]\n    chunk_intervals_per_ranks: List[List[Any]] = [[] for _ in range(distributed_env.world_size)]\n    for rank in range(distributed_env.world_size):\n        for chunk_index in range(num_chunks_per_rank[rank]):\n            chunks_per_ranks[rank].append(indexes[chunk_index])\n            chunk_intervals_per_ranks[rank].append(chunk_intervals[chunk_index])\n            indexes = indexes[num_chunks_per_rank[rank] :]\n            chunk_intervals = chunk_intervals[num_chunks_per_rank[rank] :]\n\n    return chunks_per_ranks, chunk_intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items each rank should process\n    items_per_rank = _calculate_items_per_rank(len(indexes), distributed_env.world_size, drop_last)\n\n    # assign the chunks and their corresponding intervals to each rank\n    chunks_per_ranks = [[] for _ in range(distributed_env.world_size)]\n    chunk_intervals_per_ranks = [[] for _ in range(distributed_env.world_size)]\n    for rank, items in enumerate(items_per_rank):\n        chunks_per_ranks[rank], chunk_intervals_per_ranks[rank] = _assign_chunks_and_intervals_to_rank(\n            indexes, chunk_intervals, rank, items\n        )\n\n    return chunks_per_ranks, chunk_intervals_per_ranks\n\n"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items each rank should process\n    num_items_per_rank = _calculate_num_items_per_rank(\n        num_items=len(indexes),\n        world_size=distributed_env.world_size,\n        drop_last=drop_last,\n    )\n\n    # calculate the number of chunks each rank should process\n    num_chunks_per_rank = _calculate_num_chunks_per_rank(\n        num_chunks=len(chunk_intervals),\n        world_size=distributed_env.world_size,\n        drop_last=drop_last,\n    )\n\n    # calculate the number of chunks each rank should process\n    num_chunks_per_node = _calculate_num_chunks_per_node(\n        num_chunks=len(chunk_intervals),\n        num_nodes=distributed_env.num_nodes,\n        drop_last=drop_last,\n    )\n\n    # distribute chunks to each rank\n    chunks_per_ranks: Any = [[] for _ in range(distributed_env.world_size)]\n    for rank, num_chunks in enumerate(num_chunks_per_rank):\n        chunks_per_ranks[rank] = indexes[\n            sum(num_chunks_per_node[:rank]) : sum(num_chunks_per_node[: rank + 1])\n        ]\n\n    # distribute chunks and their corresponding intervals to each rank\n    chunk_intervals_per_ranks: Any = [[] for _ in range(distributed_env.world_size)]\n    for rank, num_chunks in enumerate(num_chunks_per_rank):\n        chunk_intervals_per_ranks[rank] = chunk_intervals[\n            sum(num_chunks_per_node[:rank]) : sum(num_chunks_per_node[: rank + 1])\n        ]\n\n    return chunks_per_ranks, chunk_intervals_per_ranks\n\n"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of chunks per rank\n    num_chunks_per_rank = [\n        int(np.floor(len(indexes) / distributed_env.world_size))\n        if distributed_env.world_size > 1\n        else len(indexes)\n    ]\n    # if drop_last is True, remove the remaining chunks to make the distribution even\n    if drop_last:\n        num_chunks_per_rank = [\n            num_chunks_per_rank[i]\n            if i < len(num_chunks_per_rank) - 1\n            else num_chunks_per_rank[i] - (len(indexes) - sum(num_chunks_per_rank[:i]))\n            for i in range(len(num_chunks_per_rank))\n        ]\n\n    # calculate the number of chunks per node\n    num_chunks_per_node = [\n        int(np.floor(num_chunks_per_rank[i] / distributed_env.num_nodes))\n        if distributed_env.num_nodes > 1\n        else num_chunks_per_rank[i]\n        for i in range(len(num_chunks_per_rank))\n    ]\n\n    # if drop_last is True, remove the remaining chunks to make the distribution even\n    if drop_last:\n        num_chunks_per_node = [\n            num_chunks_per_node[i]\n            if i < len(num_chunks_per_node) - 1\n            else num_chunks_per_node[i]\n            - (\n                num_chunks_per_rank[i]\n                - sum(num_chunks_per_node[:i])\n                - sum(num_chunks_per_rank[i + 1 :])\n            )\n            for i in range(len(num_chunks_per_node))\n        ]\n\n    # calculate the number of chunks per process\n    num_chunks_per_process = [\n        int(np.floor(num_chunks_per_node"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items to be processed by each rank\n    items_per_rank = _calculate_items_per_rank(distributed_env.world_size, len(indexes), drop_last)\n\n    # associate chunks and their corresponding intervals to the ranks\n    chunks_per_ranks = [[] for _ in range(distributed_env.world_size)]\n    intervals_per_ranks = [[] for _ in range(distributed_env.world_size)]\n    for i, (chunk_index, chunk_interval) in enumerate(zip(indexes, chunk_intervals)):\n        chunks_per_ranks[i % distributed_env.world_size].append(chunk_index)\n        intervals_per_ranks[i % distributed_env.world_size].append(chunk_interval)\n\n    return chunks_per_ranks, intervals_per_ranks\n\n"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of chunks per rank\n    num_chunks = len(indexes)\n    num_chunks_per_rank = [num_chunks // distributed_env.world_size for _ in range(distributed_env.world_size)]\n    num_chunks_per_rank[0] += num_chunks - distributed_env.world_size * num_chunks_per_rank[0]\n\n    # calculate the number of items per rank\n    num_items_per_rank = [\n        num_chunks_per_rank[rank] * (chunk_intervals[indexes[rank + 1]][0] - chunk_intervals[indexes[rank]][0])\n        for rank in range(distributed_env.world_size)\n    ]\n    num_items_per_rank[0] += (\n        chunk_intervals[-1][1] - chunk_intervals[indexes[0]][0]\n        if drop_last\n        else chunk_intervals[-1][1] - chunk_intervals[indexes[0]][0] + chunk_intervals[indexes[0]][0] - chunk_intervals[-1][0]\n    )\n\n    # distribute chunks and intervals to each rank\n    chunks_per_ranks: List[List[int]] = [[] for _ in range(distributed_env.world_size)]\n    chunk_intervals_per_ranks: List[List[List[int]]] = [[] for _ in range(distributed_env.world_size)]\n    for rank in range(distributed_env.world_size):\n        for i in range(num_chunks_per_rank[rank]):\n            chunks_per_ranks[rank].append(indexes[rank * num_chunks // distributed_env.world_size + i])\n            chunk_intervals_per_ranks[rank].append(\n                chunk_intervals[indexes[rank * num_chunks // distributed_env.world_size + i]]\n            )\n\n    return chunks_per_ranks, chunk_intervals_"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items to process per rank\n    if drop_last:\n        # drop the last items to make the distribution even across all ranks\n        num_items_per_rank = [distributed_env.world_size // distributed_env.num_nodes] * distributed_env.num_nodes\n        for i in range(distributed_env.world_size % distributed_env.num_nodes):\n            num_items_per_rank[i] += 1\n    else:\n        # keep the last items to make the distribution even across all ranks\n        num_items_per_rank = [distributed_env.world_size // distributed_env.num_nodes] * distributed_env.num_nodes\n        for i in range(distributed_env.world_size % distributed_env.num_nodes):\n            num_items_per_rank[i] += 1\n\n    # distribute the chunks and their corresponding intervals to the ranks\n    chunks_per_ranks: Any = [[] for _ in range(distributed_env.num_nodes)]\n    intervals_per_ranks: Any = [[] for _ in range(distributed_env.num_nodes)]\n    process_per_node = distributed_env.world_size // distributed_env.num_nodes\n    for rank in range(distributed_env.world_size):\n        # calculate the start and end indexes of the chunks\n        start_index = 0 if rank == 0 else sum(num_items_per_rank[:rank])\n        end_index = sum(num_items_per_rank[: rank + 1])\n\n        # distribute the chunks and their corresponding intervals to the ranks\n        chunks_per_ranks[0 if distributed_env.num_nodes == 1 else rank // process_per_node].extend(\n            indexes[start_index:end_index]\n        )\n        intervals_per_ranks[0 if distributed_env.num_nodes == 1 else rank // process_per_node].extend(\n            chunk_intervals[start_index:end_index]\n        )\n\n    return chunks_per_ranks,"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items per rank\n    num_items_per_rank = [\n        len(indexes) // distributed_env.world_size for _ in range(distributed_env.world_size)\n    ]\n    # calculate the number of items left to distribute\n    num_items_left = len(indexes) % distributed_env.world_size\n\n    # if we need to drop the last items\n    if drop_last:\n        # distribute the items equally\n        for i in range(num_items_left):\n            num_items_per_rank[i] -= 1\n\n    # calculate the number of items per rank\n    num_items_per_rank = [\n        len(indexes) // distributed_env.world_size for _ in range(distributed_env.world_size)\n    ]\n    # calculate the number of items left to distribute\n    num_items_left = len(indexes) % distributed_env.world_size\n\n    # if we need to drop the last items\n    if drop_last:\n        # distribute the items equally\n        for i in range(num_items_left):\n            num_items_per_rank[i] -= 1\n\n    # initialize the list of chunks assigned to each rank\n    chunks_per_ranks = [[] for _ in range(distributed_env.world_size)]\n    # initialize the list of intervals assigned to each rank\n    intervals_per_ranks = [[] for _ in range(distributed_env.world_size)]\n\n    # iterate over all ranks\n    for rank in range(distributed_env.world_size):\n        # calculate the start index\n        start_index = sum(num_items_per_rank[:rank])\n        # calculate the end index\n        end_index = start_index + num_items_per_rank[rank]\n        # append the indexes assigned to the current rank\n        chunks_per_ranks[rank] = indexes[start_index:end_index]\n        # append the intervals assigned to the current rank\n        intervals_per_ranks[rank] = chunk_intervals[start"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items to process on each rank\n    items_per_rank = _calculate_items_per_rank(\n        distributed_env=distributed_env,\n        items=len(indexes),\n        drop_last=drop_last,\n    )\n\n    # create a list of lists of indexes and intervals to be assigned to each rank\n    indexes_per_rank: List[List[int]] = [[] for _ in range(distributed_env.world_size)]\n    chunk_intervals_per_rank: List[List[List[int]]] = [\n        [] for _ in range(distributed_env.world_size)\n    ]\n\n    # assign items and intervals to each rank\n    for rank in range(distributed_env.world_size):\n        for i in range(items_per_rank[rank]):\n            indexes_per_rank[rank].append(indexes[i])\n            chunk_intervals_per_rank[rank].append(chunk_intervals[i])\n\n    return indexes_per_rank, chunk_intervals_per_rank\n\n"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items to assign to each rank\n    num_items_per_rank: List[int] = (\n        [0] * distributed_env.world_size\n        if distributed_env.num_nodes == 1\n        else [0] * distributed_env.world_size * distributed_env.num_nodes\n    )\n    num_items_per_rank[0 if distributed_env.num_nodes == 1 else distributed_env.rank] = len(indexes)\n\n    # calculate the number of items to assign to each rank\n    for i in range(distributed_env.world_size):\n        if distributed_env.num_nodes == 1:\n            num_items_per_rank[i] = len(indexes) // distributed_env.world_size\n        else:\n            num_items_per_rank[i] = len(indexes) // distributed_env.world_size // distributed_env.num_nodes\n            if distributed_env.rank == i % distributed_env.num_nodes:\n                num_items_per_rank[i] += len(indexes) // distributed_env.world_size - (\n                    distributed_env.world_size // distributed_env.num_nodes\n                ) * distributed_env.num_nodes\n\n    # drop the last items if needed\n    if drop_last:\n        for i in range(distributed_env.world_size):\n            num_items_per_rank[i] -= distributed_env.world_size - distributed_env.num_nodes * (\n                num_items_per_rank[i] // distributed_env.num_nodes\n            )\n\n    # calculate the number of items to assign to each rank\n    num_items_per_rank = np.array(num_items_per_rank)\n    num_items_per_rank = num_items_per_rank - np.min(num_items_per_rank)\n    num_items_per_rank = np.ceil(num_items_per_rank / np.sum(num_items_per_rank) * len(indexes)).astype(int)\n\n   "}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, *self._inputs, **kwargs)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, *self._inputs, **kwargs)\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_device:\n            self._fn(item_metadata, output_dir, device=self._device, is_last=is_last)\n        elif self._contains_is_last:\n            self._fn(item_metadata, output_dir, is_last=is_last)\n        else:\n            self._fn(item_metadata, output_dir)\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n\n        self._fn(item_metadata, output_dir, **kwargs)\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, *self._inputs, **kwargs)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, *self._inputs, **kwargs)\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, *self._inputs, **kwargs)\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n\n        self._fn(item_metadata, output_dir, **kwargs)\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n\n        self._fn(item_metadata, output_dir, **kwargs)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {\"device\": self._device} if self._contains_device else {}\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n        self._fn(item_metadata, output_dir, **kwargs)\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs: Dict[str, Union[str, bool]] = {\"output_dir\": output_dir}\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n        self._fn(item_metadata, **kwargs)\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        args = [item_metadata, output_dir]\n\n        kwargs = {}\n\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(*args, **kwargs)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs: Dict[str, Any] = {}\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n        self._fn(item_metadata, output_dir, **kwargs)\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {\"is_last\": is_last} if self._contains_is_last else {}\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n\n        self._fn(item_metadata, output_dir, **kwargs)\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        args = [item_metadata, output_dir]\n        kwargs = {\"is_last\": is_last} if self._contains_is_last else {}\n        self._fn(*args, **kwargs)\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.client.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except s3.client.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n                continue\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n        except s3.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n        except s3.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n                continue\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.client.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n                continue\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except s3.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                logger.info(f\"Waiting for file {obj.geturl()} to exist\")\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.s3_client.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(bucket_name=obj.hostname, object_key=obj.path.lstrip(\"/\"))\n        except s3.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                logger.info(f\"{obj.path} not found. Retrying in {sleep_time} seconds.\")\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.head_object(Bucket=obj.hostname, Key=obj.path.lstrip(\"/\"))\n            return response\n        except s3.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                logger.warning(f\"{obj.geturl()} does not exist yet. Waiting for {sleep_time} seconds.\")\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.client.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n        except s3.client.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n                continue\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n        except s3.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n                continue\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n                continue\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(Bucket=obj.hostname, Key=obj.path.lstrip(\"/\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n                continue\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(Bucket=obj.hostname, Key=obj.path.lstrip(\"/\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                logger.info(f\"Waiting for {obj.geturl()} to exist...\")\n                sleep(sleep_time)\n                continue\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n        except s3.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                logger.info(\n                    f\"Waiting for file {obj.geturl()} to exist. Sleeping for {sleep_time} seconds.\"\n                )\n                sleep(sleep_time)\n                continue\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                logger.info(f\"Waiting for {obj.geturl()} to exist...\")\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            break\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n                continue\n            raise e\n    return response\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(Bucket=obj.hostname, Key=obj.path.lstrip(\"/\"))\n        except s3.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n                continue\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                logger.warning(f\"{obj.geturl()} does not exist. Retrying in {sleep_time} seconds.\")\n                sleep(sleep_time)\n            else:\n                raise\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            break\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                logger.info(f\"Waiting for file to exist: {obj.geturl()}\")\n                sleep(sleep_time)\n            else:\n                raise e\n    return response\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(Bucket=obj.hostname, Key=obj.path.lstrip(\"/\"))\n        except s3.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n                continue\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range("}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range("}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range("}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range("}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range("}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range("}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if isinstance(inputs, StreamingDataLoader):\n            input_dir = Dir()\n        else:\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if isinstance(inputs, StreamingDataLoader):\n            input_dir = Dir()\n        else:\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir="}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        input_dir = _resolve_dir(_get_input_dir(inputs))\n\n        if isinstance(batch_size, int) and batch_size > 1:\n            inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n           "}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if isinstance(inputs, StreamingDataLoader):\n            input_dir = Dir()\n        else:\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0,"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0,"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        output_dir = _resolve_dir(output_dir)\n\n        if output_dir.url and \"cloudspaces\" in output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {output_dir.path if output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if isinstance(inputs, StreamingDataLoader):\n            input_dir = Dir()\n        else:\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        input_dir = _resolve_dir(_get_input_dir(inputs))\n\n        if isinstance(batch_size, int) and batch_size > 1:\n            inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if batch_size is not None:\n            inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n\n        data_processor = DataProcessor(\n            input_dir=_resolve_dir(_get_input_dir(inputs)),\n            output_dir=_output_dir,\n            num_workers=num_workers or"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if batch_size is not None:\n            inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n\n        data_processor = DataProcessor(\n            input_dir=Dir(),\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n           "}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if chunk_size is None and chunk_bytes is None:\n            raise ValueError(\n                \"Either `chunk_size` or `chunk_bytes` should be provided. \"\n                \"Default is to create chunks of 10000 elements.\"\n            )\n\n        if isinstance(inputs, StreamingDataLoader):\n            input_dir = Dir()\n        else:\n            input_dir"}
{"namespace": "litdata.processing.functions.map", "completion": "    if not isinstance(fn, (FunctionType, partial)):\n        raise ValueError(f\"The provided fn {fn} isn't supported.\")\n\n    if not isinstance(inputs, Sequence):\n        raise ValueError(f\"The provided inputs {inputs} isn't supported.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs {inputs} is empty.\")\n\n    if not isinstance(output_dir, (str, Dir)):\n        raise ValueError(f\"The provided output_dir {output_dir} isn't supported.\")\n\n    if isinstance(output_dir, str):\n        output_dir = Dir(output_dir)\n\n    if not isinstance(weights, (Sequence, type(None))):\n        raise ValueError(f\"The provided weights {weights} isn't supported.\")\n\n    if not isinstance(num_workers, (int, type(None))):\n        raise ValueError(f\"The provided num_workers {num_workers} isn't supported.\")\n\n    if not isinstance(fast_dev_run, (bool, int)):\n        raise ValueError(f\"The provided fast_dev_run {fast_dev_run} isn't supported.\")\n\n    if not isinstance(num_nodes, (int, type(None))):\n        raise ValueError(f\"The provided num_nodes {num_nodes} isn't supported.\")\n\n    if not isinstance(machine, (str, type(None))):\n        raise ValueError(f\"The provided machine {machine} isn't supported.\")\n\n    if not isinstance(num_downloaders, (int, type(None))):\n        raise ValueError(f\"The provided num_downloaders {num_downloaders} isn't supported.\")\n\n    if not isinstance(num_uploaders, (int, type(None))):\n        raise ValueError(f\"The provided num_uploaders {num_uploaders} isn't supported.\")\n\n    if not isinstance(reorder_files, bool):\n        raise ValueError(f\"The provided reorder_files {reorder"}
{"namespace": "litdata.processing.functions.map", "completion": "    if not callable(fn):\n        raise ValueError(f\"The provided fn {fn} is not callable.\")\n\n    if not isinstance(inputs, Sequence):\n        raise ValueError(f\"The provided inputs {inputs} is not a sequence.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs {inputs} is empty.\")\n\n    if not isinstance(output_dir, (str, Dir)):\n        raise ValueError(f\"The provided output_dir {output_dir} is not a string or a Dir object.\")\n\n    if isinstance(output_dir, str):\n        output_dir = Dir(output_dir)\n\n    if not isinstance(weights, (list, tuple, type(None))):\n        raise ValueError(f\"The provided weights {weights} is not a list or None.\")\n\n    if isinstance(weights, (list, tuple)):\n        if len(weights) != len(inputs):\n            raise ValueError(f\"The provided weights {weights} doesn't have the same length as the inputs {inputs}.\")\n\n    if not isinstance(num_workers, (int, type(None))):\n        raise ValueError(f\"The provided num_workers {num_workers} is not an integer or None.\")\n\n    if isinstance(num_workers, int):\n        if num_workers <= 0:\n            raise ValueError(f\"The provided num_workers {num_workers} is not a positive integer.\")\n\n    if not isinstance(fast_dev_run, (bool, int)):\n        raise ValueError(f\"The provided fast_dev_run {fast_dev_run} is not a boolean or integer.\")\n\n    if isinstance(fast_dev_run, int):\n        if fast_dev_run <= 0:\n            raise ValueError(f\"The provided fast_dev_run {fast_dev_run} is not a positive integer.\")\n\n    if not isinstance(num_nodes, (int, type(None))):\n        raise ValueError(f\"The provided num_nodes"}
{"namespace": "litdata.processing.functions.map", "completion": "    if not callable(fn):\n        raise ValueError(f\"The provided {fn} isn't callable.\")\n\n    if not isinstance(inputs, Sequence):\n        raise ValueError(f\"The provided inputs {inputs} isn't a sequence.\")\n\n    if len(inputs) == 0:\n        raise ValueError(\"The provided inputs is empty.\")\n\n    if not isinstance(output_dir, (str, Dir)):\n        raise ValueError(f\"The provided output_dir {output_dir} isn't a string or a Dir.\")\n\n    if isinstance(output_dir, str):\n        output_dir = Dir(output_dir)\n\n    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"The provided output_dir {output_dir} isn't a Dir.\")\n\n    if weights is not None:\n        if not isinstance(weights, Sequence):\n            raise ValueError(f\"The provided weights {weights} isn't a Sequence.\")\n\n        if len(weights) != len(inputs):\n            raise ValueError(\n                f\"The provided weights {weights} doesn't have the same length as inputs {inputs}.\"\n            )\n\n    if num_workers is not None:\n        if not isinstance(num_workers, int):\n            raise ValueError(f\"The provided num_workers {num_workers} isn't an integer.\")\n\n    if fast_dev_run is not False:\n        if not isinstance(fast_dev_run, bool) and not isinstance(fast_dev_run, int):\n            raise ValueError(f\"The provided fast_dev_run {fast_dev_run} isn't a bool or an integer.\")\n\n        if isinstance(fast_dev_run, int) and fast_dev_run < 0:\n            raise ValueError(f\"The provided fast_dev_run {fast_dev_run} is a negative integer.\")\n\n    if num_nodes is not None:\n        if not isinstance(num_nodes, int):\n            raise ValueError(f\"The provided num"}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO:\n        raise ValueError(\"map() is not supported in the studio.\")\n\n    if not callable(fn):\n        raise ValueError(f\"The provided fn {fn} isn't callable.\")\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if not isinstance(num_workers, int) or num_workers < 1:\n        raise ValueError(f\"The provided num_workers {num_workers} isn't a positive integer.\")\n\n    if batch_size is not None:\n        if not isinstance(batch_size, int) or batch_size < 1:\n            raise ValueError(f\"The provided batch_size {batch_size} isn't a positive integer.\")\n\n    if num_nodes is not None:\n        if not isinstance(num_nodes, int) or num_nodes < 1:\n            raise ValueError(f\"The provided num_nodes {num_nodes} isn't a positive integer.\")\n\n    if num_downloaders is not None:\n        if not isinstance(num_downloaders, int) or num_downloaders < 1:\n            raise ValueError(f\"The provided num_downloaders {num_downloaders} isn't a positive integer.\")\n\n    if num_uploaders is not None:\n        if not isinstance(num_uploaders, int) or num_uploaders < 1:\n            raise ValueError(f\"The provided num_uploaders {num_uploaders} isn't a positive integer.\")\n\n    if not isinstance(reorder_files, bool):\n        raise ValueError(f\"The provided reorder_files {reorder_files} isn't a boolean.\")\n\n    if not isinstance(error_when_not_empty, bool):\n        raise ValueError(f\"The provided error_when_not_empty {error_when_not_empty} isn't a boolean.\")\n\n    if fast_dev_run is not False:\n        if isinstance(fast_dev_run, bool):\n            fast_dev_"}
{"namespace": "litdata.processing.functions.map", "completion": "    if not callable(fn):\n        raise ValueError(f\"The provided `fn` {fn} isn't callable.\")\n\n    if not isinstance(inputs, Sequence):\n        raise ValueError(f\"The provided `inputs` {inputs} isn't a Sequence.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided `inputs` {inputs} is empty.\")\n\n    if not isinstance(output_dir, (str, Dir)):\n        raise ValueError(f\"The provided `output_dir` {output_dir} isn't a str or Dir.\")\n\n    if isinstance(output_dir, str) and not os.path.isabs(output_dir):\n        raise ValueError(f\"The provided `output_dir` {output_dir} isn't an absolute path.\")\n\n    if isinstance(output_dir, Dir) and not output_dir.path:\n        raise ValueError(f\"The provided `output_dir` {output_dir} doesn't have a path.\")\n\n    if weights is not None and len(weights) != len(inputs):\n        raise ValueError(\n            f\"The provided `weights` {weights} doesn't have the same length as the inputs {inputs}.\"\n        )\n\n    if num_workers is not None and num_workers <= 0:\n        raise ValueError(f\"The provided `num_workers` {num_workers} isn't a positive integer.\")\n\n    if fast_dev_run is not False and not isinstance(fast_dev_run, int):\n        raise ValueError(f\"The provided `fast_dev_run` {fast_dev_run} isn't an integer or False.\")\n\n    if num_nodes is not None and num_nodes <= 0:\n        raise ValueError(f\"The provided `num_nodes` {num_nodes} isn't a positive integer.\")\n\n    if machine is not None and not isinstance(machine, str):\n        raise ValueError(f\"The provided `machine` {machine} isn't a str.\")"}
{"namespace": "litdata.processing.functions.map", "completion": "    if not callable(fn):\n        raise ValueError(f\"The provided fn {fn} isn't a callable.\")\n\n    if not isinstance(inputs, Sequence):\n        raise ValueError(f\"The provided inputs {inputs} isn't a sequence.\")\n\n    if len(inputs) == 0:\n        raise ValueError(\"The provided inputs are empty.\")\n\n    if not isinstance(output_dir, (str, Dir)):\n        raise ValueError(f\"The provided output_dir {output_dir} isn't a string or a Dir.\")\n\n    if isinstance(output_dir, str):\n        output_dir = Dir(output_dir)\n\n    if weights is not None and len(weights) != len(inputs):\n        raise ValueError(f\"The provided weights {weights} doesn't match the number of inputs {len(inputs)}.\")\n\n    if num_workers is not None and num_workers <= 0:\n        raise ValueError(f\"The provided num_workers {num_workers} is not a positive integer.\")\n\n    if num_workers is not None and num_workers > os.cpu_count():\n        raise ValueError(f\"The provided num_workers {num_workers} is greater than the number of CPUs available {os.cpu_count()}.\")\n\n    if num_nodes is not None and num_nodes <= 0:\n        raise ValueError(f\"The provided num_nodes {num_nodes} is not a positive integer.\")\n\n    if machine is not None and machine not in [\"cpu\", \"gpu\", \"tpu\"]:\n        raise ValueError(f\"The provided machine {machine} isn't supported. Please use 'cpu', 'gpu', or 'tpu'.\")\n\n    if num_downloaders is not None and num_downloaders <= 0:\n        raise ValueError(f\"The provided num_downloaders {num_downloaders} is not a positive integer.\")\n\n    if num_uploaders is not None and num_uploaders <= 0:\n        raise ValueError(f\"The provided num_uploaders {num_"}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO:\n        raise ValueError(\"The map function is not supported in Lightning Studio.\")\n\n    if not callable(fn):\n        raise ValueError(f\"The provided fn {fn} isn't callable.\")\n\n    if not isinstance(inputs, Sequence):\n        raise ValueError(f\"The provided inputs {inputs} isn't a sequence.\")\n\n    if len(inputs) == 0:\n        raise ValueError(\"The provided inputs is empty.\")\n\n    if num_workers is not None and num_workers < 1:\n        raise ValueError(f\"The provided num_workers {num_workers} isn't valid.\")\n\n    if num_nodes is not None and num_nodes < 1:\n        raise ValueError(f\"The provided num_nodes {num_nodes} isn't valid.\")\n\n    if num_downloaders is not None and num_downloaders < 1:\n        raise ValueError(f\"The provided num_downloaders {num_downloaders} isn't valid.\")\n\n    if num_uploaders is not None and num_uploaders < 1:\n        raise ValueError(f\"The provided num_uploaders {num_uploaders} isn't valid.\")\n\n    if batch_size is not None and batch_size < 1:\n        raise ValueError(f\"The provided batch_size {batch_size} isn't valid.\")\n\n    if batch_size is not None and not isinstance(batch_size, int):\n        raise ValueError(f\"The provided batch_size {batch_size} isn't valid.\")\n\n    if fast_dev_run is True:\n        fast_dev_run = 10\n\n    if fast_dev_run is not False and fast_dev_run < 1:\n        raise ValueError(f\"The provided fast_dev_run {fast_dev_run} isn't valid.\")\n\n    if weights is not None and len(weights) != len(inputs):\n        raise ValueError(\"The provided weights must have the same length as the inputs.\")\n\n    if weights is not None"}
{"namespace": "litdata.processing.functions.map", "completion": "    # Validate the inputs\n    if not callable(fn):\n        raise ValueError(f\"The provided fn {fn} isn't callable.\")\n\n    if not isinstance(inputs, Sequence):\n        raise ValueError(f\"The provided inputs {inputs} isn't a sequence.\")\n\n    if len(inputs) == 0:\n        raise ValueError(\"The provided inputs are empty.\")\n\n    if not isinstance(output_dir, (str, Dir)):\n        raise ValueError(f\"The provided output_dir {output_dir} isn't a string or a Dir object.\")\n\n    if isinstance(output_dir, str):\n        output_dir = Dir(output_dir)\n\n    if not isinstance(weights, (list, tuple)) and weights is not None:\n        raise ValueError(f\"The provided weights {weights} isn't a list or tuple.\")\n\n    if weights is not None and len(weights) != len(inputs):\n        raise ValueError(f\"The provided weights {weights} doesn't match the number of inputs {len(inputs)}.\")\n\n    if num_workers is not None and num_workers <= 0:\n        raise ValueError(f\"The provided num_workers {num_workers} is invalid.\")\n\n    if not isinstance(fast_dev_run, (bool, int)) or (isinstance(fast_dev_run, int) and fast_dev_run < 0):\n        raise ValueError(f\"The provided fast_dev_run {fast_dev_run} isn't a positive integer or bool.\")\n\n    if num_nodes is not None and num_nodes <= 0:\n        raise ValueError(f\"The provided num_nodes {num_nodes} isn't a positive integer.\")\n\n    if machine is not None and not isinstance(machine, str):\n        raise ValueError(f\"The provided machine {machine} isn't a string.\")\n\n    if num_downloaders is not None and num_downloaders <= 0:\n        raise ValueError(f\"The provided num_downloaders {num_downloaders} isn'"}
{"namespace": "litdata.processing.functions.map", "completion": "    # Set default values\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_nodes is None:\n        num_nodes = 1\n\n    if num_downloaders is None:\n        num_downloaders = 1\n\n    if num_uploaders is None:\n        num_uploaders = 1\n\n    # Validate arguments\n    if num_workers < 1:\n        raise ValueError(\"num_workers must be at least 1.\")\n\n    if num_nodes < 1:\n        raise ValueError(\"num_nodes must be at least 1.\")\n\n    if num_downloaders < 1:\n        raise ValueError(\"num_downloaders must be at least 1.\")\n\n    if num_uploaders < 1:\n        raise ValueError(\"num_uploaders must be at least 1.\")\n\n    if batch_size is not None and batch_size < 1:\n        raise ValueError(\"batch_size must be at least 1.\")\n\n    if not callable(fn):\n        raise ValueError(\"fn must be a callable.\")\n\n    if not isinstance(inputs, Sequence):\n        raise ValueError(\"inputs must be a sequence.\")\n\n    if len(inputs) == 0:\n        raise ValueError(\"inputs must be a non-empty sequence.\")\n\n    if not isinstance(output_dir, (str, Dir)):\n        raise ValueError(\"output_dir must be a string or a Dir.\")\n\n    if isinstance(output_dir, str):\n        output_dir = Dir(output_dir)\n\n    if weights is not None and len(weights) != len(inputs):\n        raise ValueError(\"weights must be the same length as inputs.\")\n\n    if fast_dev_run is True:\n        fast_dev_run = 10\n\n    if fast_dev_run is not False and fast_dev_run < 1:\n        raise ValueError(\"fast_dev_run must be at least 1.\")\n\n    if reader is not None and not isinstance(reader, BaseReader"}
{"namespace": "litdata.processing.functions.map", "completion": "    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_nodes is not None and num_nodes < 1:\n        raise ValueError(f\"num_nodes must be >= 1, but got {num_nodes}\")\n\n    if num_workers is not None and num_workers < 1:\n        raise ValueError(f\"num_workers must be >= 1, but got {num_workers}\")\n\n    if num_downloaders is not None and num_downloaders < 1:\n        raise ValueError(f\"num_downloaders must be >= 1, but got {num_downloaders}\")\n\n    if num_uploaders is not None and num_uploaders < 1:\n        raise ValueError(f\"num_uploaders must be >= 1, but got {num_uploaders}\")\n\n    if batch_size is not None and batch_size < 1:\n        raise ValueError(f\"batch_size must be >= 1, but got {batch_size}\")\n\n    if fast_dev_run is True:\n        fast_dev_run = 2\n\n    if not callable(fn):\n        raise ValueError(f\"fn must be callable, but got {type(fn)}\")\n\n    if not isinstance(inputs, Sequence):\n        raise ValueError(f\"inputs must be a Sequence, but got {type(inputs)}\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"inputs must have at least one element\")\n\n    if not isinstance(output_dir, (str, Dir)):\n        raise ValueError(f\"output_dir must be a str or Dir, but got {type(output_dir)}\")\n\n    if isinstance(output_dir, str):\n        output_dir = Dir(output_dir)\n\n    if not isinstance(weights, (list, tuple, type(None))):\n        raise ValueError(f\"weights must be a list, tuple, or None, but got {type(weights)}\")\n\n    if weights is not"}
{"namespace": "litdata.processing.functions.map", "completion": "    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_nodes is None:\n        num_nodes = 1\n\n    if num_downloaders is None:\n        num_downloaders = 1\n\n    if num_uploaders is None:\n        num_uploaders = 1\n\n    if batch_size is None:\n        batch_size = 1\n\n    if isinstance(output_dir, str):\n        output_dir = Dir(output_dir)\n\n    if fast_dev_run:\n        if isinstance(fast_dev_run, bool):\n            fast_dev_run = 10\n        inputs = inputs[:fast_dev_run]\n\n    if reader is None:\n        reader = BaseReader()\n\n    _assert_dir_is_empty(output_dir, error_when_not_empty)\n\n    recipe = LambdaDataTransformRecipe(fn=fn, inputs=inputs)\n    recipe.prepare_recipe(\n        output_dir=output_dir,\n        weights=weights,\n        num_workers=num_workers,\n        num_nodes=num_nodes,\n        machine=machine,\n        num_downloaders=num_downloaders,\n        num_uploaders=num_uploaders,\n        reorder_files=reorder_files,\n        batch_size=batch_size,\n    )\n\n    recipe.execute_recipe(reader=reader)\n\n"}
{"namespace": "litdata.processing.functions.map", "completion": "    # Validate the inputs\n    if not callable(fn):\n        raise ValueError(f\"The provided {fn} isn't a callable.\")\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_workers < 1:\n        raise ValueError(f\"The provided num_workers {num_workers} is invalid. It must be greater than 0.\")\n\n    if num_nodes is not None and num_nodes < 1:\n        raise ValueError(f\"The provided num_nodes {num_nodes} is invalid. It must be greater than 0.\")\n\n    if machine is not None and not isinstance(machine, str):\n        raise ValueError(f\"The provided machine {machine} is invalid. It must be a string.\")\n\n    if num_downloaders is not None and num_downloaders < 1:\n        raise ValueError(f\"The provided num_downloaders {num_downloaders} is invalid. It must be greater than 0.\")\n\n    if num_uploaders is not None and num_uploaders < 1:\n        raise ValueError(f\"The provided num_uploaders {num_uploaders} is invalid. It must be greater than 0.\")\n\n    if batch_size is not None and batch_size < 1:\n        raise ValueError(f\"The provided batch_size {batch_size} is invalid. It must be greater than 0.\")\n\n    if not isinstance(output_dir, (str, Dir)):\n        raise ValueError(f\"The provided output_dir {output_dir} is invalid. It must be a string or a Dir object.\")\n\n    if isinstance(output_dir, str):\n        output_dir = Dir(output_dir)\n\n    if not output_dir.exists():\n        output_dir.mkdir(parents=True)\n    elif error_when_not_empty and len(list(output_dir.iterdir())) != 0:\n        raise ValueError(f\"The provided output_dir {output_dir} is not empty. Specify error_when_not_empty="}
{"namespace": "litdata.processing.functions.map", "completion": "    # Check if output_dir is a string\n    if isinstance(output_dir, str):\n        output_dir = Dir(output_dir)\n\n    # Check if output_dir is a Dir object\n    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir is not a valid Dir object.\")\n\n    # Check if output_dir is empty\n    if error_when_not_empty and not output_dir.is_empty():\n        raise ValueError(\n            \"The provided output_dir is not empty. If you want to overwrite the directory, set the error_when_not_empty parameter to False.\"\n        )\n\n    # Check if output_dir is empty\n    if not output_dir.exists():\n        output_dir.mkdir(parents=True)\n\n    # Check if output_dir is empty\n    if not output_dir.is_empty():\n        raise ValueError(\"The provided output_dir is not empty.\")\n\n    # Check if output_dir is empty\n    if not output_dir.exists():\n        raise ValueError(\"The provided output_dir does not exist.\")\n\n    # Check if output_dir is empty\n    if not output_dir.is_empty():\n        raise ValueError(\"The provided output_dir is not empty.\")\n\n    # Check if output_dir is empty\n    if not output_dir.exists():\n        raise ValueError(\"The provided output_dir does not exist.\")\n\n    # Check if output_dir is empty\n    if not output_dir.is_empty():\n        raise ValueError(\"The provided output_dir is not empty.\")\n\n    # Check if output_dir is empty\n    if not output_dir.exists():\n        raise ValueError(\"The provided output_dir does not exist.\")\n\n    # Check if output_dir is empty\n    if not output_dir.is_empty():\n        raise ValueError(\"The provided output_dir is not empty.\")\n\n    # Check if output_dir is empty\n    if not output_dir.exists():\n        raise ValueError(\"The provided output_dir does not exist.\")\n\n    # Check if output_dir is empty\n    if not output"}
{"namespace": "litdata.processing.functions.map", "completion": "    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_nodes is None:\n        num_nodes = 1\n\n    if num_downloaders is None:\n        num_downloaders = 1\n\n    if num_uploaders is None:\n        num_uploaders = 1\n\n    if not isinstance(output_dir, Dir):\n        output_dir = Dir(output_dir)\n\n    if not output_dir.exists():\n        output_dir.mkdir()\n\n    if error_when_not_empty and len(output_dir.glob(\"*\")) > 0:\n        raise ValueError(f\"The output directory {output_dir} is not empty.\")\n\n    if not output_dir.is_dir():\n        raise ValueError(f\"The output directory {output_dir} is not a directory.\")\n\n    if not callable(fn):\n        raise ValueError(f\"The provided function {fn} is not callable.\")\n\n    if weights is not None and len(weights) != len(inputs):\n        raise ValueError(\n            f\"The number of weights {len(weights)} doesn't match the number of inputs {len(inputs)}.\"\n        )\n\n    if num_workers > len(inputs):\n        raise ValueError(\n            f\"The number of workers {num_workers} is greater than the number of inputs {len(inputs)}.\"\n        )\n\n    if num_workers < 0:\n        raise ValueError(f\"The number of workers {num_workers} should be greater than 0.\")\n\n    if num_nodes < 1:\n        raise ValueError(f\"The number of nodes {num_nodes} should be greater than 0.\")\n\n    if num_downloaders < 1:\n        raise ValueError(\n            f\"The number of downloaders {num_downloaders} should be greater than 0.\"\n        )\n\n    if num_uploaders < 1:\n        raise ValueError(\n            f\"The number of uploaders {num_uploaders} should be"}
{"namespace": "litdata.processing.functions.map", "completion": "    if not _IS_IN_STUDIO:\n        raise ValueError(\n            \"The map function is only supported in https://studio.lightning.ai/. \"\n            \"Please use the map function in https://huggingface.co/docs/datasets/processing/map.html#datasets.processing.map\"\n        )\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_nodes is None:\n        num_nodes = 1\n\n    if num_downloaders is None:\n        num_downloaders = 1\n\n    if num_uploaders is None:\n        num_uploaders = 1\n\n    if num_workers < 1:\n        raise ValueError(f\"num_workers must be greater than 0, not {num_workers}.\")\n\n    if num_nodes < 1:\n        raise ValueError(f\"num_nodes must be greater than 0, not {num_nodes}.\")\n\n    if num_downloaders < 1:\n        raise ValueError(f\"num_downloaders must be greater than 0, not {num_downloaders}.\")\n\n    if num_uploaders < 1:\n        raise ValueError(f\"num_uploaders must be greater than 0, not {num_uploaders}.\")\n\n    if batch_size is not None and batch_size < 1:\n        raise ValueError(f\"batch_size must be greater than 0, not {batch_size}.\")\n\n    if fast_dev_run:\n        if isinstance(fast_dev_run, bool):\n            fast_dev_run = 100\n        inputs = inputs[:fast_dev_run]\n\n    if isinstance(output_dir, str):\n        output_dir = Dir(output_dir)\n\n    if error_when_not_empty and len(os.listdir(output_dir.path)) > 0:\n        raise ValueError(f\"The output directory {output_dir} is not empty.\")\n\n    if reorder_files:\n        inputs = sorted(input"}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO:\n        raise RuntimeError(\n            \"The map function is not supported in https://studio.lightning.ai/. Please use the map_batch function.\"\n        )\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_nodes is not None and machine is None:\n        raise ValueError(\"Please specify a machine type.\")\n\n    if num_nodes is not None and num_nodes <= 0:\n        raise ValueError(\"Please specify a positive number of nodes.\")\n\n    if num_workers <= 0:\n        raise ValueError(\"Please specify a positive number of workers.\")\n\n    if num_workers > num_nodes:\n        raise ValueError(\"The number of workers cannot be greater than the number of nodes.\")\n\n    if num_downloaders is not None and num_downloaders <= 0:\n        raise ValueError(\"Please specify a positive number of downloaders.\")\n\n    if num_uploaders is not None and num_uploaders <= 0:\n        raise ValueError(\"Please specify a positive number of uploaders.\")\n\n    if batch_size is not None and batch_size <= 0:\n        raise ValueError(\"Please specify a positive batch size.\")\n\n    if batch_size is not None and batch_size > len(inputs):\n        raise ValueError(\"The batch size cannot be greater than the number of inputs.\")\n\n    if batch_size is not None and batch_size == 1:\n        raise ValueError(\"The batch size cannot be equal to 1.\")\n\n    if num_downloaders is not None and num_downloaders > num_workers:\n        raise ValueError(\"The number of downloaders cannot be greater than the number of workers.\")\n\n    if num_uploaders is not None and num_uploaders > num_workers:\n        raise ValueError(\"The number of uploaders cannot be greater than the number of workers.\")\n\n    if isinstance(output_dir, str):\n        output_dir = Dir(output_dir)\n\n    if error_when_not_empty and not output_dir.is_empty():\n       "}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO:\n        raise RuntimeError(\"map() is not supported in the studio environment.\")\n\n    if isinstance(output_dir, str):\n        output_dir = Dir(output_dir)\n\n    if not output_dir.exists():\n        output_dir.mkdir()\n\n    if error_when_not_empty and len(os.listdir(output_dir.path)) > 0:\n        raise ValueError(\n            f\"The output directory {output_dir.path} is not empty. Please specify a different directory or set `error_when_not_empty=False`.\"\n        )\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_nodes is not None:\n        if num_nodes < 1:\n            raise ValueError(f\"The provided `num_nodes` must be greater than 0.\")\n\n        if num_workers < 1:\n            raise ValueError(f\"The provided `num_workers` must be greater than 0.\")\n\n        if num_workers > num_nodes:\n            raise ValueError(\n                f\"The provided `num_workers` {num_workers} is greater than the provided `num_nodes` {num_nodes}.\"\n            )\n\n        if num_uploaders is not None and num_uploaders > num_workers:\n            raise ValueError(\n                f\"The provided `num_uploaders` {num_uploaders} is greater than the provided `num_workers` {num_workers}.\"\n            )\n\n        if num_downloaders is not None and num_downloaders > num_workers:\n            raise ValueError(\n                f\"The provided `num_downloaders` {num_downloaders} is greater than the provided `num_workers` {num_workers}.\"\n            )\n\n        if machine is None:\n            raise ValueError(\n                f\"The provided `num_nodes` {num_nodes} is greater than 1, but `machine` is not specified.\"\n            )\n\n    if fast_dev"}
{"namespace": "litdata.processing.functions.map", "completion": "    if not _IS_IN_STUDIO:\n        if num_nodes is not None:\n            raise ValueError(\"num_nodes is only supported on https://lightning.ai/.\")\n\n        if machine is not None:\n            raise ValueError(\"machine is only supported on https://lightning.ai/.\")\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_workers <= 0:\n        raise ValueError(\"num_workers must be positive.\")\n\n    if num_downloaders is not None and num_downloaders <= 0:\n        raise ValueError(\"num_downloaders must be positive.\")\n\n    if num_uploaders is not None and num_uploaders <= 0:\n        raise ValueError(\"num_uploaders must be positive.\")\n\n    if batch_size is not None and batch_size <= 0:\n        raise ValueError(\"batch_size must be positive.\")\n\n    if isinstance(output_dir, str):\n        output_dir = Dir(output_dir)\n\n    if error_when_not_empty and len(output_dir.list_recursive()) > 0:\n        raise ValueError(f\"The output directory {output_dir.path} is not empty.\")\n\n    if fast_dev_run is True:\n        fast_dev_run = 1\n    elif fast_dev_run is False:\n        fast_dev_run = None\n\n    if fast_dev_run is not None:\n        if fast_dev_run < 1:\n            raise ValueError(\"fast_dev_run must be positive.\")\n\n        if fast_dev_run > len(inputs):\n            raise ValueError(\"fast_dev_run must be smaller than the number of inputs.\")\n\n    if weights is not None and len(weights) != len(inputs):\n        raise ValueError(\"weights must have the same length as inputs.\")\n\n    if weights is not None and sum(weights) == 0:\n        raise ValueError(\"At least one weight must be positive.\")\n\n    if reorder_files:\n        inputs = sorted"}
{"namespace": "litdata.processing.functions.map", "completion": "    if not _IS_IN_STUDIO:\n        raise ValueError(\"This function is only supported in https://studio.lightning.ai/\")\n\n    if not isinstance(fn, (FunctionType, partial)):\n        raise ValueError(f\"The provided {fn} isn't supported.\")\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_workers < 1:\n        raise ValueError(f\"num_workers must be >= 1, got {num_workers}\")\n\n    if isinstance(output_dir, str):\n        output_dir = Dir(output_dir)\n\n    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"output_dir must be a string path or a Dir object, got {output_dir}\")\n\n    if isinstance(inputs, str):\n        inputs = [inputs]\n\n    if not isinstance(inputs, Sequence):\n        raise ValueError(f\"inputs must be a Sequence, got {inputs}\")\n\n    if len(inputs) < 1:\n        raise ValueError(f\"inputs must have at least one element, got {inputs}\")\n\n    if isinstance(weights, Sequence):\n        if len(weights) != len(inputs):\n            raise ValueError(f\"weights must have the same length as inputs, got {len(weights)} and {len(inputs)}\")\n\n    if isinstance(weights, Sequence):\n        if not all(isinstance(weight, int) for weight in weights):\n            raise ValueError(f\"weights must be a list of integers, got {weights}\")\n\n    if isinstance(fast_dev_run, int) and fast_dev_run < 1:\n        raise ValueError(f\"fast_dev_run must be >= 1, got {fast_dev_run}\")\n\n    if isinstance(num_nodes, int) and num_nodes < 1:\n        raise ValueError(f\"num_nodes must be >= 1, got {num_nodes"}
{"namespace": "litdata.processing.functions.map", "completion": "    if not isinstance(output_dir, str) and not isinstance(output_dir, Dir):\n        raise ValueError(f\"The provided output_dir {output_dir} is not supported.\")\n\n    if isinstance(output_dir, str):\n        output_dir = Dir(output_dir)\n\n    if output_dir.exists() and error_when_not_empty:\n        raise ValueError(f\"The provided output_dir {output_dir} is not empty.\")\n\n    if not output_dir.exists():\n        output_dir.mkdir(parents=True)\n\n    if not isinstance(fn, (FunctionType, partial)):\n        raise ValueError(f\"The provided fn {fn} is not supported.\")\n\n    if not isinstance(inputs, (list, tuple, dict)):\n        raise ValueError(f\"The provided inputs {inputs} is not supported.\")\n\n    if isinstance(inputs, (list, tuple)):\n        if len(inputs) == 0:\n            raise ValueError(\"The provided inputs is empty.\")\n        if not all(isinstance(input_element, (str, Path)) for input_element in inputs):\n            raise ValueError(\n                f\"The provided inputs {inputs} contains elements that are not supported.\"\n            )\n\n    if isinstance(inputs, dict):\n        if len(inputs) == 0:\n            raise ValueError(\"The provided inputs is empty.\")\n        if not all(isinstance(input_element, (str, Path)) for input_element in inputs.values()):\n            raise ValueError(\n                f\"The provided inputs {inputs} contains elements that are not supported.\"\n            )\n\n    if isinstance(inputs, dict) and len(inputs) != len(set(inputs.values())):\n        raise ValueError(f\"The provided inputs {inputs} contains duplicates.\")\n\n    if isinstance(inputs, dict):\n        inputs = list(inputs.values())\n\n    if isinstance(inputs[0], Path):\n        inputs = [str(input_element) for input_element in inputs]\n\n    if not isinstance"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client(input_dir.path)\n\n    while True:\n        try:\n            task_index, files = queue_in.get(timeout=1)\n        except Empty:\n            continue\n\n        for file in files:\n            file_path = os.path.join(cache_dir, file)\n            if not os.path.exists(file_path):\n                file_obj = os.path.join(input_dir.path, file)\n                file_obj = parse.urlparse(file_obj)\n                _wait_for_file_to_exist(s3, file_obj)\n                s3.download_file(file_obj.path.lstrip(\"/\"), file_path)\n\n        queue_out.put(task_index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client(input_dir.netloc)\n    while True:\n        try:\n            task_index, files = queue_in.get(timeout=1)\n        except Empty:\n            continue\n        for file in files:\n            file_path = os.path.join(cache_dir, file)\n            if not os.path.exists(file_path):\n                s3.download_file(file, file_path)\n        queue_out.put(task_index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client(input_dir)\n    while True:\n        try:\n            index, files = queue_in.get(block=False)\n        except Empty:\n            break\n        for file in files:\n            obj = _resolve_dir(file, input_dir)\n            file_path = os.path.join(cache_dir, *obj.path.split(\"/\"))\n            if not os.path.exists(file_path):\n                os.makedirs(os.path.dirname(file_path), exist_ok=True)\n                _wait_for_file_to_exist(s3, obj)\n                s3.download_file(obj, file_path)\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client(input_dir.s3_endpoint_url, input_dir.s3_access_key, input_dir.s3_secret_key)\n    while True:\n        try:\n            task_index, files = queue_in.get(timeout=1)\n            for file in files:\n                obj = _resolve_dir(file, input_dir)\n                if not os.path.exists(os.path.join(cache_dir, obj.path.lstrip(\"/\"))):\n                    _wait_for_file_to_exist(s3, obj)\n                    s3.download_file(\n                        obj.netloc,\n                        obj.path.lstrip(\"/\"),\n                        os.path.join(cache_dir, obj.path.lstrip(\"/\")),\n                    )\n            queue_out.put(task_index)\n        except Empty:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client(input_dir)\n    while True:\n        try:\n            task = queue_in.get(block=True, timeout=1)\n        except Empty:\n            continue\n        if task is None:\n            break\n        index, paths = task\n        for path in paths:\n            obj = parse.urlparse(path)\n            if not os.path.isfile(os.path.join(cache_dir, obj.path.lstrip(\"/\"))):\n                _wait_for_file_to_exist(s3, obj)\n                s3.download_file(obj, cache_dir)\n        queue_out.put((index, None))\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client(input_dir)\n    while True:\n        try:\n            index, paths = queue_in.get(timeout=1)\n        except Empty:\n            continue\n\n        for path in paths:\n            obj = s3.path_to_object(path)\n            file_path = os.path.join(cache_dir, obj.path.lstrip(\"/\"))\n            if not os.path.exists(file_path):\n                os.makedirs(os.path.dirname(file_path), exist_ok=True)\n                s3.client.download_file(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"), Filename=file_path)\n\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client(input_dir.url)\n\n    while True:\n        try:\n            task_idx, file_paths = queue_in.get(block=True, timeout=1)\n        except Empty:\n            continue\n\n        for file_path in file_paths:\n            obj = parse.urlparse(file_path)\n            local_path = os.path.join(cache_dir, obj.path.lstrip(\"/\"))\n\n            if not os.path.exists(local_path):\n                os.makedirs(os.path.dirname(local_path), exist_ok=True)\n                _wait_for_file_to_exist(s3, obj)\n                s3.download_file(obj.path.lstrip(\"/\"), local_path)\n\n        queue_out.put(task_idx)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client(input_dir.scheme)\n\n    while True:\n        try:\n            index, file_paths = queue_in.get(block=False)\n        except Empty:\n            break\n        for file_path in file_paths:\n            obj = parse.urlparse(os.path.join(input_dir.scheme, input_dir.netloc, file_path.lstrip(\"/\")))\n            if not os.path.exists(os.path.join(cache_dir, obj.path.lstrip(\"/\"))):\n                os.makedirs(os.path.join(cache_dir, os.path.dirname(obj.path.lstrip(\"/\"))), exist_ok=True)\n                _wait_for_file_to_exist(s3, obj)\n                s3.download(obj, os.path.join(cache_dir, obj.path.lstrip(\"/\")))\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client(input_dir)\n\n    while True:\n        try:\n            task = queue_in.get(block=False)\n        except Empty:\n            break\n        index, files = task\n        for file in files:\n            obj = s3.parse_url(file)\n            file_path = os.path.join(cache_dir, obj.path.lstrip(\"/\"))\n            os.makedirs(os.path.dirname(file_path), exist_ok=True)\n            if not os.path.exists(file_path):\n                _wait_for_file_to_exist(s3, obj)\n                s3.download(obj, file_path)\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client(input_dir.url)\n    while True:\n        try:\n            task_index, file_paths = queue_in.get(timeout=1)\n        except Empty:\n            continue\n        for file_path in file_paths:\n            obj = parse.urlparse(os.path.join(input_dir.url, file_path))\n            if not os.path.exists(os.path.join(cache_dir, obj.path.lstrip(\"/\"))):\n                _wait_for_file_to_exist(s3, obj)\n                s3.download_file(obj.path.lstrip(\"/\"), cache_dir)\n        queue_out.put(task_index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client(input_dir.scheme)\n    while True:\n        try:\n            idx, files = queue_in.get(block=True, timeout=1)\n        except Empty:\n            break\n        for file in files:\n            obj = _resolve_dir(file, input_dir)\n            if not os.path.exists(os.path.join(cache_dir, obj.path.lstrip(\"/\"))):\n                _wait_for_file_to_exist(s3, obj)\n                s3.download_file(obj, cache_dir)\n        queue_out.put(idx)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client(input_dir)\n\n    while True:\n        try:\n            task_index, file_paths = queue_in.get(block=False)\n        except Empty:\n            break\n        for file_path in file_paths:\n            obj = _resolve_dir(file_path, input_dir)\n            if not os.path.exists(os.path.join(cache_dir, obj.path.lstrip(\"/\"))):\n                os.makedirs(os.path.dirname(os.path.join(cache_dir, obj.path.lstrip(\"/\"))), exist_ok=True)\n                _wait_for_file_to_exist(s3, obj)\n                s3.client.download_file(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"), Filename=os.path.join(cache_dir, obj.path.lstrip(\"/\")))\n        queue_out.put(task_index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client(input_dir.path)\n    while True:\n        try:\n            index, files = queue_in.get(block=False)\n        except Empty:\n            break\n\n        for file in files:\n            file_path = Path(file)\n            local_path = Path(cache_dir) / file_path.relative_to(input_dir.path)\n            local_path.parent.mkdir(parents=True, exist_ok=True)\n            if not local_path.exists():\n                obj = parse.urlparse(file)\n                _wait_for_file_to_exist(s3, obj)\n                s3.download_file(obj, local_path)\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client(input_dir.url)\n    while True:\n        try:\n            idx, files = queue_in.get(block=False)\n        except Empty:\n            break\n\n        for file in files:\n            file_path = os.path.join(cache_dir, file)\n            if not os.path.exists(file_path):\n                s3.download_file(file, file_path)\n        queue_out.put(idx)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client(input_dir)\n    while True:\n        try:\n            task_index, file_paths = queue_in.get(timeout=1)\n        except Empty:\n            continue\n        for file_path in file_paths:\n            obj = s3.parse_url(file_path)\n            if not os.path.exists(os.path.join(cache_dir, obj.path.lstrip(\"/\"))):\n                _wait_for_file_to_exist(s3, obj)\n                s3.download_file(obj, cache_dir)\n        queue_out.put(task_index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client(input_dir.netloc)\n\n    while True:\n        try:\n            task_index, file_paths = queue_in.get(block=True, timeout=1)\n        except Empty:\n            continue\n\n        for file_path in file_paths:\n            obj = _resolve_dir(file_path, input_dir)\n            file_path_in_cache = os.path.join(cache_dir, obj.path.lstrip(\"/\"))\n            os.makedirs(os.path.dirname(file_path_in_cache), exist_ok=True)\n\n            if os.path.isfile(file_path_in_cache):\n                continue\n\n            _wait_for_file_to_exist(s3, obj)\n            s3.download_file(obj.path.lstrip(\"/\"), file_path_in_cache)\n\n        queue_out.put(task_index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client(input_dir.scheme)\n\n    while True:\n        try:\n            task = queue_in.get(timeout=1)\n        except Empty:\n            continue\n\n        if task is None:\n            break\n\n        index, files = task\n\n        for file in files:\n            obj = _resolve_dir(file, input_dir)\n            if not os.path.exists(os.path.join(cache_dir, obj.path.lstrip(\"/\"))):\n                s3.download(obj, cache_dir)\n\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client(input_dir.scheme, input_dir.netloc)\n\n    while True:\n        try:\n            task_index, files = queue_in.get(timeout=1)\n        except Empty:\n            break\n\n        for file in files:\n            obj = _resolve_dir(file, input_dir)\n            local_path = os.path.join(cache_dir, obj.path.lstrip(\"/\"))\n            os.makedirs(os.path.dirname(local_path), exist_ok=True)\n            if not os.path.exists(local_path):\n                _wait_for_file_to_exist(s3, obj)\n                s3.client.download_file(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"), Filename=local_path)\n\n        queue_out.put(task_index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client(input_dir)\n\n    while True:\n        try:\n            index, files = queue_in.get(block=False)\n        except Empty:\n            sleep(0.1)\n            continue\n\n        for file in files:\n            file_path = os.path.join(cache_dir, file.path)\n            os.makedirs(os.path.dirname(file_path), exist_ok=True)\n            if not os.path.isfile(file_path):\n                obj = _resolve_dir(file, input_dir)\n                _wait_for_file_to_exist(s3, obj)\n                s3.client.download_file(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"), Filename=file_path)\n\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    # create a s3 client\n    s3 = S3Client(input_dir)\n\n    # wait for the input queue to have a task\n    while True:\n        try:\n            # get the next task\n            index, file_paths = queue_in.get(block=True, timeout=1)\n        except Empty:\n            continue\n\n        # download all files\n        for file_path in file_paths:\n\n            # get the path to the local file\n            local_file_path = os.path.join(cache_dir, file_path.lstrip(\"/\"))\n\n            # get the path to the remote file\n            remote_file_path = os.path.join(input_dir.path, file_path.lstrip(\"/\"))\n\n            # if the file does not exist, download it\n            if not os.path.exists(local_file_path):\n\n                # create the local directory if it does not exist\n                os.makedirs(os.path.dirname(local_file_path), exist_ok=True)\n\n                # download the file\n                s3.download_file(remote_file_path, local_file_path)\n\n        # signal completion\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Tuple[int, Union[str, Tuple[str, str]]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        index, path = r\n\n        # 4. Upload the file\n        if isinstance(path, tuple):\n            dirpath, path = path\n            shutil.copytree(dirpath, dirpath.replace(cache_dir, output_dir.path))\n            shutil.rmtree(dirpath)\n        elif output_dir.url:\n            obj = parse.urlparse(path)\n            s3.client.upload_file(path, obj.netloc, obj.path.lstrip(\"/\"))\n        elif output_dir.path:\n            shutil.copy(path, path.replace(cache_dir, output_dir.path))\n\n        # 5. Inform the worker the current files are ready to be removed\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Tuple[int, Union[str, Tuple[str, str]]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        index, path = r\n\n        # 4. Upload the file\n        if isinstance(path, tuple):\n            dirpath, filepath = path\n            s3.upload_file(filepath, os.path.join(output_dir.url, filepath.replace(dirpath, \"\")[1:]))\n        else:\n            s3.upload_file(path, os.path.join(output_dir.url, path.replace(cache_dir, \"\")[1:]))\n\n        # 5. Remove the file\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Tuple[Union[str, Tuple[str, str]], bool]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        file_path, delete = r\n\n        # 4. Upload the file\n        if isinstance(file_path, str):\n            if output_dir.path:\n                file_path = file_path.replace(cache_dir, output_dir.path)\n\n            if output_dir.url:\n                obj = parse.urlparse(file_path)\n\n                if obj.scheme == \"s3\":\n                    s3.client.upload_file(obj.path.lstrip(\"/\"), obj.netloc, obj.path.lstrip(\"/\"))\n                else:\n                    raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n            else:\n                shutil.copyfile(file_path, file_path.replace(cache_dir, output_dir.path))\n\n        elif isinstance(file_path, tuple):\n            temp_dir, file_path = file_path\n\n            if output_dir.path:\n                file_path = file_path.replace(cache_dir, output_dir.path)\n\n            if output_dir.url:\n                obj = parse.urlparse(file_path)\n\n                if obj.scheme == \"s3\":\n                    s3.client.upload_file(file_path, obj.netloc, obj.path.lstrip(\"/\"))\n                else:\n                    raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n            else:\n                shutil.copyfile(file_path, file_path.replace(cache_dir, output_dir.path))\n\n            shutil.rmtree(temp_dir)\n\n        # 5. Remove the file\n        if delete:\n            remove_queue.put"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Tuple[Union[str, Tuple[str, str]], bool]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        path, remove = r\n\n        # 4. Upload the file\n        if isinstance(path, str):\n            if not path.startswith(cache_dir) and output_dir.path is not None:\n                path = path.replace(output_dir.path, cache_dir)\n\n            if output_dir.url:\n                obj = parse.urlparse(path)\n                s3.client.upload_file(obj.path.lstrip(\"/\"), obj.netloc, obj.path.lstrip(\"/\"))\n            elif output_dir.path:\n                shutil.copyfile(path, path.replace(cache_dir, output_dir.path))\n            else:\n                raise ValueError(\"The output directory isn't supported.\")\n\n        elif isinstance(path, tuple):\n            dirpath, path = path\n            if not path.startswith(cache_dir) and output_dir.path is not None:\n                path = path.replace(output_dir.path, cache_dir)\n\n            if output_dir.url:\n                obj = parse.urlparse(path)\n                s3.client.upload_file(os.path.join(dirpath, path), obj.netloc, obj.path.lstrip(\"/\"))\n            elif output_dir.path:\n                shutil.copyfile(os.path.join(dirpath, path), path.replace(cache_dir, output_dir.path))\n            else:\n                raise ValueError(\"The output directory isn't supported.\")\n\n        # 5. Remove the file\n        if remove:\n            remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Tuple[int, Union[str, Tuple[str, str]]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        index, path = r\n\n        # 4. Upload the file\n        if isinstance(path, tuple):\n            dirpath, path = path\n            shutil.copyfile(os.path.join(dirpath, path), os.path.join(output_dir.path, path))\n            shutil.rmtree(dirpath)\n        else:\n            if output_dir.scheme == \"s3\":\n                obj = parse.urlparse(output_dir.url)\n                _wait_for_file_to_exist(s3, obj, 5)\n                s3.client.upload_file(os.path.join(cache_dir, path), obj.netloc, os.path.join(obj.path.lstrip(\"/\"), path))\n            elif output_dir.scheme == \"file\":\n                shutil.copyfile(os.path.join(cache_dir, path), os.path.join(output_dir.path, path))\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n        # 5. Inform the worker the current file is ready to be removed\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Tuple[int, Union[str, Tuple[str, str]]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        index, path = r\n\n        # 4. Upload the file\n        if isinstance(path, tuple):\n            dirpath, path = path\n            shutil.copy(os.path.join(dirpath, path), path)\n        elif output_dir.scheme == \"s3\":\n            s3.client.upload_file(path, output_dir.netloc, path.replace(cache_dir, \"\"))\n        elif output_dir.scheme == \"file\":\n            if not path.startswith(output_dir.path):\n                path = os.path.join(output_dir.path, path)\n            shutil.copy(path, path)\n        else:\n            raise ValueError(f\"The provided {output_dir.scheme} isn't supported.\")\n\n        # 5. Inform the worker the current files are available\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Tuple[Union[str, Tuple[str, str]], ...]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        paths = r\n\n        # 4. Upload the files to the remote directory\n        for path in paths:\n            if isinstance(path, tuple):\n                dirpath, path = path\n                if output_dir.scheme == \"s3\":\n                    s3.client.upload_file(path, output_dir.netloc, path.replace(dirpath, \"\").lstrip(\"/\"))\n                elif output_dir.scheme == \"file\":\n                    shutil.copy(path, path.replace(dirpath, output_dir.path))\n            else:\n                if output_dir.scheme == \"s3\":\n                    s3.client.upload_file(path, output_dir.netloc, path.replace(cache_dir, \"\").lstrip(\"/\"))\n                elif output_dir.scheme == \"file\":\n                    shutil.copy(path, path.replace(cache_dir, output_dir.path))\n\n        # 5. Remove the files from the local cache\n        remove_queue.put(paths)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Tuple[int, List[str]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        index, paths = r\n\n        # 4. Upload the files to the remote directory\n        for path in paths:\n            if not path.startswith(cache_dir):\n                path = os.path.join(cache_dir, path)\n\n            if output_dir.scheme == \"file\":\n                shutil.move(path, os.path.join(output_dir.path, os.path.basename(path)))\n            elif output_dir.scheme == \"s3\":\n                s3.client.upload_file(path, output_dir.netloc, os.path.join(output_dir.path, os.path.basename(path)))\n            else:\n                raise ValueError(f\"The provided {output_dir.scheme} isn't supported.\")\n\n        # 5. Inform the worker the current files are ready to be removed\n        remove_queue.put(paths)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Tuple[int, Union[str, Tuple[str, str]]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        index, path = r\n\n        # 4. Upload the file\n        if isinstance(path, tuple):\n            dirpath, path = path\n            shutil.move(os.path.join(dirpath, path), os.path.join(cache_dir, path))\n        else:\n            if output_dir.url:\n                obj = parse.urlparse(path)\n                s3.client.upload_file(os.path.join(cache_dir, path), obj.netloc, obj.path.lstrip(\"/\"))\n            else:\n                shutil.move(os.path.join(cache_dir, path), os.path.join(output_dir.path, path))\n\n        # 5. Inform the worker the current file is uploaded\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Tuple[int, List[str]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        index, paths = r\n\n        # 4. Upload the files\n        for path in paths:\n            if not path.startswith(cache_dir):\n                path = os.path.join(cache_dir, path)\n\n            if output_dir.url:\n                obj = parse.urlparse(output_dir.url)\n\n                if obj.scheme == \"s3\":\n                    s3.client.upload_file(path, obj.netloc, obj.path.lstrip(\"/\"))\n                else:\n                    raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n            else:\n                shutil.copyfile(path, os.path.join(output_dir.path, os.path.basename(path)))\n\n        # 5. Inform the worker the current files are ready to be removed\n        remove_queue.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Tuple[int, Union[str, Tuple[str, str]]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        index, path = r\n\n        # 4. Upload the file\n        if isinstance(path, tuple):\n            path, local_path = path\n            shutil.copyfile(local_path, path)\n            os.remove(local_path)\n\n        if output_dir.url:\n            obj = parse.urlparse(path)\n            s3.client.upload_file(path, obj.netloc, obj.path.lstrip(\"/\"))\n\n        # 5. Inform the worker the current file is uploaded\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Union[str, Tuple[str, str]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Upload the data\n        if isinstance(r, str):\n            if output_dir.url:\n                obj = parse.urlparse(r.replace(cache_dir, output_dir.url))\n\n                s3.client.upload_file(r, obj.netloc, obj.path.lstrip(\"/\"))\n\n            else:\n                shutil.copyfile(r, r.replace(cache_dir, output_dir.path))\n\n        elif isinstance(r, tuple):\n            tmp_dir, r = r\n            if output_dir.url:\n                obj = parse.urlparse(r.replace(cache_dir, output_dir.url))\n\n                s3.client.upload_file(os.path.join(tmp_dir, r), obj.netloc, obj.path.lstrip(\"/\"))\n\n            else:\n                shutil.copyfile(os.path.join(tmp_dir, r), r.replace(cache_dir, output_dir.path))\n\n        # 4. Remove the data from the cache directory\n        remove_queue.put(r)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Tuple[int, Union[str, Tuple[str, str]]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        index, path = r\n\n        # 4. Check whether the file is already uploaded\n        if output_dir.path and os.path.exists(path):\n            remove_queue.put(path)\n            continue\n\n        if output_dir.url:\n            # 5. Wait for the removers to catch up when we are uploading data.\n            _wait_for_disk_usage_higher_than_threshold(\"/\", 25)\n\n            # 6. Upload the file to the remote location\n            if isinstance(path, str):\n                obj = parse.urlparse(path)\n            else:\n                obj = parse.urlparse(path[1])\n\n            if obj.scheme == \"s3\":\n                s3.client.upload_file(path[0] + \"/\" + path[1], obj.netloc, obj.path.lstrip(\"/\"))\n            else:\n                shutil.copyfile(path[0] + \"/\" + path[1], path[1])\n\n        # 7. Inform the worker the current file is available\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Union[str, Tuple[str, str]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        if isinstance(r, str):\n            path = r\n        else:\n            path = r[1]\n\n        # 4. Upload the file\n        if output_dir.url:\n            obj = parse.urlparse(path)\n            if obj.scheme == \"s3\":\n                s3.client.upload_file(path, obj.netloc, obj.path.lstrip(\"/\"))\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n        else:\n            shutil.move(path, output_dir.path)\n\n        # 5. Remove the file\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Tuple[int, Union[str, Tuple[str, str]]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        index, path = r\n\n        # 4. Check if the file is already uploaded\n        if output_dir.path and os.path.exists(path):\n            remove_queue.put(path)\n            continue\n\n        # 5. Upload the file\n        if output_dir.url:\n            # 5.1. Wait for the removers to catch up when we are downloading data.\n            _wait_for_disk_usage_higher_than_threshold(\"/\", 25)\n\n            # 5.2. Upload the file\n            obj = parse.urlparse(path)\n\n            if obj.scheme == \"s3\":\n                s3.client.upload_file(path, obj.netloc, obj.path.lstrip(\"/\"))\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n        # 6. Inform the worker the current file is ready to be removed\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Tuple[int, List[str]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        index, paths = r\n\n        # 4. Upload the files to the target directory\n        for path in paths:\n            if not path.startswith(cache_dir):\n                path = os.path.join(cache_dir, path)\n\n            if output_dir.url:\n                obj = parse.urlparse(path)\n\n                if obj.scheme == \"s3\":\n                    s3.client.upload_file(obj.path, obj.netloc, obj.path.lstrip(\"/\"))\n                elif obj.scheme == \"file\":\n                    shutil.copyfile(path, obj.path)\n                else:\n                    raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n            else:\n                shutil.copyfile(path, os.path.join(output_dir.path, os.path.basename(path)))\n\n        # 5. Send the paths to the remove queue\n        remove_queue.put(paths)\n\n        # 6. Inform the worker the current files are ready to be removed\n        upload_queue.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Tuple[int, Union[str, Tuple[str, str]]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        index, path = r\n\n        # 4. Upload the file\n        if isinstance(path, tuple):\n            tmp_dir, path = path\n            shutil.move(os.path.join(tmp_dir, path), path)\n            shutil.rmtree(tmp_dir)\n\n        if output_dir.url:\n            obj = parse.urlparse(path)\n            obj = obj._replace(netloc=output_dir.url)\n            path = parse.urlunparse(obj)\n\n        if output_dir.url:\n            s3.client.upload_file(path, obj.netloc, obj.path.lstrip(\"/\"))\n        else:\n            shutil.move(path, output_dir.path)\n\n        # 5. Inform the worker the current files are ready to be removed\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Union[str, Tuple[str, str]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            tmp_dir, path = r\n        else:\n            tmp_dir, path = \"\", r\n\n        # 4. Upload the data\n        if output_dir.url:\n            # 4.1. Upload the data to the remote directory\n            obj = parse.urlparse(path)\n\n            if obj.scheme == \"s3\":\n                s3.client.upload_file(os.path.join(tmp_dir, path), obj.netloc, obj.path.lstrip(\"/\"))\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n        else:\n            # 4.2. Move the data to the local directory\n            os.makedirs(output_dir.path, exist_ok=True)\n            shutil.move(os.path.join(tmp_dir, path), output_dir.path)\n\n        # 5. Send the file path to the remove queue\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Tuple[int, Union[str, Tuple[str, str]]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        index, data = r\n\n        # 4. Upload the data\n        if isinstance(data, str):\n            data = (cache_dir, data)\n\n        if isinstance(data, tuple):\n            tmp_dir, path = data\n            path = path.replace(tmp_dir, output_dir.path)\n\n            if output_dir.url is None:\n                os.makedirs(os.path.dirname(path), exist_ok=True)\n                shutil.copyfile(tmp_dir, path)\n            else:\n                obj = parse.urlparse(path)\n                s3.client.upload_file(os.path.join(tmp_dir, obj.path.lstrip(\"/\")), obj.netloc, obj.path.lstrip(\"/\"))\n\n        # 5. Remove the data\n        remove_queue.put(data)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Tuple[Union[str, Tuple[str, str]], bool]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        path, is_temp_dir = r\n\n        if is_temp_dir:\n            # 4. If the path is a tuple, it means that it is a temporary directory that needs to be zipped.\n            temp_dir, path = path\n            _pack_greedily(path, temp_dir, output_dir.path)\n            shutil.rmtree(temp_dir)\n\n        # 5. Upload the file\n        if output_dir.url:\n            # 6. Upload to S3\n            obj = parse.urlparse(path)\n            s3.client.upload_file(obj.path, obj.netloc, obj.path.lstrip(\"/\"))\n\n        elif output_dir.path:\n            # 7. Move to the output directory\n            shutil.move(path, output_dir.path)\n\n        # 8. Inform the worker that the file is ready to be removed.\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Associate the items to the workers based on number of nodes and node rank.\n    weights = [1] * len(user_items) if weights is None else weights\n    world_size = num_nodes * num_workers\n\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    # Print the distribution details for workers on the current node.\n    for worker_id in worker_ids_this_node:\n        if file_size:\n            print(\n                f\"Worker {worker_id} (node {worker_id // num_workers}): {sum(worker_weights[worker_id]):.2f} MB\"\n            )\n        else:\n            print(f\"Worker {worker_id} (node {worker_id // num_workers}): {sum(worker_weights[worker_id])} items\")\n\n    # Shuffle the items for each worker.\n    result = [[] for _ in range(num_workers)]\n    for worker_id in worker_ids_this_node:\n        for item, weight in zip(worker_items[worker_id], worker_weights[worker_id]):\n            result[worker_id].append(item)\n\n    return result\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Associate the items to the workers based on number of nodes and node rank.\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    # Print the distribution details for workers on the current node.\n    print(\"Worker weights on this node:\")\n    for worker_id, worker_weight in zip(worker_ids_this_node, worker_weights):\n        print(f\"\\tWorker {worker_id}: {worker_weight} items\")\n\n    if file_size:\n        total_size = sum(worker_weights)\n        print(f\"Total size: {total_size / 1000000} MB\")\n    else:\n        print(f\"Total weight: {sum(worker_weights)}\")\n\n    # Shuffle the items for each worker.\n    worker_items = [random.sample(items, len(items)) for items in worker_items]\n\n    # Return a list of items for each worker.\n    return [worker_items[i] for i in worker_ids_this_node]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Calculate the total number of workers across all nodes.\n    world_size = num_nodes * num_workers\n\n    # Distribute items to workers.\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n\n    # Print the distribution details for workers on the current node.\n    for worker_id in range(num_workers):\n        print(f\"Worker {worker_id} on node {node_rank}: {worker_items[worker_id]} with total size {worker_weights[worker_id] / 1e6} MB\")\n\n    # Return a list of items for each worker, with the items shuffled.\n    return [worker_items[i] for i in worker_ids_this_node]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Associate the items to the workers based on number of nodes and node rank.\n    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    world_size = num_nodes * num_workers\n\n    # Distribute items to workers based on weights.\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    # Print the distribution details for workers on the current node.\n    if node_rank == 0:\n        print(\"Distribution of items to workers:\")\n        for worker_id in range(world_size):\n            if worker_id in worker_ids_this_node:\n                print(\n                    f\"Worker {worker_id} (this node): \"\n                    f\"{worker_weights[worker_id] if file_size else len(worker_items[worker_id])} files or {worker_weights[worker_id] / 1e6} MB\"\n                )\n            else:\n                print(\n                    f\"Worker {worker_id}: \"\n                    f\"{worker_weights[worker_id] if file_size else len(worker_items[worker_id])} files or {worker_weights[worker_id] / 1e6} MB\"\n                )\n\n    # Return a list of items for each worker, with the items shuffled.\n    return [worker_items[worker_id] for worker_id in worker_ids_this_node]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    if len(user_items) != len(weights):\n        raise ValueError(\"Number of items and weights must be equal.\")\n\n    # Associate the items to the workers based on number of nodes and node rank.\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    # Print the distribution details for workers on the current node.\n    if file_size:\n        sizes = [os.path.getsize(item) / 1024 / 1024 for item in worker_items]\n        for worker_id in worker_ids_this_node:\n            print(\n                f\"Worker {worker_id} on node {node_rank}: {len(worker_items[worker_id])} files, \"\n                f\"{sum(sizes[worker_id]):.2f} MB in total.\"\n            )\n    else:\n        for worker_id in worker_ids_this_node:\n            print(\n                f\"Worker {worker_id} on node {node_rank}: {len(worker_items[worker_id])} files, \"\n                f\"{sum(worker_weights[worker_id]):.2f} MB in total.\"\n            )\n\n    # Return a list of items for each worker, with the items shuffled.\n    return [worker_items[worker_id] for worker_id in worker_ids_this_node]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Associate the items to the workers based on number of nodes and node rank.\n    world_size = num_nodes * num_workers\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    # Print the distribution details for workers on the current node.\n    for worker_id in worker_ids_this_node:\n        print(\n            f\"Worker {worker_id} on node {node_rank} has {len(worker_items[worker_id])} items \"\n            f\"with total {'size' if file_size else 'weight'} \"\n            f\"of {sum(worker_weights[worker_id]) / 1e6 if file_size else sum(worker_weights[worker_id])} MB.\"\n            if file_size\n            else f\"of {sum(worker_weights[worker_id])}.\"\n        )\n\n    # Shuffle the items for each worker.\n    for worker_id in worker_ids_this_node:\n        random.shuffle(worker_items[worker_id])\n\n    return [worker_items[worker_id] for worker_id in worker_ids_this_node]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    if len(user_items) != len(weights):\n        raise ValueError(\"The number of items does not match the number of weights.\")\n\n    if num_workers > len(user_items):\n        raise ValueError(\"The number of workers is greater than the number of items.\")\n\n    # Associate the items to the workers based on number of nodes and node rank.\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    # Print the distribution details for workers on the current node.\n    for worker_id in worker_ids_this_node:\n        if file_size:\n            print(\n                f\"Worker {worker_id} has {worker_weights[worker_id] / 1000 / 1000:.2f} MB of data.\"\n            )\n        else:\n            print(f\"Worker {worker_id} has {worker_weights[worker_id]} items.\")\n\n    # Return a list of items for each worker, with the items shuffled.\n    return [worker_items[i] for i in worker_ids_this_node]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    if len(user_items) != len(weights):\n        raise ValueError(\n            f\"Number of items ({len(user_items)}) does not match number of weights ({len(weights)}).\"\n        )\n\n    if len(user_items) < world_size:\n        raise ValueError(\n            f\"Number of items ({len(user_items)}) is less than the total number of workers ({world_size}).\"\n        )\n\n    if len(user_items) < num_workers:\n        raise ValueError(\n            f\"Number of items ({len(user_items)}) is less than the number of workers per node ({num_workers}).\"\n        )\n\n    if weights is not None and len(weights) != len(user_items):\n        raise ValueError(\n            f\"Number of weights ({len(weights)}) does not match number of items ({len(user_items)}).\"\n        )\n\n    if weights is not None and any(w < 0 for w in weights):\n        raise ValueError(f\"Weights ({weights}) contain negative values.\")\n\n    if weights is None:\n        weights = [1] * len(user_items)\n\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n\n    # Print the distribution details for workers on the current node\n    for worker_id in worker_ids_this_node:\n        items_this_worker = worker_items[worker_id]\n        weights_this_worker = worker_weights[worker_id]\n        total_weight = sum(weights_this_worker)\n        if file_size:\n            total_size = sum(os.path.getsize(item) for item in items_this_worker) / 1e6\n            print(f\"Worker {worker_id} has {len(items_this_worker)} files with total size {total_size} MB.\")\n        else:\n            print(f\"Worker {worker_id} has {len(items_this_worker)} items with total weight {total_weight}."}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    if len(user_items) != len(weights):\n        raise RuntimeError(\"The number of items and weights provided do not match.\")\n\n    # Distribute items to workers.\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n\n    # Print the distribution details.\n    for worker_id, (worker_item, worker_weight) in enumerate(zip(worker_items, worker_weights)):\n        if worker_id in worker_ids_this_node:\n            if file_size:\n                print(\n                    f\"Worker {worker_id}: {len(worker_item)} items, {sum(worker_weight) / 1e6} MB\"\n                )\n            else:\n                print(f\"Worker {worker_id}: {len(worker_item)} items, {sum(worker_weight)} weight\")\n\n    # Shuffle the items for each worker.\n    for worker_id, worker_item in enumerate(worker_items):\n        if worker_id in worker_ids_this_node:\n            random.shuffle(worker_item)\n\n    return [worker_item for worker_id, worker_item in enumerate(worker_items) if worker_id in worker_ids_this_node]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    if len(weights) != len(user_items):\n        raise ValueError(\"The number of weights must match the number of items.\")\n\n    if len(user_items) < world_size:\n        raise ValueError(\"The number of items must be greater than the number of workers.\")\n\n    if weights is not None:\n        if not all(w >= 0 for w in weights):\n            raise ValueError(\"All weights must be non-negative.\")\n\n    if not isinstance(file_size, bool):\n        raise TypeError(\"The parameter file_size must be a boolean.\")\n\n    # Associate the items to the workers based on number of nodes and node rank.\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    # Print the distribution details for workers on the current node.\n    if file_size:\n        for worker_id in worker_ids_this_node:\n            print(\n                \"Worker {:02d} on node {:02d} has {:.2f} MB.\".format(\n                    worker_id, node_rank, sum(worker_weights[worker_id]) / 1000000\n                )\n            )\n    else:\n        for worker_id in worker_ids_this_node:\n            print(\"Worker {:02d} on node {:02d} has {:.2f} weight.\".format(worker_id, node_rank, sum(worker_weights[worker_id])))\n\n    # Shuffle the items for each worker.\n    worker_items_shuffled = [\n        [worker_items[worker_id][i] for i in np.random.permutation(len(worker_items[worker_id]))]\n        for worker_id in worker_ids_this_node\n    ]\n\n    return worker_items_shuffled\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Calculate the number of workers across all nodes.\n    world_size = num_nodes * num_workers\n\n    # Distribute items to workers.\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n\n    # Print the distribution details for workers on the current node.\n    print(\n        f\"Worker weights on node {node_rank} (total: {len(user_items)}): \"\n        f\"{[f'{w:.2f}' for w in worker_weights]}\"\n    )\n\n    if file_size:\n        print(\n            f\"Worker file sizes on node {node_rank} (total: {len(user_items)}): \"\n            f\"{[f'{os.path.getsize(item) / 1024**2:.2f}' for item in worker_items]}\"\n        )\n    else:\n        print(\n            f\"Worker weights on node {node_rank} (total: {len(user_items)}): \"\n            f\"{worker_weights}\"\n        )\n\n    # Return a list of items for each worker, with the items shuffled.\n    return [worker_items[i] for i in worker_ids_this_node]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    if weights is None:\n        weights = [1] * len(user_items)\n\n    # Calculate the total number of workers across all nodes.\n    world_size = num_nodes * num_workers\n\n    # Distribute items to workers based on weights.\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n\n    # Print the distribution details for workers on the current node.\n    for worker_id, worker_items in enumerate(worker_items):\n        if file_size:\n            total_size = sum(worker_items) / 1000000\n            print(f\"Worker {worker_id} has {len(worker_items)} files totalling {total_size:.2f} MB.\")\n        else:\n            total_weight = sum(worker_items)\n            print(f\"Worker {worker_id} has {len(worker_items)} items with a total weight of {total_weight}.\")\n\n    # Return a list of items for each worker, with the items shuffled.\n    return [worker_items[worker_id] for worker_id in worker_ids_this_node]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    if len(user_items) != len(weights):\n        raise ValueError(\n            f\"The number of items ({len(user_items)}) does not match the number of weights ({len(weights)})\"\n        )\n\n    if weights is not None and not all(w >= 0 for w in weights):\n        raise ValueError(f\"The weights must be non-negative.\")\n\n    if weights is not None and len(weights) != len(user_items):\n        raise ValueError(\n            f\"The number of weights ({len(weights)}) does not match the number of items ({len(user_items)})\"\n        )\n\n    if num_workers <= 0:\n        raise ValueError(f\"The number of workers must be positive.\")\n\n    if num_nodes <= 0:\n        raise ValueError(f\"The number of nodes must be positive.\")\n\n    if num_workers > world_size:\n        raise ValueError(\n            f\"The number of workers per node ({num_workers}) is greater than the total number of workers ({world_size})\"\n        )\n\n    if node_rank < 0:\n        raise ValueError(f\"The node rank must be non-negative.\")\n\n    if node_rank >= num_nodes:\n        raise ValueError(f\"The node rank ({node_rank}) is greater than the number of nodes ({num_nodes})\")\n\n    # Associate the items to the workers based on number of nodes and node rank.\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    # Print the distribution details for workers on the current node.\n    for worker_id, (items, weights) in zip(worker_ids_this_node, zip(*worker_items)):\n        if file_size:\n            total_size = sum(weights)\n            print(\n                f\"Worker {worker_id} is handling {len(items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    if weights is None:\n        weights = [1] * len(user_items)\n    if len(user_items) != len(weights):\n        raise ValueError(\"The number of items and weights should be equal.\")\n\n    # Calculate the number of workers across all nodes.\n    world_size = num_nodes * num_workers\n\n    # Pack the items into the number of bins (workers) using a greedy algorithm.\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n\n    # Print the distribution details for workers on the current node.\n    for worker_id in range(num_workers):\n        if file_size:\n            print(\n                f\"Worker {worker_id} on node {node_rank} has {worker_weights[worker_id] / 1e6} MBs of data.\"\n            )\n        else:\n            print(f\"Worker {worker_id} on node {node_rank} has {worker_weights[worker_id]} items.\")\n\n    # Shuffle the items for each worker.\n    worker_items_shuffled = [\n        random.sample(worker_items[worker_id], len(worker_items[worker_id]))\n        for worker_id in worker_ids_this_node\n    ]\n\n    return worker_items_shuffled\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # If weights are not provided, all items are considered to have equal weight.\n    if weights is None:\n        weights = [1] * len(user_items)\n\n    # Calculate the total number of workers across all nodes.\n    world_size = num_nodes * num_workers\n\n    # Distribute items to workers based on weights.\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n\n    # Print the distribution details for workers on the current node.\n    if file_size:\n        # Convert the sizes to megabytes for printing.\n        sizes = [os.path.getsize(item) / 1e6 for item in worker_items]\n        print(\n            f\"Node {node_rank} (rank {node_rank * num_workers} - {(node_rank + 1) * num_workers - 1}) \"\n            f\"has {len(worker_items)} files totalling {sum(sizes):.2f} MB, distributed as follows: \"\n        )\n        for worker_id, worker_size in zip(worker_ids_this_node, worker_weights):\n            print(f\"\\tWorker {worker_id} (rank {worker_id}) has {worker_size:.2f} MB\")\n    else:\n        print(\n            f\"Node {node_rank} (rank {node_rank * num_workers} - {(node_rank + 1) * num_workers - 1}) \"\n            f\"has {len(worker_items)} files, distributed as follows: \"\n        )\n        for worker_id, worker_size in zip(worker_ids_this_node, worker_weights):\n            print(f\"\\tWorker {worker_id} (rank {worker_id}) has {worker_size} files\")\n\n    # Shuffle the items for each worker.\n    worker_items = [\n        [worker_items[i] for i in np.random.permutation(range(len(worker_items)))] for worker_items in worker"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    if weights is None:\n        weights = [1] * len(user_items)\n\n    if len(user_items) != len(weights):\n        raise ValueError(\"The number of items and weights should be equal.\")\n\n    if len(user_items) < world_size:\n        raise ValueError(\n            f\"The number of items ({len(user_items)}) is less than the number of workers ({world_size}).\"\n        )\n\n    if len(weights) != len(user_items):\n        raise ValueError(\"The number of weights should be equal to the number of items.\")\n\n    if any(w < 0 for w in weights):\n        raise ValueError(\"All weights should be non-negative.\")\n\n    # The number of workers across all nodes.\n    world_size = num_nodes * num_workers\n\n    # Distribute items to workers based on weights.\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n\n    # Print the distribution details for workers on the current node.\n    if file_size:\n        sizes = [os.path.getsize(item) for item in worker_items]\n        size_str = \"MB\"\n    else:\n        sizes = worker_weights\n        size_str = \"\"\n\n    for worker_id in worker_ids_this_node:\n        print(\n            f\"Worker {worker_id} on node {node_rank} has {len(worker_items[worker_id])} items with a total size of {sum(sizes[worker_id]) / 1e6} {size_str}.\"\n        )\n\n    # Return a list of items for each worker, shuffled.\n    return [worker_items[worker_id] for worker_id in worker_ids_this_node]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    if len(user_items) != len(weights):\n        raise ValueError(\"The number of items does not match the number of weights.\")\n\n    if not all(w >= 0 for w in weights):\n        raise ValueError(\"All weights must be non-negative.\")\n\n    if not user_items:\n        raise ValueError(\"No items to distribute.\")\n\n    if num_workers <= 0:\n        raise ValueError(\"Number of workers must be positive.\")\n\n    if world_size < num_workers:\n        raise ValueError(\"Number of workers must be smaller than the number of nodes.\")\n\n    if node_rank < 0 or node_rank >= num_nodes:\n        raise ValueError(\"Node rank must be between 0 and the number of nodes.\")\n\n    if not all(i >= 0 for i in worker_ids_this_node):\n        raise ValueError(\"Worker IDs must be non-negative.\")\n\n    if len(worker_ids_this_node) != num_workers:\n        raise ValueError(\"Number of worker IDs does not match the number of workers.\")\n\n    # Calculate the total number of workers across all nodes.\n    total_workers = num_nodes * num_workers\n\n    # Distribute the items to the workers based on weights.\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=total_workers)\n\n    # Print the distribution details.\n    _print_distribution_details(\n        num_workers=num_workers,\n        worker_ids=worker_ids_this_node,\n        worker_items=worker_items,\n        worker_weights=worker_weights,\n        file_size=file_size,\n    )\n\n    # Shuffle the items for each worker.\n    worker_items_shuffled = [random.sample(worker_items[i], len(worker_items[i])) for i in worker_ids_this_node]\n\n    return worker_items_shuffled\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Calculate the total number of workers across all nodes\n    world_size = num_nodes * num_workers\n\n    # Distribute items to workers based on provided weights\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n\n    # Print the distribution details for workers on the current node\n    print(f\"Distributing {len(user_items)} items to {num_workers} workers on node {node_rank}...\")\n    for i in range(num_workers):\n        print(\n            f\"Worker {i} on node {node_rank} will have {len(worker_items[i])} items with total \"\n            f\"size {'%.2f' % (sum(worker_weights[i]) / 1e6 if file_size else sum(worker_weights[i]))} \"\n            f\"{('MB' if file_size else 'weight')}s.\"\n        )\n\n    # Return a list of items for each worker, with the items shuffled\n    return [worker_items[i] for i in worker_ids_this_node]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    if len(user_items) != len(weights):\n        raise ValueError(f\"The number of items ({len(user_items)}) does not match the number of weights ({len(weights)}).\")\n\n    # Associate the items to the workers based on number of nodes and node rank.\n    world_size = num_nodes * num_workers\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    # Print the distribution details for workers on the current node.\n    print(\"Distribution details for workers on the current node:\")\n    for worker_id in worker_ids_this_node:\n        print(f\"Worker {worker_id}:\\t{worker_weights[worker_id] / 1000000 if file_size else sum(worker_weights[worker_id])} MB.\")\n\n    # Shuffle the items for each worker.\n    worker_items = [list(x) for x in np.array_split(worker_items, num_workers)]\n    for worker_id in worker_ids_this_node:\n        random.shuffle(worker_items[worker_id - node_rank * num_workers])\n\n    return worker_items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Calculate the total number of workers across all nodes\n    world_size = num_nodes * num_workers\n\n    # Distribute items to workers\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n\n    # Print the distribution details for workers on the current node\n    for worker_id in worker_ids_this_node:\n        if file_size:\n            total_size = sum(worker_items[worker_id]) / 1e6\n            print(f\"Worker {worker_id} has a total size of {total_size} MB.\")\n        else:\n            print(f\"Worker {worker_id} has a total weight of {worker_weights[worker_id]}.\")\n\n    # Shuffle the items for each worker\n    random.shuffle(worker_items)\n\n    return [worker_items[i] for i in worker_ids_this_node]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # Get the total number of workers across all nodes\n    num_workers_total = num_workers * _get_num_nodes()\n\n    # Get the number of items each worker should process\n    num_items_per_worker = len(user_items) // num_workers_total\n\n    # Get the number of items that will be distributed to the last workers\n    num_remaining_items = len(user_items) % num_workers_total\n\n    # Get the number of workers that will process extra items\n    num_extra_workers = num_remaining_items // num_workers\n\n    # Get the number of workers that will process the remaining items\n    num_remaining_workers = num_remaining_items % num_workers\n\n    # Get the number of workers that will process the remaining items\n    num_remaining_workers = num_remaining_items % num_workers\n\n    # Get the number of workers that will process the remaining items\n    num_remaining_workers = num_remaining_items % num_workers\n\n    # Get the number of workers that will process the remaining items\n    num_remaining_workers = num_remaining_items % num_workers\n\n    # Get the number of workers that will process the remaining items\n    num_remaining_workers = num_remaining_items % num_workers\n\n    # Get the number of workers that will process the remaining items\n    num_remaining_workers = num_remaining_items % num_workers\n\n    # Get the number of workers that will process the remaining items\n    num_remaining_workers = num_remaining_items % num_workers\n\n    # Get the number of workers that will process the remaining items\n    num_remaining_workers = num_remaining_items % num_workers\n\n    # Get the number of workers that will process the remaining items\n    num_remaining_workers = num_remaining_items % num_workers\n\n    # Get the number of workers that will process the remaining items\n    num_remaining_workers = num_remaining_items % num"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # Get the number of nodes and the current node's rank\n    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n\n    # Calculate the total number of workers across all nodes\n    num_workers_total = num_nodes * num_workers\n\n    # Calculate the number of items each worker should process\n    num_items_per_worker = len(user_items) // num_workers_total\n\n    # Adjust for any remainder by adding extra items to the workers starting from the end of the list\n    remainder = len(user_items) % num_workers_total\n    if node_rank < remainder:\n        num_items_per_worker += 1\n\n    # Calculate the start and end indices for each worker's items\n    start_indices = np.cumsum([0] + [num_items_per_worker] * (num_workers - 1))\n    end_indices = np.cumsum([num_items_per_worker] * num_workers)\n\n    # Ensure the output list has a length equal to the number of workers\n    if len(start_indices) != num_workers:\n        raise RuntimeError(f\"Improper assignment of items to workers.\")\n\n    # Return a list of lists, where each sublist contains the items assigned to a worker\n    return [user_items[start:end] for start, end in zip(start_indices, end_indices)]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # Calculate the total number of workers across all nodes\n    num_workers_across_all_nodes = num_workers * _get_num_nodes()\n\n    # Calculate the number of items each worker should process\n    num_items_per_worker = len(user_items) // num_workers_across_all_nodes\n\n    # Calculate the number of workers that will process one extra item\n    num_workers_with_extra_item = len(user_items) % num_workers_across_all_nodes\n\n    # Calculate the start and end indices for each worker's items\n    cumsum = np.cumsum([num_items_per_worker + (1 if i < num_workers_with_extra_item else 0) for i in range(num_workers_across_all_nodes)])\n    start_indices = np.concatenate([[0], cumsum[:-1]])\n    end_indices = cumsum\n\n    # Assign items to workers sequentially\n    return [user_items[start:end] for start, end in zip(start_indices, end_indices)]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # Get the total number of nodes\n    num_nodes = _get_num_nodes()\n\n    # Get the number of workers per node\n    num_workers_per_node = num_workers\n\n    # Calculate the total number of workers across all nodes\n    num_workers = num_workers * num_nodes\n\n    # Calculate the number of items each worker should process\n    num_items_per_worker = int(np.ceil(len(user_items) / num_workers))\n\n    # Calculate the number of items each worker should process\n    num_items_per_worker = int(np.ceil(len(user_items) / num_workers))\n\n    # Calculate the number of items that will be distributed to the last worker\n    remainder = len(user_items) % num_workers\n\n    # Calculate the number of items that will be distributed to the last worker\n    remainder = len(user_items) % num_workers\n\n    # Calculate the number of items that will be distributed to the last worker\n    remainder = len(user_items) % num_workers\n\n    # Calculate the number of items that will be distributed to the last worker\n    remainder = len(user_items) % num_workers\n\n    # Calculate the number of items that will be distributed to the last worker\n    remainder = len(user_items) % num_workers\n\n    # Calculate the number of items that will be distributed to the last worker\n    remainder = len(user_items) % num_workers\n\n    # Calculate the number of items that will be distributed to the last worker\n    remainder = len(user_items) % num_workers\n\n    # Calculate the number of items that will be distributed to the last worker\n    remainder = len(user_items) % num_workers\n\n    # Calculate the number of items that will be distributed to the last worker\n    remainder = len(user_items) % num_workers\n\n    # Calculate the number of items that will be distributed to the last worker\n    remainder = len(user_items) % num_workers\n\n    # Calculate the number"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # Get the total number of workers\n    total_num_workers = num_workers * _get_num_nodes()\n\n    # Calculate the number of items each worker should process\n    num_items_per_worker = int(np.ceil(len(user_items) / total_num_workers))\n\n    # Calculate the number of items that will be assigned to the last worker\n    remainder = len(user_items) % total_num_workers\n\n    # Calculate the start and end indices for each worker's items\n    start_indices = np.cumsum([0] + [num_items_per_worker] * (total_num_workers - remainder - 1) + [num_items_per_worker + remainder])\n    end_indices = np.cumsum([num_items_per_worker] * (total_num_workers - remainder) + [len(user_items)])\n\n    # Ensure the number of items is correct\n    if len(start_indices) != len(end_indices):\n        raise RuntimeError(\"Improper assignment of items to workers.\")\n\n    # Assign items to workers\n    return [user_items[start_indices[i]:end_indices[i]] for i in range(len(start_indices))]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # Calculate the total number of workers across all nodes\n    total_num_workers = num_workers * _get_num_nodes()\n\n    # Calculate the number of items each worker should process\n    num_items = len(user_items)\n    num_items_per_worker = num_items // total_num_workers\n    remainder = num_items % total_num_workers\n\n    # Adjust for any remainder by adding extra items to the workers starting from the end of the list\n    if remainder:\n        num_items_per_worker += 1\n        remainder = num_items % total_num_workers\n\n    # Get the start and end indices for each worker's items\n    start_indices = np.cumsum([0] + [num_items_per_worker] * (total_num_workers - 1))\n    end_indices = np.cumsum([num_items_per_worker] * total_num_workers)\n\n    # Ensure that the output list has a length equal to the number of workers\n    if len(start_indices) != total_num_workers or len(end_indices) != total_num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers.\")\n\n    # Get the start and end indices for the current worker's items\n    start_index = start_indices[_get_node_rank()]\n    end_index = end_indices[_get_node_rank()]\n\n    # Return a list of items assigned to the current worker\n    return [user_items[start_index:end_index]]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # Calculate the total number of workers across all nodes\n    num_workers_total = num_workers * _get_num_nodes()\n\n    # Calculate the number of items each worker should process\n    num_items_per_worker = len(user_items) // num_workers_total\n\n    # Calculate the number of workers that need to process one extra item\n    num_workers_extra = len(user_items) % num_workers_total\n\n    # Calculate the number of items each worker should process\n    num_items_per_worker = [num_items_per_worker for _ in range(num_workers)]\n\n    # Add extra items to the workers starting from the end of the list\n    for i in range(num_workers_extra):\n        num_items_per_worker[num_workers - i - 1] += 1\n\n    # Calculate the start and end indices for each worker's items\n    indices = np.cumsum(num_items_per_worker)\n    start_indices = [0] + list(indices[:-1])\n    end_indices = list(indices)\n\n    # Distribute the items among the workers\n    return [user_items[start_indices[i] : end_indices[i]] for i in range(num_workers)]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n\n    # Calculate the total number of workers across all nodes.\n    total_workers = num_workers * num_nodes\n\n    # Calculate the number of items each worker should process.\n    num_items = len(user_items)\n    num_items_per_worker = num_items // total_workers\n    remainder = num_items % total_workers\n\n    # Adjust for any remainder by adding extra items to the workers starting from the end of the list, ensuring an even distribution as much as possible.\n    if remainder != 0:\n        num_items_per_worker += 1\n        remainder -= 1\n\n    # Calculate the start and end indices for each worker's items.\n    cumsum = np.cumsum(np.append([0], [num_items_per_worker] * (total_workers - remainder)))\n    start_indices = cumsum[:-1]\n    end_indices = cumsum[1:]\n\n    # Assign the items to the workers.\n    worker_items = [user_items[start:end] for start, end in zip(start_indices, end_indices)]\n\n    # Ensure the output list has a length equal to the number of workers; otherwise, raise a RuntimeError indicating improper assignment.\n    if len(worker_items) != num_workers:\n        raise RuntimeError(\n            f\"The number of workers ({num_workers}) does not match the number of worker items ({len(worker_items)}).\"\n        )\n\n    return worker_items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # Get the number of nodes and the current node's rank\n    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n\n    # Calculate the total number of workers across all nodes\n    total_workers = num_nodes * num_workers\n\n    # Calculate the number of items each worker should process\n    num_items_per_worker = int(np.ceil(len(user_items) / total_workers))\n\n    # Calculate the number of items that should be added to the last workers\n    remainder = len(user_items) - num_items_per_worker * total_workers\n\n    # Calculate the start and end indices for each worker's items\n    start_indices = np.cumsum(np.append([0], num_items_per_worker * np.ones(total_workers)))\n    end_indices = np.cumsum(np.append(num_items_per_worker * np.ones(total_workers), [len(user_items)]))\n\n    # Add extra items to the last workers in the list\n    if remainder > 0:\n        start_indices[-remainder:] = start_indices[-remainder - num_nodes]\n        end_indices[-remainder:] = end_indices[-remainder - num_nodes] + remainder\n\n    # Ensure that the output list has a length equal to the number of workers\n    if len(start_indices) != total_workers:\n        raise RuntimeError(\"Improper assignment of items to workers.\")\n\n    # Distribute the items among the workers\n    return [user_items[start_indices[i] : end_indices[i]] for i in range(total_workers)]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # Get the total number of workers across all nodes\n    num_workers_total = _get_num_nodes() * num_workers\n\n    # Get the number of items each worker should process\n    num_items_per_worker = len(user_items) // num_workers_total\n\n    # Get the number of workers that should process one additional item\n    num_workers_with_extra_item = len(user_items) % num_workers_total\n\n    # Get the current node's rank\n    node_rank = _get_node_rank()\n\n    # Get the number of workers in the current node\n    num_workers_in_current_node = num_workers\n\n    # Get the number of workers in the current node that should process one additional item\n    num_workers_in_current_node_with_extra_item = min(num_workers_with_extra_item, num_workers)\n\n    # Get the number of workers in the current node that should process one less item\n    num_workers_in_current_node_without_extra_item = num_workers - num_workers_in_current_node_with_extra_item\n\n    # Get the number of items each worker in the current node should process\n    num_items_per_worker_in_current_node = num_items_per_worker + (\n        num_workers_in_current_node_with_extra_item > 0\n    )\n\n    # Get the start index for the current worker in the current node\n    start_index_in_current_node = (num_items_per_worker_in_current_node * node_rank) + (\n        num_workers_in_current_node_without_extra_item * node_rank\n    )\n\n    # Get the end index for the current worker in the current node\n    end_index_in_current_node = start_index_in_current_node + num_items_per_worker_in_current_node\n\n    # Get the start index for the current worker in the entire environment\n    start_index_in_entire_environment ="}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # Get the total number of workers across all nodes\n    total_num_workers = num_workers * _get_num_nodes()\n\n    # Calculate the number of items each worker should process\n    num_items_per_worker = int(np.ceil(len(user_items) / total_num_workers))\n\n    # Calculate the number of workers that will have to process one more item\n    num_workers_extra_item = len(user_items) % total_num_workers\n\n    # Calculate the number of items that each worker should process\n    num_items_per_worker = [num_items_per_worker for _ in range(total_num_workers)]\n\n    # Add an extra item to the last num_workers_extra_item workers\n    for i in range(num_workers_extra_item):\n        num_items_per_worker[total_num_workers - i - 1] += 1\n\n    # Calculate the start and end indices for each worker's items\n    start_indices = np.cumsum(num_items_per_worker) - num_items_per_worker[0]\n    end_indices = np.cumsum(num_items_per_worker)\n\n    # Create a list of lists, where each sublist contains the items assigned to a worker\n    # This ensures each worker knows which items they are responsible for processing\n    worker_items = [user_items[start:end] for start, end in zip(start_indices, end_indices)]\n\n    # Ensure that the output list has a length equal to the number of workers; otherwise, raise a RuntimeError indicating improper assignment\n    if len(worker_items) != total_num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers.\")\n\n    return worker_items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # 1. Get the total number of workers across all nodes\n    total_num_workers = num_workers * _get_num_nodes()\n\n    # 2. Calculate the number of items each worker should process\n    num_items_per_worker = len(user_items) // total_num_workers\n\n    # 3. Calculate the number of workers that will receive an extra item\n    num_extra_workers = len(user_items) % total_num_workers\n\n    # 4. Get the current node rank\n    node_rank = _get_node_rank()\n\n    # 5. Calculate the number of workers on the current node\n    num_workers_on_current_node = num_workers * (node_rank + 1)\n\n    # 6. Calculate the number of items each worker on the current node should process\n    num_items_per_worker_on_current_node = num_items_per_worker + (num_extra_workers if num_extra_workers else 0) // num_workers\n\n    # 7. Calculate the number of items each worker should process\n    num_items_per_worker_on_current_node = num_items_per_worker_on_current_node // num_workers_on_current_node\n\n    # 8. Calculate the number of items each worker should process\n    num_items_per_worker_on_current_node = num_items_per_worker_on_current_node // num_workers_on_current_node\n\n    # 9. Calculate the start and end indices for each worker's items\n    cumsum_items = np.cumsum(num_items_per_worker)\n    start_indices = np.append(0, cumsum_items[:-1])\n    end_indices = cumsum_items\n\n    # 10. Calculate the start and end indices for each worker on the current node's items\n    cumsum_items_on_current_node = np.cumsum(num_items_per_worker_on_current_node)"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # Get the total number of workers across all nodes\n    total_workers = num_workers * _get_num_nodes()\n\n    # Calculate the number of items each worker should process\n    worker_items = len(user_items) // total_workers\n\n    # Calculate the remainder\n    remainder = len(user_items) - worker_items * total_workers\n\n    # Create a list of indices for the start and end positions of the items each worker should process\n    indices = np.cumsum([worker_items + 1 if i < remainder else worker_items for i in range(total_workers)])\n\n    # Create a list of lists, where each sublist contains the items assigned to a worker\n    items_per_worker = [user_items[indices[i] : indices[i + 1]] for i in range(total_workers)]\n\n    # Ensure that the output list has a length equal to the number of workers; otherwise, raise an error\n    if len(items_per_worker) != total_workers:\n        raise RuntimeError(\n            f\"Improper assignment of items to workers. Total number of workers: {total_workers}, number of items: {len(user_items)}, number of workers with items: {len(items_per_worker)}\"\n        )\n\n    return items_per_worker\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # Get the total number of workers across all nodes.\n    total_num_workers = _get_num_nodes() * num_workers\n\n    # Calculate the number of items each worker should process.\n    num_items_per_worker = len(user_items) // total_num_workers\n\n    # Calculate the number of items that will be distributed to the last workers in the list.\n    num_remainder_items = len(user_items) % total_num_workers\n\n    # Calculate the indices for the items that each worker should process.\n    worker_indices = np.cumsum(\n        np.append(np.repeat(num_items_per_worker, total_num_workers - num_remainder_items), num_remainder_items)\n    )\n\n    # Calculate the indices for the items that each worker should process.\n    start_indices = worker_indices[:-1]\n    end_indices = worker_indices[1:]\n\n    # Distribute the items to the workers sequentially.\n    distributed_items = [\n        user_items[start:end] for start, end in zip(start_indices, end_indices)\n    ]\n\n    # Ensure the number of distributed items is equal to the number of workers.\n    if len(distributed_items) != total_num_workers:\n        raise RuntimeError(\"Improper distribution of items among workers.\")\n\n    return distributed_items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # Get the total number of nodes\n    num_nodes = _get_num_nodes()\n\n    # Get the current node's rank\n    node_rank = _get_node_rank()\n\n    # Get the total number of workers\n    total_workers = num_workers * num_nodes\n\n    # Get the number of items per worker\n    num_items_per_worker = int(np.ceil(len(user_items) / total_workers))\n\n    # Get the number of items that will be distributed to workers\n    num_items_to_distribute = num_items_per_worker * total_workers\n\n    # Get the number of items that will be distributed to the current worker\n    num_items_to_process = num_items_per_worker\n\n    # Get the number of items that will be distributed to the remaining workers\n    num_items_to_distribute_remaining = len(user_items) - num_items_to_distribute\n\n    # Get the number of workers that will process the remaining items\n    num_workers_to_process_remaining = total_workers - node_rank - 1\n\n    # If the number of items that will be distributed to the current worker is less than the total number of workers, then add the remaining items to the current worker\n    if num_items_to_process < num_workers:\n        num_items_to_process += num_items_to_distribute_remaining\n\n    # If the number of items that will be distributed to the current worker is greater than the total number of workers, then add the remaining items to the remaining workers\n    elif num_items_to_process > num_workers:\n        num_items_to_process -= num_items_to_distribute_remaining\n\n    # Get the start and end indices for the current worker's items\n    start_index = num_items_to_process * node_rank\n    end_index = num_items_to_process * (node_rank + 1)\n\n    # Get the items assigned to the current worker\n    worker_items = user_items[start_index:end_index]"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # Get the total number of workers across all nodes\n    num_workers_total = _get_num_nodes() * num_workers\n\n    # Get the number of items each worker should process\n    num_items_per_worker = len(user_items) // num_workers_total\n\n    # Calculate the remainder\n    remainder = len(user_items) - num_workers_total * num_items_per_worker\n\n    # Initialize a list to store the indices of the start and end items for each worker\n    indices = []\n\n    # Calculate the indices for each worker\n    for i in range(num_workers):\n\n        # Calculate the start index\n        start = i * num_items_per_worker\n\n        # Calculate the end index\n        end = (i + 1) * num_items_per_worker\n\n        # If there is a remainder, add one extra item to the last worker\n        if remainder > 0:\n            end += 1\n            remainder -= 1\n\n        # Add the indices to the list\n        indices.append([start, end])\n\n    # Ensure the list has a length equal to the number of workers\n    if len(indices) != num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers.\")\n\n    # Initialize a list to store the items for each worker\n    items = []\n\n    # Iterate through the indices\n    for start, end in indices:\n\n        # Add the items to the list\n        items.append(user_items[start:end])\n\n    # Return the list of items for each worker\n    return items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # Get the total number of nodes\n    num_nodes = _get_num_nodes()\n\n    # Calculate the total number of workers across all nodes\n    total_workers = num_nodes * num_workers\n\n    # Calculate the number of items each worker should process\n    num_items_per_worker = len(user_items) // total_workers\n\n    # Calculate the number of extra items to be distributed among the workers\n    num_extra_items = len(user_items) % total_workers\n\n    # Calculate the start and end indices for each worker's items\n    indices = np.cumsum([num_items_per_worker + 1 if i < num_extra_items else num_items_per_worker for i in range(num_workers)])\n    start_indices = indices - num_items_per_worker - 1\n    end_indices = indices - 1\n\n    # Adjust the start indices for the first worker\n    start_indices[0] = 0\n\n    # Adjust the end indices for the last worker\n    end_indices[-1] = len(user_items)\n\n    # Assign items to workers\n    items_per_worker = [user_items[start_indices[i]:end_indices[i]] for i in range(num_workers)]\n\n    # Ensure the number of items per worker is correct\n    if len(items_per_worker) != num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers.\")\n\n    return items_per_worker\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # Get the total number of workers across all nodes\n    total_num_workers = num_workers * _get_num_nodes()\n\n    # Calculate the number of items each worker should process\n    items_per_worker = len(user_items) // total_num_workers\n\n    # Calculate the remainder and add any extra items to the workers starting from the end of the list\n    remainder = len(user_items) % total_num_workers\n    if remainder > 0:\n        items_per_worker += 1\n\n    # Calculate the start and end indices for each worker's items\n    cumsum = np.cumsum(np.insert(np.ones(total_num_workers - 1, dtype=int) * items_per_worker, 0, 0))\n    starts = cumsum[:-1]\n    ends = cumsum[1:]\n\n    # Assign items to workers\n    assigned_items = []\n    for start, end in zip(starts, ends):\n        assigned_items.append(user_items[start:end])\n\n    # Ensure that the output list has a length equal to the number of workers\n    if len(assigned_items) != total_num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers.\")\n\n    return assigned_items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    num_workers_across_all_nodes: int = _get_num_nodes() * num_workers\n\n    num_items_per_worker: int = len(user_items) // num_workers_across_all_nodes\n    num_workers_with_extra_item: int = len(user_items) % num_workers_across_all_nodes\n\n    indices: List[int] = [num_items_per_worker] * num_workers_across_all_nodes\n    for i in range(num_workers_with_extra_item):\n        indices[i] += 1\n\n    cumsum: List[int] = [0] + list(np.cumsum(indices))\n\n    # Create a list of lists containing the items assigned to each worker.\n    items_per_worker: List[List[Any]] = [\n        user_items[cumsum[i] : cumsum[i + 1]] for i in range(len(cumsum) - 1)\n    ]\n\n    # Ensure that the number of workers is the same as the number of sublists in the output.\n    if len(items_per_worker) != num_workers_across_all_nodes:\n        raise RuntimeError(\n            f\"The number of workers ({num_workers_across_all_nodes}) does not match the number of sublists ({len(items_per_worker)}) in the output.\"\n        )\n\n    # Ensure that the current node's rank is within the range of the number of workers.\n    if _get_node_rank() >= num_workers_across_all_nodes:\n        raise RuntimeError(\n            f\"The current node's rank ({_get_node_rank()}) is greater than the number of workers ({num_workers_across_all_nodes}).\"\n        )\n\n    return items_per_worker\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # Get the total number of workers across all nodes\n    total_num_workers = num_workers * _get_num_nodes()\n\n    # Calculate the number of items each worker should process\n    num_items_per_worker = len(user_items) // total_num_workers\n\n    # Adjust for any remainder\n    remainder = len(user_items) % total_num_workers\n    num_items_per_worker += 1 if _get_node_rank() < remainder else 0\n\n    # Determine the start and end indices for each worker's items\n    cumsum = np.cumsum(np.append([0], [num_items_per_worker] * (total_num_workers - 1)))\n    start_indices = cumsum[:-1]\n    end_indices = cumsum[1:]\n\n    # Assign items to workers\n    return [user_items[start:end] for start, end in zip(start_indices, end_indices)]\n\n"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dir = _get_cache_dir()\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_data_dir = _get_cache_data_dir()\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_data_dir):\n            shutil.rmtree(cache_data_dir, ignore_errors=True)\n\n        os.makedirs(cache_data_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_data_dir = _get_cache_data_dir()\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_data_dir):\n            shutil.rmtree(cache_data_dir, ignore_errors=True)\n\n        os.makedirs(cache_data_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(self.cache_dir):\n            shutil.rmtree(self.cache_dir, ignore_errors=True)\n\n        os.makedirs(self.cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dir = _get_cache_dir()\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(self.cache_dir):\n            shutil.rmtree(self.cache_dir, ignore_errors=True)\n        os.makedirs(self.cache_dir, exist_ok=True)\n\n        # Cleanup the cache data dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(self.cache_data_dir):\n            shutil.rmtree(self.cache_data_dir, ignore_errors=True)\n        os.makedirs(self.cache_data_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(self.cache_dir):\n            shutil.rmtree(self.cache_dir, ignore_errors=True)\n\n        os.makedirs(self.cache_dir, exist_ok=True)\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(self.cache_data_dir):\n            shutil.rmtree(self.cache_data_dir, ignore_errors=True)\n\n        os.makedirs(self.cache_data_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(self.cache_dir):\n            shutil.rmtree(self.cache_dir, ignore_errors=True)\n\n        os.makedirs(self.cache_dir, exist_ok=True)\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(self.cache_data_dir):\n            shutil.rmtree(self.cache_data_dir, ignore_errors=True)\n\n        os.makedirs(self.cache_data_dir, exist_ok=True)\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(self.cache_chunks_dir):\n            shutil.rmtree(self.cache_chunks_dir, ignore_errors=True)\n\n        os.makedirs(self.cache_chunks_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(self.cache_dir):\n            shutil.rmtree(self.cache_dir, ignore_errors=True)\n\n        os.makedirs(self.cache_dir, exist_ok=True)\n\n        # Cleanup the data dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(self.data_dir):\n            shutil.rmtree(self.data_dir, ignore_errors=True)\n\n        os.makedirs(self.data_dir, exist_ok=True)\n\n        # Cleanup the data dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(self.data_dir):\n            shutil.rmtree(self.data_dir, ignore_errors=True)\n\n        os.makedirs(self.data_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(self.cache_dir):\n            shutil.rmtree(self.cache_dir, ignore_errors=True)\n        os.makedirs(self.cache_dir, exist_ok=True)\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(self.cache_data_dir):\n            shutil.rmtree(self.cache_data_dir, ignore_errors=True)\n        os.makedirs(self.cache_data_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)\n\n        # Cleanup the data dir folder to avoid corrupted files from previous run to be there.\n        if self.output_dir.path:\n            if os.path.exists(self.output_dir.path):\n                shutil.rmtree(self.output_dir.path, ignore_errors=True)\n\n            os.makedirs(self.output_dir.path, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(self.cache_dir):\n            shutil.rmtree(self.cache_dir, ignore_errors=True)\n\n        os.makedirs(self.cache_dir, exist_ok=True)\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(self.cache_data_dir):\n            shutil.rmtree(self.cache_data_dir, ignore_errors=True)\n\n        os.makedirs(self.cache_data_dir, exist_ok=True)\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(self.cache_chunks_dir):\n            shutil.rmtree(self.cache_chunks_dir, ignore_errors=True)\n\n        os.makedirs(self.cache_chunks_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)\n\n        # Cleanup the data dir folder to avoid corrupted files from previous run to be there.\n        if self.output_dir.path is not None:\n            if os.path.exists(self.output_dir.path):\n                shutil.rmtree(self.output_dir.path, ignore_errors=True)\n\n            os.makedirs(self.output_dir.path, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(self.cache_dir):\n            shutil.rmtree(self.cache_dir, ignore_errors=True)\n\n        os.makedirs(self.cache_dir, exist_ok=True)\n\n        if self.output_dir:\n            # Cleanup the output dir folder to avoid corrupted files from previous run to be there.\n            if os.path.exists(self.output_dir):\n                shutil.rmtree(self.output_dir, ignore_errors=True)\n\n            os.makedirs(self.output_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_data_dir = _get_cache_data_dir()\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_data_dir):\n            shutil.rmtree(cache_data_dir, ignore_errors=True)\n\n        os.makedirs(cache_data_dir, exist_ok=True)\n"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)\n\n"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(self.cache_dir):\n            shutil.rmtree(self.cache_dir, ignore_errors=True)\n        os.makedirs(self.cache_dir, exist_ok=True)\n        os.makedirs(self.cache_data_dir, exist_ok=True)\n        os.makedirs(self.cache_chunks_dir, exist_ok=True)\n"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(self.cache_dir):\n            shutil.rmtree(self.cache_dir, ignore_errors=True)\n\n        os.makedirs(self.cache_dir, exist_ok=True)\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in futures:\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if not isinstance(element, str):\n        return False\n\n    if _IS_IN_STUDIO and input_dir is not None:\n        if element.startswith(input_dir):\n            return True\n\n        element = str(Path(element).absolute())\n\n    return os.path.exists(element)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if not isinstance(element, str):\n        return False\n\n    if _IS_IN_STUDIO and input_dir is not None:\n        if element.startswith(input_dir):\n            return True\n\n        element = str(Path(element).absolute())\n\n    return os.path.exists(element)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        if input_dir is not None:\n            if element.startswith(input_dir):\n                return True\n            element = _to_path(element)\n\n        return os.path.exists(element)\n\n    return False\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if not isinstance(element, str):\n        return False\n\n    if _IS_IN_STUDIO and input_dir is not None:\n        if element.startswith(input_dir):\n            return True\n\n        element = str(Path(element).absolute())\n\n    \"\"\"\n    Determines if a given element is a path that exists or starts with a specified input directory. It specifically checks if the element is a string that represents a path within the input directory or if it exists in the file system. This function also handles absolute path conversion when necessary.\n\n    Input-Output Arguments\n    :param input_dir: Optional[str]. The base directory against which the element is checked. It is used to determine if the element is a subpath of this directory.\n    :param element: Any. The element to be checked if it's a path. It is converted to a string and checked against the input directory or the file system for existence.\n    :return: Bool. Indicates whether the element is a valid path that exists or starts with the specified input directory.\n    \"\"\"\n    if not isinstance(element, str):\n        return False\n\n    if _IS_IN_STUDIO and input_dir is not None:\n        if element.startswith(input_dir):\n            return True\n\n        element = str(Path(element).absolute())\n\n    return os.path.exists(element)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if not isinstance(element, str):\n        return False\n\n    if input_dir is not None:\n        if element.startswith(input_dir):\n            return True\n\n        element = str(Path(element).absolute())\n\n    return os.path.exists(element)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if not isinstance(element, str):\n        return False\n\n    if input_dir is not None:\n        if element.startswith(input_dir):\n            return True\n\n    element = str(Path(element).absolute())\n    return os.path.exists(element)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        if input_dir is not None:\n            if element.startswith(input_dir):\n                return True\n\n            element = str(Path(element).absolute())\n\n        if os.path.exists(element):\n            return True\n\n    return False\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if not isinstance(element, str):\n        return False\n\n    if input_dir is not None:\n        if element.startswith(input_dir):\n            return True\n\n    element = str(Path(element).absolute())\n    return os.path.exists(element)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return os.path.exists(_to_path(element))\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if input_dir is None:\n        return False\n\n    element = _to_path(element)\n\n    if not os.path.exists(element):\n        return False\n\n    if input_dir is None:\n        return True\n\n    return element.startswith(input_dir)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return (\n        isinstance(element, str)\n        and (\n            os.path.exists(_to_path(element))\n            or (input_dir is not None and _to_path(element).startswith(input_dir))\n        )\n    )\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if not isinstance(element, str):\n        return False\n\n    if _IS_IN_STUDIO and input_dir is not None:\n        if element.startswith(input_dir):\n            return True\n\n        element = str(Path(element).absolute())\n\n    return os.path.exists(element)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return _IS_IN_STUDIO and input_dir is not None and element.startswith(input_dir) or os.path.exists(element)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if not isinstance(element, str):\n        return False\n\n    if input_dir is not None:\n        if element.startswith(input_dir):\n            return True\n\n    element = str(Path(element).absolute())\n    return os.path.exists(element)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if not isinstance(element, str):\n        return False\n\n    if _IS_IN_STUDIO and input_dir is not None:\n        if element.startswith(input_dir):\n            return True\n\n        element = str(Path(element).absolute())\n\n    return os.path.exists(element)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if input_dir is None:\n        return os.path.exists(_to_path(element))\n    else:\n        return os.path.exists(_to_path(element)) or element.startswith(input_dir)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if not isinstance(element, str):\n        return False\n\n    if input_dir is not None:\n        if element.startswith(input_dir):\n            return True\n\n        element = str(Path(element).absolute())\n\n    return os.path.exists(element)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        if input_dir is not None:\n            if element.startswith(input_dir):\n                return True\n\n            element = str(Path(element).absolute())\n\n        if os.path.exists(element):\n            return True\n    return False\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        if input_dir is not None:\n            if element.startswith(input_dir):\n                return True\n\n            element = str(Path(element).absolute())\n\n        if os.path.exists(element):\n            return True\n\n    return False\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        if input_dir is not None:\n            if element.startswith(input_dir):\n                return True\n\n            element = str(Path(element).absolute())\n\n        if os.path.exists(element):\n            return True\n\n    return False\n\n"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n\n        if self.tcnn:\n            if n_layers == 1:\n                return tcnn.NetworkWithInputEncoding(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    encoding_config=tcnn.EncodingConfig(\n                        n_neurons=n_neurons,\n                        n_layers=n_layers,\n                        activation=tcnn.Activation.ReLU if activation == \"ReLU\" else tcnn.Activation.None,\n                        output_activation=tcnn.Activation.ReLU if output_activation == \"ReLU\" else tcnn.Activation.Sigmoid if output_activation == \"Sigmoid\" else tcnn.Activation.None,\n                    ),\n                    seed=self._get_seed(),\n                )\n            else:\n                return tcnn.NetworkWithInputEncoding(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    encoding_config=tcnn.EncodingConfig(\n                        n_neurons=n_neurons,\n                        n_layers=n_layers,\n                        activation=tcnn.Activation.ReLU if activation == \"ReLU\" else tcnn.Activation.None,\n                        output_activation=tcnn.Activation.ReLU if output_activation == \"ReLU\" else tcnn.Activation.Sigmoid if output_activation == \"Sigmoid\" else tcnn.Activation.None,\n                    ),\n                    seed=self._get_seed(),\n                )\n        else:\n            layers = []\n            if n_layers == 1:\n                layers.append(nn.Linear(n_input_dims, n_output_dims))\n            else:\n                layers.append(nn.Linear(n_input_dims, n_neur"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n\n        if self.tcnn:\n            if n_neurons <= 256:\n                return tcnn.Network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    network_config={\n                        \"otype\": \"FullyFusedMLP\",\n                        \"activation\": activation,\n                        \"output_activation\": output_activation,\n                        \"n_neurons\": n_neurons,\n                        \"n_hidden_layers\": n_layers - 1,\n                        \"bias\": True,\n                    },\n                    seed=self._get_seed(),\n                )\n            else:\n                return tcnn.Network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    network_config={\n                        \"otype\": \"ReversedFullyFusedMLP\",\n                        \"activation\": activation,\n                        \"output_activation\": output_activation,\n                        \"n_neurons\": n_neurons,\n                        \"n_hidden_layers\": n_layers - 1,\n                        \"bias\": True,\n                    },\n                    seed=self._get_seed(),\n                )\n        else:\n            layers = []\n            for i in range(n_layers - 1):\n                layers.append(nn.Linear(n_input_dims if i == 0 else n_neurons, n_neurons))\n                if activation == \"ReLU\":\n                    layers.append(nn.ReLU())\n            layers.append(nn.Linear(n_neurons, n_output_dims))\n            if output_activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            elif output_activation == \"Sigmoid\":\n                layers.append(nn.Sigmoid())\n            return nn"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"Number of layers must be greater than 0.\"\n        assert n_neurons > 0, \"Number of neurons must be greater than 0.\"\n\n        if self.tcnn:\n            if n_neurons <= 256:\n                return tcnn.NetworkWithInputEncoding(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    network_config={\n                        \"otype\": \"FullyFusedMLP\",\n                        \"activation\": activation,\n                        \"output_activation\": output_activation,\n                        \"n_neurons\": n_neurons,\n                        \"n_hidden_layers\": n_layers - 1,\n                    },\n                    use_bias=True,\n                    seed=self._get_seed(),\n                )\n            else:\n                return tcnn.NetworkWithInputEncoding(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    network_config={\n                        \"otype\": \"FullyFusedMLP\",\n                        \"activation\": activation,\n                        \"output_activation\": output_activation,\n                        \"n_neurons\": 256,\n                        \"n_hidden_layers\": (n_layers - 1) // 2,\n                    },\n                    use_bias=True,\n                    seed=self._get_seed(),\n                )\n        else:\n            layers = []\n            for i in range(n_layers - 1):\n                if i == 0:\n                    layers.append(nn.Linear(n_input_dims, n_neurons))\n                else:\n                    layers.append(nn.Linear(n_neurons, n_neurons))\n                if activation == \"ReLU\":\n                    layers.append(nn.ReLU())\n            layers.append(nn.Linear(n_neurons, n_output_dim"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"Number of layers must be greater than 0\"\n        assert n_neurons > 0, \"Number of neurons must be greater than 0\"\n\n        if self.tcnn:\n            if n_neurons <= 256:\n                from tinycudann_network import TCNN_Network\n\n                return TCNN_Network(\n                    n_input_dims,\n                    n_output_dims,\n                    n_neurons,\n                    n_layers,\n                    activation,\n                    output_activation,\n                    seed=self._get_seed(),\n                )\n            else:\n                from tinycudann_network import TCNN_Network_Large\n\n                return TCNN_Network_Large(\n                    n_input_dims,\n                    n_output_dims,\n                    n_neurons,\n                    n_layers,\n                    activation,\n                    output_activation,\n                    seed=self._get_seed(),\n                )\n        else:\n            layers = []\n            for i in range(n_layers - 1):\n                if i == 0:\n                    layers.append(nn.Linear(n_input_dims, n_neurons))\n                else:\n                    layers.append(nn.Linear(n_neurons, n_neurons))\n                if activation == \"ReLU\":\n                    layers.append(nn.ReLU())\n\n            layers.append(nn.Linear(n_neurons, n_output_dims))\n            if output_activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            elif output_activation == \"Sigmoid\":\n                layers.append(nn.Sigmoid())\n\n            return nn.Sequential(*layers)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"n_layers must be greater than 0\"\n        assert n_neurons > 0, \"n_neurons must be greater than 0\"\n        assert n_input_dims > 0, \"n_input_dims must be greater than 0\"\n        assert n_output_dims > 0, \"n_output_dims must be greater than 0\"\n\n        if self.tcnn:\n            if n_neurons <= 256:\n                return tcnn.NetworkWithInputEncoding(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    network_config={\n                        \"otype\": \"FullyFusedMLP\",\n                        \"activation\": activation,\n                        \"output_activation\": output_activation,\n                        \"n_neurons\": n_neurons,\n                        \"n_hidden_layers\": n_layers - 1,\n                    },\n                    input_encoding_config={\n                        \"otype\": \"StaticGridEncoding\",\n                        \"n_input_dims\": n_input_dims,\n                        \"n_neurons\": n_neurons,\n                    },\n                    seed=self._get_seed(),\n                )\n            else:\n                return tcnn.NetworkWithInputEncoding(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    network_config={\n                        \"otype\": \"FullyFusedMLP\",\n                        \"activation\": activation,\n                        \"output_activation\": output_activation,\n                        \"n_neurons\": n_neurons,\n                        \"n_hidden_layers\": n_layers - 1,\n                    },\n                    input_encoding_config={\n                        \"otype\": \"DynamicGridEncoding\",\n                        \"n_input_dims\": n_input_dims,\n                        \"n_neurons\": n_neur"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n\n        if self.tcnn:\n            if n_neurons <= 256:\n                return tcnn.NetworkWithInputEncoding(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    network_config={\n                        \"otype\": \"FullyFusedMLP\",\n                        \"activation\": activation,\n                        \"output_activation\": output_activation,\n                        \"n_neurons\": n_neurons,\n                        \"n_hidden_layers\": n_layers - 1,\n                    },\n                    seed=self._get_seed(),\n                )\n            else:\n                return tcnn.NetworkWithInputEncoding(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    network_config={\n                        \"otype\": \"FullyFusedMLP\",\n                        \"activation\": activation,\n                        \"output_activation\": output_activation,\n                        \"n_neurons\": 256,\n                        \"n_hidden_layers\": 1,\n                    },\n                    seed=self._get_seed(),\n                )\n        else:\n            # PyTorch\n            layers = []\n            layers.append(nn.Linear(n_input_dims, n_neurons))\n            layers.append(nn.ReLU())\n            for _ in range(n_layers - 2):\n                layers.append(nn.Linear(n_neurons, n_neurons))\n                layers.append(nn.ReLU())\n            layers.append(nn.Linear(n_neurons, n_output_dims))\n            if output_activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            elif output_activation == \"Sigmoid\":\n                layers.append(nn.Sigmoid())\n            return nn.Sequential"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"n_layers must be greater than 0.\"\n        assert n_neurons > 0, \"n_neurons must be greater than 0.\"\n\n        if self.tcnn:\n            if n_neurons < 1024:\n                return tcnn.Network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    network_config={\n                        \"otype\": \"FullyFusedMLP\",\n                        \"activation\": activation,\n                        \"output_activation\": output_activation,\n                        \"n_neurons\": n_neurons,\n                        \"n_hidden_layers\": n_layers - 1,\n                    },\n                    seed=self._get_seed(),\n                )\n            else:\n                return tcnn.Network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    network_config={\n                        \"otype\": \"FullyFusedMLP\",\n                        \"activation\": activation,\n                        \"output_activation\": output_activation,\n                        \"n_neurons\": n_neurons,\n                        \"n_hidden_layers\": n_layers - 1,\n                        \"n_hidden_layers_per_group\": 1,\n                        \"n_neurons_per_group\": n_neurons // 1024,\n                    },\n                    seed=self._get_seed(),\n                )\n        else:\n            layers = []\n            for i in range(n_layers - 1):\n                if i == 0:\n                    layers.append(nn.Linear(n_input_dims, n_neurons))\n                else:\n                    layers.append(nn.Linear(n_neurons, n_neurons))\n                if activation == \"ReLU\":\n                    layers.append(nn.ReLU())\n            layers.append(nn.Linear"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n\n        if self.tcnn:\n            if n_neurons <= 256:\n                return tcnn.Network(\n                    n_input_dims,\n                    n_output_dims,\n                    n_neurons=n_neurons,\n                    n_hidden_layers=n_layers - 1,\n                    activation=tcnn.Activation.by_name(activation),\n                    output_activation=tcnn.Activation.by_name(output_activation),\n                    seed=self._get_seed(),\n                )\n            else:\n                return tcnn.Network(\n                    n_input_dims,\n                    n_output_dims,\n                    n_neurons=n_neurons,\n                    n_hidden_layers=n_layers - 1,\n                    activation=tcnn.Activation.by_name(activation),\n                    output_activation=tcnn.Activation.by_name(output_activation),\n                    seed=self._get_seed(),\n                    arch_type=\"G\",\n                )\n        else:\n            layers = []\n            for i in range(n_layers - 1):\n                layers.append(nn.Linear(n_input_dims, n_neurons))\n                if activation == \"ReLU\":\n                    layers.append(nn.ReLU())\n                elif activation == \"None\":\n                    pass\n                else:\n                    raise NotImplementedError\n                n_input_dims = n_neurons\n            layers.append(nn.Linear(n_input_dims, n_output_dims))\n            if output_activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            elif output_activation == \"Sigmoid\":\n                layers.append(nn.Sigmoid())\n            elif output_activation == \"None\":\n                pass\n            else:\n                raise NotImplementedError\n            return nn.Sequential(*layers)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"Number of layers must be greater than 0.\"\n        assert n_neurons > 0, \"Number of neurons must be greater than 0.\"\n\n        if self.tcnn:\n            if n_layers == 1:\n                if n_neurons <= 128:\n                    network = tcnn.NetworkWithInputEncoding(\n                        n_input_dims=n_input_dims,\n                        n_output_dims=n_output_dims,\n                        encoding_config=tcnn.EncodingConfig(\n                            tcnn.EIdentity(n_input_dims)\n                        ),\n                        network_config=tcnn.NetworkConfig(\n                            tcnn.FullyFusedMLP(\n                                n_neurons=n_neurons,\n                                n_hidden_layers=0,\n                                activation=tcnn.Activation.ReLU,\n                            ),\n                            output_activation=tcnn.Activation.ReLU\n                            if output_activation == \"ReLU\"\n                            else tcnn.Activation.Sigmoid,\n                        ),\n                    )\n                else:\n                    network = tcnn.NetworkWithInputEncoding(\n                        n_input_dims=n_input_dims,\n                        n_output_dims=n_output_dims,\n                        encoding_config=tcnn.EncodingConfig(\n                            tcnn.EIdentity(n_input_dims)\n                        ),\n                        network_config=tcnn.NetworkConfig(\n                            tcnn.FullyFusedMLP(\n                                n_neurons=n_neurons,\n                                n_hidden_layers=0,\n                                activation=tcnn.Activation.ReLU,\n                            ),\n                            output_activation=tcnn.Activation.ReLU\n                            if output_activation == \"ReLU\"\n                            else tcnn.Activation.Sigmoid,\n                        ),\n                    )\n            else"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0 and n_neurons > 0, \"Network must have at least one layer and one neuron.\"\n\n        if self.tcnn:\n            if n_neurons <= 256:\n                return tcnn.NetworkWithInputEncoding(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    network_config={\n                        \"otype\": \"FullyFusedMLP\",\n                        \"activation\": activation,\n                        \"output_activation\": output_activation,\n                        \"n_neurons\": n_neurons,\n                        \"n_hidden_layers\": n_layers - 1,\n                    },\n                    seed=self._get_seed(),\n                )\n            else:\n                return tcnn.NetworkWithInputEncoding(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    network_config={\n                        \"otype\": \"FullyFusedMLP_Large\",\n                        \"activation\": activation,\n                        \"output_activation\": output_activation,\n                        \"n_neurons\": n_neurons,\n                        \"n_hidden_layers\": n_layers - 1,\n                    },\n                    seed=self._get_seed(),\n                )\n        else:\n            network = nn.Sequential()\n            network.add_module(\"InputLayer\", nn.Linear(n_input_dims, n_neurons))\n            if activation == \"ReLU\":\n                network.add_module(\"InputLayerActivation\", nn.ReLU())\n            for i in range(n_layers - 2):\n                network.add_module(f\"HiddenLayer{i}\", nn.Linear(n_neurons, n_neurons))\n                if activation == \"ReLU\":\n                    network.add_module(f\"HiddenLayer{i}Activation\", nn.ReLU())\n            network.add"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n\n        if self.tcnn:\n            from tinycudann import NetworkWithInputOutput\n\n            if n_neurons <= 256:\n                nn_type = \"FullyFusedMLPv1\"\n            elif n_neurons <= 512:\n                nn_type = \"FullyFusedMLPv2\"\n            else:\n                nn_type = \"FullyFusedMLPv3\"\n\n            network = NetworkWithInputOutput(\n                nn_type,\n                n_input_dims,\n                n_output_dims,\n                n_neurons,\n                n_hidden_layers=n_layers - 1,\n                activation=activation,\n                output_activation=output_activation,\n                seed=self._get_seed(),\n            )\n\n            return network\n        else:\n            network = nn.Sequential()\n            if n_layers == 1:\n                network.add_module(\"linear\", nn.Linear(n_input_dims, n_output_dims))\n            else:\n                network.add_module(\"linear_0\", nn.Linear(n_input_dims, n_neurons))\n                for i in range(n_layers - 2):\n                    network.add_module(\n                        f\"activation_{i}\", nn.ReLU() if activation == \"ReLU\" else nn.Identity()\n                    )\n                    network.add_module(f\"linear_{i}\", nn.Linear(n_neurons, n_neurons))\n                network.add_module(\n                    f\"activation_{n_layers - 2}\",\n                    nn.ReLU() if activation == \"ReLU\" else nn.Identity(),\n                )\n                network.add_module(\n                    f\"linear_{n_layers - 2}\",\n                    nn.Linear(n_neurons, n_output_dims),\n                )\n                network.add_module(\n                    f"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n\n        if self.tcnn:\n            if n_neurons <= 128:\n                return torch.nn.Sequential(\n                    torch.nn.Linear(n_input_dims, n_neurons),\n                    torch.nn.ReLU(),\n                    *(\n                        torch.nn.Linear(n_neurons, n_neurons),\n                        torch.nn.ReLU(),\n                    )\n                    * (n_layers - 2),\n                    torch.nn.Linear(n_neurons, n_output_dims),\n                    torch.nn.Sigmoid(),\n                )\n            else:\n                from tinycudann import NetworkWithInputOutput\n\n                return NetworkWithInputOutput(\n                    n_input_dims,\n                    n_output_dims,\n                    n_neurons,\n                    n_layers,\n                    self._get_seed(),\n                    compute_type=\"half\",\n                    return_type=\"float\",\n                )\n        else:\n            return torch.nn.Sequential(\n                torch.nn.Linear(n_input_dims, n_neurons),\n                torch.nn.ReLU(),\n                *(\n                    torch.nn.Linear(n_neurons, n_neurons),\n                    torch.nn.ReLU(),\n                )\n                * (n_layers - 2),\n                torch.nn.Linear(n_neurons, n_output_dims),\n                torch.nn.Sigmoid(),\n            )"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n\n        if self.tcnn:\n            import tinycudann as tcnn\n\n            if n_neurons <= 256:\n                return tcnn.NetworkWithInputOutput(\n                    n_input_dims,\n                    n_output_dims,\n                    n_hidden_layers=n_layers,\n                    n_hidden_neurons=n_neurons,\n                    activation=activation,\n                    output_activation=output_activation,\n                    seed=self._get_seed(),\n                )\n            else:\n                return tcnn.NetworkWithInputOutput(\n                    n_input_dims,\n                    n_output_dims,\n                    n_hidden_layers=n_layers - 1,\n                    n_hidden_neurons=n_neurons,\n                    activation=activation,\n                    output_activation=output_activation,\n                    seed=self._get_seed(),\n                )\n\n        else:\n            layers = [nn.Linear(n_input_dims, n_neurons)]\n\n            if activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            elif activation == \"None\":\n                pass\n            else:\n                raise NotImplementedError(f\"{activation} is not a supported activation function.\")\n\n            for i in range(n_layers - 2):\n                layers.append(nn.Linear(n_neurons, n_neurons))\n                if activation == \"ReLU\":\n                    layers.append(nn.ReLU())\n                elif activation == \"None\":\n                    pass\n                else:\n                    raise NotImplementedError(f\"{activation} is not a supported activation function.\")\n\n            layers.append(nn.Linear(n_neurons, n_output_dims))\n            if output_activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            elif output_activation == \"Sigmoid\":\n                layers."}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"n_layers must be greater than 0\"\n        assert n_neurons > 0, \"n_neurons must be greater than 0\"\n\n        if self.tcnn:\n            if n_layers == 1:\n                from tinycudann.network import NetworkWithInputOutput\n                from tinycudann.modules.activation import Activation\n\n                network = NetworkWithInputOutput(\n                    n_input_dims,\n                    n_output_dims,\n                    n_neurons,\n                    n_blocks=1,\n                    n_hidden_layers=0,\n                    activation=Activation.ReLU,\n                    output_activation=Activation.None,\n                    seed=self._get_seed(),\n                )\n            else:\n                from tinycudann.network import NetworkWithInputOutput\n                from tinycudann.network.fully_connected import FullyConnected\n                from tinycudann.modules.activation import Activation\n\n                network = NetworkWithInputOutput(\n                    n_input_dims,\n                    n_neurons,\n                    n_neurons,\n                    n_blocks=1,\n                    n_hidden_layers=1,\n                    activation=Activation.ReLU,\n                    output_activation=Activation.ReLU,\n                    seed=self._get_seed(),\n                )\n                for _ in range(n_layers - 2):\n                    network = NetworkWithInputOutput(\n                        n_neurons,\n                        n_neurons,\n                        n_neurons,\n                        n_blocks=1,\n                        n_hidden_layers=1,\n                        activation=Activation.ReLU,\n                        output_activation=Activation.ReLU,\n                        seed=self._get_seed(),\n                    )\n                network = FullyConnected(\n                    n_neurons,\n                    n_output_dims,\n                    n_blocks=1,\n                    activation=Activation.ReLU,"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0 and n_neurons > 0\n\n        if self.tcnn:\n            import tinycudann as tcnn\n\n            if n_neurons <= 256:\n                return tcnn.NetworkWithInputOutput(\n                    n_input_dims,\n                    n_output_dims,\n                    n_neurons,\n                    n_layers,\n                    n_input_dims,\n                    n_output_dims,\n                    tcnn.Activation.ReLU,\n                    tcnn.Activation.None,\n                    self._get_seed(),\n                )\n            elif n_neurons <= 1024:\n                return tcnn.NetworkWithInputOutput(\n                    n_input_dims,\n                    n_output_dims,\n                    n_neurons,\n                    n_layers,\n                    n_input_dims,\n                    n_output_dims,\n                    tcnn.Activation.ReLU,\n                    tcnn.Activation.None,\n                    self._get_seed(),\n                )\n            else:\n                raise Exception(\n                    \"TinycuDNN does not support networks with more than 1024 neurons per layer.\"\n                )\n\n        else:\n            skip_layers = []\n            output_layers = []\n            for i in range(n_layers - 1):\n                if i == 0:\n                    skip_layers.append(\n                        nn.Linear(n_input_dims, n_neurons, bias=True)\n                    )\n                else:\n                    skip_layers.append(nn.Linear(n_neurons, n_neurons, bias=True))\n                if activation == \"ReLU\":\n                    skip_layers.append(nn.ReLU())\n                elif activation == \"None\":\n                    pass\n                else:\n                    raise Exception(\n                        \"The specified activation function is not supported.\"\n                    )\n\n            if output_activation == \"ReLU\":"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n\n        if self.tcnn:\n            if n_neurons < 1024:\n                return self._get_tcnn_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n            else:\n                return self._get_tcnn_network_large(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n        else:\n            return self._get_pytorch_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"Number of layers must be greater than 0.\"\n        assert n_neurons > 0, \"Number of neurons must be greater than 0.\"\n\n        if self.tcnn:\n            if n_neurons < 1e3:\n                from tinycudann_network import TCNN_Network\n                return TCNN_Network(\n                    n_input_dims,\n                    n_output_dims,\n                    n_neurons,\n                    n_layers,\n                    n_fused_layers=1,\n                    n_input_channels=1,\n                    n_output_channels=1,\n                    activation=activation,\n                    output_activation=output_activation,\n                    seed=self._get_seed(),\n                )\n            else:\n                from tinycudann_network import TCNN_Network\n                return TCNN_Network(\n                    n_input_dims,\n                    n_output_dims,\n                    n_neurons,\n                    n_layers,\n                    n_fused_layers=1,\n                    n_input_channels=1,\n                    n_output_channels=1,\n                    activation=activation,\n                    output_activation=output_activation,\n                    seed=self._get_seed(),\n                    use_fast_dense_network=True,\n                )\n        else:\n            layers = []\n            layers.append(nn.Linear(n_input_dims, n_neurons))\n            if activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            elif activation == \"None\":\n                pass\n            else:\n                raise ValueError(f\"Invalid activation function: {activation}\")\n            for _ in range(n_layers - 2):\n                layers.append(nn.Linear(n_neurons, n_neurons))\n                if activation == \"ReLU\":\n                    layers.append(nn.ReLU())\n                elif activation == \"None\":\n                    pass\n               "}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"n_layers must be greater than 0.\"\n        assert n_neurons > 0, \"n_neurons must be greater than 0.\"\n\n        if self.tcnn:\n            if n_layers > 1:\n                if n_neurons < 16384:\n                    network = tc.Network(\n                        n_input_dims, n_output_dims, n_neurons, n_layers, self._get_seed()\n                    )\n                else:\n                    network = tc.Network(\n                        n_input_dims, n_output_dims, 16384, n_layers, self._get_seed()\n                    )\n            else:\n                network = tc.Network(\n                    n_input_dims, n_output_dims, 16384, n_layers, self._get_seed()\n                )\n            return network\n        else:\n            if n_layers == 1:\n                return nn.Sequential(\n                    nn.Linear(n_input_dims, n_output_dims),\n                    getattr(nn, output_activation)()\n                    if output_activation != \"None\"\n                    else nn.Identity(),\n                )\n            else:\n                skip_layers = []\n                output_layers = []\n                for i in range(n_layers - 2):\n                    skip_layers.append(nn.Linear(n_input_dims, n_neurons))\n                    skip_layers.append(getattr(nn, activation)())\n                    n_input_dims += n_neurons\n                skip_layers.append(nn.Linear(n_input_dims, n_neurons))\n                skip_layers.append(getattr(nn, activation)())\n                skip_layers.append(nn.Linear(n_neurons + n_input_dims, n_output_dims))\n                skip_layers.append(\n                    getattr(nn, output_activation)()\n                    if output"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n\n        if self.tcnn:\n            from tinycudann import NetworkWithInputOutput\n            from tinycudann.modules.network import _get_n_params_per_output_dimension\n            n_params_per_output_dimension = _get_n_params_per_output_dimension(n_neurons)\n            n_output_dimensions = (n_output_dims + n_params_per_output_dimension - 1) // n_params_per_output_dimension\n            if n_layers == 1:\n                return NetworkWithInputOutput(n_input_dims, n_output_dimensions, n_neurons, n_output_dimensions, activation=output_activation, seed=self._get_seed())\n            else:\n                return NetworkWithInputOutput(n_input_dims, n_output_dimensions, n_neurons, n_output_dimensions, activation=activation, output_activation=output_activation, n_hidden_layers=n_layers - 2, seed=self._get_seed())\n\n        else:\n            layers = []\n            if n_layers > 1:\n                layers.append(nn.Linear(n_input_dims, n_neurons))\n                if activation == \"ReLU\":\n                    layers.append(nn.ReLU())\n                else:\n                    raise ValueError(f\"Unsupported activation function {activation}\")\n                for i in range(n_layers - 2):\n                    layers.append(nn.Linear(n_neurons, n_neurons))\n                    if activation == \"ReLU\":\n                        layers.append(nn.ReLU())\n                    else:\n                        raise ValueError(f\"Unsupported activation function {activation}\")\n            layers.append(nn.Linear(n_neurons, n_output_dims))\n            if output_activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            elif output_activation == \""}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n\n        if self.tcnn:\n            if n_neurons <= 256:\n                from tinycudann import NetworkWithInput, Network\n            elif n_neurons <= 512:\n                from tinycudann import NetworkWithInput1024, Network1024\n            elif n_neurons <= 1024:\n                from tinycudann import NetworkWithInput2048, Network2048\n            else:\n                raise ValueError(\"Too many neurons per layer.\")\n\n            if n_layers == 1:\n                return NetworkWithInput(n_input_dims, n_output_dims, n_neurons, seed=self._get_seed())\n            else:\n                skip_layers = [\n                    NetworkWithInput(n_input_dims, n_neurons, n_neurons, seed=self._get_seed())\n                ]\n                skip_layers += [\n                    Network(n_neurons, n_neurons, seed=self._get_seed())\n                    for _ in range(n_layers - 2)\n                ]\n                output_layer = Network(n_neurons, n_output_dims, seed=self._get_seed())\n                return NetworkWithSkipLayers(skip_layers, output_layer)\n\n        else:\n            assert n_layers >= 1\n            assert n_neurons >= 1\n\n            if n_layers == 1:\n                return nn.Linear(n_input_dims, n_output_dims)\n            else:\n                layers = [nn.Linear(n_input_dims, n_neurons)]\n                if activation == \"ReLU\":\n                    layers.append(nn.ReLU())\n                for _ in range(n_layers - 2):\n                    layers.append(nn.Linear(n_neurons, n_neurons))\n                    if activation == \"ReLU\":\n                        layers.append(nn.ReLU())\n                layers.append(nn."}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Create a list of shifted versions of the signal.\n        shifted_signal_list = [np.roll(signal, i) for i in range(-kernel_offset, kernel_offset + 1)]\n\n        # Compute the median of the shifted versions of the signal.\n        median_signal = np.median(shifted_signal_list, axis=0)\n\n        # Trim the median signal to remove edge effects.\n        median_signal = median_signal[kernel_offset:-kernel_offset]\n\n        return median_signal"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Calculate the rolling median of the signal.\n        rolling_median = np.zeros(len(signal) - 2 * kernel_offset)\n        for i in range(len(rolling_median)):\n            rolling_median[i] = np.median(signal[i : i + 2 * kernel_offset + 1])\n\n        return rolling_median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Calculate the rolling median by shifting the signal and computing the median of the shifted signals.\n        shifted_signals = [np.roll(signal, i) for i in range(-kernel_offset, kernel_offset + 1)]\n        rolling_median = np.median(shifted_signals, axis=0)\n\n        # Trim the rolling median to remove edge effects.\n        return rolling_median[kernel_offset:-kernel_offset]"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Calculate the rolling median of the signal by shifting the signal by a range defined by the kernel offset, computing the median of these shifted signals, and then trimming the resulting median array to account for edge effects introduced by the shifting process.\n        rolling_median = np.median(np.stack([np.roll(signal, -i) for i in range(kernel_offset)] + [signal] + [np.roll(signal, i) for i in range(kernel_offset)]), axis=0)[kernel_offset:-kernel_offset]\n\n        return rolling_median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Calculate the rolling median\n        rolling_median = np.zeros(signal.shape)\n        for i in range(signal.size):\n            rolling_median[i] = np.median(signal[np.maximum(0, i - kernel_offset) : np.minimum(signal.size, i + kernel_offset + 1)])\n\n        # Trim the result to remove edge effects\n        rolling_median = rolling_median[kernel_offset:-kernel_offset]\n\n        return rolling_median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Create a copy of the signal array to avoid modifying the original array.\n        signal_copy = np.copy(signal)\n\n        # Create a list of shifted versions of the signal array.\n        shifted_signal_list = []\n        for i in range(-kernel_offset, kernel_offset + 1):\n            shifted_signal_list.append(np.roll(signal_copy, i))\n\n        # Compute the median of the shifted versions of the signal array.\n        median_signal = np.median(shifted_signal_list, axis=0)\n\n        # Trim the median signal to remove edge effects.\n        median_signal = median_signal[kernel_offset:-kernel_offset]\n\n        return median_signal"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Calculate the rolling median by shifting the signal by a range defined by the kernel offset,\n        # computing the median of these shifted signals, and then trimming the resulting median array to account for edge effects introduced by the shifting process.\n        rolling_median = np.zeros_like(signal)\n        for i in range(kernel_offset):\n            rolling_median[kernel_offset - i - 1] = np.median(np.concatenate((signal[-i - 1 :], signal[: -(i + 1)])))\n            rolling_median[kernel_offset + i] = np.median(np.concatenate((signal[-i - 1 :], signal[: -(i + 1)])))\n\n        return rolling_median[kernel_offset:-kernel_offset]"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Create the shifted versions of the signal, which are used to compute the rolling median.\n        shifted_signals = []\n        for shift in range(-kernel_offset, kernel_offset + 1):\n            shifted_signal = np.roll(signal, shift)\n            shifted_signals.append(shifted_signal)\n\n        # Compute the median of the shifted signals.\n        median_signal = np.median(shifted_signals, axis=0)\n\n        # Trim the median signal to remove edge effects.\n        median_signal = median_signal[kernel_offset:-kernel_offset]\n\n        return median_signal"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Create a 2D array containing all the shifted versions of the signal\n        shifted_signal = np.zeros((signal.shape[0] - 2 * kernel_offset, 2 * kernel_offset))\n        for i in range(2 * kernel_offset):\n            shifted_signal[:, i] = np.roll(signal, -kernel_offset + i)\n\n        # Compute the median of each row\n        median_signal = np.median(shifted_signal, axis=1)\n\n        # Trim the median signal to remove edge effects\n        median_signal = median_signal[kernel_offset:-kernel_offset]\n\n        return median_signal"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # 1. Pad the signal with the first and last elements of the signal to account for edge effects\n        # 2. Shift the signal by a range defined by the kernel offset, and compute the median of these shifted signals\n        # 3. Trim the resulting median array to account for edge effects introduced by the shifting process\n\n        # 1. Pad the signal with the first and last elements of the signal to account for edge effects\n        padded_signal = np.concatenate(([signal[-1 - kernel_offset]], signal, [signal[0 + kernel_offset]]))\n\n        # 2. Shift the signal by a range defined by the kernel offset, and compute the median of these shifted signals\n        shifted_signals = np.stack([np.roll(padded_signal, i) for i in range(-kernel_offset, kernel_offset + 1)])\n        median_signal = np.median(shifted_signals, axis=0)\n\n        # 3. Trim the resulting median array to account for edge effects introduced by the shifting process\n        return median_signal[kernel_offset:-kernel_offset]"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Trim the signal to avoid edge effects\n        trimmed_signal = signal[kernel_offset:-kernel_offset]\n\n        # Initialize the rolling median array\n        rolling_median = np.zeros_like(trimmed_signal)\n\n        # Loop over the range of shifts\n        for shift in range(-kernel_offset, kernel_offset + 1):\n\n            # Shift the signal\n            shifted_signal = np.roll(signal, shift)\n\n            # Trim the shifted signal to avoid edge effects\n            shifted_trimmed_signal = shifted_signal[kernel_offset:-kernel_offset]\n\n            # Calculate the median of the shifted signal\n            rolling_median += np.median(shifted_trimmed_signal)\n\n        # Divide the rolling median by the number of shifts to get the average\n        rolling_median /= 2 * kernel_offset + 1\n\n        return rolling_median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # The rolling median is calculated by shifting the signal by a range defined by the kernel offset,\n        # computing the median of these shifted signals, and then trimming the resulting median array to\n        # account for edge effects introduced by the shifting process.\n        rolling_median = np.median(\n            np.stack(\n                (\n                    np.roll(signal, -kernel_offset),\n                    np.roll(signal, -kernel_offset + 1),\n                    np.roll(signal, -kernel_offset + 2),\n                    np.roll(signal, -kernel_offset - 1),\n                    np.roll(signal, -kernel_offset - 2),\n                    signal,\n                    np.roll(signal, kernel_offset - 2),\n                    np.roll(signal, kernel_offset - 1),\n                    np.roll(signal, kernel_offset),\n                    np.roll(signal, kernel_offset + 1),\n                    np.roll(signal, kernel_offset + 2),\n                )\n            ),\n            axis=0,\n        )\n\n        # Trim the rolling median to remove edge effects.\n        rolling_median = rolling_median[kernel_offset:-kernel_offset]\n\n        return rolling_median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Pad the signal with the first and last kernel_offset elements.\n        padded_signal = np.pad(signal, (kernel_offset, kernel_offset), mode=\"edge\")\n\n        # Generate shifted versions of the padded signal.\n        shifted_signal = [padded_signal[i : len(padded_signal) - kernel_offset + i] for i in range(2 * kernel_offset + 1)]\n\n        # Calculate the median of the shifted signal versions.\n        median_signal = np.median(shifted_signal, axis=0)\n\n        # Trim the median signal to remove edge effects.\n        return median_signal[kernel_offset:-kernel_offset]"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Get the length of the input signal.\n        signal_length = signal.size\n\n        # Get the number of shifts to be applied to the signal for median calculation.\n        num_shifts = 2 * kernel_offset + 1\n\n        # Initialize the median array.\n        median_array = np.zeros(signal_length)\n\n        # Iterate over all shifts.\n        for shift_idx in range(num_shifts):\n\n            # Get the shifted signal.\n            shifted_signal = np.roll(signal, shift_idx - kernel_offset)\n\n            # Calculate the median of the shifted signal and store it in the median array.\n            median_array += np.median(shifted_signal)\n\n        # Divide the median array by the number of shifts to get the rolling median.\n        median_array /= num_shifts\n\n        # Return the rolling median.\n        return median_array"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Create a matrix of shifted versions of the input signal.\n        shifted_signal = np.zeros((signal.shape[0] - 2 * kernel_offset, 2 * kernel_offset))\n        for i in range(2 * kernel_offset):\n            shifted_signal[:, i] = np.roll(signal, i - kernel_offset)\n\n        # Calculate the median of each row, which corresponds to the median of the signal shifted by a particular amount.\n        median_signal = np.median(shifted_signal, axis=1)\n\n        # Trim the median signal to remove edge effects.\n        median_signal = median_signal[kernel_offset:-kernel_offset]\n\n        return median_signal"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Create a copy of the input signal.\n        signal_copy = np.copy(signal)\n\n        # Create a copy of the input signal with the first and last few elements removed.\n        signal_copy_trimmed = signal_copy[kernel_offset:-kernel_offset]\n\n        # Create a copy of the input signal with the first and last few elements removed and reversed.\n        signal_copy_trimmed_reversed = signal_copy_trimmed[::-1]\n\n        # Create a copy of the input signal with the first and last few elements removed and reversed.\n        signal_copy_trimmed_reversed_padded = np.concatenate((signal_copy_trimmed_reversed, np.zeros(2 * kernel_offset)))\n\n        # Create a copy of the input signal with the first and last few elements removed and reversed.\n        signal_copy_trimmed_padded = np.concatenate((np.zeros(2 * kernel_offset), signal_copy_trimmed))\n\n        # Create a copy of the input signal with the first and last few elements removed and reversed.\n        median_array = np.concatenate((signal_copy_trimmed_reversed_padded, signal_copy_trimmed_padded))\n\n        # Return the rolling median of the input signal.\n        return scipy.signal.medfilt(median_array, 2 * kernel_offset + 1)[2 * kernel_offset:-2 * kernel_offset]"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Get the length of the input signal.\n        signal_length = len(signal)\n\n        # Get the length of the rolling median array.\n        rolling_median_length = signal_length - 2 * kernel_offset\n\n        # Initialize the rolling median array.\n        rolling_median = np.zeros(rolling_median_length)\n\n        # Loop over the rolling median array.\n        for i in range(rolling_median_length):\n\n            # Get the indices of the left and right edges of the kernel.\n            left_kernel_index = i\n            right_kernel_index = i + 2 * kernel_offset\n\n            # Get the left and right edges of the kernel.\n            left_kernel_edge = signal[left_kernel_index]\n            right_kernel_edge = signal[right_kernel_index]\n\n            # Get the shifted signal between the left and right edges of the kernel.\n            shifted_signal = signal[left_kernel_index:right_kernel_index]\n\n            # Calculate the median of the shifted signal.\n            rolling_median[i] = np.median(shifted_signal)\n\n        return rolling_median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Initialize the output array.\n        rolling_median = np.zeros(signal.size - 2 * kernel_offset)\n\n        # Loop over all indices in the output array.\n        for i in range(rolling_median.size):\n\n            # Define the range of indices in the input signal array for the current shift.\n            start_index = i + kernel_offset\n            stop_index = start_index + 2 * kernel_offset + 1\n\n            # Compute the median of the shifted signal and store it in the output array.\n            rolling_median[i] = np.median(signal[start_index:stop_index])\n\n        return rolling_median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Pad the signal with the first and last elements to ensure the median is calculated for all regions of the signal.\n        signal = np.concatenate(([signal[0]] * kernel_offset, signal, [signal[-1]] * kernel_offset))\n\n        # Create a matrix of shifted versions of the signal, each column is a shifted version of the signal.\n        shifted_signal = np.zeros((len(signal), 2 * kernel_offset + 1))\n        for i in range(2 * kernel_offset + 1):\n            shifted_signal[:, i] = np.roll(signal, i - kernel_offset)\n\n        # Calculate the median of each column, which is a shifted version of the signal.\n        median_signal = np.median(shifted_signal, axis=1)\n\n        # Trim the median signal to remove edge effects.\n        median_signal = median_signal[kernel_offset:-kernel_offset]\n\n        return median_signal"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        if kernel_offset == 0:\n            return signal\n\n        num_elements = signal.size\n        num_median_elements = 2 * kernel_offset + 1\n\n        if num_median_elements > num_elements:\n            raise GeometryRefinementError(\n                f\"Smoothing._rolling_median: The number of elements in the median kernel ({num_median_elements}) is greater than the number of elements in the signal array ({num_elements})!\"\n            )\n\n        # Pad the signal with the edge values to avoid edge effects.\n        padded_signal = np.pad(signal, (kernel_offset, kernel_offset), mode=\"edge\")\n\n        # Shift the signal by a range defined by the kernel offset, and compute the median of these shifted signals.\n        shifted_signals = np.stack(\n            [padded_signal[i : i + num_elements] for i in range(0, 2 * kernel_offset + 1)], axis=0\n        )\n        median_signal = np.median(shifted_signals, axis=0)\n\n        # Trim the median array to account for edge effects.\n        return median_signal[kernel_offset:-kernel_offset]"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Check if the probe and gallery templates have the same code size.\n    if template_probe.code_size != template_gallery.code_size:\n        raise MatcherError(\n            \"The probe and gallery templates must have the same code size. \"\n            f\"Probe template size: {template_probe.code_size}, \"\n            f\"Gallery template size: {template_gallery.code_size}\"\n        )\n\n    # Check if the probe and gallery templates have the same number of channels.\n    if template_probe.num_channels != template_gallery.num_channels:\n        raise MatcherError(\n            \"The probe and gallery templates must have the same number of channels. \"\n            f\"Probe template channels: {template_probe.num_channels}, \"\n            f\"Gallery template channels: {template_gallery.num_channels}\"\n        )\n\n    # Check if the probe and gallery templates have the same number of channels.\n    if template_probe.num_bands != template_gallery.num_bands:\n        raise MatcherError(\n            \"The probe and gallery templates must have the same number of bands. \"\n            f\"Probe template bands: {template_probe.num_bands}, \"\n            f\"Gallery template bands: {template_gallery.num_bands}\"\n        )\n\n    # Check if the rotation shift is valid.\n    if rotation_shift < 0:\n        raise MatcherError(f\"The rotation shift must be greater than or equal to zero. {rotation_shift} given.\")\n    if rotation_shift >= template_probe.code_size:\n        raise MatcherError(\n            f\"The rotation shift must be less than the code size. {rotation_shift} given for code size {template_probe.code_size}.\"\n        )\n\n    # Check if the nonmatch distance is valid.\n    if nm_dist is not None and nm_dist < 0:\n        raise MatcherError(f\"The nonmatch distance must be greater than or equal to zero. {nm_dist} given"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Check for valid rotation shift\n    if rotation_shift < 0:\n        raise MatcherError(\"Rotation shift must be a positive integer.\")\n\n    # Check for valid weights\n    if weights is not None:\n        for weight in weights:\n            if weight.shape != template_probe.maskcode.shape:\n                raise MatcherError(\"Weights table must be the same shape as the iris templates.\")\n\n    # Calculate the minimum Hamming distance\n    min_HD = np.inf\n    min_shift = 0\n    for shift in range(rotation_shift + 1):\n        # Calculate the Hamming distance for the current shift\n        irisbits = np.roll(template_probe.iriscode, shift, axis=1)\n        maskbits = np.roll(template_gallery.maskcode, shift, axis=1)\n        irisbitcount, maskbitcount, _, _ = count_nonmatchbits(irisbits, maskbits, template_probe.half_width, weights)\n        HD = irisbitcount / maskbitcount\n\n        # Update the minimum Hamming distance\n        if HD < min_HD:\n            min_HD = HD\n            min_shift = shift\n\n    # Calculate the normalized Hamming distance\n    if nm_dist is not None:\n        sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n            template_probe.total_bits, template_probe.half_width, weights\n        )\n        irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n            irisbits, maskbits, template_probe.half_width, weights\n        )\n        HD_top = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist)\n        HD_bot = normalized_HD(irisbitcount_bot, maskbitcount_bot, sqrt_totalbitcount_bot, nm_dist)\n        min_"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    if template_probe.code_size != template_gallery.code_size:\n        raise MatcherError(\"Probe and gallery templates must have the same code size.\")\n\n    if template_probe.code_type != template_gallery.code_type:\n        raise MatcherError(\"Probe and gallery templates must have the same code type.\")\n\n    if template_probe.code_seed != template_gallery.code_seed:\n        raise MatcherError(\"Probe and gallery templates must have the same code seed.\")\n\n    if rotation_shift > template_probe.code_size:\n        raise MatcherError(\"Rotation shift must be smaller than the code size.\")\n\n    if weights is not None:\n        if len(weights) != len(template_probe.codewords):\n            raise MatcherError(\"The number of weights tables must be equal to the number of codewords.\")\n\n        for i in range(len(template_probe.codewords)):\n            if weights[i].shape != template_probe.codewords[i].shape:\n                raise MatcherError(\"The shape of all weights tables must be equal to the shape of the codewords.\")\n\n    half_width = [int(np.floor(template_probe.code_size / 2)) - rotation_shift, rotation_shift]\n\n    irisbits = [template_probe.codewords, template_gallery.codewords]\n    maskbits = [template_probe.mask, template_gallery.mask]\n\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        template_probe.code_size, half_width, weights\n    )\n\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        irisbits, maskbits, half_width, weights\n    )\n\n    if nm_dist is not None:\n        norm_HD_top = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Check for correct input arguments\n    if rotation_shift > template_gallery.code_size // 2:\n        raise MatcherError(f\"rotation_shift is larger than half of the code size: {rotation_shift} > {template_gallery.code_size // 2}\")\n\n    # Calculate the minimum Hamming distance\n    min_hd = np.inf\n    min_shift = 0\n    for shift in range(-rotation_shift, rotation_shift + 1):\n        irisbits = np.roll(template_probe.iriscode, shift, axis=1)\n        maskbits = template_gallery.maskcode\n        sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n            template_gallery.code_size, template_gallery.half_width, weights\n        )\n        irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n            irisbits, maskbits, template_gallery.half_width, weights\n        )\n        if weights:\n            hd = np.sum(\n                [\n                    np.sum(np.multiply(irisbits[:, hw:, ...], weights[i][:, hw:, ...])),\n                    np.sum(np.multiply(irisbits[:, :hw, ...], weights[i][:, :hw, ...])),\n                ]\n            )\n        else:\n            hd = irisbitcount_top + irisbitcount_bot\n        if nm_dist:\n            hd = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist)\n        if hd < min_hd:\n            min_hd = hd\n            min_shift = shift\n\n    return min_hd, min_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Check for invalid inputs\n    if rotation_shift < 0:\n        raise MatcherError(\"rotation_shift must be greater than or equal to 0\")\n\n    # Get the total size of the iris code\n    toal_codesize = template_probe.code_size\n\n    # Get the half width of the iris code\n    half_width = [int(np.floor(template_probe.code_size / 2)), int(np.floor(template_gallery.code_size / 2))]\n\n    # Get the total amount of sqrt bits\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        toal_codesize, half_width, weights\n    )\n\n    # Get the nonmatch bits\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        template_probe.bits, template_gallery.bits, half_width, weights\n    )\n\n    # Get the minimum Hamming distance\n    min_hd = min(\n        normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist)\n        + rotation_shift * np.sqrt(maskbitcount_top),\n        normalized_HD(irisbitcount_bot, maskbitcount_bot, sqrt_totalbitcount_bot, nm_dist)\n        + rotation_shift * np.sqrt(maskbitcount_bot),\n    )\n\n    # Get the rotation shift that achieves the minimum Hamming distance\n    min_rotation_shift = int(min_hd / np.sqrt(maskbitcount_top))\n\n    return min_hd, min_rotation_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Checking input arguments\n    if rotation_shift < 0 or rotation_shift > template_gallery.code_size:\n        raise MatcherError(\n            f\"Rotation shift should be between 0 and {template_gallery.code_size}.\"\n        )\n\n    # Calculating the Hamming distance for all rotation shifts\n    hamming_distances = np.zeros(template_gallery.code_size + 1)\n    for shift in range(template_gallery.code_size + 1):\n        irisbits = np.roll(template_probe.iriscode, shift, axis=1)\n        maskbits = np.roll(template_gallery.maskcode, shift, axis=1)\n        irisbitcount, maskbitcount, _, _ = count_nonmatchbits(\n            irisbits, maskbits, template_gallery.half_width, weights\n        )\n        hamming_distances[shift] = irisbitcount / maskbitcount\n\n    # Finding the minimum Hamming distance\n    min_hd_shift = np.argmin(hamming_distances)\n    min_hd = hamming_distances[min_hd_shift]\n\n    # Calculating the normalized Hamming distance\n    if nm_dist is not None:\n        sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n            template_probe.code_size, template_probe.half_width, weights\n        )\n        irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n            np.roll(template_probe.iriscode, min_hd_shift, axis=1),\n            np.roll(template_gallery.maskcode, min_hd_shift, axis=1),\n            template_gallery.half_width,\n            weights,\n        )\n        min_hd = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Checking input arguments\n    if not isinstance(template_probe, IrisTemplate):\n        raise TypeError(\"Argument 'template_probe' must be an IrisTemplate object.\")\n    if not isinstance(template_gallery, IrisTemplate):\n        raise TypeError(\"Argument 'template_gallery' must be an IrisTemplate object.\")\n    if not isinstance(rotation_shift, int):\n        raise TypeError(\"Argument 'rotation_shift' must be an integer.\")\n    if not isinstance(nm_dist, (float, type(None))):\n        raise TypeError(\"Argument 'nm_dist' must be a float or None.\")\n    if not isinstance(weights, (list, type(None))):\n        raise TypeError(\"Argument 'weights' must be a list or None.\")\n\n    # Checking input arguments\n    if template_probe.code_size != template_gallery.code_size:\n        raise MatcherError(\"Arguments 'template_probe' and 'template_gallery' must have the same code size.\")\n    if rotation_shift > template_probe.code_size / 2:\n        raise MatcherError(\"Argument 'rotation_shift' cannot be greater than the template code size divided by 2.\")\n    if nm_dist is not None and nm_dist < 0:\n        raise MatcherError(\"Argument 'nm_dist' cannot be less than zero.\")\n    if weights is not None:\n        for weight in weights:\n            if not isinstance(weight, np.ndarray):\n                raise TypeError(\"Argument 'weights' must be a list of numpy arrays.\")\n            if weight.shape != (2, template_probe.code_size, template_probe.code_size):\n                raise MatcherError(\"Argument 'weights' must be a list of 2xNxN numpy arrays.\")\n\n    # Calculate the rotation shift in columns\n    half_width = [template_probe.code_size // 2 - rotation_shift, template_probe.code_size // 2 + rotation_shift]\n\n    # Calculate the nonmatch distance\n    if nm_dist is None:\n        nm_"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    half_width = [x // 2 for x in template_probe.code_size]\n    toal_codesize = sum(template_probe.code_size)\n    irisbits_probe = template_probe.bits\n    irisbits_gallery = template_gallery.bits\n    maskbits = np.zeros(template_probe.bits.shape, dtype=bool)\n\n    for i in range(len(half_width)):\n        maskbits[:, :, i, :] = np.logical_xor(\n            irisbits_probe[:, :, i, :], np.rot90(irisbits_probe[:, :, i, :], rotation_shift, axes=(1, 2))\n        )\n\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        toal_codesize, half_width, weights\n    )\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        irisbits_probe, maskbits, half_width, weights\n    )\n\n    if weights:\n        norm_HD_top = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist)\n        norm_HD_bot = normalized_HD(irisbitcount_bot, maskbitcount_bot, sqrt_totalbitcount_bot, nm_dist)\n        norm_HD = min(norm_HD_top, norm_HD_bot)\n    else:\n        norm_HD = min(\n            normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount, nm_dist),\n            normalized_HD(irisbitcount_bot, maskbitcount_bot, sqrt_totalbitcount, nm_dist),\n        )\n\n    if norm_HD < nm_dist:\n        return norm_HD, rotation_shift\n\n    raise MatcherError"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Check the input arguments\n    if rotation_shift < 0:\n        raise MatcherError(\"The rotation shift cannot be negative.\")\n    if rotation_shift >= template_probe.code_size:\n        raise MatcherError(\"The rotation shift cannot be larger than the code size.\")\n    if nm_dist is not None and nm_dist < 0:\n        raise MatcherError(\"The nonmatch distance cannot be negative.\")\n    if weights is not None:\n        for weight in weights:\n            if weight.shape != template_probe.shape:\n                raise MatcherError(\"The weights table must have the same shape as the iris templates.\")\n\n    # Calculate the Hamming distance for each rotation shift\n    hd_list = []\n    for shift in range(rotation_shift + 1):\n        if weights is None:\n            hd = np.sum(\n                np.logical_xor(\n                    template_probe.iris_code[:, shift : template_probe.code_size + shift, ...],\n                    template_gallery.iris_code,\n                )\n            )\n        else:\n            hd = np.sum(\n                np.multiply(\n                    np.logical_xor(\n                        template_probe.iris_code[:, shift : template_probe.code_size + shift, ...],\n                        template_gallery.iris_code,\n                    ),\n                    weights,\n                )\n            )\n        hd_list.append(hd)\n\n    # Find the minimum Hamming distance and corresponding rotation shift\n    min_hd_idx = np.argmin(hd_list)\n    min_hd = hd_list[min_hd_idx]\n\n    # Calculate normalized Hamming distance if the nonmatch distance is provided\n    if nm_dist is not None:\n        sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n            template_probe.code_size, template_probe.half_width, weights\n        )\n        irisbit"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Check that the rotation_shift is valid\n    if rotation_shift < 0:\n        raise MatcherError(f\"Invalid rotation_shift {rotation_shift}\")\n\n    # Get the total code size and the half width of the code\n    toal_codesize = template_probe.code_size\n    half_width = [int(np.floor(template_probe.code_size / 2)), int(np.ceil(template_probe.code_size / 2))]\n\n    # Calculate the number of bits for the top and bottom half of the code\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        toal_codesize, half_width, weights\n    )\n\n    # Calculate the number of nonmatched bits for the top and bottom half of the code\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        template_probe.data, template_gallery.data, half_width, weights\n    )\n\n    # Calculate the minimum Hamming distance\n    min_HD = min(\n        [\n            normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist),\n            normalized_HD(irisbitcount_bot, maskbitcount_bot, sqrt_totalbitcount_bot, nm_dist),\n        ]\n    )\n\n    # Calculate the rotation shift that achieves the minimum Hamming distance\n    min_rotation_shift = rotation_shift - int(np.argmin([min_HD, min_HD]))\n\n    return min_HD, min_rotation_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Convert rotation shift to column indices\n    rotation_shift = int(np.round(rotation_shift / 180 * template_gallery.code_size))\n\n    # Get iriscodes and maskcodes\n    irisbits_probe = template_probe.iriscode\n    irisbits_gallery = template_gallery.iriscode\n    maskbits_probe = template_probe.maskcode\n    maskbits_gallery = template_gallery.maskcode\n\n    # Get half width of iriscode\n    half_width = [int(np.round(template_probe.code_size / 2)), int(np.round(template_gallery.code_size / 2))]\n\n    # Count nonmatch bits\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        irisbits_probe, maskbits_gallery, half_width, weights\n    )\n\n    # Count total sqrt bits\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        template_probe.code_size, half_width, weights\n    )\n\n    # Calculate Hamming distance\n    hd_top = max(0, irisbitcount_top - maskbitcount_top)\n    hd_bot = max(0, irisbitcount_bot - maskbitcount_bot)\n    hd_top_rot = max(0, irisbitcount_top - maskbitcount_top - rotation_shift)\n    hd_bot_rot = max(0, irisbitcount_bot - maskbitcount_bot - rotation_shift)\n\n    # Calculate normalized Hamming distance\n    if nm_dist is not None:\n        hd_top = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist)\n        hd_bot = normalized_HD(irisbitcount_bot, maskbitcount_bot, sq"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # check if the rotation shift is valid\n    if rotation_shift > template_probe.code_size:\n        raise MatcherError(\"The rotation shift is larger than the code size\")\n\n    # convert rotation shift to columns\n    half_width = [int(template_probe.code_size / 2 - rotation_shift)]\n\n    # calculate the total code size\n    toal_codesize = np.sum([np.sum(x) for x in template_probe.weights])\n\n    # calculate the total bit count\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        toal_codesize, half_width, weights\n    )\n\n    # calculate the nonmatch bit count\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        template_probe.iriscode, template_gallery.iriscode, half_width, weights\n    )\n\n    # calculate the hamming distance\n    hamming_top = irisbitcount_top / maskbitcount_top\n    hamming_bot = irisbitcount_bot / maskbitcount_bot\n\n    # calculate the normalized hamming distance\n    if nm_dist is not None:\n        norm_HD_top = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist)\n        norm_HD_bot = normalized_HD(irisbitcount_bot, maskbitcount_bot, sqrt_totalbitcount_bot, nm_dist)\n        hamming_top = norm_HD_top\n        hamming_bot = norm_HD_bot\n\n    # calculate the weighted hamming distance\n    if weights is not None:\n        weighted_HD_top = np.sum(np.multiply(irisbitcount_top, weights)) / np.sum(np.multiply(maskbitcount_top, weights))\n        weighted_HD_bot = np.sum(np.multiply"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Check input data\n    if rotation_shift > template_gallery.code_size:\n        raise MatcherError(\n            \"Rotation shift cannot be larger than code size. Please check the rotation shift value.\"\n        )\n\n    # Calculate the total code size\n    toal_codesize = template_probe.code_size + template_gallery.code_size\n\n    # Calculate the half width of the code\n    half_width = [int(np.ceil(toal_codesize / 2)) for _ in range(len(template_probe.code_words))]\n\n    # Calculate the number of bits for the iris code\n    irisbits = template_probe.code_words - template_gallery.code_words\n\n    # Calculate the number of bits for the mask code\n    maskbits = template_probe.mask_words - template_gallery.mask_words\n\n    # Calculate the number of bits for the iris code for top and bottom iris\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        irisbits, maskbits, half_width, weights\n    )\n\n    # Calculate the total number of bits for the iris code\n    irisbitcount = irisbitcount_top + irisbitcount_bot\n\n    # Calculate the total number of bits for the mask code\n    maskbitcount = maskbitcount_top + maskbitcount_bot\n\n    # Calculate the square root of the total number of bits for the iris code\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        toal_codesize, half_width, weights\n    )\n\n    # Calculate the normalized Hamming distance\n    if nm_dist:\n        norm_HD = normalized_HD(irisbitcount, maskbitcount, sqrt_totalbitcount, nm_dist)\n\n    # Calculate the weighted Hamming distance\n    if weights:\n        weighted_HD = ("}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Checks\n    if template_probe.code_size != template_gallery.code_size:\n        raise MatcherError(\"Template code sizes do not match.\")\n    if template_probe.total_bits != template_gallery.total_bits:\n        raise MatcherError(\"Template bit counts do not match.\")\n    if rotation_shift > template_probe.code_size:\n        raise MatcherError(\"Rotation shift is larger than template code size.\")\n    if nm_dist and nm_dist >= template_probe.code_size:\n        raise MatcherError(\"Nonmatch distance is larger than template code size.\")\n\n    # Setup\n    half_width = [int(template_probe.code_size / 2 - rotation_shift)]\n    if template_probe.code_size % 2 == 0:\n        half_width.append(int(template_probe.code_size / 2 + rotation_shift))\n\n    # Calculate Hamming distance\n    if weights:\n        if len(weights) != 3:\n            raise MatcherError(\"Invalid weights table length.\")\n        if weights[0].shape != (3, template_probe.code_size, template_probe.code_size):\n            raise MatcherError(\"Invalid weights table shape.\")\n        sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n            template_probe.total_bits, half_width, weights\n        )\n        irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n            template_probe.bits, template_gallery.bits, half_width, weights\n        )\n        if nm_dist:\n            hamming_top = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist)\n            hamming_bot = normalized_HD(irisbitcount_bot, maskbitcount_bot, sqrt_totalbitcount_bot, nm_dist)"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    if rotation_shift > template_gallery.code_size:\n        raise MatcherError(\"Rotation shift is larger than the code size\")\n\n    if template_probe.code_size != template_gallery.code_size:\n        raise MatcherError(\"Code size mismatch between probe and gallery\")\n\n    if weights is not None:\n        if len(weights) != template_probe.code_size:\n            raise MatcherError(\"Weights list size does not match the code size\")\n\n        for w in weights:\n            if w.shape != (3, 3):\n                raise MatcherError(\"Weights tables are not 3x3\")\n\n    toal_codesize = template_probe.code_size * 2\n    half_width = [template_probe.code_size - rotation_shift, template_probe.code_size + rotation_shift]\n\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        toal_codesize, half_width, weights\n    )\n\n    irisbits_top = template_probe.bits[:, half_width[0] :]\n    irisbits_bot = template_probe.bits[:, : half_width[1]]\n    maskbits_top = template_gallery.bits[:, half_width[0] :]\n    maskbits_bot = template_gallery.bits[:, : half_width[1]]\n\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        irisbits_top, maskbits_top, half_width, weights\n    )\n    irisbitcount_bot, maskbitcount_bot, irisbitcount_top, maskbitcount_top = count_nonmatchbits(\n        irisbits_bot, maskbits_bot, half_width, weights\n    )\n\n    HD_top = min(irisbitcount_top / maskbitcount_top, maskbitcount_top / irisbitcount_top)\n   "}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Check if the templates have the same size\n    if template_probe.code_size != template_gallery.code_size:\n        raise MatcherError(\n            f\"The probe and gallery templates must have the same size. The probe size is {template_probe.code_size}, while the gallery size is {template_gallery.code_size}.\"\n        )\n\n    # Check if the rotation shift is valid\n    if rotation_shift < 0 or rotation_shift > template_probe.code_size:\n        raise MatcherError(\n            f\"The rotation shift must be between 0 and the template size. The rotation shift is {rotation_shift} and the template size is {template_probe.code_size}.\"\n        )\n\n    # Calculate the Hamming distance for each possible rotation shift\n    hamming_distances = np.zeros(template_probe.code_size)\n    for shift in range(template_probe.code_size):\n        irisbits_probe = np.roll(template_probe.iris_bits, shift, axis=1)\n        irisbits_gallery = np.roll(template_gallery.iris_bits, shift, axis=1)\n        maskbits = template_gallery.mask_bits\n        half_width = template_gallery.half_width\n\n        # Calculate the Hamming distance\n        if weights:\n            irisbitcount, maskbitcount, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n                irisbits_probe, maskbits, half_width, weights\n            )\n        else:\n            irisbitcount = np.sum(irisbits_probe & maskbits)\n            maskbitcount = np.sum(maskbits)\n\n        hamming_distances[shift] = irisbitcount / maskbitcount\n\n    # Calculate the minimum Hamming distance\n    min_hamming_distance = np.min(hamming_distances)\n\n    # Calculate the corresponding rotation shift\n    rotation_shift = np.argmin(hamming_distances)\n\n    # Calcul"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Check that the probe and gallery templates have the same code width\n    if template_probe.codewidth != template_gallery.codewidth:\n        raise MatcherError(\n            \"The probe and gallery templates must have the same code width. \"\n            f\"The probe template has codewidth={template_probe.codewidth}, \"\n            f\"while the gallery template has codewidth={template_gallery.codewidth}.\"\n        )\n\n    # Check that the rotation shift is valid\n    if rotation_shift < 0 or rotation_shift > template_probe.codewidth:\n        raise MatcherError(\n            f\"The rotation shift must be between 0 and the code width. \"\n            f\"The current rotation shift is {rotation_shift}, \"\n            f\"while the code width is {template_probe.codewidth}.\"\n        )\n\n    # Check that the nonmatch distance is valid\n    if nm_dist is not None and nm_dist < 0:\n        raise MatcherError(f\"The nonmatch distance must be positive. The current nonmatch distance is {nm_dist}.\")\n\n    # Check that the weights are valid\n    if weights is not None:\n        if len(weights) != 3:\n            raise MatcherError(\"The weights must be a list of three tables.\")\n        if weights[0].shape != (3, 3):\n            raise MatcherError(\"The first weight table must be a 3x3 matrix.\")\n        if weights[1].shape != (3, 3):\n            raise MatcherError(\"The second weight table must be a 3x3 matrix.\")\n        if weights[2].shape != (3, 3):\n            raise MatcherError(\"The third weight table must be a 3x3 matrix.\")\n        if np.any(weights[0] < 0) or np.any(weights[1] < 0) or np.any(weights[2] < 0):\n            raise MatcherError(\"The weights must be positive.\")\n\n    # Calculate the Hamming distance\n    half_width = [template_probe.codewidth // 2 - rotation_"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Check that the probe and gallery templates are of the same type\n    if template_probe.code_size != template_gallery.code_size:\n        raise MatcherError(\"Probe and gallery templates must have the same code size.\")\n\n    # Check that the probe and gallery templates are of the same size\n    if template_probe.iris_size != template_gallery.iris_size:\n        raise MatcherError(\"Probe and gallery templates must have the same iris size.\")\n\n    # Check that the probe and gallery templates have the same number of rotations\n    if template_probe.rotations != template_gallery.rotations:\n        raise MatcherError(\"Probe and gallery templates must have the same number of rotations.\")\n\n    # Check that the rotation shift is within the allowed range\n    if rotation_shift > template_probe.rotations or rotation_shift < 0:\n        raise MatcherError(\"Rotation shift must be within the allowed range.\")\n\n    # Check that the nonmatch distance is within the allowed range\n    if nm_dist is not None and (nm_dist < 0 or nm_dist > 1):\n        raise MatcherError(\"Nonmatch distance must be within the allowed range.\")\n\n    # Check that the weights are within the allowed range\n    if weights is not None:\n        for weight in weights:\n            if weight.shape != (template_probe.rotations, template_probe.code_size, template_probe.code_size):\n                raise MatcherError(\"Weights must be a list of square matrices with the same size as the iris code.\")\n\n    # Calculate the minimum Hamming distance\n    half_width = [int(template_probe.code_size / 2 - rotation_shift) for _ in range(template_probe.rotations)]\n    irisbits_top = [\n        np.concatenate(\n            (\n                template_probe.iriscode[:, :, :, hw:],\n                template_probe.iriscode[:, :, :, :hw],\n            ),\n            axis=3,\n        )\n        for"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Validate input arguments\n    if rotation_shift < 0 or rotation_shift > template_gallery.code_size:\n        raise MatcherError(\n            \"Invalid rotation shift. The rotation shift must be an integer between 0 and the code size of the gallery template.\"\n        )\n\n    # Calculate the number of columns to be shifted in the template\n    shift_columns = rotation_shift / template_gallery.code_size * template_gallery.code_width\n\n    # Calculate the number of columns to be shifted in the weights\n    if weights:\n        shift_columns_weights = rotation_shift / template_gallery.code_size * weights[0].shape[1]\n\n    # Calculate the Hamming distances for all possible rotation shifts\n    hamming_distances = []\n    for i in range(int(shift_columns)):\n        # Shift the template\n        shifted_template = np.roll(template_gallery.code, shift=i, axis=1)\n\n        # Calculate the Hamming distance\n        if weights:\n            # Shift the weights\n            shifted_weights = np.roll(weights[0], shift=int(shift_columns_weights), axis=1)\n\n            # Calculate the nonmatch bits\n            irisbitcount, maskbitcount, irisbitcount_top, maskbitcount_top = count_nonmatchbits(\n                template_probe.code, shifted_template, template_probe.half_width, weights=[shifted_weights]\n            )\n\n            # Calculate the total bit counts\n            sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n                template_probe.code_size, template_probe.half_width, weights=[shifted_weights]\n            )\n\n            # Calculate the normalized Hamming distance\n            if nm_dist:\n                hamming_distances.append(\n                    normalized_HD(\n                        irisbitcount,\n                        maskbitcount,\n                        sqrt_totalbitcount,"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Check input arguments\n    if template_probe.code_size != template_gallery.code_size:\n        raise MatcherError(\"The probe and gallery templates must have the same code size\")\n\n    if rotation_shift > template_probe.code_size / 2:\n        raise MatcherError(\"The rotation shift is too large\")\n\n    if nm_dist is not None and nm_dist < 0:\n        raise MatcherError(\"The nonmatch distance must be nonnegative\")\n\n    if weights is not None:\n        if len(weights) != 3:\n            raise MatcherError(\"The weights list must have three elements\")\n\n        if weights[0].shape != weights[1].shape or weights[0].shape != weights[2].shape:\n            raise MatcherError(\"The weights tables must have the same shape\")\n\n        if weights[0].shape != template_probe.code.shape:\n            raise MatcherError(\"The weights shape must be the same as the code shape\")\n\n    # Calculate Hamming distances\n    if rotation_shift == 0:\n        irisbits = template_probe.code != template_gallery.code\n        maskbits = np.ones_like(template_gallery.code)\n        return np.sum(irisbits & maskbits), 0\n\n    # Calculate the number of bits for the whole iris\n    toal_codesize = template_probe.code_size * 2\n\n    # Calculate the number of bits for the top and bottom halves of the iris\n    half_width = [template_probe.code_size - rotation_shift, rotation_shift]\n\n    # Calculate the total bit counts\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        toal_codesize, half_width, weights\n    )\n\n    # Calculate nonmatch bit counts\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        template_probe.code,"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_vertices = polygon.shape[0]\n        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n\n        first_bisectors_point = np.zeros((num_bisectors, 2), dtype=np.float32)\n        second_bisectors_point = np.zeros((num_bisectors, 2), dtype=np.float32)\n\n        for i in range(num_bisectors):\n            iteration = 0\n            while iteration < max_iterations:\n                first_point_index = np.random.randint(0, num_vertices)\n                second_point_index = (first_point_index + 1) % num_vertices\n\n                first_point = polygon[first_point_index]\n                second_point = polygon[second_point_index]\n\n                first_bisector_point, second_bisector_point = self._calculate_bisectors(\n                    first_point, second_point, min_distance_between_sector_points_in_px\n                )\n\n                if first_bisector_point is not None and second_bisector_point is not None:\n                    first_bisectors_point[i] = first_bisector_point\n                    second_bisectors_point[i] = second_bisector_point\n                    break\n                iteration += 1\n\n            if iteration == max_iterations:\n                raise EyeCentersEstimationError(\n                    \"Could not find a sufficient number of point pairs that meet the distance criterion within the maximum number of iterations allowed.\"\n                )\n\n        return first_bisectors_point, second_bisectors_point\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_vertices = polygon.shape[0]\n        first_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n        second_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n        num_bisectors_found = 0\n        iterations = 0\n\n        while num_bisectors_found < self.params.num_bisectors and iterations < self.params.max_iterations:\n            iterations += 1\n            first_point = polygon[np.random.randint(0, num_vertices)]\n            second_point = polygon[np.random.randint(0, num_vertices)]\n            distance_between_points = np.linalg.norm(first_point - second_point)\n\n            if distance_between_points > min_distance_between_sector_points_in_px:\n                first_bisectors_point[num_bisectors_found] = first_point\n                second_bisectors_point[num_bisectors_found] = second_point\n                num_bisectors_found += 1\n\n        if num_bisectors_found < self.params.num_bisectors:\n            raise EyeCentersEstimationError(\n                f\"Failed to find a sufficient number of point pairs that meet the distance criterion within the maximum number of iterations allowed. Number of iterations: {iterations}\"\n            )\n\n        return first_bisectors_point, second_bisectors_point\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Initialize variables\n        num_points = polygon.shape[0]\n        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n        num_iterations = 0\n\n        # Initialize lists to store the points that will be used to calculate perpendicular bisectors\n        first_bisectors_points = []\n        second_bisectors_points = []\n\n        # Iterate until the desired number of points is reached\n        while len(first_bisectors_points) < num_bisectors:\n\n            # Increment the number of iterations\n            num_iterations += 1\n\n            # If the maximum number of iterations has been reached, raise an exception\n            if num_iterations > max_iterations:\n                raise EyeCentersEstimationError(\n                    \"Failed to find a sufficient number of point pairs that meet the distance criterion within the maximum number of iterations allowed.\"\n                )\n\n            # Randomly choose two points from the polygon\n            first_point = polygon[np.random.randint(num_points)]\n            second_point = polygon[np.random.randint(num_points)]\n\n            # If the distance between the two points is greater than the minimum distance, store them\n            if np.linalg.norm(first_point - second_point) > min_distance_between_sector_points_in_px:\n                first_bisectors_points.append(first_point)\n                second_bisectors_points.append(second_point)\n\n        # Convert the lists to numpy arrays\n        first_bisectors_points = np.array(first_bisectors_points)\n        second_bisectors_points = np.array(second_bisectors_points)\n\n        return first_bisectors_points, second_bisectors_points\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Find the number of points in the polygon.\n        num_points = polygon.shape[0]\n\n        # Initialize an array that will store the starting points of the calculated perpendicular bisectors.\n        first_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n\n        # Initialize an array that will store the ending points of the calculated perpendicular bisectors.\n        second_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n\n        # Initialize a counter that will be used to keep track of the number of iterations.\n        counter = 0\n\n        # Iterate until the number of iterations is equal to the maximum number of iterations.\n        while counter < self.params.max_iterations:\n\n            # Randomly choose two points from the polygon.\n            first_point = polygon[np.random.randint(num_points)]\n            second_point = polygon[np.random.randint(num_points)]\n\n            # Calculate the distance between the two points.\n            distance_between_points = np.linalg.norm(first_point - second_point)\n\n            # If the distance between the two points is greater than the minimum distance, then save the two points.\n            if distance_between_points > min_distance_between_sector_points_in_px:\n                first_bisectors_point[counter] = first_point\n                second_bisectors_point[counter] = second_point\n                counter += 1\n\n            # If the number of iterations is equal to the maximum number of iterations, then raise an exception.\n            if counter == self.params.max_iterations:\n                raise EyeCentersEstimationError(\n                    \"Failed to find a sufficient number of point pairs that meet the distance criterion within the maximum number of iterations allowed.\"\n                )\n\n        return first_bisectors_point, second_bisectors_point\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Initialize variables.\n        num_iterations = 0\n        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n        num_vertices = polygon.shape[0]\n        first_bisectors_point = np.zeros((num_bisectors, 2))\n        second_bisectors_point = np.zeros((num_bisectors, 2))\n\n        # Loop until the required number of bisectors have been found.\n        while num_bisectors > 0:\n\n            # Choose two random points from the polygon.\n            first_point_index = np.random.randint(num_vertices)\n            second_point_index = np.random.randint(num_vertices)\n            first_point = polygon[first_point_index]\n            second_point = polygon[second_point_index]\n\n            # Calculate the distance between the two points.\n            distance_between_points = np.linalg.norm(first_point - second_point)\n\n            # If the distance is greater than the minimum required distance, calculate the perpendicular bisector.\n            if distance_between_points > min_distance_between_sector_points_in_px:\n\n                # Calculate the perpendicular bisector.\n                first_bisectors_point[num_bisectors - 1] = first_point\n                second_bisectors_point[num_bisectors - 1] = self._calculate_perpendicular_bisector(\n                    first_point, second_point\n                )\n\n                # Decrement the number of bisectors to find.\n                num_bisectors -= 1\n\n            # Increment the number of iterations.\n            num_iterations += 1\n\n            # If the maximum number of iterations has been reached, raise an exception.\n            if num_iterations >= max_iterations:\n                raise EyeCentersEstimationError(\n                    \"Failed to find a sufficient number of point pairs that meet the distance criterion within the maximum number of iterations allowed.\"\n                )\n\n        return first_bisectors_point, second"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_vertices = polygon.shape[0]\n        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n\n        first_bisectors_point = np.empty((num_bisectors, 2), dtype=np.float64)\n        second_bisectors_point = np.empty((num_bisectors, 2), dtype=np.float64)\n\n        num_iterations = 0\n        num_valid_pairs = 0\n        while num_valid_pairs < num_bisectors and num_iterations < max_iterations:\n            # Select two random points from the polygon's vertices\n            first_point = polygon[np.random.randint(num_vertices)]\n            second_point = polygon[np.random.randint(num_vertices)]\n\n            # Calculate the distance between the two points\n            distance_between_points = np.linalg.norm(first_point - second_point)\n\n            # If the distance between the points is greater than the minimum distance, then calculate the perpendicular bisector\n            if distance_between_points > min_distance_between_sector_points_in_px:\n                first_bisectors_point[num_valid_pairs] = first_point\n                second_bisectors_point[num_valid_pairs] = second_point\n                num_valid_pairs += 1\n\n            num_iterations += 1\n\n        if num_valid_pairs < num_bisectors:\n            raise EyeCentersEstimationError(\n                \"Could not find a sufficient number of point pairs that meet the distance criterion within the maximum number of iterations allowed. This indicates that it may not be possible to accurately estimate the center of the shape.\"\n            )\n\n        return first_bisectors_point, second_bisectors_point\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        first_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n        second_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n\n        for i in range(self.params.num_bisectors):\n            iterations = 0\n            while True:\n                iterations += 1\n                if iterations > self.params.max_iterations:\n                    raise EyeCentersEstimationError(\n                        f\"Could not find {self.params.num_bisectors} point pairs with a minimum distance of {min_distance_between_sector_points_in_px} px in {self.params.max_iterations} iterations.\"\n                    )\n                first_point_index = np.random.randint(0, len(polygon))\n                second_point_index = np.random.randint(0, len(polygon))\n                if np.linalg.norm(polygon[first_point_index] - polygon[second_point_index]) > min_distance_between_sector_points_in_px:\n                    break\n            first_bisectors_point[i] = polygon[first_point_index]\n            second_bisectors_point[i] = polygon[second_point_index]\n\n        return first_bisectors_point, second_bisectors_point\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Initialize a list to hold the starting and ending points of the calculated bisectors.\n        bisectors_points = []\n\n        # Initialize a variable to keep track of the number of iterations.\n        num_iterations = 0\n\n        # Iterate until the number of bisectors has been found.\n        while len(bisectors_points) < self.params.num_bisectors:\n\n            # Increment the number of iterations.\n            num_iterations += 1\n\n            # If the maximum number of iterations has been reached, raise an exception.\n            if num_iterations > self.params.max_iterations:\n                raise EyeCentersEstimationError(\n                    \"Could not find a sufficient number of point pairs that meet the distance criterion within the maximum number of iterations allowed.\"\n                )\n\n            # Select two random points from the polygon.\n            point_1_index = np.random.randint(len(polygon))\n            point_2_index = np.random.randint(len(polygon))\n            point_1 = polygon[point_1_index]\n            point_2 = polygon[point_2_index]\n\n            # Calculate the distance between the two points.\n            distance_between_points = np.linalg.norm(point_1 - point_2)\n\n            # If the distance between the two points is greater than the minimum distance, add the points to the list of bisector points.\n            if distance_between_points > min_distance_between_sector_points_in_px:\n                bisectors_points.append((point_1, point_2))\n\n        # Convert the list of bisector points to numpy arrays.\n        bisectors_points_array = np.array(bisectors_points)\n\n        # Return the starting and ending points of the calculated bisectors.\n        return bisectors_points_array[:, 0], bisectors_points_array[:, 1]\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Initialize an array to store the starting points of the perpendicular bisectors.\n        first_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n        # Initialize an array to store the ending points of the perpendicular bisectors.\n        second_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n        # Initialize a counter to keep track of the number of iterations.\n        counter = 0\n        # Initialize a counter to keep track of the number of pairs of points that meet the minimum distance criterion.\n        num_pairs_found = 0\n        # Iterate until the maximum number of iterations is reached.\n        while counter < self.params.max_iterations:\n            # Randomly choose two points from the polygon.\n            first_point = polygon[np.random.randint(0, polygon.shape[0])]\n            second_point = polygon[np.random.randint(0, polygon.shape[0])]\n            # Calculate the distance between the two points.\n            distance = self._calculate_distance(first_point, second_point)\n            # If the distance between the two points is greater than the minimum distance criterion, store the points and increment the number of pairs found.\n            if distance > min_distance_between_sector_points_in_px:\n                first_bisectors_point[num_pairs_found] = first_point\n                second_bisectors_point[num_pairs_found] = second_point\n                num_pairs_found += 1\n            # Increment the counter.\n            counter += 1\n        # If the number of pairs found is less than the number of bisectors requested, raise an exception.\n        if num_pairs_found < self.params.num_bisectors:\n            raise EyeCentersEstimationError(\"Unable to find a sufficient number of point pairs.\")\n        # Return the starting and ending points of the perpendicular bisectors.\n        return first_bisectors_point, second_bisectors_point\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Initialize variables\n        num_points = polygon.shape[0]\n        first_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n        second_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n\n        # Iterate through the maximum number of iterations\n        for i in range(self.params.max_iterations):\n\n            # Generate a random pair of points\n            first_point = np.random.randint(num_points)\n            second_point = np.random.randint(num_points)\n\n            # Ensure that the points are not too close to each other\n            while np.linalg.norm(polygon[first_point] - polygon[second_point]) < min_distance_between_sector_points_in_px:\n                first_point = np.random.randint(num_points)\n                second_point = np.random.randint(num_points)\n\n            # Calculate the perpendicular bisector\n            first_bisectors_point[i] = polygon[first_point]\n            second_bisectors_point[i] = polygon[second_point]\n\n        # If the number of points is less than the specified number, raise an error\n        if i < self.params.num_bisectors - 1:\n            raise EyeCentersEstimationError(\"Failed to find sufficient number of points\")\n\n        # Return the points\n        return first_bisectors_point, second_bisectors_point\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Initialize variables\n        num_points = polygon.shape[0]\n        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n\n        # Initialize lists to store the bisectors\n        first_bisectors_point = np.zeros((num_bisectors, 2))\n        second_bisectors_point = np.zeros((num_bisectors, 2))\n\n        # Initialize variables to store the number of iterations and the number of bisectors found\n        num_iterations = 0\n        num_bisectors_found = 0\n\n        # Loop through the maximum number of iterations, trying to find a sufficient number of bisectors\n        while num_bisectors_found < num_bisectors and num_iterations < max_iterations:\n\n            # Randomly choose two points from the polygon\n            first_point_index = np.random.randint(0, num_points)\n            second_point_index = np.random.randint(0, num_points)\n            first_point = polygon[first_point_index]\n            second_point = polygon[second_point_index]\n\n            # Calculate the distance between the two points\n            distance = np.linalg.norm(first_point - second_point)\n\n            # If the distance is greater than the minimum distance, calculate the bisector\n            if distance > min_distance_between_sector_points_in_px:\n                first_bisectors_point[num_bisectors_found] = first_point\n                second_bisectors_point[num_bisectors_found] = second_point\n                num_bisectors_found += 1\n\n            # Increment the number of iterations\n            num_iterations += 1\n\n        # If the function did not find a sufficient number of bisectors, raise an exception\n        if num_bisectors_found < num_bisectors:\n            raise EyeCentersEstimationError(\n                f\"Failed to find {num_bisectors} bisectors with a minimum distance of {min_distance_between_sector_points_in_px} pixels in {max_iterations}"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_points = polygon.shape[0]\n        num_iterations = 0\n\n        first_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n        second_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n\n        while num_iterations < self.params.max_iterations:\n            first_point_index = np.random.randint(num_points)\n            second_point_index = np.random.randint(num_points)\n\n            if np.linalg.norm(polygon[first_point_index] - polygon[second_point_index]) > min_distance_between_sector_points_in_px:\n                first_bisectors_point[num_iterations] = polygon[first_point_index]\n                second_bisectors_point[num_iterations] = polygon[second_point_index]\n                num_iterations += 1\n\n        if num_iterations < self.params.num_bisectors:\n            raise EyeCentersEstimationError(\n                \"Could not find a sufficient number of points that meet the distance criterion within the maximum number of iterations allowed.\"\n            )\n\n        return first_bisectors_point, second_bisectors_point\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Initialize variables\n        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n        num_vertices = polygon.shape[0]\n        num_iterations = 0\n        first_bisectors_point = np.zeros((num_bisectors, 2))\n        second_bisectors_point = np.zeros((num_bisectors, 2))\n\n        # Initialize the random selection process\n        first_bisectors_point_indices = np.random.randint(num_vertices, size=num_bisectors)\n        second_bisectors_point_indices = np.random.randint(num_vertices, size=num_bisectors)\n\n        # Iterate until a sufficient number of point pairs have been found\n        while num_iterations < max_iterations:\n\n            # Iterate through each point pair\n            for i in range(num_bisectors):\n\n                # If the distance between the two points is greater than the minimum distance, store the points\n                if self._distance(polygon[first_bisectors_point_indices[i]], polygon[second_bisectors_point_indices[i]]) > min_distance_between_sector_points_in_px:\n                    first_bisectors_point[i] = polygon[first_bisectors_point_indices[i]]\n                    second_bisectors_point[i] = polygon[second_bisectors_point_indices[i]]\n\n            # Increment the number of iterations\n            num_iterations += 1\n\n            # If a sufficient number of point pairs have been found, break out of the loop\n            if np.count_nonzero(first_bisectors_point) == num_bisectors:\n                break\n\n            # If the maximum number of iterations has been reached, raise an exception\n            if num_iterations == max_iterations:\n                raise EyeCentersEstimationError(\n                    \"Unable to find a sufficient number of point pairs that meet the distance criterion within the maximum number of iterations allowed.\"\n                )\n\n            # Randomly select new point pairs\n           "}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_iterations = 0\n        first_bisectors_point = np.empty((self.params.num_bisectors, 2))\n        second_bisectors_point = np.empty((self.params.num_bisectors, 2))\n        while num_iterations < self.params.max_iterations:\n            # Choose two random points from the polygon\n            random_points = np.random.choice(polygon, 2, replace=False)\n            # Calculate the perpendicular bisector of the two points\n            first_bisectors_point[num_iterations] = random_points[0]\n            second_bisectors_point[num_iterations] = self._calculate_bisector(\n                random_points[0], random_points[1]\n            )\n            # Check if the two points are far enough apart to be used\n            if np.linalg.norm(\n                first_bisectors_point[num_iterations] - second_bisectors_point[num_iterations]\n            ) > min_distance_between_sector_points_in_px:\n                num_iterations += 1\n        if num_iterations < self.params.num_bisectors:\n            raise EyeCentersEstimationError(\n                \"Failed to find a sufficient number of point pairs that meet the distance criterion within the maximum number of iterations allowed. This indicates that it may not be possible to accurately estimate the center of the shape.\"\n            )\n        return first_bisectors_point, second_bisectors_point\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Initialize the number of iterations to zero\n        num_iterations = 0\n\n        # Initialize the number of points in the polygon\n        num_points = polygon.shape[0]\n\n        # Initialize the list of points to be used as starting points for perpendicular bisectors\n        first_bisectors_point_list = []\n\n        # Initialize the list of points to be used as ending points for perpendicular bisectors\n        second_bisectors_point_list = []\n\n        # Initialize the list of distances between the points used as starting points for perpendicular bisectors\n        first_bisectors_point_distances = []\n\n        # Initialize the list of distances between the points used as ending points for perpendicular bisectors\n        second_bisectors_point_distances = []\n\n        # Initialize the list of distances between the starting and ending points of perpendicular bisectors\n        bisector_distances = []\n\n        # Initialize the list of bisector points that meet the minimum distance criterion\n        bisector_points = []\n\n        # Initialize the list of bisector points that meet the minimum distance criterion\n        bisector_points_distances = []\n\n        # Iterate over the number of iterations\n        while num_iterations < self.params.max_iterations:\n\n            # Increment the number of iterations\n            num_iterations += 1\n\n            # Randomly select two points from the polygon\n            first_point = polygon[np.random.randint(0, num_points)]\n            second_point = polygon[np.random.randint(0, num_points)]\n\n            # Calculate the distance between the two points\n            distance = np.linalg.norm(first_point - second_point)\n\n            # If the distance between the two points is greater than the minimum distance\n            if distance > min_distance_between_sector_points_in_px:\n\n                # Add the first point to the list of points used as starting points for perpendicular bisectors\n                first_bisectors_point_list.append(first_point)\n\n                # Add the second point to the list of points used as ending points for perpendicular bisectors\n                second"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_iterations = 0\n        num_points = polygon.shape[0]\n        first_bisectors_point = np.empty((0, 2))\n        second_bisectors_point = np.empty((0, 2))\n\n        while num_iterations < self.params.max_iterations:\n            first_point = polygon[np.random.randint(num_points)]\n            second_point = polygon[np.random.randint(num_points)]\n            if np.linalg.norm(first_point - second_point) > min_distance_between_sector_points_in_px:\n                first_bisectors_point = np.append(first_bisectors_point, first_point)\n                second_bisectors_point = np.append(second_bisectors_point, second_point)\n                num_iterations += 1\n\n        if num_iterations < self.params.num_bisectors:\n            raise EyeCentersEstimationError(\n                \"Failed to find a sufficient number of points that meet the minimum distance criterion within the maximum number of iterations allowed. This indicates that it may not be possible to accurately estimate the center of the shape.\"\n            )\n\n        return first_bisectors_point, second_bisectors_point\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_vertices = polygon.shape[0]\n\n        # The number of iterations is equal to the number of pairs of points to be chosen.\n        for iteration in range(self.params.num_bisectors):\n            # Randomly select two points from the polygon.\n            first_point_index = np.random.randint(num_vertices)\n            second_point_index = np.random.randint(num_vertices)\n            first_point = polygon[first_point_index]\n            second_point = polygon[second_point_index]\n\n            # Ensure that the distance between the points is greater than the minimum distance criterion.\n            distance_between_points = np.linalg.norm(first_point - second_point)\n            if distance_between_points < min_distance_between_sector_points_in_px:\n                continue\n\n            # Calculate the perpendicular bisector of the two points.\n            slope = (first_point[1] - second_point[1]) / (first_point[0] - second_point[0])\n            slope_perp = -1 / slope\n            intercept = first_point[1] - slope * first_point[0]\n            intercept_perp = -intercept / slope_perp\n\n            # Calculate the starting and ending points of the bisector.\n            first_bisector_point = np.array([0, intercept_perp])\n            second_bisector_point = np.array([distance_between_points, slope_perp * distance_between_points + intercept_perp])\n\n            return first_bisector_point, second_bisector_point\n\n        raise EyeCentersEstimationError(\n            f\"Could not find a sufficient number of point pairs that meet the distance criterion within {self.params.max_iterations} iterations.\"\n        )\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Initialize the lists of starting and ending points for the perpendicular bisectors.\n        first_bisectors_point = []\n        second_bisectors_point = []\n\n        # Initialize a counter to track the number of iterations.\n        iteration_counter = 0\n\n        # Loop until the number of bisectors is reached.\n        while len(first_bisectors_point) < self.params.num_bisectors:\n\n            # Choose two random points from the polygon.\n            first_point = self._select_random_point_from_polygon(polygon)\n            second_point = self._select_random_point_from_polygon(polygon)\n\n            # Calculate the distance between the two points.\n            distance_between_points = self._calculate_distance_between_two_points(first_point, second_point)\n\n            # If the distance is greater than the minimum distance between points, calculate the perpendicular bisector and add it to the lists.\n            if distance_between_points > min_distance_between_sector_points_in_px:\n                first_bisectors_point.append(first_point)\n                second_bisectors_point.append(second_point)\n\n            # Increment the counter.\n            iteration_counter += 1\n\n            # If the maximum number of iterations has been reached, raise an exception.\n            if iteration_counter == self.params.max_iterations:\n                raise EyeCentersEstimationError(\"Could not find sufficient number of points for perpendicular bisectors\")\n\n        return np.array(first_bisectors_point), np.array(second_bisectors_point)\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_iterations = 0\n        num_points = polygon.shape[0]\n\n        # Initialize two empty lists for storing the starting and ending points of the perpendicular bisectors.\n        first_bisectors_points = []\n        second_bisectors_points = []\n\n        # Calculate the distance between each pair of points in the polygon.\n        distances = np.linalg.norm(polygon - np.roll(polygon, -1, axis=0), axis=1)\n\n        # While the number of perpendicular bisectors found is less than the specified number of bisectors, continue searching.\n        while len(first_bisectors_points) < self.params.num_bisectors:\n\n            # If the number of iterations has exceeded the maximum number of iterations, raise an exception.\n            if num_iterations >= self.params.max_iterations:\n                raise EyeCentersEstimationError(\"Failed to find sufficient number of point pairs.\")\n\n            # Generate two random indices for the polygon vertices.\n            first_point_index = np.random.randint(num_points)\n            second_point_index = np.random.randint(num_points)\n\n            # If the two indices are the same, skip this iteration.\n            if first_point_index == second_point_index:\n                continue\n\n            # If the two points are too close to each other, skip this iteration.\n            if distances[first_point_index, second_point_index] < min_distance_between_sector_points_in_px:\n                continue\n\n            # Add the two points to the list of starting and ending points of the perpendicular bisectors.\n            first_bisectors_points.append(polygon[first_point_index])\n            second_bisectors_points.append(polygon[second_point_index])\n\n            # Increment the number of iterations.\n            num_iterations += 1\n\n        # Convert the lists of points to numpy arrays.\n        first_bisectors_points = np.array(first_bisectors_points)\n        second_bisectors_points = np.array(second_bisectors_points"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_points = polygon.shape[0]\n        if num_points < 4:\n            raise EyeCentersEstimationError(\"Polygon must have at least 4 points\")\n\n        # Find the indices of the points to be used to calculate the perpendicular bisectors.\n        # The points are chosen randomly, ensuring that there is a minimum distance between any two points.\n        # The maximum number of iterations is set in the algorithm's parameters.\n        # If the algorithm fails to find a sufficient number of points within the maximum number of iterations,\n        # it raises an exception.\n        first_points_indices = []\n        second_points_indices = []\n        for _ in range(self.params.num_bisectors):\n            first_point_index, second_point_index = self._get_pair_of_points_with_min_distance(\n                polygon, min_distance_between_sector_points_in_px\n            )\n            first_points_indices.append(first_point_index)\n            second_points_indices.append(second_point_index)\n\n        # Calculate the coordinates of the starting points of the perpendicular bisectors.\n        first_bisectors_points = polygon[first_points_indices]\n\n        # Calculate the coordinates of the ending points of the perpendicular bisectors.\n        second_bisectors_points = polygon[second_points_indices]\n\n        return first_bisectors_points, second_bisectors_points\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.on_algorithm_start(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.on_algorithm_end(self, result, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_run(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_run(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.on_algorithm_start(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.on_algorithm_end(self, result, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.on_algorithm_start(self, *args, **kwargs)\n\n        result = self._execute(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.on_algorithm_end(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execution_hook(self, *args, **kwargs)\n\n        result = self._run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_execution_hook(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.on_algorithm_start(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.on_algorithm_end(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.on_algorithm_start(self, *args, **kwargs)\n\n        result = self._execute(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.on_algorithm_end(self, result, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.on_algorithm_begin(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.on_algorithm_end(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_run_algorithm(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_run_algorithm(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_run(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_run(self, result, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.on_algorithm_start(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.on_algorithm_end(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_run(self, *args, **kwargs)\n\n        result = self._run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_run(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_run(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_run(self, result, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        # pre-execution hooks\n        for callback in self._callbacks:\n            callback.pre_exec(self, *args, **kwargs)\n\n        # run method\n        result = self.run(*args, **kwargs)\n\n        # post-execution hooks\n        for callback in self._callbacks:\n            callback.post_exec(self, result, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.on_algorithm_begin(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.on_algorithm_end(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.on_algorithm_begin(self, *args, **kwargs)\n\n        result = self._run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.on_algorithm_end(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        self._execute_pre_hooks(*args, **kwargs)\n        result = self._execute_run(*args, **kwargs)\n        self._execute_post_hooks(*args, **kwargs)\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.on_algorithm_begin(self, *args, **kwargs)\n\n        result = self._run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.on_algorithm_end(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execution_hook(self, *args, **kwargs)\n        result = self._run(*args, **kwargs)\n        for callback in self._callbacks:\n            callback.post_execution_hook(self, result, *args, **kwargs)\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(self, *args, **kwargs)\n\n        result = self._execute(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_execute(self, result, *args, **kwargs)\n\n        return result\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        # Deserialize the output string\n        try:\n            deserialized_output = json.loads(output)\n        except:\n            return False\n\n        # Check if the deserialized output matches the type definition\n        return self.check_type(deserialized_output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            output = json.loads(output)\n            return self.validate_type(output, type_definition)\n        except Exception as e:\n            return False\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except Exception as e:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n            return self.check_type(deserialized_output, type_definition)\n        except:\n            return False\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except:\n            return False\n        return self.check_type(deserialized_output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n        return self.check_type(deserialized_output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.decoder.JSONDecodeError:\n            return False\n        return self.check_type(deserialized_output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n        return self.check_type(deserialized_output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n            return self.check_type(deserialized_output, type_definition)\n        except json.JSONDecodeError:\n            return False\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n            return self.validate_type(deserialized_output, type_definition)\n        except Exception:\n            return False\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n        return self.check_type(output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except:\n            return False\n        return self.check_type(deserialized_output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n        return self.check_type(output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            output_dict = json.loads(output)\n        except Exception as e:\n            return False\n\n        return self.check_type(output_dict, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        if output is None:\n            return True\n        try:\n            deserialized_output = json.loads(output)\n            return self.check_type(deserialized_output, type_definition)\n        except:\n            return False\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n            return self.check_type(deserialized_output, type_definition)\n        except:\n            return False\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        if not output:\n            return False\n        try:\n            deserialized_output = json.loads(output)\n        except:\n            return False\n        return self.check_type(deserialized_output, type_definition)\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get function name and docstring\n        func_name = func_object.__name__\n        docstring = inspect.getdoc(func_object)\n\n        # Get function signature\n        signature = inspect.signature(func_object)\n\n        # Get type hints\n        type_hints = get_type_hints(func_object)\n\n        # Get input and output type hints\n        input_type_hints = {}\n        output_type_hints = {}\n        for param in signature.parameters.values():\n            if param.name in type_hints:\n                input_type_hints[param.name] = type_hints[param.name]\n        if func_name in type_hints:\n            output_type_hints[func_name] = type_hints[func_name]\n\n        # Get class definitions for input and output type hints\n        input_class_definitions = {}\n        for param_name, param_type in input_type_hints.items():\n            input_class_definitions[param_name] = Register.get_class_definition(param_type)\n\n        output_class_definitions = {}\n        if len(output_type_hints) > 0:\n            output_type_hint = list(output_type_hints.values())[0]\n            output_class_definitions[func_name] = Register.get_class_definition(output_type_hint)\n\n        # Determine function type\n        if len(output_class_definitions) == 0:\n            function_type = FunctionType.SYMBOLIC\n        else:\n            output_class_definition = list(output_class_definitions.values())[0]\n            if issubclass(output_class_definition, Embedding):\n                function_type = FunctionType.EMBEDDABLE\n            else:\n                function_type = FunctionType.SYMBOLIC\n\n        # Return function description\n        return FunctionDescription(\n            name=func_name,\n            docstring=docstring,\n            input_type_hints=input_type_hints,\n            output"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get function name\n        func_name = func_object.__name__\n\n        # Get function signature\n        signature = inspect.signature(func_object)\n\n        # Get input and output type hints\n        input_type_hints = get_type_hints(func_object)\n        output_type_hints = get_type_hints(func_object).pop(\"return\", None)\n\n        # Get input and output class definitions\n        input_class_definitions = {}\n        output_class_definitions = {}\n        for key, value in input_type_hints.items():\n            input_class_definitions[key] = Register.get_class_definition(value)\n        if output_type_hints is not None:\n            output_class_definitions = Register.get_class_definition(output_type_hints)\n\n        # Get function type\n        if output_type_hints is None:\n            function_type = FunctionType.SYMBOLIC\n        elif issubclass(output_class_definitions[\"class\"], Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        elif get_origin(output_class_definitions[\"class\"]) is Union:\n            if any(issubclass(cls, Embedding) for cls in output_class_definitions[\"class_args\"]):\n                function_type = FunctionType.EMBEDDABLE\n            else:\n                function_type = FunctionType.SYMBOLIC\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        # Get function description\n        function_description = FunctionDescription(\n            name=func_name,\n            docstring=inspect.getdoc(func_object),\n            signature=signature,\n            input_type_hints=input_type_hints,\n            output_type_hints=output_type_hints,\n            input_class_definitions=input_class_definitions,\n            output_class_definitions=output_class_definitions,\n            type=function_type,\n            source=get_source(func_object)\n        )\n        return function"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        if not callable(func_object):\n            raise TypeError(\"Function object must be callable\")\n\n        # Get function name\n        func_name = func_object.__name__\n\n        # Get function signature\n        signature = inspect.signature(func_object)\n\n        # Get function docstring\n        docstring = inspect.getdoc(func_object)\n\n        # Get input and output type hints\n        input_type_hints = get_type_hints(func_object)\n        output_type_hints = input_type_hints.pop(\"return\", None)\n\n        # Get input and output class definitions\n        input_class_definition = Register.get_class_definition(input_type_hints)\n        output_class_definition = Register.get_class_definition(output_type_hints)\n\n        # Determine function type\n        if output_class_definition is not None:\n            if issubclass(output_class_definition, Embedding):\n                function_type = FunctionType.EMBEDDABLE\n            else:\n                function_type = FunctionType.SYMBOLIC\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        # Create function description\n        function_description = FunctionDescription(\n            name=func_name,\n            docstring=docstring,\n            signature=signature,\n            input_type_hints=input_type_hints,\n            output_type_hints=output_type_hints,\n            input_class_definition=input_class_definition,\n            output_class_definition=output_class_definition,\n            type=function_type,\n            source=get_source(func_object)\n        )\n\n        return function_description\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        input_type_hint = type_hints.get(\"return\", None)\n        output_type_hint = type_hints.get(\"return\", None)\n\n        input_class_def = Register.get_class_definition(input_type_hint)\n        output_class_def = Register.get_class_definition(output_type_hint)\n\n        if issubclass(output_class_def, Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        elif get_origin(output_type_hint) == Union:\n            if any([issubclass(class_def, Embedding) for class_def in output_type_hint.__args__]):\n                function_type = FunctionType.EMBEDDABLE\n            else:\n                function_type = FunctionType.SYMBOLIC\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=inspect.getdoc(func_object),\n            input_type=input_type_hint,\n            output_type=output_type_hint,\n            input_class_def=input_class_def,\n            output_class_def=output_class_def,\n            type=function_type\n        )\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get function name\n        func_name = func_object.__name__\n\n        # Get function signature\n        sig = inspect.signature(func_object)\n\n        # Get type hints\n        type_hints = get_type_hints(func_object)\n\n        # Get docstring\n        docstring = func_object.__doc__\n\n        # Get input and output type hints\n        input_type_hint = type_hints[\"return\"]\n        output_type_hint = type_hints[\"return\"]\n\n        for parameter in sig.parameters.values():\n            if parameter.name in type_hints:\n                if parameter.kind == inspect.Parameter.POSITIONAL_OR_KEYWORD:\n                    input_type_hint = type_hints[parameter.name]\n                elif parameter.kind == inspect.Parameter.VAR_KEYWORD:\n                    input_type_hint = Dict[str, type_hints[parameter.name]]\n                elif parameter.kind == inspect.Parameter.VAR_POSITIONAL:\n                    input_type_hint = Tuple[type_hints[parameter.name], ...]\n\n        # Get class definitions for type hints\n        input_class_definition = Register.get_class_definition(input_type_hint)\n        output_class_definition = Register.get_class_definition(output_type_hint)\n\n        # Determine function type\n        function_type = FunctionType.SYMBOLIC\n        if get_origin(output_type_hint) is Union:\n            for arg in get_args(output_type_hint):\n                if issubclass(arg, Embedding):\n                    function_type = FunctionType.EMBEDDABLE\n\n        # Return function description\n        return FunctionDescription(\n            name=func_name,\n            input_class_definition=input_class_definition,\n            output_class_definition=output_class_definition,\n            input_type_hint=input_type_hint,\n            output_type_hint=output_type_hint,\n            function_type=function_type,\n           "}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get function name\n        func_name = func_object.__name__\n\n        # Get function signature\n        signature = inspect.signature(func_object)\n\n        # Get input type hints\n        input_type_hints = get_type_hints(func_object)\n        input_type_hints = {\n            key: value\n            for key, value in input_type_hints.items()\n            if key != \"return\"\n        }\n\n        # Get output type hint\n        output_type_hint = get_type_hints(func_object)[\"return\"]\n\n        # Get function docstring\n        docstring = func_object.__doc__\n\n        # Get class definitions for input and output type hints\n        input_class_definitions = {\n            key: get_class_definition(value)\n            for key, value in input_type_hints.items()\n        }\n        output_class_definition = get_class_definition(output_type_hint)\n\n        # Get function type\n        if get_origin(output_type_hint) == Union:\n            if Embedding in get_args(output_type_hint):\n                function_type = FunctionType.EMBEDDABLE\n            else:\n                function_type = FunctionType.SYMBOLIC\n        elif issubclass(output_type_hint, Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        # Return function description\n        return FunctionDescription(\n            name=func_name,\n            signature=signature,\n            input_type_hints=input_type_hints,\n            output_type_hint=output_type_hint,\n            input_class_definitions=input_class_definitions,\n            output_class_definition=output_class_definition,\n            function_type=function_type,\n            docstring=docstring,\n        )\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        func_name = func_object.__name__\n        docstring = inspect.getdoc(func_object)\n        signature = inspect.signature(func_object)\n        input_type_hints = get_type_hints(func_object)\n        output_type_hints = input_type_hints.pop(\"return\", None)\n\n        input_class_definition = Register.get_class_definition(input_type_hints)\n        output_class_definition = Register.get_class_definition(output_type_hints)\n\n        function_type = Register.get_function_type(output_class_definition)\n\n        return FunctionDescription(\n            name=func_name,\n            docstring=docstring,\n            input_class_definition=input_class_definition,\n            output_class_definition=output_class_definition,\n            function_type=function_type\n        )\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get function name and docstring\n        func_name = func_object.__name__\n        docstring = func_object.__doc__\n\n        # Get function signature and type hints\n        sig = inspect.signature(func_object)\n        hints = get_type_hints(func_object)\n\n        # Get input and output type hints\n        input_type_hint = hints.get(\"return\", None)\n        output_type_hint = hints.get(\"return\", None)\n        for param in sig.parameters.values():\n            if param.name not in [\"return\", \"self\"]:\n                input_type_hint = hints.get(param.name, None)\n                break\n\n        # Get class definitions for type hints\n        input_class_definition = Register.get_class_definition(input_type_hint)\n        output_class_definition = Register.get_class_definition(output_type_hint)\n\n        # Get function type\n        if output_class_definition is None:\n            function_type = FunctionType.EMBEDDABLE\n        elif issubclass(output_class_definition, Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        elif get_origin(output_class_definition) is Union:\n            for arg in get_args(output_class_definition):\n                if issubclass(arg, Embedding):\n                    function_type = FunctionType.EMBEDDABLE\n                    break\n            else:\n                function_type = FunctionType.SYMBOLIC\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        return FunctionDescription(\n            func_name=func_name,\n            docstring=docstring,\n            input_type_hint=input_type_hint,\n            output_type_hint=output_type_hint,\n            input_class_definition=input_class_definition,\n            output_class_definition=output_class_definition,\n            function_type=function_type\n        )\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        sig = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        input_type_hint = type_hints[list(sig.parameters.keys())[0]]\n        output_type_hint = type_hints[sig.return_annotation]\n\n        input_class_def = Register.get_class_definition(input_type_hint)\n        output_class_def = Register.get_class_definition(output_type_hint)\n\n        func_type = FunctionType.SYMBOLIC\n        if get_origin(output_type_hint) == Union:\n            for type_ in output_type_hint.__args__:\n                if issubclass(type_, Embedding):\n                    func_type = FunctionType.EMBEDDABLE\n                    output_class_def = Register.get_class_definition(type_)\n                    break\n        elif issubclass(output_type_hint, Embedding):\n            func_type = FunctionType.EMBEDDABLE\n            output_class_def = Register.get_class_definition(output_type_hint)\n\n        return FunctionDescription(\n            func_object.__name__,\n            func_object.__doc__,\n            input_type_hint,\n            input_class_def,\n            output_type_hint,\n            output_class_def,\n            func_type\n        )\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get function name and signature\n        func_name = func_object.__name__\n        signature = inspect.signature(func_object)\n\n        # Get input and output type hints\n        input_hints = get_type_hints(func_object)\n        input_hints = {key: input_hints[key] for key in input_hints.keys() if key != \"return\"}\n        output_hint = get_type_hints(func_object)[\"return\"]\n\n        # Get input and output class definitions\n        input_class_defs = {}\n        for input_name in input_hints.keys():\n            input_class_defs[input_name] = Register.get_class_definition(input_hints[input_name])\n        output_class_def = Register.get_class_definition(output_hint)\n\n        # Get function type\n        if get_origin(output_hint) is Union:\n            output_class_defs = [Register.get_class_definition(arg) for arg in get_args(output_hint)]\n            if Embedding in [arg for arg in get_args(output_hint)]:\n                func_type = FunctionType.EMBEDDABLE\n            else:\n                func_type = FunctionType.SYMBOLIC\n        elif issubclass(output_hint, Embedding):\n            func_type = FunctionType.EMBEDDABLE\n            output_class_defs = [output_class_def]\n        else:\n            func_type = FunctionType.SYMBOLIC\n            output_class_defs = [output_class_def]\n\n        # Get docstring\n        docstring = inspect.getdoc(func_object)\n        if docstring is None:\n            docstring = \"\"\n\n        # Get source\n        source = get_source(func_object)\n        if source is None:\n            source = \"\"\n\n        # Return function description\n        return FunctionDescription(\n            func_name,\n            docstring,\n            source,\n            input_hints,\n            input_class_defs,\n            output"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        func_name = func_object.__name__\n        func_doc = inspect.getdoc(func_object)\n        func_sig = inspect.signature(func_object)\n        func_type_hints = get_type_hints(func_object)\n        func_type_hints = {key: value for key, value in func_type_hints.items() if key in func_sig.parameters}\n\n        input_class_defs = {}\n        for input_arg_name, input_arg_type in func_type_hints.items():\n            input_class_defs[input_arg_name] = Register.get_class_definition(input_arg_type)\n\n        output_arg_name = list(func_sig.parameters.keys())[-1]\n        output_arg_type = func_type_hints[output_arg_name]\n        output_class_def = Register.get_class_definition(output_arg_type)\n\n        if get_origin(output_arg_type) == Union:\n            if any([issubclass(x, Embedding) for x in output_arg_type.__args__]):\n                func_type = FunctionType.EMBEDDABLE\n            else:\n                func_type = FunctionType.SYMBOLIC\n        elif issubclass(output_arg_type, Embedding):\n            func_type = FunctionType.EMBEDDABLE\n        else:\n            func_type = FunctionType.SYMBOLIC\n\n        return FunctionDescription(\n            name=func_name,\n            doc=func_doc,\n            type=func_type,\n            input_class_defs=input_class_defs,\n            output_class_def=output_class_def\n        )\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get function name\n        name = func_object.__name__\n\n        # Get function signature and type hints\n        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n\n        # Get input type hints\n        input_type_hints = {}\n        for param in signature.parameters.values():\n            input_type_hints[param.name] = type_hints.get(param.name, None)\n\n        # Get output type hint\n        output_type_hints = type_hints.get(\"return\", None)\n\n        # Get function docstring\n        docstring = inspect.getdoc(func_object)\n\n        # Get class definitions\n        input_class_defs = {}\n        for param in signature.parameters.values():\n            input_class_defs[param.name] = Register.get_class_definition(input_type_hints[param.name])\n\n        output_class_def = Register.get_class_definition(output_type_hints)\n\n        # Get function type\n        if output_class_def is None:\n            function_type = FunctionType.SYMBOLIC\n        elif issubclass(output_class_def, Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        return FunctionDescription(\n            name=name,\n            input_class_defs=input_class_defs,\n            output_class_def=output_class_def,\n            function_type=function_type,\n            docstring=docstring\n        )\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get function signature and type hints\n        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n\n        # Get input and output type hints\n        input_type_hint = type_hints.get(\"return\", None)\n        output_type_hint = type_hints.get(\"return\", None)\n        for param in signature.parameters.values():\n            if param.annotation != inspect.Parameter.empty:\n                input_type_hint = param.annotation\n            if param.name == \"return\":\n                output_type_hint = param.annotation\n\n        # Get class definitions\n        input_class_definition = Register.get_class_definition(input_type_hint)\n        output_class_definition = Register.get_class_definition(output_type_hint)\n\n        # Determine function type\n        function_type = Register.get_function_type(output_type_hint)\n\n        # Get docstring\n        docstring = inspect.getdoc(func_object)\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            input_class_definition=input_class_definition,\n            output_class_definition=output_class_definition,\n            type=function_type,\n            docstring=docstring\n        )\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get function signature\n        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n\n        # Get input type hints\n        input_type_hints = {}\n        for key in signature.parameters.keys():\n            if key in type_hints:\n                input_type_hints[key] = type_hints[key]\n\n        # Get output type hint\n        output_type_hint = type_hints.get(\"return\", None)\n\n        # Get function name\n        func_name = func_object.__name__\n\n        # Get docstring\n        docstring = func_object.__doc__\n\n        # Get input class definitions\n        input_class_definitions = {}\n        for key, type_hint in input_type_hints.items():\n            input_class_definitions[key] = Register.get_class_definition(type_hint)\n\n        # Get output class definition\n        output_class_definition = Register.get_class_definition(output_type_hint)\n\n        # Get function type\n        if output_type_hint is not None:\n            if Register.is_embeddable_type(output_type_hint):\n                func_type = FunctionType.EMBEDDABLE\n            else:\n                func_type = FunctionType.SYMBOLIC\n        else:\n            func_type = FunctionType.SYMBOLIC\n\n        # Create function description\n        function_description = FunctionDescription(\n            func_name,\n            docstring,\n            input_type_hints,\n            output_type_hint,\n            input_class_definitions,\n            output_class_definition,\n            func_type\n        )\n\n        return function_description\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        if not callable(func_object):\n            raise TypeError(\"func_object must be a callable\")\n\n        func_name = func_object.__name__\n        signature = inspect.signature(func_object)\n        input_type_hints = get_type_hints(func_object)\n        docstring = get_source(func_object)\n\n        input_class_defs = {}\n        for arg_name, arg_type in input_type_hints.items():\n            if arg_name == \"return\":\n                continue\n            input_class_defs[arg_name] = get_class_definition(arg_type)\n\n        output_type_hint = input_type_hints[\"return\"]\n        output_class_def = get_class_definition(output_type_hint)\n\n        if get_origin(output_type_hint) == Union:\n            output_class_def = [get_class_definition(arg) for arg in output_type_hint.__args__]\n            if any([issubclass(arg, Embedding) for arg in output_class_def]):\n                function_type = FunctionType.EMBEDDABLE\n            else:\n                function_type = FunctionType.SYMBOLIC\n        elif issubclass(output_type_hint, Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        return FunctionDescription(\n            name=func_name,\n            docstring=docstring,\n            input_class_defs=input_class_defs,\n            output_class_def=output_class_def,\n            function_type=function_type\n        )\n\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get function name and docstring\n        name = func_object.__name__\n        docstring = inspect.getdoc(func_object)\n\n        # Get signature and type hints\n        sig = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n\n        # Get input type hint\n        input_type_hint = type_hints[list(sig.parameters.keys())[0]]\n\n        # Get output type hint\n        output_type_hint = type_hints[list(sig.parameters.keys())[-1]]\n\n        # Get input and output class definitions\n        input_class_definition = Register.get_class_definition(input_type_hint)\n        output_class_definition = Register.get_class_definition(output_type_hint)\n\n        # Determine function type\n        if get_origin(output_type_hint) == Union:\n            if Embedding in get_args(output_type_hint):\n                func_type = FunctionType.EMBEDDABLE\n            else:\n                func_type = FunctionType.SYMBOLIC\n        elif issubclass(output_type_hint, Embedding):\n            func_type = FunctionType.EMBEDDABLE\n        else:\n            func_type = FunctionType.SYMBOLIC\n\n        # Create function description\n        return FunctionDescription(name, docstring, input_class_definition, output_class_definition, func_type)\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        input_type_hints = {}\n        output_type_hints = {}\n        for key in signature.parameters.keys():\n            if key in type_hints:\n                input_type_hints[key] = type_hints[key]\n        if 'return' in type_hints:\n            output_type_hints['return'] = type_hints['return']\n\n        input_class_definition = Register.get_class_definition(input_type_hints)\n        output_class_definition = Register.get_class_definition(output_type_hints)\n\n        if len(output_class_definition) == 0:\n            raise TypeError(f\"Function {func_object.__name__} must have an output type hint\")\n        elif len(output_class_definition) > 1:\n            raise TypeError(f\"Function {func_object.__name__} has multiple output type hints\")\n\n        output_class_definition = output_class_definition[0]\n\n        if output_class_definition.type == Embedding:\n            func_type = FunctionType.EMBEDDABLE\n        elif get_origin(output_class_definition.type) == Union and Embedding in get_args(output_class_definition.type):\n            func_type = FunctionType.EMBEDDABLE\n        else:\n            func_type = FunctionType.SYMBOLIC\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=inspect.getdoc(func_object),\n            input_class_definition=input_class_definition,\n            output_class_definition=output_class_definition,\n            func_type=func_type\n        )\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get function signature\n        signature = inspect.signature(func_object)\n\n        # Get type hints\n        type_hints = get_type_hints(func_object)\n\n        # Get docstring\n        docstring = inspect.getdoc(func_object)\n\n        # Get input and output type hints\n        input_type_hint = type_hints[\"return\"]\n        output_type_hints = type_hints[\"return\"]\n\n        # Get class definitions\n        input_class_definition = Register.get_class_definition(input_type_hint)\n        output_class_definition = Register.get_class_definition(output_type_hint)\n\n        # Get function type\n        function_type = Register.get_function_type(output_type_hint)\n\n        # Create function description\n        function_description = FunctionDescription(\n            func_object.__name__,\n            docstring,\n            input_type_hint,\n            output_type_hint,\n            input_class_definition,\n            output_class_definition,\n            function_type\n        )\n\n        return function_description\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        if not callable(func_object):\n            raise ValueError(\"func_object must be callable\")\n\n        func_name = func_object.__name__\n        signature = inspect.signature(func_object)\n        input_type_hints = get_type_hints(func_object)\n        output_type_hints = get_type_hints(func_object).get(\"return\", None)\n        docstring = func_object.__doc__\n\n        input_class_definition = Register.get_class_definition(input_type_hints)\n        output_class_definition = Register.get_class_definition(output_type_hints)\n\n        if not output_class_definition:\n            raise ValueError(f\"No output class definition for function {func_name}\")\n\n        if get_origin(output_class_definition) is Union:\n            output_class_definition = next(\n                (\n                    class_def\n                    for class_def in output_class_definition.__args__\n                    if issubclass(class_def, Embedding)\n                ),\n                None,\n            )\n\n        if not output_class_definition:\n            raise ValueError(f\"No output class definition for function {func_name}\")\n\n        if issubclass(output_class_definition, Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        return FunctionDescription(\n            func_name,\n            signature,\n            input_type_hints,\n            output_type_hints,\n            input_class_definition,\n            output_class_definition,\n            function_type,\n            docstring,\n        )\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        func_name = func_object.__name__\n        docstring = inspect.getdoc(func_object)\n        signature = inspect.signature(func_object)\n\n        input_type_hints = get_type_hints(func_object)\n        input_class_definition = Register.get_class_definition(input_type_hints)\n\n        output_type_hint = input_type_hints[\"return\"]\n        output_class_definition = Register.get_class_definition(output_type_hint)\n\n        function_type = Register.get_function_type(output_type_hint)\n\n        return FunctionDescription(\n            name=func_name,\n            docstring=docstring,\n            input_class_definition=input_class_definition,\n            output_class_definition=output_class_definition,\n            type=function_type,\n            source=get_source(func_object)\n        )\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] = seed\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] = seed\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] = seed\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] = seed\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            #print(f\"Add: Seed={seed}, Digest={index}, BitValue={self.bit_array[index]}\")\n            self.bit_array[index] = 1\n            self.indices[index] = seed\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] = seed\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] = seed\n\n        return\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] = seed\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] = seed\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] = seed\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] = seed\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] = seed\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            #print(f\"Add: Seed={seed}, Digest={index}, BitValue={self.bit_array[index]}\")\n            self.bit_array[index] = 1\n            self.indices[index] = seed\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] = seed\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] = seed\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] = seed\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] = seed\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            #print(f\"Add: Seed={seed}, Digest={index}, BitValue={self.bit_array[index]}\")\n            self.bit_array[index] = 1\n            self.indices[index] = seed\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] = seed\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            #print(f\"Add: Seed={seed}, Digest={index}, BitValue={self.bit_array[index]}\")\n            self.bit_array[index] = 1\n            self.indices[index] = seed\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n        if len(bit_array) != self.size:\n            logging.warning(\"Loaded bit array length does not match expected length. Reinitializing bit array and indices.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n        if len(bit_array) != self.size:\n            logging.warning(f\"Bit array length mismatch. Expected length: {self.size}. Actual length: {len(bit_array)}. Reinitializing bit array and indices.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n        if len(bit_array) != self.size:\n            logging.warning(\"Bit array length mismatch. Reinitializing and saving.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n        if len(bit_array) != self.size:\n            logging.warning(\"Bit array length mismatch. Reinitializing bit array and indices.\")\n            bit_array, indices = self.init_bit_array(self.size)\n            self.persistence.save(bit_array)\n        else:\n            self.bit_array = bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n        if len(bit_array) != self.size:\n            logging.warning(\"Bit array length mismatch. Reinitializing bit array.\")\n            bit_array, indices = self.init_bit_array(self.size)\n            self.save()\n        self.bit_array = bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n        if len(bit_array) != self.size:\n            logging.warning(\"Loaded bit array length does not match expected length. Reinitializing.\")\n            self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n        if len(bit_array) != self.size:\n            logging.warning(\"Loaded bit array length does not match expected length. Reinitializing bit array and indices\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n        if len(bit_array) != self.size:\n            logging.warning(f\"Loaded bit array length ({len(bit_array)}) does not match expected size ({self.size}). Reinitializing bit array and indices.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n        if len(bit_array) != self.size:\n            logging.warning(\"Bit array length mismatch. Reinitializing bit array\")\n            bit_array, indices = self.init_bit_array(self.size)\n            self.save()\n        return bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n        if len(bit_array) != self.size:\n            logging.warning(f\"Bit array length mismatch. Expected: {self.size} Actual: {len(bit_array)}. Reinitializing bit array and indices.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"BloomFilter: Corrupted bit array. Reinitializing bit array and indices.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n        if len(bit_array) != self.size:\n            logging.warning(f\"Loaded bit array length {len(bit_array)} does not match expected length {self.size}. Reinitializing bit array and indices.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n        if len(bit_array) != self.size:\n            logging.warning(f\"Loaded bit array has length {len(bit_array)}, but expected length is {self.size}. Reinitializing and saving.\")\n            bit_array, indices = self.init_bit_array(self.size)\n            self.save()\n        self.bit_array = bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(f\"Loaded bit array length ({len(loaded_bit_array)}) does not match expected length ({self.size}). Reinitializing and saving.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n        if len(bit_array) != self.size:\n            logging.warning(f\"Loaded bit array length does not match expected length. Reinitializing bit array and indices.\")\n            bit_array, indices = self.init_bit_array(self.size)\n            self.save(bit_array)\n        self.bit_array = bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n        if len(bit_array) != self.size:\n            logging.warning(\"Loaded bit array length does not match BloomFilter size. Reinitializing bit array and indices.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n        if len(bit_array) != self.size:\n            logging.warning(\"Bit array length mismatch. Reinitializing bit array and indices\")\n            bit_array, indices = self.init_bit_array(self.size)\n            self.save()\n        return bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n        if len(bit_array) != self.size:\n            logging.warning(\"BloomFilter bit array length does not match expected length. Reinitializing.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n        if len(bit_array) != self.size:\n            logging.warning(\"Loaded bit array length does not match expected length. Reinitializing bit array and indices.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n        if len(bit_array) != self.size:\n            logging.warning(f\"Loaded bit array length does not match expected length. Reinitializing bit array and indices.\")\n            self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for i in range(self.hash_count):\n            index = (hash1 + i * hash2) % self.size\n            if self.bit_array[index] == 0:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        # Generate indices\n        hash1, hash2 = self.hash_functions(string)\n        indices = [(hash1 + i * hash2) % self.size for i in range(self.hash_count)]\n\n        # Check if all bits at these indices are set\n        for i in indices:\n            if self.bit_array[i] == 0:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for i in range(self.hash_count):\n            index = (hash1 + i * hash2) % self.size\n            if self.bit_array[index] == 0:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        indices = [(hash1 + i * hash2) % self.size for i in range(self.hash_count)]\n        for i in indices:\n            if self.bit_array[i] == 0:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for i in range(self.hash_count):\n            index = (hash1 + i * hash2) % self.size\n            if self.bit_array[index] == 0:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n\n        for i in range(self.hash_count):\n            index = (hash1 + i * hash2) % self.size\n            if self.bit_array[index] == 0:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for i in range(self.hash_count):\n            index = (hash1 + i * hash2) % self.size\n            if self.bit_array[index] == 0:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        # generate indices\n        indices = self.hash_functions(string)\n\n        # check if all bits are set\n        for idx in indices:\n            if not self.bit_array[idx]:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        # Generate indices\n        indices = [self.hash_functions(string + str(i))[0] % self.size for i in range(self.hash_count)]\n\n        # Check if all bits at these indices are set\n        for i in indices:\n            if self.bit_array[i] == 0:\n                return False\n\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n\n        for i in range(self.hash_count):\n            index = (hash1 + i * hash2) % self.size\n            if self.bit_array[index] == 0:\n                return False\n\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for i in range(self.hash_count):\n            index = hash1 + i * hash2\n            index = index % self.size\n            if self.bit_array[index] == 0:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        indices = self.hash_functions(string) % self.size\n        for i in range(self.hash_count):\n            if self.bit_array[indices[i]] == 0:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        indices = [hash1 % self.size for _ in range(self.hash_count)]\n        return all(self.bit_array[indices])\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        indices = [hash1 % self.size for _ in range(self.hash_count)]\n        return all(self.bit_array[indices])\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        indices = [hash1 % self.size, hash2 % self.size]\n        for i in range(self.hash_count):\n            if self.bit_array[indices[i % 2]] == 0:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        # Generate the indices\n        indices = [self.hash_functions(string)[i % 2] % self.size for i in range(self.hash_count)]\n\n        # Check if all bits at these indices are set in the bit array\n        for i in indices:\n            if self.bit_array[i] == 0:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n\n        for i in range(self.hash_count):\n            index = (hash1 + i * hash2) % self.size\n            if self.bit_array[index] == 0:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        indices = np.array([(hash1 + i * hash2) % self.size for i in range(self.hash_count)])\n        return np.all(self.bit_array[indices])\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        # hash_functions generates the hashes\n        # indices is the array of indices\n        # bit_array is the bit array\n        # hash_count is the number of hash functions\n        # size is the size of the bit array\n        indices = [self.hash_functions(string)[i % 2] % self.size for i in range(self.hash_count)]\n        return all(self.bit_array[indices])\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        # Generate the indices\n        indices = self.hash_functions(string)\n\n        # Check if the bits are set\n        for index in indices:\n            if not self.bit_array[index % self.size]:\n                return False\n        return True\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if DISTILLED_MODEL in json_dict:\n            self.distilled_model = config_factory.get_model_config(json_dict[DISTILLED_MODEL])\n        if TEACHER_MODEL in json_dict:\n            self.teacher_models = [config_factory.get_model_config(teacher_model) for teacher_model in json_dict[TEACHER_MODEL]]\n        if \"current_model_stats\" in json_dict:\n            self.current_model_stats = json_dict[\"current_model_stats\"]\n        if \"last_training_run\" in json_dict:\n            self.last_training_run = json_dict[\"last_training_run\"]\n        if \"current_training_run\" in json_dict:\n            self.current_training_run = json_dict[\"current_training_run\"]\n        if \"nr_of_training_runs\" in json_dict:\n            self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if \"distilled_model\" in json_dict:\n            self.distilled_model = config_factory.create_model_config(json_dict[\"distilled_model\"][\"type\"], json_dict[\"distilled_model\"])\n        if \"current_model_stats\" in json_dict:\n            self.current_model_stats = json_dict[\"current_model_stats\"]\n        if \"last_training_run\" in json_dict:\n            self.last_training_run = json_dict[\"last_training_run\"]\n        if \"current_training_run\" in json_dict:\n            self.current_training_run = json_dict[\"current_training_run\"]\n        if \"nr_of_training_runs\" in json_dict:\n            self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.create_model_config(teacher_model[\"type\"], teacher_model) for teacher_model in json_dict[\"teacher_models\"]]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.get_model_config(json_dict[\"distilled_model\"])\n        self.current_model_stats = json_dict[\"current_model_stats\"]\n        self.last_training_run = json_dict[\"last_training_run\"]\n        self.current_training_run = json_dict[\"current_training_run\"]\n        self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        self.teacher_models = [config_factory.get_model_config(teacher_model) for teacher_model in json_dict[\"teacher_models\"]]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if DISTILLED_MODEL in json_dict:\n            self.distilled_model = config_factory.create_model_config(json_dict[DISTILLED_MODEL])\n        if \"current_model_stats\" in json_dict:\n            self.current_model_stats = json_dict[\"current_model_stats\"]\n        if \"last_training_run\" in json_dict:\n            self.last_training_run = json_dict[\"last_training_run\"]\n        if \"current_training_run\" in json_dict:\n            self.current_training_run = json_dict[\"current_training_run\"]\n        if \"nr_of_training_runs\" in json_dict:\n            self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = []\n            for teacher_model in json_dict[\"teacher_models\"]:\n                if teacher_model[TEACHER_MODEL] in DEFAULT_TEACHER_MODEL_NAMES:\n                    self.teacher_models.append(config_factory.create_model_config(teacher_model))\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if DISTILLED_MODEL in json_dict:\n            self.distilled_model = config_factory.create_model_config(json_dict[DISTILLED_MODEL])\n        if \"current_model_stats\" in json_dict:\n            self.current_model_stats = json_dict[\"current_model_stats\"]\n        if \"last_training_run\" in json_dict:\n            self.last_training_run = json_dict[\"last_training_run\"]\n        if \"current_training_run\" in json_dict:\n            self.current_training_run = json_dict[\"current_training_run\"]\n        if \"nr_of_training_runs\" in json_dict:\n            self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = []\n            for teacher_model in json_dict[\"teacher_models\"]:\n                self.teacher_models.append(config_factory.create_model_config(teacher_model))\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if \"distilled_model\" in json_dict:\n            self.distilled_model = config_factory.create_model_config(json_dict[\"distilled_model\"][\"type\"], json_dict[\"distilled_model\"])\n        if \"current_model_stats\" in json_dict:\n            self.current_model_stats = json_dict[\"current_model_stats\"]\n        if \"last_training_run\" in json_dict:\n            self.last_training_run = json_dict[\"last_training_run\"]\n        if \"current_training_run\" in json_dict:\n            self.current_training_run = json_dict[\"current_training_run\"]\n        if \"nr_of_training_runs\" in json_dict:\n            self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.create_model_config(model_dict[\"type\"], model_dict) for model_dict in json_dict[\"teacher_models\"]]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if \"distilled_model\" in json_dict:\n            self.distilled_model = config_factory.create_model_config(json_dict[\"distilled_model\"])\n        if \"current_model_stats\" in json_dict:\n            self.current_model_stats = json_dict[\"current_model_stats\"]\n        if \"last_training_run\" in json_dict:\n            self.last_training_run = json_dict[\"last_training_run\"]\n        if \"current_training_run\" in json_dict:\n            self.current_training_run = json_dict[\"current_training_run\"]\n        if \"nr_of_training_runs\" in json_dict:\n            self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.create_model_config(teacher_model) for teacher_model in json_dict[\"teacher_models\"]]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if \"distilled_model\" in json_dict:\n            self.distilled_model = config_factory.create_model_config(json_dict[\"distilled_model\"])\n        if \"current_model_stats\" in json_dict:\n            self.current_model_stats = json_dict[\"current_model_stats\"]\n        if \"last_training_run\" in json_dict:\n            self.last_training_run = json_dict[\"last_training_run\"]\n        if \"current_training_run\" in json_dict:\n            self.current_training_run = json_dict[\"current_training_run\"]\n        if \"nr_of_training_runs\" in json_dict:\n            self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.create_model_config(teacher_model) for teacher_model in json_dict[\"teacher_models\"]]\n        return self\n\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if \"distilled_model\" in json_dict:\n            self.distilled_model = config_factory.get_model_config(json_dict[\"distilled_model\"][\"name\"], json_dict[\"distilled_model\"][\"params\"])\n        if \"current_model_stats\" in json_dict:\n            self.current_model_stats = json_dict[\"current_model_stats\"]\n        if \"last_training_run\" in json_dict:\n            self.last_training_run = json_dict[\"last_training_run\"]\n        if \"current_training_run\" in json_dict:\n            self.current_training_run = json_dict[\"current_training_run\"]\n        if \"nr_of_training_runs\" in json_dict:\n            self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = []\n            for teacher_model_dict in json_dict[\"teacher_models\"]:\n                self.teacher_models.append(config_factory.get_model_config(teacher_model_dict[\"name\"], teacher_model_dict[\"params\"]))\n        return self\n\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if \"distilled_model\" in json_dict:\n            self.distilled_model = config_factory.create_model_config(json_dict[\"distilled_model\"])\n        if \"current_model_stats\" in json_dict:\n            self.current_model_stats = json_dict[\"current_model_stats\"]\n        if \"last_training_run\" in json_dict:\n            self.last_training_run = json_dict[\"last_training_run\"]\n        if \"current_training_run\" in json_dict:\n            self.current_training_run = json_dict[\"current_training_run\"]\n        if \"nr_of_training_runs\" in json_dict:\n            self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.create_model_config(json_dict[\"teacher_models\"][i]) for i in range(len(json_dict[\"teacher_models\"]))]\n\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        # Distilled model\n        distilled_model_name = json_dict.get(\"distilled_model\", None)\n        if distilled_model_name is not None:\n            self.distilled_model = config_factory.get_model_config(distilled_model_name)\n\n        # Current model stats\n        current_model_stats = json_dict.get(\"current_model_stats\", None)\n        if current_model_stats is not None:\n            self.current_model_stats = current_model_stats\n\n        # Last training run\n        last_training_run = json_dict.get(\"last_training_run\", None)\n        if last_training_run is not None:\n            self.last_training_run = last_training_run\n\n        # Current training run\n        current_training_run = json_dict.get(\"current_training_run\", None)\n        if current_training_run is not None:\n            self.current_training_run = current_training_run\n\n        # Number of training runs\n        nr_of_training_runs = json_dict.get(\"nr_of_training_runs\", None)\n        if nr_of_training_runs is not None:\n            self.nr_of_training_runs = nr_of_training_runs\n\n        # Teacher models\n        teacher_models = json_dict.get(\"teacher_models\", None)\n        if teacher_models is not None:\n            self.teacher_models = []\n            for teacher_model_name in teacher_models:\n                self.teacher_models.append(config_factory.get_model_config(teacher_model_name))\n\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if \"distilled_model\" in json_dict:\n            self.distilled_model = config_factory.create_model_config(json_dict[\"distilled_model\"][\"type\"], json_dict[\"distilled_model\"])\n        if \"current_model_stats\" in json_dict:\n            self.current_model_stats = json_dict[\"current_model_stats\"]\n        if \"last_training_run\" in json_dict:\n            self.last_training_run = json_dict[\"last_training_run\"]\n        if \"current_training_run\" in json_dict:\n            self.current_training_run = json_dict[\"current_training_run\"]\n        if \"nr_of_training_runs\" in json_dict:\n            self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.create_model_config(teacher_model[\"type\"], teacher_model) for teacher_model in json_dict[\"teacher_models\"]]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if \"distilled_model\" in json_dict:\n            self.distilled_model = config_factory.create_config(json_dict[\"distilled_model\"][\"type\"], json_dict[\"distilled_model\"])\n        if \"current_model_stats\" in json_dict:\n            self.current_model_stats = json_dict[\"current_model_stats\"]\n        if \"last_training_run\" in json_dict:\n            self.last_training_run = json_dict[\"last_training_run\"]\n        if \"current_training_run\" in json_dict:\n            self.current_training_run = json_dict[\"current_training_run\"]\n        if \"nr_of_training_runs\" in json_dict:\n            self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.create_config(teacher_model[\"type\"], teacher_model) for teacher_model in json_dict[\"teacher_models\"]]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if DISTILLED_MODEL in json_dict:\n            self.distilled_model = config_factory.get_config(json_dict[DISTILLED_MODEL])\n        if \"current_model_stats\" in json_dict:\n            self.current_model_stats = json_dict[\"current_model_stats\"]\n        if \"last_training_run\" in json_dict:\n            self.last_training_run = json_dict[\"last_training_run\"]\n        if \"current_training_run\" in json_dict:\n            self.current_training_run = json_dict[\"current_training_run\"]\n        if \"nr_of_training_runs\" in json_dict:\n            self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.get_config(model_dict) for model_dict in json_dict[\"teacher_models\"]]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.create_model_config(json_dict[\"distilled_model\"][\"name\"], json_dict[\"distilled_model\"])\n        self.current_model_stats = json_dict[\"current_model_stats\"]\n        self.last_training_run = json_dict[\"last_training_run\"]\n        self.current_training_run = json_dict[\"current_training_run\"]\n        self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        self.teacher_models = [config_factory.create_model_config(json_dict[\"teacher_models\"][i][\"name\"], json_dict[\"teacher_models\"][i]) for i in range(len(json_dict[\"teacher_models\"]))]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if \"distilled_model\" in json_dict:\n            self.distilled_model = config_factory.get_model_config(json_dict[\"distilled_model\"][\"name\"], json_dict[\"distilled_model\"])\n        if \"current_model_stats\" in json_dict:\n            self.current_model_stats = json_dict[\"current_model_stats\"]\n        if \"last_training_run\" in json_dict:\n            self.last_training_run = json_dict[\"last_training_run\"]\n        if \"current_training_run\" in json_dict:\n            self.current_training_run = json_dict[\"current_training_run\"]\n        if \"nr_of_training_runs\" in json_dict:\n            self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.get_model_config(teacher_model[\"name\"], teacher_model) for teacher_model in json_dict[\"teacher_models\"]]\n\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if \"distilled_model\" in json_dict:\n            self.distilled_model = config_factory.create_model_config(json_dict[\"distilled_model\"])\n        if \"current_model_stats\" in json_dict:\n            self.current_model_stats = json_dict[\"current_model_stats\"]\n        if \"last_training_run\" in json_dict:\n            self.last_training_run = json_dict[\"last_training_run\"]\n        if \"current_training_run\" in json_dict:\n            self.current_training_run = json_dict[\"current_training_run\"]\n        if \"nr_of_training_runs\" in json_dict:\n            self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.create_model_config(teacher_model) for teacher_model in json_dict[\"teacher_models\"]]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        distilled_model_name = json_dict.get(\"distilled_model\", DEFAULT_DISTILLED_MODEL_NAME)\n        self.distilled_model = DEFAULT_STUDENT_MODELS[distilled_model_name]\n        self.current_model_stats = json_dict.get(\"current_model_stats\", self.current_model_stats)\n        self.last_training_run = json_dict.get(\"last_training_run\", self.last_training_run)\n        self.current_training_run = json_dict.get(\"current_training_run\", self.current_training_run)\n        self.nr_of_training_runs = json_dict.get(\"nr_of_training_runs\", self.nr_of_training_runs)\n        self.teacher_models = [config_factory.get_model_config(teacher_model_name, TEACHER_MODEL) for teacher_model_name in json_dict.get(\"teacher_models\", DEFAULT_TEACHER_MODEL_NAMES)]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.create_model_config(json_dict[\"distilled_model\"][\"model_type\"], json_dict[\"distilled_model\"])\n        self.current_model_stats = json_dict[\"current_model_stats\"]\n        self.last_training_run = json_dict[\"last_training_run\"]\n        self.current_training_run = json_dict[\"current_training_run\"]\n        self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        self.teacher_models = []\n        for teacher_model_name in json_dict[\"teacher_models\"]:\n            self.teacher_models.append(config_factory.create_model_config(teacher_model_name[\"model_type\"], teacher_model_name))\n\n        return self\n\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.create_model_config(json_dict[\"distilled_model\"])\n        self.current_model_stats = json_dict[\"current_model_stats\"]\n        self.last_training_run = json_dict[\"last_training_run\"]\n        self.current_training_run = json_dict[\"current_training_run\"]\n        self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        self.teacher_models = [config_factory.create_model_config(teacher_model) for teacher_model in json_dict[\"teacher_models\"]]\n        return self\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Check for valid model name\n        if not model.model_name in self.get_model_list():\n            raise ValueError(f\"Invalid model name: {model.model_name}\")\n\n        # Check for valid parameters\n        for parameter in kwargs.keys():\n            if parameter not in LLM_GENERATION_PARAMETERS:\n                raise ValueError(f\"Invalid parameter: {parameter}\")\n\n        # Check for valid system message\n        if not isinstance(system_message, str):\n            raise ValueError(f\"Invalid system message: {system_message}\")\n\n        # Check for valid prompt\n        if not isinstance(prompt, str):\n            raise ValueError(f\"Invalid prompt: {prompt}\")\n\n        # Check for valid temperature\n        if \"temperature\" in kwargs:\n            if not isinstance(kwargs[\"temperature\"], float):\n                raise ValueError(f\"Invalid temperature: {kwargs['temperature']}\")\n\n        # Check for valid top_p\n        if \"top_p\" in kwargs:\n            if not isinstance(kwargs[\"top_p\"], float):\n                raise ValueError(f\"Invalid top_p: {kwargs['top_p']}\")\n\n        # Check for valid frequency_penalty\n        if \"frequency_penalty\" in kwargs:\n            if not isinstance(kwargs[\"frequency_penalty\"], float):\n                raise ValueError(f\"Invalid frequency_penalty: {kwargs['frequency_penalty']}\")\n\n        # Check for valid presence_penalty\n        if \"presence_penalty\" in kwargs:\n            if not isinstance(kwargs[\"presence_penalty\"], float):\n                raise ValueError(f\"Invalid presence_penalty: {kwargs['presence_penalty']}\")\n\n        # Check for valid max_new_tokens\n        if \"max_new_tokens\" in kwargs:\n            if not isinstance(kwargs[\"max_new_tokens\"], int):\n                raise ValueError(f\"Invalid max_new_tokens: {kwargs['max_new_tokens']}\")\n\n        # Check"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        # Verify the API key is valid\n        self.check_api_key()\n\n        # Verify the model is valid\n        self.check_model(model)\n\n        # Verify the parameters are valid\n        self.check_parameters(**kwargs)\n\n        # Generate the response\n        response = self.generate_response(model, system_message, prompt, **kwargs)\n\n        # Process the response\n        response = self.process_response(response, model)\n\n        return response\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n        if model.model_name == DEFAULT_DISTILLED_MODEL_NAME:\n            raise ValueError(f\"Distilled models are not supported for generation. Please select a different model.\")\n\n        if not isinstance(model, OpenAIConfig):\n            raise ValueError(f\"model must be of type OpenAIConfig, not {type(model)}\")\n\n        if not isinstance(system_message, str):\n            raise ValueError(f\"system_message must be of type str, not {type(system_message)}\")\n\n        if not isinstance(prompt, str):\n            raise ValueError(f\"prompt must be of type str, not {type(prompt)}\")\n\n        for param in LLM_GENERATION_PARAMETERS:\n            if param in kwargs and not isinstance(kwargs[param], (int, float)):\n                raise ValueError(f\"{param} must be of type int or float, not {type(kwargs[param])}\")\n\n        if \"temperature\" in kwargs and kwargs[\"temperature\"] < 0.0 or kwargs[\"temperature\"] > 1.0:\n            raise ValueError(f\"temperature must be between 0.0 and 1.0, not {kwargs['temperature']}\")\n\n        if \"top_p\" in kwargs and kwargs[\"top_p\"] < 0.0 or kwargs[\"top_p\"] > 1.0:\n            raise ValueError(f\"top_p must be between 0.0 and 1.0, not {kwargs['top_p']}\")\n\n        if \"frequency_penalty\" in kwargs and kwargs[\"frequency_penalty\"] < 0.0:\n            raise ValueError(f\"frequency_penalty must be greater than 0.0, not {kwargs['frequency_penalty']}\")\n\n        if \"presence_penalty\" in kwargs and kwargs[\"presence_penalty\"] < 0.0:\n            raise ValueError(f\"presence_penalty must be greater than 0.0, not {kwargs['presence_penalty"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Check if the API key is valid\n        try:\n            self.client.engine.list()\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n            return None\n\n        # Check if the model is valid\n        try:\n            self.client.engine.list(search=model.model_name)\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n            return None\n\n        # Check if the input parameters are valid\n        for parameter in kwargs.keys():\n            if parameter not in LLM_GENERATION_PARAMETERS:\n                print(f\"Invalid parameter: {parameter}\")\n                return None\n\n        # Generate the response\n        response = None\n        for i in range(5):\n            try:\n                response = self.client.completions.create(\n                    engine=model.model_name,\n                    prompt=system_message + prompt,\n                    **kwargs\n                )\n                break\n            except Exception as e:\n                print(f\"An error occurred: {e}\")\n                if i == 4:\n                    return None\n                else:\n                    time.sleep(i ** 2)\n\n        # Process the response\n        if response is not None:\n            return self.process_response(response, model)\n        else:\n            return None\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n        # verify the api key is set\n        # verify the model is valid\n        # verify the prompt is valid\n        # verify the parameters are valid\n        # generate the response\n        # return the response\n\n        # verify the api key is set\n        if self.api_key is None:\n            raise ValueError(\"API Key must be set to use OpenAI API\")\n\n        # verify the model is valid\n        if model.model_name is None:\n            raise ValueError(\"Model must be set to use OpenAI API\")\n\n        # verify the prompt is valid\n        if prompt is None:\n            raise ValueError(\"Prompt must be set to use OpenAI API\")\n\n        # verify the parameters are valid\n        if any(key not in LLM_GENERATION_PARAMETERS for key in kwargs.keys()):\n            raise ValueError(\"Invalid generation parameter provided\")\n\n        # generate the response\n        response = self.generate_response(model, system_message, prompt, **kwargs)\n\n        # return the response\n        return response\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Validate the model\n        if model is None:\n            raise ValueError(\"No model specified\")\n\n        # Validate the parameters\n        if prompt is None:\n            raise ValueError(\"No prompt specified\")\n\n        # Validate the parameters\n        for param in kwargs:\n            if param not in LLM_GENERATION_PARAMETERS:\n                raise ValueError(f\"Invalid parameter {param}\")\n\n        # Prepare the prompt\n        prompt = self.prepare_prompt(model, system_message, prompt)\n\n        # Generate the response\n        response = self.generate_response(model, prompt, **kwargs)\n\n        # Process the response\n        return self.process_response(model, response)\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # validate model\n        if model is None:\n            raise ValueError(\"Model not specified\")\n        if not isinstance(model, OpenAIConfig):\n            raise TypeError(\"Model must be an instance of OpenAIConfig\")\n\n        # validate system message\n        if system_message is None:\n            raise ValueError(\"System message not specified\")\n        if not isinstance(system_message, str):\n            raise TypeError(\"System message must be a string\")\n\n        # validate prompt\n        if prompt is None:\n            raise ValueError(\"Prompt not specified\")\n        if not isinstance(prompt, str):\n            raise TypeError(\"Prompt must be a string\")\n\n        # validate parameters\n        for key, value in kwargs.items():\n            if key not in LLM_GENERATION_PARAMETERS:\n                raise ValueError(f\"Invalid generation parameter: {key}\")\n            if not isinstance(value, (int, float)):\n                raise TypeError(f\"Invalid parameter value: {value}\")\n\n        # build request\n        request = {\n            \"model\": model.model_name,\n            \"prompt\": system_message + prompt,\n            \"max_tokens\": model.max_length,\n            \"temperature\": model.temperature,\n            \"top_p\": model.top_p,\n            \"frequency_penalty\": model.frequency_penalty,\n            \"presence_penalty\": model.presence_penalty,\n            \"stop\": model.stop_tokens\n        }\n        request.update(kwargs)\n\n        # send request\n        response = None\n        for i in range(5):\n            try:\n                response = self.client.completions.create(**request)\n                break\n            except Exception as e:\n                if i < 4:\n                    print(f\"An error occurred: {e}\")\n                    print(f\"Retrying in {2**i} seconds\")\n                    time.sleep(2**i)\n                else:\n                    print(f\"An error occurred: {e}\")\n                    print(f\"Failed after 5"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Check if the model is supported\n        if model.model_name not in self.get_supported_models():\n            raise ValueError(f\"Model {model.model_name} is not supported\")\n\n        # Check if the provided parameters are supported\n        for key in kwargs.keys():\n            if key not in LLM_GENERATION_PARAMETERS:\n                raise ValueError(f\"Parameter {key} is not supported\")\n\n        # Set the default parameters\n        parameters = {\n            \"model\": model.model_name,\n            \"prompt\": prompt,\n            \"system_message\": system_message,\n            \"temperature\": model.temperature,\n            \"top_p\": model.top_p,\n            \"frequency_penalty\": model.frequency_penalty,\n            \"presence_penalty\": model.presence_penalty,\n            \"max_new_tokens\": model.max_new_tokens,\n            \"stop\": model.stop,\n            \"logprobs\": 0,\n            \"echo\": True\n        }\n\n        # Overwrite the default parameters with any provided parameters\n        for key, value in kwargs.items():\n            parameters[key] = value\n\n        # Generate the response\n        response = self.generate_response(parameters)\n\n        # Remove the parsing helper tokens from the response\n        response = response.replace(model.start_token, \"\").replace(model.end_token, \"\").replace(model.system_token, \"\")\n\n        return response\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Validate the generation parameters\n        valid_generation_parameters = [\"temperature\", \"top_p\", \"frequency_penalty\", \"presence_penalty\", \"max_new_tokens\"]\n        for parameter in kwargs:\n            if parameter not in valid_generation_parameters:\n                raise ValueError(f\"Invalid generation parameter: {parameter}\")\n\n        # Add the system message and prompt to the prompt parameter\n        prompt = system_message + model.system_message_delim + prompt\n\n        # Handle API key errors\n        try:\n            # Make the request\n            response = self.client.completions.create(\n                model=model.model_name,\n                prompt=prompt,\n                **kwargs\n            )\n\n            # Get the generated text\n            text = response.choices[0].text\n\n            # Remove any parsing helper tokens\n            text = text.replace(model.system_message_delim, \"\")\n            text = text.replace(model.user_message_delim, \"\")\n            text = text.replace(model.model_message_delim, \"\")\n\n            return text\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n            return None\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Check that the OpenAI API key is valid\n        if self.api_key is None:\n            raise ValueError(\n                \"OpenAI API key is not set. Set API key using the OPENAI_API_KEY environment variable.\"\n            )\n\n        # Check that the OpenAI API key is valid\n        if not self.is_api_key_valid():\n            raise ValueError(\"OpenAI API key is invalid.\")\n\n        # Check that the OpenAI API key is not being rate limited\n        if self.is_rate_limited():\n            raise ValueError(\"OpenAI API key is being rate limited.\")\n\n        # Check that the model is valid\n        if model.model_name not in self.get_model_list():\n            raise ValueError(f\"Model {model.model_name} is not a valid model.\")\n\n        # Check that the prompt is valid\n        if prompt is None or len(prompt) == 0:\n            raise ValueError(\"Prompt is required.\")\n\n        # Check that the system message is valid\n        if system_message is None or len(system_message) == 0:\n            raise ValueError(\"System message is required.\")\n\n        # Check that the generation parameters are valid\n        for parameter in kwargs.keys():\n            if parameter not in LLM_GENERATION_PARAMETERS:\n                raise ValueError(\n                    f\"Parameter {parameter} is not a valid generation parameter.\"\n                )\n\n        # Set the default generation parameters\n        parameters = {\n            \"model\": model.model_name,\n            \"prompt\": prompt,\n            \"max_tokens\": model.max_tokens,\n            \"temperature\": model.temperature,\n            \"top_p\": model.top_p,\n            \"frequency_penalty\": model.frequency_penalty,\n            \"presence_penalty\": model.presence_penalty,\n            \"stop\": model.stop,\n            \"logprobs\": model.logprobs,\n        }\n\n        # Update the generation parameters with any provided overrides\n        parameters.update(kwargs)\n\n        #"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Verify that the model is valid\n        assert model.model_name in self.get_models()\n\n        # Verify that the provided parameters are valid\n        for parameter in kwargs:\n            assert parameter in LLM_GENERATION_PARAMETERS\n\n        # Create the request payload\n        payload = {\n            \"model\": model.model_name,\n            \"prompt\": system_message + \"\\n\" + prompt,\n            \"temperature\": model.temperature,\n            \"top_p\": model.top_p,\n            \"frequency_penalty\": model.frequency_penalty,\n            \"presence_penalty\": model.presence_penalty,\n            \"max_new_tokens\": model.max_tokens,\n            \"stop\": model.stop_sequence\n        }\n\n        # Add any additional parameters\n        for parameter in kwargs:\n            payload[parameter] = kwargs[parameter]\n\n        # Generate the response\n        response = None\n        for i in range(5):\n            try:\n                response = self.client.completions.create(**payload)\n                break\n            except Exception as e:\n                print(f\"An error occurred: {e}\")\n                time.sleep(i * 10)\n\n        # Process the response\n        if response is not None:\n            return response.choices[0].text.replace(model.system_token, \"\").strip()\n        else:\n            return None\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # validate the parameters\n        self.validate_generation_parameters(model, system_message, prompt, **kwargs)\n\n        # add the system message and prompt to the generation request\n        prompt = system_message + model.system_message_token + prompt\n\n        # handle the retry logic\n        retries = 0\n        while True:\n            try:\n                # make the request\n                response = self.client.completions.create(\n                    model=model.model_name,\n                    prompt=prompt,\n                    **kwargs\n                )\n                break\n            except Exception as e:\n                if retries < 5:\n                    retries += 1\n                    print(f\"An error occurred: {e}. Retrying {retries}/5.\")\n                    time.sleep(2**retries)\n                else:\n                    print(f\"An error occurred: {e}. Retried 5 times, exiting.\")\n                    raise e\n\n        # process the response\n        response = response.choices[0][\"text\"]\n        response = response.replace(system_message, \"\")\n        response = response.replace(model.system_message_token, \"\")\n        response = response.replace(model.user_message_token, \"\")\n        return response\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # check for valid model\n        if model.model_name not in self.get_available_models():\n            raise ValueError(f\"Model {model.model_name} is not available in the OpenAI API.\")\n\n        # check for valid kwargs\n        for key in kwargs:\n            if key not in LLM_GENERATION_PARAMETERS:\n                raise ValueError(f\"Parameter {key} is not a valid generation parameter for the OpenAI API.\")\n\n        # add system message to prompt\n        prompt = f\"{system_message} {prompt}\"\n\n        # generate response\n        response = None\n        for i in range(5):\n            try:\n                response = self.client.completions.create(\n                    model=model.model_name,\n                    prompt=prompt,\n                    **kwargs\n                )\n                break\n            except Exception as e:\n                if i < 4:\n                    time.sleep(2**i)\n                else:\n                    raise e\n\n        # check for valid response\n        if response is None:\n            raise RuntimeError(\"Failed to generate response from OpenAI API.\")\n\n        # return generated text\n        return response.choices[0].text.strip()\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Check for invalid generation parameters\n        for key in kwargs.keys():\n            if key not in LLM_GENERATION_PARAMETERS:\n                raise ValueError(f\"Invalid generation parameter {key}\")\n\n        # Generate response with exponential backoff\n        num_tries = 0\n        while num_tries < 5:\n            try:\n                response = self.client.completions.create(\n                    model=model.model_name,\n                    prompt=system_message + prompt,\n                    **kwargs\n                )\n                break\n            except Exception as e:\n                print(f\"An error occurred: {e}\")\n                num_tries += 1\n                time.sleep(2**num_tries)\n\n        # Check for valid response\n        if num_tries == 5:\n            raise ValueError(\"No response from OpenAI API\")\n\n        # Process response\n        response = response.choices[0].text\n        for token in model.parsing_tokens:\n            response = response.replace(token, \"\")\n        return response\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Add system message and prompt to the prompt parameter\n        prompt = system_message + prompt\n\n        # Verify that the model is a valid OpenAI model\n        assert model.model_name in self.get_model_list()\n\n        # Verify that the generation parameters are valid\n        for parameter in kwargs:\n            assert parameter in LLM_GENERATION_PARAMETERS\n\n        # Generate response\n        response = None\n        for i in range(5):\n            try:\n                response = self.client.completions.create(\n                    model=model.model_name,\n                    prompt=prompt,\n                    **kwargs\n                )\n                break\n            except Exception as e:\n                if i == 4:\n                    raise e\n                else:\n                    print(f\"An error occurred: {e}\")\n                    print(f\"Retrying after {2 ** i} seconds.\")\n                    time.sleep(2 ** i)\n\n        # Process response\n        assert response.object == \"text_completion\"\n        assert len(response.data) == 1\n        response = response.data[0]\n        assert response.object == \"text_completion\"\n        assert response.finish_reason == \"length\"\n        assert len(response.choices) == 1\n        response = response.choices[0]\n        assert response.finish_reason == \"length\"\n\n        # Remove parsing helper tokens\n        for token in model.parsing_helper_tokens:\n            response.text = response.text.replace(token, \"\")\n\n        # Remove leading system message\n        response.text = response.text.replace(system_message, \"\")\n\n        return response.text\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Validate the model\n        if model.model_name == \"\":\n            model.model_name = DEFAULT_DISTILLED_MODEL_NAME\n\n        # Validate the generation parameters\n        for key, value in kwargs.items():\n            if key not in LLM_GENERATION_PARAMETERS:\n                raise ValueError(f\"Invalid generation parameter {key}\")\n\n        # Add the system message to the prompt\n        prompt = system_message + model.system_message_delimiter + prompt\n\n        # Create the request parameters\n        request_parameters = {\n            \"model\": model.model_name,\n            \"prompt\": prompt,\n            \"max_tokens\": model.max_tokens,\n            \"temperature\": model.temperature,\n            \"top_p\": model.top_p,\n            \"frequency_penalty\": model.frequency_penalty,\n            \"presence_penalty\": model.presence_penalty,\n            \"stop\": model.stop_tokens,\n            **kwargs\n        }\n\n        # Generate the response\n        response = None\n        num_attempts = 0\n        while response is None and num_attempts < 5:\n            try:\n                response = self.client.completions.create(**request_parameters)\n            except Exception as e:\n                num_attempts += 1\n                if num_attempts == 5:\n                    raise e\n                else:\n                    print(f\"Generation failed, retrying in {2 ** num_attempts} seconds\")\n                    time.sleep(2 ** num_attempts)\n\n        # Process the response\n        response = response.choices[0].text\n        for stop_token in model.stop_tokens:\n            response = response.replace(stop_token, \"\")\n        response = response.strip()\n\n        return response\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # validate the generation parameters\n        for key in kwargs:\n            if key not in LLM_GENERATION_PARAMETERS:\n                raise ValueError(f\"Invalid generation parameter: {key}\")\n\n        # create the generation request\n        request = {\n            \"model\": model.model_name,\n            \"prompt\": system_message + prompt,\n            \"max_tokens\": 1,\n            \"temperature\": 0.0,\n            \"frequency_penalty\": 0.0,\n            \"presence_penalty\": 0.0,\n            \"stop\": model.stop_sequence,\n            \"logprobs\": 0,\n        }\n\n        # update the request with any specified parameters\n        request.update(kwargs)\n\n        # send the request to the OpenAI API\n        response = None\n        for i in range(5):\n            try:\n                response = self.client.completions.create(**request)\n                break\n            except Exception as e:\n                if i == 4:\n                    raise e\n                else:\n                    time.sleep(2 ** i)\n\n        # process the response\n        if response is not None:\n            if len(response.choices) > 0:\n                response_text = response.choices[0].text\n                response_text = response_text.replace(model.system_message_token, \"\").strip()\n                return response_text\n            else:\n                raise ValueError(\"No response choices returned\")\n        else:\n            raise ValueError(\"No response returned\")\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Check that the API key is valid\n        self.check_api_key()\n\n        # Verify that the model is a valid model\n        if model is None:\n            raise ValueError(\"No model provided\")\n\n        # Verify that the system message is a string\n        if system_message is None:\n            raise ValueError(\"No system message provided\")\n        if not isinstance(system_message, str):\n            raise ValueError(\"System message must be a string\")\n\n        # Verify that the prompt is a string\n        if prompt is None:\n            raise ValueError(\"No prompt provided\")\n        if not isinstance(prompt, str):\n            raise ValueError(\"Prompt must be a string\")\n\n        # Verify that the additional parameters are valid\n        for key, value in kwargs.items():\n            if key not in LLM_GENERATION_PARAMETERS:\n                raise ValueError(f\"Invalid parameter {key} provided\")\n            if not isinstance(value, (int, float)):\n                raise ValueError(f\"Invalid parameter value {value} provided for parameter {key}\")\n\n        # Generate the response\n        response = None\n        for i in range(5):\n            try:\n                response = self.client.completions.create(\n                    model=model.model_name,\n                    prompt=system_message + prompt,\n                    **kwargs\n                )\n                break\n            except Exception as e:\n                if i < 4:\n                    time.sleep(2 ** i)\n                else:\n                    raise e\n\n        # Process the response\n        if response is None:\n            raise RuntimeError(\"Failed to generate response\")\n        if len(response.choices) == 0:\n            raise RuntimeError(\"No choices returned\")\n        text = response.choices[0].text\n        return text.strip().split(\"\\n\")[0]\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # verify that the model is a valid model name\n        if not self.is_valid_model(model.model_name):\n            raise ValueError(f\"Invalid model name: {model.model_name}\")\n\n        # verify that the system message is a string\n        if not isinstance(system_message, str):\n            raise TypeError(f\"System message must be a string, got {type(system_message)}\")\n\n        # verify that the prompt is a string\n        if not isinstance(prompt, str):\n            raise TypeError(f\"Prompt must be a string, got {type(prompt)}\")\n\n        # verify that the parameters are valid\n        for parameter in kwargs:\n            if parameter not in LLM_GENERATION_PARAMETERS:\n                raise ValueError(f\"Invalid parameter: {parameter}\")\n\n        # add the system message and prompt to the generation prompt\n        prompt = system_message + model.system_message_delimeter + prompt\n\n        # create the generation request\n        request = {\n            \"model\": model.model_name,\n            \"prompt\": prompt,\n            \"max_tokens\": model.max_tokens,\n            \"temperature\": model.temperature,\n            \"top_p\": model.top_p,\n            \"frequency_penalty\": model.frequency_penalty,\n            \"presence_penalty\": model.presence_penalty,\n            \"stop\": model.stop,\n            \"logprobs\": 1,\n        }\n        # add any additional parameters to the request\n        request.update(kwargs)\n\n        # create a new OpenAI client\n        client = OpenAI(api_key=self.api_key, api_base_url=OPENAI_URL)\n\n        # send the request to the API\n        response = client.create_completion(**request)\n\n        # get the response text\n        text = response.choices[0].text\n\n        # remove the system message from the response text\n        text = text[len(system_message):]\n\n        # remove the prompt from the response text"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # set up default parameters\n        parameters = copy.deepcopy(model.parameters)\n        parameters.update(kwargs)\n\n        # check for valid parameters\n        for parameter in parameters.keys():\n            if parameter not in LLM_GENERATION_PARAMETERS:\n                raise ValueError(f\"Parameter {parameter} is not a valid generation parameter.\")\n\n        # set up the request body\n        body = {\n            \"model\": model.model_name,\n            \"prompt\": system_message + prompt,\n            **parameters\n        }\n\n        # send the request and handle errors\n        retries = 5\n        response = None\n        while retries > 0:\n            try:\n                response = self.client.completions.create(body)\n                break\n            except Exception as e:\n                if retries == 0:\n                    print(f\"An error occurred: {e}\")\n                    return None\n                else:\n                    time.sleep(2**(5-retries+1))\n                    retries -= 1\n\n        # process the response\n        if response is not None:\n            return response.choices[0].text.strip(model.start_token).strip(model.end_token)\n        else:\n            return None\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.all(x == x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n    if not np.all(x == x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    # Check if the matrix is square.\n    assert_is_square(x)\n\n    # Check if the matrix is equal to its transpose.\n    if not np.all(x == x.T):\n        raise ValueError(\"The matrix is not symmetric.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), np.zeros(x.shape[0])):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), np.zeros(x.shape[0])):\n        raise ValueError(\"The matrix must be a distance matrix\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(x.diagonal(), np.zeros(x.shape[0])):\n        raise ValueError(\"The matrix must have zero diagonal elements\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), np.zeros(shape=(x.shape[0],))):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(x.diagonal(), np.zeros(x.shape[0])):\n        raise ValueError(\"The diagonal elements must be zeros\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), np.zeros(x.shape[0])):\n        raise ValueError(\"The matrix must have zeros along its diagonal\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n    if not np.all(x.diagonal() == 0):\n        raise ValueError(\"The diagonal elements of the matrix must be 0\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    # Check if the matrix is symmetric\n    assert_is_symmetric(x)\n\n    # Check if the diagonal elements are close to zero\n    if not np.allclose(x.diagonal(), np.zeros(x.shape[0])):\n        raise ValueError(\"The matrix is not a distance matrix\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(x.diagonal(), np.zeros(x.shape[0])):\n        raise ValueError(\"The matrix diagonal elements must be zero\")\n    if not np.all(x >= 0):\n        raise ValueError(\"The matrix elements must be greater than or equal to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.all(np.diagonal(x) == 0):\n        raise ValueError(\"The diagonal elements of the matrix must be 0\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), np.zeros(shape=(x.shape[0],))):\n        raise ValueError(\"The matrix must be zero on the diagonal\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), np.zeros(len(x))):\n        raise ValueError(\"The matrix must have zeros along its diagonal\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), np.zeros(x.shape[0])):\n        raise ValueError(\"The diagonal elements must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n    if not np.all(np.diag(x) == 0):\n        raise ValueError(\"The diagonal elements of the matrix must be 0\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n    if not np.allclose(np.diag(x), np.zeros(x.shape[0])):\n        raise ValueError(\"The matrix is not a distance matrix\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(x.diagonal(), np.zeros(x.shape[0])):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    # Check if the matrix is a square matrix.\n    assert_is_square(x)\n\n    # Check if the matrix is symmetric.\n    assert_is_symmetric(x)\n\n    # Check if the matrix is a distance matrix.\n    if not np.all(x.diagonal() == 0):\n        raise ValueError(\"The matrix is not a distance matrix because its diagonal elements are not all zeros\")\n    if not np.all(x >= 0):\n        raise ValueError(\"The matrix is not a distance matrix because it has negative elements\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n\n    # Check if the matrix is symmetric\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric.\")\n\n    # Check if the matrix is diagonal\n    if not np.allclose(np.diagonal(x), np.zeros(x.shape[0])):\n        raise ValueError(\"The matrix diagonal elements must be zeros.\")\n\n    # Check if the matrix is positive semi-definite\n    if not np.all(np.linalg.eigvals(x) >= 0):\n        raise ValueError(\"The matrix must be positive semi-definite.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(x.diagonal(), np.zeros(x.shape[0])):\n        raise ValueError(\"The diagonal elements must be zeros\")\n    if not np.all(x >= 0):\n        raise ValueError(\"All elements must be non-negative\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), np.zeros(x.shape[0])):\n        raise ValueError(\"The diagonal elements of the matrix must be 0\")\n    if not np.all(x >= 0):\n        raise ValueError(\"The matrix must be non-negative\")\n\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular\n        # TODO: Make this more modular"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            # Check if the function is already initialized with a teacher model\n            if self.initialized_functions[func_hash][\"model\"] != \"\":\n                # Check if the function is already initialized with a distilled model\n                if self.initialized_functions[func_hash][\"distilled\"]:\n                    # Check if the function is already initialized with a distilled model of the same type\n                    if self.initialized_functions[func_hash][\"model\"] == function_description.model_type:\n                        # Check if the function is already initialized with a distilled model of the same type and the same align statements\n                        if self.initialized_functions[func_hash][\"align\"] == function_description.align_statement:\n                            return self.initialized_functions[func_hash][\"prompt\"], self.initialized_functions[func_hash][\"model\"], False, True\n                        else:\n                            # Check if the function is already initialized with a distilled model of the same type and different align statements\n                            if self.initialized_functions[func_hash][\"distilled\"]:\n                                # Check if the function is already initialized with a distilled model of the same type and different align statements and the same number of examples\n                                if len(self.initialized_functions[func_hash][\"examples\"]) == len(function_description.align_statement):\n                                    # Check if the function is already initialized with a distilled model of the same type and different align statements and the same number of examples and the same examples\n                                    if self.initialized_functions[func_hash][\"examples\"] == function_description.align_statement:\n                                        return self.initialized_functions[func_hash][\"prompt\"], self.initialized_functions[func_hash][\"model\"], False, True\n                                    else:\n                                        # Check if the function is already initialized with a distilled model of the same type and different align statements and the same number of examples and different examples\n                                        if self.initialized_functions[func_hash][\"distilled\"]:"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # if the function is already initialized, get the model and examples\n        if func_hash in self.initialized_functions:\n            model = self.initialized_functions[func_hash][\"model\"]\n            examples = self.initialized_functions[func_hash][\"examples\"]\n            return self.construct_prompt(args, kwargs, function_description, examples), model, False, False\n\n        # if the function is not initialized, initialize it and get the model and examples\n        else:\n            # get the model and examples\n            model, examples, is_distilled_model = self.get_model_and_examples(args, kwargs, function_description, llm_parameters)\n            # update the initialized functions dictionary\n            self.initialized_functions[func_hash] = {\"model\": model, \"examples\": examples}\n            # construct the prompt\n            prompt = self.construct_prompt(args, kwargs, function_description, examples)\n            return prompt, model, is_distilled_model, True\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            # if it is, check if it has align statements\n            if len(self.initialized_functions[func_hash][\"examples\"]) > 0:\n                # if it does, check if the number of tokens in the align statements is less than the maximum number of tokens allowed\n                if self.token_counts[func_hash] < llm_parameters[\"max_new_tokens\"]:\n                    # if it is, check if the number of tokens in the align statements is less than the maximum number of tokens allowed\n                    if self.token_counts[func_hash] < llm_parameters[\"max_new_tokens\"]:\n                        # if it is, use the teacher model\n                        model = self.initialized_functions[func_hash][\"model\"]\n                        prompt = self.initialized_functions[func_hash][\"prompt\"]\n                        save_to_finetune = False\n                        is_distilled_model = False\n                    else:\n                        # if it is not, use the distilled model\n                        model = self.initialized_functions[func_hash][\"distilled_model\"]\n                        prompt = self.initialized_functions[func_hash][\"prompt\"]\n                        save_to_finetune = False\n                        is_distilled_model = True\n                else:\n                    # if it is not, use the distilled model\n                    model = self.initialized_functions[func_hash][\"distilled_model\"]\n                    prompt = self.initialized_functions[func_hash][\"prompt\"]\n                    save_to_finetune = False\n                    is_distilled_model = True\n            else:\n                # if it does not, check if the number of tokens in the align statements is less than the maximum number of tokens allowed\n                if self.token_counts[func_hash] < llm_parameters[\"max_new_tokens\"]:\n                    # if it is, use the teacher model\n                    model = self.initialized_functions[func_hash][\"model"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Check if the function is already initialized\n        current_function_setup = self.initialized_functions.get(func_hash, None)\n        if current_function_setup is None:\n            current_function_setup = {\n                \"model\": \"\",\n                \"examples\": []\n            }\n            self.initialized_functions[func_hash] = current_function_setup\n\n        # Check if the function has already been initialized with examples for fine-tuning\n        examples_initialized = len(current_function_setup[\"examples\"]) > 0\n\n        # Check if the function is suitable for distillation\n        distillable = self.function_modeler.is_distillable(function_description)\n\n        # Check if the function is suitable for fine-tuning\n        fine_tune_suitable = self.function_modeler.is_fine_tune_suitable(function_description)\n\n        # Check if the function is already initialized with examples for fine-tuning\n        if examples_initialized:\n            # Check if the function is suitable for fine-tuning\n            if fine_tune_suitable:\n                # Check if the function is already initialized with examples for fine-tuning\n                if examples_initialized:\n                    # Check if the function is suitable for distillation\n                    if distillable:\n                        # Check if the function is already initialized with examples for fine-tuning\n                        if examples_initialized:\n                            # Check if the function is already initialized with examples for fine-tuning\n                            if examples_initialized:\n                                # Check if the function is already initialized with examples for fine-tuning\n                                if examples_initialized:\n                                    # Check if the function is already initialized with examples for fine-tuning\n                                    if examples_initialized:\n                                        # Check if the function is already initialized with examples for fine-tuning\n                                        if examples_initialized:\n                                            # Check if the function is already initialized with examples for fine-tuning\n                                            if examples_initialized:\n                                                # Check if the function is already initialized with examples for fine-tuning\n                                               "}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # check if function is already initialized\n        if func_hash in self.initialized_functions:\n            current_function_setup = self.initialized_functions[func_hash]\n            if current_function_setup[\"model\"] != \"\":\n                return self.construct_prompt(args, kwargs, function_description, current_function_setup[\"examples\"], llm_parameters), current_function_setup[\"model\"], False, True\n            else:\n                return self.construct_prompt(args, kwargs, function_description, current_function_setup[\"examples\"], llm_parameters), current_function_setup[\"distilled_model\"], True, False\n\n        # check if function is suitable for distillation\n        if function_description.distillable:\n            # check if function is already initialized with a distilled model\n            if func_hash in self.initialized_functions:\n                current_function_setup = self.initialized_functions[func_hash]\n                if current_function_setup[\"distilled_model\"] != \"\":\n                    return self.construct_prompt(args, kwargs, function_description, current_function_setup[\"examples\"], llm_parameters), current_function_setup[\"distilled_model\"], True, False\n\n            # check if function is suitable for distillation\n            if self.is_suitable_for_distillation(args, kwargs, function_description):\n                # check if function is already initialized with a teacher model\n                if func_hash in self.initialized_functions:\n                    current_function_setup = self.initialized_functions[func_hash]\n                    if current_function_setup[\"model\"] != \"\":\n                        return self.construct_prompt(args, kwargs, function_description, current_function_setup[\"examples\"], llm_parameters), current_function_setup[\"model\"], False, True\n\n                # initialize function with a distilled model\n                self.initialized_functions[func_hash] = {\"distilled_model\": function_description.distilled_model}\n                return self.construct_prompt(args, kwargs, function_description, [], llm_parameters), function_description.distilled"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # check if the function is already initialized\n        if func_hash in self.initialized_functions.keys():\n            # check if the function is already initialized with the same model\n            if self.initialized_functions[func_hash][\"model\"] == function_description.model_type:\n                # check if the function is already initialized with the same model and has enough examples\n                if len(self.initialized_functions[func_hash][\"examples\"]) >= function_description.minimum_examples:\n                    # check if the function is already initialized with the same model and has enough examples and is distillable\n                    if self.initialized_functions[func_hash][\"distillable\"]:\n                        # check if the function is already initialized with the same model and has enough examples and is distillable and is distilled\n                        if self.initialized_functions[func_hash][\"distilled\"]:\n                            # return the prompt and model\n                            prompt = self.initialized_functions[func_hash][\"prompt\"]\n                            model = self.initialized_functions[func_hash][\"model\"]\n                            return prompt, model, False, True\n                        # return the prompt and model\n                        prompt = self.initialized_functions[func_hash][\"prompt\"]\n                        model = self.initialized_functions[func_hash][\"model\"]\n                        return prompt, model, True, True\n                    # return the prompt and model\n                    prompt = self.initialized_functions[func_hash][\"prompt\"]\n                    model = self.initialized_functions[func_hash][\"model\"]\n                    return prompt, model, False, True\n                # check if the function is already initialized with the same model and has enough examples\n                if len(self.initialized_functions[func_hash][\"examples\"]) < function_description.minimum_examples:\n                    # check if the function is already initialized with the same model and has enough examples and is distillable\n                    if self.initialized_functions[func_hash][\"distillable\"]:\n                        # check if the function is already initialized with the same model and has enough examples and is distillable"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # if the function is not initialized, initialize it\n        if func_hash not in self.initialized_functions:\n            self.initialized_functions[func_hash] = {\n                \"model\": \"\",\n                \"examples\": []\n            }\n\n        # if the function is initialized, check if it needs to be initialized for finetuning\n        elif self.initialized_functions[func_hash][\"model\"] != \"\":\n            # if it is initialized for finetuning, check if it needs to be reinitialized\n            if self.initialized_functions[func_hash][\"model\"] != \"distil\":\n                # if it needs to be reinitialized, check if it is suitable for distillation\n                if self.api_provider[function_description.model_type].is_distillable(function_description):\n                    # if it is suitable for distillation, check if the token count is less than the limit\n                    if approximate_token_count(args, kwargs) < self.api_provider[function_description.model_type].distillation_token_limit:\n                        # if it is less than the limit, initialize for distillation\n                        self.initialized_functions[func_hash][\"model\"] = \"distil\"\n                    else:\n                        # if it is not less than the limit, initialize for finetuning\n                        self.initialized_functions[func_hash][\"model\"] = \"\"\n                else:\n                    # if it is not suitable for distillation, initialize for finetuning\n                    self.initialized_functions[func_hash][\"model\"] = \"\"\n\n        # if the function is initialized for finetuning, check if it needs to be reinitialized\n        if self.initialized_functions[func_hash][\"model\"] == \"\":\n            # if it needs to be reinitialized, check if it is suitable for distillation\n            if self.api_provider[function_description.model_type].is_distillable(function_description):\n                # if it is suitable for distillation, check if the token count is less than the limit\n                if approximate_token_count(args, kwargs"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # If function is not initialized, initialize it\n        if func_hash not in self.initialized_functions:\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n\n        # If function is already initialized, check if it needs to be updated\n        elif self.initialized_functions[func_hash][\"model\"] != \"\":\n            # If function is already initialized and has an example, check if it needs to be updated\n            if len(self.initialized_functions[func_hash][\"examples\"]) > 0:\n                # If the function has a suitable model, check if it needs to be updated\n                if self.initialized_functions[func_hash][\"model\"] in self.api_provider.get_distillable_models():\n                    # If the function has a suitable model, check if it needs to be updated\n                    if self.api_provider.get_distillable_models()[self.initialized_functions[func_hash][\"model\"]].token_limit > approximate_token_count(\n                            self.initialized_functions[func_hash][\"examples\"][0]):\n                        # If the function has a suitable model, check if it needs to be updated\n                        if self.api_provider.get_distillable_models()[self.initialized_functions[func_hash][\"model\"]].token_limit > approximate_token_count(\n                                self.initialized_functions[func_hash][\"examples\"][-1]):\n                            # If the function has a suitable model, check if it needs to be updated\n                            if self.api_provider.get_distillable_models()[self.initialized_functions[func_hash][\"model\"]].token_limit > approximate_token_count(\n                                    llm_parameters[\"prompt\"]):\n                                # If the function has a suitable model, check if it needs to be updated\n                                if self.api_provider.get_distillable_models()[self.initialized_functions[func_hash][\"model\"]].token_limit > approximate_token_count(\n                                        llm_parameters[\"prompt\"] +"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            current_function_setup = self.initialized_functions[func_hash]\n            if current_function_setup[\"model\"] == \"\":\n                # if the function is initialized but no model is selected, check if the function is suitable for distillation\n                if self.function_modeler.is_function_distillable(function_description):\n                    # if the function is suitable for distillation, select a distilled model\n                    model = self.api_provider[function_description.provider].get_distilled_model(function_description)\n                    prompt = self.function_modeler.get_distill_prompt(args, kwargs, function_description)\n                    is_distilled_model = True\n                else:\n                    # if the function is not suitable for distillation, select a teacher model\n                    model = self.api_provider[function_description.provider].get_teacher_model(function_description)\n                    prompt = self.function_modeler.get_teacher_prompt(args, kwargs, function_description)\n                    is_distilled_model = False\n            else:\n                # if the function is already initialized, use the current model\n                model = self.api_provider[function_description.provider].get_model(current_function_setup[\"model\"])\n                prompt = self.function_modeler.get_teacher_prompt(args, kwargs, function_description)\n                is_distilled_model = False\n\n            # check if the model is suitable for distillation\n            if is_distilled_model:\n                # if the model is suitable for distillation, check if the function is already initialized\n                if current_function_setup[\"model\"] == \"\":\n                    # if the function is not already initialized, check if the function is suitable for distillation\n                    if self.function_modeler.is_function_distillable(function_description):\n                        # if the function is suitable for distillation, select a distilled model\n                        model = self.api_provider[function_"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # check if the function is already initialized\n        current_function_setup = self.initialized_functions.get(func_hash, None) # getting the current function setup - model and align statements\n        if current_function_setup:\n            # if the function is already initialized, check if the number of arguments has changed\n            if len(args) != len(current_function_setup[\"args\"]):\n                # if the number of arguments has changed, re-initialize the function\n                self.initialized_functions[func_hash] = {}\n                self.initialized_functions[func_hash][\"args\"] = args\n                self.initialized_functions[func_hash][\"kwargs\"] = kwargs\n                self.initialized_functions[func_hash][\"model\"] = \"\"\n                self.initialized_functions[func_hash][\"examples\"] = []\n                self.initialized_functions[func_hash][\"token_count\"] = 0\n                return self.get_generation_case(args, kwargs, function_description, llm_parameters, func_hash)\n            else:\n                # if the number of arguments has not changed, check if the arguments have changed\n                if args != current_function_setup[\"args\"] or kwargs != current_function_setup[\"kwargs\"]:\n                    # if the arguments have changed, update the examples for fine-tuning\n                    self.initialized_functions[func_hash][\"args\"] = args\n                    self.initialized_functions[func_hash][\"kwargs\"] = kwargs\n                    self.initialized_functions[func_hash][\"examples\"].append(FunctionExample(args, kwargs))\n                    # if the examples for fine-tuning have reached the maximum number of examples, fine-tune the model\n                    if len(self.initialized_functions[func_hash][\"examples\"]) >= self.initialized_functions[func_hash][\"token_count\"]:\n                        self.function_modeler.finetune(function_description,\n                                                       self.initialized_functions[func_hash][\"examples\"],\n                                                       self.initialized_functions[func_hash][\"model\"])\n                "}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            current_function_setup = self.initialized_functions[func_hash]\n            if \"model\" in current_function_setup:\n                model = current_function_setup[\"model\"]\n            else:\n                model = current_function_setup[\"distilled_model\"]\n            if \"examples\" in current_function_setup:\n                examples = current_function_setup[\"examples\"]\n            else:\n                examples = []\n            # Check if the model is suitable for distillation\n            if model.distil:\n                # Check if the token count is within the limit\n                if self.token_counts[func_hash] < model.token_limit:\n                    # Check if the function requires fine-tuning\n                    if model.fine_tuning:\n                        # Check if the examples are already saved\n                        if len(examples) == 0:\n                            prompt = self.function_modeler.construct_prompt(args, kwargs, function_description,\n                                                                            examples, model.model_name,\n                                                                            distilled=True)\n                            return prompt, model, False, True\n                        else:\n                            prompt = self.function_modeler.construct_prompt(args, kwargs, function_description,\n                                                                            examples, model.model_name,\n                                                                            distilled=True)\n                            return prompt, model, False, False\n                    else:\n                        prompt = self.function_modeler.construct_prompt(args, kwargs, function_description,\n                                                                        examples, model.model_name,\n                                                                        distilled=True)\n                        return prompt, model, True, False\n                else:\n                    # Check if the function requires fine-tuning\n                    if model.fine_tuning:\n                        # Check if the examples are already saved\n                        if len(examples) == 0:\n                            prompt = self.function_modeler.construct_prompt(args, kwargs, function_description,\n                "}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            current_function_setup = self.initialized_functions[func_hash]\n            # Check if the function has been initialized with a distilled model\n            if current_function_setup[\"distilled\"]:\n                return self.construct_prompt(args, kwargs, function_description, llm_parameters, current_function_setup[\"model\"]), current_function_setup[\"model\"], False, True\n            else:\n                # Check if the function has been initialized with a teacher model\n                if current_function_setup[\"model\"] != \"\":\n                    # Check if the function has been initialized with a teacher model and the token count is below the threshold\n                    if len(current_function_setup[\"examples\"]) < self.token_counts[func_hash]:\n                        # Add the current example to the list of examples\n                        current_function_setup[\"examples\"].append(FunctionExample(args, kwargs, None))\n                        return self.construct_prompt(args, kwargs, function_description, llm_parameters, current_function_setup[\"model\"]), current_function_setup[\"model\"], False, False\n                    else:\n                        # Check if the function has been initialized with a teacher model and the token count is above the threshold\n                        if len(current_function_setup[\"examples\"]) >= self.token_counts[func_hash]:\n                            # Check if the function has been initialized with a teacher model, the token count is above the threshold, and the model is suitable for distillation\n                            if current_function_setup[\"distillable\"]:\n                                # Check if the function has been initialized with a teacher model, the token count is above the threshold, the model is suitable for distillation, and the model has not been initialized with a distilled model\n                                if not current_function_setup[\"distilled\"]:\n                                    # Initialize the function with a distilled model\n                                    return self.construct_prompt(args, kwargs, function_description, llm_parameters, current_function_setup[\"model\"]), current_function_setup[\"model\"], True, False"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # if the function is already initialized, return the prompt and model\n        if func_hash in self.initialized_functions:\n            prompt = self._construct_prompt(args, kwargs, function_description, self.initialized_functions[func_hash][\"examples\"])\n            model = self.initialized_functions[func_hash][\"model\"]\n            save_to_finetune = False\n            is_distilled_model = False\n            return prompt, model, save_to_finetune, is_distilled_model\n\n        # if the function is not initialized, find the model and prompt\n        else:\n            # get the model\n            model, is_distilled_model = self._get_model(function_description, llm_parameters)\n\n            # get the prompt\n            prompt = self._construct_prompt(args, kwargs, function_description, [])\n\n            # check if the model is suitable for distillation\n            save_to_finetune = self._check_distillation(prompt, model, llm_parameters)\n\n            # if the model is not suitable for distillation, add the function to the initialized functions\n            if not save_to_finetune:\n                self.initialized_functions[func_hash] = {\n                    \"model\": model,\n                    \"examples\": []\n                }\n\n            return prompt, model, save_to_finetune, is_distilled_model\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # check if function is initialized\n        if func_hash not in self.initialized_functions:\n            # if not, initialize function\n            self.initialized_functions[func_hash] = {}\n            self.initialized_functions[func_hash][\"model\"] = \"\"\n            self.initialized_functions[func_hash][\"examples\"] = []\n\n        # check if examples are already saved\n        if self.initialized_functions[func_hash][\"examples\"]:\n            # if so, check if examples are sufficient for fine-tuning\n            if len(self.initialized_functions[func_hash][\"examples\"]) < self.api_provider[\n                self.api_provider.default_provider].min_num_examples:\n                # if not, add examples\n                self.function_modeler.preprocess_symbolic_datapoints(function_description.__hash__(),\n                                                                     function_description,\n                                                                     self.initialized_functions[func_hash][\n                                                                         \"examples\"])\n            else:\n                # if so, check if examples are sufficient for distillation\n                if len(self.initialized_functions[func_hash][\"examples\"]) < self.api_provider[\n                    self.api_provider.default_provider].min_num_examples_distillation:\n                    # if not, add examples\n                    self.function_modeler.preprocess_symbolic_datapoints(function_description.__hash__(),\n                                                                         function_description,\n                                                                         self.initialized_functions[func_hash][\n                                                                             \"examples\"])\n\n        # check if function is suitable for distillation\n        if self.function_modeler.is_function_distillable(function_description):\n            # if so, check if model is already initialized\n            if self.initialized_functions[func_hash][\"model\"]:\n                # if so, check if model is a distilled model\n                if self.initialized_functions[func_hash][\"model\"] == \"distilled\":\n                    # if so, check if distillation is possible\n                "}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # check if function is already initialized\n        if func_hash in self.initialized_functions:\n            if self.initialized_functions[func_hash][\"model\"] != \"\":\n                return \"\", self.initialized_functions[func_hash][\"model\"], False, False\n            else:\n                return self.initialized_functions[func_hash][\"examples\"], self.initialized_functions[func_hash][\"model\"], False, True\n\n        # get the model\n        model = self.api_provider.get_model(function_description)\n        if not model:\n            raise NotImplementedError(\n                f\"No language model found for function {function_description.name}\")\n\n        # check if the model can be distilled\n        is_distilled_model = model.distil_model\n\n        # check if the model is suitable for distillation\n        if is_distilled_model and not model.is_distillable(args, kwargs):\n            is_distilled_model = False\n\n        # check if the model is suitable for fine-tuning\n        if not is_distilled_model and not model.is_finetunable(args, kwargs):\n            raise NotImplementedError(\n                f\"Model {model.model_name} is not suitable for fine-tuning for function {function_description.name}\")\n\n        # get the prompt\n        prompt = self.api_provider.get_prompt(args, kwargs, function_description,\n                                              self.function_modeler.get_function_description_string(function_description),\n                                              is_distilled_model)\n\n        # check if the model is suitable for distillation\n        if is_distilled_model and not model.is_distillable(prompt):\n            is_distilled_model = False\n\n        # check if the model is suitable for fine-tuning\n        if not is_distilled_model and not model.is_finetunable(prompt):\n            raise NotImplementedError(\n                f\"Model {model.model_name} is not suitable for fine-tuning for function {function_description.name"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # if the function is already initialized, just return the model and prompt\n        if func_hash in self.initialized_functions:\n            model = self.initialized_functions[func_hash][\"model\"]\n            prompt = self.initialized_functions[func_hash][\"prompt\"]\n            return prompt, model, False, True\n\n        # otherwise, initialize the function\n        self.initialized_functions[func_hash] = {\"model\": \"\", \"prompt\": \"\", \"examples\": []}\n\n        # get the model\n        model = self.api_provider.get_model(function_description, llm_parameters)\n\n        # get the prompt\n        prompt = self.api_provider.get_prompt(function_description, args, kwargs)\n\n        # check if the model is suitable for distillation\n        is_distilled_model = self.api_provider.is_distillable(model, prompt)\n\n        # check if the model is suitable for fine-tuning\n        suitable_for_finetuning = self.api_provider.is_finetunable(model, prompt)\n\n        # save the model, prompt, and examples for fine-tuning if needed\n        if not suitable_for_finetuning:\n            self.initialized_functions[func_hash][\"model\"] = model\n            self.initialized_functions[func_hash][\"prompt\"] = prompt\n            self.initialized_functions[func_hash][\"examples\"] = []\n        else:\n            self.initialized_functions[func_hash][\"model\"] = model\n            self.initialized_functions[func_hash][\"prompt\"] = prompt\n            self.initialized_functions[func_hash][\"examples\"] = self.api_provider.get_examples(function_description, args, kwargs)\n\n        return prompt, model, is_distilled_model, False\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        model = self.api_provider.get_model(function_description.name)\n        if not model:\n            raise Exception(f\"Model for function {function_description.name} not found\")\n\n        # check if function is already initialized\n        if func_hash in self.initialized_functions:\n            # check if function has already been initialized with a distilled model\n            if self.initialized_functions[func_hash][\"distilled\"]:\n                return self.construct_prompt(args, kwargs, function_description), model, False, True\n            else:\n                # check if function has already been initialized with a teacher model\n                if self.initialized_functions[func_hash][\"model\"] == model.model_name:\n                    return self.construct_prompt(args, kwargs, function_description), model, False, True\n                else:\n                    # if not, check if the function can be distilled\n                    if model.distil_model:\n                        return self.construct_prompt(args, kwargs, function_description), model, True, False\n                    else:\n                        # if not, check if the function can be fine-tuned\n                        if model.fine_tune:\n                            # check if the function has already been initialized with a teacher model\n                            if self.initialized_functions[func_hash][\"model\"] != \"\":\n                                # check if the function has already been initialized with a teacher model\n                                if self.initialized_functions[func_hash][\"model\"] == model.model_name:\n                                    # if so, check if the function has already been initialized with examples\n                                    if len(self.initialized_functions[func_hash][\"examples\"]) > 0:\n                                        # if so, check if the function has already been initialized with examples\n                                        if len(self.initialized_functions[func_hash][\"examples\"]) < model.max_fine_tuning_examples:\n                                            # if not, add the example to the list\n                                            self.initialized_functions[func_hash][\"examples\"].append(\n                                                FunctionExample(args"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # check if the function is initialized\n        if func_hash not in self.initialized_functions:\n            # if not, initialize it\n            self.initialized_functions[func_hash] = {\n                \"model\": \"\",\n                \"examples\": []\n            }\n\n        # get the model to use\n        model = self.api_provider.get_model(function_description, llm_parameters)\n\n        # check if the model is suitable for distillation\n        if self.api_provider.is_distillable(model):\n            # if so, use a distilled model\n            prompt = self.api_provider.get_distilled_prompt(function_description, args, kwargs)\n            is_distilled_model = True\n        else:\n            # if not, use a teacher model\n            prompt = self.api_provider.get_teacher_prompt(function_description, args, kwargs)\n            is_distilled_model = False\n\n        # check if the function is already initialized and does not require saving examples for fine-tuning\n        if len(self.initialized_functions[func_hash][\"examples\"]) == 0:\n            # if so, return the prompt, model, and distillation boolean\n            return prompt, model, True, is_distilled_model\n\n        # if not, get the token count\n        token_count = approximate_token_count(prompt)\n\n        # if the token count is too high, save the example for fine-tuning\n        if token_count > self.api_provider.get_max_tokens(model):\n            # if so, add the example to the function examples and return the prompt, model, and distillation boolean\n            self.initialized_functions[func_hash][\"examples\"].append((args, kwargs, prompt))\n            return prompt, model, True, is_distilled_model\n\n        # if the token count is too low, use the distilled model\n        if token_count < self.api_provider.get_min_tokens(model):\n            # if so, return the prompt, model, and distillation boolean\n            return prompt, model, False,"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        model = self._get_model(function_description)\n        if not model:\n            raise ValueError(f\"No language model available for {function_description.name}\")\n        is_distilled_model = False\n        if model.distil:\n            # check if the function is already initialized\n            if func_hash in self.initialized_functions:\n                # check if the model is the same\n                if self.initialized_functions[func_hash][\"model\"] == model.model_name:\n                    # if the model is the same, check if the example is suitable for distillation\n                    if self._check_example_distillation_suitability(args, kwargs, function_description,\n                                                                    self.initialized_functions[func_hash][\"examples\"][0]):\n                        # if the example is suitable, use the distilled model\n                        is_distilled_model = True\n                    else:\n                        # if the example is not suitable, use the teacher model\n                        model = model.teacher_model\n            else:\n                # if the function is not initialized, use the distilled model\n                is_distilled_model = True\n        prompt = self._construct_prompt(args, kwargs, function_description, is_distilled_model)\n        save_to_finetune = False\n        if model.distil:\n            # if the model is distilled, check if the example is suitable for fine-tuning\n            if not is_distilled_model:\n                save_to_finetune = self._check_example_finetuning_suitability(args, kwargs, function_description)\n                if save_to_finetune:\n                    # if the example is suitable for fine-tuning, add it to the function's examples\n                    self._add_example_to_function(args, kwargs, function_description)\n        return prompt, model, save_to_finetune, is_distilled_model\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        # Use the Higham & Nick (2002) algorithm\n        cov_nearest = nearest_pd(cov, higham_max_iteration)\n    else:\n        # Clip eigenvalues\n        cov_nearest = cov.copy()\n        w, v = np.linalg.eig(cov_nearest)\n        w[w < _CLIPPING_VALUE] = _CLIPPING_VALUE\n        cov_nearest = v @ np.diag(w) @ v.T\n\n    return cov_nearest\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if cov.ndim != 2:\n        raise ValueError(f\"`cov` must be a 2D array, got a {cov.ndim}D array\")\n    if cov.shape[0] != cov.shape[1]:\n        raise ValueError(\"`cov` must be a square matrix\")\n\n    if higham:\n        # Higham & Nick (2002) algorithm\n        cov_adj = _cov_nearest_higham(cov, max_iteration=higham_max_iteration)\n    else:\n        # Clip eigenvalues\n        cov_adj = _cov_nearest_clip(cov)\n\n    return cov_adj\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if cov.ndim != 2:\n        raise ValueError(f\"`cov` must be a 2D array, got a {cov.ndim}D array\")\n\n    # Compute the nearest correlation matrix\n    if higham:\n        # Use Higham & Nick (2002) algorithm\n        corr, _ = cov_to_corr(cov)\n        corr = _cov_nearest_higham(corr, max_iter=higham_max_iteration)\n    else:\n        # Use clipping\n        corr, _ = cov_to_corr(cov)\n        corr = _cov_nearest_clipping(corr)\n\n    # Compute the nearest covariance matrix\n    cov = corr_to_cov(corr, np.sqrt(np.diag(corr)))\n\n    return cov\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if cov.ndim != 2:\n        raise ValueError(f\"`cov` must be a 2D array, got a {cov.ndim}D array\")\n\n    # Compute the nearest correlation matrix\n    if higham:\n        corr = _cov_to_corr_higham(cov, higham_max_iteration)\n    else:\n        corr, _ = cov_to_corr(cov)\n\n    # Compute the nearest positive definite matrix\n    corr = _corr_to_nearest_pos_def(corr)\n\n    # Compute the nearest covariance matrix\n    cov = corr_to_cov(corr, np.sqrt(np.diag(corr)))\n\n    return cov\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if cov.ndim != 2:\n        raise ValueError(f\"`cov` must be a 2D array, got a {cov.ndim}D array\")\n\n    if np.all(np.linalg.eigvals(cov) > 0):\n        return cov\n\n    if higham:\n        cov_nearest = _cov_nearest_higham(cov, max_iteration=higham_max_iteration)\n    else:\n        cov_nearest = _cov_nearest_clipping(cov)\n\n    return cov_nearest\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if cov.ndim != 2:\n        raise ValueError(f\"`cov` must be a 2D array, got a {cov.ndim}D array\")\n\n    if higham:\n        # Use Higham & Nick (2002) algorithm\n        cov = _cov_nearest_higham(cov, higham_max_iteration)\n    else:\n        # Clip eigenvalues\n        cov = _cov_nearest_clip(cov)\n\n    return cov\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    # Compute the nearest correlation matrix\n    if higham:\n        # Use the Higham & Nick (2002) algorithm\n        corr, _ = cov_to_corr(cov)\n        corr = _cov_nearest_higham(corr, max_iteration=higham_max_iteration)\n    else:\n        # Clip eigenvalues\n        corr, std = cov_to_corr(cov)\n        corr = _cov_nearest_clip(corr)\n\n    # Convert the correlation matrix to a covariance matrix\n    cov = corr_to_cov(corr, std)\n\n    return cov\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        # Use Higham & Nick (2002) algorithm\n        cov = nearest_correlation_matrix(cov, higham_max_iteration)\n    else:\n        # Clip eigenvalues to ensure the matrix is positive definite\n        cov = cov_nearest_pd(cov)\n    return cov\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if cov.ndim != 2:\n        raise ValueError(f\"`cov` must be a 2D array, got a {cov.ndim}D array\")\n    if cov.shape[0] != cov.shape[1]:\n        raise ValueError(f\"`cov` must be a square matrix, got {cov.shape}\")\n\n    if higham:\n        # Use Higham & Nick (2002) algorithm to find the nearest positive definite matrix\n        cov = _cov_nearest_higham(cov, higham_max_iteration)\n    else:\n        # Clip eigenvalues to avoid having a singular matrix\n        cov = _cov_nearest_clip(cov)\n\n    return cov\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        # Higham & Nick (2002) algorithm\n        cov_adj = cov.copy()\n        for i in range(higham_max_iteration):\n            if is_cholesky_dec(cov_adj):\n                break\n            else:\n                cov_adj = _higham_2002(cov_adj)\n        return cov_adj\n    else:\n        # Clipping\n        cov_adj = cov.copy()\n        eigval, eigvec = np.linalg.eigh(cov_adj)\n        eigval[eigval < _CLIPPING_VALUE] = _CLIPPING_VALUE\n        cov_adj = eigvec @ np.diag(eigval) @ eigvec.T\n        return cov_adj\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    # Checking if the covariance matrix is positive definite\n    if is_positive_definite(cov):\n        return cov\n\n    # If the covariance matrix is not positive definite, we use the Higham & Nick (2002) algorithm to find the nearest positive definite matrix\n    if higham:\n        # Computing the nearest correlation matrix\n        corr, _ = cov_to_corr(cov)\n        corr = sch.correlation_tools.cov_nearest(corr, max_iter=higham_max_iteration)\n\n        # Computing the nearest covariance matrix\n        cov = corr_to_cov(corr, np.sqrt(np.diag(corr)))\n\n    # If the Higham & Nick (2002) algorithm is not used, we clip the eigenvalues of the covariance matrix\n    else:\n        # Computing the eigenvalues and eigenvectors of the covariance matrix\n        e, v = np.linalg.eigh(cov)\n\n        # Clipping the eigenvalues\n        e[e < _CLIPPING_VALUE] = _CLIPPING_VALUE\n\n        # Computing the nearest covariance matrix\n        cov = v @ np.diag(e) @ v.T\n\n    return cov\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if cov.ndim != 2:\n        raise ValueError(f\"`cov` must be a 2D array, got a {cov.ndim}D array\")\n\n    if higham:\n        # Higham & Nick (2002) algorithm\n        # https://www.sciencedirect.com/science/article/pii/S0022247X01002121\n        # https://www.maths.manchester.ac.uk/~higham/narep/narep269.pdf\n        cov_new = cov.copy()\n        iteration = 0\n        while not is_cholesky_dec(cov_new) and iteration < higham_max_iteration:\n            iteration += 1\n            w, v = np.linalg.eigh(cov_new)\n            wmin = np.min(w)\n            if wmin < 0:\n                cov_new = cov_new + np.eye(len(w)) * (-wmin + _CLIPPING_VALUE)\n            else:\n                cov_new = cov_new - np.eye(len(w)) * _CLIPPING_VALUE\n    else:\n        # Clipping algorithm\n        w, v = np.linalg.eigh(cov)\n        w[w < _CLIPPING_VALUE] = _CLIPPING_VALUE\n        cov_new = v @ np.diag(w) @ v.T\n\n    return cov_new\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        cov = _cov_nearest_higham(cov, max_iteration=higham_max_iteration)\n    else:\n        cov = _cov_nearest_clipping(cov)\n\n    return cov\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        # Higham & Nick (2002) algorithm\n        cov_nearest = cov.copy()\n        for i in range(higham_max_iteration):\n            try:\n                np.linalg.cholesky(cov_nearest)\n                break\n            except np.linalg.linalg.LinAlgError:\n                # Compute the nearest correlation matrix\n                cov_nearest = cov_to_corr(cov_nearest)[0]\n                cov_nearest = corr_to_cov(cov_nearest, np.sqrt(np.diag(cov_nearest)))\n                # Make it positive definite\n                w, v = np.linalg.eigh(cov_nearest)\n                w[w < 0] = _CLIPPING_VALUE\n                cov_nearest = v @ np.diag(w) @ v.T\n        return cov_nearest\n    else:\n        # Clip eigenvalues\n        w, v = np.linalg.eigh(cov)\n        w[w < _CLIPPING_VALUE] = _CLIPPING_VALUE\n        return v @ np.diag(w) @ v.T\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    # Copy the covariance matrix\n    cov_copy = cov.copy()\n\n    # Check if the covariance matrix is symmetric\n    if not np.allclose(cov_copy, cov_copy.T):\n        raise ValueError(\"The covariance matrix is not symmetric\")\n\n    # Check if the covariance matrix is positive definite\n    if is_positive_definite(cov_copy):\n        return cov_copy\n\n    # Check if the covariance matrix can be decomposed into a Cholesky factor\n    if not is_cholesky_dec(cov_copy):\n        raise ValueError(\"The covariance matrix cannot be decomposed into a Cholesky factor\")\n\n    # Compute the nearest positive definite matrix using the Higham & Nick (2002) algorithm\n    if higham:\n        # Compute the nearest correlation matrix\n        corr_copy = np.linalg.inv(np.sqrt(np.linalg.cholesky(np.linalg.inv(cov_copy))))\n\n        # Compute the nearest positive definite matrix using the Higham & Nick (2002) algorithm\n        cov_copy = HighamNickCovariance(corr_copy, max_iteration=higham_max_iteration)\n\n        # Check if the covariance matrix is positive definite\n        if not is_positive_definite(cov_copy):\n            raise ValueError(\"The covariance matrix is not positive definite\")\n\n        # Check if the covariance matrix can be decomposed into a Cholesky factor\n        if not is_cholesky_dec(cov_copy):\n            raise ValueError(\"The covariance matrix cannot be decomposed into a Cholesky factor\")\n\n        # Return the nearest covariance matrix that is positive definite and allows for a Cholesky decomposition\n        return cov_copy\n\n    # Clip eigenvalues\n    else:\n        # Compute the eigenvalues and eigenvectors of the covariance matrix\n        eig_vals, eig_vecs = np.linalg.eig(cov_copy)\n\n        # Clip eigenvalues\n        eig_vals = np.clip"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    # Check that the input covariance matrix is symmetric\n    if not np.allclose(cov, cov.T):\n        raise ValueError(\"The input covariance matrix must be symmetric\")\n\n    # Compute the nearest correlation matrix\n    corr, std = cov_to_corr(cov)\n    if not higham:\n        corr = _clip_eigenvalues(corr, std)\n    else:\n        corr = _higham_correlation_matrix(corr, std, max_iter=higham_max_iteration)\n\n    # Compute the nearest covariance matrix\n    cov = corr_to_cov(corr, std)\n\n    return cov\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        # Use Higham & Nick (2002) algorithm to compute the nearest correlation matrix\n        # The algorithm is based on the idea of projecting the covariance matrix onto the space of positive definite matrices\n        # This is done by computing the nearest correlation matrix to the original covariance matrix\n        # The nearest correlation matrix is computed using the Higham & Nick (2002) algorithm\n        # The algorithm is based on the spectral decomposition of the covariance matrix\n        # The spectral decomposition is used to compute the nearest correlation matrix to the original covariance matrix\n        # The nearest correlation matrix is computed using the Higham & Nick (2002) algorithm\n        # The nearest correlation matrix is then computed using the spectral decomposition\n        # The nearest correlation matrix is then transformed back to the original space of covariance matrices\n        # The nearest covariance matrix is computed by transforming the nearest correlation matrix to the space of positive definite matrices\n        # The nearest covariance matrix is computed by clipping the eigenvalues of the nearest correlation matrix\n        # The eigenvalues of the nearest correlation matrix are clipped to be above a threshold\n        # The threshold is computed using the original covariance matrix\n        # The threshold is computed as the mean of the absolute value of the eigenvalues of the original covariance matrix\n        # The threshold is computed as the mean of the absolute value of the eigenvalues of the original covariance matrix\n        # The threshold is computed as the mean of the absolute value of the eigenvalues of the original covariance matrix\n        # The threshold is computed as the mean of the absolute value of the eigenvalues of the original covariance matrix\n        # The threshold is computed as the mean of the absolute value of the eigenvalues of the original covariance matrix\n        # The threshold is computed as the mean of the absolute value of the eigenvalues of the original covariance matrix\n        # The threshold is computed as the mean of the absolute value of the eigenvalues of the original covariance matrix\n        # The threshold is computed as the mean of the absolute value of the eigenvalues of the original covariance matrix\n        # The threshold is computed as the mean of the absolute value of the eigenvalues of the original covariance matrix\n        # The threshold is computed as the mean of the absolute value of the eigenvalues of"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        # Higham & Nick (2002) algorithm\n        # https://www.sciencedirect.com/science/article/pii/S0020019002002091\n        # https://www.maths.manchester.ac.uk/~higham/nareff/nareff_v0_9_5.pdf\n        # https://www.maths.manchester.ac.uk/~higham/nareff/nareff.pdf\n        # https://www.maths.manchester.ac.uk/~higham/nareff/naref_code.zip\n        # https://github.com/bmcfee/graphical_lasso/blob/master/graphical_lasso/higham_nearestcorr.py\n        # https://github.com/scipy/scipy/issues/12596\n        # https://stackoverflow.com/questions/52910150/scipy-optimize-minimize-with-bounds-on-the-variables\n        # https://github.com/scipy/scipy/issues/9359\n        # https://github.com/scipy/scipy/pull/9360\n        # https://github.com/scipy/scipy/pull/9360/files\n        # https://github.com/scipy/scipy/issues/11024\n        # https://github.com/scipy/scipy/pull/11025\n        # https://github.com/scipy/scipy/issues/11024/files\n        # https://github.com/scipy/scipy/issues/11819\n        # https://github.com/scipy/scipy/pull/11820\n        # https://github.com/scipy/scipy/issues/11819/files\n        # https://github.com/scipy/scipy/issues/12596\n        # https://github.com/scipy/scipy/pull/12601"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if not higham:\n        # Clip the eigenvalues of the covariance matrix to be positive\n        # and to scale the variance by 1.\n        cov = np.clip(cov, _CLIPPING_VALUE, None)\n        cov /= np.trace(cov)\n        return cov\n\n    # Compute the nearest correlation matrix using the Higham & Nick (2002) algorithm.\n    n = cov.shape[0]\n    x = np.diag(np.diag(cov))\n    d = np.diag(cov)\n    y = np.diag(1 / np.sqrt(d))\n    last_x = np.zeros_like(x)\n\n    for _ in range(higham_max_iteration):\n        last_x[:] = x\n        x = y @ (cov @ (y @ x))\n        if np.allclose(x, last_x, atol=1e-12):\n            break\n\n    if not np.allclose(x, last_x, atol=1e-12):\n        raise ValueError(\"The Higham & Nick (2002) algorithm did not converge.\")\n\n    # Clip the eigenvalues of the correlation matrix to be between 0 and 1.\n    x = np.clip(x, _CLIPPING_VALUE, 1)\n    x = x / np.trace(x)\n    return x\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if not higham:\n        # clip the eigenvalues of the covariance matrix to be above the threshold\n        # threshold is the square root of the smallest eigenvalue\n        eigvals, eigvecs = np.linalg.eigh(cov)\n        threshold = np.sqrt(np.min(eigvals))\n        eigvals[eigvals < threshold] = threshold\n        return eigvecs.dot(np.diag(eigvals)).dot(eigvecs.T)\n\n    # Higham & Nick (2002) algorithm\n    # This algorithm is based on the following paper:\n    # \"Computing the nearest correlation matrix - a problem from finance\"\n    # Higham, Nicholas J. and Nicholas J. Nick (2002) IMA Journal of Numerical Analysis\n    # https://doi.org/10.1093/imanum/24.2.143\n\n    # The algorithm is based on the following:\n    # 1. The covariance matrix is decomposed into a symmetric part and a skew-symmetric part\n    # 2. The symmetric part is positive-definite, and the skew-symmetric part is skew-symmetric\n    # 3. The symmetric part is scaled until it is positive-definite\n    # 4. The covariance matrix is the sum of the scaled symmetric part and the skew-symmetric part\n    # 5. The symmetric part is scaled until it is positive-definite\n\n    # 1. Decompose covariance matrix\n    cov_sym = (cov + cov.T) / 2\n    cov_skew = (cov - cov.T) / 2\n\n    # 2. The symmetric part is positive-definite, and the skew-symmetric part is skew-symmetric\n    # The symmetric part is positive-definite\n    assert_is_positive_definite(cov_sym)\n    # The skew-symmetric part is skew-symmetric\n    assert_is_symmetric(cov_skew)\n\n    # 3. The symmetric part is scaled until"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home=data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home=data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home=data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home=data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    schemas = [\n        ((str, bytes), IdentitySchema),\n        (list, ListSchema),\n        (tuple, TupleSchema),\n        (dict, DictSchema),\n        (Instances, InstancesSchema),\n        (Boxes, TensorWrapSchema),\n        (ROIMasks, TensorWrapSchema),\n    ]\n    for classes, schema in schemas:\n        if isinstance(obj, classes):\n            return schema.flatten(obj)\n    else:\n        raise ValueError(\"Unable to flatten the object!\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes)):\n        # these objects have builtin tracing support\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res, schema = ListSchema.flatten(obj)\n        return res, schema\n    elif isinstance(obj, collections.abc.Mapping):\n        res, schema = DictSchema.flatten(obj)\n        return res, schema\n    elif isinstance(obj, Instances):\n        res, schema = InstancesSchema.flatten(obj)\n        return res, schema\n    elif isinstance(obj, (Boxes, ROIMasks)):\n        res, schema = TensorWrapSchema.flatten(obj)\n        return res, schema\n    else:\n        raise ValueError(f\"Cannot flatten {type(obj)}!\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes)):\n        #\n        # 1. handle strings and bytes\n        #\n        return (obj,), IdentitySchema()\n    if isinstance(obj, torch.Tensor):\n        #\n        # 2. handle tensors\n        #\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        #\n        # 3. handle list or tuple\n        #\n        res, schemas = [], []\n        for k in obj:\n            r, s = flatten_to_tuple(k)\n            res.append(r)\n            schemas.append(s)\n        return tuple(res), ListSchema(schemas)\n    elif isinstance(obj, collections.abc.Mapping):\n        #\n        # 4. handle dictionary\n        #\n        res, schemas, keys = [], [], sorted(obj.keys())\n        for k in keys:\n            r, s = flatten_to_tuple(obj[k])\n            res.append(r)\n            schemas.append(s)\n        return tuple(res), DictSchema(schemas, keys)\n    elif isinstance(obj, Instances):\n        #\n        # 5. handle Instances\n        #\n        res, schemas = [], []\n        for k in sorted(obj.get_fields().keys()):\n            r, s = flatten_to_tuple(obj.get(k))\n            res.append(r)\n            schemas.append(s)\n        size = obj.image_size\n        if not isinstance(size, torch.Tensor):\n            size = torch.tensor(size)\n        res.append(size)\n        return tuple(res), InstancesSchema(schemas)\n    elif isinstance(obj, (Boxes, ROIMasks)):\n        #\n        # 6. handle Boxes and ROIMasks\n        #\n        return (obj.tensor,), TensorWrapSchema(_convert_target_to_string(type(obj)))\n    else:\n        raise NotImplementedError(f\"Type {type(obj)} not supported\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    schemas = [\n        (isinstance(obj, str), StringSchema),\n        (isinstance(obj, bytes), BytesSchema),\n        (isinstance(obj, torch.Tensor), TensorSchema),\n        (isinstance(obj, (list, tuple)), ListSchema),\n        (isinstance(obj, collections.abc.Mapping), DictSchema),\n        (isinstance(obj, Instances), InstancesSchema),\n        (isinstance(obj, Boxes), TensorWrapSchema),\n        (isinstance(obj, ROIMasks), TensorWrapSchema),\n    ]\n    for type_check, schema in schemas:\n        if type_check:\n            return schema.flatten(obj)\n    raise TypeError(\"Type {} is not supported.\".format(type(obj)))\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    schemas = [\n        ((str, bytes), IdentitySchema),\n        (list, ListSchema),\n        (tuple, TupleSchema),\n        (collections.abc.Mapping, DictSchema),\n        ((Instances, ROIMasks, Boxes), InstancesSchema),\n        (TensorWrapSchema, TensorWrapSchema),\n    ]\n    for classes, schema in schemas:\n        if isinstance(obj, classes):\n            return schema.flatten(obj)\n    return (obj,), IdentitySchema()\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes)):\n        #\n        # 1. handle string or bytes\n        #\n        return (obj,), IdentitySchema()\n    if isinstance(obj, torch.Tensor):\n        #\n        # 2. handle tensor\n        #\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        #\n        # 3. handle list or tuple\n        #\n        res, schema = ListSchema.flatten(obj)\n        return res, schema\n    elif isinstance(obj, collections.abc.Mapping):\n        #\n        # 4. handle dictionary\n        #\n        res, schema = DictSchema.flatten(obj)\n        return res, schema\n    elif isinstance(obj, Instances):\n        #\n        # 5. handle Instances\n        #\n        res, schema = InstancesSchema.flatten(obj)\n        return res, schema\n    elif isinstance(obj, (Boxes, ROIMasks)):\n        #\n        # 6. handle Boxes or ROIMasks\n        #\n        return (obj.tensor,), TensorWrapSchema(_convert_target_to_string(type(obj)))\n    else:\n        raise ValueError(f\"Cannot flatten {type(obj)}!\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes)):\n        #\n        # if it is a string or bytes, we wrap it with tensor\n        # to make tracing work\n        #\n        obj = torch.tensor(obj)\n    if isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res, schemas = zip(*[flatten_to_tuple(k) for k in obj])\n        return tuple([*res]), ListSchema(list(schemas))\n    elif isinstance(obj, collections.abc.Mapping):\n        res, schemas = zip(*[flatten_to_tuple(obj[k]) for k in sorted(obj.keys())])\n        return tuple([*res]), DictSchema(list(schemas), sorted(obj.keys()))\n    elif isinstance(obj, Instances):\n        res, schemas = zip(*[flatten_to_tuple(getattr(obj, k)) for k in obj._fields.keys()])\n        res = list(res)\n        res.append(obj.image_size)\n        res = tuple(res)\n        return res, InstancesSchema(list(schemas), sorted(obj._fields.keys()))\n    elif isinstance(obj, (Boxes, ROIMasks)):\n        return (obj.tensor,), TensorWrapSchema(_convert_target_to_string(type(obj)))\n    else:\n        raise NotImplementedError(f\"Type {type(obj)} not supported yet!\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes)):\n        #\n        # 1. handle the type that has builtin len()\n        #\n        return (obj,), IdentitySchema()\n    if isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, (list, tuple)):\n        res, schema = ListSchema.flatten(obj)\n        return res, schema\n    if isinstance(obj, collections.abc.Mapping):\n        res, schema = DictSchema.flatten(obj)\n        return res, schema\n    if isinstance(obj, Instances):\n        res, schema = InstancesSchema.flatten(obj)\n        return res, schema\n    if isinstance(obj, (Boxes, ROIMasks)):\n        return (obj.tensor,), TensorWrapSchema(_convert_target_to_string(type(obj)))\n\n    raise NotImplementedError(f\"Type {type(obj)} not supported\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes)):\n        # TODO: maybe encode bytes to str\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res, schema = ListSchema.flatten(obj)\n        return res, schema\n    elif isinstance(obj, collections.abc.Mapping):\n        res, schema = DictSchema.flatten(obj)\n        return res, schema\n    elif isinstance(obj, Instances):\n        res, schema = InstancesSchema.flatten(obj)\n        return res, schema\n    elif isinstance(obj, Boxes):\n        return (obj.tensor,), TensorWrapSchema(\"Boxes\")\n    elif isinstance(obj, ROIMasks):\n        return (obj.tensor,), TensorWrapSchema(\"ROIMasks\")\n    else:\n        raise TypeError(f\"Type {type(obj)} not supported\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes)):\n        #\n        # 1. handle strings and bytes\n        #\n        return (obj,), IdentitySchema()\n    if isinstance(obj, (list, tuple)):\n        #\n        # 2. handle lists and tuples\n        #\n        res, schema = ListSchema.flatten(obj)\n        return res, schema\n    elif isinstance(obj, collections.abc.Mapping):\n        #\n        # 3. handle dict\n        #\n        res, schema = DictSchema.flatten(obj)\n        return res, schema\n    elif isinstance(obj, Instances):\n        #\n        # 4. handle Instances\n        #\n        res, schema = InstancesSchema.flatten(obj)\n        return res, schema\n    elif isinstance(obj, (Boxes, ROIMasks)):\n        #\n        # 5. handle Boxes, ROIMasks\n        #\n        return (obj.tensor,), TensorWrapSchema(_convert_target_to_string(type(obj)))\n    else:\n        raise TypeError(f\"Type {type(obj)} not supported for flattening!\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    schemas = [\n        ((str, bytes), IdentitySchema),\n        (list, ListSchema),\n        (tuple, TupleSchema),\n        (dict, DictSchema),\n        (Instances, InstancesSchema),\n        (Boxes, TensorWrapSchema),\n        (ROIMasks, TensorWrapSchema),\n    ]\n    for klasses, schema in schemas:\n        if isinstance(obj, klasses):\n            res, schema = schema.flatten(obj)\n            return res, schema\n    else:\n        raise ValueError(\"Cannot flatten data of type %s.\" % type(obj))\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes)):\n        #\n        # handle str and bytes separately as they are immutable in python and thus tracing does not work\n        #\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res, schema = ListSchema.flatten(obj)\n        return res, schema\n    elif isinstance(obj, collections.abc.Mapping):\n        res, schema = DictSchema.flatten(obj)\n        return res, schema\n    elif isinstance(obj, Instances):\n        res, schema = InstancesSchema.flatten(obj)\n        return res, schema\n    elif isinstance(obj, (Boxes, ROIMasks)):\n        return (obj.tensor,), TensorWrapSchema(_convert_target_to_string(type(obj)))\n    else:\n        raise TypeError(f\"Cannot flatten {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes)):\n        #\n        # TODO: PyTorch does not support serializing str or bytes.\n        # This is a workaround to convert them to tensors for now.\n        # https://github.com/pytorch/pytorch/issues/11232\n        #\n        # We assume strings are at most 256 characters\n        if isinstance(obj, str):\n            obj = obj.encode()\n        obj = torch.as_tensor(bytearray(obj))\n    if torch.is_tensor(obj):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, list):\n        res, schema = ListSchema.flatten(obj)\n        return res, schema\n    elif isinstance(obj, tuple):\n        res, schema = TupleSchema.flatten(obj)\n        return res, schema\n    elif isinstance(obj, collections.abc.Mapping):\n        res, schema = DictSchema.flatten(obj)\n        return res, schema\n    elif isinstance(obj, Instances):\n        res, schema = InstancesSchema.flatten(obj)\n        return res, schema\n    elif isinstance(obj, (Boxes, ROIMasks)):\n        return (obj.tensor,), TensorWrapSchema(_convert_target_to_string(type(obj)))\n    else:\n        raise ValueError(f\"Cannot flatten {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes)):\n        #\n        # 1. handle the type that has builtin len()\n\n        return (obj,), IdentitySchema()\n    if isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, (list, tuple)):\n        # 2. handle list or tuple\n        res, schema = ListSchema.flatten(obj)\n        return res, schema\n    if isinstance(obj, collections.abc.Mapping):\n        # 3. handle mapping\n        res, schema = DictSchema.flatten(obj)\n        return res, schema\n    if isinstance(obj, Instances):\n        res, schema = InstancesSchema.flatten(obj)\n        return res, schema\n    if isinstance(obj, (Boxes, ROIMasks)):\n        res, schema = TensorWrapSchema.flatten(obj)\n        return res, schema\n\n    raise TypeError(f\"Type {type(obj)} not supported\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        # str is a subclass of bytes so this must be checked first\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res, schema = ListSchema.flatten(obj)\n        return res, schema\n    elif isinstance(obj, collections.abc.Mapping):\n        res, schema = DictSchema.flatten(obj)\n        return res, schema\n    elif isinstance(obj, Instances):\n        res, schema = InstancesSchema.flatten(obj)\n        return res, schema\n    elif isinstance(obj, Boxes):\n        return (obj.tensor,), TensorWrapSchema(\"Boxes\")\n    elif isinstance(obj, ROIMasks):\n        return (obj.tensor,), TensorWrapSchema(\"ROIMasks\")\n    else:\n        raise ValueError(f\"Cannot flatten {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes)):\n        # TODO: maybe encode bytes to str\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res, schema = ListSchema.flatten(obj)\n        return res, schema\n    elif isinstance(obj, collections.abc.Mapping):\n        res, schema = DictSchema.flatten(obj)\n        return res, schema\n    elif isinstance(obj, Instances):\n        res, schema = InstancesSchema.flatten(obj)\n        return res, schema\n    elif isinstance(obj, ROIMasks):\n        res, schema = TensorWrapSchema.flatten(obj)\n        return res, schema\n    elif isinstance(obj, Boxes):\n        res, schema = TensorWrapSchema.flatten(obj)\n        return res, schema\n    else:\n        raise ValueError(f\"Cannot flatten {type(obj)}!\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        # str is a subclass of bytes, but we want to treat them differently\n        # since tracing does not support bytes\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (bytes, bytearray)):\n        # tracing does not support bytes\n        # this is mainly for torch.jit.save\n        obj = str(obj)\n        return flatten_to_tuple(obj)\n    elif dataclasses.is_dataclass(obj):\n        res, schema = DictSchema.flatten(dataclasses.asdict(obj))\n        return res, schema\n    elif isinstance(obj, (list, tuple)):\n        res, schema = ListSchema.flatten(obj)\n        if isinstance(obj, list):\n            return res, schema\n        else:\n            return res, TupleSchema(schema.schemas, schema.sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        res, schema = DictSchema.flatten(dict(obj))\n        return res, schema\n    elif isinstance(obj, (Instances, Boxes, ROIMasks)):\n        res, schema = obj.get_schema().flatten(obj)\n        return res, schema\n    else:\n        try:\n            # arbitrary tensor-like object\n            return (obj,), TensorWrapSchema(_convert_target_to_string(type(obj)))\n        except (TypeError, AttributeError):\n            # not a tensor-like object\n            return (obj,), IdentitySchema()\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes)):\n        #\n        # if obj is a string or bytes, the tensor conversion will throw an error, so return early\n        #\n        return (obj,), IdentitySchema()\n\n    if torch.is_tensor(obj):\n        return (obj,), IdentitySchema()\n\n    if isinstance(obj, (list, tuple)):\n        res, schema = ListSchema.flatten(obj)\n        return res, schema\n\n    if isinstance(obj, collections.abc.Mapping):\n        res, schema = DictSchema.flatten(obj)\n        return res, schema\n\n    if isinstance(obj, Instances):\n        res, schema = InstancesSchema.flatten(obj)\n        return res, schema\n\n    if isinstance(obj, (Boxes, ROIMasks)):\n        res, schema = TensorWrapSchema.flatten(obj)\n        return res, schema\n\n    raise NotImplementedError(f\"Cannot flatten a {type(obj)} object\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    schemas = [\n        ((str, bytes), IdentitySchema),\n        (list, ListSchema),\n        (tuple, TupleSchema),\n        (collections.abc.Mapping, DictSchema),\n        ((Instances, ROIMasks, Boxes), InstancesSchema),\n        (TensorWrapSchema, TensorWrapSchema),\n    ]\n    for klasses, schema in schemas:\n        if isinstance(obj, klasses):\n            res, schema = schema.flatten(obj)\n            return res, schema\n    else:\n        return obj, None\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    schemas = [\n        ((str, bytes), IdentitySchema),\n        (list, ListSchema),\n        (tuple, TupleSchema),\n        (collections.abc.Mapping, DictSchema),\n        (Instances, InstancesSchema),\n        (Boxes, TensorWrapSchema),\n        (ROIMasks, TensorWrapSchema),\n    ]\n    for klasses, schema in schemas:\n        if isinstance(obj, klasses):\n            return schema.flatten(obj)\n    return obj, None\n\n"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    if not isinstance(groups, (np.ndarray, list)):\n        raise TypeError(\n            f\"{names[0]} should be an array-like of shape (n_groups, n_assets).\"\n        )\n\n    if not isinstance(equations, (np.ndarray, list)):\n        raise TypeError(\n            f\"{names[1]} should be an array-like of shape (n_equations,).\"\n        )\n\n    if not isinstance(sum_to_one, bool):\n        raise TypeError(\"sum_to_one should be a boolean.\")\n\n    if not isinstance(raise_if_group_missing, bool):\n        raise TypeError(\"raise_if_group_missing should be a boolean.\")\n\n    if not isinstance(names, tuple):\n        raise TypeError(\"names should be a tuple of two strings.\")\n\n    if not len(names) == 2:\n        raise ValueError(\"names should be a tuple of two strings.\")\n\n    groups = np.array(groups)\n    equations = np.array(equations)\n\n    if groups.ndim != 2:\n        raise ValueError(\n            f\"{names[0]} should be an array-like of shape (n_groups, n_assets).\"\n        )\n\n    if equations.ndim != 1:\n        raise ValueError(\n            f\"{names[1]} should be an array-like of shape (n_equations,).\"\n        )\n\n    if groups.shape[0] == 0:\n        raise ValueError(\n            f\"{names[0]} should be an array-like of shape (n_groups, n_assets).\"\n        )\n\n    if equations.size == 0:\n        raise ValueError(\n            f\"{names[1]} should be an array-like of shape (n_equations,).\"\n        )\n\n    if groups.shape[1] == 0:\n        raise ValueError(\n            f\"{names[0]} should be an array-like of shape (n_groups, n_assets).\"\n        )\n\n    if not isinstance(sum_to_one,"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    if not isinstance(groups, (list, np.ndarray)):\n        raise TypeError(\n            f\"{names[0]} must be a list or numpy array, but got {type(groups)}\"\n        )\n\n    if not isinstance(equations, (list, np.ndarray)):\n        raise TypeError(\n            f\"{names[1]} must be a list or numpy array, but got {type(equations)}\"\n        )\n\n    if not isinstance(sum_to_one, bool):\n        raise TypeError(\n            f\"sum_to_one must be a boolean, but got {type(sum_to_one)}\"\n        )\n\n    if not isinstance(raise_if_group_missing, bool):\n        raise TypeError(\n            f\"raise_if_group_missing must be a boolean, but got {type(raise_if_group_missing)}\"\n        )\n\n    if not isinstance(names, tuple):\n        raise TypeError(\n            f\"names must be a tuple, but got {type(names)}\"\n        )\n\n    if not isinstance(names[0], str):\n        raise TypeError(\n            f\"names[0] must be a string, but got {type(names[0])}\"\n        )\n\n    if not isinstance(names[1], str):\n        raise TypeError(\n            f\"names[1] must be a string, but got {type(names[1])}\"\n        )\n\n    # Convert groups to numpy array\n    groups = np.array(groups)\n\n    # Convert equations to numpy array\n    equations = np.array(equations)\n\n    # Check if groups is 2D\n    if len(groups.shape) != 2:\n        raise ValueError(\n            f\"{names[0]} must be a 2D array, but got {len(groups.shape)} dimensions\"\n        )\n\n    # Check if equations is 1D\n    if len(equations.shape) != 1:\n        raise ValueError(\n            f\"{names[1]} must be a 1D array, but got {len(equations.shape)} dimensions\"\n       "}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    if not isinstance(groups, (np.ndarray, list)):\n        raise TypeError(f\"{names[0]} must be an array-like object\")\n\n    if not isinstance(equations, (np.ndarray, list)):\n        raise TypeError(f\"{names[1]} must be an array-like object\")\n\n    if len(groups) == 0:\n        raise ValueError(f\"{names[0]} cannot be empty\")\n\n    if len(equations) == 0:\n        raise ValueError(f\"{names[1]} cannot be empty\")\n\n    if len(groups) == 1:\n        warnings.warn(\n            f\"{names[0]} contains only one group. The output matrices will be None\",\n            UserWarning,\n        )\n\n    if len(equations) == 1:\n        warnings.warn(\n            f\"{names[1]} contains only one equation. The output matrices will be None\",\n            UserWarning,\n        )\n\n    if not isinstance(sum_to_one, bool):\n        raise TypeError(\"sum_to_one must be a boolean\")\n\n    if not isinstance(raise_if_group_missing, bool):\n        raise TypeError(\"raise_if_group_missing must be a boolean\")\n\n    if not isinstance(names, tuple):\n        raise TypeError(\"names must be a tuple\")\n\n    if not isinstance(names[0], str):\n        raise TypeError(\"names[0] must be a string\")\n\n    if not isinstance(names[1], str):\n        raise TypeError(\"names[1] must be a string\")\n\n    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n\n    if groups.ndim != 2:\n        raise ValueError(f\"{names[0]} must be a 2D array\")\n\n    if equations.ndim != 1:\n        raise ValueError(f\"{names[1]} must be a 1D array\")\n\n    if groups.shape[1] != equations.shape[0]:\n        raise ValueError(\n            f\"The number of groups in {names"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    if isinstance(groups, list):\n        groups = np.array(groups)\n    if isinstance(equations, list):\n        equations = np.array(equations)\n\n    if len(groups.shape) != 2:\n        raise ValueError(\n            \"The 'groups' parameter should be a 2D array of assets groups, where each row can be a different categorization of assets (e.g., by type or region).\"\n        )\n    if len(equations.shape) != 1:\n        raise ValueError(\n            \"The 'equations' parameter should be a 1D array of string representations of linear equations that describe the relationships between different groups of assets.\"\n        )\n\n    if not isinstance(sum_to_one, bool):\n        raise TypeError(\"The 'sum_to_one' parameter should be a boolean.\")\n    if not isinstance(raise_if_group_missing, bool):\n        raise TypeError(\"The 'raise_if_group_missing' parameter should be a boolean.\")\n    if not isinstance(names, tuple):\n        raise TypeError(\"The 'names' parameter should be a tuple.\")\n    if len(names) != 2:\n        raise ValueError(\"The 'names' parameter should be a tuple with two strings.\")\n\n    if not isinstance(groups, np.ndarray):\n        raise TypeError(\"The 'groups' parameter should be a numpy array.\")\n    if not isinstance(equations, np.ndarray):\n        raise TypeError(\"The 'equations' parameter should be a numpy array.\")\n    if not isinstance(sum_to_one, bool):\n        raise TypeError(\"The 'sum_to_one' parameter should be a boolean.\")\n    if not isinstance(raise_if_group_missing, bool):\n        raise TypeError(\"The 'raise_if_group_missing' parameter should be a boolean.\")\n    if not isinstance(names, tuple):\n        raise TypeError(\"The 'names' parameter should be a tuple.\")\n    if len(names) != 2:\n        raise ValueError(\"The 'names' parameter should be a tuple with two strings.\")\n\n    if not isinstance(groups, np.ndarray):\n        raise"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check input arguments\n    if not isinstance(groups, (list, tuple, np.ndarray)):\n        raise TypeError(f\"{names[0]} must be an array-like object.\")\n    if not isinstance(equations, (list, tuple, np.ndarray)):\n        raise TypeError(f\"{names[1]} must be an array-like object.\")\n    if not isinstance(sum_to_one, bool):\n        raise TypeError(\"sum_to_one must be a boolean.\")\n    if not isinstance(raise_if_group_missing, bool):\n        raise TypeError(\"raise_if_group_missing must be a boolean.\")\n    if not isinstance(names, (list, tuple)):\n        raise TypeError(\"names must be a tuple of two strings.\")\n    if len(names) != 2:\n        raise ValueError(\"names must be a tuple of two strings.\")\n    if not isinstance(names[0], str):\n        raise TypeError(\"names[0] must be a string.\")\n    if not isinstance(names[1], str):\n        raise TypeError(\"names[1] must be a string.\")\n\n    # Convert input arguments to numpy arrays\n    groups = np.array(groups, dtype=object)\n    equations = np.array(equations, dtype=object)\n\n    # Check input arguments\n    if groups.ndim != 2:\n        raise ValueError(f\"{names[0]} must be a 2D array.\")\n    if equations.ndim != 1:\n        raise ValueError(f\"{names[1]} must be a 1D array.\")\n    if groups.shape[1] != equations.shape[0]:\n        raise ValueError(\n            f\"The number of columns of {names[0]} must be equal to the number of elements of {names[1]}.\"\n        )\n\n    # Convert equations to matrix\n    left_matrix, right_matrix = _equations_to_matrix(groups, equations, sum_to_one)\n\n    # Check if any of the groups in the equations are part of the input groups\n    if left_matrix is None:\n        if raise_if_group_missing:\n            raise Group"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check that groups is array-like\n    if not isinstance(groups, (np.ndarray, list)):\n        raise TypeError(\n            f\"{names[0]} must be an array-like object. Got {type(groups)} instead.\"\n        )\n\n    # Check that equations is array-like\n    if not isinstance(equations, (np.ndarray, list)):\n        raise TypeError(\n            f\"{names[1]} must be an array-like object. Got {type(equations)} instead.\"\n        )\n\n    # Check that groups is not empty\n    if len(groups) == 0:\n        raise ValueError(f\"{names[0]} must not be empty.\")\n\n    # Check that equations is not empty\n    if len(equations) == 0:\n        raise ValueError(f\"{names[1]} must not be empty.\")\n\n    # Check that groups is a 2D array\n    if groups.ndim != 2:\n        raise ValueError(f\"{names[0]} must be a 2D array. Got {groups.ndim}D instead.\")\n\n    # Check that groups is not a 1D array\n    if groups.ndim == 1:\n        raise ValueError(\n            f\"{names[0]} must not be a 1D array. Got 1D instead. If you have only one group, please reshape it to 2D using groups.reshape(1, -1).\"\n        )\n\n    # Check that groups is not a 1D array\n    if groups.shape[1] == 1:\n        raise ValueError(\n            f\"{names[0]} must not be a 1D array. Got 1D instead. If you have only one group, please reshape it to 2D using groups.reshape(1, -1).\"\n        )\n\n    # Check that equations is a 1D array\n    if equations.ndim != 1:\n        raise ValueError(\n            f\"{names[1]} must be a 1D array. Got {equations.ndim}D instead.\"\n        )\n\n    # Check that equations is not"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    if not isinstance(groups, (list, tuple, np.ndarray)):\n        raise TypeError(\n            f\"groups must be a list or tuple of strings, not {type(groups)}\"\n        )\n\n    if not isinstance(equations, (list, tuple, np.ndarray)):\n        raise TypeError(\n            f\"equations must be a list or tuple of strings, not {type(equations)}\"\n        )\n\n    if not isinstance(sum_to_one, bool):\n        raise TypeError(f\"sum_to_one must be a bool, not {type(sum_to_one)}\")\n\n    if not isinstance(raise_if_group_missing, bool):\n        raise TypeError(\n            f\"raise_if_group_missing must be a bool, not {type(raise_if_group_missing)}\"\n        )\n\n    if not isinstance(names, (list, tuple)):\n        raise TypeError(f\"names must be a list or tuple, not {type(names)}\")\n\n    if len(names) != 2:\n        raise ValueError(f\"names must be a list or tuple of length 2\")\n\n    if not all(isinstance(name, str) for name in names):\n        raise TypeError(\n            f\"names must be a list or tuple of strings, not {[type(name) for name in names]}\"\n        )\n\n    groups = np.array(groups)\n    equations = np.array(equations)\n\n    if groups.shape[0] == 0:\n        warnings.warn(\n            f\"{names[0]} is empty. Returning None\",\n            RuntimeWarning,\n        )\n        return None, None\n\n    if equations.shape[0] == 0:\n        warnings.warn(\n            f\"{names[1]} is empty. Returning None\",\n            RuntimeWarning,\n        )\n        return None, None\n\n    if groups.shape[1] != equations.shape[1]:\n        raise EquationToMatrixError(\n            f\"groups and equations must have the same number of columns, not {groups.shape[1]} and {equations.shape"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check groups\n    groups = np.array(groups, dtype=float)\n    if groups.ndim != 2:\n        raise ValueError(\n            f\"The parameter {names[0]} should be a 2D array of assets groups, where each row can be a different categorization of assets (e.g., by type or region).\"\n        )\n\n    # Check equations\n    equations = np.array(equations, dtype=object)\n    if equations.ndim != 1:\n        raise ValueError(\n            f\"The parameter {names[1]} should be a 1D array of string representations of linear equations that describe the relationships between different groups of assets.\"\n        )\n\n    # Check that equations are linear\n    for equation in equations:\n        if \"**\" in equation or \"*\" in equation:\n            raise ValueError(\n                \"Only linear equations are supported. The use of '**' or '*' is not allowed.\"\n            )\n\n    # Check that equations are valid\n    for equation in equations:\n        if not re.match(r\"^[\\w\\s\\+\\-\\*\\/]*=[\\w\\s\\+\\-\\*\\/]*$\", equation):\n            raise ValueError(\n                \"Each equation should be a string representation of a linear equation that describes the relationships between different groups of assets. The use of '**' or '*' is not allowed.\"\n            )\n\n    # Check that equations are well-formed\n    for equation in equations:\n        if \"=\" not in equation:\n            raise ValueError(\n                \"Each equation should be a string representation of a linear equation that describes the relationships between different groups of assets. The use of '**' or '*' is not allowed.\"\n            )\n\n    # Check that equations are well-formed\n    for equation in equations:\n        if equation.count(\"=\") != 1:\n            raise ValueError(\n                \"Each equation should be a string representation of a linear equation that describes the relationships between different groups of assets. The use of '**' or '*' is not allowed.\"\n            )\n\n    # Check that equations are well-formed\n    for equation in equations:\n        if not re.match(r\""}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check input arguments\n    if not isinstance(groups, (list, np.ndarray)):\n        raise TypeError(f\"{names[0]} must be a list or numpy array\")\n\n    if not isinstance(equations, (list, np.ndarray)):\n        raise TypeError(f\"{names[1]} must be a list or numpy array\")\n\n    if not isinstance(sum_to_one, bool):\n        raise TypeError(\"sum_to_one must be a boolean\")\n\n    if not isinstance(raise_if_group_missing, bool):\n        raise TypeError(\"raise_if_group_missing must be a boolean\")\n\n    if not isinstance(names, tuple):\n        raise TypeError(\"names must be a tuple\")\n\n    # Convert input arguments to numpy arrays\n    groups = np.array(groups)\n    equations = np.array(equations)\n\n    # Check input arguments\n    if groups.ndim != 2:\n        raise ValueError(f\"{names[0]} must be a 2D array\")\n\n    if equations.ndim != 1:\n        raise ValueError(f\"{names[1]} must be a 1D array\")\n\n    # Create a dictionary of groups\n    groups_dict = {\n        name: np.where(groups == name)[1] for name in np.unique(groups.ravel())\n    }\n\n    # Check if there are equations\n    if len(equations) == 0:\n        return None, None\n\n    # Check if there are groups\n    if len(groups_dict) == 0:\n        raise EquationToMatrixError(\"No groups found\")\n\n    # Initialize the left and right matrices\n    left_matrix = np.zeros((len(equations), len(groups_dict)))\n    right_matrix = np.zeros((len(equations),))\n\n    # Iterate over equations\n    for i, equation in enumerate(equations):\n\n        # Split the equation into left and right sides\n        left_side, right_side = equation.split(\"=\")\n\n        # Split the left side into terms\n        terms = left_side.split(\"+"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n\n    # Check inputs\n    if groups.ndim != 2:\n        raise ValueError(f\"{names[0]} must be a 2D array\")\n    if equations.ndim != 1:\n        raise ValueError(f\"{names[1]} must be a 1D array\")\n    if groups.shape[1] != equations.shape[1]:\n        raise ValueError(\n            f\"The number of columns in {names[0]} must be the same as the number of columns in {names[1]}\"\n        )\n    if not isinstance(sum_to_one, bool):\n        raise TypeError(\"sum_to_one must be a boolean\")\n    if not isinstance(raise_if_group_missing, bool):\n        raise TypeError(\"raise_if_group_missing must be a boolean\")\n    if not isinstance(names, tuple):\n        raise TypeError(\"names must be a tuple\")\n    if len(names) != 2:\n        raise ValueError(\"names must be a tuple of two strings\")\n\n    # Parse equations\n    left_matrix = []\n    right_matrix = []\n    for eq in equations:\n        if not isinstance(eq, str):\n            raise TypeError(f\"{names[1]} must contain strings\")\n        left_side = []\n        right_side = []\n        for group in re.findall(r\"\\[.*?\\]\", eq):\n            try:\n                group_idx = np.where(groups == group)[1][0]\n            except IndexError:\n                if raise_if_group_missing:\n                    raise GroupNotFoundError(f\"{group} not found in {names[0]}\")\n                else:\n                    warnings.warn(\n                        f\"{group} not found in {names[0]}. It will be ignored.\",\n                        UserWarning,\n                    )\n                    continue\n            left_side.append(group_idx)\n            right_side.append(1)\n        if len(left_side) == 0:\n            continue\n        if sum_to"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check inputs\n    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n    if groups.ndim != 2:\n        raise ValueError(f\"The '{names[0]}' parameter must be a 2D array.\")\n    if equations.ndim != 1:\n        raise ValueError(f\"The '{names[1]}' parameter must be a 1D array.\")\n    if groups.shape[1] < 2:\n        raise ValueError(f\"The '{names[0]}' parameter must have at least two columns.\")\n    if not isinstance(sum_to_one, bool):\n        raise TypeError(f\"The 'sum_to_one' parameter must be a boolean.\")\n    if not isinstance(raise_if_group_missing, bool):\n        raise TypeError(f\"The 'raise_if_group_missing' parameter must be a boolean.\")\n\n    # Build a dictionary of groups and their indices\n    group_to_indices = {}\n    for i, group in enumerate(groups):\n        group_to_indices[tuple(group)] = i\n\n    # Build the left and right matrices\n    left = []\n    right = []\n    for equation in equations:\n        # Split the equation into left and right parts\n        left_str, right_str = equation.split(\"=\")\n        left_str = left_str.strip()\n        right_str = right_str.strip()\n\n        # Split the left part into groups\n        left_groups = re.split(r\"\\s*[+-]\\s*\", left_str)\n        left_groups = [group.strip() for group in left_groups]\n\n        # Split the right part into groups\n        right_groups = re.split(r\"\\s*[+-]\\s*\", right_str)\n        right_groups = [group.strip() for group in right_groups]\n\n        # Check that there is exactly one right group\n        if len(right_groups) != 1:\n            raise EquationToMatrixError(\n                f\"The '{names[1]}' parameter must contain exactly one group on the right side of the"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check input\n    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n    if groups.ndim != 2:\n        raise ValueError(f\"{names[0]} must be a 2D array.\")\n    if equations.ndim != 1:\n        raise ValueError(f\"{names[1]} must be a 1D array.\")\n\n    # Convert equations to matrix\n    groups_names = [f\"G{i}\" for i in range(groups.shape[0])]\n    groups_dict = {groups_names[i]: groups[i] for i in range(groups.shape[0])}\n    left_matrix = np.zeros((equations.size, groups.shape[1]))\n    right_matrix = np.zeros((equations.size,))\n    for i, equation in enumerate(equations):\n        # Parse equation\n        try:\n            left_side, right_side = re.split(\"<=|>=|==|<|>\", equation)\n        except ValueError:\n            raise EquationToMatrixError(\n                \"Equation must be of the form 'A <= B' or 'A >= B' or 'A < B' or 'A > B' or 'A == B'.\"\n            )\n\n        # Parse left side\n        left_side = left_side.replace(\" \", \"\")\n        left_side_groups = re.findall(r\"[A-Z]\", left_side)\n        left_side_coeffs = re.findall(r\"-?\\d*\\.?\\d*\", left_side)\n        if len(left_side_groups) != len(left_side_coeffs):\n            raise EquationToMatrixError(\n                \"Left side of the equation must be of the form 'aG1 + bG2 + cG3 + ...'.\"\n            )\n        for group, coeff in zip(left_side_groups, left_side_coeffs):\n            if group not in groups_names:\n                if raise_if_group_missing:\n                    raise GroupNotFoundError(f\"Group {group} not found"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    if len(groups) == 0:\n        raise ValueError(f\"'{names[0]}' must not be empty.\")\n    if len(equations) == 0:\n        raise ValueError(f\"'{names[1]}' must not be empty.\")\n\n    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n\n    if groups.ndim != 2:\n        raise ValueError(f\"'{names[0]}' must be a 2D array.\")\n    if equations.ndim != 1:\n        raise ValueError(f\"'{names[1]}' must be a 1D array.\")\n\n    if not np.issubdtype(groups.dtype, np.number):\n        raise ValueError(f\"'{names[0]}' must be numeric.\")\n    if not np.issubdtype(equations.dtype, np.str_):\n        raise ValueError(f\"'{names[1]}' must be strings.\")\n\n    if groups.shape[1] != equations.size:\n        raise ValueError(\n            f\"The number of columns in '{names[0]}' must match the number of elements in '{names[1]}'.\"\n        )\n\n    groups_names = np.unique(groups)\n\n    left = np.zeros((equations.size, groups.shape[1]))\n    right = np.zeros((equations.size,))\n\n    for i, equation in enumerate(equations):\n        if \"=\" in equation:\n            raise EquationToMatrixError(\n                \"Equations must be of the form 'A1 - A2 + A3 <= 0' or 'A1 + A2 + A3 >= 0'.\",\n                equation,\n            )\n        elif not equation:\n            raise EquationToMatrixError(\"Equations must not be empty.\", equation)\n        elif not equation.strip():\n            raise EquationToMatrixError(\"Equations must not be blank.\", equation)\n\n        try:\n            left[i, :] = _equation_to_matrix(\n                equation, groups_names, groups, sum_to_"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n    n_groups, n_assets = groups.shape\n\n    # Check input arguments\n    if groups.ndim != 2:\n        raise ValueError(\n            f\"The input array {names[0]} should be of shape (n_groups, n_assets).\"\n        )\n    if equations.ndim != 1:\n        raise ValueError(\n            f\"The input array {names[1]} should be of shape (n_equations,).\"\n        )\n    if np.any(groups.sum(axis=1) == 0):\n        raise ValueError(\n            \"The input array groups should contain at least one asset in each group.\"\n        )\n\n    # Find groups mentioned in the equations\n    groups_in_equations = np.unique(\n        [\n            group\n            for equation in equations\n            for group in re.findall(r\"[a-zA-Z]+\", equation)\n            if group in groups\n        ]\n    )\n\n    if len(groups_in_equations) == 0:\n        warnings.warn(\n            f\"None of the groups in {names[1]} are part of the input array {names[0]}.\",\n            UserWarning,\n        )\n        return None\n\n    # Check if all groups mentioned in the equations are part of the input groups\n    if len(groups_in_equations) < len(groups_in_equations) and raise_if_group_missing:\n        raise GroupNotFoundError(\n            f\"The following groups are mentioned in {names[1]} but are not part of the input array {names[0]}: {', '.join(set(groups_in_equations) - set(groups))}.\"\n        )\n\n    # Create left and right matrices\n    left = np.zeros((len(equations), n_assets))\n    right = np.zeros(len(equations))\n\n    # Loop over equations\n    for i, equation in enumerate(equations):\n\n        # Split equation into groups and coefficients\n        groups_and_coefficients = re"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Convert to numpy arrays\n    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n\n    # Check that the input arrays have the correct shape\n    if groups.ndim != 2:\n        raise ValueError(\n            f\"The parameter {names[0]} should be a 2D array of shape (n_groups, n_assets).\"\n        )\n    if equations.ndim != 1:\n        raise ValueError(\n            f\"The parameter {names[1]} should be a 1D array of shape (n_equations,).\"\n        )\n\n    # Check that the input arrays have the correct length\n    n_groups, n_assets = groups.shape\n    n_equations = equations.shape[0]\n    if n_equations > n_groups:\n        raise ValueError(\n            f\"The parameter {names[1]} should have length less than or equal to the number of groups.\"\n        )\n\n    # Check that the equations are valid\n    for equation in equations:\n        try:\n            re.sub(\" +\", \" \", equation)\n        except TypeError:\n            raise EquationToMatrixError(\n                f\"The parameter {names[1]} contains an invalid equation: {equation}.\"\n            )\n\n    # Find the groups in the equations\n    groups_in_equations = set(\n        [\n            re.sub(\" +\", \" \", group)\n            for equation in equations\n            for group in re.split(\"[<>=]\", equation)\n        ]\n    )\n\n    # Check that the groups in the equations are part of the groups array\n    if not set(groups_in_equations).issubset(set(groups)):\n        if raise_if_group_missing:\n            raise GroupNotFoundError(\n                f\"The parameter {names[1]} contains a group that is not part of the parameter {names[0]}.\"\n            )\n        else:\n            warnings.warn(\n                f\"The parameter {names[1]} contains a group that is not part of the parameter {names[0]}.\"\n            )\n\n    # Convert the equations to matrices\n    if sum_"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check inputs\n    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n    if groups.ndim != 2:\n        raise ValueError(f\"{names[0]} must be a 2D array\")\n    if equations.ndim != 1:\n        raise ValueError(f\"{names[1]} must be a 1D array\")\n\n    # Define the regex patterns to parse the equations\n    regex_patterns = {\n        \"groups\": r\"([a-zA-Z0-9_]+)\",\n        \"operators\": r\"([<>=]+)\",\n        \"numbers\": r\"([-+]?[0-9]*\\.?[0-9]+)\",\n        \"parenthesis\": r\"(\\(|\\))\",\n    }\n    regex_groups = {\n        \"groups\": r\"({})\".format(regex_patterns[\"groups\"]),\n        \"operators\": r\"({})\".format(regex_patterns[\"operators\"]),\n        \"numbers\": r\"({})\".format(regex_patterns[\"numbers\"]),\n        \"parenthesis\": r\"({})\".format(regex_patterns[\"parenthesis\"]),\n    }\n\n    # Parse the equations\n    left_matrix = []\n    right_matrix = []\n    for eq in equations:\n\n        # Parse the equation\n        eq = eq.replace(\" \", \"\")\n        groups_found = re.findall(regex_groups[\"groups\"], eq)\n        operators_found = re.findall(regex_groups[\"operators\"], eq)\n        numbers_found = re.findall(regex_groups[\"numbers\"], eq)\n        parenthesis_found = re.findall(regex_groups[\"parenthesis\"], eq)\n\n        # Check that the equation is valid\n        if len(groups_found) == 0:\n            raise EquationToMatrixError(\n                f\"No groups found in equation '{eq}'.\"\n            )\n        if len(operators_found) != 1:\n            raise EquationToMatrixError(\n                f\"Exactly one operator required in equation '{eq}'.\"\n            )\n        if"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check inputs\n    groups = np.array(groups)\n    equations = np.array(equations)\n    if groups.ndim != 2:\n        raise ValueError(f\"{names[0]} should be a 2D array\")\n    if equations.ndim != 1:\n        raise ValueError(f\"{names[1]} should be a 1D array\")\n    if len(groups) == 0:\n        raise ValueError(f\"{names[0]} should not be empty\")\n    if len(equations) == 0:\n        raise ValueError(f\"{names[1]} should not be empty\")\n\n    # Check if any group in equations is not part of the groups\n    groups_names = np.array([str(group) for group in groups])\n    groups_in_equations = np.array(\n        [\n            re.findall(r\"\\b\" + group + r\"\\b\", equation)\n            for equation in equations\n            for group in groups_names\n        ]\n    )\n    if len(groups_in_equations) == 0:\n        warnings.warn(\n            f\"No group is part of the {names[1]}. Returning None.\",\n            UserWarning,\n        )\n        return None\n\n    # Parse equations\n    groups_in_equations = np.array(\n        [\n            re.findall(r\"\\b\" + group + r\"\\b\", equation)\n            for equation in equations\n            for group in groups_names\n        ]\n    )\n    groups_in_equations = groups_in_equations[groups_in_equations != []]\n    groups_in_equations = groups_in_equations.reshape(len(equations), -1)\n    groups_in_equations = np.unique(groups_in_equations, axis=1)\n    groups_in_equations = np.array(\n        [\n            [groups_names == group for group in equation]\n            for equation in groups_in_equations\n        ]\n    )\n\n    # Check if any group in equations is not part of the groups\n    groups_in"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check input arguments\n    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n\n    if groups.ndim != 2:\n        raise ValueError(f\"{names[0]} must be a 2D array.\")\n    if equations.ndim != 1:\n        raise ValueError(f\"{names[1]} must be a 1D array.\")\n\n    # Check that all equations are valid\n    for eq in equations:\n        if not re.match(r\"^([\\w\\d\\s\\+\\-\\*\\/]*)=([\\w\\d\\s\\+\\-\\*\\/]*)$\", eq):\n            raise ValueError(\n                f\"Equation {eq} is not valid. It should be of the form 'a + b = c + d'.\"\n            )\n\n    # Check that all groups are valid\n    for group in groups:\n        if group.ndim != 1:\n            raise ValueError(\n                f\"Each group should be a 1D array. The group {group} is not valid.\"\n            )\n\n    # Find all groups mentioned in the equations\n    groups_mentioned = set()\n    for eq in equations:\n        groups_mentioned.update(re.findall(r\"\\w+\", eq))\n\n    # Find the intersection between the groups mentioned in the equations and the input groups\n    groups_intersection = groups_mentioned.intersection(\n        set(np.array(groups).flatten())\n    )\n\n    # If none of the groups in the equations are part of the input groups, return None\n    if len(groups_intersection) == 0:\n        warnings.warn(\n            \"None of the groups mentioned in the equations are part of the input groups. Returning None.\"\n        )\n        return None\n\n    # Create the left matrix\n    groups_intersection = list(groups_intersection)\n    groups_intersection.sort()\n    left_matrix = np.zeros((len(equations), len(groups)))\n    for i, eq in enumerate(equations):\n        for j, group in enumerate(groups):\n            if group.name in"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check input arguments\n    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n    assert groups.ndim == 2, f\"The parameter {names[0]} must be a 2D array.\"\n    assert equations.ndim == 1, f\"The parameter {names[1]} must be a 1D array.\"\n\n    # Check that all groups are included in the equations\n    groups_names = np.unique(groups)\n    equations_groups = np.unique(\n        np.hstack([re.findall(\"[A-Za-z]+\", eq) for eq in equations])\n    )\n    missing_groups = np.setdiff1d(equations_groups, groups_names)\n    if len(missing_groups) > 0:\n        msg = f\"The following groups were not found in the {names[0]} parameter: {', '.join(missing_groups)}\"\n        if raise_if_group_missing:\n            raise GroupNotFoundError(msg)\n        else:\n            warnings.warn(msg)\n\n    # Convert equations to matrix\n    n_groups, n_assets = groups.shape\n    n_equations = len(equations)\n    left_matrix = np.zeros((n_equations, n_assets))\n    right_matrix = np.zeros(n_equations)\n    for i, eq in enumerate(equations):\n        # Split equation into left and right parts\n        parts = re.split(\"(<=|>=|==|<|>)\", eq)\n        left = parts[0].strip()\n        right = parts[1].strip()\n        # Parse left part\n        if left == \"\":\n            left_matrix[i, :] = 1\n        else:\n            coefs = np.array(re.split(\"[+-]\", left))\n            signs = np.array(re.findall(\"[+-]\", left))\n            signs = np.array([\"+\" if s == \"\" else s for s in signs])\n            groups = np.array([g.strip() for g in coefs])\n            coefs = np"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check inputs\n    if len(groups.shape) != 2:\n        raise ValueError(f\"{names[0]} must be 2D array\")\n    if len(equations) == 0:\n        raise ValueError(f\"{names[1]} must not be empty\")\n    if not isinstance(equations[0], str):\n        raise ValueError(f\"{names[1]} must be an array of strings\")\n    if not isinstance(raise_if_group_missing, bool):\n        raise ValueError(\"raise_if_group_missing must be bool\")\n    if not isinstance(sum_to_one, bool):\n        raise ValueError(\"sum_to_one must be bool\")\n\n    # Parse equations\n    equations = [re.split(\"<=|=|>|<\", eq) for eq in equations]\n    equations = [[s.strip() for s in eq] for eq in equations]\n    equations = [[s for s in eq if s] for eq in equations]\n\n    # Check that all equations are valid\n    for eq in equations:\n        if len(eq) != 2:\n            raise ValueError(\n                f\"Equation '{eq}' must contain exactly one '<=', '=', '>', or '<' operator\"\n            )\n        if len(eq[0].split(\" \")) != len(eq[1].split(\" \")):\n            raise ValueError(f\"Equation '{eq}' must have same number of groups in both sides\")\n\n    # Find groups\n    groups = [set(g.split(\" \")) for g in groups]\n    groups = [g for g in groups if g]\n    groups = {g: i for i, g in enumerate(groups)}\n    groups = {k: v for k, v in groups.items() if v < groups[k]}\n    groups = list(groups.keys())\n\n    # Check that all groups are valid\n    for eq in equations:\n        for group in eq[0].split(\" \"):\n            if group not in groups:\n                if raise_if_group_missing:\n                    raise GroupNotFoundError(f\"Group '{group}' not found in {"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    # Define the new Instances class\n    cls_name = \"Instances\"\n    cls_members = {}\n    cls_members.update({\"__annotations__\": {}})\n    cls_members.update({\"__annotations__\": {}})\n    cls_members.update({\"__annotations__\": {}})\n    cls_members.update({\"__annotations__\": {}})\n    cls_members.update({\"__annotations__\": {}})\n    cls_members.update({\"__annotations__\": {}})\n    cls_members.update({\"__annotations__\": {}})\n    cls_members.update({\"__annotations__\": {}})\n    cls_members.update({\"__annotations__\": {}})\n    cls_members.update({\"__annotations__\": {}})\n    cls_members.update({\"__annotations__\": {}})\n    cls_members.update({\"__annotations__\": {}})\n    cls_members.update({\"__annotations__\": {}})\n    cls_members.update({\"__annotations__\": {}})\n    cls_members.update({\"__annotations__\": {}})\n    cls_members.update({\"__annotations__\": {}})\n    cls_members.update({\"__annotations__\": {}})\n    cls_members.update({\"__annotations__\": {}})\n    cls_members.update({\"__annotations__\": {}})\n    cls_members.update({\"__annotations__\": {}})\n    cls_members.update({\"__annotations__\": {}})\n    cls_members.update({\"__annotations__\": {}})\n    cls_members.update({\"__annotations__\": {}})\n    cls_members.update({\"__annotations__\": {}})\n    cls_members.update({\"__annotations__\": {}})\n    cls_members.update({\"__annotations__\": {}})\n    cls_members.update({\"__annotations__\": {}})\n    cls_members.update({\"__annot"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n\n    # Define new Instances class\n    cls_name = \"Instances_patched_%d\" % _counter\n    cls_code_str = f\"\"\""}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n\n    def get_new_instances_class(fields):\n        # Create new scriptable Instances class\n        cls_name = \"Instances_patched_%d\" % _counter\n        cls_code_str = \"class %s(torch.nn.Module):\\n\" % cls_name\n        for name, val in fields.items():\n            cls_code_str += \"    _%s: %s\\n\" % (name, val)\n\n        cls_code_str += \"    def __init__(self, image_size: Tuple[int, int]):\\n\"\n        cls_code_str += \"        super().__init__()\\n\"\n        cls_code_str += \"        self.image_size = image_size\\n\"\n        for name, val in fields.items():\n            cls_code_str += \"        self._%s = torch.jit.annotate(Optional[%s], None)\\n\" % (name, val)\n\n        cls_code_str += \"    def __getattribute__(self, name):\\n\"\n        cls_code_str += \"        if name.startswith('_'):\\n\"\n        cls_code_str += \"            return torch.jit._unwrap_optional(super().__getattribute__(name))\\n\"\n        cls_code_str += \"        else:\\n\"\n        cls_code_str += \"            return super().__getattribute__(name)\\n\"\n\n        cls_code_str += \"    def __repr__(self):\\n\"\n        cls_code_str += \"        s = self.__class__.__name__ + '('\\n\"\n        cls_code_str += \"            image_size=%s\\\\n\" % repr(tuple(self.image_size))\n        cls_code_str += \"        )\\n\"\n        cls_code_str += \"        for k, v in self.__dict__.items():\\n\"\n        cls_code_str += \"            if not k.starts"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    # Define the new class\n    class NewInstances(Instances):\n        def __init__(self, image_size: Tuple[int, int]):\n            self._image_size = image_size\n            self._fields = {}\n            for k, v in fields:\n                self._fields[k] = v\n\n        def __getattr__(self, name: str):\n            if name in self._fields:\n                return self._fields[name]\n            raise AttributeError(f\"Cannot find field '{name}' in the given Instances!\")\n\n        def __repr__(self):\n            s = self.__class__.__name__ + \"(\"\n            s += \"num_instances={}, \".format(len(self))\n            s += \"image_height={}, \".format(self._image_size[0])\n            s += \"image_width={}, \".format(self._image_size[1])\n            s += \"fields=[{}])\".format(\", \".join((f\"{k}: {v}\" for k, v in self._fields.items())))\n            return s\n\n        def remove(self, field: str):\n            del self._fields[field]\n\n        def get_fields(self) -> Dict[str, Any]:\n            return self._fields\n\n        @torch.jit.export\n        def has(self, name: str) -> bool:\n            return name in self._fields\n\n        @torch.jit.export\n        def get(self, name: str) -> Any:\n            if name in self._fields:\n                return self._fields[name]\n            raise AttributeError(f\"Cannot find field '{name}' in the given Instances!\")\n\n        @torch.jit.export\n        def get_fields(self) -> Dict[str, Any]:\n            return self._fields\n\n        @torch.jit.export\n        def to(self, *args, **kwargs):\n            ret = Instances(self._image_size)\n            for k, v in self._fields.items():\n                if hasattr(v, \"to\"):\n                    v = v.to(*args,"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    # Generate the new Instances class\n    cls_name = \"Instances\"\n    cls_code = f\"\"\""}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n\n    # Define the new Instances class\n    cls_name = \"Instances_scripted_\" + str(_counter)\n    cls_def = f\"\"\""}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n\n    # Create a new Instances class with the given fields\n    cls_name = f\"Instances_patched_{_counter}\"\n    _counter += 1\n    newInstances = type(cls_name, (Instances,), {})\n    for i, name in enumerate(fields):\n        setattr(newInstances, name, Instances.Field(i))\n\n    # Write the new class to a temporary file\n    with tempfile.TemporaryDirectory() as tmpdir:\n        with open(os.path.join(tmpdir, \"new_instances.py\"), \"w\") as f:\n            f.write(f\"class {cls_name}(Instances):\\n\")\n            f.write(f\"    def __init__(self, image_size: Tuple[int, int]):\\n\")\n            f.write(f\"        super().__init__(image_size)\\n\")\n            for name in fields:\n                f.write(f\"        self._{name} = []\\n\")\n\n        # Import the new class\n        sys.path.insert(0, tmpdir)\n        new_instances_module = _import_file(\"new_instances\", os.path.join(tmpdir, \"new_instances.py\"))\n        newInstances = getattr(new_instances_module, cls_name)\n        sys.path.pop(0)\n\n    # Add the from_instances method to the new class\n    _add_instances_conversion_methods(newInstances)\n\n    # Set up the environment so that torchscript can recognize the new class\n    with ExitStack() as stack:\n        # Patch the Instances class to be the new class\n        stack.enter_context(mock.patch(\"detectron2.structures.Instances\", newInstances))\n        # Patch the _C.Instances class to be the new class\n        new_instances_c_cls = type(cls_name + \"_c\", (object,), {})\n        stack.enter_context(mock.patch(\"detectron2.structures._C.Instances\","}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    # Create new scriptable Instances class\n    newInstances = create_scriptable_instances_class(fields)\n\n    # Add from_instances methods to the scriptable Instances class\n    _add_instances_conversion_methods(newInstances)\n\n    # Create new module for the new scriptable Instances class\n    cls_name = newInstances.__name__\n    new_module = create_module_for_class(cls_name, newInstances)\n\n    # Write the new module to a temporary file\n    with tempfile.TemporaryDirectory() as tmpdirname:\n        new_module_path = os.path.join(tmpdirname, f\"instances_scriptable_{_counter}.py\")\n        with open(new_module_path, \"w\") as f:\n            f.write(new_module)\n\n        # Import the new module\n        new_module_import_path = new_module_path.replace(os.sep, \".\")\n        new_module_import_path = new_module_import_path[:-3]\n        new_module = _import_file(new_module_import_path)\n\n        # Set the Instances class to the new class\n        setattr(detectron2, cls_name, getattr(new_module, cls_name))\n\n        # Set the Instances class to the new class\n        setattr(Instances, \"_fields\", fields)\n\n        # Set the Instances class to the new class\n        setattr(Instances, \"__name__\", cls_name)\n\n        # Set the Instances class to the new class\n        setattr(Instances, \"__module__\", new_module_import_path)\n\n        # Set the Instances class to the new class\n        setattr(Instances, \"__qualname__\", cls_name)\n\n        # Yield the new class\n        yield newInstances\n\n    # Cleanup\n    _clear_jit_cache()\n    delattr(detectron2, cls_name)\n    delattr(Instances, \"_fields\")\n    delattr(Instances, \"__"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n\n    def get_new_name():\n        global _counter\n        _counter += 1\n        return \"Instances_scriptable\" + str(_counter)\n\n    def get_new_module_name():\n        return \"instances_scriptable\" + str(_counter)\n\n    def get_scriptable_instances_class(name, fields):\n        # Define class\n        class NewInstances(Instances):\n            def __init__(self, image_size: Tuple[int, int]):\n                super().__init__(image_size)\n                for name, val in fields.items():\n                    assert hasattr(self, f\"_{name}\"), f\"No attribute named {name} in {name}\"\n                    setattr(self, name, val)\n\n        # Set class attributes\n        for name, val in fields.items():\n            assert hasattr(NewInstances, f\"_{name}\"), f\"No attribute named {name} in {name}\"\n            setattr(NewInstances, name, val)\n\n        return NewInstances\n\n    # Get new class name\n    new_name = get_new_name()\n\n    # Get new module name\n    new_module_name = get_new_module_name()\n\n    # Get scriptable instances class\n    new_instances_class = get_scriptable_instances_class(new_name, fields)\n\n    # Write class to temporary file\n    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\") as f:\n        f.write(f\"import torch\\n\")\n        f.write(f\"from typing import List, Tuple, Dict\\n\")\n        f.write(f\"from detectron2.structures import Instances\\n\")\n        f.write(f\"class {new_name}(Instances):\\n\")\n        for name, val in fields.items():\n            f.write(f\"    _{name}: {val}\\n\")\n            f.write(f\"    @property\\n\")\n            f.write(f\"    def {name}(self):\\n\")\n            f."}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n\n    # create new Instances class\n    cls_name = \"Instances\"\n    cls_members = {}\n    for i, field in enumerate(fields):\n        field_name, field_type = field\n        cls_members[field_name] = field_type\n\n    newInstances = type(cls_name, (object,), cls_members)\n    _add_instances_conversion_methods(newInstances)\n\n    # create new module for the new class\n    cls_mod = _import_file(\n        f\"instances_module_{_counter}\",\n        \"\"\""}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    oldInstances = Instances\n    newInstances = _generate_new_instances_class(fields)\n    _add_instances_conversion_methods(newInstances)\n    # generate new Instances class\n\n    # write to temp file\n    s = f\"\"\""}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n\n    # Define the new Instances class\n    cls_name = \"Instances\" + str(_counter)\n    cls_name_script = cls_name + \"_script\"\n    cls_name_script_module = cls_name_script + \".py\"\n    cls_name_script_module_path = os.path.join(tempfile.gettempdir(), cls_name_script_module)\n    cls_name_script_module_import_path = \".\".join(\n        [tempfile.gettempdir().replace(os.sep, \".\"), cls_name_script_module.replace(\".py\", \"\")])\n\n    cls_def = \"class {}(Instances):\\n\".format(cls_name)\n    cls_def += \"    def __init__(self, image_size: Tuple[int, int]):\\n\"\n    cls_def += \"        super().__init__(image_size)\\n\"\n    for name, type in fields.items():\n        cls_def += \"        self.{} = {}\\n\".format(name, type)\n\n    # Write the new class to a file\n    with open(cls_name_script_module_path, \"w\") as f:\n        f.write(cls_def)\n\n    # Import the new class\n    newInstances = _import_file(cls_name_script_module_import_path)[cls_name]\n\n    # Add from_instances method to the scripted Instances class\n    _add_instances_conversion_methods(newInstances)\n\n    # Add the new class to the environment\n    torch.jit.script(newInstances)\n\n    # Yield the new class\n    with ExitStack() as stack:\n        stack.enter_context(mock.patch(\"detectron2.structures.instances.Instances\", newInstances))\n        stack.enter_context(mock.patch(\"detectron2.structures.boxes.Boxes\", Boxes))\n        stack.enter_context(mock.patch(\"detectron2.structures."}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n\n    # Generate new scriptable Instances class\n    cls_name = \"Instances_patched_%d\" % _counter\n    cls_code_lines = [\"class %s(object):\" % cls_name]\n    for name, type_ in fields:\n        cls_code_lines.append(\"  %s: %s\" % (name, type_))\n\n    # Write class to temporary file\n    temp_dir = tempfile.mkdtemp()\n    cls_code = \"\\n\".join(cls_code_lines)\n    filename = os.path.join(temp_dir, \"instances_%d.py\" % _counter)\n    with open(filename, \"w\") as fid:\n        fid.write(cls_code)\n\n    # Import new module with generated class\n    sys.path.insert(0, temp_dir)\n    new_module = _import_file(filename)\n    sys.path.pop(0)\n\n    # Extract new class from module\n    newInstances = getattr(new_module, cls_name)\n\n    # Add from_instances method to new class\n    _add_instances_conversion_methods(newInstances)\n\n    # Set up environment to support torchscript\n    newInstances.__torch_script_class__ = True\n    newInstances.__jit_unused_properties__ = [\"pred_boxes\", \"pred_classes\", \"pred_scores\"]\n    torch.jit._recursive.concrete_type_store.register_deferred_type(\n        cls_name, torch.jit.script(newInstances)\n    )\n\n    # Replace original Instances with new class\n    with ExitStack() as context_stack:\n        context_stack.enter_context(mock.patch(\"detectron2.structures.Instances\", newInstances))\n        context_stack.enter_context(\n            mock.patch(\"detectron2.structures.instances\", newInstances)\n        )\n        yield newInstances\n\n    # C"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n\n    # Create new Instances class\n    cls_name = f\"Instances_patched_{_counter}\"\n    cls_def = f\"\"\""}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    old_instances = Instances\n    old_instances_name = old_instances.__name__\n    new_instances_name = f\"Instances_scriptable_{_counter}\"\n    _counter += 1\n\n    # create a new Instances class that inherits from the original Instances class\n    new_instances = type(new_instances_name, (old_instances,), {})\n    # add necessary fields to the new class\n    for name, type in fields:\n        setattr(new_instances, name, torch.jit.annotate(type, torch.nn.Parameter(torch.Tensor())))\n\n    # add conversion methods\n    _add_instances_conversion_methods(new_instances)\n\n    # write the new class to a temporary file\n    temp_dir = tempfile.mkdtemp()\n    filename = os.path.join(temp_dir, new_instances_name + \".py\")\n    with open(filename, \"w\") as f:\n        f.write(new_instances.__repr__())\n        f.write(\"\\n\")\n\n    # import the new class\n    new_instances = _import_file(filename)[new_instances_name]\n\n    # patch the environment\n    with ExitStack() as stack:\n        # patch Instances to be the new class\n        stack.enter_context(mock.patch(\"detectron2.structures.Instances\", new_instances))\n        # patch Instances.__name__ to be the original name\n        stack.enter_context(mock.patch(\"detectron2.structures.Instances.__name__\", old_instances_name))\n        # patch Instances.__qualname__ to be the original name\n        stack.enter_context(mock.patch(\"detectron2.structures.Instances.__qualname__\", old_instances_name))\n        # patch Instances.__module__ to be the original module\n        stack.enter_context(mock.patch(\"detectron2.structures.Instances.__module__\", old_instances.__module__))\n        yield new_"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    # Define the new Instances class\n    cls_name = \"Instances\"\n    cls_fields = []\n    cls_fields.extend(fields)\n    cls_fields.append((\"_image_size\", torch.Size))\n    cls_fields.append((\"_extra_fields\", dict))\n    cls_str = f\"\"\""}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n\n    # Define the new class\n    class InstancesScriptable(nn.Module):\n        def __init__(self, image_size: tuple):\n            super().__init__()\n            self.image_size = image_size\n            for name, value in fields.items():\n                self.register_buffer(name, value)\n\n        def __len__(self):\n            return len(self._fields)\n\n        def __getattr__(self, name):\n            if name in self._fields:\n                ret = getattr(self, name)\n                if ret.shape[0] == 0:\n                    return ret\n                return ret.to(self.device)\n            raise AttributeError(f\"Cannot find field '{name}' in the given Instances!\")\n\n        def __getitem__(self, item):\n            if isinstance(item, str):\n                # get attribute\n                return getattr(self, item)\n            elif isinstance(item, int):\n                # create new Instances with only one instance\n                return InstancesScriptable(self.image_size, **{k: v[[item]] for k, v in self._fields.items()})\n            else:\n                # create new Instances with selected instances\n                return InstancesScriptable(self.image_size, **{k: v[item] for k, v in self._fields.items()})\n\n        def __setattr__(self, name, value):\n            if name in self._fields:\n                self._fields[name] = value\n            else:\n                super().__setattr__(name, value)\n\n        def __setstate__(self, state):\n            super().__setstate__(state)\n            if \"_fields\" not in self.__dict__:\n                self._fields = {}\n                for name, value in fields.items():\n                    self.register_buffer(name, value)\n\n        def __getstate__(self):\n            state = super().__getstate__()\n            state[\"_fields\"] = self._fields\n            return state\n\n    # Generate new class module\n    cls_name = \"InstancesScriptable\"\n    cls_"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    # Define new Instances class\n    cls_name = \"Instances\"\n    cls_code_str = f\"\"\""}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n    if _counter > 1:\n        raise RuntimeError(\"Cannot recursively call patch_instances\")\n\n    # Define a new Instances class with the given fields.\n    cls_name = \"Instances_patched\" + str(_counter)\n    cls_def = f\"\"\""}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n\n    # Create a new Instances class with the given fields\n    newInstances = create_scriptable_instances_class(fields)\n\n    # Add the from_instances method to the new class\n    _add_instances_conversion_methods(newInstances)\n\n    # Create a new module for the new class\n    new_module = create_instances_module(newInstances)\n\n    # Write the module to a temporary file\n    with tempfile.TemporaryDirectory() as tmpdir:\n        module_path = os.path.join(tmpdir, f\"instances_{_counter}.py\")\n        _counter += 1\n        with open(module_path, \"w\") as f:\n            f.write(new_module)\n\n        # Import the module\n        new_module = _import_file(module_path)\n\n        # Add the module to the global namespace\n        setattr(sys.modules[__name__], newInstances.__name__, new_module.__getattribute__(newInstances.__name__))\n\n        # Return the new class\n        yield newInstances\n\n    # Remove the module from the global namespace\n    delattr(sys.modules[__name__], newInstances.__name__)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n\n        # work around this bug: https://github.com/python-pillow/Pillow/issues/3973\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n\n        # work around this bug: https://github.com/python-pillow/Pillow/issues/3973\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n\n        # work around this bug: https://github.com/python-pillow/Pillow/issues/3973\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n\n        # work around this bug: https://github.com/python-pillow/Pillow/issues/3973\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n\n        # work around this bug: https://github.com/python-pillow/Pillow/issues/3973\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n\n        # work around this bug: https://github.com/python-pillow/Pillow/issues/3973\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        # work around this bug: https://github.com/python-pillow/Pillow/issues/3973\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n\n        # work around this bug: https://github.com/python-pillow/Pillow/issues/3973\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n\n        # work around this bug: https://github.com/python-pillow/Pillow/issues/3973\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        # work around this bug: https://github.com/python-pillow/Pillow/issues/3973\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        # work around this bug: https://github.com/python-pillow/Pillow/issues/3973\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        # work around this bug: https://github.com/python-pillow/Pillow/issues/3973\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        # work around this bug: https://github.com/python-pillow/Pillow/issues/3973\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n\n        # work around this bug: https://github.com/python-pillow/Pillow/issues/3973\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n\n        # work around this bug: https://github.com/python-pillow/Pillow/issues/3973\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        if format == \"YUV-BT.601\":\n            image = image.convert(\"RGB\")\n            image = np.asarray(image).astype(np.float32) / 255.0\n            image = np.dot(image, np.array(_M_RGB2YUV).T)\n        else:\n            image = _apply_exif_orientation(image)\n            return convert_PIL_to_numpy(image, format)\n\n    return image\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if isinstance(transforms, (tuple, list)):\n        transforms = T.TransformList(transforms)\n    # bbox is 1d (per-instance bounding box)\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # clip transformed boxes to image size\n    bbox = transforms.apply_box(np.array([bbox]))[0].clip(min=0)\n    annotation[\"bbox\"] = np.minimum(bbox, list(image_size + image_size)[::-1])\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    if \"segmentation\" in annotation:\n        # each instance contains 1 or more polygons\n        segm = annotation[\"segmentation\"]\n        if isinstance(segm, list):\n            # polygons\n            polygons = [np.asarray(p).reshape(-1, 2) for p in segm]\n            annotation[\"segmentation\"] = [\n                p.reshape(-1) for p in transforms.apply_polygons(polygons)\n            ]\n        elif isinstance(segm, dict):\n            # RLE\n            mask = mask_util.decode(segm)\n            mask = transforms.apply_segmentation(mask)\n            assert tuple(mask.shape[:2]) == image_size\n            annotation[\"segmentation\"] = mask\n        else:\n            raise ValueError(\n                \"Cannot transform segmentation of type '{}'!\"\n                \"Supported types are: polygons as list[list[float] or ndarray],\"\n                \" COCO-style RLE as a dict.\".format(type(segm))\n            )\n\n    if \"keypoints\" in annotation:\n        keypoints = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if isinstance(transforms, (tuple, list)):\n        transforms = T.TransformList(transforms)\n    # bbox is 1d (per-instance bounding box)\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # clip transformed bbox to image size\n    bbox = transforms.apply_box(np.array([bbox]))[0].clip(min=0)\n    annotation[\"bbox\"] = np.minimum(bbox, list(image_size + image_size)[::-1])\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    if \"segmentation\" in annotation:\n        # each instance contains 1 or more polygons\n        segm = annotation[\"segmentation\"]\n        if isinstance(segm, list):\n            # polygons\n            polygons = [np.asarray(p).reshape(-1, 2) for p in segm]\n            annotation[\"segmentation\"] = [\n                p.reshape(-1) for p in transforms.apply_polygons(polygons)\n            ]\n        elif isinstance(segm, dict):\n            # RLE\n            mask = mask_util.decode(segm)\n            mask = transforms.apply_segmentation(mask)\n            assert tuple(mask.shape[:2]) == image_size\n            annotation[\"segmentation\"] = mask\n        else:\n            raise ValueError(\n                \"Cannot transform segmentation of type '{}'!\"\n                \"Supported types are: polygons as list[list[float] or ndarray],\"\n                \" COCO-style RLE as a dict.\".format(type(segm))\n            )\n\n    if \"keypoints\" in annotation:\n        keypoints = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if isinstance(transforms, (tuple, list)):\n        transforms = T.TransformList(transforms)\n    # bbox is 1d (per-instance bounding box)\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # clip transformed boxes to image size\n    bbox = transforms.apply_box(np.array([bbox]))[0].clip(min=0)\n    annotation[\"bbox\"] = np.minimum(bbox, list(image_size + image_size)[::-1])\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    if \"segmentation\" in annotation:\n        # each instance contains 1 or more polygons\n        segm = annotation[\"segmentation\"]\n        if isinstance(segm, list):\n            # polygons\n            polygons = [np.asarray(p).reshape(-1, 2) for p in segm]\n            annotation[\"segmentation\"] = [\n                p.reshape(-1) for p in transforms.apply_polygons(polygons)\n            ]\n        elif isinstance(segm, dict) and \"counts\" in segm and \"size\" in segm:\n            # RLE\n            mask = mask_util.decode(segm)\n            mask = transforms.apply_segmentation(mask)\n            assert tuple(mask.shape[:2]) == image_size\n            annotation[\"segmentation\"] = mask\n        else:\n            raise ValueError(\n                \"Cannot transform segmentation of type '{}'!\"\n                \"Supported types are: polygons as list[list[float] or ndarray],\"\n                \" COCO-style RLE as a dict.\".format(type(segm))\n            )\n\n    if \"keypoints\" in annotation:\n        keypoints = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if isinstance(transforms, (tuple, list)):\n        transforms = T.TransformList(transforms)\n    # bbox is 1d (per-instance bounding box)\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # clip transformed boxes to image size\n    bbox = transforms.apply_box(np.array([bbox]))[0].clip(min=0)\n    annotation[\"bbox\"] = np.minimum(bbox, list(image_size + image_size)[::-1])\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    if \"segmentation\" in annotation:\n        # each instance contains 1 or more polygons\n        segm = annotation[\"segmentation\"]\n        if isinstance(segm, list):\n            # polygons\n            polygons = [np.asarray(p).reshape(-1, 2) for p in segm]\n            annotation[\"segmentation\"] = [\n                p.reshape(-1) for p in transforms.apply_polygons(polygons)\n            ]\n        elif isinstance(segm, dict) and \"counts\" in segm and \"size\" in segm:\n            # RLE\n            mask = mask_util.decode(segm)\n            mask = transforms.apply_segmentation(mask)\n            assert tuple(mask.shape[:2]) == image_size\n            annotation[\"segmentation\"] = mask\n        else:\n            raise ValueError(\n                \"Cannot transform segmentation of type '{}'!\"\n                \"Supported types are: polygons as list[list[float] or ndarray],\"\n                \" COCO-style RLE as a dict.\".format(type(segm))\n            )\n\n    if \"keypoints\" in annotation:\n        keypoints = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if isinstance(transforms, (tuple, list)):\n        transforms = T.TransformList(transforms)\n    # bbox is 1d (per-instance bounding box)\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # clip transformed boxes to image size\n    bbox = transforms.apply_box(np.array([bbox]))[0].clip(min=0)\n    annotation[\"bbox\"] = np.minimum(bbox, list(image_size + image_size)[::-1])\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    if \"segmentation\" in annotation:\n        # each instance contains 1 or more polygons\n        segm = annotation[\"segmentation\"]\n        if isinstance(segm, list):\n            # polygons\n            polygons = [np.asarray(p).reshape(-1, 2) for p in segm]\n            annotation[\"segmentation\"] = [\n                p.reshape(-1) for p in transforms.apply_polygons(polygons)\n            ]\n        elif isinstance(segm, dict) and \"counts\" in segm and \"size\" in segm:\n            # RLE\n            mask = mask_util.decode(segm)\n            mask = transforms.apply_segmentation(mask)\n            assert tuple(mask.shape[:2]) == image_size\n            annotation[\"segmentation\"] = mask\n        else:\n            raise ValueError(\n                \"Cannot transform segmentation of type '{}'!\"\n                \"Supported types are: polygons as list[list[float] or ndarray],\"\n                \" COCO-style RLE as a dict.\".format(type(segm))\n            )\n\n    if \"keypoints\" in annotation:\n        keypoints = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if isinstance(transforms, (tuple, list)):\n        transforms = T.TransformList(transforms)\n    # bbox is 1d (per-instance bounding box)\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # clip transformed bbox to image size\n    bbox = transforms.apply_box(np.array([bbox]))[0].clip(min=0)\n    annotation[\"bbox\"] = np.minimum(bbox, list(image_size + image_size)[::-1])\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    if \"segmentation\" in annotation:\n        # each instance contains 1 or more polygons\n        segm = annotation[\"segmentation\"]\n        if isinstance(segm, list):\n            # polygons\n            polygons = [np.asarray(p).reshape(-1, 2) for p in segm]\n            annotation[\"segmentation\"] = [\n                p.reshape(-1) for p in transforms.apply_polygons(polygons)\n            ]\n        elif isinstance(segm, dict):\n            # RLE\n            mask = mask_util.decode(segm)\n            mask = transforms.apply_segmentation(mask)\n            assert tuple(mask.shape[:2]) == image_size\n            annotation[\"segmentation\"] = mask\n        else:\n            raise ValueError(\n                \"Cannot transform segmentation of type '{}'!\"\n                \"Supported types are: polygons as list[list[float] or ndarray],\"\n                \" COCO-style RLE as a dict.\".format(type(segm))\n            )\n\n    if \"keypoints\" in annotation:\n        keypoints = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if isinstance(transforms, (tuple, list)):\n        transforms = T.TransformList(transforms)\n    # bbox is 1d (per-instance bounding box)\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # clip transformed bbox to image size\n    bbox = transforms.apply_box(np.array([bbox]))[0].clip(min=0)\n    annotation[\"bbox\"] = np.minimum(bbox, list(image_size + image_size)[::-1])\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    if \"segmentation\" in annotation:\n        # each instance contains 1 or more polygons\n        segm = annotation[\"segmentation\"]\n        if isinstance(segm, list):\n            # polygons\n            polygons = [np.asarray(p).reshape(-1, 2) for p in segm]\n            annotation[\"segmentation\"] = [\n                p.reshape(-1) for p in transforms.apply_polygons(polygons)\n            ]\n        elif isinstance(segm, dict) and \"counts\" in segm and \"size\" in segm:\n            # RLE\n            mask = mask_util.decode(segm)\n            mask = transforms.apply_segmentation(mask)\n            assert tuple(mask.shape[:2]) == image_size\n            annotation[\"segmentation\"] = mask\n        else:\n            raise ValueError(\n                \"Cannot transform segmentation of type '{}'!\"\n                \"Supported types are: polygons as list[list[float] or ndarray],\"\n                \" COCO-style RLE as a dict.\".format(type(segm))\n            )\n\n    if \"keypoints\" in annotation:\n        keypoints = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if isinstance(transforms, (tuple, list)):\n        transforms = T.TransformList(transforms)\n    # bbox is 1d (per-instance bounding box)\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # clip transformed bbox to image size\n    bbox = transforms.apply_box(np.array([bbox]))[0].clip(min=0)\n    annotation[\"bbox\"] = np.minimum(bbox, list(image_size + image_size)[::-1])\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    if \"segmentation\" in annotation:\n        # each instance contains 1 or more polygons\n        segm = annotation[\"segmentation\"]\n        if isinstance(segm, list):\n            # polygons\n            polygons = [np.asarray(p).reshape(-1, 2) for p in segm]\n            annotation[\"segmentation\"] = [\n                p.reshape(-1) for p in transforms.apply_polygons(polygons)\n            ]\n        elif isinstance(segm, dict):\n            # RLE\n            mask = mask_util.decode(segm)\n            mask = transforms.apply_segmentation(mask)\n            assert tuple(mask.shape[:2]) == image_size\n            annotation[\"segmentation\"] = mask\n        else:\n            raise ValueError(\n                \"Cannot transform segmentation of type '{}'!\"\n                \"Supported types are: polygons as list[list[float] or ndarray],\"\n                \" COCO-style RLE as a dict.\".format(type(segm))\n            )\n\n    if \"keypoints\" in annotation:\n        keypoints = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if isinstance(transforms, (tuple, list)):\n        transforms = T.TransformList(transforms)\n    # bbox is 1d (per-instance bounding box)\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # clip transformed bbox to image size\n    bbox = transforms.apply_box(np.array([bbox]))[0].clip(min=0)\n    annotation[\"bbox\"] = np.minimum(bbox, list(image_size + image_size)[::-1])\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    if \"segmentation\" in annotation:\n        # each instance contains 1 or more polygons\n        segm = annotation[\"segmentation\"]\n        if isinstance(segm, list):\n            # polygons\n            polygons = [np.asarray(p).reshape(-1, 2) for p in segm]\n            annotation[\"segmentation\"] = [\n                p.reshape(-1) for p in transforms.apply_polygons(polygons)\n            ]\n        elif isinstance(segm, dict) and \"counts\" in segm and \"size\" in segm:\n            # RLE\n            mask = mask_util.decode(segm)\n            mask = transforms.apply_segmentation(mask)\n            assert tuple(mask.shape[:2]) == image_size\n            annotation[\"segmentation\"] = mask\n        else:\n            raise ValueError(\n                \"Cannot transform segmentation of type '{}'!\"\n                \"Supported types are: polygons as list[list[float] or ndarray],\"\n                \" COCO-style RLE as a dict.\".format(type(segm))\n            )\n\n    if \"keypoints\" in annotation:\n        keypoints = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if isinstance(transforms, (tuple, list)):\n        transforms = T.TransformList(transforms)\n    # bbox is 1d (per-instance bounding box)\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # clip transformed boxes to image size\n    bbox = transforms.apply_box(np.array([bbox]))[0].clip(min=0)\n    annotation[\"bbox\"] = np.minimum(bbox, list(image_size + image_size)[::-1])\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    if \"segmentation\" in annotation:\n        # each instance contains 1 or more polygons\n        segm = annotation[\"segmentation\"]\n        if isinstance(segm, list):\n            # polygons\n            polygons = [np.asarray(p).reshape(-1, 2) for p in segm]\n            annotation[\"segmentation\"] = [\n                p.reshape(-1) for p in transforms.apply_polygons(polygons)\n            ]\n        elif isinstance(segm, dict) and \"counts\" in segm and \"size\" in segm:\n            # RLE\n            mask = mask_util.decode(segm)\n            mask = transforms.apply_segmentation(mask)\n            assert tuple(mask.shape[:2]) == image_size\n            annotation[\"segmentation\"] = mask\n        else:\n            raise ValueError(\n                \"Cannot transform segmentation of type '{}'!\"\n                \"Supported types are: polygons as list[list[float] or ndarray],\"\n                \" COCO-style RLE as a dict.\".format(type(segm))\n            )\n\n    if \"keypoints\" in annotation:\n        keypoints = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if isinstance(transforms, (tuple, list)):\n        transforms = T.TransformList(transforms)\n    # bbox is 1d (per-instance bounding box)\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # clip transformed bbox to image size\n    bbox = transforms.apply_box(np.array([bbox]))[0].clip(min=0)\n    annotation[\"bbox\"] = np.minimum(bbox, list(image_size + image_size)[::-1])\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    if \"segmentation\" in annotation:\n        # each instance contains 1 or more polygons\n        segm = annotation[\"segmentation\"]\n        if isinstance(segm, list):\n            # polygons\n            polygons = [np.asarray(p).reshape(-1, 2) for p in segm]\n            annotation[\"segmentation\"] = [\n                p.reshape(-1) for p in transforms.apply_polygons(polygons)\n            ]\n        elif isinstance(segm, dict):\n            # RLE\n            mask = mask_util.decode(segm)\n            mask = transforms.apply_segmentation(mask)\n            assert tuple(mask.shape[:2]) == image_size\n            annotation[\"segmentation\"] = mask\n        else:\n            raise ValueError(\n                \"Cannot transform segmentation of type '{}'!\"\n                \"Supported types are: polygons as list[list[float] or ndarray],\"\n                \" COCO-style RLE as a dict.\".format(type(segm))\n            )\n\n    if \"keypoints\" in annotation:\n        keypoints = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if isinstance(transforms, (tuple, list)):\n        transforms = T.TransformList(transforms)\n    # bbox is 1d (per-instance bounding box)\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # clip transformed boxes to image size\n    bbox = transforms.apply_box(np.array([bbox]))[0].clip(min=0)\n    annotation[\"bbox\"] = np.minimum(bbox, list(image_size + image_size)[::-1])\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    if \"segmentation\" in annotation:\n        # each instance contains 1 or more polygons\n        segm = annotation[\"segmentation\"]\n        if isinstance(segm, list):\n            # polygons\n            polygons = [np.asarray(p).reshape(-1, 2) for p in segm]\n            annotation[\"segmentation\"] = [\n                p.reshape(-1) for p in transforms.apply_polygons(polygons)\n            ]\n        elif isinstance(segm, dict) and \"counts\" in segm and \"size\" in segm:\n            # RLE\n            mask = mask_util.decode(segm)\n            mask = transforms.apply_segmentation(mask)\n            assert tuple(mask.shape[:2]) == image_size\n            annotation[\"segmentation\"] = mask\n        else:\n            raise ValueError(\n                \"Cannot transform segmentation of type '{}'!\"\n                \"Supported types are: polygons as list[list[float] or ndarray],\"\n                \" COCO-style RLE as a dict.\".format(type(segm))\n            )\n\n    if \"keypoints\" in annotation:\n        keypoints = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if isinstance(transforms, (tuple, list)):\n        transforms = T.TransformList(transforms)\n    # bbox is 1d (per-instance bounding box)\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # clip transformed bbox to image size\n    bbox = transforms.apply_box(np.array([bbox]))[0].clip(min=0)\n    annotation[\"bbox\"] = np.minimum(bbox, list(image_size + image_size)[::-1])\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    if \"segmentation\" in annotation:\n        # each instance contains 1 or more polygons\n        segm = annotation[\"segmentation\"]\n        if isinstance(segm, list):\n            # polygons\n            polygons = [np.asarray(p).reshape(-1, 2) for p in segm]\n            annotation[\"segmentation\"] = [\n                p.reshape(-1) for p in transforms.apply_polygons(polygons)\n            ]\n        elif isinstance(segm, dict) and \"counts\" in segm and \"size\" in segm:\n            # RLE\n            mask = mask_util.decode(segm)\n            mask = transforms.apply_segmentation(mask)\n            assert tuple(mask.shape[:2]) == image_size\n            annotation[\"segmentation\"] = mask\n        else:\n            raise ValueError(\n                \"Cannot transform segmentation of type '{}'!\"\n                \"Supported types are: polygons as list[list[float] or ndarray],\"\n                \" COCO-style RLE as a dict.\".format(type(segm))\n            )\n\n    if \"keypoints\" in annotation:\n        keypoints = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if \"bbox\" in annotation:\n        bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n        # Note that bbox is 1d (per-instance bounding box)\n        annotation[\"bbox\"] = transforms.apply_box([bbox])[0]\n        annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    if \"segmentation\" in annotation:\n        # each instance contains 1 or more polygons\n        segm = annotation[\"segmentation\"]\n        if isinstance(segm, list):\n            # polygons\n            polygons = [np.asarray(p).reshape(-1, 2) for p in segm]\n            annotation[\"segmentation\"] = [\n                p.reshape(-1) for p in transforms.apply_polygons(polygons)\n            ]\n        elif isinstance(segm, dict):\n            # RLE\n            mask = mask_util.decode(segm)\n            mask = transforms.apply_segmentation(mask)\n            assert tuple(mask.shape[:2]) == image_size\n            annotation[\"segmentation\"] = mask\n        else:\n            raise ValueError(\n                \"Cannot transform segmentation of type '{}'!\"\n                \"Supported types are: polygons as list[list[float] or ndarray],\"\n                \" COCO-style RLE as a dict.\".format(type(segm))\n            )\n\n    if \"keypoints\" in annotation:\n        keypoints = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if isinstance(transforms, (tuple, list)):\n        transforms = T.TransformList(transforms)\n    # bbox is 1d (per-instance bounding box)\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # clip transformed boxes to image size\n    bbox = transforms.apply_box(np.array([bbox]))[0].clip(min=0)\n    annotation[\"bbox\"] = np.minimum(bbox, list(image_size + image_size)[::-1])\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    if \"segmentation\" in annotation:\n        # each instance contains 1 or more polygons\n        segm = annotation[\"segmentation\"]\n        if isinstance(segm, list):\n            # polygons\n            polygons = [np.asarray(p).reshape(-1, 2) for p in segm]\n            annotation[\"segmentation\"] = [\n                p.reshape(-1) for p in transforms.apply_polygons(polygons)\n            ]\n        elif isinstance(segm, dict) and \"counts\" in segm and \"size\" in segm:\n            # RLE\n            mask = mask_util.decode(segm)\n            mask = transforms.apply_segmentation(mask)\n            assert tuple(mask.shape[:2]) == image_size\n            annotation[\"segmentation\"] = mask\n        else:\n            raise ValueError(\n                \"Cannot transform segmentation of type '{}'!\"\n                \"Supported types are: polygons as list[list[float] or ndarray], or RLE as a dict.\".format(\n                    type(segm)\n                )\n            )\n\n    if \"keypoints\" in annotation:\n        keypoints = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if \"bbox\" in annotation:\n        bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n        # Note that bbox is 1d (per-instance bounding box)\n        annotation[\"bbox\"] = transforms.apply_box([bbox])[0]\n        annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    if \"segmentation\" in annotation:\n        # each instance contains 1 or more polygons\n        segm = annotation[\"segmentation\"]\n        if isinstance(segm, list):\n            # polygons\n            polygons = [np.asarray(p).reshape(-1, 2) for p in segm]\n            annotation[\"segmentation\"] = [\n                p.reshape(-1) for p in transforms.apply_polygons(polygons)\n            ]\n        elif isinstance(segm, dict):\n            # RLE\n            mask = mask_util.decode(segm)\n            mask = transforms.apply_segmentation(mask)\n            assert tuple(mask.shape[:2]) == image_size\n            annotation[\"segmentation\"] = mask\n        else:\n            raise ValueError(\n                \"Cannot transform segmentation of type '{}'!\"\n                \"Supported types are: polygons as list[list[float] or ndarray],\"\n                \" COCO-style RLE as a dict.\".format(type(segm))\n            )\n\n    if \"keypoints\" in annotation:\n        keypoints = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints\n\n    if \"regression_targets\" in annotation:\n        regression_targets = transforms.apply_box(np.array(annotation[\"regression_targets\"]))\n        annotation[\"regression_targets\"] = regression_targets.tolist()\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if \"bbox\" in annotation:\n        bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n        # Note that bbox is 1d (per-instance bounding box)\n        annotation[\"bbox\"] = transforms.apply_box([bbox])[0]\n        annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    if \"segmentation\" in annotation:\n        # each instance contains 1 or more polygons\n        segm = annotation[\"segmentation\"]\n        if isinstance(segm, list):\n            # polygons\n            polygons = [np.asarray(p).reshape(-1, 2) for p in segm]\n            annotation[\"segmentation\"] = [\n                p.reshape(-1) for p in transforms.apply_polygons(polygons)\n            ]\n        elif isinstance(segm, dict) and \"counts\" in segm and \"size\" in segm:\n            # RLE\n            mask = mask_util.decode(segm)\n            mask = transforms.apply_segmentation(mask)\n            assert tuple(mask.shape[:2]) == image_size\n            annotation[\"segmentation\"] = mask\n        else:\n            raise ValueError(\n                \"Cannot transform segmentation of type '{}'!\"\n                \"Supported types are: polygons as list[list[float] or ndarray],\"\n                \" COCO-style RLE as a dict.\".format(type(segm))\n            )\n\n    if \"keypoints\" in annotation:\n        keypoints = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints\n\n    if \"bbox_normalize\" in annotation:\n        bbox_normalize = BoxMode.convert(\n            annotation[\"bbox_normalize\"], annotation[\"bbox_normalize_mode\"], BoxMode.XYXY_ABS\n        )\n        # Note that bbox is 1d ("}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Apply bounding box transformation.\n    if \"bbox\" in annotation:\n        bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n        annotation[\"bbox\"] = transforms.apply_box([bbox])[0]\n        annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Apply segmentation transformation.\n    if \"segmentation\" in annotation:\n        if isinstance(annotation[\"segmentation\"], list):\n            # polygons\n            # PyTorch Code\n            annotation[\"segmentation\"] = [\n                transforms.apply_polygons(\n                    [np.asarray(p).reshape(-1, 2) for p in annotation[\"segmentation\"]]\n                )\n            ]\n        elif isinstance(annotation[\"segmentation\"], dict):\n            # RLE\n            mask = mask_util.decode(annotation[\"segmentation\"])\n            mask = transforms.apply_segmentation(mask)\n            assert tuple(mask.shape[:2]) == image_size\n            annotation[\"segmentation\"] = mask\n\n    # Apply keypoint transformation.\n    if \"keypoints\" in annotation:\n        keypoints = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if \"bbox\" in annotation:\n        annotation[\"bbox\"] = transforms.apply_box(\n            [annotation[\"bbox\"]]\n        )[0]\n        annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    if \"bbox_normalize\" in annotation:\n        annotation[\"bbox_normalize\"] = transforms.apply_box(\n            [annotation[\"bbox_normalize\"]]\n        )[0]\n        annotation[\"bbox_normalize_mode\"] = BoxMode.XYXY_ABS\n\n    if \"bbox_denormalize\" in annotation:\n        annotation[\"bbox_denormalize\"] = transforms.apply_box(\n            [annotation[\"bbox_denormalize\"]]\n        )[0]\n        annotation[\"bbox_denormalize_mode\"] = BoxMode.XYXY_ABS\n\n    if \"bbox_mask_denormalize\" in annotation:\n        annotation[\"bbox_mask_denormalize\"] = transforms.apply_box(\n            [annotation[\"bbox_mask_denormalize\"]]\n        )[0]\n        annotation[\"bbox_mask_denormalize_mode\"] = BoxMode.XYXY_ABS\n\n    if \"bbox_denormalize_with_size\" in annotation:\n        annotation[\"bbox_denormalize_with_size\"] = transforms.apply_box(\n            [annotation[\"bbox_denormalize_with_size\"]]\n        )[0]\n        annotation[\"bbox_denormalize_with_size_mode\"] = BoxMode.XYXY_ABS\n\n    if \"bbox_mask_denormalize_with_size\" in annotation:\n        annotation[\"bbox_mask_denormalize_with_size\"] = transforms.apply_box(\n            [annotation[\"bbox_mask_denormalize_with_size\"]]\n        )[0]\n        annotation[\"bbox_mask_denormalize_with_size_mode\"] = BoxMode.XYXY_ABS\n\n    if \"bbox_denormalize_with_image_size\" in annotation:"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Apply bounding box transformation\n    bbox = BoxMode.convert(\n        annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # Note that bbox is 1d (per-instance bounding box)\n    annotation[\"bbox\"] = transforms.apply_box([bbox])[0]\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Apply segmentation transformation\n    if \"segmentation\" in annotation:\n        # NOTE: here we transform segms to binary masks (interp is nearest by default)\n        if isinstance(annotation[\"segmentation\"], list):\n            # polygons\n            masks = PolygonMasks(\n                [anno_to_rle(p) for p in annotation[\"segmentation\"]])\n        else:\n            # mask array\n            masks = PolygonMasks([annotation[\"segmentation\"]])\n        masks = transforms.apply_segmentation(masks)\n        annotation[\"segmentation\"] = masks_to_rle(masks.polygons)\n\n    # Apply keypoints transformation\n    if \"keypoints\" in annotation:\n        keypoints = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size,\n            keypoint_hflip_indices)\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        coords = np.asarray(coords, dtype=float)\n        return cv2.transform(coords[:, np.newaxis, :], self.rm_coords)[:, 0, :]\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        # Transform image center from source coordinates into output coordinates\n        # and then map the new origin to the center of the output image.\n        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        coords = np.asarray(coords, dtype=float)\n        coords[:, 0] -= self.center[0]\n        coords[:, 1] -= self.center[1]\n        coords = np.transpose(np.dot(self.rm_coords, np.transpose(coords)))\n        coords[:, 0] += self.center[0]\n        coords[:, 1] += self.center[1]\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        # return coords\n        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        coords = np.asarray(coords, dtype=float)\n        return cv2.transform(coords[:, np.newaxis, :], self.rm_coords)[:, 0, :]\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        # If the coordinates are empty or the rotation angle is a multiple of 360 degrees, the original coordinates are returned without modification.\n        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n\n        # Otherwise, the rotation matrix is applied to the coordinates.\n        coords = np.asarray(coords, dtype=float)\n        return coords @ self.rm_coords.T\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        # If the rotation angle is a multiple of 360 degrees or the input is empty, the original coordinates are returned without modification.\n        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n\n        # Transforms each coordinate in the input array according to a predefined rotation matrix.\n        coords = np.asarray(coords, dtype=float)\n        return coords @ self.rm_coords.T\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        # If the rotation angle is a multiple of 360 degrees or the input is empty, the original coordinates are returned without modification.\n        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        # Transforms each coordinate in the input array according to a predefined rotation matrix associated with the instance.\n        coords = np.asarray(coords, dtype=float)\n        return coords @ self.rm_coords.T\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        # If the rotation angle is a multiple of 360 degrees or the input is empty, the original coordinates are returned without modification.\n        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n\n        # Transform each coordinate in the input array according to a predefined rotation matrix.\n        coords = np.asarray(coords, dtype=float)\n        return np.einsum(\"...k,kl->...l\", coords - self.center[:, None], self.rm_coords) + self.center[:, None]\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        # If the rotation angle is a multiple of 360 degrees or the input is empty, the original coordinates are returned without modification.\n        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        # Transforms each coordinate in the input array according to a predefined rotation matrix associated with the instance.\n        coords = np.asarray(coords, dtype=float)\n        return np.einsum(\"...k,kl->...l\", coords - self.center[:, None], self.rm_coords) + self.center[:, None]\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        # return coords\n        # if len(coords) == 0 or self.angle % 360 == 0:\n        #     return coords\n        # assert coords.shape[1] == 2\n        # return np.matmul(coords, self.rm_coords) + self.offset\n        return cv2.transform(coords, self.rm_coords)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        # Transform image center from global coordinates into local coordinates\n        # (the rotation matrix is defined with respect to the center of the image)\n        center = np.array([self.w, self.h]) * 0.5\n        coords -= center\n        # Apply rotation matrix to the coordinates\n        coords = np.einsum(\"...ij,...j->...i\", self.rm_coords[:2, :2], coords)\n        # Translate the coordinates back to the global frame of reference\n        coords += center\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        # If the rotation angle is a multiple of 360 degrees or the input is empty, the original coordinates are returned without modification.\n        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        # Applies a rotation transformation to a set of coordinates.\n        # This function transforms each coordinate in the input array according to a predefined rotation matrix associated with the instance.\n        return np.matmul(coords, self.rm_coords)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        # If the angle is a multiple of 360 or the coordinates are empty, the original coordinates are returned.\n        if self.angle % 360 == 0 or len(coords) == 0:\n            return coords\n        # If the center is at the origin, the rotation is around the top left corner.\n        if np.array_equal(self.center, np.array([0, 0])):\n            coords[:, 0] = coords[:, 0] + self.w / 2\n            coords[:, 1] = coords[:, 1] + self.h / 2\n        # If the center is at the top left corner, the rotation is around the origin.\n        elif np.array_equal(self.center, np.array([0, self.h])):\n            coords[:, 1] = coords[:, 1] - self.h / 2\n        # If the center is at the top right corner, the rotation is around the origin.\n        elif np.array_equal(self.center, np.array([self.w, self.h])):\n            coords[:, 0] = coords[:, 0] - self.w / 2\n            coords[:, 1] = coords[:, 1] - self.h / 2\n        # If the center is at the bottom left corner, the rotation is around the origin.\n        elif np.array_equal(self.center, np.array([0, 0])):\n            coords[:, 0] = coords[:, 0] + self.w / 2\n            coords[:, 1] = coords[:, 1] + self.h / 2\n        # Otherwise, the rotation is around the center.\n        else:\n            coords[:, 0] = coords[:, 0] - self.center[0]\n            coords[:, 1] = coords[:, 1] - self.center[1]\n        # Apply the rotation matrix to the coordinates.\n        coords = np.matmul(coords, self.rm_coords)\n        # If the"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        coords = np.asarray(coords, dtype=float)\n        coords[:, 0] -= self.center[0]\n        coords[:, 1] -= self.center[1]\n        coords = np.transpose(np.dot(self.rm_coords[:, :2], np.transpose(coords)))\n        coords[:, 0] += self.center[0]\n        coords[:, 1] += self.center[1]\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        coords = np.asarray(coords, dtype=float)\n        coords[:, 0] -= self.center[0]\n        coords[:, 1] -= self.center[1]\n        coords = np.transpose(np.dot(self.rm_coords[:, :2], np.transpose(coords)))\n        coords[:, 0] += self.center[0]\n        coords[:, 1] += self.center[1]\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        # If the rotation angle is a multiple of 360 degrees or the input is empty, the original coordinates are returned without modification.\n        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n\n        # Applies a rotation transformation to a set of coordinates.\n        coords = np.asarray(coords, dtype=float)\n        return np.einsum(\"...k,kl->...l\", coords - self.center[:, None], self.rm_coords) + self.center[:, None]\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        # If the coordinates are empty or the angle is 360, no transformation is necessary.\n        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n\n        # Otherwise, apply the rotation.\n        coords = np.asarray(coords, dtype=float)\n        return coords @ self.rm_coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        # If the angle is a multiple of 360 degrees or the coordinates are empty, the original coordinates are returned without modification.\n        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        # The rotation matrix associated with the instance is applied to the input coordinates.\n        coords = np.asarray(coords, dtype=float).reshape((-1, 2))\n        return np.einsum(\"ij, kj->ki\", self.rm_coords, coords)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        # If the coordinates are empty or the angle is a multiple of 360 degrees, the original coordinates are returned.\n        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n\n        # The rotation matrix is applied to the input coordinates.\n        coords = np.matmul(coords, self.rm_coords)\n\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        # return coords\n        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        coords = np.asarray(coords, dtype=float)\n        coords[:, 0] -= self.center[0]\n        coords[:, 1] -= self.center[1]\n        coords = np.transpose(np.dot(self.rm_coords[:, :2], np.transpose(coords)))\n        coords[:, 0] += self.center[0]\n        coords[:, 1] += self.center[1]\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        # If the rotation angle is a multiple of 360 degrees, the original coordinates are returned without modification.\n        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n\n        # Otherwise, the input coordinates are transformed based on the instance's rotation matrix.\n        coords = np.asarray(coords, dtype=float)\n        return coords @ self.rm_coords\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    flops_model = FlopCountAnalysis(model, inputs)\n    return flops_model.by_operator()\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    flop_counter = FlopCountAnalysis(model, inputs)\n    flop_count = flop_counter.total()\n    return flop_count\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    flops = FlopCountAnalysis(model, inputs)\n    return flops.by_operator()\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # return flop_count(model, inputs)\n    return FlopCountAnalysis(model, inputs).by_operator()\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    model = FlopCountAnalysis(model, inputs)\n    return model.by_operator()\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    if not isinstance(inputs, list):\n        inputs = [inputs]\n    flops = FlopCountAnalysis(model, inputs).total()\n    flops_per_g = flops / 10**9\n    return flops_per_g\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    model = FlopCountAnalysis(model, inputs)\n    return model.by_operator()\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    model = FlopCountAnalysis(model, inputs)\n    giga_flops = defaultdict(float)\n    for op, flop in model.by_operator().items():\n        giga_flops[op] = flop / 1e9\n    return giga_flops\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # assert isinstance(model, nn.Module)\n    # assert isinstance(inputs, list)\n    # assert len(inputs) > 0\n\n    # if isinstance(model, torch.jit.ScriptModule):\n    #     model = torch.jit._recursive.wrap_cpp_module(model._c)\n\n    flops = FlopCountAnalysis(model, inputs).by_operator()\n    flops = {k: v / 1e9 for k, v in flops.items()}\n    return flops\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # assert isinstance(model, nn.Module)\n    # assert isinstance(inputs, list)\n    # assert len(inputs) > 0\n    # assert isinstance(inputs[0], dict)\n    # assert \"image\" in inputs[0]\n\n    # if isinstance(model, (nn.parallel.distributed.DistributedDataParallel, nn.DataParallel)):\n    #     model = model.module\n\n    # flop_counter = FlopCountAnalysis(model, inputs)\n    # return flop_counter.by_operator()\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # assert isinstance(model, nn.Module)\n    # assert isinstance(inputs, list)\n    # assert len(inputs) > 0\n\n    # if isinstance(model, (nn.parallel.distributed.DistributedDataParallel, nn.DataParallel)):\n    #     model = model.module\n\n    # flop_dict = FlopCountAnalysis(model, inputs).by_operator()\n    # flop_dict = {k.replace(\"_\", \".\"): v for k, v in flop_dict.items()}\n    # return flop_dict\n\n    # return FlopCountAnalysis(model, inputs).by_operator()\n    return FlopCountAnalysis(model, inputs).total()\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # assert isinstance(model, nn.Module)\n    # assert isinstance(inputs, list)\n\n    # if not isinstance(inputs, list):\n    #     inputs = [inputs]\n    # inputs = [x[\"image\"] for x in inputs]\n    # inputs = [x.to(torch.device(\"cuda\")) for x in inputs]\n\n    # flop_counter = FlopCountAnalysis(model, inputs)\n    # flop_count = flop_counter.total()\n    # flop_count /= 1e9\n    # return flop_count\n\n    return FlopCountAnalysis(model, inputs).total()\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # model = copy.deepcopy(model)\n    # model = model.eval()\n    # flops = FlopCountAnalysis(model, inputs)\n    # return flops.total()\n    model = copy.deepcopy(model)\n    model = model.eval()\n    flops = FlopCountAnalysis(model, inputs)\n    return flops.unsupported_ops_warnings()\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    #assert isinstance(model, nn.Module) and isinstance(inputs, list), \"'model' must be a nn.Module and 'inputs' must be a list.\"\n\n    #assert len(inputs) > 0, \"'inputs' must be non-empty.\"\n\n    #assert all(isinstance(x, dict) for x in inputs), \"'inputs' must be a list of dictionaries.\"\n\n    #assert all(isinstance(x[\"image\"], torch.Tensor) for x in inputs), \"'image' must be a torch.Tensor.\"\n\n    flops = FlopCountAnalysis(model, inputs).total()\n\n    return flops\n\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # TODO: this function is not tested.\n    flops = FlopCountAnalysis(model, inputs).unsupported_ops_warnings()\n    flops_dict = defaultdict(float)\n    for op, flop in flops.items():\n        if op in _IGNORED_OPS:\n            continue\n        flops_dict[op] = flop / 1e9\n    return flops_dict\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # TODO: Add support for multiple inputs\n    assert isinstance(inputs, list), \"Inputs must be a list of dictionaries!\"\n    assert len(inputs) > 0, \"Inputs are empty!\"\n\n    # Compute flops\n    flop_counter = FlopCountAnalysis(model, inputs).unsupported_ops_warnings()\n\n    # Compute flops for each layer\n    flops = defaultdict(float)\n    for layer in flop_counter.by_operator().keys():\n        if layer in _IGNORED_OPS:\n            continue\n        flops[layer] += flop_counter.by_operator()[layer]\n\n    return flops\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # Set the model to evaluation mode\n    model.eval()\n\n    # Setup the inputs to the model\n    inputs = [{\"image\": inputs[0][\"image\"]}]\n\n    # Run the model to estimate the flops\n    flops = FlopCountAnalysis(model, inputs)\n\n    # Get the Gflop counts for each individual operator\n    giga_flops = flops.by_operator()\n\n    # Remove the unwanted operators\n    giga_flops = {k: v for k, v in giga_flops.items() if k in FLOPS_MODE}\n\n    return giga_flops\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # This code is modified from https://github.com/facebookresearch/fvcore/blob/main/fvcore/nn/benchmark.py\n    # Copyright (c) Facebook, Inc. and its affiliates.\n    # This source code is licensed under the MIT license found in the LICENSE file in the root directory of this source tree.\n    #\n    # Copyright (c) Facebook, Inc. and its affiliates.\n    #\n    # Licensed under the Apache License, Version 2.0 (the \"License\");\n    # you may not use this file except in compliance with the License.\n    # You may obtain a copy of the License at\n    #\n    #     http://www.apache.org/licenses/LICENSE-2.0\n    #\n    # Unless required by applicable law or agreed to in writing, software\n    # distributed under the License is distributed on an \"AS IS\" BASIS,\n    # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    # See the License for the specific language governing permissions and\n    # limitations under the License.\n\n    assert isinstance(model, nn.Module)\n    assert isinstance(inputs, list)\n\n    # ignore some ops\n    supported_ops = {k: lambda *args, **kwargs: {} for k in _IGNORED_OPS}\n    supported_ops.update(flop_count)\n    flop_analysis = FlopCountAnalysis(model, inputs)\n    flop_analysis.unsupported_ops_warnings(supported_ops)\n    flop_analysis.uncalled_modules_warnings()\n    return flop_analysis.by_operator()\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # Calculate the flops for each operation in the model\n    flop_count_dict = FlopCountAnalysis(model, inputs).by_operator()\n\n    # Remove all the ignored operations\n    for op in _IGNORED_OPS:\n        if op in flop_count_dict:\n            del flop_count_dict[op]\n\n    # Sort the operations in the model based on their Gflops counts\n    sorted_flop_count_dict = sorted(flop_count_dict.items(), key=lambda item: -item[1])\n\n    # Compute the total flops\n    total_flops = sum(flop_count_dict.values())\n\n    # Return the total flops and the flops count dict\n    return total_flops, sorted_flop_count_dict\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # Create a flop_count_analysis object\n    flop_count_analysis = FlopCountAnalysis(model, inputs)\n\n    # Run the analysis\n    flop_count_analysis.unsupported_ops_warnings(True)\n    flop_count_analysis.ignore_ops(\n        {\n            \"aten::add\",\n            \"aten::add_\",\n            \"aten::argmax\",\n            \"aten::argsort\",\n            \"aten::batch_norm\",\n            \"aten::constant_pad_nd\",\n            \"aten::div\",\n            \"aten::div_\",\n            \"aten::exp\",\n            \"aten::log2\",\n            \"aten::max_pool2d\",\n            \"aten::meshgrid\",\n            \"aten::mul\",\n            \"aten::mul_\",\n            \"aten::neg\",\n            \"aten::nonzero_numpy\",\n            \"aten::reciprocal\",\n            \"aten::repeat_interleave\",\n            \"aten::rsub\",\n            \"aten::sigmoid\",\n            \"aten::sigmoid_\",\n            \"aten::softmax\",\n            \"aten::sort\",\n            \"aten::sqrt\",\n            \"aten::sub\",\n            \"torchvision::nms\",\n        }\n    )\n    flop_count_analysis.tracing_context()\n    flop_count_analysis.unsupported_ops_warnings(False)\n    flop_count_analysis.uncalled_modules_warnings(False)\n    flop_count_analysis.uncalled_functions_warnings(False)\n    flop_count_analysis.run()\n\n    # Print the results\n    results = flop_count_analysis.by_operator()\n    results = {k: v / 1e9 for k, v in results.items()}\n    print(\"Flop Count Analysis Results (Gflop):\")\n    for k, v in results.items():\n        print(k, v)\n\n    return results\n\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if img.shape[:2] == (0, 0) or abs(self.angle) % 360 == 0:\n            return img\n        if interp is None:\n            interp = self.interp\n        return cv2.warpAffine(img, self.rm_image, (int(self.bound_w), int(self.bound_h)), flags=interp)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        assert img.shape[:2] == (self.h, self.w)\n        interp = interp if interp is not None else self.interp\n        if img.dtype == np.uint8:\n            # PIL only supports uint8\n            if len(img.shape) > 2 and img.shape[2] == 1:\n                return F.rotate(\n                    Image.fromarray(img[:, :, 0], mode=\"L\"),\n                    self.angle,\n                    center=tuple(self.center),\n                    expand=self.expand,\n                    fillcolor=(255,),\n                )\n            else:\n                return F.rotate(\n                    Image.fromarray(img),\n                    self.angle,\n                    center=tuple(self.center),\n                    expand=self.expand,\n                    fillcolor=(255, 255, 255),\n                )\n        else:\n            return cv2.warpAffine(\n                img,\n                self.rm_image,\n                dsize=(self.bound_w, self.bound_h),\n                flags=interp,\n            )\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if img.shape[:2] == (0, 0) or abs(self.angle) % 360 == 0:\n            return img\n        if len(img.shape) == 2:\n            return cv2.warpAffine(img, self.rm_image, (int(self.bound_w), int(self.bound_h)), flags=self.interp)\n        else:\n            return cv2.warpAffine(img, self.rm_image, (int(self.bound_w), int(self.bound_h)), flags=self.interp,\n                                  borderMode=cv2.BORDER_CONSTANT, borderValue=0)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if img.shape[:2] == (0, 0) or abs(self.angle) % 360 == 0:\n            return img\n        if img.ndim == 3 and img.shape[2] > 4:\n            raise Exception(\n                \"Rotation not yet supported for images with more than 4 channels!\"\n            )\n        if interp is None:\n            interp = self.interp\n        return cv2.warpAffine(\n            img, self.rm_image, (int(self.bound_w), int(self.bound_h)), flags=interp\n        )\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if img.shape[:2] == (0, 0) or abs(self.angle) % 360 == 0:\n            return img\n        if img.ndim == 3 and img.shape[2] == 1:\n            return self.apply_image(img.squeeze(-1), interp).unsqueeze(-1)\n        if interp is None:\n            interp = self.interp\n        ret = cv2.warpAffine(img, self.rm_image, (int(self.bound_w), int(self.bound_h)), flags=interp)\n        return ret\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if img.shape[:2] == (0, 0) or abs(self.angle) % 360 == 0:\n            return img\n        if img.shape[:2] != (self.h, self.w):\n            # print(f\"Size mismatch {self.h}, {self.w} vs {img.shape[:2]}\")\n            # Resize the input image to match the size of the transformation matrix.\n            img = cv2.resize(img, dsize=(self.w, self.h))\n        interp = interp if interp is not None else self.interp\n        img = cv2.warpAffine(\n            img,\n            self.rm_image,\n            dsize=(int(self.bound_w), int(self.bound_h)),\n            flags=interp,\n        )\n        return img\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        # if the image is 1-dimensional, temporarily add a singleton dimension, so that opencv can handle it\n        if len(img.shape) == 2:\n            img = np.expand_dims(img, -1)\n        else:\n            img = img.copy()\n        interp = interp if interp is not None else self.interp\n        if img.shape[1] == 0 or np.all(self.rm_image == np.eye(3)):\n            return img\n        h, w = img.shape[:2]\n        warped_img = cv2.warpAffine(img, self.rm_image, (int(self.bound_w), int(self.bound_h)), flags=interp)\n        if len(img.shape) == 2:\n            return warped_img[:, :, 0]\n        else:\n            return warped_img\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        # if the given image is empty, return the original image unchanged\n        if img.size == 0 or img is None:\n            return img\n        # if the angle is multiples of 360 degrees, return the original image unchanged\n        if (self.angle % 360) == 0:\n            return img\n        # apply the rotation matrix to the image\n        if len(img.shape) == 2:\n            return cv2.warpAffine(img, self.rm_image, (int(self.bound_w), int(self.bound_h)), flags=self.interp)\n        else:\n            # warp each channel independently\n            ret = []\n            for i in range(img.shape[2]):\n                ret.append(cv2.warpAffine(img[:, :, i], self.rm_image, (int(self.bound_w), int(self.bound_h)), flags=self.interp))\n            return np.transpose(np.array(ret), (1, 2, 0))\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if img.shape[:2] == (self.h, self.w):\n            # The original image had the dimensions of the bounding box, so no cropping is necessary\n            return cv2.warpAffine(img, self.rm_image, (self.bound_w, self.bound_h), flags=interp)\n        else:\n            # The original image had different dimensions, so center-crop before applying rotation\n            img = Image.fromarray(img)\n            img = F.center_crop(img, (self.h, self.w))\n            img = np.array(img)\n            return cv2.warpAffine(img, self.rm_image, (self.bound_w, self.bound_h), flags=interp)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        # if the given image is empty, return the original image unchanged\n        if img.size == 0 or img is None:\n            return img\n        # if the given angle is 360/0, return the original image unchanged\n        if np.isclose(self.angle % 360, 0.0):\n            return img\n        # if the given angle is 180/180, flip the image\n        if np.isclose(self.angle % 180, 180.0):\n            return np.fliplr(img)\n        if interp is None:\n            interp = self.interp\n        ret = cv2.warpAffine(img, self.rm_image, (int(self.bound_w), int(self.bound_h)), flags=interp)\n        return ret\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if img.shape[:2] == (0, 0) or abs(self.angle) % 360 == 0:\n            # When the angle is a multiple of 360, the rotation is not applied.\n            # When the image is empty, the rotation also does not apply.\n            return img\n        if interp is None:\n            interp = self.interp\n        return cv2.warpAffine(img, self.rm_image, dsize=(int(self.bound_w), int(self.bound_h)), flags=interp)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        # if the image is 1-dimensional, temporarily add a singleton dimension, so that opencv can handle it\n        if len(img.shape) == 2:\n            img = np.expand_dims(img, -1)\n\n        if img.shape[:2] != (self.h, self.w):\n            # this should not happen\n            img = cv2.resize(img, (self.w, self.h), interpolation=cv2.INTER_LINEAR)\n\n        # apply the rotation matrix to the image\n        rotated_image = cv2.warpAffine(\n            img, self.rm_image, (self.bound_w, self.bound_h), flags=interp\n        )\n\n        # remove the singleton dimension if it exists\n        if len(img.shape) == 3 and img.shape[-1] == 1:\n            rotated_image = np.squeeze(rotated_image, -1)\n\n        return rotated_image\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if img.shape[:2] == (self.h, self.w):\n            # The image center of rotation is not necessarily the image center\n            # if the image has been resized\n            center = self.center\n        else:\n            # We should ideally never end up here, but we don't want to crash if we do\n            image_center = np.array(img.shape[:2]) / 2\n            center = (image_center + np.array([-self.w, -self.h])) * self.scale + image_center\n        matrix = self.rm_image[:, :2]\n        return cv2.warpAffine(img, matrix, (self.bound_w, self.bound_h), flags=interp, borderMode=cv2.BORDER_CONSTANT)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if img.shape[:2] == (0, 0):\n            return img\n        h, w = img.shape[:2]\n        if interp is None:\n            interp = self.interp\n        center = (self.w / 2, self.h / 2)\n        assert img.shape[:2] == (self.h, self.w)\n        rotated_image = cv2.warpAffine(img, self.rm_image, (int(self.bound_w), int(self.bound_h)), flags=interp,\n                                       borderMode=cv2.BORDER_CONSTANT, borderValue=0)\n        assert rotated_image.shape[:2] == (self.bound_h, self.bound_w)\n        return rotated_image\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if img.shape[:2] == (self.h, self.w):\n            # The original image is already the correct dimensions\n            return self.apply_image_dim_unchanged(img, interp)\n        else:\n            # The original image is not the correct dimensions, so resize first\n            img = Image.fromarray(img)\n            img = img.resize((self.w, self.h), resample=Image.BILINEAR)\n            img = np.asarray(img)\n            return self.apply_image_dim_unchanged(img, interp)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if img.shape[:2] == (self.h, self.w):\n            # The image center of rotation is not changed.\n            offset = 0\n        else:\n            # The rotation center is changed to be the center of the image.\n            # This is needed to support clipping borders.\n            offset = 1\n        assert (\n            img.shape[:2] == (self.h + offset, self.w + offset)\n        ), \"The input image size should be ({},{}), but got {}\".format(\n            self.h + offset, self.w + offset, img.shape[:2]\n        )\n\n        interp = interp if interp is not None else self.interp\n        return cv2.warpAffine(img, self.rm_image, (self.bound_w, self.bound_h), flags=interp)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        # if the given image is empty, return the original image unchanged\n        if img.size == 0 or img is None:\n            return img\n        # if the given angle is 360 or 0 degrees, return the original image unchanged\n        elif self.angle % 360 == 0:\n            return img\n        # otherwise, apply the rotation matrix to the image\n        else:\n            # get the image dimensions\n            h, w = img.shape[:2]\n            # get the rotation matrix\n            rm = self.rm_image if interp is None else self.create_rotation_matrix(interp=interp)\n            # apply the rotation matrix to the image\n            rotated_img = cv2.warpAffine(img, rm, (int(self.bound_w), int(self.bound_h)))\n            # if the image is grayscale, convert it to a 3-channel image\n            if len(img.shape) == 2:\n                rotated_img = rotated_img[:, :, None]\n            return rotated_img\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if img.shape[:2] == (self.h, self.w):\n            # The original image had the same dimensions as the bounding box.\n            # No need to crop.\n            expand = False\n        else:\n            expand = True\n        img = cv2.warpAffine(img, self.rm_image, (int(self.bound_w), int(self.bound_h)), flags=interp)\n\n        if expand:\n            # The warp changed the image dimensions. Add a black border to match the original dimensions.\n            if img.ndim == 2:\n                # grayscale\n                border_value = 0\n            else:\n                # rgb, rgba\n                border_value = (0, 0, 0)\n            img = cv2.copyMakeBorder(img, 0, self.h - self.bound_h, 0, self.w - self.bound_w, cv2.BORDER_CONSTANT,\n                                     value=border_value)\n        return img\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if img.shape[:2] == (0, 0) or abs(self.angle) % 360 == 0:\n            return img\n        h, w = img.shape[:2]\n        interp = interp if interp is not None else self.interp\n        # image center needs to be float and subtracted before and added after rotation\n        # to keep its position at the center\n        center = (w / 2.0, h / 2.0)\n        rot_mat = self.rm_image\n        if img.shape[2] == 1:\n            return cv2.warpAffine(\n                img,\n                rot_mat,\n                (int(self.bound_w), int(self.bound_h)),\n                flags=interp,\n                borderMode=cv2.BORDER_CONSTANT,\n                borderValue=0,\n            )\n        else:\n            return cv2.warpAffine(\n                img,\n                rot_mat,\n                (int(self.bound_w), int(self.bound_h)),\n                flags=interp,\n                # The following two flags are necessary to ensure proper pasting\n                # of image segments.\n                # https://github.com/opencv/opencv/issues/11784\n                # borderMode=cv2.BORDER_REPLICATE,\n                # borderValue=0,\n            )\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if img.shape[:2] == (self.h, self.w):\n            # The image center has no effect on the rotation, so simplify the matrix\n            self.rm_coords = self.rm_coords[:2, :]\n\n        if cv2 is None:\n            raise RuntimeError(\"Need to compile with OpenCV for rotation.\")\n\n        h, w = img.shape[:2]\n        if interp is None:\n            interp = self.interp\n        ret = cv2.warpAffine(img, self.rm_coords, (int(self.bound_w), int(self.bound_h)), flags=interp)\n        if img.shape[:2] == (self.bound_h, self.bound_w):\n            # This indicates that the image size hasn't changed\n            # so it should be returned as is\n            return ret\n        else:\n            # Crop to the desired output size\n            # This is done by picking the top left corner and bottom right corner of the image,\n            # and then using slicing to select the region of interest\n            # The order of the corners is top left, bottom left, bottom right, top right\n            corners = np.array([[0, 0], [0, self.bound_h - 1], [self.bound_w - 1, self.bound_h - 1], [self.bound_w - 1, 0]])\n            corners = np.matmul(corners, self.rm_coords[:2, :2].T) + self.rm_coords[:2, 2].reshape(1, -1)\n            top_left = np.min(corners, axis=0)\n            bottom_right = np.max(corners, axis=0)\n            # Round and then clamp to the just in case the image was resized\n            top_left = np.maximum(top_left.round().astype(int), 0)\n            bottom_right = np.minimum(bottom_right.round().astype(int), (self.bound_w - 1, self.bound_h - 1"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n                if predictions.has(\"pred_masks\")\n                else None\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n                if predictions.has(\"pred_masks\")\n                else None\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n                if predictions.has(\"pred_masks\")\n                else None\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n                if predictions.has(\"pred_masks\")\n                else None\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n        # buf = io.BytesIO()  # works for cairo backend\n        # canvas.print_rgba(buf)\n        # width, height = self.width, self.height\n        # s = buf.getvalue()\n\n        buffer = np.frombuffer(s, dtype=\"uint8\")\n\n        img_rgba = buffer.reshape(height, width, 4)\n        rgb, alpha = np.split(img_rgba, [3], axis=2)\n        return rgb.astype(\"uint8\")\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n        # buf = io.BytesIO()  # works for cairo backend\n        # canvas.print_rgba(buf)\n        # width, height = self.width, self.height\n        # s = buf.getvalue()\n\n        buffer = np.frombuffer(s, dtype=\"uint8\")\n\n        # imshow is slow. blend manually (still quite slow)\n        img_rgba = buffer.reshape(height, width, 4)\n        rgb, alpha = np.split(img_rgba, [3], axis=2)\n\n        try:\n            import numexpr as ne  # fuse them with numexpr\n\n            visual_img = ne.evaluate(\"img_rgba * alpha / 255.0\")\n        except ImportError:\n            visual_img = np.asarray(img_rgba, dtype=float) * (alpha / 255.0)\n\n        visual_img = visual_img.astype(\"uint8\")\n\n        # display image\n        return visual_img\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n        # buf = io.BytesIO()  # works for cairo backend\n        # canvas.print_rgba(buf)\n        # print(buf)\n        # width, height = self.width, self.height\n        # s = buf.getvalue()\n\n        buffer = np.frombuffer(s, dtype=\"uint8\")\n\n        # Defaults to RGBA\n        img_rgba = buffer.reshape(height, width, 4)\n        rgb, alpha = np.split(img_rgba, [3], axis=2)\n        return rgb.astype(\"uint8\")\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n        # buf = io.BytesIO()  # works for cairo backend\n        # canvas.print_rgba(buf)\n        # width, height = self.width, self.height\n        # s = buf.getvalue()\n\n        buffer = np.frombuffer(s, dtype=\"uint8\")\n\n        # imshow is slow. blend manually (still quite slow)\n        img_rgba = buffer.reshape(height, width, 4)\n        rgb, alpha = np.split(img_rgba, [3], axis=2)\n\n        try:\n            import numexpr as ne  # fuse them with numexpr\n\n            visual_img = ne.evaluate(\"img_rgba * alpha / 255.0\")\n        except ImportError:\n            visual_img = np.asarray(img_rgba, dtype=np.float32) * (alpha / 255.0)\n\n        visual_img = visual_img.clip(0, 255).astype(\"uint8\")\n\n        # crop\n        return visual_img\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas.figure.canvas\n        # draw the canvas, cache the renderer\n        canvas.draw()\n        buf = canvas.buffer_rgba()\n        # convert to NumPy array\n        image = np.asarray(buf)\n        return image\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas.canvas\n        s, (width, height) = canvas.print_to_buffer()\n        # buf = io.BytesIO()  # works for cairo backend\n        # canvas.print_rgba(buf)\n        # return np.frombuffer(buf.getvalue(), dtype=\"uint8\")\n        im = np.frombuffer(s, dtype=\"uint8\")\n        im.shape = (height, width, 4)\n        im = cv2.cvtColor(im, cv2.COLOR_RGBA2RGB)\n        return im\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas.figure.canvas\n        canvas.draw()       # draw the canvas, cache the renderer\n        width, height = self.width, self.height\n        s, (width, height) = canvas.print_to_buffer()\n        # buffer = np.frombuffer(s, dtype='uint8')\n        # img_rgba = buffer.reshape(height, width, 4)\n        # rgb, alpha = np.split(img_rgba, [3], axis=2)\n        # return rgb.astype(\"uint8\")\n        return np.array(Image.frombytes('RGBA', (width, height), s))\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas.figure.canvas\n        buffer = io.BytesIO()\n        canvas.print_rgba(buffer)\n        buffer.seek(0)\n        img_arr = np.frombuffer(buffer.getvalue(), dtype=np.uint8)\n        w, h = self.width, self.height\n        img_arr = img_arr.reshape(h, w, 4)\n        # img_arr = img_arr[..., [2, 1, 0]]\n        # Convert RGBA to RGB:\n        img_arr = np.delete(img_arr, 3, 2)\n        return img_arr\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas.canvas\n        s, (width, height) = canvas.print_to_buffer()\n        # buf = io.BytesIO()  # works for cairo backend\n        # canvas.print_rgba(buf)\n        # res = np.frombuffer(buf.getvalue(), dtype=np.uint8)\n\n        im = np.asarray(s).reshape((height, width, 4))\n        # res = im[:, :, :3]\n        res = np.zeros((height, width, 3), dtype=np.uint8)\n        for i in range(height):\n            for j in range(width):\n                # for k in range(3):\n                res[i][j] = im[i][j][:3]\n        return res\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas.switch_backends(FigureCanvasAgg)\n        canvas.draw()\n        width, height = self.get_image_width_height()\n        ret = np.frombuffer(canvas.tostring_rgb(), dtype=\"uint8\")\n        ret = ret.reshape((height, width, 3))\n        return ret\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas.canvas\n        s, (width, height) = canvas.print_to_buffer()\n        # buf = io.BytesIO()  # works for cairo backend\n        # canvas.print_rgba(buf)\n        # res = np.frombuffer(buf.getvalue(), dtype=np.uint8)\n\n        im = np.asarray(s).reshape(height, width, 4)\n        # res = res.reshape(height, width, 4)\n        # return res[..., :3]\n        rgb, alpha = np.split(im, [3], axis=2)\n        return rgb.astype(\"uint8\")\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas.figure.canvas\n        # canvas.draw()\n        buf = canvas.buffer_rgba()\n        linewidth = self.fig.get_figwidth() * self.dpi\n        width, height = self.width, self.height\n        img = np.asarray(buf)\n        img = img.reshape((int(linewidth), int(linewidth* self.height / self.width), 4))\n        img = np.transpose(img, (1, 0, 2))\n        img = img[:, :, 0:3]\n        return img\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas.canvas\n        s, (width, height) = canvas.print_to_buffer()\n        # buf = io.BytesIO()  # works for cairo backend\n        # canvas.print_rgba(buf)\n        # print(buf)\n        # return np.frombuffer(buf.getvalue(), dtype=\"uint8\").reshape(height, width, 4)\n        buffer = np.frombuffer(s, dtype=\"uint8\")\n\n        img_rgba = buffer.reshape(height, width, 4)\n        # print(img_rgba)\n        # print(img_rgba.shape)\n        img_rgb = img_rgba[:, :, :3]\n        # print(img_rgb)\n        # print(img_rgb.shape)\n        # img_rgb = img_rgba[:, :, :3] / 255\n        return img_rgb\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas.switch_backends(FigureCanvasAgg)\n        canvas.draw()\n        width, height = self.get_image_width_height()\n        ret = np.frombuffer(canvas.tostring_rgb(), dtype=\"uint8\")\n        ret = ret.reshape(height, width, 3)\n        return ret\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # Get the RGBA buffer from the canvas and convert to RGB\n        buf = self.canvas.buffer_rgba()\n        img = Image.frombuffer(\"RGBA\", (self.width, self.height), buf, \"raw\", \"RGBA\", 0, 1)\n        img = img.convert(\"RGB\")\n\n        # Get the numpy array from the RGB image\n        img = np.asarray(img)\n\n        return img\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas.switch_backends(FigureCanvasAgg)\n        canvas.draw()\n        width, height = self.get_image_width_height()\n        ret = np.frombuffer(canvas.tostring_rgb(), dtype=\"uint8\")\n        ret = ret.reshape((height, width, 3))\n        return ret\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n        # buf = io.BytesIO()  # works for cairo backend\n        # canvas.print_rgba(buf)\n        # width, height = self.width, self.height\n        # s = buf.getvalue()\n\n        buffer = np.frombuffer(s, dtype=\"uint8\")\n\n        # Default RGBA\n        img_rgba = buffer.reshape(height, width, 4)\n        # # Remove alpha channel, replace with fill value\n        # rgb, alpha = np.split(img_rgba, [3], axis=2)\n        # return np.concatenate((rgb, np.maximum(alpha, fill_value)[:, :, np.newaxis]), axis=2)\n        img_rgba = img_rgba.reshape(height, width, 4)\n        h, w = img_rgba.shape[:2]\n        # remove alpha channel\n        r, g, b, a = np.split(img_rgba, [3, 3 + 1, 3 + 2], axis=2)\n        # make white background\n        img_rgba = np.dstack(\n            (r * a, g * a, b * a, a)\n        )  # alpha blend rgb to rgba\n        img_rgba = img_rgba.reshape(h, w, 4)\n        return img_rgba\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas.canvas\n        s, (width, height) = canvas.print_to_buffer()\n        # buf = io.BytesIO()  # works for cairo backend\n        # canvas.print_rgba(buf)\n        # print(buf)\n        # width, height = self.width, self.height\n        # s = buf.getvalue()\n\n        buffer = np.frombuffer(s, dtype=\"uint8\")\n\n        # Default RGBA\n        img_rgba = buffer.reshape(height, width, 4)\n        # # Remove transparency\n        # img_rgb = np.sigmoid(img_rgba[..., :3])\n        # # img_rgb = np.where(img_rgba[..., 3:] == 0, 1, 0)\n        # # img_rgb = np.expand_dims(img_rgb, axis=-1)\n        # # img_rgb = np.repeat(img_rgb, 3, axis=-1)\n        # # img_rgb = img_rgb * img_rgba[..., :3]\n        # img_rgb = np.sum(img_rgb, axis=-1)\n        # # img_rgb = np.where(img_rgb[..., 3:] == 0, 1, 0)\n        # # img_rgb = np.expand_dims(img_rgb, axis=-1)\n        # # img_rgb = np.repeat(img_rgb, 3, axis=-1)\n        # # img_rgb = img_rgb * img_rgba[..., :3]\n        # # img_rgb = np.sum(img_rgb, axis=-1)\n        # img_rgb = img_rgb.astype(np.uint8)\n        # return img_rgb\n\n        # Convert RGBA to RGB\n        img_rgb = np.delete(img_rgba, 3, 2)\n        img_rgb = img_rgb.astype(np.uint8)\n        return img_rgb\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas.figure.canvas\n        canvas.draw()\n        buf = canvas.buffer_rgba()\n        # convert to (H, W, 3)\n        img = np.asarray(buf)\n        img = np.delete(img, 3, 2)\n        return img\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas.switch_backends(mpl.backends.backend_agg)\n        canvas.draw()\n        buf = canvas.buffer_rgba()\n        width, height = self.width, self.height\n        image = np.asarray(buf).reshape((height, width, 4))\n        # The first channel of the image is the alpha channel.\n        # The alpha channel has values ranging from 0 to 1, where 0 is transparent and 1 is opaque.\n        # The background of the image is transparent.\n        # We want to remove the alpha channel and make the background opaque.\n        # To do this, we multiply the RGB channels with the alpha channel, and then divide the result by 255.\n        # This will multiply the RGB channels by the alpha channel and then normalize the result so that it is in the range [0, 255].\n        # The alpha channel is the fourth channel of the image, which is the last one.\n        image = image[:, :, :3] * image[:, :, 3][:, :, np.newaxis]\n        image = image / 255\n        return image\n\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\", None)\n        if annos:\n            if \"segmentation\" in annos[0]:\n                masks = [x[\"segmentation\"] for x in annos]\n            else:\n                masks = None\n            if \"keypoints\" in annos[0]:\n                keypts = [x[\"keypoints\"] for x in annos]\n                keypts = np.array(keypts).reshape(len(annos), -1, 3)\n            else:\n                keypts = None\n\n            boxes = [\n                BoxMode.convert(x[\"bbox\"], x[\"bbox_mode\"], BoxMode.XYXY_ABS)\n                if len(x[\"bbox\"]) == 4\n                else x[\"bbox\"]\n                for x in annos\n            ]\n\n            colors = None\n            category_ids = [x[\"category_id\"] for x in annos]\n            if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n                colors = [\n                    self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in category_ids\n                ]\n            names = self.metadata.get(\"thing_classes\", None)\n            labels = _create_text_labels(\n                category_ids,\n                scores=None,\n                class_names=names,\n                is_crowd=[x.get(\"iscrowd\", 0) for x in annos],\n            )\n            boxes = boxes if boxes else None\n            masks = masks if masks else None\n\n            self.overlay_instances(\n                labels=labels, boxes=boxes, masks=masks, keypoints=keypts, assigned_colors=colors\n            )\n\n        sem_seg = dic.get(\"sem_seg\", None)\n        if sem_seg is None and \"sem_seg_file_name\" in dic:\n            with PathManager.open(dic[\"sem_seg_file_name\"], \"rb\") as f:\n                sem_seg = Image.open(f)\n               "}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        img = self.img\n        if \"annotations\" in dic:\n            for anno in dic[\"annotations\"]:\n                if not anno.get(\"iscrowd\", False):\n                    try:\n                        self.draw_box(anno[\"bbox\"], edge_color=_RED)\n                    except KeyError:\n                        pass\n\n        if \"segmentation\" in dic:\n            if isinstance(dic[\"segmentation\"], list):\n                # polygons\n                for seg in dic[\"segmentation\"]:\n                    try:\n                        self.draw_polygon(seg, edge_color=_RED)\n                    except KeyError:\n                        pass\n            else:\n                # mask\n                try:\n                    self.draw_binary_mask(dic[\"segmentation\"], edge_color=_RED)\n                except KeyError:\n                    pass\n\n        if \"keypoints\" in dic:\n            kpts = dic[\"keypoints\"]\n            try:\n                self.draw_and_connect_keypoints(kpts)\n            except KeyError:\n                pass\n\n        if \"sem_seg\" in dic:\n            self.draw_sem_seg(dic[\"sem_seg\"], area_threshold=0, alpha=0.5)\n\n        if \"pano_seg\" in dic:\n            self.draw_panoptic_seg(dic[\"pano_seg\"])\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # Assume that the dataset uses the standard Detectron2 Dataset format\n        # This code is based on the detectron2.utils.visualizer.Visualizer.draw_dataset_dict\n\n        annos = dic.get(\"annotations\", None)\n        if annos:\n            if \"segmentation\" in annos[0]:\n                masks = [x[\"segmentation\"] for x in annos]\n            else:\n                masks = None\n            if \"keypoints\" in annos[0]:\n                keypts = [x[\"keypoints\"] for x in annos]\n                keypts = np.array(keypts).reshape(len(annos), -1, 3)\n            else:\n                keypts = None\n\n            boxes = [BoxMode.convert(x[\"bbox\"], x[\"bbox_mode\"], BoxMode.XYXY_ABS) for x in annos]\n\n            labels = [x[\"category_id\"] for x in annos]\n            colors = None\n            if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n                colors = [\n                    self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in labels\n                ]\n            names = self.metadata.get(\"thing_classes\", None)\n            if names:\n                labels = [names[i] for i in labels]\n            labels = [\n                \"{}\".format(i) + (\"|crowd\" if a.get(\"iscrowd\", 0) else \"\")\n                for i, a in zip(labels, annos)\n            ]\n            self.overlay_instances(\n                labels=labels, boxes=boxes, masks=masks, keypoints=keypts, assigned_colors=colors\n            )\n\n        # Semantic segmentation\n        sem_seg = dic.get(\"sem_seg\", None)\n        if sem_seg is None and \"sem_seg_file_name\" in dic:\n            with PathManager.open(dic[\"sem_seg_file_name\"], \"rb\") as f:\n                sem_"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        img = self.img\n        if \"sem_seg\" in dic:\n            sem_seg = dic[\"sem_seg\"]\n            self.draw_sem_seg(sem_seg, area_threshold=0, alpha=0.5)\n        if \"panoptic_seg\" in dic:\n            panoptic_seg, segments_info = dic[\"panoptic_seg\"]\n            self.draw_panoptic_seg(panoptic_seg, segments_info, area_threshold=0, alpha=0.5)\n        if \"instances\" in dic:\n            instances = dic[\"instances\"]\n            # self.draw_dataset_dict(a)\n            boxes = instances.get(\"pred_boxes\")\n            classes = instances.get(\"pred_classes\")\n            scores = instances.get(\"scores\")\n            keypoints = instances.get(\"pred_keypoints\")\n            if \"pred_masks\" in instances:\n                masks = np.asarray(instances.pred_masks)\n                masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n            self.overlay_instances(\n                boxes=boxes,\n                labels=classes,\n                keypoints=keypoints,\n                assigned_colors=True,\n                alpha=0.5,\n            )\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # Draw panoptic segmentation.\n        if \"panoptic_seg\" in dic:\n            panoptic_seg, segments_info = dic[\"panoptic_seg\"], dic[\"segments_info\"]\n            self.draw_panoptic_seg(panoptic_seg, segments_info)\n\n        # Draw semantic segmentation.\n        if \"sem_seg\" in dic:\n            sem_seg = dic[\"sem_seg\"]\n            self.draw_sem_seg(sem_seg, area_threshold=0, alpha=0.5)\n\n        # Draw instance-level data.\n        if \"instances\" in dic:\n            instances = dic[\"instances\"]\n            return self.draw_instance_predictions(instances)\n\n        # Draw keypoints.\n        if \"keypoints\" in dic:\n            keypoints = dic[\"keypoints\"]\n            return self.draw_keypoints(keypoints)\n\n        # Draw bounding boxes.\n        if \"boxes\" in dic:\n            boxes = dic[\"boxes\"]\n            return self.draw_boxes(boxes).output\n\n        # Draw labels.\n        if \"labels\" in dic:\n            labels = dic[\"labels\"]\n            return self.draw_labels(labels)\n\n        # Draw masks.\n        if \"masks\" in dic:\n            masks = dic[\"masks\"]\n            return self.draw_masks(masks)\n\n        # Draw polygons.\n        if \"polygons\" in dic:\n            polygons = dic[\"polygons\"]\n            return self.draw_polygons(polygons)\n\n        # Draw points.\n        if \"points\" in dic:\n            points = dic[\"points\"]\n            return self.draw_points(points)\n\n        # Draw text.\n        if \"texts\" in dic:\n            texts = dic[\"texts\"]\n            return self.draw_texts(texts)\n\n        # Draw image.\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # Draw annotations for \"instances\" category in the COCO panoptic segmentation dataset\n        if \"instances\" in dic:\n            assert \"sem_seg\" in dic, (\n                \"Found instances annotation in COCO panoptic data, but no segmentation annotation. \"\n                \"Please use the panoptic COCO JSONs, and see https://github.com/facebookresearch/detectron2/issues/373 for more info.\"\n            )\n            self.draw_instance_predictions(dic[\"instances\"])\n\n        if \"sem_seg\" in dic:\n            self.draw_sem_seg(dic[\"sem_seg\"], area_threshold=0, alpha=0.5)\n\n        if \"panoptic_seg\" in dic:\n            self.draw_panoptic_seg(dic[\"panoptic_seg\"])\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # Draw panoptic segmentation on the image\n        if \"panoptic_seg\" in dic:\n            self.draw_panoptic_seg(dic[\"panoptic_seg\"])\n\n        # Draw semantic segmentation on the image\n        if \"sem_seg\" in dic:\n            self.draw_sem_seg(dic[\"sem_seg\"], area_threshold=0, alpha=0.5)\n\n        # Draw instances on the image\n        if \"instances\" in dic:\n            instances = dic[\"instances\"]\n            boxes = instances.pred_boxes.tensor.numpy()\n            scores = instances.scores.numpy()\n            classes = instances.pred_classes.numpy()\n            keypoints = instances.pred_keypoints\n\n            if keypoints:\n                keypoints = keypoints.numpy()\n\n            if \"pred_masks\" in instances.fields():\n                masks = np.asarray(instances.pred_masks)\n                self.draw_instance_mask(masks, boxes, classes, alpha=0.5)\n\n            if \"pred_boxes\" in instances.fields():\n                self.draw_instance_outlines(boxes, classes, scores, keypoints=keypoints, alpha=0.5)\n\n        # Draw the image\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # Draw panoptic segmentation on the image.\n        if \"panoptic_seg\" in dic:\n            self.draw_panoptic_seg(dic[\"panoptic_seg\"])\n\n        # Draw semantic segmentation on the image.\n        if \"sem_seg\" in dic:\n            self.draw_sem_seg(dic[\"sem_seg\"])\n\n        # Draw instance-level annotations on the image.\n        for ann in dic.get(\"annotations\", []):\n            # Draw panoptic segmentation on the image.\n            if \"panoptic_seg\" in dic:\n                self.draw_panoptic_seg(dic[\"panoptic_seg\"])\n\n            # Draw semantic segmentation on the image.\n            if \"sem_seg\" in dic:\n                self.draw_sem_seg(dic[\"sem_seg\"])\n\n            # Draw instance-level annotations on the image.\n            if ann.get(\"iscrowd\", 0) == 0:\n                self.draw_instance_predictions(ann)\n            else:\n                self.draw_rotated_box_3d(ann)\n\n        # Draw instance-level predictions on the image.\n        if \"instances\" in dic:\n            instances = dic[\"instances\"]\n            # Detectron2 stores predictions in a format similar to an annotation.\n            # Convert the instance predictions to a format similar to an annotation.\n            instances_dict = {\n                \"pred_boxes\": instances.pred_boxes,\n                \"scores\": instances.scores,\n                \"pred_classes\": instances.pred_classes,\n                \"pred_masks\": instances.pred_masks,\n            }\n            self.draw_instance_predictions(instances_dict)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # Draw panoptic segmentation on the image\n        if \"panoptic_seg\" in dic:\n            self.draw_panoptic_seg(dic[\"panoptic_seg\"])\n\n        # Draw each instance in its own color\n        if \"instances\" in dic:\n            instances = dic[\"instances\"]\n            labels = instances.pred_classes\n            colors = self._jitter([self._get_color(i) for i in labels])\n            self.overlay_instances(\n                masks=instances.pred_masks,\n                boxes=instances.pred_boxes,\n                labels=labels,\n                keypoints=instances.pred_keypoints,\n                assigned_colors=colors,\n            )\n\n        # Draw semantic segmentation on the image\n        if \"sem_seg\" in dic:\n            self.draw_sem_seg(dic[\"sem_seg\"])\n\n        # Draw bounding boxes on the image\n        if \"instances\" in dic:\n            instances = dic[\"instances\"]\n            boxes = instances.pred_boxes.tensor.numpy()\n            scores = instances.scores\n            labels = instances.pred_classes\n            keypoints = instances.pred_keypoints\n            boxes_with_scores = np.concatenate([boxes, scores[:, None]], axis=1)\n            boxes_with_classes = np.concatenate([boxes_with_scores, labels[:, None]], axis=1)\n            boxes_with_scores_and_classes = np.concatenate(\n                [boxes_with_classes, keypoints], axis=1\n            )\n            self.overlay_instances(\n                boxes=boxes_with_scores_and_classes,\n                labels=labels,\n                keypoints=keypoints,\n                assigned_colors=colors,\n            )\n\n        # Draw keypoints on the image\n        if \"instances\" in dic:\n            try:\n                instances = dic[\"instances\"]\n                labels = instances.pred_classes\n                colors = self._jitter([self._get_color(i) for i in labels])\n                key"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # Draw annotations on image\n        if \"annotations\" in dic:\n            for anno in dic[\"annotations\"]:\n                if not anno.get(\"iscrowd\", False):\n                    try:\n                        self.draw_box(anno[\"bbox\"], edge_color=_RED)\n                    except:\n                        continue\n                    if anno.get(\"keypoints\", None):\n                        self.draw_keypoints(anno[\"keypoints\"])\n                # Draw bbox and/or mask on the image if they are available\n                if anno.get(\"bbox\", False):\n                    self.draw_bbox(anno[\"bbox\"], edge_color=_BLUE)\n                if anno.get(\"mask\", False):\n                    self.draw_binary_mask(anno[\"mask\"])\n\n        # Draw segmentation masks on image\n        if \"sem_seg\" in dic:\n            self.draw_sem_seg(dic[\"sem_seg\"], area_threshold=0, alpha=0.5)\n\n        # Draw panoptic masks on image\n        if \"pan_seg\" in dic:\n            self.draw_panoptic_seg(dic[\"pan_seg\"], area_threshold=0, alpha=0.5)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # Assume that the dataset uses detectron2's default format\n        # Note that settings like panoptic_seg are only available for some datasets\n        # If you need to visualize a different format, please feel free to add code\n        self.draw_dataset_dict_instance_seg(dic)\n        self.draw_dataset_dict_sem_seg(dic)\n        self.draw_dataset_dict_panoptic_seg(dic)\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # Draw annotations/segmentations\n        if \"annotations\" in dic:\n            for anno in dic.get(\"annotations\", []):\n                if not anno.get(\"iscrowd\", 0):\n                    self.draw_bbox(anno[\"bbox\"])\n                if \"keypoints\" in anno:\n                    # NOTE: keypoints in Detectron2 format are floating point values in [0, 1],\n                    # while keypoints used by this lib are integer values in [0, height or width]\n                    # Therefore, we assume the keypoints are relative to the image size, and\n                    # transform them to absolute coordinates.\n                    keypoints = (\n                        np.asarray(anno[\"keypoints\"])\n                        * np.array([dic[\"height\"], dic[\"width\"]])\n                    ).astype(np.int32)\n                    self.draw_keypoint(keypoints, [1, 1, 1])\n        if \"sem_seg\" in dic:\n            self.draw_sem_seg(dic[\"sem_seg\"], area_threshold=0, alpha=0.5)\n        if \"panoptic_seg\" in dic:\n            self.draw_panoptic_seg(dic[\"panoptic_seg\"])\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # Draw all annotations for object detection task\n        self.draw_dataset_dict_instances(dic, bbox_alpha=0.9, text_alpha=0.9, panoptic_seg=False)\n\n        # Draw panoptic segmentation on top of object detection boxes\n        if \"panoptic_seg\" in dic:\n            panoptic_seg, segments_info = dic[\"panoptic_seg\"], dic[\"segments_info\"]\n            self.draw_panoptic_seg(panoptic_seg, segments_info, area_threshold=None, alpha=0.7)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # draw image\n        img = self.img\n\n        if \"image\" in dic:\n            img = dic[\"image\"]\n        elif \"image_id\" in dic:\n            img = self._image_id_to_image(dic[\"image_id\"])\n\n        visualizer = Visualizer(img, self.metadata)\n\n        if \"annotations\" in dic:\n            for ann in dic[\"annotations\"]:\n                visualizer = self.draw_bbox(ann, visualizer)\n\n        if \"sem_seg\" in dic:\n            visualizer = self.draw_sem_seg(dic[\"sem_seg\"], area_threshold=0, alpha=0.5)\n\n        if \"panoptic_seg\" in dic:\n            panoptic_seg, segments_info = dic[\"panoptic_seg\"]\n            pred = _PanopticPrediction(panoptic_seg, segments_info, self.metadata)\n            visualizer = self.draw_panoptic_seg(\n                panoptic_seg, segments_info, area_threshold=0, alpha=0.5\n            )\n\n        return visualizer.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # Draw panoptic segmentation on the image\n        if \"panoptic_seg\" in dic:\n            self.draw_panoptic_seg(dic[\"panoptic_seg\"])\n\n        # Draw semantic segmentation on the image\n        if \"sem_seg\" in dic:\n            self.draw_sem_seg(dic[\"sem_seg\"], area_threshold=0, alpha=0.5)\n\n        # Draw instance-level annotations on the image\n        for ann in dic.get(\"annotations\", []):\n            # Draw each instance using its annotation ID\n            try:\n                color = random_color(rgb=True, maximum=1)\n            except:\n                color = random_color()\n            if ann.get(\"iscrowd\", 0) == 0:\n                self.draw_box(ann[\"bbox\"], edge_color=color)\n                if \"segmentation\" in ann:\n                    # Draw segmentation masks as white padding around the box\n                    mask_color = (1.0, 1.0, 1.0)\n                    self.draw_mask(ann[\"segmentation\"], color=mask_color, alpha=1.0)\n            elif ann.get(\"iscrowd\", 0) == 1:\n                self.draw_polygon(ann[\"segmentation\"], edge_color=color, alpha=0.5)\n\n        # Draw keypoints on the image\n        if \"keypoints\" in dic:\n            # Keypoints are drawn as a set of circles\n            for keypoints in dic[\"keypoints\"]:\n                for x, y in keypoints:\n                    self.draw_circle((x, y), color=color)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # Make a copy of the image, if it hasn't been copied yet.\n        if self.output.get_image() is None:\n            self.output.img = self.img\n\n        annos = dic.get(\"annotations\", None)\n        if annos:\n            # Display in largest to smallest order to reduce occlusion.\n            if not isinstance(annos, list):\n                annos = [annos]\n            annos = sorted(annos, key=lambda x: x[\"bbox\"][2] * x[\"bbox\"][3], reverse=True)\n            for anno in annos:\n                if anno.get(\"iscrowd\", 0) == 1:\n                    # Draw crowd regions as a mask.\n                    self.draw_mask(\n                        anno[\"segmentation\"],\n                        color=[0.9, 0.9, 0.9],\n                        alpha=0.5,\n                    )\n                else:\n                    # Draw instance masks.\n                    color = random_color(rgb=True, maximum=1)\n                    self.draw_mask(\n                        anno[\"segmentation\"],\n                        color=color,\n                        alpha=0.5,\n                    )\n                    # Draw instance bounding boxes.\n                    self.draw_box(\n                        anno[\"bbox\"],\n                        edge_color=color,\n                        alpha=0.5,\n                    )\n                    # Draw instance keypoints.\n                    if anno.get(\"keypoints\", None):\n                        self.draw_keypoints(\n                            anno[\"keypoints\"],\n                            alpha=0.5,\n                        )\n\n        if \"sem_seg\" in dic:\n            self.draw_sem_seg(dic[\"sem_seg\"], area_threshold=0, alpha=0.5)\n\n        if \"panoptic_seg\" in dic:\n            self.draw_panoptic_seg(dic[\"panoptic_seg\"])\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # Draw panoptic segmentation.\n        if \"panoptic_seg\" in dic:\n            self.draw_panoptic_seg(dic[\"panoptic_seg\"])\n\n        # Draw semantic segmentation.\n        if \"sem_seg\" in dic:\n            self.draw_sem_seg(dic[\"sem_seg\"])\n\n        # Draw instance-level data.\n        for ann in dic.get(\"annotations\", []):\n            # Draw instance-level annotations.\n            is_crowd = ann.get(\"iscrowd\", 0)\n            label = ann[\"category_id\"]\n            try:\n                color = [x / 255 for x in self.metadata.thing_colors[label]]\n            except AttributeError:\n                color = random_color(rgb=True, maximum=1)\n\n            # Draw panoptic segmentation.\n            if \"segmentation\" in ann and isinstance(ann[\"segmentation\"], dict):\n                if ann[\"segmentation\"][\"type\"] == \"pan_opt\":\n                    segmentation = ann[\"segmentation\"][\"data\"]\n                    self.draw_panoptic_seg(\n                        panoptic_seg=segmentation,\n                        segments_info=self.metadata.stuff_dataset_id_to_contiguous_id,\n                        area_threshold=0,\n                        alpha=0.5,\n                    )\n\n            # Draw semantic segmentation.\n            if \"segmentation\" in ann and isinstance(ann[\"segmentation\"], dict):\n                if ann[\"segmentation\"][\"type\"] == \"segm\":\n                    for segmentation in ann[\"segmentation\"][\"counts\"]:\n                        self.draw_binary_mask(\n                            mask=segmentation,\n                            color=color,\n                            edge_color=None,\n                            text=None,\n                            alpha=0.5,\n                        )\n\n            # Draw bounding box.\n            if \"bbox\" in ann and \"bbox_mode\" in ann:\n                x0, y0, w, h = ann[\"bbox\"]\n                if ann[\"bbox_mode\"]"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # The input dic is a dictionary of annotations/segmentations for a single image.\n        # The dictionary may contain keys for annotations, semantic segmentation, and panoptic segmentation, among others.\n        # The following are the basic visualization methods that can be applied to each type of data.\n\n        # Draw segmentation masks\n        if \"sem_seg\" in dic:\n            self.draw_sem_seg(dic[\"sem_seg\"], area_threshold=0, alpha=0.5)\n\n        # Draw panoptic segmentation\n        if \"pan_seg\" in dic:\n            self.draw_panoptic_seg(dic[\"pan_seg\"], area_threshold=0, alpha=0.5)\n\n        # Draw keypoints\n        if \"keypoints\" in dic:\n            keypoints = [k for k in dic[\"keypoints\"] if len(k) > 0]\n            if len(keypoints) > 0:\n                keypoints = np.array(keypoints)\n                for keypoints_per_instance in keypoints:\n                    self.draw_and_connect_keypoints(keypoints_per_instance)\n\n        # Draw bounding boxes\n        if \"instances\" in dic:\n            boxes = [\n                BoxMode.convert(x.get(\"bbox\", x[\"bbox_mode\"].convert(x[\"bbox\"])), x[\"bbox_mode\"], BoxMode.XYXY_ABS)\n                for x in dic[\"instances\"]\n            ]\n            scores = np.asarray([x[\"score\"] for x in dic[\"instances\"]])\n            labels = np.asarray([self.metadata.thing_classes[x[\"category_id\"]] for x in dic[\"instances\"]])\n            labels = [None] * len(labels) if all(x is None for x in labels) else labels\n            boxes_with_labels = list(zip(boxes, labels))\n            boxes = boxes if boxes_with_labels else None\n            self.overlay_instances(boxes=boxes, labels=labels, keypoints=boxes_with_labels, assigned_colors=None)\n\n        # Draw masks"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # Assume that the dataset uses the standard Detectron2 Dataset format\n        # The following will work for the COCO dataset, but it may need to be adjusted for other datasets\n        # The vis_dataset_dict function is a helper function to draw annotations on an image based on the Detectron2 Dataset format.\n        # The input is the image, the output is the image with annotations drawn on it\n        self.draw_dataset_dict(dic)\n\n        # The image object can be output as a numpy array or a PIL image\n        return self.get_image()\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # The dictionary must contain either \"annotations\" or \"sem_seg\"\n        assert \"annotations\" in dic or \"sem_seg\" in dic, dic.keys()\n\n        # The dictionary must contain either \"image\" or \"segments_info\"\n        assert \"image\" in dic or \"segments_info\" in dic, dic.keys()\n\n        # The dictionary must contain either \"annotations\" or \"panoptic_seg\"\n        assert \"panoptic_seg\" in dic or \"annotations\" in dic, dic.keys()\n\n        # Draw annotations\n        if \"annotations\" in dic:\n            for ann in dic[\"annotations\"]:\n                self.draw_bbox(ann[\"bbox\"], color=random_color(rgb=True, maximum=1))\n                if \"segmentation\" in ann:\n                    # Either binary mask or COCO polygon\n                    if isinstance(ann[\"segmentation\"], dict):\n                        if \"counts\" in ann[\"segmentation\"]:\n                            mask = mask_util.decode(ann[\"segmentation\"])\n                            self.draw_binary_mask(mask, color=random_color(rgb=True, maximum=1))\n                        else:\n                            print(\"Unsupported COCO RLE segmentation format, skipping\")\n                    else:\n                        self.draw_polygon(ann[\"segmentation\"], color=random_color(rgb=True, maximum=1))\n                if \"keypoints\" in ann:\n                    self.draw_keypoints(ann[\"keypoints\"])\n                if \"crowd\" in ann:\n                    if ann[\"crowd\"]:\n                        text = \"crowd\"\n                    else:\n                        text = \"not crowd\"\n                    self.draw_text(text, ann[\"bbox\"])\n\n        # Draw semantic segmentation\n        if \"sem_seg\" in dic:\n            self.draw_sem_seg(dic[\"sem_seg\"])\n\n        # Draw panoptic segmentation\n        if \"panoptic_seg\" in dic:\n            self.draw_panoptic_seg(dic[\"panoptic_seg\"])"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # Convert the mask to 0 and 1 format\n        binary_mask = binary_mask.astype(\"uint8\")\n\n        # Draw the mask\n        self.draw_binary_mask_helper(binary_mask, color, edge_color, alpha, area_threshold)\n\n        # Draw the text if specified\n        if text is not None:\n            # Find the center of the mask\n            nonzero_pixels = binary_mask.nonzero()\n            y = np.mean(nonzero_pixels[0])\n            x = np.mean(nonzero_pixels[1])\n\n            # Draw the text on the top left corner of the mask\n            self.draw_text(text, (x, y), color=color)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # Convert the binary mask to a polygon mask.\n        contours = _mask_to_polygon(binary_mask, area_threshold)\n\n        # Draw the mask on the image.\n        self.draw_polygon(contours, color=color, edge_color=edge_color, alpha=alpha)\n\n        # Draw the text on the mask.\n        if text is not None:\n            # Find the top left corner of the largest component in the mask.\n            contour_sizes = [cv2.contourArea(contour) for contour in contours]\n            largest_component = contours[np.argmax(contour_sizes)]\n            top_left = tuple(largest_component[largest_component[:, :, 0].argmin()][0])\n\n            # Draw the text at the top left corner of the largest component.\n            self.draw_text(text, top_left, color=color)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        color = mplc.to_rgb(color)\n\n        has_holes = get_mask_from_polygons_with_holes(binary_mask)\n        if not has_holes:\n            self._draw_mask_as_polygon(binary_mask, color, edge_color, alpha, area_threshold)\n        else:\n            self._draw_mask_with_holes(binary_mask, color, edge_color, alpha, area_threshold)\n\n        if text is not None:\n            self._draw_text_on_top(binary_mask, text)\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        color = mplc.to_rgb(color)\n\n        has_holes = get_mask_defects(binary_mask)\n        binary_mask = binary_mask.astype(\"uint8\")\n        contours = cv2.findContours(binary_mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n        contours = contours[-2]\n\n        if edge_color is None:\n            # make edge color darker than the mask color\n            if has_holes:\n                edge_color = np.maximum(0, np.array(color) - 0.25)\n            else:\n                edge_color = np.maximum(0, np.array(color) - 0.05)\n\n        edge_color = mplc.to_rgb(edge_color) + (1,)\n\n        for c in contours:\n            area = cv2.contourArea(c)\n            if area < area_threshold:\n                continue\n\n            m = cv2.moments(c)\n            x, y = m[\"m10\"] / m[\"m00\"], m[\"m01\"] / m[\"m00\"]\n            if has_holes:\n                self.draw_polygon(c[:, 0, :], color=color, edge_color=edge_color, alpha=alpha)\n            else:\n                self.draw_circle((x, y), color=color, radius=3, edge_color=edge_color, alpha=alpha)\n\n        if text is not None:\n            self.draw_text(text, (x, y), color=edge_color, horizontal_alignment=\"center\", rotation=0)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # Generate random colors for masks\n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        # Convert binary masks to polygons\n        padded_binary_mask = np.pad(binary_mask, pad_width=1, mode=\"constant\", constant_values=0)\n        contours = cv2.findContours(padded_binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[-2]\n        polygons = [c.reshape(-1).tolist() for c in contours if len(c) >= 3]\n        if not polygons:\n            return self.output\n\n        # Draw polygons\n        if edge_color is None:\n            edge_color = color\n        edge_color = mplc.to_rgb(edge_color) + (1,)\n        polygon = Polygon(polygons, facecolor=color, edgecolor=edge_color, fill=True, alpha=alpha)\n        self.output.ax.add_patch(polygon)\n\n        # Draw text\n        if text is not None:\n            # Find the average location of the polygon\n            y_coord, x_coord = 0, 0\n            for coord in polygons:\n                y_coord += coord[0]\n                x_coord += coord[1]\n            y_coord /= len(polygons)\n            x_coord /= len(polygons)\n\n            # Draw the text on the mask\n            text_pos = (x_coord, y_coord)\n            horiz_align = \"center\"\n            vert_align = \"center\"\n            text_color = \"black\"\n            font_size = self._default_font_size\n            self.draw_text(text, text_pos, color=text_color, horizontal_alignment=horiz_align, font_size=font_size,\n                           vertical_alignment=vert_align)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        color = mplc.to_rgb(color)\n        if edge_color is None:\n            edge_color = color\n        edge_color = mplc.to_rgb(edge_color) + (1,)\n\n        polygons = _mask_to_polygons(binary_mask, area_threshold)\n        self.draw_polygons(polygons, color, edge_color=edge_color, alpha=alpha)\n\n        if text is not None:\n            # TODO(ruthfong): Draw text in the center of the smallest bounding box containing the mask.\n            raise NotImplementedError()\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        color = mplc.to_rgb(color)\n\n        has_holes = get_mask_from_polygon_with_holes(binary_mask)\n\n        # Draw polygons\n        if not has_holes:\n            self._draw_binary_mask_in_polygon_mode(binary_mask, color=color, edge_color=edge_color, alpha=alpha)\n        # Draw polygons with holes\n        else:\n            self._draw_binary_mask_in_contour_mode(binary_mask, color=color, edge_color=edge_color, alpha=alpha, area_threshold=area_threshold)\n\n        # Draw text\n        if text is not None:\n            # Find the center of the mask\n            nonzero_pixels = binary_mask.nonzero()\n            y = np.mean(nonzero_pixels[0])\n            x = np.mean(nonzero_pixels[1])\n            self.draw_text(text, (x, y), color=color)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # Generate random colors for the masks if no color is provided.\n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        # Convert the masks to a list of polygons.\n        polygons = binary_mask_to_polygon(binary_mask, area_threshold=area_threshold)\n\n        # Draw the masks on the image.\n        for polygon in polygons:\n            # Draw the mask polygon with the specified color.\n            self.draw_polygon(polygon, color=color, edge_color=edge_color, alpha=alpha)\n\n        # Draw the text on the image if specified.\n        if text is not None:\n            # Draw the text on the top left corner of the bounding box.\n            y_min, x_min, y_max, x_max = binary_mask.nonzero()[0:4]\n            x_center = (x_min + x_max) / 2\n            y_center = (y_min + y_max) / 2\n            self.draw_text(text, (x_center, y_center))\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        if area_threshold is None:\n            area_threshold = 10\n\n        # This function cannot draw masks that are completely empty.\n        if binary_mask.sum() < area_threshold:\n            return self.output\n\n        # This function cannot draw masks that are completely empty.\n        if binary_mask.sum() < area_threshold:\n            return self.output\n\n        # Instantiate contours object to draw masks.\n        contours = Contours(binary_mask)\n\n        # Draw masks as polygons.\n        for mask in contours.polygons:\n            if edge_color is None:\n                edge_color = color\n            edge_color = mplc.to_rgb(edge_color) + (1,)\n            mask = Polygon(mask, facecolor=color, edgecolor=edge_color, fill=True, alpha=alpha)\n            self.output.ax.add_patch(mask)\n\n        # Draw masks as holes in the masks.\n        for hole in contours.holes:\n            hole = Polygon(hole, edgecolor=color, fill=True, alpha=alpha)\n            self.output.ax.add_patch(hole)\n\n        # Draw text on the masks.\n        if text is not None:\n            text_pos = contours.centroid\n            self.draw_text(text, text_pos)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # Generate random colors for masks if not given\n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        if edge_color is None:\n            edge_color = color\n\n        if area_threshold is None:\n            area_threshold = 10\n\n        # Convert the masks to polygons\n        padded_mask = np.zeros((binary_mask.shape[0] + 2, binary_mask.shape[1] + 2), dtype=np.uint8)\n        padded_mask[1:-1, 1:-1] = binary_mask\n        contours = find_contours(padded_mask, 0.5)\n\n        # Draw the masks\n        for verts in contours:\n            verts = verts[:, [1, 0]]\n            verts = verts.reshape((-1, 1, 2)).astype(float)\n            if verts.shape[0] < area_threshold:\n                continue\n            self.draw_polygon(verts, color=color, edge_color=edge_color, alpha=alpha)\n\n        # Draw the text\n        if text is not None:\n            mask_center = np.array(binary_mask.shape)[::-1] / 2\n            self.draw_text(text, mask_center, color=edge_color, font_size=self._default_font_size)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # This function is adapted from https://github.com/facebookresearch/detectron2/blob/main/detectron2/utils/visualizer.py\n        # In the original function, binary_mask is a numpy array of shape (H, W) representing the binary mask, where H is the image height and W is the image width. Each value in the array is either 0 or 1 of uint8 type.\n        # In this implementation, binary_mask is a torch tensor of shape (H, W) representing the binary mask, where H is the image height and W is the image width. Each value in the tensor is either 0 or 1 of uint8 type.\n\n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        color = mplc.to_rgb(color)\n\n        has_holes = False\n\n        # Draw polygons for the mask\n        mask = generic_mask.GenericMask(binary_mask, self.output.height, self.output.width)\n        for segment in mask.polygons:\n            segment = segment.reshape(-1, 2)\n            if segment.shape[0] < 3:  # An object must have at least 3 points to be drawn\n                continue\n            if segment.shape[0] == 4:\n                # This is the case when the object is a rectangle.\n                self.draw_rectangle(segment, edge_color=color, alpha=alpha)\n            else:\n                # This is the case when the object is a polygon.\n                self.draw_polygon(segment, edge_color=color, face_color=color, alpha=alpha)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # if colors as string, convert to tuple\n        if isinstance(color, str):\n            color = mplc.to_rgb(color)\n        if isinstance(edge_color, str):\n            edge_color = mplc.to_rgb(edge_color)\n        # if no color provided, random color\n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        # if no edge_color provided, color is darker version of color\n        if edge_color is None:\n            edge_color = self._change_color_brightness(color, brightness_factor=-0.7)\n\n        binary_mask = binary_mask.astype(\"uint8\")  # opencv needs uint8\n        contours, hierarchy = cv2.findContours(\n            binary_mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE\n        )\n        if not contours:\n            return self.output\n\n        # Draw polygons and calculate polygons' areas\n        areas = []\n        for c in contours:\n            area = cv2.contourArea(c)\n            areas.append(area)\n            if area >= area_threshold:\n                self.draw_polygon(c, color=color, edge_color=edge_color, alpha=alpha)\n\n        # Draw text if text is provided\n        if text is not None:\n            # The contour that wraps the text is the largest component,\n            # and the second largest component is the outlining component.\n            # We draw the text on the outlining component.\n            c = contours[np.argmax(areas) if len(areas) > 1 else 0]\n            self.draw_text(text, c, color=color, font_size=8, alpha=alpha)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        color = mplc.to_rgb(color)\n\n        has_holes = get_mask_from_polygons(binary_mask, \"bitwise_not\")\n        binary_mask = binary_mask.astype(\"uint8\")\n\n        if has_holes:\n            # Draw polygons for both mask foreground and mask background\n            # Obtain the contours for each object\n            contours = cv2.findContours(binary_mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)[-2]\n            mask_contours = []\n            border_contours = []\n            for contour in contours:\n                # Draw contour for mask foreground\n                contour = contour[:, 0, :]\n                contour_area = cv2.contourArea(contour)\n                if contour_area < area_threshold:\n                    continue\n                mask_contours.append(contour)\n\n                # Draw contour for mask background\n                border = contour.copy()\n                border[:, 0, :] = border[:, 0, :] + 1\n                border_contours.append(border)\n\n            for contour in mask_contours:\n                self.draw_polygon(contour, color=color, edge_color=edge_color, alpha=None)\n            for contour in border_contours:\n                self.draw_polygon(contour, color=color, edge_color=edge_color, alpha=alpha)\n        else:\n            self.draw_binary_mask_on_image(binary_mask, color=color, edge_color=edge_color, alpha=alpha)\n\n        if text is not None:\n            # TODO: add an option to draw text on the mask\n            raise NotImplementedError(\"drawing text on masks not implemented yet\")\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # Convert the binary mask to a polygon mask\n        # This function uses the PIL package. If PIL package is not installed, the function will not work.\n        try:\n            import PIL.Image\n            import PIL.ImageDraw\n        except ModuleNotFoundError:\n            self._logger.error(\n                \"draw_binary_mask requires the PIL package: pip install Pillow\"\n            )\n            return self.output\n\n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        if area_threshold is None:\n            area_threshold = 10\n\n        mask = PIL.Image.fromarray(binary_mask)\n        mask = PIL.Image.fromarray(np.array(mask))\n        draw = PIL.ImageDraw.Draw(mask)\n        solid_countours = cv2.findContours(\n            binary_mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE\n        )\n        solid_countours = solid_countours[0] if len(solid_countours) == 2 else solid_countours[1]\n        for c in solid_countours:\n            if cv2.contourArea(c) >= area_threshold:\n                draw.polygon(c.flatten().tolist(), outline=tuple(edge_color), fill=tuple(color))\n        if text is not None:\n            draw.text((10, 10), text, fill=tuple(edge_color))\n        mask = np.array(mask)\n\n        # Draw the mask on the image\n        mask = torch.from_numpy(mask)\n        mask = mask.unsqueeze(0)\n        mask = mask.unsqueeze(0)\n        mask = mask.type(torch.float32)\n        self.output.img = self.output.img * (1 - mask) + mask * color\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        if area_threshold is None:\n            area_threshold = 10\n\n        # In order to get the coordinates of the polygon edges, we need to find the contours of the mask.\n        mask = GenericMask(binary_mask, self.output.height, self.output.width)\n        polygons = mask.polygons()\n\n        # If the mask is very small, we draw the mask as a rectangle.\n        if len(polygons) > 0 and polygons[0].is_valid and len(polygons[0]) >= 6:\n            for polygon in polygons:\n                if polygon.is_valid and len(polygon) >= 6:\n                    coords = polygon.coords\n                    self.draw_polygon(coords, color=color, edge_color=edge_color, alpha=alpha)\n        else:\n            # Draw the mask as a rectangle.\n            x0, y0, x1, y1 = binary_mask.nonzero()\n            x0, x1 = np.min(x0), np.max(x1)\n            y0, y1 = np.min(y0), np.max(y1)\n            self.draw_rectangle(x0, y0, x1, y1, color=color, alpha=alpha)\n\n        if text is not None:\n            # TODO(ruthfong): Draw text in the middle of the object's bounding box.\n            raise NotImplementedError()\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # If binary mask contains holes, a mask with holes is drawn.\n        # Otherwise, a regular mask is drawn.\n        if binary_mask.sum() > 0:\n            if np.ndim(binary_mask) != 2:\n                raise ValueError(\"The binary mask format is incorrect. Only 2-dimensional binary masks are supported.\")\n            if binary_mask.dtype != np.uint8:\n                raise ValueError(\"The binary mask data type is incorrect. Only uint8 type is supported.\")\n\n            # Get the contours of the binary mask.\n            contours = cv2.findContours(binary_mask.astype(np.uint8), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)[-2]\n\n            # Draw the mask contours if the area of the component is larger than the threshold.\n            for c in contours:\n                if cv2.contourArea(c) > area_threshold:\n                    self.draw_polygon(c.reshape(-1, 2), edge_color=edge_color, color=color, alpha=alpha)\n\n        # Draw the text on the mask if specified.\n        if text is not None:\n            # Set the color for the text background.\n            text_color = color if color is not None else random_color(rgb=True, maximum=1)\n\n            # Set the color for the text.\n            text_color = (\n                np.asarray(text_color) - np.asarray(_OFF_WHITE)\n            )\n            text_color[text_color < 0] = 0\n            text_color[text_color > 1] = 1\n            text_color = text_color.astype(np.float32)\n\n            # Draw the text on the binary mask.\n            binary_mask = draw_text(binary_mask, text, color=text_color)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # Validate the input arguments.\n        if not isinstance(binary_mask, np.ndarray) or binary_mask.dtype != np.uint8:\n            raise ValueError(\"binary_mask should be a uint8 type numpy array.\")\n        if binary_mask.ndim != 2:\n            raise ValueError(\"binary_mask should be of rank 2 (image).\")\n        if not isinstance(area_threshold, int) or area_threshold < 0:\n            raise ValueError(\"area_threshold should be a positive integer.\")\n\n        # Compute the contours of the mask.\n        contours = cv2.findContours(binary_mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)[0]\n\n        # Draw the contours on the image.\n        if edge_color is None:\n            edge_color = random_color(rgb=True, maximum=1)\n        self.draw_polygon(contours, edge_color=edge_color, fill_color=color, alpha=alpha)\n\n        # Draw the text on the image.\n        if text is not None:\n            # The contours are not guaranteed to be sorted by area.\n            # Therefore, we sort them by area.\n            sorted_contours = sorted(contours, key=lambda c: cv2.contourArea(c))\n            # Draw the text on the largest component.\n            self.draw_text(text, sorted_contours[-1], color=color)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # If binary mask is None, then return the output image unchanged\n        if binary_mask is None:\n            return self.output\n\n        # If binary mask is not None, then draw the binary mask\n        binary_mask = binary_mask.astype(\"uint8\")  # make sure binary_mask is np.uint8\n        shape = binary_mask.shape[:2]\n\n        # If color is not specified, then use a random color\n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        # If edge_color is not specified, then use the same color as mask\n        if edge_color is None:\n            edge_color = color\n\n        # Convert the binary mask to a polygon mask\n        mask = GenericMask(binary_mask, self.output.height, self.output.width)\n        polygons = mask.polygons()\n\n        # Draw the mask on the image\n        if polygons:\n            # Draw the mask on the image as a set of polygons\n            # If there are too many polygons, then draw the mask as a set of rectangles\n            for segment in polygons:\n                segment = segment.reshape(-1, 2)\n                if len(segment) < 3:  # skip if not a closed polygon\n                    continue\n                if len(segment) == 4 and area(segment) > area_threshold:\n                    (x0, y0), (x1, y1) = segment[0], segment[2]\n                    self.draw_rectangle([x0, y0, x1, y1], color=color, alpha=alpha)\n                else:\n                    self.draw_polygon(segment, color=color, edge_color=edge_color, alpha=alpha)\n\n        # Draw the text on the image if specified\n        if text is not None:\n            # If the mask is big enough, then draw the text on the mask\n            if area(polygons) > area_threshold:\n                lighter_color = self._change_color_brightness(color, brightness_factor=0.7)"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # This function is based on the draw_binary_mask function from the detectron2.visualizer.Visualizer class.\n        # The draw_binary_mask function is modified to support drawing polygons and masks with holes.\n\n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        if area_threshold is None:\n            area_threshold = 10\n\n        if area_threshold == 0:\n            bin_mask_polygon = binary_mask\n        else:\n            bin_mask_polygon = mask_util.polygon_from_mask(binary_mask, area_threshold)\n\n        if bin_mask_polygon is None:\n            return self.output\n\n        if edge_color is None:\n            if sum(color) < 1.5:\n                edge_color = color\n            else:\n                edge_color = (0, 0, 0)\n\n        edge_color = mplc.to_rgb(edge_color) + (1,)\n\n        self.draw_polygon(bin_mask_polygon, edge_color, alpha=alpha)\n\n        if text is not None:\n            # TODO: Add a text_color parameter.\n            self.draw_text(text, bin_mask_polygon.mean(axis=0), color=edge_color)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # This function is adapted from https://github.com/facebookresearch/detectron2/blob/main/detectron2/utils/visualizer.py#L139\n\n        area_threshold = max(area_threshold, 0.5)\n        # This is a hack to white out the area that is outside of the mask\n        binary_mask = np.logical_not(binary_mask)\n        binary_mask = np.logical_and(binary_mask, binary_mask.any(axis=1))\n        binary_mask = np.logical_and(binary_mask, binary_mask.any(axis=0))\n        binary_mask = np.logical_not(binary_mask)\n        binary_mask = binary_mask.astype(np.uint8)\n        contours = Image.fromarray(binary_mask).contours()\n        contours = [(c.reshape(-1, 2).astype(\"int16\")) for c in contours]\n        for contour in contours:\n            contour = contour[np.abs(contour[:, 0] - contour[:, 2]) > 1e-4]\n            contour = contour[np.abs(contour[:, 1] - contour[:, 3]) > 1e-4]\n            if contour.shape[0] < 4:\n                continue\n            if contour.shape[0] == 4:\n                contour = contour[[0, 2]]\n            if area(contour) < area_threshold:\n                continue\n            if edge_color is None:\n                color = self._jitter([x / 255 for x in self.metadata.get(\"theme_colors\", [180, 30, 200])])\n            else:\n                color = edge_color\n            if text is not None:\n                self.draw_text(text, tuple(contour[0]), color=color)\n            self.draw_polygon(contour, edge_color=color, fill_color=color, alpha=alpha)\n        return self.output\n\n   "}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    # check image_size\n    if size_as_tensor:\n        assert torch.equal(input.image_size, other.image_size)\n    else:\n        assert input.image_size == other.image_size\n\n    # check fields\n    for name in input._field_names:\n        assert hasattr(other, name)\n        val1, val2 = getattr(input, name), getattr(other, name)\n        if isinstance(val1, Boxes):\n            # boxes in the range of [0, scale]\n            assert torch.allclose(val1.tensor, val2.tensor, atol=0, rtol=rtol)\n        elif isinstance(val1, ROIMasks):\n            # check the shape and contents\n            assert val1.tensor.shape == val2.tensor.shape\n            assert torch.allclose(val1.tensor, val2.tensor, atol=0, rtol=rtol)\n        elif isinstance(val1, torch.Tensor):\n            assert torch.allclose(val1, val2, atol=0, rtol=rtol)\n        elif isinstance(val1, int):\n            assert val1 == val2\n        elif isinstance(val1, float):\n            assert np.isclose(val1, val2, rtol=rtol)\n        else:\n            raise ValueError(\"Unsupported field type: {}\".format(type(val1)))"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(input, Instances) or not isinstance(other, Instances):\n        raise AssertionError(\"The inputs must be two instances of type Instances\")\n\n    if not isinstance(rtol, float):\n        raise AssertionError(\"rtol must be a float\")\n\n    if not isinstance(msg, str):\n        raise AssertionError(\"msg must be a string\")\n\n    if not isinstance(size_as_tensor, bool):\n        raise AssertionError(\"size_as_tensor must be a boolean\")\n\n    if not isinstance(input.image_size, (tuple, torch.Tensor)):\n        raise AssertionError(\"The image_size of the first input must be a tuple or a tensor\")\n\n    if not isinstance(other.image_size, (tuple, torch.Tensor)):\n        raise AssertionError(\"The image_size of the second input must be a tuple or a tensor\")\n\n    if isinstance(input.image_size, tuple) and isinstance(other.image_size, tuple):\n        if size_as_tensor:\n            assert torch.tensor(input.image_size) == torch.tensor(other.image_size), (\n                f\"The image_size of the first input is {input.image_size}, \"\n                f\"while the image_size of the second input is {other.image_size}.\\n{msg}\"\n            )\n        else:\n            assert input.image_size == other.image_size, (\n                f\"The image_size of the first input is {input.image_size}, \"\n                f\"while the image_size of the second input is {other.image_size}.\\n{msg}\"\n            )\n    elif isinstance(input.image_size, torch.Tensor) and isinstance(other.image_size, torch.Tensor):\n        assert torch.equal(input.image_size, other.image_size), (\n            f\"The image_size of the first input is {input.image_size}, \"\n            f\"while the image_size of the second input is {other.image_size}.\\n{"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances) and isinstance(other, Instances), (\n        f\"{msg}The input and output to this function must be of type Instances. \"\n        f\"Got input of type {type(input)} and output of type {type(other)}\"\n    )\n\n    if size_as_tensor:\n        assert input.image_size == other.image_size, (\n            f\"{msg}The image_size of the input and output must be the same. \"\n            f\"Got {input.image_size} and {other.image_size} instead.\"\n        )\n    else:\n        assert input.image_size == other.image_size, (\n            f\"{msg}The image_size of the input and output must be the same. \"\n            f\"Got {input.image_size} and {other.image_size} instead.\"\n        )\n\n    for field_name in input._metadata.get(\"fields\"):\n        if isinstance(input.__dict__[field_name], Boxes):\n            assert isinstance(other.__dict__[field_name], Boxes), (\n                f\"{msg}The field {field_name} of the input and output must be of type Boxes.\"\n            )\n            assert torch.allclose(\n                input.__dict__[field_name].tensor, other.__dict__[field_name].tensor, rtol=rtol\n            ), f\"{msg}The field {field_name} of the input and output must be close!\"\n        elif isinstance(input.__dict__[field_name], ROIMasks):\n            assert isinstance(other.__dict__[field_name], ROIMasks), (\n                f\"{msg}The field {field_name} of the input and output must be of type ROIMasks.\"\n            )\n            assert torch.allclose(\n                input.__dict__[field_name].tensor, other.__dict__[field_name].tensor, rtol=rtol\n            ), f\"{msg}The field {field_name} of the input and output must be close!\"\n        elif isinstance(input.__"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(input, Instances) or not isinstance(other, Instances):\n        raise ValueError(\"input and other must be of type Instances!\")\n    if not isinstance(rtol, float):\n        raise ValueError(\"rtol must be a float!\")\n    if not isinstance(msg, str):\n        raise ValueError(\"msg must be a string!\")\n\n    if not isinstance(size_as_tensor, bool):\n        raise ValueError(\"size_as_tensor must be a bool!\")\n\n    if size_as_tensor:\n        assert (\n            input.image_size == other.image_size\n        ), f\"image_size of {input} is {input.image_size}, while that of {other} is {other.image_size}!\"\n    else:\n        assert (\n            input.image_size == other.image_size\n        ), f\"image_size of {input} is {input.image_size}, while that of {other} is {other.image_size}!\"\n\n    for name in input._field_names:\n        if not hasattr(other, name):\n            raise AssertionError(f\"{other} does not have the field {name}!\")\n        if isinstance(getattr(input, name), Boxes):\n            assert (\n                getattr(input, name) == getattr(other, name)\n            ), f\"{name} of {input} is {getattr(input, name)}, while that of {other} is {getattr(other, name)}!\"\n        elif isinstance(getattr(input, name), ROIMasks):\n            assert (\n                getattr(input, name).to_bitmasks() == getattr(other, name).to_bitmasks()\n            ), f\"{name} of {input} is {getattr(input, name)}, while that of {other} is {getattr(other, name)}!\"\n        elif isinstance(getattr(input, name), torch.Tensor):\n            assert torch.allclose(\n                getattr(input, name), getattr(other, name), rtol=rtol\n            ), f"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(input, type(other)):\n        raise AssertionError(f\"Type mismatch: {type(input)} vs {type(other)}!\")\n\n    if not isinstance(input, Instances):\n        raise ValueError(f\"Expected type {Instances}! Got {type(input)}.\")\n\n    if size_as_tensor:\n        assert_equal(input.image_size, other.image_size, msg=msg + \"image_size\")\n    else:\n        assert_equal(\n            input.image_size,\n            other.image_size,\n            msg=msg + \"image_size\",\n            atol=0,\n            rtol=0,\n            equal_nan=True,\n        )\n\n    for name in input._fields:\n        if name == \"proposal_boxes\":\n            assert_equal(input.proposal_boxes.tensor, other.proposal_boxes.tensor, msg=msg + \"proposal_boxes\")\n        elif name == \"objectness_logits\":\n            assert_equal(input.objectness_logits, other.objectness_logits, msg=msg + \"objectness_logits\")\n        elif name == \"gt_boxes\":\n            assert_equal(input.gt_boxes.tensor, other.gt_boxes.tensor, msg=msg + \"gt_boxes\")\n        elif name == \"pred_boxes\":\n            assert_equal(input.pred_boxes.tensor, other.pred_boxes.tensor, msg=msg + \"pred_boxes\")\n        elif name == \"pred_masks\":\n            assert_equal(input.pred_masks.tensor, other.pred_masks.tensor, msg=msg + \"pred_masks\")\n        elif name == \"gt_masks\":\n            assert_equal(input.gt_masks.tensor, other.gt_masks.tensor, msg=msg + \"gt_masks\")\n        elif name == \"scores\":\n            assert_equal(input.scores, other.scores, msg=msg + \"scores\")\n        elif name =="}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(input, Instances) or not isinstance(other, Instances):\n        raise ValueError(f\"Expected two Instances objects, but got {type(input)} and {type(other)}.\")\n\n    if not isinstance(input.image_size, tuple) or not isinstance(other.image_size, tuple):\n        raise ValueError(f\"Expected image_size to be a tuple, but got {type(input.image_size)} and {type(other.image_size)}.\")\n\n    if size_as_tensor:\n        if not isinstance(input.image_size, torch.Tensor) or not isinstance(other.image_size, torch.Tensor):\n            raise ValueError(f\"Expected image_size to be a tensor, but got {type(input.image_size)} and {type(other.image_size)}.\")\n\n    if not size_as_tensor:\n        assert (\n            input.image_size == other.image_size\n        ), f\"Expected image_size to be {input.image_size}, but got {other.image_size}.\"\n    else:\n        assert torch.all(input.image_size == other.image_size), (\n            f\"Expected image_size to be {input.image_size}, but got {other.image_size}.\"\n        )\n\n    for name in input._field_names:\n        assert hasattr(input, name) and hasattr(other, name), (\n            f\"{name} is a field in one of the Instances but not the other!\"\n        )\n\n    for name in input._field_names:\n        first_val = getattr(input, name)\n        second_val = getattr(other, name)\n\n        if isinstance(first_val, Boxes) and isinstance(second_val, Boxes):\n            assert torch.allclose(first_val.tensor, second_val.tensor, rtol=rtol), (\n                f\"Expected {name} to be close to {second_val.tensor}, but got {first_val.tensor}.\"\n            )"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(input, Instances) or not isinstance(other, Instances):\n        raise ValueError(\"Both input and other need to be of type Instances!\")\n\n    if not size_as_tensor:\n        assert (\n            input.image_size == other.image_size\n        ), f\"image_size {input.image_size} (input) != {other.image_size} (other)\"\n    else:\n        assert torch.equal(input.image_size, other.image_size), f\"image_size {input.image_size} (input) != {other.image_size} (other)\"\n\n    for name in input._field_names:\n        val1 = getattr(input, name)\n        val2 = getattr(other, name)\n        if isinstance(val1, Boxes) and isinstance(val2, Boxes):\n            assert torch.allclose(val1.tensor, val2.tensor), f\"{name} tensor: {val1.tensor} != {val2.tensor}\"\n        elif isinstance(val1, ROIMasks) and isinstance(val2, ROIMasks):\n            assert torch.equal(val1.tensor, val2.tensor), f\"{name} tensor: {val1.tensor} != {val2.tensor}\"\n        elif isinstance(val1, torch.Tensor) and isinstance(val2, torch.Tensor):\n            assert torch.allclose(val1, val2, rtol=rtol), f\"{name}: {val1} != {val2}\"\n        elif isinstance(val1, list) and isinstance(val2, list):\n            assert len(val1) == len(val2), f\"length of {name}: {val1} != {val2}\"\n            for i, (x, y) in enumerate(zip(val1, val2)):\n                if isinstance(x, torch.Tensor) and isinstance(y, torch.Tensor):\n                    assert torch.allclose(x, y, rtol=rtol), f\"{i}th {name}:"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(input, type(other)):\n        raise AssertionError(\n            f\"The two objects to be compared have different types: {type(input)} and {type(other)}.\"\n        )\n\n    if not isinstance(input, Instances):\n        raise ValueError(\n            f\"This function can only compare instances of type Instances. The provided instances have type {type(input)}.\"\n        )\n\n    if not isinstance(input, type(other)):\n        raise AssertionError(\n            f\"The two objects to be compared have different types: {type(input)} and {type(other)}.\"\n        )\n\n    if not isinstance(input, Instances):\n        raise ValueError(\n            f\"This function can only compare instances of type Instances. The provided instances have type {type(input)}.\"\n        )\n\n    if len(input) != len(other):\n        raise AssertionError(\n            f\"The two objects to be compared have different lengths: {len(input)} and {len(other)}.\"\n        )\n\n    if len(input) == 0:\n        return\n\n    if not size_as_tensor and not isinstance(input.image_size, tuple):\n        raise AssertionError(\n            f\"The two objects to be compared have different image_sizes: {input.image_size} and {other.image_size}.\"\n        )\n\n    if size_as_tensor and not isinstance(input.image_size, torch.Tensor):\n        raise AssertionError(\n            f\"The two objects to be compared have different image_sizes: {input.image_size} and {other.image_size}.\"\n        )\n\n    if size_as_tensor and not torch.all(torch.eq(input.image_size, other.image_size)):\n        raise AssertionError(\n            f\"The two objects to be compared have different image_sizes: {input.image_size} and {other.image_size}.\"\n        )\n\n    if not size_as_tensor and not input.image_size == other.image_size:\n        raise Assertion"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(input, Instances) or not isinstance(other, Instances):\n        raise ValueError(\"input and other should be of type Instances!\")\n\n    if input.image_size != other.image_size:\n        if size_as_tensor:\n            assert torch.equal(\n                torch.tensor(input.image_size), torch.tensor(other.image_size)\n            ), f\"{msg}image_size should be the same!\\nInput: {input.image_size}\\nOther: {other.image_size}\"\n        else:\n            assert input.image_size == other.image_size, f\"{msg}image_size should be the same!\\nInput: {input.image_size}\\nOther: {other.image_size}\"\n\n    for name in input._metadata.get(\"fields\", []):\n        if not hasattr(input, name) or not hasattr(other, name):\n            continue\n\n        val1, val2 = getattr(input, name), getattr(other, name)\n        if isinstance(val1, Boxes) and isinstance(val2, Boxes):\n            assert torch.allclose(val1.tensor, val2.tensor, atol=1e-5), f\"{msg}{name} is not close!\"\n        elif isinstance(val1, ROIMasks) and isinstance(val2, ROIMasks):\n            # ROIMasks does not have a tensor field, so we compare masks and boxes directly\n            assert torch.allclose(val1.masks, val2.masks, atol=1e-5), f\"{msg}{name} is not close!\"\n            assert torch.allclose(val1.boxes.tensor, val2.boxes.tensor, atol=1e-5), f\"{msg}{name} is not close!\"\n        elif isinstance(val1, torch.Tensor) and isinstance(val2, torch.Tensor):\n            assert torch.allclose(val1, val2, atol=1e-5), f\"{msg}{name} is not close"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    # Check that the image_sizes match\n    if size_as_tensor:\n        assert torch.equal(input.image_size, other.image_size), \\\n            f\"{msg} Image sizes do not match: {input.image_size} vs. {other.image_size}\"\n    else:\n        assert input.image_size == other.image_size, f\"{msg} Image sizes do not match: {input.image_size} vs. {other.image_size}\"\n\n    # Check that the fields match\n    for field_name in input._metadata.get(\"fields\", []):\n        assert hasattr(input, field_name) and hasattr(other, field_name), f\"{msg} missing field {field_name}\"\n        if isinstance(getattr(input, field_name), Boxes):\n            assert torch.allclose(getattr(input, field_name).tensor, getattr(other, field_name).tensor, rtol=rtol), \\\n                f\"{msg} Boxes field {field_name} does not match!\"\n        elif isinstance(getattr(input, field_name), ROIMasks):\n            assert torch.allclose(getattr(input, field_name).tensor, getattr(other, field_name).tensor, rtol=rtol), \\\n                f\"{msg} ROIMasks field {field_name} does not match!\"\n        elif isinstance(getattr(input, field_name), torch.Tensor):\n            assert torch.allclose(getattr(input, field_name), getattr(other, field_name), rtol=rtol), \\\n                f\"{msg} Tensor field {field_name} does not match!\"\n        elif isinstance(getattr(input, field_name), int):\n            assert getattr(input, field_name) == getattr(other, field_name), \\\n                f\"{msg} int field {field_name} does not match!\"\n        elif isinstance(getattr(input, field_name), float):\n            assert np.isclose(getattr(input, field_name), getattr("}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    # Check that the image sizes are equal\n    if size_as_tensor:\n        assert torch.equal(input.image_size, other.image_size)\n    else:\n        assert input.image_size == other.image_size\n\n    # Check that all fields are equal\n    for field_name in input._metadata.get(\"fields\", []):\n        if isinstance(input.__dict__[field_name], Boxes):\n            assert torch.equal(\n                input.__dict__[field_name].tensor, other.__dict__[field_name].tensor\n            ), f\"{msg} Box field {field_name} are not the same!\"\n        elif isinstance(input.__dict__[field_name], ROIMasks):\n            assert torch.equal(\n                input.__dict__[field_name].tensor, other.__dict__[field_name].tensor\n            ), f\"{msg} ROIMask field {field_name} are not the same!\"\n        elif isinstance(input.__dict__[field_name], torch.Tensor):\n            assert torch.allclose(\n                input.__dict__[field_name], other.__dict__[field_name], rtol=rtol\n            ), f\"{msg} Tensor field {field_name} are not the same!\"\n        elif isinstance(input.__dict__[field_name], int):\n            assert input.__dict__[field_name] == other.__dict__[field_name], f\"{msg} Field {field_name} is not the same!\"\n        elif isinstance(input.__dict__[field_name], (list, tuple)):\n            assert input.__dict__[field_name] == other.__dict__[field_name], f\"{msg} Field {field_name} is not the same!\"\n        else:\n            raise ValueError(f\"Unknown field type {type(input.__dict__[field_name])} for field {field_name}!\")\n\n"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    # Check that the image_size is the same\n    if size_as_tensor:\n        assert_allclose(input.image_size, other.image_size, msg=msg)\n    else:\n        assert input.image_size == other.image_size, msg\n\n    # Check that all fields are the same\n    for name in input._field_names:\n        assert hasattr(other, name), f\"{msg} ({name}) does not exist in both instances!\"\n\n    # Check that all fields are equal or close\n    for name in input._field_names:\n        assert hasattr(other, name), f\"{msg} ({name}) does not exist in both instances!\"\n        if isinstance(getattr(input, name), Boxes):\n            assert_allclose(getattr(input, name).tensor, getattr(other, name).tensor, msg=msg)\n        elif isinstance(getattr(input, name), ROIMasks):\n            assert_allclose(getattr(input, name).tensor, getattr(other, name).tensor, msg=msg)\n        elif isinstance(getattr(input, name), torch.Tensor):\n            assert_allclose(getattr(input, name), getattr(other, name), rtol=rtol, msg=msg)\n        elif isinstance(getattr(input, name), int):\n            assert getattr(input, name) == getattr(other, name), msg\n        elif isinstance(getattr(input, name), float):\n            assert np.isclose(getattr(input, name), getattr(other, name)), msg\n        else:\n            raise ValueError(f\"Unknown field type: {type(getattr(input, name))}\")\n\n"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(input, Instances) or not isinstance(other, Instances):\n        raise ValueError(\"'input' and 'other' must be Instances objects\")\n\n    if not size_as_tensor and isinstance(input.image_size, torch.Tensor):\n        input.image_size = tuple(input.image_size.tolist())\n\n    if not size_as_tensor and isinstance(other.image_size, torch.Tensor):\n        other.image_size = tuple(other.image_size.tolist())\n\n    if input.image_size != other.image_size:\n        raise AssertionError(\n            f\"Image sizes do not match: {input.image_size} vs {other.image_size}.\"\n        )\n\n    for name in input._metadata.get(\"fields\", []):\n        if getattr(input, name) is None and getattr(other, name) is None:\n            continue\n        if getattr(input, name) is None:\n            raise AssertionError(f\"Field '{name}' is None in 'input' but not in 'other'\")\n        if getattr(other, name) is None:\n            raise AssertionError(f\"Field '{name}' is None in 'other' but not in 'input'\")\n\n        if type(getattr(input, name)) != type(getattr(other, name)):\n            raise AssertionError(\n                f\"Field '{name}' of type {type(getattr(input, name))} does not match type {type(getattr(other, name))}.\"\n            )\n\n        if isinstance(getattr(input, name), torch.Tensor):\n            if not torch.allclose(getattr(input, name), getattr(other, name), rtol=rtol):\n                raise AssertionError(\n                    f\"Field '{name}' does not match. Max diff: {float((getattr(input, name) - getattr(other, name)).abs().max()):.5f}\"\n                )\n        elif isinstance(getattr(input, name), Boxes) or isinstance(\n            get"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    # check that the image sizes are equal\n    if size_as_tensor:\n        assert torch.equal(input.image_size, other.image_size), msg + f\"Different image sizes: {input.image_size} vs. {other.image_size}\"\n    else:\n        assert input.image_size == other.image_size, msg + f\"Different image sizes: {input.image_size} vs. {other.image_size}\"\n\n    # check that all fields are equal or close\n    fields = set(input._fields.keys())\n    other_fields = set(other._fields.keys())\n    if fields != other_fields:\n        raise AssertionError(\n            msg + f\"Different fields: {fields.symmetric_difference(other_fields)}\"\n        )\n    for name in fields:\n        # handle Boxes, ROIMasks, and torch.Tensor fields\n        if isinstance(input._fields[name], (Boxes, ROIMasks, torch.Tensor)):\n            assert torch.allclose(\n                getattr(input, name), getattr(other, name), rtol=rtol, atol=1e-5\n            ), msg + f\"Different '{name}': {getattr(input, name)} vs. {getattr(other, name)}\"\n        # handle other fields\n        else:\n            assert getattr(input, name) == getattr(other, name), msg + f\"Different '{name}': {getattr(input, name)} vs. {getattr(other, name)}\""}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(input, Instances) or not isinstance(other, Instances):\n        raise AssertionError(\"The inputs must be torch.class.Instances objects.\")\n\n    if not size_as_tensor:\n        assert (\n            input.image_size == other.image_size\n        ), f\"The image_sizes of the two instances mismatch: {input.image_size} != {other.image_size} !\"\n    else:\n        assert (\n            (input.image_size[0] == other.image_size[0]) and (input.image_size[1] == other.image_size[1])\n        ), f\"The image_sizes of the two instances mismatch: {input.image_size} != {other.image_size} !\"\n\n    for name in input._fields:\n        self_val = getattr(input, name)\n        other_val = getattr(other, name)\n\n        if isinstance(self_val, Boxes) and isinstance(other_val, Boxes):\n            assert torch.allclose(self_val.tensor, other_val.tensor, rtol=rtol), \\\n                f\"The values of the two {name} Boxes mismatch!\"\n        elif isinstance(self_val, ROIMasks) and isinstance(other_val, ROIMasks):\n            assert torch.allclose(self_val.tensor, other_val.tensor, rtol=rtol), \\\n                f\"The values of the two {name} ROIMasks mismatch!\"\n        elif isinstance(self_val, torch.Tensor) and isinstance(other_val, torch.Tensor):\n            assert torch.allclose(self_val, other_val, rtol=rtol), \\\n                f\"The values of the two {name} tensors mismatch!\"\n        elif isinstance(self_val, int) and isinstance(other_val, int):\n            assert self_val == other_val, f\"The values of the two {name} ints mismatch!\"\n        elif isinstance(self_val, float) and isinstance(other_val,"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(input, type(other)):\n        raise AssertionError(f\"Type mismatch: {type(input)} vs {type(other)}\")\n    if not isinstance(input, Instances):\n        raise ValueError(f\"Argument input must be of type Instances. Got {type(input)}\")\n\n    if size_as_tensor:\n        assert_equal(\n            input.image_size, other.image_size, msg=msg + f\"image_size mismatch: {input.image_size} vs {other.image_size}\"\n        )\n    else:\n        assert_equal(\n            input.image_size,\n            other.image_size,\n            msg=msg + f\"image_size mismatch: {input.image_size} vs {other.image_size}\"\n        )\n\n    for a, b in zip(input.get_fields(), other.get_fields()):\n        assert a == b, f\"{msg} Field name mismatch: {a} vs {b}\"\n\n    for field_name in input.get_fields():\n        a = getattr(input, field_name)\n        b = getattr(other, field_name)\n        if isinstance(a, Boxes):\n            assert isinstance(b, Boxes), f\"{msg} Type mismatch for {field_name}: {type(a)} vs {type(b)}\"\n            assert len(a) == len(b), msg + f\"Length mismatch for {field_name}: {len(a)} vs {len(b)}\"\n            assert torch.allclose(a.tensor, b.tensor, rtol=rtol), msg + f\"Tensor mismatch for {field_name}.\"\n            assert torch.allclose(a.tensor, b.tensor, rtol=rtol), msg + f\"Tensor mismatch for {field_name}.\"\n        elif isinstance(a, ROIMasks):\n            assert isinstance(b, ROIMasks), f\"{msg} Type mismatch for {field_name}: {type(a)} vs {type(b)}\"\n            assert len(a) == len(b), msg + f\"Length"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(input, type(other)):\n        raise AssertionError(f\"Expected type {type(input)}, but got {type(other)}\")\n\n    if not isinstance(input, Instances):\n        raise ValueError(f\"Expected input type {Instances}, but got {type(other)}\")\n\n    if not isinstance(other, Instances):\n        raise ValueError(f\"Expected input type {Instances}, but got {type(other)}\")\n\n    if size_as_tensor:\n        assert (\n            torch.equal(torch.tensor(input.image_size), torch.tensor(other.image_size))\n        ), f\"{msg} image_size do not match: {input.image_size} vs. {other.image_size}\"\n    else:\n        assert (\n            input.image_size == other.image_size\n        ), f\"{msg} image_size do not match: {input.image_size} vs. {other.image_size}\"\n\n    input_fields = set(input.get_fields().keys())\n    other_fields = set(other.get_fields().keys())\n    assert (\n        input_fields == other_fields\n    ), f\"{msg} Fields do not match: {input_fields} vs. {other_fields}\"\n\n    for name in input_fields:\n        lhs = getattr(input, name)\n        rhs = getattr(other, name)\n\n        if isinstance(lhs, Boxes) and isinstance(rhs, Boxes):\n            assert torch.allclose(lhs.tensor, rhs.tensor, atol=1e-5), f\"{msg} boxes.tensor do not match: {lhs} vs. {rhs}\"\n            continue\n\n        if isinstance(lhs, ROIMasks) and isinstance(rhs, ROIMasks):\n            assert torch.equal(lhs.tensor, rhs.tensor), f\"{msg} roimasks.tensor do not match: {lhs} vs. {rhs}\"\n            continue\n\n        if isinstance(lhs,"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(input, Instances) or not isinstance(other, Instances):\n        raise ValueError(\"input and other should be of type Instances!\")\n\n    if not isinstance(input.image_size, (tuple, torch.Tensor)) or not isinstance(\n        other.image_size, (tuple, torch.Tensor)\n    ):\n        raise ValueError(\"image_size should be of type tuple or torch.Tensor!\")\n\n    if isinstance(input.image_size, tuple) and isinstance(other.image_size, tuple):\n        assert (\n            input.image_size == other.image_size\n        ), f\"image_size {input.image_size} != {other.image_size} !\"\n    else:\n        if size_as_tensor:\n            assert torch.equal(\n                input.image_size, other.image_size\n            ), f\"image_size {input.image_size} != {other.image_size}!\"\n        else:\n            assert (\n                input.image_size == other.image_size\n            ), f\"image_size {input.image_size} != {other.image_size} !\"\n\n    for name in input._fields:\n        if name == \"proposal_boxes\":\n            assert hasattr(input, \"proposal_boxes\") and hasattr(\n                other, \"proposal_boxes\"\n            ), f\"{name} is a property of Instances, but it does not exist in input {input} or output {other}!\"\n            assert torch.allclose(\n                input.proposal_boxes.tensor, other.proposal_boxes.tensor, rtol=rtol\n            ), f\"{name} are not close!\"\n        elif name == \"objectness_logits\":\n            assert hasattr(input, \"objectness_logits\") and hasattr(\n                other, \"objectness_logits\"\n            ), f\"{name} is a property of Instances, but it does not exist in input {input} or output {other}!\"\n            assert torch.allclose("}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(input, Instances) or not isinstance(other, Instances):\n        raise ValueError(\"Inputs need to be torch.class.Instances objects!\")\n\n    if not size_as_tensor:\n        assert (\n            input.image_size == other.image_size\n        ), \"The image_size of the inputs do not match!\"\n    else:\n        assert torch.equal(\n            torch.tensor(input.image_size), torch.tensor(other.image_size)\n        ), \"The image_size of the inputs do not match!\"\n\n    for key in input._metadata.keys():\n        if key != \"image_size\":\n            assert (\n                key in other._metadata.keys()\n            ), f\"The field {key} is not in the second input!\"\n\n    for field in input._field_names:\n        assert hasattr(\n            other, field\n        ), f\"The field {field} is not in the second input!\"\n\n        if isinstance(input._data[field], Boxes) or isinstance(\n            input._data[field], ROIMasks\n        ):\n            assert isinstance(other._data[field], Boxes) or isinstance(\n                other._data[field], ROIMasks\n            ), f\"The field {field} is not of type Boxes or ROIMasks in the second input!\"\n            assert torch.allclose(\n                input._data[field].tensor, other._data[field].tensor, rtol=rtol\n            ), f\"The field {field} does not match!\"\n        elif isinstance(input._data[field], torch.Tensor):\n            assert isinstance(other._data[field], torch.Tensor), f\"The field {field} is not of type torch.Tensor in the second input!\"\n            assert torch.allclose(\n                input._data[field], other._data[field], rtol=rtol\n            ), f\"The field {field} does not match!\"\n        else:\n            raise ValueError(\n                f\"Unknown field type {type(input._data[field])} for field {field}"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(input, Instances) or not isinstance(other, Instances):\n        raise ValueError(f\"Expected two instances, but got {type(input)} and {type(other)}\")\n\n    if not isinstance(input.image_size, (tuple, torch.Tensor)) or not isinstance(\n        other.image_size, (tuple, torch.Tensor)\n    ):\n        raise ValueError(\n            f\"Expected two tuples or tensors for image_size, but got {type(input.image_size)} and {type(other.image_size)}\"\n        )\n\n    if size_as_tensor:\n        assert torch.all(torch.as_tensor(input.image_size) == torch.as_tensor(other.image_size)), (\n            f\"{msg}image_size does not match: \" f\"{input.image_size} != {other.image_size}\"\n        )\n    else:\n        assert input.image_size == other.image_size, (\n            f\"{msg}image_size does not match: \" f\"{input.image_size} != {other.image_size}\"\n        )\n\n    input_fields = set(input._metadata.get(\"fields\", []))\n    other_fields = set(other._metadata.get(\"fields\", []))\n\n    # handle fields that are present in only one instance but not in the other\n    err_msg_fmt = \"{} field is present in one instance but not in the other\"\n    for name in input_fields.symmetric_difference(other_fields):\n        raise AssertionError(err_msg_fmt.format(name))\n\n    # handle fields that are present in both instances\n    for name in input_fields.intersection(other_fields):\n        # special handling for fields that are expected to match exactly\n        if name in (\"image_size\",):\n            continue\n        self_val = getattr(input, name)\n        other_val = getattr(other, name)\n        if isinstance(self_val, Boxes) and isinstance(other_val, Boxes):"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box = self.tensor\n        area = box[:, 2] * box[:, 3]\n\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box = self.tensor\n        area = box[:, 2] * box[:, 3]\n\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box = self.tensor\n        area = box[:, 2] * box[:, 3]\n\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box = self.tensor\n        area = box[:, 2] * box[:, 3]\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box = self.tensor\n        area = box[:, 2] * box[:, 3]\n\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box = self.tensor\n        area = box[:, 2] * box[:, 3]\n\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box = self.tensor\n        area = box[:, 2] * box[:, 3]\n\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box = self.tensor\n        area = box[:, 2] * box[:, 3]\n\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box = self.tensor\n        area = box[:, 2] * box[:, 3]\n\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box = self.tensor\n        area = box[:, 2] * box[:, 3]\n\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box = self.tensor\n        area = box[:, 2] * box[:, 3]\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box = self.tensor\n        area = box[:, 2] * box[:, 3]\n\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box = self.tensor\n        area = box[:, 2] * box[:, 3]\n\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box = self.tensor\n        area = box[:, 2] * box[:, 3]\n\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box = self.tensor\n        area = box[:, 2] * box[:, 3]\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box = self.tensor\n        area = box[:, 2] * box[:, 3]\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box = self.tensor\n        area = box[:, 2] * box[:, 3]\n\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box = self.tensor\n        area = box[:, 2] * box[:, 3]\n\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box = self.tensor\n        area = box[:, 2] * box[:, 3]\n\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box = self.tensor\n        area = box[:, 2] * box[:, 3]\n\n        return area\n"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    if cfg.MODEL.PROPOSAL_GENERATOR.NAME == \"PrecomputedProposals\":\n        return None\n    else:\n        proposal_generator = PROPOSAL_GENERATOR_REGISTRY.get(cfg.MODEL.PROPOSAL_GENERATOR.NAME)(cfg, input_shape)\n        return proposal_generator"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    if cfg.MODEL.PROPOSAL_GENERATOR.NAME == \"PrecomputedProposals\":\n        return None\n    else:\n        proposal_generator = PROPOSAL_GENERATOR_REGISTRY.get(cfg.MODEL.PROPOSAL_GENERATOR.NAME)(cfg, input_shape)\n        return proposal_generator"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    if cfg.MODEL.PROPOSAL_GENERATOR.NAME == \"PrecomputedProposals\":\n        return None\n    proposal_generator = PROPOSAL_GENERATOR_REGISTRY.get(cfg.MODEL.PROPOSAL_GENERATOR.NAME)(cfg, input_shape)\n    return proposal_generator"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    if cfg.PROPOSAL_GENERATOR.NAME == \"PrecomputedProposals\":\n        return None\n    else:\n        proposal_generator = PROPOSAL_GENERATOR_REGISTRY.get(cfg.PROPOSAL_GENERATOR.NAME)(cfg, input_shape)\n        return proposal_generator"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    if cfg.MODEL.PROPOSAL_GENERATOR.NAME == \"PrecomputedProposals\":\n        return None\n    proposal_generator = PROPOSAL_GENERATOR_REGISTRY.get(cfg.MODEL.PROPOSAL_GENERATOR.NAME)(cfg, input_shape)\n    return proposal_generator"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    if cfg.PROPOSAL_GENERATOR.NAME == \"PrecomputedProposals\":\n        return None\n    proposal_generator = PROPOSAL_GENERATOR_REGISTRY.get(cfg.PROPOSAL_GENERATOR.NAME)(cfg, input_shape)\n    return proposal_generator"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    if cfg.MODEL.PROPOSAL_GENERATOR.NAME == \"PrecomputedProposals\":\n        return None\n    else:\n        proposal_generator = PROPOSAL_GENERATOR_REGISTRY.get(cfg.MODEL.PROPOSAL_GENERATOR.NAME)(cfg, input_shape)\n        return proposal_generator"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    if cfg.PROPOSAL_GENERATOR.NAME == \"PrecomputedProposals\":\n        return None\n    proposal_generator = PROPOSAL_GENERATOR_REGISTRY.get(cfg.PROPOSAL_GENERATOR.NAME)(cfg, input_shape)\n    return proposal_generator"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    if cfg.PROPOSAL_GENERATOR.NAME == \"PrecomputedProposals\":\n        return None\n    proposal_generator = PROPOSAL_GENERATOR_REGISTRY.get(cfg.PROPOSAL_GENERATOR.NAME)(cfg, input_shape)\n    return proposal_generator"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    if cfg.MODEL.PROPOSAL_GENERATOR.NAME == \"PrecomputedProposals\":\n        return None\n\n    proposal_generator = PROPOSAL_GENERATOR_REGISTRY.get(cfg.MODEL.PROPOSAL_GENERATOR.NAME)(cfg, input_shape)\n\n    return proposal_generator"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    proposal_generator_name = cfg.MODEL.PROPOSAL_HEAD.PROPOSAL_GENERATOR.NAME\n    if proposal_generator_name == \"PrecomputedProposals\":\n        return None\n    proposal_generator = PROPOSAL_GENERATOR_REGISTRY.get(proposal_generator_name)(cfg, input_shape)\n    return proposal_generator"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_HEAD.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    else:\n        proposal_generator = PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)\n        return proposal_generator"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    proposal_generator_name = cfg.MODEL.PROPOSAL_HEAD.PROPOSAL_GENERATOR.NAME\n\n    if proposal_generator_name == \"PrecomputedProposals\":\n        return None\n\n    proposal_generator = PROPOSAL_GENERATOR_REGISTRY.get(proposal_generator_name)(cfg, input_shape)\n\n    return proposal_generator"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    proposal_generator_name = cfg.MODEL.PROPOSAL_HEAD.PROPOSAL_GENERATOR\n    if proposal_generator_name == \"PrecomputedProposals\":\n        return None\n    proposal_generator = PROPOSAL_GENERATOR_REGISTRY.get(proposal_generator_name)(cfg, input_shape)\n    return proposal_generator"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_HEAD.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    else:\n        return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    proposal_generator_name = cfg.MODEL.PROPOSAL_HEAD.NAME\n    if proposal_generator_name == \"PrecomputedProposals\":\n        return None\n    proposal_generator = PROPOSAL_GENERATOR_REGISTRY.get(proposal_generator_name)(cfg, input_shape)\n    return proposal_generator"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_HEAD.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    else:\n        return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_HEAD.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    proposal_generator = PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)\n    return proposal_generator"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    proposal_generator_name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if proposal_generator_name == \"PrecomputedProposals\":\n        return None\n    proposal_generator = PROPOSAL_GENERATOR_REGISTRY.get(proposal_generator_name)(cfg, input_shape)\n    return proposal_generator"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    if cfg.MODEL.PROPOSAL_GENERATOR.NAME == \"PrecomputedProposals\":\n        return None\n\n    proposal_generator = PROPOSAL_GENERATOR_REGISTRY.get(cfg.MODEL.PROPOSAL_GENERATOR.NAME)(cfg, input_shape)\n    return proposal_generator"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        losses = FastRCNNOutputs(\n            self.box2box_transform,\n            scores,\n            proposal_deltas,\n            proposals,\n            self.smooth_l1_beta,\n            self.box_reg_loss_type,\n        ).losses()\n        return {k: v * self.loss_weight.get(k, 1.0) for k, v in losses.items()}"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        losses = FastRCNNOutputs(\n            self.box2box_transform,\n            scores,\n            proposal_deltas,\n            proposals,\n            self.smooth_l1_beta,\n            self.box_reg_loss_type,\n        ).losses()\n        return {k: v * self.loss_weight.get(k, 1.0) for k, v in losses.items()}"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        losses = FastRCNNOutputs(\n            self.box2box_transform,\n            scores,\n            proposal_deltas,\n            proposals,\n            self.smooth_l1_beta,\n            self.box_reg_loss_type,\n        ).losses()\n        return {k: v * self.loss_weight.get(k, 1.0) for k, v in losses.items()}"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        losses = FastRCNNOutputs(\n            self.box2box_transform,\n            scores,\n            proposal_deltas,\n            proposals,\n            self.smooth_l1_beta,\n            self.box_reg_loss_type,\n        ).losses()\n        return {k: v * self.loss_weight.get(k, 1.0) for k, v in losses.items()}\n\n\n\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        losses = FastRCNNOutputs(\n            self.box2box_transform,\n            scores,\n            proposal_deltas,\n            proposals,\n            self.smooth_l1_beta,\n            self.box_reg_loss_type,\n        ).losses()\n        return {k: v * self.loss_weight.get(k, 1.0) for k, v in losses.items()}\n\n\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        losses = FastRCNNOutputs(\n            self.box2box_transform,\n            scores,\n            proposal_deltas,\n            proposals,\n            self.smooth_l1_beta,\n            self.box_reg_loss_type,\n        ).losses()\n        return {k: v * self.loss_weight.get(k, 1.0) for k, v in losses.items()}\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        losses = FastRCNNOutputs(\n            self.box2box_transform,\n            scores,\n            proposal_deltas,\n            proposals,\n            self.smooth_l1_beta,\n            self.box_reg_loss_type,\n        ).losses()\n        return {k: v * self.loss_weight.get(k, 1.0) for k, v in losses.items()}\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        losses = FastRCNNOutputs(\n            self.box2box_transform,\n            scores,\n            proposal_deltas,\n            proposals,\n            self.smooth_l1_beta,\n            self.box_reg_loss_type,\n        ).losses()\n        return {k: v * self.loss_weight.get(k, 1.0) for k, v in losses.items()}\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        losses = FastRCNNOutputs(\n            self.box2box_transform,\n            scores,\n            proposal_deltas,\n            proposals,\n            self.smooth_l1_beta,\n            self.box_reg_loss_type,\n        ).losses()\n        return {k: v * self.loss_weight.get(k, 1.0) for k, v in losses.items()}\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        losses = FastRCNNOutputs(\n            self.box2box_transform,\n            scores,\n            proposal_deltas,\n            proposals,\n            self.smooth_l1_beta,\n            self.box_reg_loss_type,\n        ).losses()\n        losses.update(\n            {k: v * self.loss_weight.get(k, 1.0) for k, v in losses.items()}\n        )\n        return losses\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        losses = FastRCNNOutputs(\n            self.box2box_transform,\n            scores,\n            proposal_deltas,\n            proposals,\n            self.smooth_l1_beta,\n            self.box_reg_loss_type,\n        ).losses()\n        losses.update(\n            {k: v * self.loss_weight.get(k, 1.0) for k, v in losses.items()}\n        )\n        return losses\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        losses = FastRCNNOutputs(\n            self.box2box_transform,\n            scores,\n            proposal_deltas,\n            proposals,\n            self.smooth_l1_beta,\n            self.box_reg_loss_type,\n        ).losses()\n        return {k: v * self.loss_weight.get(k, 1.0) for k, v in losses.items()}\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n\n        # parse classification outputs\n        gt_classes = (\n            cat([p.gt_classes for p in proposals], dim=0) if len(proposals) else torch.empty(0)\n        )\n        _log_classification_stats(scores, gt_classes)\n\n        # parse box regression outputs\n        num_prop_per_image = [len(p) for p in proposals]\n        if len(proposals):\n            proposal_boxes = cat([p.proposal_boxes.tensor for p in proposals], dim=0)  # Nx4\n            assert not proposal_boxes.requires_grad, \"Proposals should not require gradients!\"\n            gt_boxes = cat(\n                [(p.gt_boxes if p.has(\"gt_boxes\") else p.proposal_boxes).tensor for p in proposals],\n                dim=0,\n            )\n        else:\n            proposal_boxes = gt_boxes = torch.empty((0, 4), device=proposal_deltas.device)\n\n        loss_cls = self.loss_cls(scores, gt_classes, num_prop_per_image)\n\n        losses = {\n            \"loss_cls\": loss_cls,\n            \"loss_box_reg\": self.loss_box_reg(\n                proposal_boxes, gt_boxes, proposal_deltas, num_prop_per_image\n            ),\n        }\n        return {k: v * self.loss_weight.get(k, 1.0) for k, v in losses.items()}\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        losses = FastRCNNOutputs(\n            self.box2box_transform,\n            scores,\n            proposal_deltas,\n            proposals,\n            self.smooth_l1_beta,\n            self.box_reg_loss_type,\n        ).losses()\n        return {k: v * self.loss_weight.get(k, 1.0) for k, v in losses.items()}\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        losses = FastRCNNOutputs(\n            self.box2box_transform,\n            scores,\n            proposal_deltas,\n            proposals,\n            self.smooth_l1_beta,\n            self.box_reg_loss_type,\n        ).losses()\n        return {k: v * self.loss_weight.get(k, 1.0) for k, v in losses.items()}\n\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        losses = FastRCNNOutputs(\n            self.box2box_transform,\n            scores,\n            proposal_deltas,\n            proposals,\n            self.smooth_l1_beta,\n            self.box_reg_loss_type,\n        ).losses()\n        return {k: v * self.loss_weight.get(k, 1.0) for k, v in losses.items()}\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        losses = FastRCNNOutputs(\n            self.box2box_transform,\n            scores,\n            proposal_deltas,\n            proposals,\n            self.smooth_l1_beta,\n            self.box_reg_loss_type,\n        ).losses()\n        return {k: v * self.loss_weight.get(k, 1.0) for k, v in losses.items()}\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        losses = FastRCNNOutputs(\n            self.box2box_transform,\n            scores,\n            proposal_deltas,\n            proposals,\n            self.smooth_l1_beta,\n            self.box_reg_loss_type,\n        ).losses()\n        return {k: v * self.loss_weight.get(k, 1.0) for k, v in losses.items()}\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        losses = FastRCNNOutputs(\n            self.box2box_transform,\n            scores,\n            proposal_deltas,\n            proposals,\n            self.smooth_l1_beta,\n            self.box_reg_loss_type,\n        ).losses()\n        return {k: v * self.loss_weight.get(k, 1.0) for k, v in losses.items()}\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n\n        # parse classification outputs\n        gt_classes = (\n            cat([p.gt_classes for p in proposals], dim=0) if len(proposals) else torch.empty(0)\n        )\n        _log_classification_stats(scores, gt_classes)\n\n        # parse box regression outputs\n        num_prop_per_image = [len(p) for p in proposals]\n        proposal_boxes = cat([p.proposal_boxes.tensor for p in proposals], dim=0)  # Nx4\n        gt_boxes = cat(\n            [(p.gt_boxes if p.has(\"gt_boxes\") else p.proposal_boxes).tensor for p in proposals],\n            dim=0,\n        )\n\n        if len(proposals):\n            proposal_boxes = proposal_boxes[:, :4]\n            gt_boxes = gt_boxes[:, :4]\n\n            # Box delta loss is normalized by the number of proposals (by default)\n            normalizer = get_norm(self.box_reg_loss_type, gt_boxes, proposal_boxes, num_prop_per_image)\n            if self.box_reg_loss_type == \"giou\":\n                loss_box_reg = at.giou_loss(\n                    proposal_boxes,\n                    gt_boxes,\n                    gt_classes,\n                    normalizer=normalizer,\n                )\n            else:\n                loss_box_reg = at.l1_loss(\n                    self.box2box_transform.get_deltas(proposal_boxes, gt_boxes),\n                    gt_classes,\n                    normalizer=normalizer,\n                )\n        else:\n            loss_box_reg = proposal_boxes.sum() * 0\n\n        # The loss is normalized using the total number of regions (R), not the number\n        # of foreground (+ background) regions even though the box regression loss is"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.TRACKER_NAME\n    tracker = TRACKER_HEADS_REGISTRY.get(tracker_name)\n    tracker = tracker(cfg)\n    return tracker"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.TRACKER_NAME\n    tracker = TRACKER_HEADS_REGISTRY.get(tracker_name)\n    tracker = tracker(cfg)\n    return tracker"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.TRACKER_HEADS.NAME\n    tracker_head = TRACKER_HEADS_REGISTRY.get(name)(cfg)\n    return tracker_head"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.TRACKER_HEADS.NAME\n    tracker_head = TRACKER_HEADS_REGISTRY.get(name)(cfg)\n    return tracker_head"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.TRACKER_NAME\n    tracker = TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)\n    return tracker"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.TRACKER_NAME\n    tracker = TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)\n    return tracker"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.TRACKER_HEADS.NAME\n    tracker_head = TRACKER_HEADS_REGISTRY.get(name)(cfg)\n    return tracker_head"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.TRACKER_HEADS.NAME\n    tracker = TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)\n    return tracker"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.TRACKER_HEADS.NAME\n    tracker = TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)\n    return tracker"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.TRACKER_NAME\n    tracker = TRACKER_HEADS_REGISTRY.get(tracker_name)\n    tracker = tracker(cfg)\n    return tracker"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.TRACKER_HEAD.NAME\n    tracker_head = TRACKER_HEADS_REGISTRY.get(name)(cfg)\n    return tracker_head"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.TRACKER_NAME\n    tracker = TRACKER_HEADS_REGISTRY.get(name)\n    return tracker(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.TRACKER_HEADS.NAME\n    tracker = TRACKER_HEADS_REGISTRY.get(name)(cfg)\n    return tracker"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.TRACKER_HEADS.NAME\n    tracker_class = TRACKER_HEADS_REGISTRY.get(name)\n    tracker = tracker_class.from_config(cfg)\n    return tracker"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.TRACKER_HEADS.NAME\n    tracker = TRACKER_HEADS_REGISTRY.get(name)(cfg)\n    return tracker\n\n"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.TRACKER_NAME\n    tracker_class = TRACKER_HEADS_REGISTRY.get(name)\n    tracker = tracker_class(cfg)\n    return tracker\n\n"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.TRACKER_HEAD.NAME\n    tracker_head = TRACKER_HEADS_REGISTRY.get(name)\n    tracker_head = tracker_head(cfg)\n    return tracker_head\n\n"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.TRACKER_NAME\n    tracker_head = TRACKER_HEADS_REGISTRY.get(name)(cfg)\n    return tracker_head\n\n"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.TRACKER_NAME\n    tracker = TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)\n    return tracker\n\n"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.TRACKER_NAME\n    tracker = TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)\n    return tracker\n\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        \"\"\"\n        Apply transformation `deltas` (dx, dy, dw, dh) to `boxes`.\n\n        Args:\n            deltas (Tensor): transformation deltas of shape (N, k*4), where k >= 1.\n                deltas[i] represents k potentially different class-specific\n                box transformations for the single box boxes[i].\n            boxes (Tensor): boxes to transform, of shape (N, 4)\n        \"\"\"\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        \"\"\"\n        Apply transformation `deltas` (dx, dy, dw, dh) to `boxes`.\n\n        Args:\n            deltas (Tensor): transformation deltas of shape (N, k*4), where k >= 1.\n                deltas[i] represents k potentially different class-specific\n                box transformations for the single box boxes[i].\n            boxes (Tensor): boxes to transform, of shape (N, 4)\n        \"\"\"\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        \"\"\"\n        Apply transformation `deltas` (dx, dy, dw, dh) to `boxes`.\n\n        Args:\n            deltas (Tensor): transformation deltas of shape (N, k*4), where k >= 1.\n                deltas[i] represents k potentially different class-specific\n                box transformations for the single box boxes[i].\n            boxes (Tensor): boxes to transform, of shape (N, 4)\n        \"\"\"\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        \"\"\"\n        Apply transformation `deltas` (dx, dy, dw, dh) to `boxes`.\n\n        Args:\n            deltas (Tensor): transformation deltas of shape (N, k*4), where k >= 1.\n                deltas[i] represents k potentially different class-specific\n                box transformations for the single box boxes[i].\n            boxes (Tensor): boxes to transform, of shape (N, 4)\n        \"\"\"\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4]"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        \"\"\"\n        Apply transformation `deltas` (dx, dy, dw, dh) to `boxes`.\n\n        Args:\n            deltas (Tensor): transformation deltas of shape (N, k*4), where k >= 1.\n                deltas[i] represents k potentially different class-specific\n                box transformations for the single box boxes[i].\n            boxes (Tensor): boxes to transform, of shape (N, 4)\n        \"\"\"\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4]"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        \"\"\"\n        Apply transformation `deltas` (dx, dy, dw, dh) to `boxes`.\n\n        Args:\n            deltas (Tensor): transformation deltas of shape (N, k*4), where k >= 1.\n                deltas[i] represents k potentially different class-specific\n                box transformations for the single box boxes[i].\n            boxes (Tensor): boxes to transform, of shape (N, 4)\n        \"\"\"\n        assert torch.isfinite(deltas).all().item(), \"Box regression deltas become infinite or NaN!\"\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        \"\"\"\n        Apply transformation `deltas` (dx, dy, dw, dh) to `boxes`.\n\n        Args:\n            deltas (Tensor): transformation deltas of shape (N, k*4), where k >= 1.\n                deltas[i] represents k potentially different class-specific\n                box transformations for the single box boxes[i].\n            boxes (Tensor): boxes to transform, of shape (N, 4)\n        \"\"\"\n        assert torch.isfinite(deltas).all().item(), \"Box regression deltas become infinite or NaN!\"\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        \"\"\"\n        Apply transformation `deltas` (dx, dy, dw, dh) to `boxes`.\n\n        Args:\n            deltas (Tensor): transformation deltas of shape (N, k*4), where k >= 1.\n                deltas[i] represents k potentially different class-specific\n                box transformations for the single box boxes[i].\n            boxes (Tensor): boxes to transform, of shape (N, 4)\n        \"\"\"\n        assert torch.isfinite(deltas).all().item(), \"Box regression deltas become infinite or NaN!\"\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        \"\"\"\n        Args:\n            deltas (Tensor): deltas to apply\n            boxes (Tensor): boxes to transform\n        \"\"\"\n        assert torch.isfinite(deltas).all().item(), \"Box regression deltas become infinite or NaN!\"\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        \"\"\"\n        Args:\n            deltas (Tensor): deltas to apply\n            boxes (Tensor): boxes to transform\n        \"\"\"\n        assert torch.isfinite(deltas).all().item(), \"Box regression deltas become infinite or NaN!\"\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        \"\"\"\n        Args:\n            deltas (Tensor): deltas to apply\n            boxes (Tensor): boxes to transform\n        \"\"\"\n        # boxes = boxes.to(deltas.dtype)\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w  # x2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        \"\"\"\n        Apply transformation `deltas` (dx, dy, dw, dh) to `boxes`.\n\n        Args:\n            deltas (Tensor): transformation deltas of shape (N, k*4), where k >= 1.\n                deltas[i] represents k potentially different class-specific\n                box transformations for the single box boxes[i].\n            boxes (Tensor): boxes to transform, of shape (N, 4)\n        \"\"\"\n        # boxes = boxes.to(deltas.dtype)\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        \"\"\"\n        Applies bounding-box regression deltas to boxes.\n\n        Args:\n            deltas (Tensor): bounding-box regression deltas (dx, dy, dw, dh) of\n                shape (N, k*4), where N is the number of boxes to be transformed.\n            boxes (Tensor): boxes to apply deltas to, of shape (N, 4)\n        \"\"\"\n        assert torch.isfinite(deltas).all().item(), \"Box regression deltas become infinite or NaN!\"\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        \"\"\"\n        Args:\n            deltas (Tensor): encoded offsets with respect to each roi, has shape\n                (N, 4 * num_classes). Note N = num rois, num_classes = 80 in Faster-RCNN\n            boxes (Tensor): reference boxes, has shape (N, 4).\n        \"\"\"\n        assert isinstance(deltas, torch.Tensor), type(deltas)\n        assert isinstance(boxes, torch.Tensor), type(boxes)\n\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        \"\"\"\n        Apply transformation `deltas` (dx, dy, dw, dh) to `boxes`.\n\n        Args:\n            deltas (Tensor): transformation deltas of shape (N, k*4), where k >= 1.\n                deltas[i] represents k potentially different class-specific\n                box transformations for the single box boxes[i].\n            boxes (Tensor): boxes to transform, of shape (N, 4)\n        \"\"\"\n        # boxes = boxes.to(deltas.dtype)\n        #\n        # widths = boxes[:, 2] - boxes[:, 0]\n        # heights = boxes[:, 3] - boxes[:, 1]\n        # ctr_x = boxes[:, 0] + 0.5 * widths\n        # ctr_y = boxes[:, 1] + 0.5 * heights\n        #\n        # wx, wy, ww, wh = self.weights\n        # dx = deltas[:, 0::4] / wx\n        # dy = deltas[:, 1::4] / wy\n        # dw = deltas[:, 2::4] / ww\n        # dh = deltas[:, 3::4] / wh\n        #\n        # # Prevent sending too large values into torch.exp()\n        # dx_width = dx * widths[..., None]\n        # dy_height = dy * heights[..., None]\n        # dw_width = dw * widths[..., None]\n        # dh_height = dh * heights[..., None]\n        #\n        # if self.scale_clamp > 0:\n        #     dw_width = torch.clamp(dw_width, max=self.scale_clamp)\n        #     dh_height = torch.clamp(dh_height, max=self.scale_clamp)\n        #\n        # pred_ctr_x = ctr_x[..., None] + dx_width\n        # pred_ctr_y = ctr_y[..., None] + dy_height\n       "}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        \"\"\"\n        Args:\n            deltas (Tensor): encoded offsets with respect to each roi, has shape\n                (N, 4 * num_classes). Note N = num rois, num_classes = num object classes\n                (k in the paper)\n            boxes (Tensor): reference boxes, has shape (N, 4)\n        \"\"\"\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:,"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        \"\"\"\n        Applies bounding-box regression deltas to boxes.\n\n        The outpus is the same as the input boxes. See the details of each argument:\n          boxes: (N, 4) ndarray of float\n          deltas: (N, 4) ndarray of float\n          cfg: configuration parameters\n\n        :return:\n        \"\"\"\n        assert isinstance(boxes, torch.Tensor), type(boxes)\n        assert isinstance(deltas, torch.Tensor), type(deltas)\n\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dx = torch.clamp(dx, max=self.scale_clamp, min=-self.scale_clamp)\n        dy = torch.clamp(dy, max=self.scale_clamp, min=-self.scale_clamp)\n        dw = torch.clamp(dw, max=self.scale_clamp, min=-self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp, min=-self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w ="}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        \"\"\"\n        Applies bounding-box regression deltas to boxes.\n\n        The outpu is the same as the input boxes.\n\n        Args:\n            deltas (Tensor): Nx4 or Nx(kx4) shaped tensor. The deltas are the predicted\n                transformations for each bounding box.\n            boxes (Tensor): Nx4 or Nx(kx4) shaped tensor, the same shape as the deltas.\n                The boxes are the original bounding boxes before applying the deltas.\n        Returns:\n            Tensor: Same shape as the input boxes.\n        \"\"\"\n        assert torch.isfinite(deltas).all().item(), \"Box regression deltas become infinite or NaN!\"\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dx_width = dx * widths[..., None]\n        dy_height = dy * heights[..., None]\n        if self.scale_clamp > 0:\n            dw = torch.clamp(dw, max=self.scale_clamp)\n            dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[..., None] + ctr_x[..., None]\n        pred_ctr_y = dy * heights[..., None] + ctr_y[..., None]"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        \"\"\"\n        Args:\n            deltas (Tensor): encoded offsets with respect to each roi, has shape\n                (N, 4 * num_classes).  The (encoded) offsets should have already\n                been through clamping.\n            boxes (Tensor): roi boxes.\n        \"\"\"\n        deltas = deltas.float() # Ensure the data type of the deltas is torch.float32\n        boxes = boxes.to(deltas.dtype) # Make sure that the data type of the boxes is the same as that of the deltas\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n       "}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        \"\"\"\n        Args:\n            deltas (Tensor): encoded offsets with respect to each roi, has shape\n                (N, 4 * num_classes). Note N = num rois, num_classes = num_fg_classes + 1\n            boxes (Tensor): reference boxes, has shape (batch_size, N, 4)\n        \"\"\"\n        assert deltas.shape[1] % 4 == 0 and deltas.shape[1] / 4 >= 1\n        boxes_per_image = deltas.shape[1] // 4\n\n        # Convert to Boxes to use the `box_cxcywh_to_xyxy` function\n        target_boxes = torch.zeros_like(deltas)\n        target_boxes = Boxes(target_boxes)\n        target_boxes[:, 2:] += boxes\n        target_boxes[:, :2] += deltas[:, :2]\n\n        if boxes_per_image > 1:\n            target_boxes = target_boxes.view(deltas.shape[0], -1, 4)\n\n        # Apply box decoding\n        target_boxes = target_boxes.tensor\n        target_boxes[:, :, 2:] = torch.exp(target_boxes[:, :, 2:]) * target_boxes[:, :, :2]\n        target_boxes[:, :, 0::2] = target_boxes[:, :, 0::2] * target_boxes[:, :, 2:] + target_boxes[:, :, 2:]\n        target_boxes[:, :, 1::2] = target_boxes[:, :, 1::2] * target_boxes[:, :, 3:] + target_boxes[:, :, 3:]\n\n        if boxes_per_image > 1:\n            target_boxes = target_boxes.view(deltas.shape[0], -1, 4)\n\n        return target_boxes\n\n"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            return self.general_ins(image)\n        elif isinstance(anno_type, str):\n            return self.general_ins(image)[anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            return {tp: self.general_ins(image)[tp] for tp in anno_type}\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            return self.general_ins(image)\n        elif isinstance(anno_type, str):\n            return self.general_ins(image)[anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            return {\n                tp: self.general_ins(image)[tp]\n                for tp in anno_type if tp in self.general_ins(image)\n            }\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            return self.general_ins(image)\n        else:\n            output = self.general_ins(image)\n            if isinstance(anno_type, str):\n                return output[anno_type]\n            elif isinstance(anno_type, (list, tuple)):\n                return {tp: output[tp] for tp in anno_type}\n            else:\n                raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            return self.general_ins(image)\n\n        if isinstance(anno_type, str):\n            anno_type = [anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')\n\n        output = self.general_ins(image)\n        if len(anno_type) == 1:\n            return output[anno_type[0]]\n        else:\n            return {tp: output[tp] for tp in anno_type}"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            return self.general_ins(image)\n        elif isinstance(anno_type, str):\n            output = self.general_ins(image)\n            return output[anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            output = self.general_ins(image)\n            return {tp: output[tp] for tp in anno_type}\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            return self.general_ins(image)\n        if isinstance(anno_type, str):\n            anno_type = [anno_type]\n        assert isinstance(anno_type, (list, tuple))\n        result = self.general_ins(image)\n        output = {}\n        for tp in anno_type:\n            if tp in result.keys():\n                output[tp] = result[tp]\n        return output"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            return self.general_ins(image)\n\n        if isinstance(anno_type, str):\n            anno_type = [anno_type]\n        assert isinstance(anno_type, (list, tuple))\n\n        out = self.general_ins(image)\n\n        if len(anno_type) == 1:\n            return out[anno_type[0]]\n\n        return {tp: out[tp] for tp in anno_type}"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            return self.general_ins(image)\n        else:\n            output = self.general_ins(image)\n            if isinstance(anno_type, str):\n                anno_type = [anno_type]\n            anno_type = set(anno_type)\n            if anno_type.issubset(output.keys()):\n                return {tp: output[tp] for tp in anno_type}\n            else:\n                raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        image = image.astype(np.float32)\n        image /= 255.0\n        image = image.transpose(2, 0, 1)\n        image = np.expand_dims(image, axis=0)\n        image = np.ascontiguousarray(image)\n        image = torch.from_numpy(image).float().to(we.device_id)\n\n        with torch.no_grad():\n            output = self.general_ins(image)\n\n        output = {\n            k: v.detach().cpu().numpy()\n            for k, v in output.items()\n        }\n\n        if anno_type is None:\n            return output\n        elif isinstance(anno_type, str):\n            return output[anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            return {tp: output[tp] for tp in anno_type}\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        input_dict = {'img': image}\n        output_dict = self.general_ins(input_dict)\n\n        if anno_type is None:\n            return output_dict\n\n        if isinstance(anno_type, str):\n            anno_type = [anno_type]\n        assert isinstance(anno_type, (list, tuple))\n\n        return {tp: output_dict[tp] for tp in anno_type if tp in output_dict}\n\n"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            return self.general_ins(image)\n        elif isinstance(anno_type, str):\n            output = self.general_ins(image)\n            return output[anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            output = self.general_ins(image)\n            return {tp: output[tp] for tp in anno_type}\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')\n\n"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, (512, 512))\n        image = image.astype(np.float32) / 255.0\n        image = np.transpose(image, (2, 0, 1))\n        image = np.expand_dims(image, axis=0)\n        image = np.ascontiguousarray(image)\n        image = torch.from_numpy(image)\n\n        with torch.no_grad():\n            output = self.general_ins.forward(image)\n\n        output = {k: v.cpu().numpy() for k, v in output.items()}\n\n        if anno_type is None:\n            return output\n\n        if isinstance(anno_type, str):\n            anno_type = [anno_type]\n\n        output = {k: v for k, v in output.items() if k in anno_type}\n\n        return output"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        assert anno_type is None or isinstance(anno_type, (str, list, tuple))\n        if isinstance(anno_type, str):\n            anno_type = [anno_type]\n        if anno_type is None:\n            anno_type = list(self.anno_type_map.keys())\n\n        output = self.general_ins(image)\n        if isinstance(output, dict):\n            if len(output) == 1:\n                return list(output.values())[0]\n            else:\n                return {k: v for k, v in output.items() if k in anno_type}\n        else:\n            return output"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        image = image.astype(np.uint8)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = np.transpose(image, (2, 0, 1))\n        image = np.expand_dims(image, 0)\n        image = image.astype(np.float32)\n        image = image / 255.0\n        image = image.copy()\n        image = np.ascontiguousarray(image)\n        image = torch.from_numpy(image).to(we.device_id)\n        output = self.general_ins(image)\n        output = {k: v.detach().cpu().numpy() for k, v in output.items()}\n        if anno_type is not None:\n            if isinstance(anno_type, str):\n                if anno_type in output:\n                    output = output[anno_type]\n                else:\n                    output = None\n            elif isinstance(anno_type, (list, tuple)):\n                output = {k: v for k, v in output.items() if k in anno_type}\n            else:\n                raise Exception(f'Error anno_type: {anno_type}')\n        return output"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            anno_type = self.anno_type_map.keys()\n\n        if isinstance(anno_type, str):\n            anno_type = [anno_type]\n\n        # Process the image with the annotator.\n        outputs = self.general_ins(image)\n\n        # Filter the output by the specified anno_type(s).\n        if isinstance(anno_type, (list, tuple)):\n            output = {\n                k: v\n                for k, v in outputs.items() if k in anno_type\n            }\n        else:\n            output = outputs[anno_type]\n\n        return output"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is not None:\n            if isinstance(anno_type, str):\n                anno_type = [anno_type]\n            assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n\n        # image = cv2.imread(image_path)\n        # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = image.astype(np.float32)\n        image /= 255.0\n        image = np.transpose(image, (2, 0, 1))\n        image = np.expand_dims(image, axis=0)\n        image = torch.from_numpy(image).cuda()\n\n        output = self.general_ins(image)\n        output = output.cpu().numpy()\n        output = np.squeeze(output, axis=0)\n        output = np.transpose(output, (1, 2, 0))\n        output = output * 255.0\n        output = output.astype(np.uint8)\n\n        if anno_type is None:\n            return output\n        else:\n            if isinstance(anno_type, str):\n                return output[self.anno_type_map[anno_type]['OUTPUT_KEYS'][0]]\n            else:\n                anno_dict = {}\n                for tp in anno_type:\n                    anno_dict[tp] = output[self.anno_type_map[tp]['OUTPUT_KEYS'][0]]\n                return anno_dict"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            return self.general_ins(image)\n        else:\n            if isinstance(anno_type, str):\n                anno_type = [anno_type]\n            assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n            out = self.general_ins(image)\n            return {tp: out[tp] for tp in anno_type}\n\n"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        # Resize image to be divisible by 64\n        image, k = resize_image(image, 64)\n\n        # Run general annotator\n        output = self.general_ins(image)\n\n        # Resize image back to original size\n        output = {key: resize_image_ori(image.shape[0], image.shape[1], value, k) for key, value in output.items()}\n\n        # Return only the requested annotation types\n        if anno_type is not None:\n            if isinstance(anno_type, str):\n                anno_type = [anno_type]\n            output = {key: value for key, value in output.items() if key in anno_type}\n\n        return output\n\n"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            anno_type = self.general_ins.anno_type\n        elif isinstance(anno_type, str):\n            anno_type = [anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')\n\n        anno_type = set(anno_type)\n\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = image.astype(np.float32) / 255.0\n        image = np.transpose(image, (2, 0, 1))\n        image = np.expand_dims(image, 0)\n        image = image.copy()\n        image = torch.from_numpy(image).to(we.device_id)\n\n        with torch.no_grad():\n            output = self.general_ins(image)\n\n        output = {\n            key: value.cpu().numpy()\n            for key, value in output.items()\n        }\n\n        if len(anno_type) == 1:\n            return output[anno_type.pop()]\n        else:\n            return {tp: output[tp] for tp in anno_type}\n\n"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is not None:\n            if isinstance(anno_type, str):\n                anno_type = [anno_type]\n            assert isinstance(anno_type, (list, tuple))\n\n        # process the image\n        output = self.general_ins(image)\n\n        # if no specific annotation type is requested, return the entire output\n        if anno_type is None:\n            return output\n\n        # if a specific annotation type is requested, return only that annotation\n        # if multiple annotation types are requested, return a dictionary of those annotation types found in the output\n        output_dict = {}\n        for tp in anno_type:\n            if tp in output.keys():\n                output_dict[tp] = output[tp]\n        return output_dict\n\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split(\" \")\n        result = {}\n        for keyword in keywords:\n            result = update_url_scores(result, self.bm25(keyword))\n        return result\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        result = {}\n        for keyword in keywords:\n            result = update_url_scores(result, self.bm25(keyword))\n        return result\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        score_dict = {}\n        for keyword in keywords:\n            score_dict = update_url_scores(score_dict, self.bm25(keyword))\n        return score_dict\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        scores = defaultdict(float)\n        for keyword in keywords:\n            scores = update_url_scores(scores, self.bm25(keyword))\n        return dict(scores)\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        result = defaultdict(float)\n        for kw in keywords:\n            result = update_url_scores(result, self.bm25(kw))\n        return result\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        result = {}\n        for kw in keywords:\n            result = update_url_scores(result, self.bm25(kw))\n        return result\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        # Normalize the query string and split it into keywords\n        query = normalize_string(query)\n        keywords = query.split()\n\n        # Initialize the result dictionary\n        result = {}\n\n        # Iterate over keywords and update the result dictionary\n        for keyword in keywords:\n            result = update_url_scores(result, self.bm25(keyword))\n\n        return result\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        result = {}\n        for kw in keywords:\n            result = update_url_scores(result, self.bm25(kw))\n        return result\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        # Normalize the query\n        normalized_query = normalize_string(query)\n        # Split the query into keywords\n        keywords = normalized_query.split()\n        # Initialize the result dictionary\n        result = {}\n        # Loop through each keyword and update the result dictionary\n        for kw in keywords:\n            result = update_url_scores(result, self.bm25(kw))\n        return result\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        # Normalize the query string and split into keywords.\n        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n\n        # Calculate the BM25 score for each keyword across URLs.\n        scores = defaultdict(float)\n        for kw in keywords:\n            scores = update_url_scores(scores, self.bm25(kw))\n\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        result = {}\n        for kw in keywords:\n            result = update_url_scores(result, self.bm25(kw))\n        return result\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        scores = {}\n        for keyword in keywords:\n            scores = update_url_scores(scores, self.bm25(keyword))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        result = {}\n        for kw in keywords:\n            result = update_url_scores(result, self.bm25(kw))\n        return result\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        # Normalize the query\n        normalized_query = normalize_string(query)\n        # Split the query into keywords\n        keywords = normalized_query.split(\" \")\n        # Initialize the result dictionary\n        result = {}\n        # Iterate over keywords\n        for keyword in keywords:\n            # Get the BM25 score for each keyword\n            keyword_scores = self.bm25(keyword)\n            # Update the result dictionary\n            result = update_url_scores(result, keyword_scores)\n        return result\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        # Normalize the query\n        normalized_query = normalize_string(query)\n\n        # Split the query into keywords\n        keywords = normalized_query.split(\" \")\n\n        # Initialize the result dictionary\n        result = {}\n\n        # For each keyword, get the BM25 scores for all URLs\n        for keyword in keywords:\n            result = update_url_scores(result, self.bm25(keyword))\n\n        return result\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        # Normalize the query string\n        normalized_query = normalize_string(query)\n\n        # Split the query string into keywords\n        keywords = normalized_query.split()\n\n        # Initialize the result dictionary\n        result = {}\n\n        # Iterate over keywords\n        for keyword in keywords:\n            # Calculate the BM25 score for each keyword\n            bm25_score = self.bm25(keyword)\n\n            # Update the result dictionary\n            result = update_url_scores(result, bm25_score)\n\n        return result\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        result = {}\n        for keyword in keywords:\n            result = update_url_scores(result, self.bm25(keyword))\n        return result\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        # Normalize the query and split it into keywords\n        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n\n        # Initialize the score dictionary\n        score = defaultdict(float)\n\n        # Iterate over keywords and calculate BM25 score for each\n        for kw in keywords:\n            kw_scores = self.bm25(kw)\n            score = update_url_scores(score, kw_scores)\n\n        return score\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        scores = defaultdict(float)\n        for keyword in keywords:\n            scores = update_url_scores(scores, self.bm25(keyword))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        # Normalize the query\n        query = normalize_string(query)\n\n        # Split the query into keywords\n        keywords = query.split()\n\n        # Initialize the result dictionary\n        result = defaultdict(float)\n\n        # Iterate over the keywords\n        for kw in keywords:\n            # Get the BM25 score for the keyword\n            scores = self.bm25(kw)\n            # Aggregate the scores in the result dictionary\n            result = update_url_scores(result, scores)\n\n        # Return the result dictionary\n        return result\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        h, w = box_size\n        self.normalize_angles()\n        idx = torch.abs(self.tensor[:, 4]) <= clip_angle_threshold\n        if not idx.any():\n            return\n        ct_x, ct_y, w, h, a = self.tensor[idx, 0], self.tensor[idx, 1], self.tensor[idx, 2], self.tensor[idx, 3], self.tensor[idx, 4]\n        x1 = ct_x - w / 2.0\n        y1 = ct_y - h / 2.0\n        x2 = ct_x + w / 2.0\n        y2 = ct_y + h / 2.0\n        self.tensor[idx, 0] = x1\n        self.tensor[idx, 1] = y1\n        self.tensor[idx, 2] = x2\n        self.tensor[idx, 3] = y2\n        self.tensor[idx, 0].clamp_(min=0, max=w)\n        self.tensor[idx, 1].clamp_(min=0, max=h)\n        self.tensor[idx, 2].clamp_(min=0, max=w)\n        self.tensor[idx, 3].clamp_(min=0, max=h)\n        self.tensor[idx, 0] = (self.tensor[idx, 0] + self.tensor[idx, 2]) / 2.0\n        self.tensor[idx, 1] = (self.tensor[idx, 1] + self.tensor[idx, 3]) / 2.0\n        self.tensor[idx, 2] = self.tensor[idx, 2] - self.tensor[idx, 0]\n        self.tensor[idx, 3] = self.tensor[idx, 3] - self.tensor[idx, 1]\n        self.tensor[idx, 4] = a\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        h, w = box_size\n\n        # Step 1: Normalize angles to be within (-180, 180] degrees\n        self.normalize_angles()\n\n        # Step 2: Identify nearly-horizontal boxes based on clip_angle_threshold\n        inds_to_clip = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n\n        # Step 3: Convert boxes to (x1, y1, x2, y2) format for clipping\n        x1 = self.tensor[inds_to_clip, 0] - self.tensor[inds_to_clip, 2] / 2.0\n        y1 = self.tensor[inds_to_clip, 1] - self.tensor[inds_to_clip, 3] / 2.0\n        x2 = self.tensor[inds_to_clip, 0] + self.tensor[inds_to_clip, 2] / 2.0\n        y2 = self.tensor[inds_to_clip, 1] + self.tensor[inds_to_clip, 3] / 2.0\n\n        # Step 4: Clip coordinates to be within the specified box_size limits\n        x1.clamp_(min=0, max=w)\n        y1.clamp_(min=0, max=h)\n        x2.clamp_(min=0, max=w)\n        y2.clamp_(min=0, max=h)\n\n        # Step 5: Convert back to original format to avoid numerical issues\n        self.tensor[inds_to_clip, 0] = (x1 + x2) / 2.0\n        self.tensor[inds_to_clip, 1] = (y1 + y2) / 2.0\n        self.tensor[inds_to_clip, 2] = x2 - x1\n        self.tensor[inds_to_clip, 3] = y2 - y1\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        h, w = box_size\n\n        # Normalize angles to be within (-180, 180] degrees\n        self.normalize_angles()\n\n        # Identify nearly-horizontal boxes\n        idx = torch.abs(self.tensor[:, 4]) <= clip_angle_threshold\n\n        # Convert boxes to (x1, y1, x2, y2) format for easier clipping\n        x1 = self.tensor[idx, 0] - self.tensor[idx, 2] / 2.0\n        y1 = self.tensor[idx, 1] - self.tensor[idx, 3] / 2.0\n        x2 = self.tensor[idx, 0] + self.tensor[idx, 2] / 2.0\n        y2 = self.tensor[idx, 1] + self.tensor[idx, 3] / 2.0\n\n        # Clip coordinates to be within the specified box size\n        x1.clamp_(min=0, max=w)\n        y1.clamp_(min=0, max=h)\n        x2.clamp_(min=0, max=w)\n        y2.clamp_(min=0, max=h)\n\n        # Convert back to original format to avoid numerical errors\n        self.tensor[idx, 0] = (x1 + x2) / 2.0\n        self.tensor[idx, 1] = (y1 + y2) / 2.0\n        self.tensor[idx, 2] = x2 - x1\n        self.tensor[idx, 3] = y2 - y1\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        h, w = box_size\n\n        # Normalize angles to be within (-180, 180] degrees\n        self.normalize_angles()\n\n        # Identify nearly-horizontal boxes based on angle threshold\n        idx = torch.abs(self.tensor[:, 4]) <= clip_angle_threshold\n\n        # Convert boxes to (x1, y1, x2, y2) format for easier clipping\n        x1 = self.tensor[idx, 0] - self.tensor[idx, 2] / 2.0\n        y1 = self.tensor[idx, 1] - self.tensor[idx, 3] / 2.0\n        x2 = self.tensor[idx, 0] + self.tensor[idx, 2] / 2.0\n        y2 = self.tensor[idx, 1] + self.tensor[idx, 3] / 2.0\n\n        # Clip coordinates to be within the specified box size\n        x1.clamp_(min=0, max=w)\n        y1.clamp_(min=0, max=h)\n        x2.clamp_(min=0, max=w)\n        y2.clamp_(min=0, max=h)\n\n        # Convert back to original format to avoid numerical errors\n        self.tensor[idx, 0] = (x1 + x2) / 2.0\n        self.tensor[idx, 1] = (y1 + y2) / 2.0\n        self.tensor[idx, 2] = x2 - x1\n        self.tensor[idx, 3] = y2 - y1\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        h, w = box_size\n\n        # Step 1: Normalize angles to be within (-180, 180] degrees.\n        self.normalize_angles()\n\n        # Step 2: Identify nearly-horizontal boxes based on the clip_angle_threshold.\n        idx = torch.abs(self.tensor[:, 4]) <= clip_angle_threshold\n\n        # Step 3: Convert boxes to (x1, y1, x2, y2) format for easier clipping.\n        x1 = self.tensor[idx, 0] - self.tensor[idx, 2] / 2.0\n        y1 = self.tensor[idx, 1] - self.tensor[idx, 3] / 2.0\n        x2 = self.tensor[idx, 0] + self.tensor[idx, 2] / 2.0\n        y2 = self.tensor[idx, 1] + self.tensor[idx, 3] / 2.0\n\n        # Step 4: Clip to ensure all boxes fit within the specified box_size limits.\n        x1.clamp_(min=0, max=w)\n        y1.clamp_(min=0, max=h)\n        x2.clamp_(min=0, max=w)\n        y2.clamp_(min=0, max=h)\n\n        # Step 5: Convert back to original format to avoid numerical issues.\n        self.tensor[idx, 0] = (x1 + x2) / 2.0\n        self.tensor[idx, 1] = (y1 + y2) / 2.0\n        self.tensor[idx, 2] = x2 - x1\n        self.tensor[idx, 3] = y2 - y1\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        h, w = box_size\n        self.normalize_angles()\n        idx = torch.where(torch.abs(self.tensor[:, 4]) <= clip_angle_threshold)[0]\n        if len(idx) == 0:\n            return\n        x1, y1, x2, y2 = self.tensor[idx, 0], self.tensor[idx, 1], self.tensor[idx, 0]+self.tensor[idx, 2], self.tensor[idx, 1]+self.tensor[idx, 3]\n        x1.clamp_(min=0, max=w)\n        y1.clamp_(min=0, max=h)\n        x2.clamp_(min=0, max=w)\n        y2.clamp_(min=0, max=h)\n        self.tensor[idx, 0], self.tensor[idx, 1] = (x1+x2)/2, (y1+y2)/2\n        self.tensor[idx, 2], self.tensor[idx, 3] = x2-x1, y2-y1\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        # Normalize angles to be within (-180, 180] degrees.\n        self.normalize_angles()\n\n        # Identify indices of boxes that are nearly horizontal (<= 1.0 degrees)\n        idx = torch.abs(self.tensor[:, 4]) <= clip_angle_threshold\n\n        # Convert boxes to (x1, y1, x2, y2) format for easier clipping\n        x1 = self.tensor[idx, 0] - self.tensor[idx, 2] / 2.0\n        y1 = self.tensor[idx, 1] - self.tensor[idx, 3] / 2.0\n        x2 = self.tensor[idx, 0] + self.tensor[idx, 2] / 2.0\n        y2 = self.tensor[idx, 1] + self.tensor[idx, 3] / 2.0\n\n        # Clip coordinates to be within the specified box_size limits\n        height, width = box_size\n        x1.clamp_(min=0, max=width)\n        y1.clamp_(min=0, max=height)\n        x2.clamp_(min=0, max=width)\n        y2.clamp_(min=0, max=height)\n\n        # Convert back to original format to avoid numerical errors\n        self.tensor[idx, 0] = (x1 + x2) / 2.0\n        self.tensor[idx, 1] = (y1 + y2) / 2.0\n        self.tensor[idx, 2] = x2 - x1\n        self.tensor[idx, 3] = y2 - y1\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        h, w = box_size\n\n        # Normalize angles to be within (-180, 180] degrees\n        self.normalize_angles()\n\n        # Identify nearly-horizontal boxes\n        idx = torch.abs(self.tensor[:, 4]) <= clip_angle_threshold\n\n        # Convert the representation of the rotated boxes from (center x, center y, width, height, angle) to (x1, y1, x2, y2)\n        x1 = self.tensor[idx, 0] - self.tensor[idx, 2] / 2.0\n        y1 = self.tensor[idx, 1] - self.tensor[idx, 3] / 2.0\n        x2 = self.tensor[idx, 0] + self.tensor[idx, 2] / 2.0\n        y2 = self.tensor[idx, 1] + self.tensor[idx, 3] / 2.0\n\n        # Clip the values to lie within the given box_size limits\n        x1.clamp_(min=0, max=w)\n        y1.clamp_(min=0, max=h)\n        x2.clamp_(min=0, max=w)\n        y2.clamp_(min=0, max=h)\n\n        # Convert back to the original representation\n        self.tensor[idx, 0] = (x1 + x2) / 2.0\n        self.tensor[idx, 1] = (y1 + y2) / 2.0\n        self.tensor[idx, 2] = x2 - x1\n        self.tensor[idx, 3] = y2 - y1\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        h, w = box_size\n\n        # Step 1: Normalize angles to be within (-180, 180] degrees\n        self.normalize_angles()\n\n        # Step 2: Identify nearly-horizontal boxes based on clip_angle_threshold\n        inds_to_clip = torch.abs(self.tensor[:, 4]) <= clip_angle_threshold\n\n        # Step 3: Convert boxes to (x1, y1, x2, y2) representation\n        if inds_to_clip.any():\n            boxes_to_clip = self.tensor[inds_to_clip]\n            x1 = boxes_to_clip[:, 0] - boxes_to_clip[:, 2] / 2.0\n            y1 = boxes_to_clip[:, 1] - boxes_to_clip[:, 3] / 2.0\n            x2 = boxes_to_clip[:, 0] + boxes_to_clip[:, 2] / 2.0\n            y2 = boxes_to_clip[:, 1] + boxes_to_clip[:, 3] / 2.0\n\n            # Step 4: Clip x1, y1, x2, y2 within the box_size limits\n            x1.clamp_(min=0, max=w)\n            y1.clamp_(min=0, max=h)\n            x2.clamp_(min=0, max=w)\n            y2.clamp_(min=0, max=h)\n\n            # Step 5: Convert back to original format\n            boxes_to_clip[:, 0] = (x1 + x2) / 2.0\n            boxes_to_clip[:, 1] = (y1 + y2) / 2.0\n            boxes_to_clip[:, 2] = x2 - x1\n            boxes_to_clip[:, 3] = y2 - y1\n\n            # Step 6: Update the original tensor\n            self.tensor[inds_to_clip] = boxes_to_clip\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        h, w = box_size\n        self.normalize_angles()\n        idx = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n        xyxy_boxes = self.tensor[idx]\n        if not xyxy_boxes.numel():\n            return\n        original_xywha_boxes = self.tensor[~idx]\n        xyxy_boxes[:, :2] -= xyxy_boxes[:, :2] - (xyxy_boxes[:, :2] % 1.0)\n        xyxy_boxes[:, 2:] += (xyxy_boxes[:, 2:] - 1) - ((xyxy_boxes[:, 2:] - 1) % 1.0)\n        xyxy_boxes[:, 0].clamp_(min=0, max=w - 1)\n        xyxy_boxes[:, 1].clamp_(min=0, max=h - 1)\n        xyxy_boxes[:, 2].clamp_(min=0, max=w - 1)\n        xyxy_boxes[:, 3].clamp_(min=0, max=h - 1)\n        xywha_boxes = torch.zeros_like(xyxy_boxes)\n        xywha_boxes[:, :2] = xyxy_boxes[:, :2]\n        xywha_boxes[:, 2:4] = xyxy_boxes[:, 2:] - xyxy_boxes[:, :2]\n        xywha_boxes[:, 4] = -torch.atan2(-(xyxy_boxes[:, 3] - xyxy_boxes[:, 1]),\n                                         xyxy_boxes[:, 2] - xyxy_boxes[:, 0]) * 180.0 / math.pi\n        self.tensor = torch.cat((xywha_boxes, original_xywha_boxes), dim=0)"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        h, w = box_size\n\n        # Step 1: Normalize angles to be within (-180, 180] degrees\n        self.normalize_angles()\n\n        # Step 2: Identify nearly-horizontal boxes based on clip_angle_threshold\n        inds_to_clip = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n\n        # Step 3: Convert boxes to (x1, y1, x2, y2) representation\n        x1 = self.tensor[inds_to_clip, 0:1] - self.tensor[inds_to_clip, 2:3] / 2.0\n        y1 = self.tensor[inds_to_clip, 1:2] - self.tensor[inds_to_clip, 3:4] / 2.0\n        x2 = self.tensor[inds_to_clip, 0:1] + self.tensor[inds_to_clip, 2:3] / 2.0\n        y2 = self.tensor[inds_to_clip, 1:2] + self.tensor[inds_to_clip, 3:4] / 2.0\n\n        # Step 4: Clip coordinates to be within the specified box_size\n        self.tensor[inds_to_clip, 0:1] = x1.clamp(min=0, max=w)\n        self.tensor[inds_to_clip, 1:2] = y1.clamp(min=0, max=h)\n        self.tensor[inds_to_clip, 2:3] = x2.clamp(min=0, max=w)\n        self.tensor[inds_to_clip, 3:4] = y2.clamp(min=0, max=h)\n\n        # Step 5: Convert boxes back to original format\n        self.tensor[inds_to_clip, 0:2] = (self.tensor[inds_to_clip, 0:2] + self.tensor[inds_to_clip, 2:4]) / 2.0"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        # Normalize angles to be within (-180, 180] degrees.\n        self.normalize_angles()\n\n        # Identify indices of boxes that are nearly horizontal.\n        angle_threshold = torch.tensor(clip_angle_threshold, device=self.device)\n        is_box_nearly_upright = torch.abs(self.tensor[:, 4]) <= angle_threshold\n        upright_box_idxs = torch.where(is_box_nearly_upright)[0]\n\n        # Convert boxes that are nearly horizontal to (x1, y1, x2, y2) representation and clip.\n        upright_boxes = self.tensor[upright_box_idxs]\n        upright_boxes[:, 0] = upright_boxes[:, 0] - upright_boxes[:, 2] / 2.0\n        upright_boxes[:, 1] = upright_boxes[:, 1] - upright_boxes[:, 3] / 2.0\n        upright_boxes[:, 2] = upright_boxes[:, 0] + upright_boxes[:, 2]\n        upright_boxes[:, 3] = upright_boxes[:, 1] + upright_boxes[:, 3]\n        upright_boxes[:, 0].clamp_(min=0, max=box_size[1])  # limit to box width\n        upright_boxes[:, 1].clamp_(min=0, max=box_size[0])  # limit to box height\n        upright_boxes[:, 2].clamp_(min=0, max=box_size[1])  # limit to box width\n        upright_boxes[:, 3].clamp_(min=0, max=box_size[0])  # limit to box height\n\n        # Convert back to original representation.\n        upright_boxes[:, 0] = (u"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        h, w = box_size\n\n        # Step 1: Normalize angles to be within (-180, 180] degrees\n        self.normalize_angles()\n\n        # Step 2: Identify nearly-horizontal boxes based on clip_angle_threshold\n        angle_threshold = torch.tensor(\n            [clip_angle_threshold], device=self.device, dtype=self.tensor.dtype\n        )\n        is_box_nearly_h = torch.abs(self.tensor[:, 4]) < angle_threshold\n\n        # Step 3: Convert boxes to (x1, y1, x2, y2) representation, then clip\n        # For boxes that are nearly horizontal, it is better to clip them as if they were horizontal,\n        # to avoid any numerical errors while clipping.\n        boxes_x1y1x2y2 = self.tensor.clone()\n        boxes_x1y1x2y2[is_box_nearly_h, :4] = xywha_to_xyxy(\n            self.tensor[is_box_nearly_h, :4], input_format=\"xywha\"\n        )\n        boxes_x1y1x2y2[:, 0] = torch.clamp(boxes_x1y1x2y2[:, 0], min=0, max=w)\n        boxes_x1y1x2y2[:, 1] = torch.clamp(boxes_x1y1x2y2[:, 1], min=0, max=h)\n        boxes_x1y1x2y2[:, 2] = torch.clamp(boxes_x1y1x2y2[:, 2], min=0, max=w)\n        boxes_x1y1x2y2[:, 3] = torch.clamp(boxes_x1y1x2y2[:, 3], min=0, max=h)\n\n        # Step 4: Convert back to original representation\n        self.tensor[is_box_nearly_h, :"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        if len(self) == 0:\n            return\n\n        # Normalize angles to be within (-180, 180] degrees\n        self.normalize_angles()\n\n        # Identify nearly-horizontal boxes using threshold in degrees\n        is_box_large = torch.abs(self.tensor[:, 4]) <= clip_angle_threshold\n        is_box_small = ~is_box_large\n\n        # Convert large boxes to (x1, y1, x2, y2) representation\n        large_boxes = self.tensor[is_box_large, :]\n        large_boxes_x1y1 = large_boxes.new_zeros((len(large_boxes), 2))\n        large_boxes_x1y1[:, 0] = large_boxes[:, 0] - large_boxes[:, 2] / 2.0\n        large_boxes_x1y1[:, 1] = large_boxes[:, 1] - large_boxes[:, 3] / 2.0\n        large_boxes_x2y2 = large_boxes.new_zeros((len(large_boxes), 2))\n        large_boxes_x2y2[:, 0] = large_boxes[:, 0] + large_boxes[:, 2] / 2.0\n        large_boxes_x2y2[:, 1] = large_boxes[:, 1] + large_boxes[:, 3] / 2.0\n        large_boxes = torch.cat((large_boxes_x1y1, large_boxes_x2y2), dim=-1)\n\n        # Clamp large boxes to fit the scale\n        large_boxes[:, [0, 2]] = large_boxes[:, [0, 2]].clamp(min=0, max=box_size[1] - 1)\n        large_boxes[:, [1, 3]] = large_boxes[:, [1, 3]].clamp(min=0,"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        h, w = box_size\n\n        # Step 1: Normalize angles to be within (-180, 180] degrees\n        self.normalize_angles()\n\n        # Step 2: Identify indices of boxes that are nearly horizontal\n        idx = torch.abs(self.tensor[:, 4]) <= clip_angle_threshold\n\n        # Step 3: Convert boxes to (x1, y1, x2, y2) representation\n        # NOTE: In this process no angle normalization is performed\n        ct_x = self.tensor[idx, 0]\n        ct_y = self.tensor[idx, 1]\n        width = self.tensor[idx, 2]\n        height = self.tensor[idx, 3]\n        angle = self.tensor[idx, 4]\n\n        pi = torch.tensor(math.pi).to(self.tensor.device)\n        atan_angle = torch.atan(width / height)\n        angle = atan_angle + angle\n        x1 = ct_x + torch.cos(angle) * -width / 2\n        y1 = ct_y + torch.sin(angle) * -width / 2\n        x2 = ct_x + torch.cos(angle) * width / 2\n        y2 = ct_y + torch.sin(angle) * width / 2\n\n        # Step 4: Clamp to ensure all points are within the box size\n        x1 = torch.clamp(x1, min=0, max=w)\n        y1 = torch.clamp(y1, min=0, max=h)\n        x2 = torch.clamp(x2, min=0, max=w)\n        y2 = torch.clamp(y2, min=0, max=h)\n\n        # Step 5: Convert boxes back to (center x, center y, width, height, angle) representation\n        angle = atan_angle - (x2 - x1).clone().atan()\n        ct_x = ((x1 + x2)"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        h, w = box_size\n\n        # Step 1: Normalize angles to be within (-180, 180] degrees\n        self.normalize_angles()\n\n        # Step 2: Identify the indices of boxes that are nearly horizontal\n        angle = self.tensor[:, 4]\n        keep = torch.abs(angle) < clip_angle_threshold\n\n        # Step 3: Convert the boxes that are nearly horizontal to (x1, y1, x2, y2) representation\n        xc, yc, w, h, angle = self.tensor[keep].unbind(dim=1)\n        box = self.tensor[keep]\n        assert (angle < 45).all(), \"Angle difference should be less than 45 degrees\"\n        angle = angle * math.pi / 180.\n        w_bound = torch.min(w, h)\n        h_bound = torch.max(w, h)\n        box[:, 2] = (w_bound * torch.cos(angle) + h_bound * torch.sin(angle)) * 0.5\n        box[:, 3] = (w_bound * torch.sin(angle) + h_bound * torch.cos(angle)) * 0.5\n        box[:, 0] = xc - box[:, 2]\n        box[:, 1] = yc - box[:, 3]\n\n        # Step 4: Clip the boxes to the specified box_size limits\n        box[:, [0, 2]] = box[:, [0, 2]].clamp(min=0, max=w)\n        box[:, [1, 3]] = box[:, [1, 3]].clamp(min=0, max=h)\n\n        # Step 5: Convert back to original representation\n        box[:, 2] = box[:, 2] + box[:, 0]\n        box[:, 3] = box[:, 3] + box[:, 1]\n        box[:, 0] = xc\n        box[:, 1"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        h, w = box_size\n\n        # Step 1: Normalize angles to be within (-180, 180] degrees.\n        self.normalize_angles()\n\n        # Step 2: Identify the indices of boxes that are nearly horizontal\n        idxs = torch.abs(self.tensor[:, 4]) <= clip_angle_threshold\n\n        # Step 3: Convert the boxes that are nearly horizontal to (x1, y1, x2, y2) representation and clip.\n        xc, yc, w, h, a = self.tensor[idxs, 0], self.tensor[idxs, 1], self.tensor[idxs, 2], self.tensor[idxs, 3], self.tensor[idxs, 4]\n        assert torch.all(xc + w / 2.0 == xc + w / 2.0) and torch.all(yc - h / 2.0 == yc - h / 2.0), \"The x and y centers of the rotated boxes must be integers.\"\n        x1 = xc - w / 2.0\n        y1 = yc - h / 2.0\n        x2 = xc + w / 2.0\n        y2 = yc + h / 2.0\n        self.tensor[idxs, :4] = torch.stack((x1, y1, x2, y2), dim=1)\n        self.tensor[idxs, :4] = torch.clamp(self.tensor[idxs, :4], min=0, max=max(h - 1, w - 1))\n        self.tensor[idxs, 0] = x1\n        self.tensor[idxs, 1] = y1\n        self.tensor[idxs, 2] = x2\n        self.tensor[idxs, 3] = y2\n\n        # Step 4: Convert back to original format and return\n        self.tensor[idxs, 4] = a\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        # Normalize angles to be within (-180, 180] degrees.\n        self.normalize_angles()\n\n        # Identify indices of boxes that are nearly horizontal.\n        cos_clip_threshold = math.cos(clip_angle_threshold / 180.0 * math.pi)\n        keep_horizontal = torch.abs(torch.cos(self.tensor[:, 4] * math.pi / 180.0)) > cos_clip_threshold\n\n        # For the boxes that are nearly horizontal, convert representation from (center x, center y, width, height, angle) to (x1, y1, x2, y2).\n        # NOTE: We store the width and height in the 3rd and 4th column respectively of self.tensor, hence the + 2 offset.\n        x1 = self.tensor[keep_horizontal, 0:1] - self.tensor[keep_horizontal, 2:3] / 2.0\n        y1 = self.tensor[keep_horizontal, 1:2] - self.tensor[keep_horizontal, 3:4] / 2.0\n        x2 = self.tensor[keep_horizontal, 0:1] + self.tensor[keep_horizontal, 2:3] / 2.0\n        y2 = self.tensor[keep_horizontal, 1:2] + self.tensor[keep_horizontal, 3:4] / 2.0\n\n        # Clamp the coordinates to make sure they stay within the specified box_size limits.\n        x1.clamp_(min=0, max=box_size[1])\n        y1.clamp_(min=0, max=box_size[0])\n        x2.clamp_(min=0, max=box_size[1])\n        y2.clamp_(min=0, max=box_size[0])\n\n        # Convert back to the original representation.\n        self.tensor[keep_horizontal, 0:1] = (x1 + x2) / 2.0\n        self.tensor[keep_horizontal, 1:2] ="}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        # Normalize angles to be within (-180, 180] degrees.\n        self.normalize_angles()\n\n        # Identify nearly-horizontal boxes to perform clipping on.\n        cos_clip_angle_threshold = math.cos(clip_angle_threshold * math.pi / 180.0)\n        is_box_too_horizontal = self.tensor[:, 2] / self.tensor[:, 3] > cos_clip_angle_threshold\n\n        # If the box is too horizontal, clip it using its 4 corners.\n        if torch.any(is_box_too_horizontal):\n            # Convert boxes from (center x, center y, width, height, angle) to (x1, y1, x2, y2).\n            # x1, y1 = top left corner\n            # x2, y2 = bottom right corner\n            ct_x = self.tensor[:, 0]\n            ct_y = self.tensor[:, 1]\n            width = self.tensor[:, 2]\n            height = self.tensor[:, 3]\n            angle = self.tensor[:, 4]\n            half_w = width / 2.0\n            half_h = height / 2.0\n            # Note: The following line fails when self.tensor is an empty tensor.\n            # Thus, we add an exception to handle this case.\n            if len(self.tensor) > 0:\n                # This is equivalent to self.tensor[:, 0].clone()\n                ct_x = ct_x.unsqueeze(dim=-1)\n                ct_y = ct_y.unsqueeze(dim=-1)\n                half_w = half_w.unsqueeze(dim=-1)\n                half_h = half_h.unsqueeze(dim=-1)\n                angle = angle.unsqueeze(dim=-1)\n                x1 = ct_x + half_w * torch.cos(angle) - half_h * torch.sin(angle)\n                y1 = ct_y + half"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        h, w = box_size\n\n        # Step 1: Normalize angles to be within (-180, 180] degrees\n        self.normalize_angles()\n\n        # Step 2: Identify nearly-horizontal boxes based on clip_angle_threshold\n        inds_to_clip = torch.abs(self.tensor[:, 4]) <= clip_angle_threshold\n        nearly_h_boxes = self.tensor[inds_to_clip]\n\n        if not nearly_h_boxes.numel():\n            # Early return\n            return\n\n        # Step 3: Convert nearly-horizontal boxes from (center x, center y, width, height, angle) to (x1, y1, x2, y2)\n        #         where (x1, y1) and (x2, y2) are the coordinates of the top-left and bottom-right corners, respectively.\n        #         This conversion is needed to ensure that the clipping operation does not increase the size of the box.\n        nearly_h_x1 = (nearly_h_boxes[:, 0] - nearly_h_boxes[:, 2] / 2)\n        nearly_h_y1 = (nearly_h_boxes[:, 1] - nearly_h_boxes[:, 3] / 2)\n        nearly_h_x2 = (nearly_h_boxes[:, 0] + nearly_h_boxes[:, 2] / 2)\n        nearly_h_y2 = (nearly_h_boxes[:, 1] + nearly_h_boxes[:, 3] / 2)\n\n        # Step 4: Clamp the values to be within the box size.\n        #         This is needed to ensure that the clipping operation does not increase the size of the box.\n        #         Note that the clip operation is performed on the *normalized* coordinates and not on the direct coordinates.\n        #         This is done because the clip operation with direct coordinates might cause one of the box coordinates to go out of the box size limits.\n        #         This would have a ripple effect on the"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0\n        }\n\n        for item in self.data:\n            statistics[item['type']] += 1\n\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            stats[item['type']] += 1\n        return stats"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            if item['type'] in stats:\n                stats[item['type']] += 1\n            else:\n                stats[item['type']] = 1\n        return stats"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for entry in self.data:\n            statistics[entry['type']] += 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0\n        }\n        for entry in self.data:\n            statistics[entry['type']] += 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0\n        }\n        for d in self.data:\n            stats[d['type']] += 1\n        return stats"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            stats[item['type']] += 1\n        return stats\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        types = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            if item['type'] in types:\n                types[item['type']] += 1\n            else:\n                types[item['type']] = 1\n        return types\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            if item['type'] in statistics:\n                statistics[item['type']] += 1\n            else:\n                statistics[item['type']] = 1\n        return statistics\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        # Initialize the statistics dictionary\n        statistics = {\"doc\": 0, \"gen\": 0, \"kno\": 0, \"num\": 0}\n\n        # Iterate over the data\n        for item in self.data:\n\n            # Update the statistics dictionary\n            statistics[item[\"type\"]] += 1\n\n        # Return the statistics dictionary\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stat = {\n            \"doc\": 0,\n            \"gen\": 0,\n            \"kno\": 0,\n            \"num\": 0\n        }\n\n        for item in self.data:\n            if item[\"type\"] == \"doc\":\n                stat[\"doc\"] += 1\n            elif item[\"type\"] == \"gen\":\n                stat[\"gen\"] += 1\n            elif item[\"type\"] == \"kno\":\n                stat[\"kno\"] += 1\n            elif item[\"type\"] == \"num\":\n                stat[\"num\"] += 1\n\n        return stat"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {\"doc\": 0, \"gen\": 0, \"kno\": 0, \"num\": 0}\n        for data in self.data:\n            if data['type'] in statistics:\n                statistics[data['type']] += 1\n            else:\n                statistics.update({data['type']: 1})\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        # Initialize the statistics dictionary\n        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n\n        # Iterate through the data\n        for item in self.data:\n            # Update the statistics dictionary\n            statistics[item['type']] += 1\n\n        # Return the statistics dictionary\n        return statistics\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {\"doc\": 0, \"gen\": 0, \"kno\": 0, \"num\": 0}\n        for item in self.data:\n            if item['type'] in stats.keys():\n                stats[item['type']] += 1\n            else:\n                stats[item['type']] = 1\n        return stats\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0\n        }\n        for data in self.data:\n            statistics[data['type']] += 1\n\n        return statistics\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        # Initialize a dictionary to hold the statistics of the types of objects contained in the data attribute\n        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n\n        # Iterate through the data attribute\n        for i in range(len(self.data)):\n\n            # Get the type of the object\n            type = self.data[i]['type']\n\n            # Update the statistics dictionary\n            statistics[type] += 1\n\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            statistics[item['type']] += 1\n\n        return statistics\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {\"doc\": 0, \"gen\": 0, \"kno\": 0, \"num\": 0}\n        for item in self.data:\n            if item[\"type\"] in statistics:\n                statistics[item[\"type\"]] += 1\n            else:\n                statistics[item[\"type\"]] = 1\n        return statistics\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for data in self.data:\n            stats[data['type']] += 1\n        return stats\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0\n        }\n\n        for item in self.data:\n            if item['type'] in statistics:\n                statistics[item['type']] += 1\n            else:\n                print(f'Unknown type {item[\"type\"]}')\n\n        return statistics\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        raise NotImplementedError\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        raise NotImplementedError\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        raise TypeError('Unrecognized Loss type:', cfg['type'])\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        raise NotImplementedError\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        raise NotImplementedError\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        warnings.warn('WARNING: Unknown loss type, using MMDET_LOSSES.')\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        raise NotImplementedError\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn('train_cfg and test_cfg is deprecated, '\n                      'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    return SEGMENTORS.build(\n        cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn('train_cfg and test_cfg is deprecated, '\n                      'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    return SEGMENTORS.build(\n        cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError\n\n"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError\n\n"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    return SEGMENTORS.build(\n        cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    return SEGMENTORS.build(\n        cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    return SEGMENTORS.build(\n        cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    return SEGMENTORS.build(\n        cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError\n\n"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError\n\n"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError\n\n"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    return SEGMENTORS.build(\n        cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn('train_cfg and test_cfg is deprecated, '\n                      'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    return SEGMENTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn('train_cfg and test_cfg is deprecated, '\n                      'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    return SEGMENTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn('train_cfg and test_cfg is deprecated, '\n                      'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    return SEGMENTORS.build(\n        cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise ValueError(f'{cfg[\"type\"]} is not registered in SEGMENTORS')"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    assert SEGMENTORS._module_dict.get(cfg['type']) is not None\n    return SEGMENTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    # Check if the training or testing configurations are specified both in the function arguments and the model configuration\n    if train_cfg is not None or test_cfg is not None:\n        warnings.warn('train_cfg and test_cfg is deprecated, '\n                      'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    # Build the segmentor model\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    # Warnings for duplicate training/testing configurations.\n    if train_cfg is not None and cfg.get('train_cfg') is not None:\n        warnings.warn('train_cfg specified in both outer field and model '\n                      'field \"train_cfg\", and the latter will be used.')\n    if test_cfg is not None and cfg.get('test_cfg') is not None:\n        warnings.warn('test_cfg specified in both outer field and model '\n                      'field \"test_cfg\", and the latter will be used.')\n\n    # Ensure that the training and testing configurations are not duplicated in the cfg dictionary.\n    if cfg.get('train_cfg') is not None:\n        train_cfg = cfg['train_cfg']\n        if train_cfg.get('data') is not None:\n            warnings.warn(\n                'The training configuration (cfg[\"train_cfg\"]) '\n                'already contains \"data\", which will be overwritten by '\n                'the outer field \"data\".')\n    else:\n        train_cfg = cfg\n    if cfg.get('test_cfg') is not None:\n        test_cfg = cfg['test_cfg']\n        if test_cfg.get('data') is not None:\n            warnings.warn(\n                'The testing configuration (cfg[\"test_cfg\"]) '\n                'already contains \"data\", which will be overwritten by '\n                'the outer field \"data\".')\n    else:\n        test_cfg = cfg\n\n    # Build the segmentor model.\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if cfg['type'] in DETECTORS._module_dict.keys():\n        assert train_cfg is None or cfg.get('train_cfg') is None, \\\n            'train_cfg specified in both outer field and model field ' \\\n            'of the config file'\n        assert test_cfg is None or cfg.get('test_cfg') is None, \\\n            'test_cfg specified in both outer field and model field ' \\\n            'of the config file'\n        return DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, train_cfg, test_cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg, train_cfg, test_cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if cfg['type'] in DETECTORS._module_dict.keys():\n        assert train_cfg is None or cfg.get('train_cfg') is None, \\\n            'train_cfg specified in both outer field and model field ' \\\n            'of config file'\n        assert test_cfg is None or cfg.get('test_cfg') is None, \\\n            'test_cfg specified in both outer field and model field ' \\\n            'of config file'\n        return DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if cfg['type'] in DETECTORS._module_dict.keys():\n        assert train_cfg is None or all(\n            item in cfg for item in ['train_cfg', 'test_cfg']\n        ), 'train_cfg and test_cfg should be specified in the model file to be consistent with the cfg argument.'\n        assert test_cfg is None or all(\n            item in cfg for item in ['train_cfg', 'test_cfg']\n        ), 'train_cfg and test_cfg should be specified in the model file to be consistent with the cfg argument.'\n        if train_cfg is not None or test_cfg is not None:\n            warnings.warn(\n                'train_cfg and test_cfg should be specified in the model file to be consistent with the cfg argument.'\n            )\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg, train_cfg=train_cfg, test_cfg=test_cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if cfg['type'] in DETECTORS._module_dict.keys():\n        assert train_cfg is None or all(\n            item not in cfg for item in train_cfg.keys()\n        ), 'train_cfg specified in both outer field and model field ' \\\n           'of the config file, which is unexpected.'\n        assert test_cfg is None or all(\n            item not in cfg for item in test_cfg.keys()\n        ), 'test_cfg specified in both outer field and model field ' \\\n           'of the config file, which is unexpected.'\n        return DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        warnings.warn('The detector type specified in the config file is not '\n                      'implemented by MMPose. The supported types are '\n                      f'{list(DETECTORS._module_dict.keys())}. '\n                      'Please build the detector model by yourself.')\n        return MMDET_DETECTORS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if 'train_cfg' in cfg or 'test_cfg' in cfg:\n        warnings.warn(\n            'train_cfg and test_cfg in Detector should be deprecated in favor of \\\n            model.train_cfg and model.test_cfg.', UserWarning)\n    if train_cfg is not None:\n        assert 'train_cfg' not in cfg, 'train_cfg specified in both outer field \\\n            and model field, which is confusing'\n        warnings.warn('train_cfg is now specified in model field. You can remove \\\n            train_cfg in outer field.', UserWarning)\n        cfg['train_cfg'] = train_cfg\n    if test_cfg is not None:\n        assert 'test_cfg' not in cfg, 'test_cfg specified in both outer field \\\n            and model field, which is confusing'\n        warnings.warn('test_cfg is now specified in model field. You can remove \\\n            test_cfg in outer field.', UserWarning)\n        cfg['test_cfg'] = test_cfg\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if 'type' not in cfg:\n        raise ValueError('cfg should contain the key \"type\", but found \\'%s\\'' % cfg)\n    if train_cfg is not None:\n        warnings.warn('train_cfg is deprecated. Now it is specified in the cfg dictionary.')\n    if test_cfg is not None:\n        warnings.warn('test_cfg is deprecated. Now it is specified in the cfg dictionary.')\n    if 'train_cfg' in cfg:\n        assert train_cfg is None, 'train_cfg specified in both outer field and model field ' \\\n                                 'of the config file'\n        train_cfg = cfg['train_cfg']\n    if 'test_cfg' in cfg:\n        assert test_cfg is None, 'test_cfg specified in both outer field and model field ' \\\n                                'of the config file'\n        test_cfg = cfg['test_cfg']\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, train_cfg, test_cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg, train_cfg, test_cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if 'train_cfg' in cfg or 'test_cfg' in cfg:\n        warnings.warn(\n            'train_cfg and test_cfg should not be dicts in the model config. '\n            'They should be specified in the dataset config instead.')\n\n    if 'train_cfg' in cfg:\n        assert train_cfg is None\n        train_cfg = cfg.pop('train_cfg')\n\n    if 'test_cfg' in cfg:\n        assert test_cfg is None\n        test_cfg = cfg.pop('test_cfg')\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        assert train_cfg is None and test_cfg is None\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg, train_cfg, test_cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if 'train_cfg' in cfg or 'test_cfg' in cfg:\n        warnings.warn(\n            'train_cfg and test_cfg should be specified in the model, not here. '\n            'Please check your code.')\n    if train_cfg is not None or test_cfg is not None:\n        assert train_cfg is not None and test_cfg is not None\n        cfg = cfg.copy()\n        if 'train_cfg' in cfg:\n            assert cfg['train_cfg'] == train_cfg\n            cfg.pop('train_cfg')\n        if 'test_cfg' in cfg:\n            assert cfg['test_cfg'] == test_cfg\n            cfg.pop('test_cfg')\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, train_cfg, test_cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg, train_cfg, test_cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if 'train_cfg' in cfg or 'test_cfg' in cfg:\n        warnings.warn('train_cfg and test_cfg in general should be specified in the model\\'s '\n                      'configuration and not in the data loader. Please check your code')\n\n    if train_cfg is not None:\n        assert 'train_cfg' not in cfg, 'train_cfg specified in both outer field and model field ' \\\n                                       'of the config file'\n        cfg['train_cfg'] = train_cfg\n    if test_cfg is not None:\n        assert 'test_cfg' not in cfg, 'test_cfg specified in both outer field and model field ' \\\n                                      'of the config file'\n        cfg['test_cfg'] = test_cfg\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if 'type' not in cfg:\n        raise KeyError('cfg should contain the key \"type\".')\n\n    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg in build_detector will be deprecated. '\n            'Please specify them in model. Details see '\n            'https://github.com/open-mmlab/mmdetection/pull/6290.')\n\n    if 'train_cfg' in cfg or 'test_cfg' in cfg:\n        assert train_cfg is None and test_cfg is None, 'The train_cfg and test_cfg in build_detector will be deprecated.'\n        train_cfg = cfg.get('train_cfg', None)\n        test_cfg = cfg.get('test_cfg', None)\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, train_cfg, test_cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg, train_cfg, test_cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if 'train_cfg' in cfg or 'test_cfg' in cfg:\n        warnings.warn(\n            'train_cfg and test_cfg in plain options is deprecated, '\n            'it should be specified in model\\'s sub-module. See '\n            'https://github.com/open-mmlab/mmdetection/pull/6191 for details.',\n            DeprecationWarning)\n    assert train_cfg is None or cfg.get('train_cfg') is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert test_cfg is None or cfg.get('test_cfg') is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg.get('train_cfg') is not None:\n        train_cfg = cfg['train_cfg']\n    if cfg.get('test_cfg') is not None:\n        test_cfg = cfg['test_cfg']\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, train_cfg, test_cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg, train_cfg, test_cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg in detectors should be deprecated and be '\n            'moved to the model config.', DeprecationWarning)\n    assert train_cfg is None or cfg.get('train_cfg') is None, \\\n        'train_cfg specified in arguments and model config.'\n    assert test_cfg is None or cfg.get('test_cfg') is None, \\\n        'test_cfg specified in arguments and model config.'\n    if cfg.get('train_cfg') is not None:\n        train_cfg = cfg['train_cfg']\n    if cfg.get('test_cfg') is not None:\n        test_cfg = cfg['test_cfg']\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        if 'train_cfg' in cfg:\n            cfg.pop('train_cfg')\n        if 'test_cfg' in cfg:\n            cfg.pop('test_cfg')\n        return DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        if 'train_cfg' in cfg:\n            cfg.pop('train_cfg')\n        if 'test_cfg' in cfg:\n            cfg.pop('test_cfg')\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if 'type' not in cfg:\n        raise KeyError('cfg should contain the key \"type\".')\n\n    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg in detectors should be deprecated and be '\n            'specified in model. Details see docs/en/tutorials/customize_config.md'\n        )\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        assert train_cfg is None and test_cfg is None\n        if 'train_cfg' in cfg or 'test_cfg' in cfg:\n            warnings.warn(\n                'train_cfg and test_cfg in detectors will be deprecated. '\n                'Please specify them in model. Details see '\n                'docs/en/tutorials/customize_config.md')\n            if 'train_cfg' in cfg:\n                train_cfg = cfg['train_cfg']\n            if 'test_cfg' in cfg:\n                test_cfg = cfg['test_cfg']\n\n        return DETECTORS.build(\n            cfg['type'], cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if 'type' not in cfg:\n        raise KeyError('cfg must have the key \"type\"')\n\n    if train_cfg is not None:\n        warnings.warn(\n            'train_cfg should be specified in the model, not in the function')\n\n    if test_cfg is not None:\n        warnings.warn(\n            'test_cfg should be specified in the model, not in the function')\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        if train_cfg is not None:\n            assert cfg.get('train_cfg') is None, 'train_cfg specified in both outer field and model field'\n            cfg['train_cfg'] = train_cfg\n        if test_cfg is not None:\n            assert cfg.get('test_cfg') is None, 'test_cfg specified in both outer field and model field'\n            cfg['test_cfg'] = test_cfg\n        return DETECTORS.build(cfg)\n    else:\n        if train_cfg is not None:\n            assert cfg.get('train_cfg') is None, 'train_cfg specified in both outer field and model field'\n            cfg['train_cfg'] = train_cfg\n        if test_cfg is not None:\n            assert cfg.get('test_cfg') is None, 'test_cfg specified in both outer field and model field'\n            cfg['test_cfg'] = test_cfg\n        return MMDET_DETECTORS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if 'type' not in cfg:\n        raise KeyError('cfg should contain the key \"type\".')\n\n    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg should be specified in the model, not here. '\n            'The arguments should be passed to the model instead.')\n\n    if 'train_cfg' in cfg or 'test_cfg' in cfg:\n        assert train_cfg is None and test_cfg is None, \\\n            'train_cfg and test_cfg should be specified in the model, not here.'\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, train_cfg, test_cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg, train_cfg, test_cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if 'train_cfg' in cfg or 'test_cfg' in cfg:\n        warnings.warn(\n            'train_cfg and test_cfg in plain options is deprecated, '\n            'it should be specified in model field. See '\n            'https://github.com/open-mmlab/mmdetection/pull/2063 '\n            'for details.', DeprecationWarning)\n\n    if train_cfg is not None or test_cfg is not None:\n        assert 'train_cfg' not in cfg, (\n            'train_cfg specified in both outer field and model field '\n            'at the same time')\n        assert 'test_cfg' not in cfg, (\n            'test_cfg specified in both outer field and model field '\n            'at the same time')\n        warnings.warn(\n            'train_cfg and test_cfg in plain options is deprecated, '\n            'it should be specified in model field. See '\n            'https://github.com/open-mmlab/mmdetection/pull/2063 '\n            'for details.', DeprecationWarning)\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(\n            cfg, train_cfg=train_cfg, test_cfg=test_cfg)\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, train_cfg=train_cfg, test_cfg=test_cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if 'train_cfg' in cfg or 'test_cfg' in cfg:\n        warnings.warn('The `train_cfg` and `test_cfg` in the model field are deprecated \\\n            since they will be moved to the `train_cfg` and `test_cfg` field of the \\\n            second stage detectors.')\n\n    if train_cfg is not None or test_cfg is not None:\n        assert train_cfg is not None and test_cfg is not None\n        return DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        if cfg['type'] in DETECTORS._module_dict.keys():\n            return DETECTORS.build(cfg)\n        else:\n            return MMDET_DETECTORS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if cfg['type'] in DETECTORS._module_dict.keys():\n        if train_cfg is not None:\n            warnings.warn('train_cfg is deprecated. Now all training settings are specified in the cfg dict.')\n        if test_cfg is not None:\n            warnings.warn('test_cfg is deprecated. Now all test settings are specified in the cfg dict.')\n        assert 'train_cfg' not in cfg.keys() and 'test_cfg' not in cfg.keys(), \\\n            'Please rename the train_cfg and test_cfg to cfg.'\n        return DETECTORS.build(cfg)\n    else:\n        if train_cfg is None:\n            warnings.warn('train_cfg is missing. You should specify it in the outer field of the config.')\n        if test_cfg is None:\n            warnings.warn('test_cfg is missing. You should specify it in the outer field of the config.')\n        return MMDET_DETECTORS.build(cfg, train_cfg=train_cfg, test_cfg=test_cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if 'type' not in cfg:\n        raise KeyError('cfg should have key \"type\", but found {}'.format(cfg))\n    if 'train_cfg' in cfg or 'test_cfg' in cfg:\n        warnings.warn(\n            'train_cfg and test_cfg in cfg should be deprecated and be '\n            'specified in model. Details see this PR: '\n            'https://github.com/open-mmlab/mmdetection/pull/6292.', UserWarning)\n    if 'train_cfg' in cfg:\n        assert train_cfg is None, 'train_cfg specified in both outer field and ' \\\n                                 'model field, which is unexpected.'\n        train_cfg = cfg.pop('train_cfg')\n    if 'test_cfg' in cfg:\n        assert test_cfg is None, 'test_cfg specified in both outer field and ' \\\n                                'model field, which is unexpected.'\n        test_cfg = cfg.pop('test_cfg')\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    elif cfg['type'] in MMDET_DETECTORS._module_dict.keys():\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise TypeError('type {} is not exist in DETECTORS or MMDET_DETECTORS, '\n                        'valid types are {}'.format(\n                            cfg['type'],\n                            DETECTORS._module_dict.keys() +\n                            MMDET_DETECTORS._module_dict.keys()))\n"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    if box_type_3d is None:\n        from pcdet.utils.box_utils import LiDARInstance3DBoxes\n        box_type_3d = LiDARInstance3DBoxes\n\n    if box_mode_3d is None:\n        box_mode_3d = 'lidar'\n\n    if not isinstance(metric, list):\n        metric = [metric]\n\n    mAP_bbox = None\n    mAP_bev = None\n    if 'bbox' in metric:\n        mAP_bbox, mAP_bev = eval_class(\n            gt_annos, dt_annos, label2cat, box_type_3d, box_mode_3d,\n            iou_thresh=0.7,\n            eval_types=['bbox', 'bev'])\n\n    ret_dict = {}\n    difficulty = ['easy', 'moderate', 'hard']\n    for j, cur_difficulty in enumerate(difficulty):\n        # mAP threshold array: [num_minoverlap, metric, class]\n        # mAR threshold array: [num_minoverlap, metric, class]\n        mAP_bbox_0_7, mAP_bev_0_7 = eval_class(\n            gt_annos, dt_annos, label2cat, box_type_3d, box_mode_3d,\n            iou_thresh=0.7,\n            eval_types=['bbox', 'bev'],\n            difficulty=cur_difficulty)\n\n        for i in range(len(metric)):\n            ret_dict['%s_%s_easy_AP' % (metric[i], label2cat[i])] = \\\n                mAP_bbox_0_7[j, i, 0]\n            ret_dict['%s_%s_moderate_AP' % (metric[i], label2cat[i])] = \\\n                mAP_bbox_0_7[j, i, 1]\n            ret_dict['%s_%s_hard"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    mAP_bbox = []\n    mAP_bev = []\n    mAP_3d = []\n    for i in range(len(metric)):\n        mAP_bbox.append(0)\n        mAP_bev.append(0)\n        mAP_3d.append(0)\n\n    ret_dict = {}\n    for i in range(len(metric)):\n        ret_dict['%s_bbox_mAP_%s' % (metric[i], str(i))] = 0\n        ret_dict['%s_bev_mAP_%s' % (metric[i], str(i))] = 0\n        ret_dict['%s_3d_mAP_%s' % (metric[i], str(i))] = 0\n\n    gt_annos_bak = copy.deepcopy(gt_annos)\n    dt_annos_bak = copy.deepcopy(dt_annos)\n    if not gt_annos_bak:\n        return ret_dict\n\n    for classname in gt_annos_bak.keys():\n        for i in range(len(metric)):\n            ret_dict['%s_bbox_mAP_%s' % (metric[i], str(i))] += 0\n            ret_dict['%s_bev_mAP_%s' % (metric[i], str(i))] += 0\n            ret_dict['%s_3d_mAP_%s' % (metric[i], str(i))] += 0\n\n    recalls_list = []\n    precisions_list = []\n    for i in range(len(metric)):\n        recalls_list.append([])\n        precisions_list.append([])\n\n    for i in range(len(metric)):\n        recalls_list[i], precisions_list[i], ap_list = eval_map_recall(\n            gt_annos, dt_annos, [metric[i]], label2cat, box_type_3d, box_mode_3d)\n\n        for j in range"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    # convert to kitti format\n    gt_annos = kitti.get_label_annos(gt_annos)\n    dt_annos = kitti.get_label_annos(dt_annos)\n\n    # convert to kitti format\n    gt_annos = kitti.get_label_annos(gt_annos)\n    dt_annos = kitti.get_label_annos(dt_annos)\n\n    # filter label ==0\n    filter_annos = []\n    for anno in gt_annos:\n        filter_boxes = []\n        filter_scores = []\n        filter_labels = []\n        for box, score, label in zip(anno['location'], anno['score'], anno['name']):\n            if label > 0:\n                filter_boxes.append(box)\n                filter_scores.append(score)\n                filter_labels.append(label)\n        anno['location'] = np.array(filter_boxes)\n        anno['score'] = np.array(filter_scores)\n        anno['name'] = np.array(filter_labels)\n        filter_annos.append(anno)\n    gt_annos = filter_annos\n\n    # filter label ==0\n    filter_annos = []\n    for anno in dt_annos:\n        filter_boxes = []\n        filter_scores = []\n        filter_labels = []\n        for box, score, label in zip(anno['location'], anno['score'], anno['name']):\n            if label > 0:\n                filter_boxes.append(box)\n                filter_scores.append(score)\n                filter_labels.append(label)\n        anno['location'] = np.array(filter_boxes)\n        anno['score'] = np.array(filter_scores)\n        anno['name'] = np.array(filter_labels)\n        filter_annos.append(anno)\n    dt_annos = filter_annos\n\n    # TODO: check whether the order of box_type and box_mode_3"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(dt_annos) == len(gt_annos)\n    num_examples = len(gt_annos)\n    assert len(metric) > 0\n    # print(metric)\n    # print(gt_annos[0])\n    # print(dt_annos[0])\n    # print(num_examples)\n\n    # print(gt_annos[0]['gt_num'])\n    # print(dt_annos[0]['dt_num'])\n\n    # print(gt_annos[0]['gt_boxes'])\n    # print(dt_annos[0]['dt_boxes'])\n\n    # print(gt_annos[0]['gt_names'])\n    # print(dt_annos[0]['dt_names'])\n\n    # print(gt_annos[0]['gt_boxes'].shape)\n    # print(dt_annos[0]['dt_boxes'].shape)\n\n    # print(gt_annos[0]['gt_boxes'].dtype)\n    # print(dt_annos[0]['dt_boxes'].dtype)\n\n    # print(gt_annos[0]['gt_boxes'].device)\n    # print(dt_annos[0]['dt_boxes'].device)\n\n    # print(gt_annos[0]['gt_boxes'].cpu().numpy())\n    # print(dt_annos[0]['dt_boxes'].cpu().numpy())\n\n    # print(gt_annos[0]['gt_names'].shape)\n    # print(dt_annos[0]['dt_names'].shape)\n\n    # print(gt_annos[0]['gt_names'].dtype)\n    # print(dt_annos[0]['dt_names'].dtype)\n\n    # print(gt_annos[0]['gt_names'].device)\n    # print(dt_annos[0]['dt_names'].device)\n\n    # print(gt_annos[0]['gt_names'].cpu().numpy())\n    # print(dt_annos[0]['dt_names'].cpu().numpy())"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    mAP_bbox = None\n    if 'bbox' in metric:\n        ret = eval_map_recall(\n            dt_annos, gt_annos, metric['bbox'], label2cat, logger=logger)\n        recall, precision, ap = ret\n        mAP_bbox = sum(ap[1]) / len(ap[1])\n\n    mAP_bev = None\n    if 'bev' in metric:\n        ret = eval_map_recall(\n            dt_annos, gt_annos, metric['bev'], label2cat, logger=logger)\n        recall, precision, ap = ret\n        mAP_bev = sum(ap[1]) / len(ap[1])\n\n    mAP_3d = None\n    if '3d' in metric:\n        ret = eval_map_recall(\n            dt_annos, gt_annos, metric['3d'], label2cat, logger=logger)\n        recall, precision, ap = ret\n        mAP_3d = sum(ap[1]) / len(ap[1])\n\n    # calculate the overall mAP\n    mAP = np.nanmean([mAP_bbox, mAP_bev, mAP_3d])\n\n    # calculate the overall mAR\n    mAR = np.nanmean([recall['bbox'][1], recall['bev'][1], recall['3d'][1]])\n\n    # log the results\n    log_msg = []\n    metric_items = [\n        'num_gt', 'mAP', 'mAR', 'mAP_bbox', 'mAP_bev', 'mAP_3d'\n    ]\n    for item in metric_items:\n        value = -1\n        if item == 'mAP':\n            value = mAP\n        elif item == 'mAR':\n            value = mAR\n        elif item in mAP_bbox:\n            value = mAP_bbox\n        elif item in mAP_bev:\n            value = mAP_bev\n        elif item in mAP_3d:\n           "}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    if logger is None:\n        logger = get_root_logger()\n    if box_type_3d is None:\n        box_type_3d = LiDARInstance3DBoxes\n    if box_mode_3d is None:\n        box_mode_3d = 'lidar'\n\n    if not isinstance(gt_annos, list):\n        gt_annos = [gt_annos]\n    if not isinstance(dt_annos, list):\n        dt_annos = [dt_annos]\n\n    # filter boxes without any label\n    for gt_anno in gt_annos:\n        gt_anno['gt_bboxes_3d'] = gt_anno['gt_bboxes_3d'][gt_anno['gt_labels_3d'] > 0]\n        gt_anno['gt_labels_3d'] = gt_anno['gt_labels_3d'][gt_anno['gt_labels_3d'] > 0]\n\n    for dt_anno in dt_annos:\n        dt_anno['boxes_3d'] = dt_anno['boxes_3d'][dt_anno['labels_3d'] > 0]\n        dt_anno['labels_3d'] = dt_anno['labels_3d'][dt_anno['labels_3d'] > 0]\n        dt_anno['scores_3d'] = dt_anno['scores_3d'][dt_anno['labels_3d'] > 0]\n\n    # convert to kitti format then to coco format\n    gt_annos_kitti = kitti2coco_bbox(gt_annos, label2cat)\n    dt_annos_kitti = kitti2coco_bbox(dt_annos, label2cat)\n\n    # convert to coco format\n    gt_annos_coco = kitti2coco_bbox(gt_annos, label2cat)\n    dt_annos_coco = kitti2coco_bbox(dt"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(metric) == 1\n    assert metric[0] == 0.7, \"only support iou 0.7 for now\"\n\n    # construct gt objects\n    gt_obj_list = []\n    for frame_id, gt_anno in enumerate(gt_annos):\n        for j in range(len(gt_anno[\"name\"])):\n            obj = {}\n            obj[\"sample_token\"] = frame_id\n            obj[\"translation\"] = gt_anno[\"location\"][j]\n            obj[\"size\"] = gt_anno[\"dimensions\"][j]\n            obj[\"rotation\"] = gt_anno[\"rotation_y\"][j]\n            obj[\"velocity\"] = gt_anno[\"velocity\"][j]\n            obj[\"detection_name\"] = gt_anno[\"name\"][j]\n            obj[\"detection_score\"] = np.array([1.0])\n            obj[\"attribute_name\"] = gt_anno[\"attribute\"][j]\n            gt_obj_list.append(obj)\n\n    # construct pred objects\n    dt_obj_list = []\n    for frame_id, dt_anno in enumerate(dt_annos):\n        for j in range(len(dt_anno[\"name\"])):\n            obj = {}\n            obj[\"sample_token\"] = frame_id\n            obj[\"translation\"] = dt_anno[\"location\"][j]\n            obj[\"size\"] = dt_anno[\"dimensions\"][j]\n            obj[\"rotation\"] = dt_anno[\"rotation_y\"][j]\n            obj[\"velocity\"] = dt_anno[\"velocity\"][j]\n            obj[\"detection_name\"] = dt_anno[\"name\"][j]\n            obj[\"detection_score\"] = dt_anno[\"score\"][j]\n            obj[\"attribute_name\"] = dt_anno[\"attribute\"][j]\n            dt_obj_list.append(obj)\n\n    # eval\n    gt_dataset = IndoorScenesWithAllInfo(gt_obj_list)\n    dt_dataset = IndoorScenesWith"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    mAP_bbox = []\n    mAR_bbox = []\n\n    for iou_thr in metric:\n        ret = eval_map_recall(\n            gt_annos,\n            dt_annos,\n            iou_thr=iou_thr,\n            label2cat=label2cat,\n            logger=logger,\n            box_type_3d=box_type_3d,\n            box_mode_3d=box_mode_3d)\n\n        recall = ret[0]\n        precision = ret[1]\n        ap = ret[2]\n\n        mAR = 0.0\n        mAP = 0.0\n        for cat_id in ap.keys():\n            mAR += recall[cat_id][0]\n            mAP += ap[cat_id][0]\n        mAR /= len(ap.keys())\n        mAP /= len(ap.keys())\n        mAR_bbox.append(mAR)\n        mAP_bbox.append(mAP)\n\n    return mAP_bbox, mAR_bbox\n\n"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    if box_type_3d is None:\n        from .box_np_ops import points_in_rbbox\n    else:\n        points_in_rbbox = box_type_3d.points_in_rbbox\n\n    if label2cat is not None:\n        cat2label = {v: k for k, v in label2cat.items()}\n\n    gt_annos_by_cls = defaultdict(list)\n    dt_annos_by_cls = defaultdict(list)\n    gt_num_annos_by_cls = defaultdict(int)\n    dt_num_annos_by_cls = defaultdict(int)\n    for i in range(len(gt_annos)):\n        annos = gt_annos[i]\n        for anno in annos:\n            gt_annos_by_cls[anno['label_class']].append(anno)\n            gt_num_annos_by_cls[anno['label_class']] += 1\n    for i in range(len(dt_annos)):\n        annos = dt_annos[i]\n        for anno in annos:\n            dt_annos_by_cls[anno['label_class']].append(anno)\n            dt_num_annos_by_cls[anno['label_class']] += 1\n    for label in gt_annos_by_cls.keys():\n        if label not in dt_annos_by_cls.keys():\n            print(f\"Label {label} is not detected.\")\n            gt_annos_by_cls.pop(label)\n            dt_annos_by_cls[label] = []\n            dt_num_annos_by_cls[label] = 0\n    for label in dt_annos_by_cls.keys():\n        if label not in gt_annos_by_cls.keys():\n            print(f\"Label {label} is not in ground truth.\")\n            dt_annos_by_cls.pop(label)\n            gt_annos_by_cls[label] = []\n            g"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    if box_type_3d is None:\n        from .box_np_ops import center_to_corner_box3d\n        box_type_3d = center_to_corner_box3d\n\n    assert len(metric) == 1\n    assert metric[0] >= 0.0\n\n    mAP = np.zeros(len(metric))\n    mAP_bbox = np.zeros(len(metric))\n    mAP_bev = np.zeros(len(metric))\n    mAR_2d = np.zeros(len(metric))\n    mAR_bev = np.zeros(len(metric))\n\n    if logger is None:\n        logger = get_root_logger()\n\n    ret_dict = {}\n    for i, current_thresh in enumerate(metric):\n        logger.info(f'Current threshold: {current_thresh}')\n        pred_annos = []\n        gt_annos_target = []\n        for gt_anno in gt_annos:\n            gt_anno_target = dict(gt_anno)\n            gt_anno_target['name'] = label2cat[gt_anno_target['name']]\n            gt_annos_target.append(gt_anno_target)\n\n        for dt_anno in dt_annos:\n            dt_anno_target = dict(dt_anno)\n            dt_anno_target['name'] = label2cat[dt_anno_target['name']]\n            pred_annos.append(dt_anno_target)\n\n        # calculate recall and precision\n        recall, precision, ap = eval_map_recall(gt_annos_target, pred_annos,\n                                                metric=[current_thresh],\n                                                label2cat=label2cat,\n                                                box_type_3d=box_type_3d,\n                                                box_mode_3d=box_mode_3d)\n        mAP[i] = ap[0]\n        mAP_bbox[i] = ap[0]\n        mAP_be"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    # convert gt_annos and dt_annos from list[dict] to dict[list[dict]]\n    gt_dict = {}\n    dt_dict = {}\n    for gt_anno in gt_annos:\n        gt_dict.update({gt_anno['frame_id']: gt_anno})\n    for dt_anno in dt_annos:\n        dt_dict.update({dt_anno['frame_id']: dt_anno})\n\n    # get the list of classes\n    class_list = []\n    for gt_anno in gt_annos:\n        for label in gt_anno['labels']:\n            if label not in class_list:\n                class_list.append(label)\n    class_list.sort()\n\n    # get the list of IoU thresholds\n    iou_thresholds = metric\n\n    # initialize the evaluation results\n    ap_dict = {}\n    ar_dict = {}\n    for class_name in class_list:\n        ap_dict[class_name] = []\n        ar_dict[class_name] = []\n    for iou_thr in iou_thresholds:\n        ap_dict[f'mAP@{iou_thr}'] = []\n        ar_dict[f'mAR@{iou_thr}'] = []\n\n    # loop over the classes\n    for class_name in class_list:\n        gt_annos_list = []\n        dt_annos_list = []\n        for frame_id in gt_dict.keys():\n            gt_annos_list.append(gt_dict[frame_id])\n            dt_annos_list.append(dt_dict[frame_id])\n\n        # extract the bounding boxes and labels\n        gt_boxes = []\n        gt_labels = []\n        dt_boxes = []\n        dt_labels = []\n        dt_scores = []\n        for gt_anno in gt_annos_list:\n            gt_boxes.append(gt_anno['boxes'])\n            gt_"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(dt_annos) == len(gt_annos)\n    # assert box_type_3d is not None\n    # assert box_mode_3d is not None\n\n    # convert to kitti format\n    gt_annos = kitti.get_label_annos(gt_annos)\n    dt_annos = kitti.get_label_results(dt_annos)\n\n    # get class names\n    class_names = [label2cat[i] for i in range(len(label2cat))]\n\n    # get metrics\n    mAPbbox, mAPbev, mAP3d, mAPaos = do_eval(\n        gt_annos, dt_annos, label2cat, box_type_3d, box_mode_3d, metric)\n\n    # get mAP and mAR\n    mAP = mAPbbox\n    mAR = mAPbbox\n    # for i in range(len(metric)):\n    #     mAP = mAPbbox[i]\n    #     mAR = mAPbbox[i]\n    ret_dict = {}\n    # ret_dict['R11'] = mAR[0]\n    # ret_dict['R10'] = mAR[1]\n    # ret_dict['R09'] = mAR[2]\n    # ret_dict['R05'] = mAR[3]\n    # ret_dict['R01'] = mAR[4]\n    # ret_dict['mAR'] = sum(mAR[0:5]) / 5.0\n    ret_dict['mAP'] = mAP[0]\n    ret_dict['mAR'] = mAR[0]\n\n    # get mAP and mAR for each class\n    mAPbbox_dict = {}\n    mARbbox_dict = {}\n    mAPbev_dict = {}\n    mARbev_dict = {}\n    mAP3d_dict = {}\n    mAR3d_dict = {}\n    mAPaos_dict = {}\n    mAP2d"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(dt_annos) == len(gt_annos)\n    assert len(dt_annos) > 0\n\n    num_cats = len(label2cat)\n    num_thresh = len(metric)\n    num_samples = len(gt_annos)\n\n    gt_num = [0] * num_cats\n    dt_num = [0] * num_cats\n    hit_num = [0] * num_cats\n\n    gt_boxes = [[] for i in range(num_cats)]\n    dt_boxes = [[] for i in range(num_cats)]\n\n    for dt_anno, gt_anno in zip(dt_annos, gt_annos):\n        for i in range(num_cats):\n            gt_boxes[i] += gt_anno['gt_boxes_3d'][i]\n            dt_boxes[i] += dt_anno['boxes_3d'][i]\n            gt_num[i] += len(gt_anno['gt_boxes_3d'][i])\n            dt_num[i] += len(dt_anno['boxes_3d'][i])\n\n    for i in range(num_cats):\n        gt_boxes[i] = np.array(gt_boxes[i], dtype=np.float32)\n        dt_boxes[i] = np.array(dt_boxes[i], dtype=np.float32)\n\n    # calculate mAP\n    mAP = np.zeros(num_thresh, dtype=np.float32)\n    mAR = np.zeros(num_thresh, dtype=np.float32)\n    for i in range(num_cats):\n        for j in range(num_thresh):\n            mAP[j] += cal_map(dt_boxes[i], gt_boxes[i], metric[j])\n            mAR[j] += cal_ar(dt_boxes[i], gt_boxes[i], metric"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(metric) == 1\n    assert metric[0] == 0.7\n\n    mAP_list = []\n    mAP_list_R40 = []\n    mAR_list = []\n    mAR_list_R40 = []\n    # init the result dict\n    ret_dict = {}\n    for i in range(len(metric)):\n        mAP_list.append({})\n        mAP_list_R40.append({})\n        mAR_list.append({})\n        mAR_list_R40.append({})\n    # check whether it is a dataset with GT annotations\n    if len(gt_annos) == 0:\n        for i in range(len(metric)):\n            mAP_list[i]['Overall'] = 0.0\n            mAP_list_R40[i]['Overall'] = 0.0\n            mAR_list[i]['Overall'] = 0.0\n            mAR_list_R40[i]['Overall'] = 0.0\n        return\n\n    # start evaluation\n    for i in range(len(metric)):\n        for cur_cls in label2cat.values():\n            mAP_list[i][cur_cls] = []\n            mAR_list[i][cur_cls] = []\n            mAP_list_R40[i][cur_cls] = []\n            mAR_list_R40[i][cur_cls] = []\n\n    for i in range(len(metric)):\n        gt_annos_cls = {}\n        dt_annos_cls = {}\n        for cur_cls in label2cat.values():\n            gt_annos_cls[cur_cls] = []\n            dt_annos_cls[cur_cls] = []\n        for gt_anno in gt_annos:\n            gt_anno = gt_anno.copy()\n            for i in range(len(gt_anno['gt_names'])):\n                gt_anno['gt_names'][i] = label2cat[gt_anno['gt_names']"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    # Evaluate the detections and get the results.\n    results = eval_map_recall(\n        gt_annos, dt_annos, metric, label2cat, box_type_3d=box_type_3d)\n\n    # Compute the metrics for each class.\n    mAP_bbox = 0.0\n    mAR_bbox = 0.0\n    for name, rec_prec in results.items():\n        # Compute the average precision and recall.\n        ap = np.array([x['ap'] for x in rec_prec])\n        ar = np.array([x['recall'] for x in rec_prec])\n        # Compute the mean AP and AR.\n        mAP_bbox += ap.mean()\n        mAR_bbox += ar.mean()\n        # Print the results.\n        print_log(f'{name} AP: {ap.mean()}, AR: {ar.mean()}, '\n                  f'number of gt {len(rec_prec[0][\"recall\"])}.', logger=logger)\n\n    # Compute the mean AP and AR.\n    mAP_bbox = mAP_bbox / len(results)\n    mAR_bbox = mAR_bbox / len(results)\n    # Print the mean AP and AR.\n    print_log(f'mAP: {mAP_bbox}, mAR: {mAR_bbox}', logger=logger)\n\n    # Compute the overall metrics.\n    mAP = np.array([x['ap'] for x in results['OVERALL']]).mean()\n    mAR = np.array([x['recall'] for x in results['OVERALL']]).mean()\n    # Print the overall metrics.\n    print_log(f'Overall AP: {mAP}, Overall AR: {mAR}', logger=logger)\n\n    # Organize the results into a table.\n    table_data = [['category', 'AP', 'AR']]\n    for name, rec_prec in results.items():\n        if name == 'OVERALL':\n           "}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(dt_annos) == len(gt_annos)\n\n    if box_type_3d is None:\n        from .box_np_ops import center_to_corner_box3d\n        box_type_3d = center_to_corner_box3d\n\n    if box_mode_3d is None:\n        box_mode_3d = 'lidar'\n\n    if logger is None:\n        logger = common_utils.create_logger('indoor_eval.eval_utils', rank=0)\n\n    logger.info('Evaluating the detection results ...')\n    result = OrderedDict()\n    ap_dict = OrderedDict()\n    recall_dict = OrderedDict()\n    precision_dict = OrderedDict()\n    for classname in gt_annos[0]['gt_names']:\n        # precision: [N, num_thresh]\n        # recall:    [N, num_thresh]\n        # AP: [num_thresh]\n        # AR: [num_thresh]\n        precision, recall, ap, ar = eval_map_recall(\n            gt_annos, dt_annos, metric, label2cat, box_type_3d, box_mode_3d, classname)\n\n        # calculate the number of gt objects\n        num_gt_objects = np.sum([len(x['gt_names']) for x in gt_annos])\n\n        ap_dict[classname] = ap\n        recall_dict[classname] = {\n            iou: recall[idx]\n            for idx, iou in enumerate(metric)\n        }\n        precision_dict[classname] = {\n            iou: precision[idx]\n            for idx, iou in enumerate(metric)\n        }\n\n        logger.info(\n            f\"{classname} Nums of GT objects: {num_gt_objects}, Recall: {recall}, Precision: {precision}, AP: {ap}\")\n\n        f2 = lambda x: \"{:.4f}\".format(x)\n        ret_dict"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(dt_annos) == len(gt_annos)\n\n    # get the list of classes\n    class_names = [label2cat[label] for label in label2cat]\n    num_classes = len(class_names)\n\n    # get the list of classes\n    class_names = [label2cat[label] for label in label2cat]\n    num_classes = len(class_names)\n\n    # construct gt_annos and dt_annos.\n    # Note that gt_annos and dt_annos are lists of lists of annotations.\n    # The outer lists are for different classes, and the inner lists are for\n    # different images.\n    gt_annos_list = [[] for i in range(num_classes)]\n    dt_annos_list = [[] for i in range(num_classes)]\n    for i in range(len(dt_annos)):\n        dt_annos_list[dt_annos[i]['labels']] = dt_annos[i]\n    for i in range(len(gt_annos)):\n        gt_annos_list[gt_annos[i]['labels']] = gt_annos[i]\n\n    # construct gt_annos_dict and dt_annos_dict.\n    # Note that gt_annos_dict and dt_annos_dict are dicts of lists of lists of annotations.\n    # The keys are the classes, and the inner lists are for different images.\n    gt_annos_dict = {}\n    dt_annos_dict = {}\n    for i in range(num_classes):\n        gt_annos_dict[class_names[i]] = gt_annos_list[i]\n        dt_annos_dict[class_names[i]] = dt_annos_list[i]\n\n    # compute the mAP and mAR for each class\n    mAP = np.zeros(num_classes)\n    mAR = np.zeros(num_classes)\n    for i in range(num_classes):\n        gt_annos = gt"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(dt_annos) == len(gt_annos)\n    assert len(metric) > 0\n    assert box_type_3d is not None and box_mode_3d is not None\n\n    if logger is None:\n        logger = get_root_logger()\n\n    # start logging\n    logger.info(f'Evaluating detection performance...')\n\n    # get the list of classes\n    class_list = [\n        'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',\n        'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'\n    ]\n\n    # get the list of labels\n    label_list = [label2cat[k] for k in label_list]\n\n    # get the list of indices\n    label_indices = [label2cat[k] for k in label_list]\n\n    # get the list of IoU thresholds\n    iou_thresholds = metric\n\n    # get the list of metric names\n    metric_names = metric\n\n    # get the list of metric keys\n    metric_keys = metric\n\n    # initialize the list of dictionaries for holding the evaluation results\n    det_results = [{} for i in range(len(metric_keys))]\n\n    # initialize the list of dictionaries for holding the evaluation results\n    ae_results = [{} for i in range(len(metric_keys))]\n\n    # initialize the list of dictionaries for holding the evaluation results\n    ae_results_wo_occ = [{} for i in range(len(metric_keys))]\n\n    # initialize the list of dictionaries for holding the evaluation results\n    ae_results_wo_det = [{} for i in range(len(metric_keys))]\n\n    # initialize the list of dictionaries for holding the evaluation results\n    ae_results_pred = [{} for i in range(len(metric_keys))]\n\n    # initialize the list of dictionaries for holding the evaluation results\n    ae_results_pred_wo_occ = [{} for i in range(len(metric_keys"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(dt_annos) == len(gt_annos)\n    # assert box_type_3d is not None\n    # assert box_mode_3d is not None\n\n    # if logger is None:\n    #     logger = logging.getLogger()\n\n    # if box_type_3d is not None:\n    #     box_type_3d = BOX_MODEL[box_type_3d]\n    #     box_mode_3d = BOX_MODE[box_mode_3d]\n\n    # check if the input annotations are in the right format\n    # assert check_numpy_to_scalar(dt_annos)\n    # assert check_numpy_to_scalar(gt_annos)\n\n    # if not isinstance(metric, list):\n    #     metric = [metric]\n\n    # if not isinstance(metric, list):\n    #     metric = [metric]\n\n    # if not metric:\n    #     metric = [0.7, 0.5, 0.75]\n\n    # get the number of classes\n    # class_num = len(label2cat)\n    # class_names = list(label2cat.values())\n\n    # print the mAP and mAR summary\n    # result = OrderedDict()\n    # result['class_names'] = class_names\n    # result['bbox'] = {}\n    # result['bev'] = {}\n    # result['3d'] = {}\n\n    # # evaluate by classes\n    # for class_id, class_name in enumerate(class_names):\n    #     # prepare gt and dt annotations for evaluation\n    #     gt_anno = [\n    #         deepcopy(anno) for anno in gt_annos if anno['name'] == class_name\n    #     ]\n    #     dt_anno = [\n    #         deepcopy(anno) for anno in dt_annos if anno['name'] == class_name\n    #     ]\n    #     # assert len(gt_anno)\n    #     # assert len(dt_anno)\n\n    #    "}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    if logger is None:\n        logger = get_root_logger()\n\n    assert len(dt_annos) == len(gt_annos)\n    num_examples = len(gt_annos)\n\n    # get the list of classes\n    classes = list(label2cat.values())\n\n    # get the list of class ids\n    class_ids = list(label2cat.keys())\n\n    # initialize the list of class-wise metrics\n    class_aps = [[] for i in range(len(classes))]\n    class_ar = [[] for i in range(len(classes))]\n\n    # initialize the overall metrics\n    overall_aps = []\n    overall_ar = []\n\n    for i in range(len(metric)):\n        # initialize the dicts for the current IoU threshold\n        gt_annos_iou = {}\n        dt_annos_iou = {}\n        for j in range(num_examples):\n            gt_annos_iou[j] = []\n            dt_annos_iou[j] = []\n\n        # iterate over the images\n        for j in range(num_examples):\n            # filter the ground truth annotations and detection annotations based on the current IoU threshold\n            gt_annos_iou[j] = filter_by_min_points(gt_annos[j], min_points=5)\n            dt_annos_iou[j] = filter_by_min_points(dt_annos[j], min_points=5)\n\n            # convert the bounding boxes from box_type_3d to box_type_3d\n            gt_annos_iou[j] = box_type_3d.convert(gt_annos_iou[j], box_mode_3d,\n                                                  box_type_3d)\n            dt_annos_iou[j] = box_type_3d.convert(dt_annos_iou[j], box_mode_3d,\n                                                  box_type_3d)\n\n            # sort the detection annotations based on the scores\n            dt_annos"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        box_class = LiDARInstance3DBoxes\n        box_mode = Box3DMode.LIDAR\n    elif box_type == 'Camera':\n        box_class = CameraInstance3DBoxes\n        box_mode = Box3DMode.DEPTH\n    elif box_type == 'Depth':\n        box_class = DepthInstance3DBoxes\n        box_mode = Box3DMode.DEPTH\n    else:\n        raise ValueError('Only \"box_type\" of \"LiDAR\", \"Camera\", or \"Depth\" '\n                         f'are supported, got {box_type}')\n\n    return box_class, box_mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        box_class = LiDARInstance3DBoxes\n        box_mode = Box3DMode.LIDAR\n    elif box_type == 'Camera':\n        box_class = CameraInstance3DBoxes\n        box_mode = Box3DMode.DEPTH\n    elif box_type == 'Depth':\n        box_class = DepthInstance3DBoxes\n        box_mode = Box3DMode.DEPTH\n    else:\n        raise ValueError('Only \"box_type\" of \"LiDAR\", \"Camera\", or \"Depth\" '\n                         f'are supported, got {box_type}')\n\n    return box_class, box_mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        box_type_3d = LiDARInstance3DBoxes\n        box_mode_3d = Box3DMode.LIDAR\n    elif box_type == 'Camera':\n        box_type_3d = CameraInstance3DBoxes\n        box_mode_3d = Box3DMode.CAM\n    elif box_type == 'Depth':\n        box_type_3d = DepthInstance3DBoxes\n        box_mode_3d = Box3DMode.DEPTH\n    else:\n        raise ValueError('Only \"box_type\" of \"LiDAR\", \"Camera\", or \"Depth\" '\n                         f'are supported, got {box_type}')\n\n    return box_type_3d, box_mode_3d\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        box_type_3d = Box3D\n        box_mode_3d = Box3DMode.LIDAR\n    elif box_type == 'Camera':\n        box_type_3d = Box3D\n        box_mode_3d = Box3DMode.CAM\n    elif box_type == 'Depth':\n        box_type_3d = DepthInstance3DBoxes\n        box_mode_3d = Box3DMode.DEPTH\n    else:\n        raise ValueError('Input box type is not recognized ' + box_type)\n\n    return box_type_3d, box_mode_3d\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        box_type_3d = 'LiDAR'\n        box_mode_3d = 'LIDAR'\n    elif box_type == 'Camera':\n        box_type_3d = 'Camera'\n        box_mode_3d = 'CAM'\n    elif box_type == 'Depth':\n        box_type_3d = 'Depth'\n        box_mode_3d = 'DEPTH'\n    else:\n        raise TypeError('Input box type is not recognized')\n\n    return box_type_3d, box_mode_3d\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        box_type_3d = LiDARInstance3DBoxes\n        box_mode_3d = Box3DMode.LIDAR\n    elif box_type == 'Camera':\n        box_type_3d = CameraInstance3DBoxes\n        box_mode_3d = Box3DMode.CAM\n    elif box_type == 'Depth':\n        box_type_3d = DepthInstance3DBoxes\n        box_mode_3d = Box3DMode.DEPTH\n    else:\n        raise TypeError('3D box type {} is not supported'.format(box_type))\n\n    return box_type_3d, box_mode_3d\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        box_type_3d = Box3D\n        box_mode_3d = Box3DMode.LIDAR\n    elif box_type == 'Camera':\n        box_type_3d = Box3D\n        box_mode_3d = Box3DMode.CAM\n    elif box_type == 'Depth':\n        box_type_3d = DepthInstance3DBoxes\n        box_mode_3d = Box3DMode.DEPTH\n    else:\n        raise ValueError('Input box type is not recognized' + str(box_type))\n\n    return box_type_3d, box_mode_3d\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        box_class = LiDARInstance3DBoxes\n        box_mode = Box3DMode.LIDAR\n    elif box_type == 'Camera':\n        box_class = CameraInstance3DBoxes\n        box_mode = Box3DMode.DEPTH\n    elif box_type == 'Depth':\n        box_class = DepthInstance3DBoxes\n        box_mode = Box3DMode.DEPTH\n    else:\n        raise ValueError('Only \"box_type\" of \"LiDAR\", \"Camera\", or \"Depth\" '\n                         f'are supported, got {box_type}')\n\n    return box_class, box_mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        box_class = LiDARInstance3DBoxes\n        box_mode = Box3DMode.LIDAR\n    elif box_type == 'Camera':\n        box_class = CameraInstance3DBoxes\n        box_mode = Box3DMode.DEPTH\n    elif box_type == 'Depth':\n        box_class = DepthInstance3DBoxes\n        box_mode = Box3DMode.DEPTH\n    else:\n        raise ValueError('Only \"box_type\" of \"LiDAR\", \"Camera\", or \"Depth\" '\n                         f'are supported, got {box_type}')\n\n    return box_class, box_mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        return Box3D, 'lidar'\n    elif box_type == 'Camera':\n        return CameraInstance3DBoxes, 'camera'\n    elif box_type == 'Depth':\n        return DepthInstance3DBoxes, 'depth'\n    else:\n        raise ValueError('Only \"box_type\" of \"camera\", \"lidar\", \"depth\"'\n                         f' are supported, got {box_type}')\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        box_type_3d = Box3D\n        box_mode_3d = Box3DMode.LIDAR\n    elif box_type == 'Camera':\n        box_type_3d = Box3D\n        box_mode_3d = Box3DMode.CAM\n    elif box_type == 'Depth':\n        box_type_3d = DepthInstance3DBoxes\n        box_mode_3d = Box3DMode.DEPTH\n    else:\n        raise TypeError('Input box type is not recognized ' + box_type)\n\n    return box_type_3d, box_mode_3d\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        box_dim = 7\n        box_mode = 'LIDAR'\n        box_cls = 'LiDARInstance3DBoxes'\n    elif box_type == 'Camera':\n        box_dim = 7\n        box_mode = 'CAM'\n        box_cls = 'CameraInstance3DBoxes'\n    elif box_type == 'Depth':\n        box_dim = 7\n        box_mode = 'DEPTH'\n        box_cls = 'DepthInstance3DBoxes'\n    else:\n        raise ValueError('Input box type is not recognized' + \\\n            'only \"box_type\" of \"LiDAR\", \"Camera\", or \"Depth\" is supported')\n\n    return eval(box_cls), box_mode, box_dim\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        return Box3D, Box3DMode.LIDAR\n    elif box_type == 'Camera':\n        return Box3D, Box3DMode.CAM\n    elif box_type == 'Depth':\n        return DepthInstance3DBoxes, Box3DMode.DEPTH\n    else:\n        raise ValueError('Only \"box_type\" of \"LiDAR\" and \"Camera\" and \"Depth\"'\n                         f' are supported, got {box_type}')\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        return Box3D, 'lidar'\n    elif box_type == 'Camera':\n        return CameraInstance3DBoxes, 'camera'\n    elif box_type == 'Depth':\n        return DepthInstance3DBoxes, 'depth'\n    else:\n        raise ValueError('Only \"box_type\" of \"LiDAR\", \"Camera\", or \"Depth\" '\n                         f'are supported, got {box_type}')\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        box_dim = 7\n        box_mode = Box3DMode.LIDAR\n    elif box_type == 'Camera':\n        box_dim = 7\n        box_mode = Box3DMode.CAM\n    elif box_type == 'Depth':\n        box_dim = 7\n        box_mode = Box3DMode.DEPTH\n    else:\n        raise ValueError('Invalid box type: ' + box_type + '.')\n\n    return box_dim, box_mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        box_class = LiDARInstance3DBoxes\n        box_mode = Box3DMode.LIDAR\n    elif box_type == 'Camera':\n        box_class = CameraInstance3DBoxes\n        box_mode = Box3DMode.CAM\n    elif box_type == 'Depth':\n        box_class = DepthInstance3DBoxes\n        box_mode = Box3DMode.DEPTH\n    else:\n        raise ValueError('Only \"box_type\" of \"camera\", \"lidar\", \"depth\"'\n                         f' are supported, got {box_type}')\n\n    return box_class, box_mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        return LiDARInstance3DBoxes, Box3DMode.LIDAR\n    elif box_type == 'Camera':\n        return CameraInstance3DBoxes, Box3DMode.CAM\n    elif box_type == 'Depth':\n        return DepthInstance3DBoxes, Box3DMode.DEPTH\n    else:\n        raise ValueError('Only \"box_type\" of \"LiDAR\", \"Camera\", or \"Depth\" '\n                         f'are supported, got {box_type}')\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        box_dim = 7\n        box_mode = 'LIDAR'\n        box_type = 'LiDAR_box'\n    elif box_type == 'Camera':\n        box_dim = 7\n        box_mode = 'CAM'\n        box_type = 'Camera_box'\n    elif box_type == 'Depth':\n        box_dim = 7\n        box_mode = 'LIDAR'\n        box_type = 'Depth_box'\n    else:\n        raise ValueError('Invalid box type is given.')\n\n    return eval(box_type), box_dim, box_mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        box_type_3d = Box3D\n        box_mode_3d = Box3DMode.LIDAR\n    elif box_type == 'Camera':\n        box_type_3d = Box3D\n        box_mode_3d = Box3DMode.CAM\n    elif box_type == 'Depth':\n        box_type_3d = Box3D\n        box_mode_3d = Box3DMode.DEPTH\n    else:\n        raise ValueError('Input box type should be one of '\n                         '\"LiDAR\", \"CAM\", or \"DEPTH\"')\n    return box_type_3d, box_mode_3d\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        return Box3D, 'lidar'\n    elif box_type == 'Camera':\n        return CameraInstance3DBoxes, 'camera'\n    elif box_type == 'Depth':\n        return DepthInstance3DBoxes, 'depth'\n    else:\n        raise ValueError('Only \"box_type\" of \"camera\", \"lidar\", \"depth\"'\n                         f' are supported, got {box_type}')\n\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages is None:\n      messages = []\n\n    if not isinstance(messages, list):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    if not all(isinstance(message, Message) or isinstance(message, Mapping) for message in messages):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [_encode_message(message) for message in messages],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages is None:\n      messages = []\n\n    if not isinstance(messages, list):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    if not all(isinstance(message, (dict, Message)) for message in messages):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [\n          {\n            'role': message.role,\n            'content': message.content,\n            'images': [_encode_image(image) for image in message.images] if isinstance(message, Message) else [message.get('image')],\n          }\n          for message in messages\n        ],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      if not isinstance(messages, list):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n\n      messages = [\n        _encode_message(message)\n        for message in messages\n      ]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      raise RequestError('must provide messages')\n\n    try:\n      messages = [Message(**message) for message in messages]\n    except TypeError:\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      raise RequestError('must provide messages')\n\n    try:\n      messages = [Message(**message) for message in messages]\n    except TypeError:\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      messages = []\n\n    for message in messages:\n      if not isinstance(message, Message) and not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n\n      if 'role' not in message:\n        raise RequestError('messages must contain a role')\n\n      if 'content' not in message:\n        raise RequestError('messages must contain content')\n\n      if 'images' in message:\n        message['images'] = [_encode_image(image) for image in message['images']]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages is not None:\n      if not isinstance(messages, list):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n\n      for message in messages:\n        if not isinstance(message, Message):\n          message = Message(**message)\n\n        if 'images' in message:\n          message['images'] = [_encode_image(image) for image in message['images']]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      raise RequestError('must provide messages')\n\n    if not isinstance(messages, Sequence):\n      raise TypeError('messages must be a sequence')\n\n    if not all(isinstance(m, (dict, Message)) for m in messages):\n      raise TypeError('messages must be a sequence of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [_encode_message(message) for message in messages],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      try:\n        messages = [\n          {\n            'role': message['role'],\n            'content': message['content'],\n            'images': [_encode_image(image) for image in message.get('images', [])],\n          }\n          for message in messages\n        ]\n      except (TypeError, KeyError):\n        raise RequestError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      if not isinstance(messages, list):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n\n      for message in messages:\n        if not isinstance(message, Message) and not isinstance(message, dict):\n          raise TypeError('messages must be a list of Message or dict-like objects')\n\n        if not message.get('role') or not message.get('content'):\n          raise RequestError('messages must contain a \"role\" and \"content\"')\n\n        if 'images' in message and not isinstance(message['images'], list):\n          raise TypeError('images must be a list of str, bytes, or PathLike')\n\n        message['images'] = [_encode_image(image) for image in message.get('images') or []]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      if isinstance(messages, list):\n        for message in messages:\n          if not isinstance(message, Message):\n            raise TypeError('messages must be a list of Message or dict-like objects')\n      else:\n        raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      raise RequestError('must provide messages')\n\n    try:\n      messages = [\n        {\n          'role': message['role'],\n          'content': message['content'],\n          'images': [_encode_image(image) for image in message.get('images', [])],\n        }\n        for message in messages\n      ]\n    except (KeyError, TypeError):\n      raise RequestError('messages must be a list of dicts with the keys \"role\" and \"content\"')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      messages = []\n\n    if not isinstance(messages, list):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    for i, message in enumerate(messages):\n      if not isinstance(message, Message):\n        try:\n          messages[i] = Message(**message)\n        except TypeError as e:\n          raise TypeError(f'messages[{i}] must be a Message or dict-like object') from None\n\n      if 'images' in message:\n        messages[i].images = [_encode_image(image) for image in message.images]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      raise RequestError('must provide messages')\n\n    if not isinstance(messages, list):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    messages = [\n      _encode_message(message)\n      for message in messages\n    ]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages is not None and not isinstance(messages, Sequence):\n      raise TypeError('messages must be a sequence of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [\n          {\n            'role': message.role,\n            'content': message.content,\n            'images': [_encode_image(image) for image in message.images or []],\n          }\n          if isinstance(message, Message)\n          else message\n          for message in messages or []\n        ],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      for message in messages:\n        if not isinstance(message, Message):\n          raise TypeError('messages must be a list of Message or dict-like objects')\n\n        if 'images' in message:\n          message['images'] = [_encode_image(image) for image in message['images']]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages is not None:\n      if not isinstance(messages, list):\n        raise TypeError('messages must be a list')\n\n      for message in messages:\n        if not isinstance(message, dict):\n          raise TypeError('messages must be a list of dicts')\n\n        if 'role' not in message:\n          raise RequestError('messages must have a role')\n\n        if message['role'] not in ['system', 'user', 'assistant']:\n          raise RequestError('messages must have a role of \"system\", \"user\", or \"assistant\"')\n\n        if 'content' not in message:\n          raise RequestError('messages must have content')\n\n        if 'images' in message:\n          message['images'] = [_encode_image(image) for image in message['images']]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages is None:\n      messages = []\n\n    if not isinstance(messages, list):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    if any(not isinstance(message, (Message, dict)) for message in messages):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [\n          {\n            'role': message.get('role'),\n            'content': message.get('content'),\n            'images': [_encode_image(image) for image in message.get('images', [])],\n          }\n          for message in messages\n        ],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      if not all(isinstance(message, Message) or isinstance(message, dict) for message in messages):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      messages = [Message(**message) for message in messages]\n      for message in messages:\n        if 'images' in message:\n          message['images'] = [_encode_image(image) for image in message['images']]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      if isinstance(messages, list):\n        messages = list(messages)\n        for i, message in enumerate(messages):\n          if isinstance(message, Message):\n            message = dict(message)\n            messages[i] = message\n          if not isinstance(message, dict):\n            raise TypeError('messages must be a list of Message or dict-like objects')\n          if not message.get('role'):\n            raise RequestError('messages must include a role')\n          if not message.get('content'):\n            raise RequestError('messages must include content')\n          if 'images' in message:\n            message['images'] = [_encode_image(image) for image in message['images']]\n      else:\n        raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    response = self._request(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n    )\n\n    if stream:\n      return (ProgressResponse(r) for r in response.iter_lines())\n    else:\n      return ProgressResponse(response)\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    response = self._request(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n    )\n\n    if stream:\n      return (\n        ProgressResponse(**r)\n        for r in response.json()\n      )\n    else:\n      return ProgressResponse(**response.json())\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    response = self._request(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=True,\n    )\n\n    if stream:\n      return _stream_progress(response)\n    else:\n      return _parse_progress(response)\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    response = self._request(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n\n    if stream:\n      return (\n        ProgressResponse(message)\n        for message in response.iter_lines()\n        if message\n      )\n\n    return ProgressResponse(response.text)\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context or [],\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream(\n      'POST',\n      '/generate',\n      json=data,\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('Model is required.')\n\n    if context is None:\n      context = []\n\n    if images is None:\n      images = []\n\n    if options is None:\n      options = {}\n\n    if keep_alive is None:\n      keep_alive = ''\n\n    return self._request_stream(\n      'POST',\n      '/generate',\n      stream=stream,\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context,\n        'raw': raw,\n        'format': format,\n        'images': images,\n        'options': options,\n        'keep-alive': keep_alive,\n      },\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    params = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    if images:\n      params['images'] = images\n\n    return self._request_stream(\n      'POST',\n      'generate',\n      stream=stream,\n      json=params,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if model == '':\n      raise RequestError('Model is required')\n\n    params = {\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream(\n      'POST',\n      f'/models/{model}/generate',\n      params=params,\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('Model is required')\n\n    if images is not None:\n      images = [self._encode_image(i) for i in images]\n\n    return self._request_stream(\n      'POST',\n      'generate',\n      stream=stream,\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context,\n        'raw': raw,\n        'format': format,\n        'images': images,\n        'options': options,\n        'keep_alive': keep_alive,\n      },\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('Model is required')\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context or [],\n      'raw': raw,\n      'format': format,\n    }\n\n    if images is not None:\n      data['images'] = [\n        _encode_image(image)\n        for image in images\n      ]\n\n    if options is not None:\n      data['options'] = options\n\n    if keep_alive is not None:\n      data['keep_alive'] = keep_alive\n\n    return self._request_stream(\n      'POST',\n      'generate',\n      stream=stream,\n      json=data,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('Model is required.')\n\n    params = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep-alive': keep_alive,\n    }\n\n    return self._request_stream(\n      'POST',\n      '/generate',\n      stream=stream,\n      json=params,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if model == '':\n      raise RequestError('model must be provided')\n\n    if context is None:\n      context = []\n\n    if images is None:\n      images = []\n\n    if options is None:\n      options = {}\n\n    if keep_alive is None:\n      keep_alive = ''\n\n    return self._request_stream(\n      'POST',\n      'generate',\n      stream=stream,\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context,\n        'raw': raw,\n        'format': format,\n        'images': images,\n        'options': options,\n        'keep_alive': keep_alive,\n      },\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model must be provided')\n\n    if options is None:\n      options = {}\n\n    if context is None:\n      context = []\n\n    if images is None:\n      images = []\n\n    if keep_alive is not None:\n      options['keep_alive'] = keep_alive\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'options': options,\n    }\n\n    if images:\n      data['images'] = images\n\n    return self._request_stream(\n      'POST',\n      '/generate',\n      data=data,\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    if context is None:\n      context = []\n\n    if images is None:\n      images = []\n\n    if options is None:\n      options = {}\n\n    if keep_alive is None:\n      keep_alive = 'close'\n\n    if isinstance(keep_alive, float):\n      keep_alive = str(keep_alive)\n\n    if format not in ['', 'json']:\n      raise RequestError(f'invalid format: {format}')\n\n    if format == 'json':\n      format = 'application/json'\n    else:\n      format = 'text/plain'\n\n    return self._request_stream(\n      'POST',\n      '/generate',\n      stream=stream,\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context,\n        'raw': raw,\n        'format': format,\n        'images': images,\n        'options': options,\n        'keep_alive': keep_alive,\n      },\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if model == '':\n      raise RequestError('Model is required.')\n\n    if context is None:\n      context = []\n\n    if images is None:\n      images = []\n\n    if options is None:\n      options = {}\n\n    if keep_alive is None:\n      keep_alive = ''\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream(\n      'POST',\n      '/generate',\n      data=data,\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    if not isinstance(model, str):\n      raise RequestError('model must be a string')\n\n    if not isinstance(prompt, str):\n      raise RequestError('prompt must be a string')\n\n    if not isinstance(system, str):\n      raise RequestError('system must be a string')\n\n    if not isinstance(template, str):\n      raise RequestError('template must be a string')\n\n    if context is not None and not isinstance(context, Sequence):\n      raise RequestError('context must be a sequence')\n\n    if not isinstance(stream, bool):\n      raise RequestError('stream must be a boolean')\n\n    if not isinstance(raw, bool):\n      raise RequestError('raw must be a boolean')\n\n    if format not in ['', 'json']:\n      raise RequestError('format must be an empty string or \"json\"')\n\n    if images is not None and not isinstance(images, Sequence):\n      raise RequestError('images must be a sequence')\n\n    if options is not None and not isinstance(options, Options):\n      raise RequestError('options must be an Options object')\n\n    if keep_alive is not None and not isinstance(keep_alive, (float, str)):\n      raise RequestError('keep_alive must be a float or a string')\n\n    if images is not None:\n      images = [\n        _get_file(image, 'image')\n        for image in images\n      ]\n\n    if options is not None:\n      options = options.dict()\n\n    return self._request_stream(\n      'POST',\n      'generate',\n      stream=stream,\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context,\n        'raw': raw,\n        'format': format,\n        'images': images,\n        'options': options,\n        'keep_alive': keep_alive,\n      },\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream(\n      'POST',\n      '/generate',\n      stream=stream,\n      json=data,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if model == '':\n      raise RequestError('Model is required.')\n\n    if context is None:\n      context = []\n\n    if images is None:\n      images = []\n\n    if options is None:\n      options = {}\n\n    if keep_alive is None:\n      keep_alive = ''\n\n    if format not in ['', 'json']:\n      raise RequestError(f'Invalid format: {format}.')\n\n    if format == '':\n      format = 'json'\n\n    if keep_alive == '':\n      keep_alive = 0\n\n    if isinstance(keep_alive, str):\n      try:\n        keep_alive = float(keep_alive)\n      except ValueError:\n        raise RequestError(f'Invalid keep-alive: {keep_alive}.')\n\n    if keep_alive < 0:\n      raise RequestError(f'Invalid keep-alive: {keep_alive}.')\n\n    return self._request_stream(\n      'POST',\n      '/generate',\n      stream=stream,\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context,\n        'raw': raw,\n        'format': format,\n        'images': [\n          _encode_image(image)\n          for image in images\n        ],\n        'options': options,\n        'keep_alive': keep_alive,\n      },\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream(\n      'POST',\n      'generate',\n      json=data,\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('Model not provided')\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context or [],\n      'raw': raw,\n      'format': format,\n    }\n\n    if images:\n      data['images'] = _encode_images(images)\n\n    if options:\n      data['options'] = options\n\n    if keep_alive is not None:\n      data['keep_alive'] = keep_alive\n\n    return self._request_stream(\n      'POST',\n      'generate',\n      json=data,\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    if context is None:\n      context = []\n\n    if images is None:\n      images = []\n\n    if options is None:\n      options = {}\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream(\n      'POST',\n      '/generate',\n      json=data,\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    if not context:\n      context = []\n\n    if not images:\n      images = []\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    if images:\n      files = {}\n      for i, image in enumerate(images):\n        if isinstance(image, str):\n          if not Path(image).exists():\n            raise RequestError(f'image {i} does not exist')\n          files[f'images.{i}'] = open(image, 'rb')\n        elif isinstance(image, (bytes, bytearray)):\n          files[f'images.{i}'] = io.BytesIO(image)\n        elif isinstance(image, (PathLike, Path)):\n          if not Path(image).exists():\n            raise RequestError(f'image {i} does not exist')\n          files[f'images.{i}'] = open(image, 'rb')\n        else:\n          raise RequestError(f'image {i} is not a valid image')\n\n      return self._request_stream(\n        'POST',\n        '/generate',\n        stream=stream,\n        files=files,\n        data={'data': json.dumps(data)},\n      )\n    else:\n      return self._request_stream(\n        'POST',\n        '/generate',\n        stream=stream,\n        json=data,\n      )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('Model must be provided.')\n\n    if not options:\n      options = {}\n\n    if images:\n      images = [\n        _encode_image(image)\n        for image in images\n      ]\n\n    if context:\n      context = list(context)\n\n    if keep_alive:\n      keep_alive = str(keep_alive)\n\n    response = self._request_stream(\n      'POST',\n      f'/generate/{model}',\n      stream=stream,\n      json={\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context,\n        'raw': raw,\n        'format': format,\n        'images': images,\n        'options': options,\n        'keep_alive': keep_alive,\n      },\n    )\n\n    if stream:\n      return response\n\n    if e := response.get('error'):\n      raise ResponseError(e)\n\n    return response\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('Model is required')\n\n    if format not in ['', 'json']:\n      raise RequestError('Invalid format')\n\n    if isinstance(keep_alive, str):\n      try:\n        keep_alive = float(keep_alive)\n      except ValueError:\n        raise RequestError('Invalid keep_alive')\n\n    if isinstance(images, Sequence):\n      images = [self._encode_image(image) for image in images]\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream(\n      'POST',\n      '/generate',\n      stream=stream,\n      json=data,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not (path or modelfile):\n      raise RequestError('must provide a path or modelfile')\n\n    if path:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not (path or modelfile):\n      raise RequestError('must provide either path or modelfile')\n\n    if path:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide a path or modelfile')\n\n    if path:\n      modelfile = Path(path).read_text()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide a path or modelfile')\n\n    if path:\n      with open(path, 'r') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide a path or modelfile')\n\n    if path:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide either a path or modelfile')\n\n    if path:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not (path or modelfile):\n      raise RequestError('must provide a path or modelfile')\n\n    if path:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide path or modelfile')\n\n    if path:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not path and not modelfile:\n      raise RequestError('must provide a path or modelfile')\n\n    if path:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not (path or modelfile):\n      raise RequestError('must provide either a path or modelfile')\n\n    if path:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not (path or modelfile):\n      raise RequestError('must provide a path or modelfile')\n\n    if path:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not (path or modelfile):\n      raise RequestError('must provide either a path or modelfile')\n\n    if path:\n      modelfile = Path(path).read_text()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if path and modelfile:\n      raise RequestError('must provide either a path or a modelfile, not both')\n\n    if not path and not modelfile:\n      raise RequestError('must provide either a path or a modelfile')\n\n    if path:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not modelfile:\n      if not path:\n        raise RequestError('must provide either a path or modelfile')\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not (path or modelfile):\n      raise RequestError('must provide either a path or modelfile')\n\n    if path:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not (path or modelfile):\n      raise RequestError('must provide either path or modelfile')\n\n    if path:\n      modelfile = Path(path).read_text()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'model': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not modelfile and not path:\n      raise RequestError('must provide a path or modelfile')\n\n    if not modelfile and path:\n      if isinstance(path, str):\n        path = Path(path)\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide a path or modelfile')\n\n    if not modelfile:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not (path or modelfile):\n      raise RequestError('must provide a path or modelfile')\n\n    if path:\n      modelfile = Path(path).read_text()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not (path or modelfile):\n      raise RequestError('must provide a path or modelfile')\n\n    if not modelfile:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, 'rb') as f:\n      digest = sha256(f.read()).hexdigest()\n\n    response = self._client.head(f'/api/blobs/{digest}')\n    if response.status_code == 404:\n      with open(path, 'rb') as f:\n        self._client.post(f'/api/blobs/{digest}', data=f)\n\n    return digest\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = _as_path(path)\n    if not path.exists():\n      raise RequestError(f'path does not exist: {path}')\n\n    with path.open('rb') as f:\n      digest = sha256(f.read()).hexdigest()\n\n    r = self._client.head(f'/api/blobs/{digest}')\n    if r.status_code == 404:\n      with path.open('rb') as f:\n        self._client.post(f'/api/blobs/{digest}', data=f)\n\n    return digest\n\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, 'rb') as f:\n      digest = sha256(f.read()).hexdigest()\n\n    r = self._client.head(f'/api/blobs/{digest}')\n    if r.status_code == 404:\n      with open(path, 'rb') as f:\n        r = self._client.post(f'/api/blobs', files={'file': f})\n        r.raise_for_status()\n\n    return digest\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, 'rb') as f:\n      digest = 'sha256:' + sha256(f.read()).hexdigest()\n\n    r = self._client.head(f'/api/blobs/{digest}')\n    if r.status_code == 404:\n      with open(path, 'rb') as f:\n        self._client.post(f'/api/blobs', files={'file': f})\n\n    return digest\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = Path(path).expanduser()\n    if not path.exists():\n      raise RequestError(f'file not found: {path}')\n\n    with path.open('rb') as f:\n      digest = 'sha256:' + sha256(f.read()).hexdigest()\n\n    r = self._client.head(f'/api/blobs/{digest}')\n    if r.status_code == 404:\n      with path.open('rb') as f:\n        r = self._client.post('/api/blobs', files={'file': f})\n\n    try:\n      r.raise_for_status()\n    except httpx.HTTPStatusError as e:\n      raise ResponseError(e.response.text, e.response.status_code) from None\n\n    return digest\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, 'rb') as f:\n      digest = sha256(f.read()).hexdigest()\n\n    r = self._client.head(f'/api/blobs/{digest}')\n    if r.status_code == 404:\n      with open(path, 'rb') as f:\n        r = self._client.post(f'/api/blobs', files={'file': f})\n\n    return r.json()['digest']\n\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = _as_path(path)\n    digest = 'sha256:' + sha256(path.read_bytes()).hexdigest()\n    r = self._client.head(f'/api/blobs/{digest}')\n    if r.status_code == 404:\n      r = self._client.post(\n        '/api/blobs',\n        files={\n          'file': (path.name, path.read_bytes()),\n        },\n      )\n      r.raise_for_status()\n    return digest\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = _as_path(path)\n\n    digest = f'sha256:{_checksum(path)}'\n    if self._head(f'/api/blobs/{digest}').status_code == 200:\n      return digest\n\n    with path.open('rb') as f:\n      self._client.post(\n        '/api/blobs/uploads/',\n        headers={'Content-Type': 'application/octet-stream'},\n        data=f,\n      )\n\n    return digest\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = Path(path).expanduser()\n    if not path.exists():\n      raise RequestError(f'{path} does not exist')\n\n    digest = sha256(path.read_bytes()).hexdigest()\n    response = self._client.head(f'/api/blobs/{digest}')\n    if response.status_code == 404:\n      response = self._client.post(\n        '/api/blobs',\n        files={'file': path.read_bytes()},\n        headers={'Content-Type': 'application/octet-stream'},\n      )\n      response.raise_for_status()\n\n    return digest\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = _as_path(path)\n    if not path.exists():\n      raise RequestError(f'{path} does not exist')\n\n    with path.open('rb') as f:\n      checksum = sha256(f.read()).hexdigest()\n\n    response = self._client.head(f'/api/blobs/{checksum}')\n    if response.status_code == 404:\n      with path.open('rb') as f:\n        self._client.post(f'/api/blobs/{checksum}', data=f)\n\n    return checksum\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, 'rb') as f:\n      digest = 'sha256:' + sha256(f.read()).hexdigest()\n\n    r = self._client.head(f'/api/blobs/{digest}')\n    if r.status_code == 404:\n      with open(path, 'rb') as f:\n        self._client.post('/api/blobs', files={'blob': f})\n\n    return digest\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, 'rb') as f:\n      digest = sha256()\n      for chunk in iter(lambda: f.read(io.DEFAULT_BUFFER_SIZE), b''):\n        digest.update(chunk)\n      digest = f'sha256:{digest.hexdigest()}'\n\n    try:\n      self._client.head(f'/blobs/{digest}')\n    except httpx.HTTPStatusError as e:\n      if e.response.status_code != 404:\n        raise ResponseError(e.response.text, e.response.status_code) from None\n\n      with open(path, 'rb') as f:\n        self._client.post(f'/blobs/uploads/{digest}', content=f)\n\n    return digest\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = _as_path(path)\n\n    if not path.exists():\n      raise RequestError(f'path does not exist: {path}')\n\n    with path.open('rb') as f:\n      digest = sha256(f.read()).hexdigest()\n\n    try:\n      self._client.head(f'/api/blobs/{digest}')\n    except httpx.HTTPStatusError as e:\n      if e.response.status_code != 404:\n        raise ResponseError(e.response.text, e.response.status_code) from None\n      self._client.post(f'/api/blobs/{digest}', content=path.read_bytes())\n\n    return f'sha256:{digest}'\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = _as_path(path)\n    if not path.exists():\n      raise RequestError(f'{path} does not exist')\n\n    digest = f'sha256:{_calculate_digest(path)}'\n\n    response = self._client.head(f'/api/blobs/{digest}')\n    if response.status_code == 404:\n      response = self._client.post(\n        '/api/blobs',\n        headers={'Content-Type': 'application/octet-stream'},\n        content=path.read_bytes(),\n      )\n      try:\n        response.raise_for_status()\n      except httpx.HTTPStatusError as e:\n        raise ResponseError(e.response.text, e.response.status_code) from None\n\n    return digest\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, 'rb') as f:\n      digest = sha256(f.read()).hexdigest()\n\n    r = self._client.head(f'/api/blobs/{digest}')\n    if r.status_code == 200:\n      return digest\n\n    with open(path, 'rb') as f:\n      r = self._client.post('/api/blobs', files={'blob': f})\n\n    try:\n      r.raise_for_status()\n    except httpx.HTTPStatusError as e:\n      raise ResponseError(e.response.text, e.response.status_code) from None\n\n    return digest\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = _as_path(path)\n    if not path.exists():\n      raise RequestError(f'{path} does not exist')\n\n    with path.open('rb') as f:\n      checksum = sha256(f.read())\n\n    response = self._client.head(\n      f'/api/blobs/{checksum.hexdigest()}',\n      headers={'Accept': 'application/json'},\n    )\n    if response.status_code == 200:\n      return response.json()['digest']\n\n    with path.open('rb') as f:\n      response = self._client.post(\n        '/api/blobs/uploads/',\n        headers={'Content-Type': 'application/octet-stream'},\n        content=f,\n      )\n\n    try:\n      response.raise_for_status()\n    except httpx.HTTPStatusError as e:\n      raise ResponseError(e.response.text, e.response.status_code) from None\n\n    return response.json()['digest']\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = _as_path(path)\n    if not path.exists():\n      raise RequestError(f'{path} does not exist')\n\n    with path.open('rb') as f:\n      digest = sha256()\n      while chunk := f.read(65536):\n        digest.update(chunk)\n      digest = digest.hexdigest()\n\n    response = self._client.head(f'/api/blobs/{digest}')\n    if response.status_code == 404:\n      response = self._client.post(\n        '/api/blobs',\n        headers={'Content-Type': 'application/octet-stream'},\n        data=path.read_bytes(),\n      )\n\n    return f'sha256:{digest}'\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = _as_path(path)\n\n    if not path.exists():\n      raise RequestError(f'{path} does not exist')\n\n    with path.open('rb') as f:\n      digest = sha256()\n      while chunk := f.read(1024):\n        digest.update(chunk)\n\n    digest = f'sha256:{digest.hexdigest()}'\n\n    response = self._client.head(f'/api/blobs/{digest}')\n    if response.status_code == 404:\n      response = self._client.post(f'/api/blobs/{digest}', data=path.open('rb'))\n\n    try:\n      response.raise_for_status()\n    except httpx.HTTPStatusError as e:\n      raise ResponseError(e.response.text, e.response.status_code) from None\n\n    return digest\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = _as_path(path)\n\n    checksum = sha256()\n    with path.open('rb') as f:\n      for chunk in iter(lambda: f.read(4096), b''):\n        checksum.update(chunk)\n\n    digest = f'sha256:{checksum.hexdigest()}'\n    if self._head(f'/api/blobs/{digest}'):\n      return digest\n\n    with path.open('rb') as f:\n      self._request(\n        'POST',\n        '/api/blobs',\n        headers={\n          'Content-Type': 'application/octet-stream',\n          'Content-Length': str(path.stat().st_size),\n          'Digest': digest,\n        },\n        data=f,\n      )\n\n    return digest\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    # Calculate the SHA-256 checksum of the file.\n    checksum = sha256()\n    with open(path, 'rb') as f:\n      for chunk in iter(lambda: f.read(1024 * 1024), b''):\n        checksum.update(chunk)\n\n    # Check if the file already exists on the server.\n    response = self._client.head(\n      f'/api/blobs/{checksum.hexdigest()}',\n      headers={'Accept': 'application/json'},\n    )\n    if response.status_code == 200:\n      return f'sha256:{checksum.hexdigest()}'\n\n    # Upload the file as a new blob.\n    response = self._client.post(\n      '/api/blobs',\n      files={'file': (checksum.hexdigest(), open(path, 'rb'))},\n    )\n    response.raise_for_status()\n    return f'sha256:{checksum.hexdigest()}'\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/uploads/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/uploads/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n    response = await self._request('HEAD', f'/api/blobs/{digest}')\n\n    if response.status_code == 404:\n      with open(path, 'rb') as r:\n        response = await self._request('POST', f'/api/blobs/uploads/{digest}', data=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/uploads/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n    response = await self._request('HEAD', f'/api/blobs/{digest}')\n    if response.status_code == 200:\n      return digest\n\n    with open(path, 'rb') as r:\n      async with self._client.stream('POST', f'/api/blobs/{digest}', headers={'Content-Type': 'application/octet-stream'}) as w:\n        while True:\n          chunk = r.read(32 * 1024)\n          if not chunk:\n            break\n          w.write(chunk)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary file to store the user-provided code.\n        with tempfile.NamedTemporaryFile(mode=\"w\", encoding=\"utf-8\", suffix=\".py\") as user_code_file:\n            user_code_file.write(user_code)\n            user_code_file.flush()\n\n            # Create a temporary file to store the test code.\n            with tempfile.NamedTemporaryFile(mode=\"w\", encoding=\"utf-8\", suffix=\".py\") as test_code_file:\n                test_code_file.write(test_code)\n                test_code_file.flush()\n\n                # Run Pyright on the combined user-provided code and test code.\n                completed_process = subprocess.run(\n                    [\"pyright\", user_code_file.name, test_code_file.name],\n                    capture_output=True,\n                    text=True,\n                )\n\n                # If there was an error running Pyright, return a failed TypeCheckResult.\n                if completed_process.returncode != 0:\n                    return TypeCheckResult(\n                        message=f\"Error running Pyright: {completed_process.stderr}\",\n                        passed=False,\n                    )\n\n                # Parse the output of Pyright to identify lines with expected type errors.\n                expected_error_lines = set()\n                for line in completed_process.stdout.splitlines():\n                    match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n                    if match:\n                        line_no = int(match.group(1))\n                        message = match.group(2)\n                        if cls.EXPECT_ERROR_COMMENT in message:\n                            expected_error_lines.add(line_no)\n\n                # If there are no errors, return a successful TypeCheckResult.\n                if not expected_error_lines:\n                    return TypeCheckResult(\n                        message=\"Your code is type-safe!\",\n                        passed=True,\n                    )\n\n                # If there are errors, return a failed TypeCheckResult.\n               "}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Write user code and test code to temporary files\n        with tempfile.NamedTemporaryFile(mode=\"w+\", suffix=\".py\") as user_code_file, tempfile.NamedTemporaryFile(mode=\"w+\", suffix=\".py\") as test_code_file:\n            user_code_file.write(user_code)\n            test_code_file.write(test_code)\n\n            # Run Pyright on the temporary files\n            process = subprocess.run(\n                [\"pyright\", user_code_file.name, test_code_file.name],\n                capture_output=True,\n                text=True,\n            )\n\n            # Extract Pyright error messages from the output\n            error_messages = []\n            for line in process.stdout.splitlines():\n                match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n                if match:\n                    error_messages.append(match.group(2))\n\n        # Determine if the type check passed\n        passed = True\n        for message in error_messages:\n            if cls.EXPECT_ERROR_COMMENT not in message:\n                passed = False\n                break\n\n        # Create a message detailing the type check result\n        if passed:\n            message = \"All type checks have passed!\"\n        else:\n            message = \"Some type checks have failed.\\n\" + \"\\n\".join(error_messages)\n\n        return TypeCheckResult(message=message, passed=passed)"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary file to store the user code.\n        with tempfile.NamedTemporaryFile(mode=\"w\", encoding=\"utf-8\", suffix=\".py\") as f:\n            f.write(user_code)\n            f.flush()\n\n            # Create a temporary file to store the test code.\n            with tempfile.NamedTemporaryFile(mode=\"w\", encoding=\"utf-8\", suffix=\".py\") as g:\n                g.write(test_code)\n                g.flush()\n\n                # Run Pyright on the combined user and test code.\n                proc = subprocess.run(\n                    [\"pyright\", f.name, g.name],\n                    capture_output=True,\n                    text=True,\n                    check=False,\n                )\n\n                # If there is an error in the subprocess call, return a TypeCheckResult with the error message.\n                if proc.returncode != 0:\n                    return TypeCheckResult(\n                        message=f\"Error running Pyright: {proc.stderr}\", passed=False\n                    )\n\n                # Otherwise, parse the output to identify expected type errors and determine if the type check passed.\n                return cls._parse_pyright_output(proc.stdout)\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary file to store the user code.\n        with tempfile.NamedTemporaryFile(mode=\"w\", encoding=\"utf-8\", suffix=\".py\") as user_code_file:\n            user_code_file.write(user_code)\n            user_code_file.flush()\n\n            # Create a temporary file to store the test code.\n            with tempfile.NamedTemporaryFile(mode=\"w\", encoding=\"utf-8\", suffix=\".py\") as test_code_file:\n                test_code_file.write(test_code)\n                test_code_file.flush()\n\n                # Run Pyright on the user code and test code.\n                pyright_process = subprocess.run(\n                    [\"pyright\", user_code_file.name, test_code_file.name],\n                    capture_output=True,\n                    encoding=\"utf-8\",\n                )\n\n                # Parse the Pyright output.\n                pyright_output = pyright_process.stdout\n                pyright_errors = re.findall(cls.PYRIGHT_MESSAGE_REGEX, pyright_output)\n\n                # Check if the type check passed.\n                pyright_passed = pyright_process.returncode == 0\n\n                # Check if there are any lines with expected type errors.\n                expected_error_lines = []\n                for line_no, message in pyright_errors:\n                    if cls.EXPECT_ERROR_COMMENT in test_code.splitlines()[int(line_no) - 1]:\n                        expected_error_lines.append(line_no)\n\n                # Create the result message.\n                if pyright_passed:\n                    message = \"Type checking passed!\"\n                else:\n                    message = \"Type checking failed.\"\n\n                if expected_error_lines:\n                    message += (\n                        f\"\\nHowever, there are {len(expected_error_lines)} lines with expected type errors.\"\n                    )\n\n                # Create the result object.\n                result = TypeCheckResult(\n                    message=message,\n                    passed="}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary file to store the user code and test code\n        with tempfile.NamedTemporaryFile(mode=\"w+\", suffix=\".py\") as tmp_file:\n            tmp_file.write(user_code)\n            tmp_file.write(\"\\n\\n\")\n            tmp_file.write(test_code)\n            tmp_file.seek(0)\n\n            # Run Pyright on the temporary file\n            process = subprocess.run(\n                [\"pyright\", tmp_file.name],\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n            )\n\n        # Process the output of Pyright\n        output = process.stdout.decode(\"utf-8\")\n        error_messages = cls._get_error_messages(output)\n        passed = cls._check_if_passed(error_messages)\n\n        # Create a message for the type check result\n        if passed:\n            message = \"Type check passed!\"\n        else:\n            message = \"Type check failed. \"\n            if len(error_messages) == 1:\n                message += f\"There is 1 error in your code: {error_messages[0]}\"\n            else:\n                message += f\"There are {len(error_messages)} errors in your code: \\n\"\n                for error_message in error_messages:\n                    message += f\"- {error_message}\\n\"\n\n        return TypeCheckResult(message, passed, {\"error_messages\": error_messages})\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary file to store the user code\n        with tempfile.NamedTemporaryFile(mode=\"w\", encoding=\"utf-8\") as f:\n            f.write(user_code)\n            f.flush()\n\n            # Create a temporary file to store the test code\n            with tempfile.NamedTemporaryFile(mode=\"w\", encoding=\"utf-8\") as test_file:\n                test_file.write(test_code)\n                test_file.flush()\n\n                # Run Pyright on the combined code\n                process = subprocess.run(\n                    [\"pyright\", f.name, test_file.name],\n                    capture_output=True,\n                    encoding=\"utf-8\",\n                    text=True,\n                )\n\n        # Parse the output of Pyright to identify expected type errors\n        expected_error_lines = cls._get_expected_error_lines(process.stdout)\n        # Parse the output of Pyright to identify actual type errors\n        actual_error_lines = cls._get_actual_error_lines(process.stdout)\n\n        # If the number of actual errors is the same as the number of expected errors, the type check passes\n        if len(actual_error_lines) == len(expected_error_lines):\n            return TypeCheckResult(message=\"Passed\", passed=True)\n\n        # If the number of actual errors is less than the number of expected errors, the type check failed\n        elif len(actual_error_lines) < len(expected_error_lines):\n            return TypeCheckResult(\n                message=\"Failed: Not all expected type errors were found\", passed=False\n            )\n\n        # If the number of actual errors is greater than the number of expected errors, the type check failed\n        else:\n            return TypeCheckResult(\n                message=\"Failed: More errors than expected were found\", passed=False\n            )\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Write user-provided code to a temporary file.\n        with tempfile.NamedTemporaryFile(mode=\"w\", encoding=\"utf-8\", suffix=\".py\") as user_code_file:\n            user_code_file.write(user_code)\n            user_code_file.flush()\n\n            # Write test code to a temporary file.\n            with tempfile.NamedTemporaryFile(mode=\"w\", encoding=\"utf-8\", suffix=\".py\") as test_code_file:\n                test_code_file.write(test_code)\n                test_code_file.flush()\n\n                # Run Pyright on the combined code.\n                completed_process = subprocess.run(\n                    [\"pyright\", user_code_file.name, test_code_file.name],\n                    stdout=subprocess.PIPE,\n                    stderr=subprocess.PIPE,\n                    text=True,\n                )\n\n                # Parse the output to identify the lines with expected type errors.\n                expected_error_lines = set()\n                for line in completed_process.stderr.splitlines():\n                    match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n                    if match:\n                        line_no = int(match.group(1))\n                        if cls.EXPECT_ERROR_COMMENT in test_code.splitlines()[line_no - 1]:\n                            expected_error_lines.add(line_no)\n\n                # Determine whether the type check passed.\n                if completed_process.returncode == 0:\n                    passed = True\n                    message = \"Passed type checking\"\n                else:\n                    passed = False\n                    message = \"Failed type checking\"\n\n                    # If there are expected type errors, add the lines to the message.\n                    if expected_error_lines:\n                        message += f\" (expected errors on lines {expected_error_lines})\"\n\n                return TypeCheckResult(message=message, passed=passed)"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary file to store the user code.\n        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\") as user_file:\n            user_file.write(user_code)\n            user_file.flush()\n\n            # Create a temporary file to store the test code.\n            with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\") as test_file:\n                test_file.write(test_code)\n                test_file.flush()\n\n                # Run pyright on the combined user code and test code.\n                result = subprocess.run(\n                    [\"pyright\", user_file.name, test_file.name],\n                    stdout=subprocess.PIPE,\n                    stderr=subprocess.PIPE,\n                    text=True,\n                )\n\n                # Parse the output to identify the lines with expected type errors.\n                expected_errors = cls._parse_pyright_output(result.stderr)\n\n                # Parse the user code to identify the lines with expect-type-error comments.\n                expect_error_lines = cls._parse_user_code(user_code)\n\n                # Compare the expected type errors with the lines with expect-type-error comments.\n                passed = cls._compare_expected_errors(\n                    expected_errors, expect_error_lines\n                )\n\n                # Create a message to indicate whether the type check passed or failed.\n                if passed:\n                    message = \"All type checks passed!\"\n                else:\n                    message = \"Some type checks failed!\"\n\n                return TypeCheckResult(message, passed)\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Write the user code and test code to a temporary file\n        with tempfile.NamedTemporaryFile(\"w\", encoding=\"utf-8\", suffix=\".py\") as f:\n            f.write(user_code)\n            f.flush()\n\n            # Write the test code to a temporary file\n            with tempfile.NamedTemporaryFile(\"w\", encoding=\"utf-8\", suffix=\".py\") as g:\n                g.write(test_code)\n                g.flush()\n\n                # Run Pyright on the temporary file\n                process = subprocess.run(\n                    [\"pyright\", f.name, g.name],\n                    stdout=subprocess.PIPE,\n                    stderr=subprocess.PIPE,\n                )\n\n                # Get the error messages\n                error_messages = process.stderr.decode(\"utf-8\")\n\n                # Get the line numbers of the expected type errors\n                expected_error_lines = cls._get_expected_error_lines(user_code)\n\n                # Determine if the type check passed\n                passed = True\n                for line_no in expected_error_lines:\n                    if f\"{f.name}:{line_no}:\" not in error_messages:\n                        passed = False\n                        break\n\n                # Create the message\n                if passed:\n                    message = \"No errors found!\"\n                else:\n                    # Get the error messages that are not expected type errors\n                    unexpected_error_messages = []\n                    for line in error_messages.splitlines():\n                        if \"error:\" in line and f\"{f.name}:{line.split(':')[1]}: \" not in expected_error_lines:\n                            unexpected_error_messages.append(line)\n\n                    # Create the message\n                    if unexpected_error_messages:\n                        message = \"\\n\".join(unexpected_error_messages)\n                    else:\n                        message = \"All expected type errors found!\"\n\n                return TypeCheckResult(message, passed)\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary file to write the user code to\n        with tempfile.NamedTemporaryFile(mode=\"w\", encoding=\"utf-8\") as user_code_file:\n            user_code_file.write(user_code)\n            user_code_file.flush()\n\n            # Create a temporary file to write the test code to\n            with tempfile.NamedTemporaryFile(mode=\"w\", encoding=\"utf-8\") as test_code_file:\n                test_code_file.write(test_code)\n                test_code_file.flush()\n\n                # Run Pyright on the combined code\n                completed_process = subprocess.run(\n                    [\n                        \"pyright\",\n                        \"--outputjson\",\n                        user_code_file.name,\n                        test_code_file.name,\n                    ],\n                    capture_output=True,\n                    text=True,\n                )\n\n                # If the subprocess returns a non-zero exit code, raise an exception\n                if completed_process.returncode != 0:\n                    raise RuntimeError(completed_process.stderr)\n\n                # Parse the Pyright output\n                pyright_output = completed_process.stdout\n                pyright_output_dict = json.loads(pyright_output)\n\n                # Extract the error messages from the Pyright output\n                error_messages = []\n                for diagnostic in pyright_output_dict[\"generalDiagnostics\"]:\n                    # If the error is not an error, skip it\n                    if diagnostic[\"severity\"] != \"error\":\n                        continue\n\n                    # Extract the line number and message\n                    line_no = diagnostic[\"file\"][len(user_code_file.name) + 1 :]\n                    message = diagnostic[\"message\"]\n\n                    # If the error is expected, skip it\n                    if cls._is_expected_error(user_code, line_no, message):\n                        continue\n\n                    # Add the error message to the list\n                    error_messages.append(f\"Line {line_no}: {message}\")"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Write the user code and test code to a temporary file\n        with tempfile.NamedTemporaryFile(\n            mode=\"w\", encoding=\"utf-8\", suffix=\".py\", delete=False\n        ) as temp_file:\n            temp_file.write(user_code)\n            temp_file.write(test_code)\n            temp_file.write(\"\\n\")\n            temp_file.flush()\n\n        # Run Pyright on the temporary file\n        pyright_result = subprocess.run(\n            [\"pyright\", temp_file.name], capture_output=True, text=True\n        )\n\n        # Remove the temporary file\n        Path(temp_file.name).unlink()\n\n        # Split the output of Pyright into lines\n        pyright_result_lines = pyright_result.stderr.splitlines()\n\n        # If the output of Pyright is empty, the type check passed\n        if not pyright_result_lines:\n            return TypeCheckResult(message=\"Type check passed!\", passed=True)\n\n        # If the output of Pyright is not empty, the type check failed\n        # Parse the output to identify lines with expected type errors\n        expected_error_lines = []\n        unexpected_error_lines = []\n\n        for line in pyright_result_lines:\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                line_no = int(match.group(1))\n                message = match.group(2)\n                if cls.EXPECT_ERROR_COMMENT in test_code.splitlines()[line_no - 1]:\n                    expected_error_lines.append(message)\n                else:\n                    unexpected_error_lines.append(message)\n\n        # Build a message describing the type check outcome\n        message = \"\"\n        if expected_error_lines:\n            message += \"Type errors expected here:\\n\" + \"\\n\".join(\n                [f\"- {line}\" for line in expected_error_lines]\n            )\n        if unexpected_error_lines:\n            if message:\n                message"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Write user and test code to temporary files\n        with tempfile.TemporaryDirectory() as temp_dir_name:\n            temp_dir = Path(temp_dir_name)\n            user_code_file = temp_dir / \"user_code.py\"\n            user_code_file.write_text(user_code, encoding=\"utf-8\")\n            test_code_file = temp_dir / \"test_code.py\"\n            test_code_file.write_text(test_code, encoding=\"utf-8\")\n\n            # Run Pyright on the combined code\n            result = subprocess.run(\n                [\"pyright\", \"--outputjson\", str(user_code_file), str(test_code_file)],\n                capture_output=True,\n                text=True,\n            )\n            pyright_output = result.stdout\n\n        # Parse Pyright output\n        debug_info = {\"pyright_output\": pyright_output}\n        pyright_output_lines = pyright_output.splitlines()\n        errors = []\n        passed = True\n        for line in pyright_output_lines:\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if not match:\n                continue\n\n            # Ignore lines with expected type errors\n            line_no = int(match.group(1))\n            message = match.group(2)\n            if cls.EXPECT_ERROR_COMMENT in user_code_file.read_text(\n                encoding=\"utf-8\"\n            ).splitlines()[line_no - 1]:\n                continue\n\n            # If the line is not an expected type error, then the type check failed\n            passed = False\n            errors.append(message)\n\n        # Format the result message\n        if not errors:\n            message = \"All type checks passed!\"\n        else:\n            message = \"Type check failed:\\n\" + \"\\n\".join(errors)\n\n        return TypeCheckResult(message, passed, debug_info)\n\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Write the user code to a temporary file for Pyright to read.\n        with tempfile.NamedTemporaryFile(mode=\"w\", encoding=\"utf-8\") as user_code_file:\n            user_code_file.write(user_code)\n            user_code_file.flush()\n\n            # Write the test code to a temporary file for Pyright to read.\n            with tempfile.NamedTemporaryFile(mode=\"w\", encoding=\"utf-8\") as test_code_file:\n                test_code_file.write(test_code)\n                test_code_file.flush()\n\n                # Run Pyright on the combined user code and test code.\n                pyright_process = subprocess.run(\n                    [\"pyright\", user_code_file.name, test_code_file.name],\n                    capture_output=True,\n                    text=True,\n                )\n\n        # If Pyright has any errors or warnings, parse the output to identify lines with expected type errors.\n        if pyright_process.returncode == 0:\n            return TypeCheckResult(\n                message=\"Your code is type-safe!\",\n                passed=True,\n            )\n        else:\n            # Parse the output to identify lines with expected type errors.\n            expected_error_lines = []\n            for line in pyright_process.stderr.splitlines():\n                match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n                if match is not None:\n                    line_no = int(match.group(1))\n                    message = match.group(2)\n\n                    # If the line contains the special comment, ignore the error.\n                    if cls.EXPECT_ERROR_COMMENT in message:\n                        continue\n\n                    # If the line is not in the user code, ignore the error.\n                    if line_no <= len(user_code.splitlines()):\n                        continue\n\n                    # If the line is in the user code, add it to the list of expected errors.\n                    expected_error_lines.append(line_no)"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Write user and test code to a temporary file\n        with tempfile.NamedTemporaryFile(mode=\"w\", encoding=\"utf-8\", suffix=\".py\") as f:\n            f.write(user_code)\n            f.write(test_code)\n            f.flush()\n\n            # Run Pyright\n            result = subprocess.run(\n                [\"pyright\", f.name],\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n                universal_newlines=True,\n            )\n\n        # Parse the output\n        passed = True\n        messages = []\n        expect_error_line_nos = set()\n        for line in result.stdout.splitlines():\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                line_no = int(match.group(1))\n                message = match.group(2)\n                if message.startswith(\"expect-type-error\"):\n                    expect_error_line_nos.add(line_no)\n                else:\n                    messages.append(message)\n                    passed = False\n\n        # If the user has indicated that they expect a type error, then if there are no type errors, the type check passes\n        if expect_error_line_nos:\n            if not messages:\n                passed = True\n            else:\n                # If there are type errors, then the type check fails if there are no errors on the expected lines\n                passed = not expect_error_line_nos.isdisjoint(\n                    line_no for line_no, _ in messages\n                )\n\n        return TypeCheckResult(\n            message=\"\\n\".join(messages),\n            passed=passed,\n            debug_info={\n                \"user_code\": user_code,\n                \"test_code\": test_code,\n                \"stdout\": result.stdout,\n                \"stderr\": result.stderr,\n                \"expect_error_line_nos\": expect_error_line_nos,\n            },\n        )"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary file to store the user code\n        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\") as f:\n            f.write(user_code)\n            f.seek(0)\n\n            # Create a temporary file to store the test code\n            with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\") as g:\n                g.write(test_code)\n                g.seek(0)\n\n                # Run Pyright on the combined code\n                proc = subprocess.run(\n                    [\"pyright\", f.name, g.name], capture_output=True, text=True\n                )\n                output = proc.stdout\n\n        # Split the output into lines\n        lines = output.splitlines()\n\n        # If there is no output, return a TypeCheckResult with passed=True\n        if not lines:\n            return TypeCheckResult(message=\"\", passed=True)\n\n        # Split each line into a line number and a message\n        messages = [\n            (int(line_number), message)\n            for line_number, message in re.findall(cls.PYRIGHT_MESSAGE_REGEX, output)\n        ]\n\n        # Sort the messages by line number\n        messages.sort(key=lambda x: x[0])\n\n        # Remove lines that are not errors\n        messages = [message for message in messages if \"error:\" in message[1]]\n\n        # If there are no errors, return a TypeCheckResult with passed=True\n        if not messages:\n            return TypeCheckResult(message=\"\", passed=True)\n\n        # Remove lines that are expected errors\n        expected_errors = cls._get_expected_errors(user_code)\n        messages = [\n            message\n            for message in messages\n            if message[0] not in expected_errors and \"error: \" in message[1]\n        ]\n\n        # If there are no errors left, return a TypeCheckResult with passed=True\n        if not messages:\n            return TypeCheckResult(message=\"\", passed=True)\n\n        # Create a message with the error messages\n        message ="}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Remove the expect-type-error comment from the user code.\n        user_code = re.sub(\n            f\"#.*{cls.EXPECT_ERROR_COMMENT}.*\", \"\", user_code, flags=re.IGNORECASE\n        )\n\n        # Combine the user code and test code into a single file.\n        combined_code = user_code + test_code\n\n        # Write the combined code to a temporary file.\n        temp_file = tempfile.NamedTemporaryFile(mode=\"w\", delete=False, suffix=\".py\")\n        temp_file_name = temp_file.name\n        temp_file.write(combined_code)\n        temp_file.close()\n\n        # Run Pyright on the temporary file.\n        proc = subprocess.run(\n            [\"pyright\", temp_file_name],\n            capture_output=True,\n            text=True,\n        )\n\n        # Remove the temporary file.\n        Path(temp_file_name).unlink()\n\n        # If the process exited with a non-zero status code, return an error message.\n        if proc.returncode != 0:\n            return TypeCheckResult(\n                message=f\"Something went wrong. Please try again.\",\n                passed=False,\n            )\n\n        # If the process exited with a zero status code, parse the output to determine if there were any type errors.\n        # If there were any type errors, determine which lines should be ignored.\n        # If there were any ignored lines, return an error message.\n        # If there were no type errors, return a success message.\n        output = proc.stdout\n        type_error_lines = []\n        ignored_lines = []\n        for line in output.splitlines():\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                line_no = int(match.group(1))\n                error_message = match.group(2)\n                if cls.EXPECT_ERROR_COMMENT in error_message.lower():\n                    ignored_lines.append(line_no)"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary file to store the user code and test code\n        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\") as f:\n            f.write(user_code)\n            f.write(\"\\n\")\n            f.write(test_code)\n            f.seek(0)\n            # Run Pyright on the temporary file\n            pyright_output = subprocess.run(\n                [\"pyright\", f.name, \"--outputjson\"],\n                capture_output=True,\n                text=True,\n            )\n            # Parse the output for the relevant information\n            result = cls._parse_pyright_output(pyright_output.stdout)\n            # Check if the user has used the expect-type-error comment\n            if cls.EXPECT_ERROR_COMMENT in user_code:\n                return cls._handle_expect_type_error(result, test_code)\n            return result\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Write user code and test code to a temporary file\n        with tempfile.NamedTemporaryFile(mode=\"w+\") as f:\n            f.write(user_code)\n            f.write(test_code)\n            f.flush()\n\n            # Run Pyright and capture the output\n            proc = subprocess.run(\n                [\"pyright\", f.name, \"--outputjson\"],\n                capture_output=True,\n                encoding=\"utf-8\",\n            )\n            if proc.returncode != 0:\n                raise RuntimeError(\n                    f\"Failed to run Pyright on the code:\\n{proc.stderr}\"\n                )\n            pyright_output = proc.stdout\n\n        # Parse the output to identify expected type errors\n        expect_type_error_lines = []\n        messages = []\n        for line in pyright_output.splitlines():\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if not match:\n                continue\n            line_no = int(match.group(1))\n            message = match.group(2)\n            if cls.EXPECT_ERROR_COMMENT in user_code.splitlines()[line_no - 1]:\n                expect_type_error_lines.append(line_no)\n            messages.append(message)\n\n        # Determine the result of the type check\n        if expect_type_error_lines:\n            # Expected type errors were found\n            if any(\n                line_no not in expect_type_error_lines\n                for line_no, _ in cls._get_error_lines(user_code)\n            ):\n                # Type errors were found that were not expected\n                return TypeCheckResult(\n                    message=\"\\n\".join(messages),\n                    passed=False,\n                    debug_info={\n                        \"expected_type_errors\": expect_type_error_lines,\n                        \"type_errors\": [\n                            line_no for line_no, _ in cls._get_error_lines(user_code)\n                        ],\n                    },"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Write user code to a temporary file\n        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\") as f:\n            f.write(user_code)\n            f.flush()\n\n            # Write test code to a temporary file\n            with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\") as g:\n                g.write(test_code)\n                g.flush()\n\n                # Run Pyright on the combined user code and test code\n                # and capture the output\n                result = subprocess.run(\n                    [\"pyright\", f.name, g.name], capture_output=True, text=True\n                )\n\n                # Parse the output\n                pyright_output = result.stdout\n                pyright_errors = re.findall(cls.PYRIGHT_MESSAGE_REGEX, pyright_output)\n\n                # If there are no errors, return a successful result\n                if not pyright_errors:\n                    return TypeCheckResult(\n                        message=\"Type check passed!\",\n                        passed=True,\n                    )\n\n                # If there are errors, return a failed result\n                else:\n                    # Create a dict to store the expected error lines\n                    expected_error_lines = {}\n\n                    # Iterate through the errors and store the error messages\n                    # for lines that are expected to contain type errors\n                    for line_no, error_message in pyright_errors:\n                        with open(f.name, \"r\") as h:\n                            # Read the line of the user code\n                            user_code_line = h.readlines()[int(line_no) - 1]\n\n                        # If the line contains an expected type error comment,\n                        # store the error message\n                        if cls.EXPECT_ERROR_COMMENT in user_code_line:\n                            expected_error_lines[line_no] = error_message\n\n                    # If there are no expected type errors, return a failed result\n                    if not expected_error_lines:\n                        return TypeCheckResult(\n                            message=\"Type"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary file for the user code.\n        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\") as f:\n            f.write(user_code)\n            f.flush()\n\n            # Create a temporary file for the test code.\n            with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\") as g:\n                g.write(test_code)\n                g.flush()\n\n                # Type check the temporary files.\n                try:\n                    proc = subprocess.run(\n                        [\"pyright\", f.name, g.name],\n                        stdout=subprocess.PIPE,\n                        stderr=subprocess.PIPE,\n                        check=True,\n                    )\n                except subprocess.CalledProcessError as e:\n                    return TypeCheckResult(\n                        message=f\"Internal error: {e}\",\n                        passed=False,\n                        debug_info={\"stdout\": e.stdout, \"stderr\": e.stderr},\n                    )\n\n                # Parse the output of the type checker.\n                result_lines = proc.stdout.decode(\"utf-8\").split(\"\\n\")\n                result_lines = [\n                    line\n                    for line in result_lines\n                    if line\n                    and not line.startswith(\"Found \")\n                    and not line.startswith(\"Warning: \")\n                    and not line.startswith(\"Info: \")\n                ]\n\n                # Create a dictionary to store the error messages.\n                error_messages = {}\n\n                # Iterate through the lines of the output.\n                for line in result_lines:\n                    # Search for lines that contain errors.\n                    match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n\n                    # If the line contains an error, store the error message.\n                    if match:\n                        line_no = int(match.group(1))\n                        error_messages[line_no] = match.group(2)\n\n                # Create a list of lines to ignore.\n                ignore_lines = []\n\n               "}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn())\n    else:\n        return aot_function(fn, get_compiler_fn())"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn())\n    else:\n        return aot_function(fn, get_compiler_fn())"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn())\n    else:\n        return aot_function(fn, get_compiler_fn())"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, compiler_fn=get_compiler_fn())\n    else:\n        return aot_function(fn, compiler_fn=get_compiler_fn())"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, compiler_fn=get_compiler_fn())\n    else:\n        return aot_function(fn, compiler_fn=get_compiler_fn())"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, compiler_fn=get_compiler_fn())\n    else:\n        return aot_function(fn, compiler_fn=get_compiler_fn())"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"Module Code:\"))\n    else:\n        return aot_function(fn, get_compiler_fn(\"Function Code:\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"Module code:\"))\n    else:\n        return aot_function(fn, get_compiler_fn(\"Function code:\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"Module Code: \"))\n    else:\n        return aot_function(fn, get_compiler_fn(\"Function Code: \"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, compiler_fn=get_compiler_fn(\"Module code:\"))\n    else:\n        return aot_function(fn, compiler_fn=get_compiler_fn(\"Function code:\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, compiler_fn=get_compiler_fn(title=fn.__name__))\n    else:\n        return aot_function(fn, compiler_fn=get_compiler_fn(title=fn.__name__))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"Module: \"))\n    else:\n        return aot_function(fn, get_compiler_fn(\"Function: \"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(title=fn.__name__))\n    else:\n        return aot_function(fn, get_compiler_fn(title=fn.__name__))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, compiler_fn=get_compiler_fn(\"Module Code\"))\n    else:\n        return aot_function(fn, compiler_fn=get_compiler_fn(\"Function Code\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"Module:\"))\n    else:\n        return aot_function(fn, get_compiler_fn(\"Function:\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"Module forward compiler\"), get_compiler_fn(\"Module backward compiler\"))\n    else:\n        return aot_function(fn, get_compiler_fn(\"Function forward compiler\"), get_compiler_fn(\"Function backward compiler\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(title=\"Module code: \"))\n    else:\n        return aot_function(fn, get_compiler_fn(title=\"Function code: \"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, compiler_fn=get_compiler_fn())\n    else:\n        return aot_function(fn, compiler_fn=get_compiler_fn())\n\n"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(\n            fn,\n            get_compiler_fn(\"Module Forward\"),\n            get_compiler_fn(\"Module Backward\"),\n        )\n    else:\n        return aot_function(\n            fn,\n            get_compiler_fn(\"Function Forward\"),\n            get_compiler_fn(\"Function Backward\"),\n        )\n\n"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"Module code: \"))\n    else:\n        return aot_function(fn, get_compiler_fn(\"Function code: \"))\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.safe_load(open(os.path.join(trial_path, 'config.yaml'), 'r'))\n    best_config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path is not None:\n        if output_path.endswith('.yaml') or output_path.endswith('.yml'):\n            yaml.dump(best_config_dict, open(output_path, 'w'))\n        else:\n            raise ValueError('The file extension must be .yaml or .yml if provided.')\n\n    return best_config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    # Load summary file\n    summary_df = load_summary_file(trial_path)\n\n    # Load config file\n    with open(os.path.join(trial_path, 'config.yaml'), 'r') as f:\n        config_dict = yaml.safe_load(f)\n\n    # Extract best config\n    best_config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    # Save best config\n    if output_path is not None:\n        if output_path.endswith('.yaml') or output_path.endswith('.yml'):\n            with open(output_path, 'w') as f:\n                yaml.dump(best_config_dict, f)\n        else:\n            raise ValueError('output_path must end with .yaml or .yml if provided.')\n\n    return best_config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.safe_load(open(os.path.join(trial_path, 'config.yaml'), 'r'))\n    config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path is not None:\n        if not output_path.endswith('.yaml') and not output_path.endswith('.yml'):\n            raise ValueError('output_path must end with .yaml or .yml if specified.')\n        with open(output_path, 'w') as f:\n            yaml.dump(config_dict, f)\n\n    return config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.safe_load(open(os.path.join(trial_path, 'config.yaml'), 'r'))\n    config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path is not None:\n        if not output_path.endswith('.yaml') and not output_path.endswith('.yml'):\n            raise ValueError(\"The output_path must end with .yaml or .yml if provided.\")\n        with open(output_path, 'w') as f:\n            yaml.dump(config_dict, f)\n\n    return config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(os.path.join(trial_path, 'summary.csv'))\n    config_dict = yaml.load(open(os.path.join(trial_path, 'config.yaml')), Loader=yaml.SafeLoader)\n    best_config_dict = summary_df_to_yaml(summary_df, config_dict)\n    if output_path is not None:\n        if not output_path.endswith('.yaml') and not output_path.endswith('.yml'):\n            raise ValueError('output_path must end with .yaml or .yml if provided.')\n        with open(output_path, 'w') as file:\n            yaml.dump(best_config_dict, file)\n    return best_config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.safe_load(open(os.path.join(trial_path, 'config.yaml'), 'r'))\n    config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path is not None:\n        if output_path.endswith('.yaml') or output_path.endswith('.yml'):\n            with open(output_path, 'w') as f:\n                yaml.dump(config_dict, f)\n        else:\n            raise ValueError('output_path must have file extension .yaml or .yml')\n\n    return config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    # Load the summary file\n    summary_df = load_summary_file(os.path.join(trial_path, 'summary.csv'))\n\n    # Load the config file\n    with open(os.path.join(trial_path, 'config.yaml'), 'r') as f:\n        config_dict = yaml.safe_load(f)\n\n    # Extract the best configuration\n    best_config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    # Save the best configuration if specified\n    if output_path is not None:\n        if not output_path.endswith('.yaml') and not output_path.endswith('.yml'):\n            raise ValueError('The output path must have a .yaml or .yml extension.')\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config_dict, f)\n\n    # Return the best configuration\n    return best_config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(os.path.join(trial_path, 'summary.csv'))\n    config_dict = yaml.safe_load(open(os.path.join(trial_path, 'config.yaml')))\n    best_config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path is not None:\n        if not (output_path.endswith('.yaml') or output_path.endswith('.yml')):\n            raise ValueError('output_path must end with .yaml or .yml if specified.')\n        with open(output_path, 'w') as f:\n            yaml.safe_dump(best_config_dict, f)\n\n    return best_config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(os.path.join(trial_path, 'summary.csv'))\n    config_dict = yaml.safe_load(open(os.path.join(trial_path, 'config.yaml'), 'r'))\n    best_config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path is not None:\n        if output_path.endswith('.yaml') or output_path.endswith('.yml'):\n            with open(output_path, 'w') as f:\n                yaml.dump(best_config_dict, f)\n        else:\n            raise ValueError(\"The output file extension must be .yaml or .yml if provided.\")\n\n    return best_config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.load(open(os.path.join(trial_path, 'config.yaml'), 'r'), Loader=yaml.FullLoader)\n    config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path is not None:\n        if output_path.endswith('.yaml') or output_path.endswith('.yml'):\n            with open(output_path, 'w') as f:\n                yaml.dump(config_dict, f)\n        else:\n            raise ValueError('output_path must have .yaml or .yml extension.')\n\n    return config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    # Load summary file\n    summary_df = load_summary_file(trial_path)\n\n    # Load config file\n    with open(os.path.join(trial_path, 'config.yaml'), 'r') as config_file:\n        config_dict = yaml.load(config_file, Loader=yaml.FullLoader)\n\n    # Extract best config\n    best_config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    # Save to file if specified\n    if output_path is not None:\n        if output_path.endswith('.yaml') or output_path.endswith('.yml'):\n            with open(output_path, 'w') as output_file:\n                yaml.dump(best_config_dict, output_file)\n        else:\n            raise ValueError('output_path must have a .yaml or .yml extension if specified.')\n\n    return best_config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    # load summary\n    summary_df = load_summary_file(os.path.join(trial_path, 'summary.csv'))\n    summary_df = summary_df.sort_values(by='best_execution_time')\n    best_row = summary_df.iloc[0]\n    best_config = summary_df_to_yaml(summary_df, yaml.safe_load(open(os.path.join(trial_path, 'config.yaml'))))\n\n    # save best config\n    if output_path is not None:\n        if not output_path.endswith('.yaml') and not output_path.endswith('.yml'):\n            raise ValueError('output_path must have file extension .yaml or .yml')\n        with open(output_path, 'w') as f:\n            yaml.safe_dump(best_config, f)\n\n    return best_config\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.load(open(os.path.join(trial_path, 'config.yaml'), 'r'), Loader=yaml.FullLoader)\n    config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path is not None:\n        if output_path.endswith('.yaml') or output_path.endswith('.yml'):\n            with open(output_path, 'w') as f:\n                yaml.dump(config_dict, f)\n        else:\n            raise ValueError('output_path must have a .yaml or .yml file extension.')\n\n    return config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    # Load summary and config files\n    summary_df = load_summary_file(os.path.join(trial_path, 'summary.csv'))\n    config_dict = yaml.safe_load(open(os.path.join(trial_path, 'config.yaml'), 'r'))\n\n    # Extract best pipeline configuration\n    best_config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    # Save configuration to file\n    if output_path is not None:\n        if output_path.endswith('.yaml') or output_path.endswith('.yml'):\n            with open(output_path, 'w') as f:\n                yaml.safe_dump(best_config_dict, f)\n        else:\n            raise ValueError('output_path must have a .yaml or .yml file extension if specified.')\n\n    return best_config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.load(open(os.path.join(trial_path, 'config.yaml'), 'r'), Loader=yaml.FullLoader)\n    best_config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path is not None:\n        if not output_path.endswith('.yaml') and not output_path.endswith('.yml'):\n            raise ValueError('The output file path must have a .yaml or .yml extension.')\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config_dict, f)\n\n    return best_config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.load(open(os.path.join(trial_path, 'config.yaml'), 'r'), Loader=yaml.FullLoader)\n    best_config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path is not None:\n        if not output_path.endswith('.yaml') and not output_path.endswith('.yml'):\n            raise ValueError(f'The output file extension must be .yaml or .yml. The specified output path is {output_path}')\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config_dict, f)\n\n    return best_config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.load(open(os.path.join(trial_path, 'config.yaml'), 'r'), Loader=yaml.FullLoader)\n    best_config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path is not None:\n        if not output_path.endswith('.yaml') and not output_path.endswith('.yml'):\n            raise ValueError('output_path must have .yaml or .yml extension.')\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config_dict, f)\n\n    return best_config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    # Load summary and config files\n    summary_df = load_summary_file(os.path.join(trial_path, 'summary.csv'))\n    config_dict = yaml.safe_load(open(os.path.join(trial_path, 'config.yaml'), 'r'))\n\n    # Extract best config\n    best_config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    # Save best config to file\n    if output_path is not None:\n        if output_path.endswith('.yaml') or output_path.endswith('.yml'):\n            yaml.dump(best_config_dict, open(output_path, 'w'))\n        else:\n            raise ValueError('The output_path must end with .yaml or .yml if provided.')\n\n    # Return best config\n    return best_config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.safe_load(open(os.path.join(trial_path, 'config.yaml'), 'r'))\n    config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path is not None:\n        if output_path.endswith('.yaml') or output_path.endswith('.yml'):\n            yaml.safe_dump(config_dict, open(output_path, 'w'))\n        else:\n            raise ValueError(f'The output file path must have .yaml or .yml file extension. The given path is {output_path}.')\n\n    return config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    # Read the summary file\n    summary_df = load_summary_file(os.path.join(trial_path, 'summary.csv'))\n\n    # Read the configuration file\n    with open(os.path.join(trial_path, 'config.yaml'), 'r') as f:\n        config_dict = yaml.load(f, Loader=yaml.FullLoader)\n\n    # Extract the best configuration\n    best_config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    # Save the best configuration to a YAML file if output_path is specified\n    if output_path is not None:\n        if not output_path.endswith('.yaml') and not output_path.endswith('.yml'):\n            raise ValueError('output_path must end with .yaml or .yml if provided.')\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config_dict, f)\n\n    return best_config_dict\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    if ts_compiler is None:\n        ts_compiler = lambda m, **kwargs: m\n    cache = {}\n    lock = threading.Lock()\n\n    @functools.wraps(func)\n    def wrapped(*args, **kwargs):\n        nonlocal cache\n        nonlocal lock\n        key = (args, tuple(sorted(kwargs.items())))\n        with lock:\n            if key in cache:\n                traced_module = cache[key]\n            else:\n                if inspect.isfunction(func):\n                    traced_module = ts_compiler(\n                        torch.jit.trace(func, args, **kwargs_), **kwargs_)\n                else:\n                    traced_module = ts_compiler(\n                        torch.jit.trace(func.forward, args, **kwargs_), **kwargs_)\n                cache[key] = traced_module\n        return traced_module(*args, **kwargs)\n\n    return wrapped\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    def wrapped(*args, **kwargs):\n        if wrapped.cache is None:\n            wrapped.cache = {}\n        key = (func, tuple(args), tuple(sorted(kwargs.items())))\n        if key not in wrapped.cache:\n            with wrapped.lock:\n                if key not in wrapped.cache:\n                    traced_module, _ = trace_with_kwargs(func,\n                                                         example_inputs=args,\n                                                         example_kwarg_inputs=kwargs,\n                                                         **kwargs_)\n                    if ts_compiler is not None:\n                        traced_module = ts_compiler(traced_module)\n                    wrapped.cache[key] = traced_module\n        return wrapped.cache[key](*args, **kwargs)\n\n    wrapped.lock = threading.Lock()\n    wrapped.cache = None\n    return wrapped\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    if ts_compiler is None:\n        ts_compiler = lambda m, **kwargs: m\n\n    traced_modules = {}\n    lock = threading.Lock()\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        if len(args) > 0 and isinstance(args[0], torch.nn.Module):\n            args = args[1:]\n        with lock:\n            if func in traced_modules:\n                traced_module = traced_modules[func]\n            else:\n                traced_module, _ = trace_with_kwargs(func, *args, **kwargs_)\n                traced_module = ts_compiler(traced_module, **kwargs)\n                traced_modules[func] = traced_module\n        return traced_module(*args, **kwargs)\n\n    return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    if not hasattr(lazy_trace, 'cache'):\n        lazy_trace.cache = {}\n        lazy_trace.lock = threading.Lock()\n\n    def trace_func(func_, *args, **kwargs):\n        key = (func_, args, tuple(sorted(kwargs.items())))\n        with lazy_trace.lock:\n            if key not in lazy_trace.cache:\n                lazy_trace.cache[key] = trace_with_kwargs(func_,\n                                                          args,\n                                                          kwargs,\n                                                          **kwargs_)\n        return lazy_trace.cache[key]\n\n    if inspect.isfunction(func) or inspect.ismethod(func):\n        return lambda *args, **kwargs: trace_func(func, *args, **kwargs)\n    elif isinstance(func, torch.nn.Module):\n        return TraceableModuleWrapper(func, trace_func, ts_compiler)\n    else:\n        raise ValueError(\n            f'The provided function or module {func} is not supported.')\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    # Create a lock to ensure thread safety\n    lock = threading.Lock()\n\n    # Create a cache to store traced modules\n    cache = {}\n\n    # Create a wrapper function to trace the forward method of a module\n    def trace_forward_method(module, *args, **kwargs):\n        # Get the module's forward method\n        forward = module.forward\n\n        # Create a wrapper function to trace the forward method\n        def forward_wrapper(*args, **kwargs):\n            # Get the key for the cache\n            key = (forward, args, kwargs)\n\n            # Acquire the lock\n            lock.acquire()\n\n            # If the key is not in the cache, trace the forward method\n            if key not in cache:\n                # Trace the forward method\n                traced_forward = torch.jit.trace(forward, args, **kwargs_)\n\n                # If a compiler is provided, compile the traced forward method\n                if ts_compiler is not None:\n                    traced_forward = ts_compiler(traced_forward, **kwargs_)\n\n                # Update the cache\n                cache[key] = traced_forward\n\n            # Release the lock\n            lock.release()\n\n            # Return the traced forward method\n            return cache[key](*args, **kwargs)\n\n        # Return the wrapper function\n        return forward_wrapper\n\n    # Create a wrapper function to trace the function\n    def trace_function(func, *args, **kwargs):\n        # Get the key for the cache\n        key = (func, args, kwargs)\n\n        # Acquire the lock\n        lock.acquire()\n\n        # If the key is not in the cache, trace the function\n        if key not in cache:\n            # Trace the function\n            traced_func = torch.jit.trace(func, args, **kwargs_)\n\n            # If a compiler is provided, compile the traced function\n            if ts_compiler is not None:\n                traced_func = ts_compiler(traced_func, **kwargs_)\n\n            # Update the cache\n            cache[key] = traced_func\n\n        # Release"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    if not hasattr(lazy_trace, 'cache'):\n        lazy_trace.cache = {}\n\n    def traced_func(*args, **kwargs):\n        key = (func, tuple(args), tuple(kwargs.items()))\n        if key not in lazy_trace.cache:\n            with threading.Lock():\n                if key not in lazy_trace.cache:\n                    if inspect.isfunction(func):\n                        traced_module = better_trace(func, args, **kwargs_)\n                    elif isinstance(func, torch.nn.Module):\n                        traced_module = better_trace(func, args, **kwargs_)\n                    else:\n                        raise ValueError(\n                            'lazy_trace only accepts functions or modules as input')\n                    if ts_compiler is not None:\n                        traced_module = ts_compiler(traced_module, **kwargs_)\n                    lazy_trace.cache[key] = traced_module\n        return lazy_trace.cache[key](*args, **kwargs)\n\n    return traced_func\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    # Create a lock to ensure thread safety.\n    lock = threading.Lock()\n\n    # Create a cache to store traced modules.\n    cache = {}\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        # Get the key for the cache.\n        key = get_key(func, args, kwargs)\n\n        # Get the traced module from the cache.\n        with lock:\n            traced_module = cache.get(key, None)\n\n        # Trace the module if it is not in the cache.\n        if traced_module is None:\n            # Trace the module.\n            traced_module = trace_with_kwargs(func, *args, **kwargs_)\n\n            # Compile the traced module if a compiler is provided.\n            if ts_compiler is not None:\n                traced_module = ts_compiler(traced_module, *args, **kwargs_)\n\n            # Store the traced module in the cache.\n            with lock:\n                cache[key] = traced_module\n\n        # Run the traced module.\n        return traced_module(*args, **kwargs)\n\n    return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    # Get the cache of traced modules\n    traced_module_cache = getattr(lazy_trace, 'traced_module_cache', {})\n\n    # Get the cache of traced module compilers\n    traced_module_compiler_cache = getattr(\n        lazy_trace, 'traced_module_compiler_cache', {})\n\n    # Get the cache of traced module call helpers\n    traced_module_call_helper_cache = getattr(\n        lazy_trace, 'traced_module_call_helper_cache', {})\n\n    # Get the cache of traced module call helpers\n    traced_module_training_cache = getattr(\n        lazy_trace, 'traced_module_training_cache', {})\n\n    # Get the lock for thread safety\n    traced_module_lock = getattr(lazy_trace, 'traced_module_lock', threading.Lock())\n\n    # Get the lock for thread safety\n    traced_module_compiler_lock = getattr(\n        lazy_trace, 'traced_module_compiler_lock', threading.Lock())\n\n    # Get the lock for thread safety\n    traced_module_call_helper_lock = getattr(\n        lazy_trace, 'traced_module_call_helper_lock', threading.Lock())\n\n    # Get the lock for thread safety\n    traced_module_training_lock = getattr(\n        lazy_trace, 'traced_module_training_lock', threading.Lock())\n\n    # Create a wrapper function to trace the module\n    def wrapper_func(module, *args, **kwargs):\n\n        # Get the name of the module\n        name = module.__class__.__name__\n\n        # Get the signature of the module\n        signature = inspect.signature(module.forward)\n\n        # Get the parameters of the module\n        parameters = signature.parameters\n\n        # Get the parameter names of the module\n        parameter_names = list(parameters.keys())\n\n        # Get the parameter annotations of the module\n        parameter_annotations = list(parameters.values"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    # Create a lock for thread safety\n    lock = threading.Lock()\n\n    # Create a cache for traced modules\n    cache = {}\n\n    # Create a wrapper to trace the function or module's forward method\n    @functools.wraps(func)\n    def traced_wrapper(*args, **kwargs):\n        # Check if the function or module's forward method has been traced\n        with lock:\n            key = (args, tuple(sorted(kwargs.items())))\n            if key not in cache:\n                # Trace the function or module's forward method\n                if inspect.isfunction(func):\n                    traced_func = torch.jit.trace(func, args, **kwargs_)\n                elif isinstance(func, torch.nn.Module):\n                    traced_func = torch.jit.trace(func, args, **kwargs_)\n                else:\n                    raise ValueError(\n                        \"The provided function or module is not supported.\")\n                # Compile the traced function or module's forward method if a compiler is provided\n                if ts_compiler is not None:\n                    traced_func = ts_compiler(traced_func, **kwargs_)\n                # Cache the traced function or module's forward method\n                cache[key] = traced_func\n        # Return the traced function or module's forward method\n        return cache[key](*args, **kwargs)\n\n    # Return the wrapped function or module\n    return traced_wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    # Initialize the tracing cache\n    tracing_cache = {}\n    tracing_cache_lock = threading.Lock()\n\n    # Define the wrapped function\n    @functools.wraps(func)\n    def wrapped_func(*args, **kwargs):\n\n        # Determine whether the function is a module or a function\n        is_module = isinstance(func, torch.nn.Module)\n\n        # Determine the key for the tracing cache\n        if is_module:\n            key = id(func)\n        else:\n            key = str(func) + str(args) + str(kwargs)\n\n        # Acquire the tracing cache lock\n        tracing_cache_lock.acquire()\n\n        # Check if the traced module is in the tracing cache\n        if key in tracing_cache:\n\n            # Load the traced module from the tracing cache\n            traced_module = tracing_cache[key]\n\n        else:\n\n            # Trace the module or function\n            traced_module, _ = trace_with_kwargs(func,\n                                                 example_inputs=args,\n                                                 example_kwarg_inputs=kwargs,\n                                                 **kwargs_)\n\n            # Store the traced module in the tracing cache\n            tracing_cache[key] = traced_module\n\n        # Release the tracing cache lock\n        tracing_cache_lock.release()\n\n        # Compile the traced module or call helper if a compiler is provided\n        if ts_compiler is not None:\n            traced_module = ts_compiler(traced_module)\n\n        # Determine whether to call the module or call helper\n        if is_module:\n            return traced_module(*args, **kwargs)\n        else:\n            return traced_module.forward(*args, **kwargs)\n\n    # Return the wrapped function\n    return wrapped_func\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    # Use a lock to ensure thread safety when accessing or updating the cache of traced modules.\n    lock = threading.Lock()\n\n    # Create a cache to store traced modules.\n    cache = {}\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        # Flatten the input arguments.\n        args_ = flat_tensors.flattern(args)\n        kwargs_ = flat_tensors.flattern(kwargs)\n        # Flatten the keyword arguments.\n        kwargs_ = flat_tensors.flattern(kwargs)\n        # Get the key for the cache.\n        key = (id(func), tuple(args_), tuple(kwargs_.items()))\n        # Get the traced module.\n        with lock:\n            traced_module = cache.get(key)\n        # If the traced module is not cached, trace the function or module's forward method.\n        if traced_module is None:\n            # Trace the function or module's forward method.\n            traced_module = trace_with_kwargs(func, args_, kwargs_, **kwargs_)\n            # If a compiler function is provided, compile the traced module or its call helper.\n            if ts_compiler is not None:\n                traced_module = ts_compiler(traced_module)\n            # Cache the traced module.\n            with lock:\n                cache[key] = traced_module\n        # Return the traced module.\n        return traced_module\n\n    return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        if func in wrapper.cache:\n            traced_module = wrapper.cache[func]\n        else:\n            traced_module, _ = trace_with_kwargs(func, *args, **kwargs_)\n            if ts_compiler is not None:\n                traced_module = ts_compiler(traced_module)\n            wrapper.cache[func] = traced_module\n        return traced_module(*args, **kwargs)\n\n    wrapper.cache = {}\n    wrapper.lock = threading.Lock()\n    return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    if ts_compiler is None:\n        ts_compiler = lambda x: x\n\n    # Define a wrapper function to wrap the original function or module's forward method.\n    @functools.wraps(func)\n    def wrapped(*args, **kwargs):\n        # Get the original function or module's forward method.\n        forward_func = func if inspect.isfunction(func) else func.forward\n\n        # Get the input arguments to the forward method.\n        args = list(args)\n        kwargs = dict(kwargs)\n\n        # Use the input arguments to generate a unique key for caching.\n        key = (forward_func, tuple(args), tuple(kwargs.items()))\n\n        # Use a lock to ensure thread safety.\n        with wrapped._lock:\n            # Check if the key exists in the cache.\n            if key in wrapped._cache:\n                # Use the cached traced module if the key exists.\n                traced_module = wrapped._cache[key]\n            else:\n                # Trace the function or module's forward method.\n                traced_module = trace_with_kwargs(forward_func,\n                                                  example_inputs=args,\n                                                  example_kwarg_inputs=kwargs,\n                                                  **kwargs_)\n                # Compile the traced module with the compiler function.\n                traced_module = ts_compiler(traced_module)\n                # Cache the traced module.\n                wrapped._cache[key] = traced_module\n\n        # Return the traced module.\n        return traced_module\n\n    # Initialize the cache.\n    wrapped._cache = {}\n    # Initialize the lock.\n    wrapped._lock = threading.Lock()\n\n    # Return the wrapped function.\n    return wrapped\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    # Create a lock to ensure thread safety when accessing or updating the cache of traced modules.\n    trace_lock = threading.Lock()\n\n    # Create a cache to store traced modules.\n    trace_cache = {}\n\n    @functools.wraps(func)\n    def traced_func(*args, **kwargs):\n        # Get the function's signature.\n        func_sig = inspect.signature(func)\n        # Bind the inputs to the function's signature.\n        bound_args = func_sig.bind(*args, **kwargs)\n        # Get the function's inputs as a dictionary.\n        bound_args_dict = bound_args.arguments\n        # Convert the dictionary to a hashable tuple.\n        bound_args_tuple = tuple(bound_args_dict.items())\n        # Hash the tuple.\n        bound_args_tuple_hash = hash(bound_args_tuple)\n        # Check if the function has been traced before.\n        with trace_lock:\n            if bound_args_tuple_hash in trace_cache:\n                # If the function has been traced before, return the traced module.\n                traced_module = trace_cache[bound_args_tuple_hash]\n            else:\n                # If the function has not been traced before, trace it.\n                traced_module, _ = trace_with_kwargs(func,\n                                                     example_kwarg_inputs=bound_args_dict,\n                                                     **kwargs_)\n                # Cache the traced module.\n                trace_cache[bound_args_tuple_hash] = traced_module\n        # If a compiler is provided, compile the traced module.\n        if ts_compiler is not None:\n            traced_module = ts_compiler(traced_module, **kwargs_)\n        # Return the traced module.\n        return traced_module\n\n    # Return the wrapped function.\n    return traced_func\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    # Create a lock to ensure thread safety\n    lock = threading.Lock()\n\n    # Create a cache to store traced modules\n    cache = {}\n\n    # Create a decorator that wraps the forward method of a module\n    def decorator(module):\n\n        # Create a wrapper function that wraps the forward method\n        @functools.wraps(module.forward)\n        def wrapper(*args, **kwargs):\n\n            # Get the module's forward method\n            forward_method = module.forward\n\n            # Get the module's forward method's name\n            forward_method_name = forward_method.__name__\n\n            # Get the module's forward method's signature\n            forward_method_signature = inspect.signature(forward_method)\n\n            # Get the module's forward method's parameters\n            forward_method_parameters = forward_method_signature.parameters\n\n            # Get the module's forward method's parameter names\n            forward_method_parameter_names = forward_method_parameters.keys()\n\n            # Get the module's forward method's parameter names and values\n            forward_method_parameter_name_value_pairs = zip(\n                forward_method_parameter_names, args, kwargs)\n\n            # Create a key for the cache that uniquely identifies the traced module\n            key = (id(module), forward_method_name,\n                   forward_method_parameter_name_value_pairs)\n\n            # Acquire the lock to ensure thread safety\n            lock.acquire()\n\n            # If the module is not in the cache, trace the module\n            if key not in cache:\n\n                # Trace the module\n                traced_module = trace_with_kwargs(\n                    module, *args, **kwargs_, **kwargs)[0]\n\n                # If a compiler is provided, compile the traced module\n                if ts_compiler is not None:\n\n                    # Compile the traced module\n                    traced_module = ts_compiler(traced_module, **kwargs_)\n\n                # Add the traced module to the cache\n                cache[key] = traced"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    traced_modules = {}\n    traced_modules_lock = threading.Lock()\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        if ts_compiler is not None and not callable(ts_compiler):\n            raise ValueError(\n                f\"ts_compiler is expected to be callable, but is {ts_compiler}\")\n        # TODO: Add support for torch.jit.RecursiveScriptModule.\n        if isinstance(func, torch.jit.ScriptModule):\n            raise NotImplementedError(\n                \"ts_compiler does not support torch.jit.ScriptModule\")\n        if isinstance(func, torch.jit.ScriptFunction):\n            raise NotImplementedError(\n                \"ts_compiler does not support torch.jit.ScriptFunction\")\n        if isinstance(func, torch.jit.TopLevelTracedModule):\n            raise NotImplementedError(\n                \"ts_compiler does not support torch.jit.TopLevelTracedModule\")\n        if isinstance(func, torch.jit.TracedModule):\n            raise NotImplementedError(\n                \"ts_compiler does not support torch.jit.TracedModule\")\n        if isinstance(func, torch.nn.Module):\n            if len(args) > 0 or len(kwargs) > 0:\n                raise ValueError(\n                    \"lazy_trace does not support input arguments with a torch.nn.Module input\")\n            func = func.forward\n        if inspect.isfunction(func):\n            if len(args) > 0 or len(kwargs) > 0:\n                raise ValueError(\n                    \"lazy_trace does not support input arguments with a function input\")\n            key = func\n        else:\n            key = (func, args, kwargs)\n        with traced_modules_lock:\n            if key not in traced_modules:\n                traced_modules[key] = trace_with_kwargs(func,\n                                                        example_inputs=args,\n                                                        example_"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    if ts_compiler is None:\n        ts_compiler = lambda m, **kwargs: m\n\n    # The traced modules are cached in a dictionary. The key is a tuple of the function's code and the kwargs used to trace the function.\n    traced_modules_cache = {}\n    traced_modules_lock = threading.Lock()\n\n    # The wrapped function is used to trace the function or module's forward method.\n    @functools.wraps(func)\n    def wrapped(*args, **kwargs):\n        # The code of the function is used as the key to the traced modules cache.\n        code = func.__code__ if inspect.isfunction(func) else func.forward.__code__\n        # The key is a tuple of the code and the kwargs used to trace the function.\n        key = (code, tuple(sorted(kwargs.items())))\n\n        # The traced modules cache is accessed in a thread-safe manner.\n        with traced_modules_lock:\n            # If the key is in the cache, the traced module is retrieved from the cache.\n            if key in traced_modules_cache:\n                traced_module = traced_modules_cache[key]\n            # Otherwise, the function or module is traced and the traced module is cached.\n            else:\n                traced_module = ts_compiler(func, **kwargs)\n                traced_modules_cache[key] = traced_module\n\n        # The traced module is called with the given arguments.\n        return traced_module(*args, **kwargs)\n\n    # The wrapped function is returned.\n    return wrapped\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    # Initialize the trace cache.\n    trace_cache = {}\n    trace_lock = threading.Lock()\n\n    def traced_func(*args, **kwargs):\n        # Retrieve the current tracing key.\n        tracing_key = get_tracing_key(args, kwargs)\n\n        # Acquire the trace lock.\n        trace_lock.acquire()\n\n        # Check if the trace exists in the cache.\n        if tracing_key not in trace_cache:\n            # If it does not, trace the function or module.\n            traced_module = trace_with_kwargs(func,\n                                              example_inputs=args,\n                                              example_kwarg_inputs=kwargs,\n                                              **kwargs_)\n            # If a compiler is provided, use it to compile the traced module.\n            if ts_compiler is not None:\n                traced_module = ts_compiler(traced_module[0], **kwargs_)\n            # Cache the traced module.\n            trace_cache[tracing_key] = traced_module\n        # Release the trace lock.\n        trace_lock.release()\n\n        # Return the traced module.\n        return trace_cache[tracing_key]\n\n    # Return the traced function.\n    return traced_func\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    # Get the lock.\n    lock = getattr(lazy_trace, 'lock', None)\n    if lock is None:\n        lazy_trace.lock = threading.Lock()\n\n    # Get the traced module cache.\n    cache = getattr(lazy_trace, 'cache', None)\n    if cache is None:\n        lazy_trace.cache = {}\n\n    # Get the traced module cache key.\n    key = (id(func), ts_compiler, tuple(sorted(kwargs_.items())))\n\n    # Return the cached traced module if it exists.\n    if key in lazy_trace.cache:\n        return lazy_trace.cache[key]\n\n    # Otherwise, trace the function or module.\n    else:\n\n        # Trace the function or module.\n        with lazy_trace.lock:\n\n            # Check if the traced module was created in another thread while the lock was acquired.\n            if key in lazy_trace.cache:\n                return lazy_trace.cache[key]\n\n            # Trace the function or module.\n            traced_module = trace_with_kwargs(func, **kwargs_)\n\n            # Compile the traced module if a compiler is provided.\n            if ts_compiler is not None:\n                traced_module = ts_compiler(traced_module, **kwargs_)\n\n            # Cache the traced module.\n            lazy_trace.cache[key] = traced_module\n\n            # Return the traced module.\n            return traced_module\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    # Handle the case where the function is a torch.nn.Module\n    if isinstance(func, torch.nn.Module):\n        func = func.forward\n\n    # Create a lock to ensure thread safety\n    lock = threading.Lock()\n\n    # Create a cache for storing the traced modules\n    cache = {}\n\n    # Define the function that will be returned\n    @functools.wraps(func)\n    def traced_func(*args, **kwargs):\n\n        # Use the lock to ensure thread safety\n        with lock:\n\n            # Get the key for the traced module\n            key = (func, args, tuple(sorted(kwargs.items())))\n\n            # If the traced module is in the cache, return it\n            if key in cache:\n                return cache[key]\n\n            # Otherwise, trace the module and store it in the cache\n            else:\n                traced_module = trace_with_kwargs(func, *args, **kwargs_)[0]\n                if ts_compiler is not None:\n                    traced_module = ts_compiler(traced_module, *args, **kwargs)\n                cache[key] = traced_module\n                return traced_module\n\n    # Return the wrapped function\n    return traced_func\n\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        yaml_path = os.path.join(trial_path, 'best_config.yaml')\n        return cls.from_yaml(yaml_path, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config = extract_best_config(trial_path)\n        return cls(config, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config = extract_best_config(trial_path)\n        return cls(config, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        return cls.from_yaml(os.path.join(trial_path, 'best_config.yaml'), project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config = extract_best_config(trial_path)\n        return cls(config, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config = extract_best_config(trial_path)\n        return cls(config, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        return cls.from_yaml(os.path.join(trial_path, 'best_config.yaml'), os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config = extract_best_config(trial_path)\n        return cls(config, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config = extract_best_config(trial_path)\n        return cls(config, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config = extract_best_config(trial_path)\n        return cls(config, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config = extract_best_config(trial_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls(config, project_dir=project_dir)\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config = extract_best_config(trial_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls(config, project_dir=project_dir)\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        return cls.from_yaml(os.path.join(trial_path, 'best_config.yaml'), os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config = extract_best_config(trial_path)\n        return cls(config, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        return cls.from_yaml(os.path.join(trial_path, 'best_config.yaml'), project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        yaml_path = os.path.join(trial_path, 'best_config.yaml')\n        return cls.from_yaml(yaml_path, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config = extract_best_config(trial_path)\n        return cls(config, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        yaml_path = os.path.join(trial_path, 'best_config.yaml')\n        return cls.from_yaml(yaml_path, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config = extract_best_config(trial_path)\n        return cls(config, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        if not os.path.exists(trial_path):\n            raise ValueError(f\"Trial path {trial_path} does not exist.\")\n        trial_path = os.path.abspath(trial_path)\n        config_path = os.path.join(trial_path, \"config.yaml\")\n        if not os.path.exists(config_path):\n            raise ValueError(f\"Config file {config_path} does not exist.\")\n        return cls.from_yaml(config_path, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    logger.info(\"Running retrieval node\")\n\n    # Create a directory for this node line\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Evaluate and select the best module result\n    best_result, best_module_name, best_module_params, best_module_time = select_best_average(modules, module_params, previous_result, strategies)\n\n    # Save the best result\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n\n    # Save the best module name\n    with open(os.path.join(node_line_dir, \"best_module_name.txt\"), \"w\") as f:\n        f.write(best_module_name)\n\n    # Save the best module parameters\n    with open(os.path.join(node_line_dir, \"best_module_params.txt\"), \"w\") as f:\n        f.write(str(best_module_params))\n\n    # Save the best module execution time\n    with open(os.path.join(node_line_dir, \"best_module_time.txt\"), \"w\") as f:\n        f.write(str(best_module_time))\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Create a directory for this node line\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Evaluate each module and select the best one\n    module_results = []\n    for module, params in zip(modules, module_params):\n        logger.info(f\"Evaluating {module.__name__} with {params}\")\n        module_result = evaluate_retrieval(module, params, previous_result, node_line_dir)\n        module_results.append(module_result)\n\n    # Measure execution times\n    module_results = measure_speed(module_results)\n\n    # Apply strategies\n    if \"threshold\" in strategies:\n        module_results = filter_by_threshold(module_results, strategies[\"threshold\"])\n    if \"select\" in strategies:\n        module_results = select_best_average(module_results, strategies[\"select\"])\n\n    # Save results\n    for module_result in module_results:\n        module_result.to_csv(os.path.join(node_line_dir, f\"{module_result.name}.csv\"), index=False)\n\n    # Save summary\n    summary_file = os.path.join(node_line_dir, \"summary.csv\")\n    module_results.to_csv(summary_file, index=False)\n\n    # Load the best result\n    best_result = load_summary_file(summary_file)\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Create node line directory if it doesn't exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Evaluate each module\n    module_results = []\n    for module, params in zip(modules, module_params):\n        logger.info(f\"Evaluating module {module.__name__} with parameters {params}\")\n        result = module(previous_result, **params)\n        module_results.append(result)\n\n    # Measure speed for each module\n    module_speed_results = measure_speed(module_results)\n\n    # Apply strategies\n    selected_result = select_best_average(module_results, module_speed_results, strategies)\n\n    # Save results\n    for result, speed_result in zip(module_results, module_speed_results):\n        result.to_csv(os.path.join(node_line_dir, \"module_result.csv\"), index=False)\n        speed_result.to_csv(os.path.join(node_line_dir, \"module_speed_result.csv\"), index=False)\n\n    # Save summary\n    summary = load_summary_file(node_line_dir)\n    summary[\"module_results\"] = module_results\n    summary[\"module_speed_results\"] = module_speed_results\n    summary[\"selected_result\"] = selected_result\n    summary.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    return selected_result\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # check if the node_line_dir exists\n    if not os.path.exists(node_line_dir):\n        os.makedirs(node_line_dir)\n\n    # evaluate each module\n    logger.info(\"Evaluating each module...\")\n    module_results = []\n    for module, params in zip(modules, module_params):\n        module_result = evaluate_retrieval(module, params, previous_result)\n        module_results.append(module_result)\n\n    # measure execution times\n    logger.info(\"Measuring execution times...\")\n    module_times = measure_speed(module_results)\n\n    # filter by speed\n    if \"speed_threshold\" in strategies:\n        logger.info(\"Filtering by speed...\")\n        module_results, module_times = filter_by_threshold(module_results, module_times, strategies[\"speed_threshold\"])\n\n    # select best module\n    logger.info(\"Selecting best module...\")\n    best_module_result = select_best_average(module_results, module_times, strategies[\"average_strategy\"])\n\n    # save results\n    logger.info(\"Saving results...\")\n    best_module_result.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n    module_times.to_csv(os.path.join(node_line_dir, \"times.csv\"), index=False)\n\n    return best_module_result\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Initialize the results list\n    results = []\n\n    # For each module, run the module with the given parameters\n    for module, params in zip(modules, module_params):\n\n        logger.info(f\"Running module {module.__name__} with parameters {params}\")\n\n        # Run the module\n        result = module(**params)\n\n        # Evaluate the result\n        result = evaluate_retrieval(result, previous_result, strategies)\n\n        # Append the result to the results list\n        results.append(result)\n\n    # Measure the execution times of each module\n    results = measure_speed(results, strategies)\n\n    # Apply the strategies to select the best result\n    results = filter_by_threshold(results, strategies)\n    results = select_best_average(results, strategies)\n\n    # Save the results to disk\n    results.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n\n    # Save a summary of the results to disk\n    summary = load_summary_file(results)\n    summary.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    # Return the best result\n    return results[results[\"best\"] == 1]\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # run each module with the given parameters\n    logger.info(\"Running retrieval node modules\")\n    results = []\n    for module, params in zip(modules, module_params):\n        result = module(**params)\n        if not isinstance(result, pd.DataFrame):\n            result = pd.DataFrame(result)\n        results.append(result)\n\n    # evaluate the results\n    logger.info(\"Evaluating retrieval node results\")\n    results = evaluate_retrieval(results, previous_result, strategies)\n\n    # measure execution times\n    logger.info(\"Measuring execution times\")\n    results = measure_speed(results)\n\n    # apply strategies\n    logger.info(\"Applying strategies\")\n    results = filter_by_threshold(results, strategies)\n    results = select_best_average(results)\n\n    # save results\n    logger.info(\"Saving results\")\n    results_path = os.path.join(node_line_dir, \"results.csv\")\n    results.to_csv(results_path, index=False)\n\n    # save summary\n    logger.info(\"Saving summary\")\n    summary_path = os.path.join(node_line_dir, \"summary.csv\")\n    summary = load_summary_file(results)\n    summary.to_csv(summary_path, index=False)\n\n    # return the best result\n    best_result = results.loc[results[\"best\"] == 1]\n    return best_result\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Run each module with its parameters\n    logger.info(\"Running retrieval node modules...\")\n    module_results = []\n    for module, params in zip(modules, module_params):\n        logger.info(f\"Running {module.__name__} with params {params}\")\n        module_result = module(**params)\n        module_result = pd.merge(previous_result, module_result, on=\"id\", how=\"left\")\n        module_results.append(module_result)\n\n    # Measure the execution times of each module\n    logger.info(\"Measuring execution times...\")\n    module_times = measure_speed(module_results)\n\n    # Apply strategies\n    logger.info(\"Applying strategies...\")\n    module_results, module_times = filter_by_threshold(module_results, module_times, strategies[\"speed_threshold\"])\n    module_results, module_times = select_best_average(module_results, module_times, strategies[\"evaluation_strategy\"])\n\n    # Save results and summary\n    logger.info(\"Saving results and summary...\")\n    for module_result, module_time in zip(module_results, module_times):\n        module_result.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n        module_time.to_csv(os.path.join(node_line_dir, \"times.csv\"), index=False)\n\n    return module_results[0]\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Create the output directory\n    os.makedirs(node_line_dir, exist_ok=True)\n\n    # Run each module\n    results = []\n    for module, params in zip(modules, module_params):\n        result = module(previous_result, **params)\n        results.append(result)\n\n    # Evaluate and select the best result\n    best_result = select_best_average(results, strategies)\n\n    # Save the results\n    best_result.to_csv(os.path.join(node_line_dir, \"result.csv\"), index=False)\n    for result in results:\n        result.to_csv(os.path.join(node_line_dir, \"result_raw.csv\"), index=False)\n\n    # Save the execution times\n    times = measure_speed(results)\n    times.to_csv(os.path.join(node_line_dir, \"times.csv\"), index=False)\n\n    # Save the evaluation metrics\n    metrics = evaluate_retrieval(best_result, previous_result)\n    metrics.to_csv(os.path.join(node_line_dir, \"metrics.csv\"), index=False)\n\n    # Save the summary of the execution times and evaluation metrics\n    summary = load_summary_file(node_line_dir)\n    summary.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Create directory for this node line\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Evaluate each module\n    logger.info(\"Evaluating each module...\")\n    results = []\n    for module, params in zip(modules, module_params):\n        result = evaluate_retrieval(previous_result, module, params)\n        results.append(result)\n\n    # Measure speed and select best\n    logger.info(\"Measuring speed and selecting best...\")\n    best_result = measure_speed(results, strategies)\n\n    # Filter by speed\n    if \"speed\" in strategies:\n        logger.info(\"Filtering by speed...\")\n        best_result = filter_by_threshold(best_result, strategies[\"speed\"])\n\n    # Select best average\n    if \"average\" in strategies:\n        logger.info(\"Selecting best average...\")\n        best_result = select_best_average(best_result, strategies[\"average\"])\n\n    # Save results and summary\n    logger.info(\"Saving results and summary...\")\n    best_result.to_csv(os.path.join(node_line_dir, \"result.csv\"), index=False)\n    best_result.to_csv(os.path.join(node_line_dir, \"result_with_context.csv\"), index=False)\n    best_result.to_csv(os.path.join(node_line_dir, \"result_without_context.csv\"), index=False)\n    best_result.to_csv(os.path.join(node_line_dir, \"result_without_context_and_score.csv\"), index=False)\n    best_result.to_csv(os.path.join(node_line_dir, \"result_without_context_and_score_and_idf.csv\"), index=False)\n\n    best_result_summary = pd.DataFrame(best_result.groupby(\"id\")[\"score\"].max().reset_index())\n    best_result_summary.to_csv(os.path."}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Create the directory for this node line\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Run each module and evaluate the results\n    results = []\n    for module, params in zip(modules, module_params):\n        logger.info(f\"Running {module.__name__} with parameters {params}\")\n        result = module(**params)\n        results.append(result)\n\n    # Measure the execution times\n    times = measure_speed(results)\n\n    # Evaluate the results\n    eval_results = evaluate_retrieval(results, previous_result)\n\n    # Apply the strategies\n    selected_result, selected_index = filter_by_threshold(eval_results, times, strategies)\n\n    # Save the results and the summary of the execution times and evaluation metrics\n    selected_result.to_csv(os.path.join(node_line_dir, \"selected_result.csv\"), index=False)\n    times.to_csv(os.path.join(node_line_dir, \"times.csv\"), index=False)\n    eval_results.to_csv(os.path.join(node_line_dir, \"eval_results.csv\"), index=False)\n\n    # Return the selected result\n    return results[selected_index]\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Create directory for this node line\n    if not os.path.exists(node_line_dir):\n        os.makedirs(node_line_dir)\n\n    # Run each module\n    results = []\n    for module, params in zip(modules, module_params):\n        logger.info(f\"Running {module.__name__} with parameters {params}\")\n        result = module(previous_result, **params)\n        result = pd.DataFrame(result)\n        results.append(result)\n\n    # Measure execution times\n    logger.info(\"Measuring execution times\")\n    times = measure_speed(results)\n\n    # Save results\n    logger.info(\"Saving results\")\n    for module, result in zip(modules, results):\n        result.to_csv(os.path.join(node_line_dir, f\"{module.__name__}.csv\"), index=False)\n\n    # Evaluate results\n    logger.info(\"Evaluating results\")\n    metrics = evaluate_retrieval(results, previous_result, times)\n\n    # Save metrics\n    logger.info(\"Saving metrics\")\n    metrics.to_csv(os.path.join(node_line_dir, \"metrics.csv\"), index=False)\n\n    # Apply strategies\n    logger.info(\"Applying strategies\")\n    if \"threshold\" in strategies:\n        results = filter_by_threshold(results, metrics, strategies[\"threshold\"])\n    if \"select\" in strategies:\n        results = select_best_average(results, metrics, strategies[\"select\"])\n\n    # Save summary\n    logger.info(\"Saving summary\")\n    summary = load_summary_file(node_line_dir)\n    summary = summary.append(times)\n    summary = summary.append(metrics)\n    summary.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    # Return best result\n    return results[0]\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Create the directory for this node line\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Evaluate the modules\n    module_results = []\n    module_times = []\n    for module, params in zip(modules, module_params):\n        logger.info(f\"Evaluating module {module.__name__} with params {params}\")\n        result, time = measure_speed(module, params, previous_result)\n        module_results.append(result)\n        module_times.append(time)\n\n    # Evaluate the results\n    logger.info(\"Evaluating results\")\n    module_metrics = []\n    for result in module_results:\n        module_metrics.append(evaluate_retrieval(previous_result, result))\n\n    # Apply strategies to select the best result\n    logger.info(\"Applying strategies\")\n    selected_result, selected_time, selected_metric = apply_strategies(module_results,\n                                                                      module_times,\n                                                                      module_metrics,\n                                                                      strategies)\n\n    # Save results and summary to disk\n    logger.info(\"Saving results and summary\")\n    for i, result in enumerate(module_results):\n        result.to_csv(os.path.join(node_line_dir, f\"result_{i}.csv\"), index=False)\n        module_metrics[i].to_csv(os.path.join(node_line_dir, f\"metric_{i}.csv\"), index=False)\n    pd.DataFrame({\"time\": module_times}).to_csv(os.path.join(node_line_dir, \"time.csv\"), index=False)\n    pd.DataFrame({\"selected_result\": selected_result,\n                  \"selected_time\": selected_time,\n                  \"selected_metric\": selected_metric}).to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    return selected_result\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Initialize a list to store the results\n    results = []\n\n    # Run each module with its parameters\n    for i, (module, params) in enumerate(zip(modules, module_params)):\n\n        # Run the module\n        logger.info(f\"Running module {i + 1}/{len(modules)}: {module.__name__}\")\n        result = module(**params)\n\n        # Evaluate the result\n        logger.info(f\"Evaluating module {i + 1}/{len(modules)}: {module.__name__}\")\n        result = evaluate_retrieval(result, previous_result, strategies)\n\n        # Add the module name to the result\n        result[\"module\"] = module.__name__\n\n        # Add the result to the list\n        results.append(result)\n\n    # Measure the speed of each module\n    logger.info(f\"Measuring speed of each module\")\n    results = measure_speed(results, strategies)\n\n    # Save the results to disk\n    logger.info(f\"Saving results to disk\")\n    results.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n\n    # Save a summary of the results to disk\n    logger.info(f\"Saving summary of results to disk\")\n    summary = load_summary_file(results)\n    summary.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    # Apply the strategies to select the best result\n    logger.info(f\"Selecting best result\")\n    result = select_best_average(results, strategies)\n\n    return result\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Load the summary file\n    summary_file = os.path.join(node_line_dir, \"summary.csv\")\n    if os.path.isfile(summary_file):\n        summary = load_summary_file(summary_file)\n    else:\n        summary = pd.DataFrame(columns=[\"module_name\", \"module_params\", \"speed_ratio\", \"speed_threshold\", \"eval_metric\", \"eval_threshold\", \"eval_value\"])\n\n    # Evaluate each module\n    for module_name, module_params in zip(modules, module_params):\n        logger.info(f\"Evaluating {module_name.__name__} with {module_params}\")\n        # Evaluate the module\n        result = module_name(previous_result, **module_params)\n        # Measure the speed\n        speed_ratio = measure_speed(result, previous_result)\n        # Filter by speed\n        if \"speed_threshold\" in strategies:\n            result = filter_by_threshold(result, speed_ratio, strategies[\"speed_threshold\"])\n        # Select the best result\n        if \"eval_metric\" in strategies:\n            result = select_best_average(result, strategies[\"eval_metric\"], strategies[\"eval_threshold\"])\n        # Evaluate the result\n        eval_value = evaluate_retrieval(result, previous_result, strategies[\"eval_metric\"])\n        # Save the result\n        result.to_csv(os.path.join(node_line_dir, f\"{module_name.__name__}.csv\"), index=False)\n        # Save the summary\n        summary = summary.append({\"module_name\": module_name.__name__,\n                                 \"module_params\": module_params,\n                                 \"speed_ratio\": speed_ratio,\n                                 \"speed_threshold\": strategies[\"speed_threshold\"],\n                                 \"eval_metric\": strategies[\"eval_metric\"],\n                                 \"eval_threshold\": strategies[\"eval_threshold\"],\n                                 \"eval_value\": eval_value}, ignore_index=True)"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Evaluate each module and select the best one\n    logger.info(\"Evaluating and selecting the best retrieval node result\")\n    logger.info(\"Module list: {}\".format(modules))\n    logger.info(\"Module parameters: {}\".format(module_params))\n    logger.info(\"Previous result: {}\".format(previous_result.shape))\n    logger.info(\"Strategies: {}\".format(strategies))\n\n    # Evaluate each module and select the best one\n    results = []\n    for module, params in zip(modules, module_params):\n        logger.info(\"Evaluating module: {}\".format(module))\n        logger.info(\"Module parameters: {}\".format(params))\n        result = module(previous_result, **params)\n        logger.info(\"Result: {}\".format(result.shape))\n        results.append(result)\n\n    # Measure execution time for each module\n    results_time = measure_speed(results)\n    logger.info(\"Execution times: {}\".format(results_time))\n\n    # Filter results by speed\n    if \"speed_threshold\" in strategies:\n        results_speed = filter_by_threshold(results_time, strategies[\"speed_threshold\"])\n        logger.info(\"Speed filtered results: {}\".format(results_speed))\n    else:\n        results_speed = results\n\n    # Select best result\n    result_selected = select_best_average(results_speed)\n    logger.info(\"Selected result: {}\".format(result_selected.shape))\n\n    # Evaluate selected result\n    if \"metrics\" in strategies:\n        result_selected_eval = evaluate_retrieval(result_selected, previous_result, strategies[\"metrics\"])\n    else:\n        result_selected_eval = result_selected\n\n    # Save results and summary\n    logger.info(\"Saving results and summary\")\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n    result_selected_eval.to_csv(os.path.join(node_line_dir, \"result."}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Initialize the result dataframe with the previous result\n    result = previous_result\n\n    # Initialize the summary dataframe\n    summary_df = pd.DataFrame(columns=[\"module_name\", \"module_params\", \"time\", \"metric\", \"value\"])\n\n    # Run each module with the given parameters\n    for module, params in zip(modules, module_params):\n\n        logger.info(f\"Running module: {module.__name__} with parameters: {params}\")\n\n        # Run the module\n        module_result = module(**params)\n\n        # Add the module result to the result dataframe\n        result = pd.concat([result, module_result], axis=1)\n\n        # Measure the execution time\n        time = measure_speed(module, params)\n\n        # Evaluate the module result\n        for metric in strategies[\"metrics\"]:\n            # Evaluate the module result\n            value = evaluate_retrieval(result, metric)\n\n            # Add the module result to the summary dataframe\n            summary_df = summary_df.append(\n                {\"module_name\": module.__name__, \"module_params\": params, \"time\": time, \"metric\": metric, \"value\": value},\n                ignore_index=True)\n\n    # Apply the speed threshold\n    if \"speed_threshold\" in strategies:\n        summary_df, result = filter_by_threshold(summary_df, result, strategies[\"speed_threshold\"])\n\n    # Select the best result\n    if \"select_best_average\" in strategies:\n        summary_df, result = select_best_average(summary_df, result, strategies[\"select_best_average\"])\n\n    # Save the results and summary to disk\n    result.to_csv(os.path.join(node_line_dir, \"result.csv\"), index=False)\n    summary_df.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    return result\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Check if the directory exists and create it if not\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Run the modules and evaluate them\n    results = []\n    for i, module in enumerate(modules):\n        logger.info(\"Running module {}\".format(module.__name__))\n        result = module(**module_params[i])\n        result = pd.concat([previous_result, result], axis=1)\n        result = measure_speed(result)\n        result = evaluate_retrieval(result, strategies)\n        results.append(result)\n\n    # Save the results\n    for i, result in enumerate(results):\n        result.to_csv(os.path.join(node_line_dir, \"module_{}_result.csv\".format(i)), index=False)\n\n    # Save the results summary\n    results_summary = load_summary_file(node_line_dir)\n    results_summary = results_summary.append(pd.DataFrame({\n        \"module_name\": [module.__name__ for module in modules],\n        \"module_params\": module_params,\n        \"speed_threshold\": strategies.get(\"speed_threshold\", None),\n        \"speed_metric\": strategies.get(\"speed_metric\", None),\n        \"speed_threshold_satisfied\": [result[\"speed_threshold_satisfied\"].iloc[0] for result in results],\n        \"speed_time\": [result[\"speed_time\"].iloc[0] for result in results],\n        \"speed_time_baseline\": [result[\"speed_time_baseline\"].iloc[0] for result in results],\n        \"speed_time_ratio\": [result[\"speed_time_ratio\"].iloc[0] for result in results],\n        \"speed_time_ratio_baseline\": [result[\"speed_time_ratio_baseline\"].iloc[0] for result in results],\n        \"speed_time_ratio_baseline_std\": [result[\"speed_time_ratio_baseline_std\"].iloc[0] for"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    logger.info(\"Starting retrieval node\")\n    logger.info(\"Modules: %s\", [str(module) for module in modules])\n    logger.info(\"Module params: %s\", module_params)\n    logger.info(\"Previous result: %s\", previous_result.columns)\n    logger.info(\"Node line dir: %s\", node_line_dir)\n    logger.info(\"Strategies: %s\", strategies)\n\n    # Create the node line directory if it doesn't exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Run each module and evaluate the results\n    module_results = []\n    for module, params in zip(modules, module_params):\n        module_name = module.__name__\n        logger.info(\"Running module: %s\", module_name)\n        logger.info(\"Params: %s\", params)\n        result = module(**params)\n        logger.info(\"Result: %s\", result.columns)\n        # Evaluate the results\n        module_results.append(evaluate_retrieval(result, previous_result, strategies))\n\n    # Measure the execution times\n    module_results = measure_speed(module_results)\n\n    # Apply strategies\n    logger.info(\"Applying strategies\")\n    module_results = filter_by_threshold(module_results, strategies)\n    module_results = select_best_average(module_results)\n\n    # Save the results\n    for result in module_results:\n        result.to_csv(os.path.join(node_line_dir, result[\"module\"] + \".csv\"), index=False)\n\n    # Save a summary of the results\n    summary_df = pd.DataFrame(module_results)\n    summary_df.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    # Return the best result\n    return module_results[0][\"result\"]\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Create node line directory if it does not exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Run each module with its parameters, and measure their execution time\n    module_results = []\n    module_times = []\n    for module, params in zip(modules, module_params):\n        logger.info(\"Running module: {}\".format(module.__name__))\n        module_result, module_time = measure_speed(module, params)\n        module_results.append(module_result)\n        module_times.append(module_time)\n\n    # Evaluate each module's result, and apply strategies to select the best result\n    module_metrics = []\n    for module_result in module_results:\n        module_metrics.append(evaluate_retrieval(module_result, previous_result, strategies[\"metrics\"]))\n    best_result, best_time, best_metric = select_best_average(module_results, module_times, module_metrics, strategies)\n\n    # Save the results and summary to disk\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n    best_summary = pd.DataFrame([best_time, best_metric], index=[\"time\", \"metric\"]).T\n    best_summary.to_csv(os.path.join(node_line_dir, \"best_summary.csv\"), index=False)\n    logger.info(\"Saved best result and summary to: {}\".format(node_line_dir))\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Check if previous result is not None\n    if previous_result is None:\n        raise ValueError(\"Previous result is None.\")\n\n    # Check if strategies is not None\n    if strategies is None:\n        raise ValueError(\"Strategies is None.\")\n\n    # Check if modules and module_params have same length\n    if len(modules) != len(module_params):\n        raise ValueError(\"modules and module_params have different length.\")\n\n    # Check if strategies are valid\n    if \"metrics\" not in strategies:\n        raise ValueError(\"'metrics' key is not in strategies.\")\n\n    # Check if strategies are valid\n    if \"speed_threshold\" not in strategies:\n        raise ValueError(\"'speed_threshold' key is not in strategies.\")\n\n    # Check if strategies are valid\n    if \"select_best_average\" not in strategies:\n        raise ValueError(\"'select_best_average' key is not in strategies.\")\n\n    # Create directory if it does not exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create a list of results\n    results = []\n\n    # Iterate over modules and module_params\n    for module, params in zip(modules, module_params):\n\n        # Get the name of the module\n        module_name = module.__name__\n\n        # Get the module parameters\n        module_params = params\n\n        # Create the module directory\n        module_dir = os.path.join(node_line_dir, module_name)\n\n        # Create the module directory if it does not exist\n        pathlib.Path(module_dir).mkdir(parents=True, exist_ok=True)\n\n        # Run the module\n        logger.info(\"Running module: {}\".format(module_name))\n        result = module(previous_result, **module_params)\n\n        # Check if result is not None\n        if result is None:\n            logger.warning(\"Result is None. Skipping...\")\n            continue\n\n        # Check if result is not empty"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # get support modules\n    support_modules = get_support_modules()\n\n    # make combinations of modules and parameters\n    combinations = make_combinations(modules, module_params)\n\n    # iterate over combinations\n    results = []\n    for module, params in combinations:\n\n        # get module name\n        module_name = module.__name__\n\n        # get module params\n        module_params = params[\"params\"]\n\n        # get module name\n        module_name = module.__name__\n\n        # get module params\n        module_params = params[\"params\"]\n\n        # get module params\n        module_params = params[\"params\"]\n\n        # get module name\n        module_name = module.__name__\n\n        # get module params\n        module_params = params[\"params\"]\n\n        # get module name\n        module_name = module.__name__\n\n        # get module params\n        module_params = params[\"params\"]\n\n        # get module name\n        module_name = module.__name__\n\n        # get module params\n        module_params = params[\"params\"]\n\n        # get module name\n        module_name = module.__name__\n\n        # get module params\n        module_params = params[\"params\"]\n\n        # get module name\n        module_name = module.__name__\n\n        # get module params\n        module_params = params[\"params\"]\n\n        # get module name\n        module_name = module.__name__\n\n        # get module params\n        module_params = params[\"params\"]\n\n        # get module name\n        module_name = module.__name__\n\n        # get module params\n        module_params = params[\"params\"]\n\n        # get module name\n        module_name = module.__name__\n\n        # get module params\n        module_params = params[\"params\"]\n\n        # get module name\n        module_name = module.__name__\n\n        # get module params\n        module_params = params[\"params\"]\n\n        # get module name\n        module_name = module.__name__\n\n        # get module params\n        module_params = params[\"params\"]\n\n        # get module name\n       "}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # get the support modules\n    support_modules = get_support_modules()\n\n    # create the node directory\n    node_dir = os.path.join(node_line_dir, \"query_expansion\")\n    pathlib.Path(node_dir).mkdir(exist_ok=True, parents=True)\n\n    # create the node summary file\n    node_summary_file = os.path.join(node_dir, \"node_summary.csv\")\n\n    # create the node summary file header\n    node_summary_header = [\"module\", \"module_params\", \"speed\", \"speed_threshold\", \"metric\", \"metric_threshold\", \"metric_value\"]\n    with open(node_summary_file, \"w\") as f:\n        f.write(\",\".join(node_summary_header) + \"\\n\")\n\n    # run each module\n    for i, module in enumerate(modules):\n\n        # get the module parameters\n        module_params_dict = module_params[i]\n\n        # get the module name\n        module_name = module_params_dict[\"name\"]\n\n        # get the module parameters\n        module_params_dict = module_params[i]\n\n        # get the module name\n        module_name = module_params_dict[\"name\"]\n\n        # get the module parameters\n        module_params_dict = module_params[i]\n\n        # get the module parameters\n        module_params_dict = module_params[i]\n\n        # get the module parameters\n        module_params_dict = module_params[i]\n\n        # get the module parameters\n        module_params_dict = module_params[i]\n\n        # get the module parameters\n        module_params_dict = module_params[i]\n\n        # get the module parameters\n        module_params_dict = module_params[i]\n\n        # get the module parameters\n        module_params_dict = module_params[i]\n\n        # get the module parameters\n        module_params_dict = module_params[i]\n\n        # get the module parameters\n        module_params_dict = module_params[i]"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Create the output directory\n    output_dir = os.path.join(node_line_dir, \"query_expansion\")\n    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create a list of combinations of modules and parameters\n    module_combinations = make_combinations(modules, module_params)\n\n    # Run each module with its parameters\n    results = []\n    for module, params in module_combinations:\n        logger.info(f\"Running module {module.__name__} with parameters {params}\")\n        result = evaluate_retrieval_node(module, params, previous_result, output_dir)\n        results.append(result)\n\n    # Measure the speed of each module\n    results = measure_speed(results, strategies[\"speed_threshold\"])\n\n    # Evaluate the results using the specified strategies\n    results = filter_by_threshold(results, strategies[\"speed_threshold\"])\n    results = select_best_average(results, strategies[\"average_strategy\"])\n\n    # Save the results and a summary\n    results.to_csv(os.path.join(output_dir, \"results.csv\"), index=False)\n    results.to_csv(os.path.join(output_dir, \"summary.csv\"), index=False)\n\n    # Select the best result\n    best_result = results.iloc[0]\n\n    # Save the best result\n    best_result.to_csv(os.path.join(output_dir, \"best_result.csv\"), index=False)\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Create directory for saving results and summaries\n    node_line_dir = pathlib.Path(node_line_dir)\n    node_line_dir.mkdir(parents=True, exist_ok=True)\n\n    # Get support modules\n    support_modules = get_support_modules()\n\n    # Evaluate query expansion modules\n    logger.info(\"Evaluating query expansion modules...\")\n    module_results = []\n    for module, params in zip(modules, module_params):\n        logger.info(f\"Running {module.__name__} with parameters: {params}\")\n        module_result = evaluate_retrieval_node(\n            module,\n            params,\n            previous_result,\n            support_modules,\n            node_line_dir,\n            strategies,\n        )\n        module_results.append(module_result)\n\n    # Save results and summaries\n    logger.info(\"Saving results and summaries...\")\n    for module, result in zip(modules, module_results):\n        result.to_csv(node_line_dir / f\"{module.__name__}_results.csv\", index=False)\n        result.describe().to_csv(\n            node_line_dir / f\"{module.__name__}_summary.csv\", index=True\n        )\n\n    # Filter results by speed\n    logger.info(\"Filtering results by speed...\")\n    module_results = filter_by_threshold(module_results, strategies[\"speed_threshold\"])\n\n    # Select best result\n    logger.info(\"Selecting best result...\")\n    best_result = select_best_average(module_results, strategies)\n    best_result.to_csv(node_line_dir / \"best_result.csv\", index=False)\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Get support modules\n    support_modules = get_support_modules()\n\n    # Create directory to save results\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Evaluate modules\n    results = []\n    for module, params in zip(modules, module_params):\n        logger.info(f\"Evaluating module {module.__name__} with parameters {params}\")\n        result = evaluate_retrieval_node(\n            module=module,\n            module_params=params,\n            previous_result=previous_result,\n            support_modules=support_modules,\n        )\n        results.append(result)\n\n    # Save results\n    for i, result in enumerate(results):\n        result.to_csv(os.path.join(node_line_dir, f\"result_{i}.csv\"), index=False)\n\n    # Measure speed\n    results = measure_speed(results)\n\n    # Filter by speed\n    if \"speed_threshold\" in strategies[\"query_expansion\"]:\n        results = filter_by_threshold(results, strategies[\"query_expansion\"][\"speed_threshold\"])\n\n    # Evaluate results\n    results = explode(results)\n    results = select_best_average(results, strategies[\"query_expansion\"][\"metrics\"])\n\n    # Save results\n    for i, result in enumerate(results):\n        result.to_csv(os.path.join(node_line_dir, f\"result_{i}.csv\"), index=False)\n\n    # Save summary\n    results = pd.concat(results)\n    results.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    # Save best result\n    best_result = pd.read_csv(os.path.join(node_line_dir, \"summary.csv\"))\n    best_result = best_result.sort_values(by=\"score\", ascending=False).iloc[0]\n    best_result = pd.read_csv(os.path.join("}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Create a directory for the node results\n    node_dir = os.path.join(node_line_dir, \"query_expansion\")\n    pathlib.Path(node_dir).mkdir(parents=True, exist_ok=True)\n\n    # Evaluate each module\n    results = []\n    for module, params in zip(modules, module_params):\n        logger.info(f\"Evaluating {module.__name__} with {params}\")\n        result = evaluate_retrieval_node(module, params, previous_result, node_dir)\n        results.append(result)\n\n    # Measure speed and evaluate performance\n    results = measure_speed(results, node_dir)\n    results = filter_by_threshold(results, strategies[\"speed_threshold\"])\n    results = select_best_average(results, strategies[\"average_metric\"])\n\n    # Save the results\n    results.to_csv(os.path.join(node_dir, \"results.csv\"), index=False)\n    summary = results.groupby(\"module\").mean().reset_index()\n    summary.to_csv(os.path.join(node_dir, \"summary.csv\"), index=False)\n\n    # Select the best result\n    best_result = results.loc[results[\"module\"] == results[\"best_module\"]]\n    best_result.to_csv(os.path.join(node_dir, \"best_result.csv\"), index=False)\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # create directory for saving results and summaries\n    if not os.path.exists(node_line_dir):\n        os.makedirs(node_line_dir)\n\n    # get support modules\n    support_modules = get_support_modules()\n\n    # create combinations of modules and params\n    module_combinations = make_combinations(modules, module_params)\n\n    # run modules and evaluate\n    results = []\n    for module, params in module_combinations:\n        logger.info(f\"Running module {module.__name__} with params {params}\")\n        result = evaluate_retrieval_node(module, params, previous_result, strategies)\n        results.append(result)\n\n    # save results\n    results_df = pd.concat(results)\n    results_df.to_csv(os.path.join(node_line_dir, \"query_expansion_results.csv\"), index=False)\n\n    # save results summary\n    results_summary = results_df.groupby(\"module\").agg(\n        avg_time=(\"time\", \"mean\"),\n        avg_precision=(\"precision\", \"mean\"),\n        avg_recall=(\"recall\", \"mean\"),\n        avg_f1=(\"f1\", \"mean\"),\n        avg_precision_at_k=(\"precision_at_k\", \"mean\"),\n        avg_recall_at_k=(\"recall_at_k\", \"mean\"),\n        avg_f1_at_k=(\"f1_at_k\", \"mean\"),\n        avg_num_predicted_docs=(\"num_predicted_docs\", \"mean\"),\n        avg_num_relevant_docs=(\"num_relevant_docs\", \"mean\"),\n        avg_num_relevant_docs_in_top_k=(\"num_relevant_docs_in_top_k\", \"mean\"),\n        avg_num_predicted_docs_in_top_k=(\"num_predicted_docs_in_top_k\", \"mean\"),\n    )\n    results_summary.to_"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Get support modules\n    support_modules = get_support_modules()\n\n    # Initialize results\n    results = []\n    # Iterate over modules and parameters\n    for module, params in zip(modules, module_params):\n        logger.info(f\"Evaluating module {module.__name__} with parameters {params}\")\n        # Run module\n        result = evaluate_retrieval_node(module, params, previous_result, support_modules)\n        # Measure speed\n        result = measure_speed(result)\n        # Filter by speed\n        result = filter_by_threshold(result, strategies[\"speed_threshold\"])\n        # Add module name to results\n        result[\"module\"] = module.__name__\n        # Add parameters to results\n        for param, value in params.items():\n            result[param] = value\n        # Add results to list\n        results.append(result)\n\n    # Explode results\n    results = explode(results, [\"module\", \"param\", \"value\"])\n    # Save results\n    results.to_csv(os.path.join(node_line_dir, \"query_expansion_results.csv\"), index=False)\n    # Save results summary\n    results.groupby(\"module\").mean().to_csv(os.path.join(node_line_dir, \"query_expansion_results_summary.csv\"))\n    # Save best result\n    best_result = select_best_average(results, strategies[\"selection_strategy\"])\n    best_result.to_csv(os.path.join(node_line_dir, \"best_query_expansion_result.csv\"), index=False)\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Get the support modules\n    support_modules = get_support_modules()\n\n    # Set the output directory\n    output_dir = pathlib.Path(node_line_dir) / \"query_expansion\"\n    output_dir.mkdir(parents=True, exist_ok=True)\n\n    # Set the output file names\n    output_file = output_dir / \"results.csv\"\n    summary_file = output_dir / \"summary.csv\"\n\n    # Set the strategies\n    speed_threshold = strategies[\"speed_threshold\"]\n    metrics = strategies[\"metrics\"]\n    metric_weights = strategies[\"metric_weights\"]\n    metric_thresholds = strategies[\"metric_thresholds\"]\n    metric_directions = strategies[\"metric_directions\"]\n    metric_best_results = strategies[\"metric_best_results\"]\n    metric_best_directions = strategies[\"metric_best_directions\"]\n    metric_best_directions = strategies[\"metric_best_directions\"]\n    metric_aggregation = strategies[\"metric_aggregation\"]\n\n    # Initialize the output dataframe\n    output_df = pd.DataFrame()\n\n    # Initialize the summary dataframe\n    summary_df = pd.DataFrame()\n\n    # Initialize the best result\n    best_result = pd.DataFrame()\n\n    # Initialize the best result metric\n    best_result_metric = 0\n\n    # Initialize the best result module\n    best_result_module = None\n\n    # Initialize the best result module parameters\n    best_result_module_params = None\n\n    # Initialize the best result module name\n    best_result_module_name = None\n\n    # Initialize the best result module parameters\n    best_result_module_params = None\n\n    # Initialize the best result module name\n    best_result_module_name = None\n\n    # Initialize the best result module parameters\n    best_result_module_params = None\n\n    # Initialize the best result module name\n    best_result_module_name = None\n\n    # Initialize the best result module parameters\n    best_result_module_params = None"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Initialize the output dataframe\n    node_result = pd.DataFrame()\n\n    # Create a directory for the node\n    os.makedirs(node_line_dir, exist_ok=True)\n\n    # Create a list of combinations of modules and parameters\n    module_combinations = make_combinations(modules, module_params)\n\n    # Run each combination and evaluate the results\n    for module, params in module_combinations:\n\n        # Run the module\n        result = evaluate_retrieval_node(module, params, previous_result)\n\n        # Measure the speed of the module\n        result = measure_speed(result, params)\n\n        # Save the results\n        result.to_csv(os.path.join(node_line_dir, f\"{module.__name__}.csv\"), index=False)\n\n        # Save the summary\n        result[[\"module\", \"params\", \"speed\"]].to_csv(\n            os.path.join(node_line_dir, f\"{module.__name__}_summary.csv\"), index=False\n        )\n\n        # Evaluate the results\n        result = filter_by_threshold(result, strategies)\n\n        # Save the evaluation results\n        result.to_csv(\n            os.path.join(node_line_dir, f\"{module.__name__}_evaluation.csv\"), index=False\n        )\n\n        # Select the best result\n        best_result = select_best_average(result, strategies)\n\n        # Save the best result\n        best_result.to_csv(\n            os.path.join(node_line_dir, f\"{module.__name__}_best.csv\"), index=False\n        )\n\n        # Append the best result to the output dataframe\n        node_result = pd.concat([node_result, best_result])\n\n    return node_result\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # get the support modules\n    support_modules = get_support_modules()\n\n    # make combinations of modules and parameters\n    module_combinations = make_combinations(modules, module_params)\n\n    # create a list to store results\n    results = []\n\n    # iterate over module combinations\n    for i, (module, params) in enumerate(module_combinations):\n\n        # get the name of the module\n        module_name = module.__name__\n\n        # get the module from the support modules\n        module_func = support_modules[module_name]\n\n        # run the module\n        result = module_func(previous_result, **params)\n\n        # explode the result\n        result = explode(result, [\"query\"])\n\n        # get the name of the module\n        module_name = module.__name__\n\n        # get the module from the support modules\n        module_func = support_modules[module_name]\n\n        # run the module\n        result = module_func(previous_result, **params)\n\n        # explode the result\n        result = explode(result, [\"query\"])\n\n        # get the name of the module\n        module_name = module.__name__\n\n        # get the module from the support modules\n        module_func = support_modules[module_name]\n\n        # run the module\n        result = module_func(previous_result, **params)\n\n        # explode the result\n        result = explode(result, [\"query\"])\n\n        # measure the execution time\n        execution_time = measure_speed(module_func, previous_result, **params)\n\n        # get the name of the module\n        module_name = module.__name__\n\n        # add the module name to the result\n        result[\"module\"] = module_name\n\n        # add the execution time to the result\n        result[\"execution_time\"] = execution_time\n\n        # add the parameters to the result\n        result[\"params\"] = str(params)\n\n        # append the result to the results list\n        results.append(result)\n\n    # convert the results to a dataframe\n    results ="}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # make combinations of modules and params\n    module_combinations = make_combinations(modules, module_params)\n\n    # run each module and evaluate\n    results = []\n    for module, params in module_combinations:\n        logger.info(f\"Running query expansion module {module.__name__}\")\n        result = evaluate_retrieval_node(module, params, previous_result, node_line_dir)\n        results.append(result)\n\n    # filter by speed\n    results = filter_by_threshold(results, strategies[\"speed_threshold\"])\n\n    # measure speed\n    results = measure_speed(results)\n\n    # select best\n    results = select_best_average(results, strategies[\"average_strategy\"])\n\n    # explode results\n    results = explode(results)\n\n    # save results\n    results.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n\n    # save summary\n    summary = results.groupby([\"module\", \"module_params\"]).mean().reset_index()\n    summary.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    # save best\n    best_result = results[results[\"selected\"] == 1].iloc[0]\n    best_result.to_csv(os.path.join(node_line_dir, \"best.csv\"), index=False)\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Get support modules\n    support_modules = get_support_modules()\n\n    # Define node line directory\n    node_line_dir = pathlib.Path(node_line_dir)\n\n    # Create node line directory if it does not exist\n    if not os.path.exists(node_line_dir):\n        os.makedirs(node_line_dir)\n\n    # Create results directory if it does not exist\n    results_dir = node_line_dir / \"results\"\n    if not os.path.exists(results_dir):\n        os.makedirs(results_dir)\n\n    # Create summary directory if it does not exist\n    summary_dir = node_line_dir / \"summary\"\n    if not os.path.exists(summary_dir):\n        os.makedirs(summary_dir)\n\n    # Create list of combinations of module and parameters\n    module_combinations = make_combinations(modules, module_params)\n\n    # Create list of combinations of module, parameters, and strategies\n    strategy_combinations = []\n    for module_combination in module_combinations:\n        for strategy in strategies:\n            strategy_combinations.append(\n                {\n                    \"module\": module_combination[\"module\"],\n                    \"params\": module_combination[\"params\"],\n                    \"strategy\": strategy,\n                }\n            )\n\n    # Evaluate each combination of module, parameters, and strategy\n    for strategy_combination in strategy_combinations:\n\n        # Get module\n        module = strategy_combination[\"module\"]\n\n        # Get parameters\n        params = strategy_combination[\"params\"]\n\n        # Get strategy\n        strategy = strategy_combination[\"strategy\"]\n\n        # Get strategy name\n        strategy_name = strategy[\"name\"]\n\n        # Get module name\n        module_name = module.__name__\n\n        # Get module file name\n        module_file_name = module_name.lower()\n\n        # Get module parameters\n        module_params = params[module_file_name]\n\n        # Get module"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Create a directory for the node\n    if not os.path.exists(node_line_dir):\n        os.makedirs(node_line_dir)\n\n    # Get the support modules\n    support_modules = get_support_modules()\n\n    # Create a list of all combinations of module and parameters\n    module_combinations = make_combinations(modules, module_params)\n\n    # Create a list of all combinations of module, parameters, and strategy\n    strategy_combinations = []\n    for module_combination in module_combinations:\n        for strategy in strategies:\n            strategy_combinations.append((module_combination, strategy))\n\n    # Create a list of all combinations of module, parameters, strategy, and speed threshold\n    threshold_combinations = []\n    for strategy_combination in strategy_combinations:\n        for threshold in strategies[strategy_combination[1][\"speed_threshold\"]]:\n            threshold_combinations.append((strategy_combination, threshold))\n\n    # Evaluate all combinations\n    for threshold_combination in threshold_combinations:\n        strategy_combination = threshold_combination[0]\n        module_combination = strategy_combination[0]\n        strategy = strategy_combination[1]\n        threshold = threshold_combination[1]\n\n        # Get module name\n        module_name = module_combination[0].__name__\n\n        # Get module parameters\n        module_params = module_combination[1]\n\n        # Get the module\n        module = module_combination[0]\n\n        # Get the module support module\n        support_module = support_modules[module_name]\n\n        # Get the strategy name\n        strategy_name = strategy[\"name\"]\n\n        # Get the speed threshold\n        speed_threshold = threshold\n\n        # Get the strategy parameters\n        strategy_params = strategy[\"params\"]\n\n        # Get the strategy metric\n        metric = strategy_params[\"metric\"]\n\n        # Get the strategy metric parameters\n        metric_params ="}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Create a list of combinations of modules and their parameters\n    module_combinations = make_combinations(modules, module_params)\n\n    # Evaluate each module with the given parameters\n    module_results = [\n        evaluate_retrieval_node(\n            module,\n            module_params,\n            previous_result,\n            node_line_dir,\n            strategies,\n        )\n        for module, module_params in module_combinations\n    ]\n\n    # Measure the speed of each module\n    module_results = measure_speed(module_results)\n\n    # Filter modules based on speed threshold\n    module_results = filter_by_threshold(module_results, strategies)\n\n    # Select the best module based on the specified strategies\n    best_result = select_best_average(module_results, strategies)\n\n    # Save results and summaries\n    save_results(module_results, node_line_dir)\n    save_summary(module_results, node_line_dir)\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Initialize\n    results = []\n    summaries = []\n\n    # Run each module\n    for module, params in zip(modules, module_params):\n\n        logger.info(f\"Running module {module.__name__}\")\n        result = evaluate_retrieval_node(module, params, previous_result, node_line_dir)\n        results.append(result)\n\n        # Measure speed\n        speed = measure_speed(result)\n        logger.info(f\"Speed: {speed}\")\n\n        # Evaluate performance\n        metrics = strategies[\"metrics\"]\n        for metric in metrics:\n            logger.info(f\"Evaluating {metric} metric\")\n            metric_result = result.copy()\n            metric_result[\"score\"] = metric_result[metric]\n            metric_result[\"module\"] = module.__name__\n            metric_result[\"params\"] = str(params)\n            metric_result[\"speed\"] = speed\n            summaries.append(metric_result)\n\n    # Save results and summaries\n    results_df = pd.concat(results)\n    results_df.to_csv(os.path.join(node_line_dir, \"query_expansion_results.csv\"), index=False)\n    summaries_df = pd.concat(summaries)\n    summaries_df.to_csv(os.path.join(node_line_dir, \"query_expansion_summaries.csv\"), index=False)\n\n    # Select best result\n    speed_threshold = strategies[\"speed_threshold\"]\n    logger.info(f\"Selecting best result based on speed threshold {speed_threshold}\")\n    best_result = filter_by_threshold(summaries_df, speed_threshold)\n\n    # Select best result based on average\n    metrics = strategies[\"metrics\"]\n    best_result = select_best_average(best_result, metrics)\n\n    # Save best result\n    best_result.to_csv(os.path.join(node_line_dir, \"query_expansion_best.csv\"), index=False)\n\n    return best_result"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Get support modules\n    support_modules = get_support_modules()\n\n    # Check if directory exists\n    if not os.path.exists(node_line_dir):\n        os.makedirs(node_line_dir)\n\n    # Create a list of combinations of modules and their parameters\n    combinations = make_combinations(modules, module_params)\n\n    # Create a list of results\n    results = []\n\n    # Iterate over combinations\n    for i, (module, module_params) in enumerate(combinations):\n\n        # Get module name\n        module_name = module.__name__\n\n        # Get module parameters\n        module_params_str = \"_\".join([f\"{k}_{v}\" for k, v in module_params.items()])\n\n        # Get module path\n        module_path = os.path.join(node_line_dir, f\"{module_name}_{module_params_str}.csv\")\n\n        # If the module has already been executed, skip it\n        if os.path.exists(module_path):\n            logger.info(f\"Skipping module {module_name} with parameters {module_params_str}\")\n            continue\n\n        # Execute module\n        logger.info(f\"Executing module {module_name} with parameters {module_params_str}\")\n        result = module(previous_result, **module_params)\n\n        # Explode the result\n        result = explode(result)\n\n        # Save the result\n        result.to_csv(module_path)\n\n        # Measure the execution time\n        logger.info(f\"Measuring execution time for module {module_name} with parameters {module_params_str}\")\n        time = measure_speed(module, previous_result, **module_params)\n\n        # Add execution time to result\n        result[\"time\"] = time\n\n        # Add module name to result\n        result[\"module\"] = module_name\n\n        # Add module parameters to result\n        for k, v in module_params.items():\n            result[k] = v\n\n        # Append result to results list\n        results.append"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Initialize support modules\n    support_modules = get_support_modules()\n\n    # Create directory for saving results and summaries\n    os.makedirs(node_line_dir, exist_ok=True)\n\n    # Run query expansion modules\n    results = []\n    for module, params in zip(modules, module_params):\n        result = evaluate_retrieval_node(\n            module=module,\n            params=params,\n            previous_result=previous_result,\n            support_modules=support_modules,\n        )\n        results.append(result)\n\n    # Save results\n    for result in results:\n        result.to_csv(\n            os.path.join(node_line_dir, \"query_expansion_results.csv\"),\n            sep=\",\",\n            index=False,\n            header=True,\n            encoding=\"utf-8\",\n            mode=\"a\",\n        )\n\n    # Save results summary\n    summary = pd.concat(results, ignore_index=True)\n    summary.to_csv(\n        os.path.join(node_line_dir, \"query_expansion_summary.csv\"),\n        sep=\",\",\n        index=False,\n        header=True,\n        encoding=\"utf-8\",\n    )\n\n    # Measure execution times\n    summary[\"execution_time\"] = summary[\"execution_time\"].apply(\n        lambda x: x.total_seconds()\n    )\n\n    # Filter results based on speed\n    summary = measure_speed(\n        df=summary,\n        threshold=strategies[\"speed_threshold\"],\n        time_col=\"execution_time\",\n    )\n\n    # Evaluate results\n    summary = filter_by_threshold(\n        df=summary,\n        metric=strategies[\"metric\"],\n        threshold=strategies[\"threshold\"],\n        metric_col=\"f1_score\",\n    )\n\n    # Select best result\n    best_result = select_best_average(\n        df=summary,\n        metric=strategies[\"metric\"],\n        metric_col=\"f1_score\",\n        mode=\"max\","}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Get support modules\n    support_modules = get_support_modules()\n\n    # Define the directory paths\n    node_dir = os.path.join(node_line_dir, \"query_expansion\")\n    if not os.path.exists(node_dir):\n        os.makedirs(node_dir)\n\n    # Define the result file paths\n    result_path = os.path.join(node_dir, \"results.csv\")\n    summary_path = os.path.join(node_dir, \"summary.csv\")\n\n    # Define the strategies\n    metrics = strategies[\"metrics\"]\n    speed_thresholds = strategies[\"speed_thresholds\"]\n    speed_metric = strategies[\"speed_metric\"]\n    speed_mode = strategies[\"speed_mode\"]\n    speed_sign = strategies[\"speed_sign\"]\n    best_mode = strategies[\"best_mode\"]\n    best_metric = strategies[\"best_metric\"]\n    best_sign = strategies[\"best_sign\"]\n    best_group_key = strategies[\"best_group_key\"]\n    best_group_sign = strategies[\"best_group_sign\"]\n\n    # Define the result columns\n    result_columns = [\"module\", \"module_params\", \"result\", \"execution_time\", \"speed_metric\", \"speed_mode\", \"speed_sign\", \"speed_threshold\", \"speed_value\"]\n\n    # Define the summary columns\n    summary_columns = [\"module\", \"module_params\", \"speed_metric\", \"speed_mode\", \"speed_sign\", \"speed_threshold\", \"speed_value\", \"best_metric\", \"best_mode\", \"best_sign\", \"best_group_key\", \"best_group_sign\", \"best_module\", \"best_module_params\"]\n\n    # Define the result dataframe\n    result_df = pd.DataFrame(columns=result_columns)\n\n    # Define the summary dataframe\n    summary_df = pd.DataFrame(columns=summary_columns)\n\n    # Define the result dataframe\n    best_df = pd.DataFrame(columns=previous_result.columns)\n\n    # Run the"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Get support modules\n    support_modules = get_support_modules()\n\n    # Get module names\n    module_names = [module.__name__ for module in modules]\n\n    # Get combinations of modules and parameters\n    module_combinations = make_combinations(module_names, module_params)\n\n    # Create results dataframe\n    results = pd.DataFrame()\n\n    # Loop over combinations\n    for module_name, module_param in module_combinations:\n\n        # Get module\n        module = support_modules[module_name]\n\n        # Run module\n        logger.info(\"Running module: {}\".format(module_name))\n        result = module(previous_result, **module_param)\n\n        # Get metrics\n        logger.info(\"Evaluating module: {}\".format(module_name))\n        metrics = evaluate_retrieval_node(result, strategies)\n\n        # Get speed\n        logger.info(\"Measuring speed: {}\".format(module_name))\n        speed = measure_speed(module, previous_result, module_param)\n\n        # Combine metrics and speed\n        result_dict = {**metrics, **speed}\n\n        # Add module information\n        result_dict[\"module\"] = module_name\n        result_dict[\"module_param\"] = module_param\n\n        # Append result\n        results = results.append(result_dict, ignore_index=True)\n\n    # Save results\n    results.to_csv(os.path.join(node_line_dir, \"query_expansion_results.csv\"), index=False)\n\n    # Get summary\n    summary = results.copy()\n\n    # Explode results\n    summary = explode(summary, [\"metrics\"], [\"metric\", \"value\"])\n\n    # Save summary\n    summary.to_csv(os.path.join(node_line_dir, \"query_expansion_summary.csv\"), index=False)\n\n    # Filter results by speed\n    filtered_results = filter_by_threshold(results, strategies[\"speed_threshold\"])\n\n    # Get best result\n    best_result = select"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create a directory for the node's output\n    if not os.path.exists(node_line_dir):\n        os.makedirs(node_line_dir)\n\n    # Create a directory for the node's output\n    if not os.path.exists(os.path.join(node_line_dir, \"results\")):\n        os.makedirs(os.path.join(node_line_dir, \"results\"))\n\n    # Create a directory for the node's output\n    if not os.path.exists(os.path.join(node_line_dir, \"summary\")):\n        os.makedirs(os.path.join(node_line_dir, \"summary\"))\n\n    # Create a directory for the node's output\n    if not os.path.exists(os.path.join(node_line_dir, \"best_prompt_maker\")):\n        os.makedirs(os.path.join(node_line_dir, \"best_prompt_maker\"))\n\n    # Create a directory for the node's output\n    if not os.path.exists(os.path.join(node_line_dir, \"best_prompt_maker\", \"results\")):\n        os.makedirs(os.path.join(node_line_dir, \"best_prompt_maker\", \"results\"))\n\n    # Create a directory for the node's output\n    if not os.path.exists(os.path.join(node_line_dir, \"best_prompt_maker\", \"summary\")):\n        os.makedirs(os.path.join(node_line_dir, \"best_prompt_maker\", \"summary\"))\n\n    # Create a directory for the node's output\n    if not os.path.exists(os.path.join(node_line_dir, \"best_prompt_maker\", \"best_prompts\")):\n        os.makedirs(os.path.join(node_line_dir, \"best_prompt_maker\", \"best_prompts\"))\n\n    # Create a directory for the node's output\n    if not os.path."}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Get the support modules\n    support_modules = get_support_modules()\n\n    # Get the output directory\n    output_dir = os.path.join(node_line_dir, \"prompt_maker\")\n    os.makedirs(output_dir, exist_ok=True)\n\n    # Get the output file\n    output_file = os.path.join(output_dir, \"results.csv\")\n\n    # Get the output summary file\n    output_summary_file = os.path.join(output_dir, \"summary.txt\")\n\n    # Get the output prompt file\n    output_prompt_file = os.path.join(output_dir, \"best_prompt.txt\")\n\n    # Get the output prompt file\n    output_prompt_file = os.path.join(output_dir, \"best_prompt.txt\")\n\n    # Get the output prompt file\n    output_prompt_file = os.path.join(output_dir, \"best_prompt.txt\")\n\n    # Get the output prompt file\n    output_prompt_file = os.path.join(output_dir, \"best_prompt.txt\")\n\n    # Get the output prompt file\n    output_prompt_file = os.path.join(output_dir, \"best_prompt.txt\")\n\n    # Get the output prompt file\n    output_prompt_file = os.path.join(output_dir, \"best_prompt.txt\")\n\n    # Get the output prompt file\n    output_prompt_file = os.path.join(output_dir, \"best_prompt.txt\")\n\n    # Get the output prompt file\n    output_prompt_file = os.path.join(output_dir, \"best_prompt.txt\")\n\n    # Get the output prompt file\n    output_prompt_file = os.path.join(output_dir, \"best_prompt.txt\")\n\n    # Get the output prompt file\n    output_prompt_file = os.path.join(output_dir, \"best_prompt.txt\")\n\n    # Get the output prompt file"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create the directory for the node's output\n    if not os.path.exists(node_line_dir):\n        os.makedirs(node_line_dir)\n\n    # Create the directory for the node's output\n    if not os.path.exists(os.path.join(node_line_dir, \"prompt_maker\")):\n        os.makedirs(os.path.join(node_line_dir, \"prompt_maker\"))\n\n    # Create the directory for the node's output\n    if not os.path.exists(os.path.join(node_line_dir, \"prompt_maker\", \"results\")):\n        os.makedirs(os.path.join(node_line_dir, \"prompt_maker\", \"results\"))\n\n    # Create the directory for the node's output\n    if not os.path.exists(os.path.join(node_line_dir, \"prompt_maker\", \"summary\")):\n        os.makedirs(os.path.join(node_line_dir, \"prompt_maker\", \"summary\"))\n\n    # Create the directory for the node's output\n    if not os.path.exists(os.path.join(node_line_dir, \"prompt_maker\", \"raw_results\")):\n        os.makedirs(os.path.join(node_line_dir, \"prompt_maker\", \"raw_results\"))\n\n    # Create the directory for the node's output\n    if not os.path.exists(os.path.join(node_line_dir, \"prompt_maker\", \"raw_results\", \"best\")):\n        os.makedirs(os.path.join(node_line_dir, \"prompt_maker\", \"raw_results\", \"best\"))\n\n    # Create the directory for the node's output\n    if not os.path.exists(os.path.join(node_line_dir, \"prompt_maker\", \"raw_results\", \"all\")):\n        os.makedirs(os.path.join(node_line_dir, \"prompt_maker\", \"raw_"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create a directory for the node\n    if not os.path.exists(node_line_dir):\n        os.makedirs(node_line_dir)\n\n    # Create a directory for the node's results\n    results_dir = os.path.join(node_line_dir, \"results\")\n    if not os.path.exists(results_dir):\n        os.makedirs(results_dir)\n\n    # Create a directory for the node's results\n    summary_dir = os.path.join(node_line_dir, \"summary\")\n    if not os.path.exists(summary_dir):\n        os.makedirs(summary_dir)\n\n    # Create a directory for the node's results\n    best_dir = os.path.join(node_line_dir, \"best\")\n    if not os.path.exists(best_dir):\n        os.makedirs(best_dir)\n\n    # Create a directory for the node's results\n    raw_dir = os.path.join(node_line_dir, \"raw\")\n    if not os.path.exists(raw_dir):\n        os.makedirs(raw_dir)\n\n    # Create a directory for the node's results\n    raw_dir = os.path.join(node_line_dir, \"raw\")\n    if not os.path.exists(raw_dir):\n        os.makedirs(raw_dir)\n\n    # Create a directory for the node's results\n    raw_dir = os.path.join(node_line_dir, \"raw\")\n    if not os.path.exists(raw_dir):\n        os.makedirs(raw_dir)\n\n    # Create a directory for the node's results\n    raw_dir = os.path.join(node_line_dir, \"raw\")\n    if not os.path.exists(raw_dir):\n        os.makedirs(raw_dir)\n\n    # Create a directory for the node's results\n    raw_dir = os.path.join(node_line_dir, \"raw\")\n    if not os."}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Get support modules\n    support_modules = get_support_modules()\n\n    # Create directory for node\n    if not os.path.exists(node_line_dir):\n        os.makedirs(node_line_dir)\n\n    # Create directory for results\n    results_dir = os.path.join(node_line_dir, 'results')\n    if not os.path.exists(results_dir):\n        os.makedirs(results_dir)\n\n    # Create directory for summaries\n    summaries_dir = os.path.join(node_line_dir, 'summaries')\n    if not os.path.exists(summaries_dir):\n        os.makedirs(summaries_dir)\n\n    # Create directory for prompts\n    prompts_dir = os.path.join(node_line_dir, 'prompts')\n    if not os.path.exists(prompts_dir):\n        os.makedirs(prompts_dir)\n\n    # Create directory for generations\n    generations_dir = os.path.join(node_line_dir, 'generations')\n    if not os.path.exists(generations_dir):\n        os.makedirs(generations_dir)\n\n    # Create directory for prompts\n    prompts_dir = os.path.join(node_line_dir, 'prompts')\n    if not os.path.exists(prompts_dir):\n        os.makedirs(prompts_dir)\n\n    # Create directory for generations\n    generations_dir = os.path.join(node_line_dir, 'generations')\n    if not os.path.exists(generations_dir):\n        os.makedirs(generations_dir)\n\n    # Create directory for summaries\n    summaries_dir = os.path.join(node_line_dir, 'summaries')\n    if not os.path.exists(summaries_dir):\n        os.makedirs(summaries_dir)\n\n    # Create directory for summaries\n    summaries_dir = os.path.join("}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Get the support modules\n    support_modules = get_support_modules()\n\n    # Get the generator module\n    if \"gen_module\" in strategies:\n        gen_module = strategies[\"gen_module\"]\n    else:\n        gen_module = support_modules[\"gen_module\"]\n\n    # Get the metrics\n    if \"metrics\" in strategies:\n        metrics = strategies[\"metrics\"]\n    else:\n        metrics = [\"bleu\", \"rouge1\", \"rouge2\", \"rougeL\"]\n\n    # Get the speed threshold\n    if \"speed_threshold\" in strategies:\n        speed_threshold = strategies[\"speed_threshold\"]\n    else:\n        speed_threshold = None\n\n    # Get the number of prompts\n    if \"num_prompts\" in strategies:\n        num_prompts = strategies[\"num_prompts\"]\n    else:\n        num_prompts = 1\n\n    # Get the number of examples\n    if \"num_examples\" in strategies:\n        num_examples = strategies[\"num_examples\"]\n    else:\n        num_examples = 100\n\n    # Get the number of prompts\n    if \"num_prompts\" in strategies:\n        num_prompts = strategies[\"num_prompts\"]\n    else:\n        num_prompts = 1\n\n    # Get the number of examples\n    if \"num_examples\" in strategies:\n        num_examples = strategies[\"num_examples\"]\n    else:\n        num_examples = 100\n\n    # Get the number of examples\n    if \"num_examples\" in strategies:\n        num_examples = strategies[\"num_examples\"]\n    else:\n        num_examples = 100\n\n    # Get the number of examples\n    if \"num_examples\" in strategies:\n        num_examples = strategies[\"num_examples\"]\n    else:\n        num_examples = 100\n\n    # Get the number of examples\n    if \"num_examples\" in strategies:\n        num_examples = strategies[\"num_"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create a directory for the current node\n    os.makedirs(node_line_dir, exist_ok=True)\n\n    # Create a directory for the current node's output\n    output_dir = os.path.join(node_line_dir, \"output\")\n    os.makedirs(output_dir, exist_ok=True)\n\n    # Create a directory for the current node's evaluation results\n    results_dir = os.path.join(node_line_dir, \"results\")\n    os.makedirs(results_dir, exist_ok=True)\n\n    # Create a directory for the current node's evaluation results\n    summary_dir = os.path.join(node_line_dir, \"summary\")\n    os.makedirs(summary_dir, exist_ok=True)\n\n    # Create a directory for the current node's evaluation results\n    graphs_dir = os.path.join(node_line_dir, \"graphs\")\n    os.makedirs(graphs_dir, exist_ok=True)\n\n    # Create a directory for the current node's evaluation results\n    prompt_dir = os.path.join(node_line_dir, \"prompts\")\n    os.makedirs(prompt_dir, exist_ok=True)\n\n    # Create a directory for the current node's evaluation results\n    prompt_dir = os.path.join(node_line_dir, \"prompts\")\n    os.makedirs(prompt_dir, exist_ok=True)\n\n    # Create a directory for the current node's evaluation results\n    prompt_dir = os.path.join(node_line_dir, \"prompts\")\n    os.makedirs(prompt_dir, exist_ok=True)\n\n    # Create a directory for the current node's evaluation results\n    prompt_dir = os.path.join(node_line_dir, \"prompts\")\n    os.makedirs(prompt_dir, exist_ok=True)\n\n    # Create a directory for the current node's evaluation results\n    prompt_dir = os.path.join(node"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create the output directory for the node\n    node_dir = os.path.join(node_line_dir, \"prompt_maker\")\n    if not os.path.exists(node_dir):\n        os.makedirs(node_dir)\n\n    # Create the output directory for the node's output\n    output_dir = os.path.join(node_dir, \"output\")\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    # Create the output directory for the node's metrics\n    metrics_dir = os.path.join(node_dir, \"metrics\")\n    if not os.path.exists(metrics_dir):\n        os.makedirs(metrics_dir)\n\n    # Create the output directory for the node's execution times\n    times_dir = os.path.join(node_dir, \"times\")\n    if not os.path.exists(times_dir):\n        os.makedirs(times_dir)\n\n    # Create the output directory for the node's prompts\n    prompts_dir = os.path.join(node_dir, \"prompts\")\n    if not os.path.exists(prompts_dir):\n        os.makedirs(prompts_dir)\n\n    # Create the output directory for the node's results\n    results_dir = os.path.join(node_dir, \"results\")\n    if not os.path.exists(results_dir):\n        os.makedirs(results_dir)\n\n    # Create the output directory for the node's summary\n    summary_dir = os.path.join(node_dir, \"summary\")\n    if not os.path.exists(summary_dir):\n        os.makedirs(summary_dir)\n\n    # Create the output directory for the node's summary\n    summary_dir = os.path.join(node_dir, \"summary\")\n    if not os.path.exists(summary_dir):\n        os.makedirs(summary_dir)\n\n    # Create the output directory for the node's summary\n    summary"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary directories\n    os.makedirs(node_line_dir, exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, \"results\"), exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, \"results\", \"prompt_maker\"), exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, \"results\", \"prompt_maker\", \"best\"), exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, \"results\", \"prompt_maker\", \"all\"), exist_ok=True)\n\n    # Create a list of prompt maker module combinations\n    module_combinations = make_combinations(modules, module_params)\n\n    # Create a list of prompt maker module combinations with parameters\n    module_combinations_params = []\n    for module, params in module_combinations:\n        module_combinations_params.append((module, deepcopy(params)))\n\n    # Run prompt maker modules\n    results = []\n    for module, params in module_combinations_params:\n        print(f\"Running {module.__name__} with parameters: {params}\")\n        result = module(**params)\n        results.append(result)\n\n    # Combine results\n    results = pd.concat(results, axis=0)\n\n    # Combine previous results\n    if previous_result is not None:\n        results = pd.concat([previous_result, results], axis=0)\n\n    # Save results\n    results.to_csv(os.path.join(node_line_dir, \"results\", \"prompt_maker\", \"all\", \"results.csv\"), index=False)\n\n    # Evaluate results\n    metrics = strategies.get(\"metrics\", None)\n    if metrics is not None:\n        metrics = cast_metrics(metrics)\n        results = evaluate_generation(results, metrics)\n\n    # Save results\n    results.to_csv(os.path."}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary directories\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n    pathlib.Path(os.path.join(node_line_dir, \"results\")).mkdir(parents=True, exist_ok=True)\n    pathlib.Path(os.path.join(node_line_dir, \"results\", \"raw\")).mkdir(parents=True, exist_ok=True)\n    pathlib.Path(os.path.join(node_line_dir, \"results\", \"summary\")).mkdir(parents=True, exist_ok=True)\n\n    # Initialize results dataframe\n    results = pd.DataFrame()\n\n    # Initialize best prompt maker\n    best_prompt_maker = None\n\n    # Initialize best prompt maker result\n    best_prompt_maker_result = pd.DataFrame()\n\n    # Initialize best prompt maker execution time\n    best_prompt_maker_execution_time = 0\n\n    # Initialize best prompt maker metrics\n    best_prompt_maker_metrics = pd.DataFrame()\n\n    # Initialize best prompt maker metrics\n    best_prompt_maker_metrics_summary = pd.DataFrame()\n\n    # Initialize best prompt maker metrics\n    best_prompt_maker_metrics_summary_summary = pd.DataFrame()\n\n    # Initialize best prompt maker parameters\n    best_prompt_maker_params = pd.DataFrame()\n\n    # Initialize best prompt maker parameters\n    best_prompt_maker_params_summary = pd.DataFrame()\n\n    # Initialize best prompt maker parameters\n    best_prompt_maker_params_summary_summary = pd.DataFrame()\n\n    # Initialize best prompt maker metrics\n    best_prompt_maker_params_summary_summary = pd.DataFrame()\n\n    # Initialize best prompt maker metrics\n    best_prompt_maker_params_summary_summary_summary = pd.DataFrame()\n\n    # Initialize best prompt maker metrics\n    best_prompt_maker_params_summary_summary_summary_summary = pd.DataFrame()\n\n    # Initialize best"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Get support modules\n    support_modules = get_support_modules()\n\n    # Create output directory\n    node_dir = pathlib.Path(node_line_dir)\n    node_dir.mkdir(parents=True, exist_ok=True)\n\n    # Get generator module\n    if \"generator\" in strategies:\n        gen_module = strategies[\"generator\"]\n    else:\n        gen_module = support_modules[\"generation\"][\"default\"]\n\n    # Get metrics\n    if \"metrics\" in strategies:\n        metrics = strategies[\"metrics\"]\n    else:\n        metrics = [\"bleu\"]\n\n    # Get speed thresholds\n    if \"speed_thresholds\" in strategies:\n        speed_thresholds = strategies[\"speed_thresholds\"]\n    else:\n        speed_thresholds = [0.001]\n\n    # Get evaluation function\n    if \"evaluation_function\" in strategies:\n        evaluation_function = strategies[\"evaluation_function\"]\n    else:\n        evaluation_function = evaluate_generation.evaluate\n\n    # Get output directory\n    if \"output_dir\" in strategies:\n        output_dir = strategies[\"output_dir\"]\n    else:\n        output_dir = node_line_dir\n\n    # Get output file\n    if \"output_file\" in strategies:\n        output_file = strategies[\"output_file\"]\n    else:\n        output_file = \"results.csv\"\n\n    # Get output file\n    if \"output_summary\" in strategies:\n        output_summary = strategies[\"output_summary\"]\n    else:\n        output_summary = \"summary.txt\"\n\n    # Get output file\n    if \"output_best\" in strategies:\n        output_best = strategies[\"output_best\"]\n    else:\n        output_best = \"best.txt\"\n\n    # Get output file\n    if \"output_best_result\" in strategies:\n        output_best_result = strategies[\"output_best_result\"]\n    else:\n        output_best_result = \"best"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create a directory for the current node\n    if not os.path.exists(node_line_dir):\n        os.makedirs(node_line_dir)\n\n    # Get the list of support modules\n    support_modules = get_support_modules()\n\n    # Get the generator module\n    if \"gen_module\" in strategies:\n        gen_module = strategies[\"gen_module\"]\n    else:\n        gen_module = support_modules[\"gen_module\"]\n\n    # Get the evaluation metrics\n    if \"metrics\" in strategies:\n        metrics = strategies[\"metrics\"]\n    else:\n        metrics = [\"bleu\"]\n\n    # Get the speed thresholds\n    if \"speed_thresholds\" in strategies:\n        speed_thresholds = strategies[\"speed_thresholds\"]\n    else:\n        speed_thresholds = [0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n\n    # Get the prompt maker module combinations\n    combinations = make_combinations(modules, module_params)\n\n    # Create a directory for the current node\n    if not os.path.exists(node_line_dir):\n        os.makedirs(node_line_dir)\n\n    # Create a directory for the prompt maker module combinations\n    if not os.path.exists(os.path.join(node_line_dir, \"prompt_maker\")):\n        os.makedirs(os.path.join(node_line_dir, \"prompt_maker\"))\n\n    # Create a directory for the evaluation results\n    if not os.path.exists(os.path.join(node_line_dir, \"evaluation\")):\n        os.makedirs(os.path.join(node_line_dir, \"evaluation\"))\n\n    # Create a directory for the evaluation summary\n    if not os.path.exists(os.path.join(node_line_dir,"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create subdirectory for the node\n    node_dir = os.path.join(node_line_dir, \"prompt_maker\")\n    pathlib.Path(node_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create subdirectory for the node's results\n    results_dir = os.path.join(node_dir, \"results\")\n    pathlib.Path(results_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create subdirectory for the node's results\n    summary_dir = os.path.join(node_dir, \"summary\")\n    pathlib.Path(summary_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create a list of combinations of modules and their parameters\n    module_combinations = make_combinations(modules, module_params)\n\n    # Create a list of combinations of modules and their parameters\n    module_combinations = make_combinations(modules, module_params)\n\n    # Initialize a list for storing results\n    results = []\n\n    # Iterate over the module combinations\n    for module, params in module_combinations:\n\n        # Create a directory for the module's results\n        module_dir = os.path.join(results_dir, module.__name__)\n        pathlib.Path(module_dir).mkdir(parents=True, exist_ok=True)\n\n        # Run the module\n        result = module(**params)\n\n        # Explode the results\n        result = explode(result)\n\n        # Add the module's name to the results\n        result[\"module\"] = module.__name__\n\n        # Save the results\n        result.to_csv(os.path.join(module_dir, \"results.csv\"), index=False)\n\n        # Append the results to the list\n        results.append(result)\n\n    # Combine the results\n    results = pd.concat(results)\n\n    # Add the previous results\n    results = pd.concat([previous_result, results])\n\n    # Evaluate the results\n    results"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # get the directory path\n    node_dir = pathlib.Path(node_line_dir)\n\n    # create subdirectories\n    subdirs = [\"raw\", \"processed\", \"evaluation\"]\n    for subdir in subdirs:\n        os.makedirs(node_dir / subdir, exist_ok=True)\n\n    # get the default or specified generator module\n    if \"gen_module\" in strategies:\n        gen_module = strategies[\"gen_module\"]\n    else:\n        gen_module = get_support_modules()[\"gen_module\"]\n\n    # get the default or specified metrics\n    if \"metrics\" in strategies:\n        metrics = strategies[\"metrics\"]\n    else:\n        metrics = get_support_modules()[\"metrics\"]\n\n    # get the default or specified speed threshold\n    if \"speed_threshold\" in strategies:\n        speed_threshold = strategies[\"speed_threshold\"]\n    else:\n        speed_threshold = get_support_modules()[\"speed_threshold\"]\n\n    # get the default or specified evaluation function\n    if \"evaluation_function\" in strategies:\n        evaluation_function = strategies[\"evaluation_function\"]\n    else:\n        evaluation_function = get_support_modules()[\"evaluation_function\"]\n\n    # get the default or specified prompt maker selector function\n    if \"prompt_maker_selector\" in strategies:\n        prompt_maker_selector = strategies[\"prompt_maker_selector\"]\n    else:\n        prompt_maker_selector = get_support_modules()[\"prompt_maker_selector\"]\n\n    # get the default or specified prompt maker selector function\n    if \"prompt_maker_selector_params\" in strategies:\n        prompt_maker_selector_params = strategies[\"prompt_maker_selector_params\"]\n    else:\n        prompt_maker_selector_params = get_support_modules()[\"prompt_maker_selector_params\"]\n\n    # create a list to store the results\n    results = []\n\n    # iterate over the prompt maker modules and their parameters\n    for module,"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create directories for output\n    pathlib.Path(os.path.join(node_line_dir, \"results\")).mkdir(parents=True, exist_ok=True)\n    pathlib.Path(os.path.join(node_line_dir, \"summary\")).mkdir(parents=True, exist_ok=True)\n\n    # Create a list of combinations of modules and parameters\n    module_combinations = make_combinations(modules, module_params)\n\n    # Create a list of tuples containing module, parameters, and module's name\n    module_tuples = [(module, params, module.__name__) for module, params in module_combinations]\n\n    # Create a list of tuples containing module, parameters, module's name, and module's output\n    module_output_tuples = []\n    for module, params, name in module_tuples:\n        # Run the module and get the output\n        output = module(**params)\n\n        # Add the module's output to the list of tuples\n        module_output_tuples.append((module, params, name, output))\n\n    # Create a dataframe containing the module's outputs\n    module_output_df = pd.DataFrame(module_output_tuples, columns=[\"module\", \"params\", \"name\", \"output\"])\n\n    # Explode the dataframe to have a row for each prompt\n    module_output_df = explode(module_output_df, \"output\")\n\n    # Add the previous results to the dataframe\n    module_output_df = pd.concat([module_output_df, previous_result], axis=0)\n\n    # Get the list of metrics for evaluation\n    metrics = strategies.get(\"metrics\", [\"f1_score_overall\", \"f1_score_start\", \"f1_score_end\"])\n\n    # Get the speed threshold for evaluation\n    speed_threshold = strategies.get(\"speed_threshold\", None)\n\n    # Get the name of the generator module\n    gen_module_name = strategies.get(\"gen_module_name\", \"generate_with_reference\")"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Validate input\n    if len(modules) != len(module_params):\n        raise ValueError(\"Number of modules and module parameters must be the same.\")\n\n    # Create necessary directories\n    if not os.path.exists(node_line_dir):\n        os.makedirs(node_line_dir)\n\n    # Create a support module for evaluation\n    support_module = get_support_modules(strategies[\"support_module\"])\n\n    # Run modules\n    results = []\n    for i in range(len(modules)):\n        print(\"Running prompt maker module:\", modules[i].__name__)\n        module_result = modules[i](**module_params[i])\n        module_result = explode(module_result)\n        module_result[\"prompt_maker\"] = modules[i].__name__\n        module_result[\"prompt_maker_params\"] = module_params[i]\n        results.append(module_result)\n\n    # Evaluate modules\n    if \"metrics\" in strategies:\n        print(\"Evaluating modules...\")\n        results = evaluate_generation(\n            results,\n            support_module,\n            strategies[\"metrics\"],\n            strategies[\"generation_params\"],\n        )\n        print(\"Evaluation complete.\")\n\n    # Save results\n    print(\"Saving results...\")\n    results = pd.concat(results)\n    results.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n    print(\"Saving complete.\")\n\n    # Select best module\n    if \"selection_strategy\" in strategies:\n        print(\"Selecting best module...\")\n        results = select_best_average(\n            results,\n            strategies[\"selection_strategy\"],\n        )\n        print(\"Selection complete.\")\n\n    # Combine results with previous operation\n    results = pd.concat([previous_result, results])\n\n    # Save summary\n    print(\"Saving summary...\")\n    results.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n   "}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Validate inputs\n    if len(modules) != len(module_params):\n        raise ValueError(f\"The length of modules and module_params must be equal. Got {len(modules)} and {len(module_params)}.\")\n\n    # Create output directory\n    if not os.path.exists(node_line_dir):\n        os.makedirs(node_line_dir)\n\n    # Initialize dataframe to store results\n    result = pd.DataFrame()\n\n    # Run prompt maker modules\n    for i, (module, params) in enumerate(zip(modules, module_params)):\n        print(f\"Running prompt maker module {i + 1} of {len(modules)}\")\n        # Create subdirectory\n        module_dir = os.path.join(node_line_dir, f\"prompt_maker_{i + 1}\")\n        if not os.path.exists(module_dir):\n            os.makedirs(module_dir)\n\n        # Run prompt maker module\n        prompts = module(**params)\n\n        # Evaluate module\n        metrics = evaluate_generation(prompts, strategies[\"evaluation_metrics\"])\n\n        # Combine results\n        if len(result) == 0:\n            result = pd.DataFrame(metrics, index=[0])\n        else:\n            result = pd.concat([result, pd.DataFrame(metrics, index=[0])], ignore_index=True)\n\n        # Save results\n        result.to_csv(os.path.join(module_dir, \"results.csv\"), index=False)\n\n    # Measure speed\n    if \"speed_threshold\" in strategies:\n        result = measure_speed(result, strategies[\"speed_threshold\"])\n\n    # Filter by speed\n    if \"speed_threshold\" in strategies:\n        result = filter_by_threshold(result, strategies[\"speed_threshold\"])\n\n    # Select best module\n    if \"selection_strategy\" in strategies:\n        result = select_best_average(result, strategies[\"selection_strategy\"])\n\n    # Combine with previous"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Get support modules\n    support_modules = get_support_modules()\n\n    # Set up output directory\n    if not os.path.exists(node_line_dir):\n        os.makedirs(node_line_dir)\n\n    # Set up output files\n    output_file = os.path.join(node_line_dir, \"output.csv\")\n    summary_file = os.path.join(node_line_dir, \"summary.csv\")\n\n    # Set up default strategies\n    if not strategies:\n        strategies = {\n            \"metrics\": [\"bleu\", \"rouge1\", \"rouge2\", \"rougeL\"],\n            \"thresholds\": {\"speed\": 10},\n            \"generation\": {\"module\": \"generate_from_file\", \"params\": {}}\n        }\n\n    # Set up default module parameters\n    if not module_params:\n        module_params = [{}] * len(modules)\n\n    # Set up default modules\n    if not modules:\n        modules = [support_modules[\"make_prompt_from_template\"]] * len(module_params)\n\n    # Check if modules and parameters match\n    if len(modules) != len(module_params):\n        raise ValueError(\"Number of modules and parameters must match.\")\n\n    # Create a list of prompt maker module names\n    module_names = [module.__name__ for module in modules]\n\n    # Create a list of prompt maker module parameters\n    module_params = [\n        {**module_param, \"node_line_dir\": node_line_dir}\n        for module_param in module_params\n    ]\n\n    # Create a list of prompt maker module combinations\n    module_combinations = make_combinations(module_names, module_params)\n\n    # Create a dataframe to store results\n    results = pd.DataFrame()\n\n    # Iterate over each module combination\n    for module_combination in module_combinations:\n\n        # Get module name and parameters\n        module_name = module_combination[0]\n        module_param = module_combination["}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create subdirectories for the current node\n    os.makedirs(node_line_dir, exist_ok=True)\n    dir_path = pathlib.Path(node_line_dir)\n    dir_path_summary = dir_path / 'summary'\n    dir_path_summary.mkdir(exist_ok=True)\n    dir_path_results = dir_path / 'results'\n    dir_path_results.mkdir(exist_ok=True)\n\n    # Create a copy of the previous result\n    result = deepcopy(previous_result)\n\n    # Get the list of metrics\n    metrics = strategies.get('metrics')\n\n    # Get the list of generators\n    generators = strategies.get('generators')\n\n    # Get the speed threshold\n    speed_threshold = strategies.get('speed_threshold')\n\n    # Get the support modules\n    support_modules = get_support_modules()\n\n    # Get the combinations of modules and parameters\n    combinations = make_combinations(modules, module_params)\n\n    # Run the modules\n    for module, params in combinations:\n\n        # Create a copy of the result\n        current_result = deepcopy(result)\n\n        # Get the module name\n        module_name = module.__name__\n\n        # Get the module parameters\n        module_params = params\n\n        # Get the module function\n        module_func = support_modules.get(module_name)\n\n        # Run the module\n        result = module_func(module, params, current_result)\n\n        # Save the result to a file\n        result.to_csv(dir_path_results / f'{module_name}.csv', index=False)\n\n        # Evaluate the result\n        for gen in generators:\n            for metric in metrics:\n                print(f'Evaluating {module_name} with {gen} and {metric}')\n                evaluation = evaluate_generation(result, metric, gen)\n                evaluation.to_csv(dir_path_results / f'{module_name}_{gen}_{metric}.csv', index=False)"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create output directories\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create output directory for the node's results\n    node_dir = os.path.join(node_line_dir, \"results\")\n    pathlib.Path(node_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create output directory for the node's results\n    node_dir_summary = os.path.join(node_line_dir, \"summary\")\n    pathlib.Path(node_dir_summary).mkdir(parents=True, exist_ok=True)\n\n    # Get the list of strategies\n    speed_threshold = strategies.get(\"speed_threshold\", None)\n    metrics = strategies.get(\"metrics\", None)\n    gen_module = strategies.get(\"gen_module\", None)\n    gen_module_params = strategies.get(\"gen_module_params\", None)\n\n    # Create a list of combinations of prompt maker modules and their parameters\n    module_combinations = make_combinations(modules, module_params)\n\n    # Initialize a list for storing the results\n    results = []\n\n    # Iterate over the list of combinations\n    for module, module_param in module_combinations:\n\n        # Get the name of the module\n        module_name = module.__name__\n\n        # Get the parameters\n        module_param = module_param\n\n        # Run the prompt maker module\n        prompt_maker_result = module(**module_param)\n\n        # Measure the execution time\n        exec_time = measure_speed(module)\n\n        # Check if the speed threshold is specified\n        if speed_threshold is not None:\n            prompt_maker_result = filter_by_threshold(prompt_maker_result, exec_time, speed_threshold)\n\n        # Check if the metrics are specified\n        if metrics is not None:\n            # Get the name of the metrics\n            metrics_name = metrics.__name__\n\n            # Evaluate the results\n            evaluation"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(itertools.chain.from_iterable(list(map(lambda x: extract_values(x, key), nodes))))\n    return list(set(values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(itertools.chain.from_iterable(list(map(lambda x: extract_values(x, key), nodes))))\n    return list(set(values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(itertools.chain.from_iterable(list(map(lambda x: extract_values(x, key), nodes))))\n    return list(set(values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(itertools.chain.from_iterable(list(map(lambda x: extract_values(x, key), nodes))))\n    return list(set(values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(itertools.chain.from_iterable(list(map(lambda x: extract_values(x, key), nodes))))\n    return list(set(values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(itertools.chain.from_iterable(list(map(lambda x: extract_values(x, key), nodes))))\n    return list(set(values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(itertools.chain.from_iterable(list(map(lambda x: extract_values(x, key), nodes))))\n    return list(set(values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    def extract_values_from_node(node: Node):\n        return extract_values(node, key)\n\n    values = list(map(extract_values_from_node, nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    def extract_module_values(node: Node):\n        if key not in node.node_params:\n            return []\n        value = node.node_params[key]\n        if isinstance(value, str):\n            return [value]\n        elif isinstance(value, list):\n            return value\n        else:\n            raise ValueError(f\"{key} must be str or list, but got {type(value)}\")\n\n    values = list(map(extract_module_values, nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))\n\n"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    if not isinstance(nodes, list):\n        raise ValueError(\"nodes must be a list\")\n\n    if not isinstance(key, str):\n        raise ValueError(\"key must be a string\")\n\n    values = []\n    for node in nodes:\n        values += extract_values(node, key)\n    return list(set(values))"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n\n    # Convert the strings into embeddings\n    gt_embeddings = embedding_model.encode(generation_gt)\n    pred_embedding = embedding_model.encode([pred])\n\n    # Calculate the cosine similarity between the prediction and each ground truth string\n    cosine_similarities = calculate_cosine_similarity(pred_embedding, gt_embeddings)\n\n    # Return the maximum cosine similarity\n    return max(cosine_similarities)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if not embedding_model:\n        embedding_model = embedding_models.get_default_model()\n\n    gt_embeddings = embedding_model.get_embeddings(generation_gt)\n    pred_embedding = embedding_model.get_embeddings([pred])\n    scores = calculate_cosine_similarity(gt_embeddings, pred_embedding)\n    return max(scores)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n    return max(list(map(lambda x: calculate_cosine_similarity(embedding_model, x, pred), generation_gt)))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model(\"all-mpnet-base-v2\")\n\n    return max(list(map(lambda x: calculate_cosine_similarity(embedding_model.encode(pred), embedding_model.encode(x)), generation_gt)))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.MPNetModel()\n\n    return max(list(map(lambda x: calculate_cosine_similarity(embedding_model.encode(pred), embedding_model.encode(x)), generation_gt)))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n    return max(list(map(lambda x: calculate_cosine_similarity(x, pred, embedding_model), generation_gt)))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if not embedding_model:\n        embedding_model = embedding_models.MPNet()\n\n    if len(generation_gt) == 0:\n        return 0.0\n\n    # Convert strings to embeddings\n    generation_gt_embeddings = embedding_model.encode(generation_gt)\n    pred_embedding = embedding_model.encode([pred])\n\n    # Calculate cosine similarity between the prediction and each ground truth string\n    cosine_similarities = calculate_cosine_similarity(pred_embedding, generation_gt_embeddings)\n\n    # Return the maximum cosine similarity\n    return max(cosine_similarities)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    # Use the default model if no model is provided\n    if embedding_model is None:\n        embedding_model = embedding_models.get_model('all-mpnet-base-v2')\n\n    # Convert the strings to embeddings\n    gt_embeddings = embedding_model.get_embeddings(generation_gt)\n    pred_embedding = embedding_model.get_embeddings([pred])\n\n    # Calculate the semantic similarity between the predicted string and each ground truth string\n    semantic_similarity = calculate_cosine_similarity(gt_embeddings, pred_embedding)\n\n    # Return the maximum semantic similarity score\n    return semantic_similarity\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n\n    # Convert strings to embeddings\n    gt_embeddings = embedding_model.get_embeddings(generation_gt)\n    pred_embedding = embedding_model.get_embeddings([pred])\n\n    # Calculate cosine similarity between the predicted string and each ground truth string\n    cosine_similarities = calculate_cosine_similarity(gt_embeddings, pred_embedding)\n\n    # Return the maximum cosine similarity\n    return max(cosine_similarities)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    # Check if an embedding model is provided\n    if embedding_model is None:\n        # If no embedding model is provided, load a default model\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n\n    # Calculate the semantic similarity score between the predicted string and each string in the ground truth list\n    sem_similarity_scores = list(map(lambda x: calculate_cosine_similarity(x, pred, embedding_model), generation_gt))\n\n    # Return the maximum semantic similarity score\n    return max(sem_similarity_scores)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.MPNetModel()\n\n    return max(list(map(lambda x: calculate_cosine_similarity(embedding_model.encode(pred), embedding_model.encode(x)), generation_gt)))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model(\"all-mpnet-base-v2\")\n\n    gt_embeddings = embedding_model.encode(generation_gt, convert_to_tensor=True)\n    pred_embedding = embedding_model.encode([pred], convert_to_tensor=True)\n\n    return calculate_cosine_similarity(gt_embeddings, pred_embedding).max().item()\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n    return max(list(map(lambda x: calculate_cosine_similarity(embedding_model, pred, x), generation_gt)))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n\n    # Get embeddings for the ground truth strings and the predicted string\n    gt_embeddings = embedding_model.encode(generation_gt)\n    pred_embedding = embedding_model.encode([pred])\n\n    # Calculate the semantic similarity score for each ground truth string\n    similarity_scores = []\n    for gt_embedding in gt_embeddings:\n        similarity_scores.append(calculate_cosine_similarity(gt_embedding, pred_embedding))\n\n    # Return the maximum semantic similarity score\n    return max(similarity_scores)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    # Load the default model if no model is provided\n    if not embedding_model:\n        embedding_model = embedding_models.get_model(\"all-mpnet-base-v2\")\n\n    # Convert the strings into embeddings\n    gt_embeddings = embedding_model.encode(generation_gt)\n    pred_embedding = embedding_model.encode([pred])\n\n    # Calculate the semantic similarity between the prediction and each ground truth string\n    sem_sims = []\n    for gt_embedding in gt_embeddings:\n        sem_sims.append(calculate_cosine_similarity(gt_embedding, pred_embedding))\n\n    return max(sem_sims)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_model('all-mpnet-base-v2')\n\n    pred_embedding = embedding_model.encode(pred)\n    gt_embeddings = embedding_model.encode(generation_gt)\n\n    return max(calculate_cosine_similarity(pred_embedding, gt_embedding) for gt_embedding in gt_embeddings)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if not embedding_model:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n\n    gt_embeddings = embedding_model.encode(generation_gt)\n    pred_embedding = embedding_model.encode([pred])\n\n    return max(calculate_cosine_similarity(gt_embeddings, pred_embedding))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    # Set default embedding model\n    if embedding_model is None:\n        embedding_model = embedding_models.get_model('all-mpnet-base-v2')\n\n    # Convert strings to embeddings\n    gt_embeddings = embedding_model.get_embeddings(generation_gt)\n    pred_embedding = embedding_model.get_embeddings([pred])\n\n    # Calculate cosine similarity between the predicted embedding and the ground truth embeddings\n    cos_sims = calculate_cosine_similarity(gt_embeddings, pred_embedding)\n\n    # Return the maximum cosine similarity\n    return max(cos_sims)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if not embedding_model:\n        embedding_model = embedding_models.get_embedding_model(\"all-mpnet-base-v2\")\n\n    gt_embeddings = embedding_model.get_embeddings(generation_gt)\n    pred_embedding = embedding_model.get_embeddings([pred])\n\n    return max(calculate_cosine_similarity(gt_embeddings, pred_embedding))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    # Check if an embedding model is provided. If not, use the default model.\n    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n\n    # Compute the cosine similarity between the predicted string and each ground truth string.\n    similarity_scores = list(map(lambda gt_string: calculate_cosine_similarity(gt_string, pred, embedding_model), generation_gt))\n\n    # Return the maximum similarity score.\n    return max(similarity_scores)\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        gfpgan_face_restorer = FaceRestorerGFPGAN()\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.RestorationError as e:\n        logger.warning(f\"Could not restore faces in image using GFPGAN: {e}\")\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        gfpgan_face_restorer = FaceRestorerGFPGAN()\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.RestorationError as e:\n        logger.warning(f\"Failed to restore faces in image using GFPGAN: {e}\")\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(\n            model_path=shared.model_path,\n            upscale_factor=shared.upscale_factor,\n        )\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.ModelNotSetUpError:\n        logger.warning(\"GFPGAN face restorer is not set up, skipping face restoration\")\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        gfpgan_face_restorer = FaceRestorerGFPGAN()\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.RestorationFailedError as e:\n        logger.warning(f\"GFPGAN failed to restore faces in an image. The original image will be used instead. Error: {e}\")\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=shared.model_path)\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.RestorationError as e:\n        logger.warning(f\"Could not restore faces using GFPGAN: {e}\")\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(\n            model_path=shared.model_path,\n            upscale_factor=2,\n            model_type='clean',\n            num_face=1,\n            only_center_face=False,\n            aligned=False,\n            ext='auto',\n        )\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.ModelNotSetUpError:\n        logger.warning(\"GFPGAN is not set up, skipping face restoration\")\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(\n            model_path=shared.model_path,\n            upscale_factor=2,\n        )\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.ModelNotSetUpError as error:\n        logger.warning(f\"{error.message}. Returning the original image.\")\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        gfpgan_face_restorer = FaceRestorerGFPGAN()\n    if gfpgan_face_restorer.net is None:\n        logger.warning(\"GFPGAN face restorer is not set up. Skipping face restoration.\")\n        return np_image\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.RestorationError as e:\n        logger.warning(f\"Error in GFPGAN face restoration: {e}. Skipping face restoration.\")\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(\n            model_path=shared.model_path,\n            upscale_factor=2,\n            model_type='GFPGANv1',\n            num_style_factors=5,\n            artifact_removal=True,\n            optimize_options=None,\n        )\n\n    try:\n        restored_image = gfpgan_face_restorer.restore(np_image)\n    except errors.RestorationError as e:\n        logger.warning(f\"Failed to restore faces using GFPGAN: {e}\")\n        return np_image\n\n    return restored_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        try:\n            gfpgan_face_restorer = FaceRestorerGFPGAN()\n        except errors.ModelNotSetUpError as e:\n            logger.warning(f\"GFPGAN face restorer not set up: {e}\")\n            return np_image\n\n    try:\n        np_image = gfpgan_face_restorer.restore(np_image)\n    except Exception as e:\n        logger.warning(f\"Could not restore faces using GFPGAN: {e}\")\n\n    return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        try:\n            gfpgan_face_restorer = FaceRestorerGFPGAN(\n                model_path=shared.model_gfpgan,\n                upscale_factor=2,\n                model_type=\"clean\",\n            )\n        except errors.ModelNotSetUpError:\n            logger.warning(\n                f\"GFPGAN face restorer not set up. Unable to restore faces in image.\"\n            )\n            return np_image\n\n    return gfpgan_face_restorer.restore(np_image)"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer not set up. Please set up GFPGAN face restorer before calling gfpgan_fix_faces.\")\n        return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except Exception as e:\n        logger.warning(f\"Failed to restore faces using GFPGAN. Error: {e}\")\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        try:\n            gfpgan_face_restorer = FaceRestorerGFPGAN(\n                model_path=shared.model_path,\n                upscale_factor=2,\n                model_type='clean',\n                num_face=1,\n                only_center_face=False,\n                aligned=False,\n                ext='auto',\n                device=devices.device_gfpgan,\n            )\n        except errors.ModelNotSetUpError:\n            logger.warning(\n                \"GFPGAN is not set up. Please set up GFPGAN by running 'python -m face_restorer.gfpgan setup'.\"\n            )\n            return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except Exception as e:\n        logger.warning(f\"GFPGAN failed to restore faces. {e}\")\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up. Please set it up before calling this function.\")\n        return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.RestorationError as e:\n        logger.warning(f\"GFPGAN face restoration failed: {e}.\")\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer not set up\")\n        return np_image\n\n    try:\n        np_image = gfpgan_face_restorer.restore(np_image)\n    except Exception as e:\n        logger.warning(f\"GFPGAN face restoration failed: {e}\")\n\n    return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        gfpgan_face_restorer = FaceRestorerGFPGAN()\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.ModelNotSetUpError as e:\n        logger.warning(e)\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN is not set up. If you want to use it, call set_up_gfpgan() first.\")\n        return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except Exception as e:\n        logger.warning(f\"Could not restore faces in image using GFPGAN. The error was: {e}\")\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        if not shared.gfpgan_setup_done:\n            logger.warning(\n                \"The GFPGAN face restorer has not been set up yet. Please call setup_gfpgan() first.\"\n            )\n            return np_image\n        else:\n            gfpgan_face_restorer = FaceRestorerGFPGAN()\n            gfpgan_face_restorer.setup(model_path=shared.model_gfpgan)\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.NoFacesDetectedError:\n        logger.warning(\"No faces detected. Skipping GFPGAN face restoration.\")\n        return np_image\n    except Exception as e:\n        logger.warning(f\"Could not run GFPGAN face restoration. Skipping. Exception: {e}\")\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        if devices.device_gfpgan is None:\n            logger.warning(\"GFPGAN not set up\")\n            return np_image\n        gfpgan_face_restorer = FaceRestorerGFPGAN(\n            model_path=shared.model_path,\n            upscale_factor=2,\n        )\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.NoFaces:\n        logger.warning(\"No faces to fix\")\n        return np_image\n    except Exception as e:\n        logger.warning(f\"Failed to fix faces using GFPGAN: {e}\")\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        gfpgan_face_restorer = FaceRestorerGFPGAN()\n        try:\n            gfpgan_face_restorer.set_up()\n        except errors.ModelNotSetUpError:\n            logger.warning(\"GFPGAN face restorer is not set up\")\n            return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.ModelNotSetUpError:\n        logger.warning(\"GFPGAN face restorer is not set up\")\n        return np_image\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.InvalidModelError as e:\n        logger.error(f'Error setting up CodeFormer model: {e}')"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.ModelSetupError as e:\n        logger.error(f\"Error setting up codeformer model: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        logger.info('Setting up CodeFormer...')\n        codeformer = FaceRestorerCodeFormer(dirname)\n        logger.info('CodeFormer set up.')\n    except errors.BaseError as e:\n        logger.error(f'Error setting up CodeFormer: {e}')"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.BaseError as e:\n        logger.warning(f'Error setting up codeformer model: {e}')"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n        logger.info(\"CodeFormer model loaded successfully.\")\n    except Exception as e:\n        logger.error(f\"Error loading CodeFormer model: {e}\")\n        errors.report(e)"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.InvalidModelError as e:\n        logger.error(f\"Could not load codeformer model: {e}\")\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.InvalidModelError as e:\n        logger.error(f'Invalid CodeFormer model: {e}')\n    except errors.MissingModelError as e:\n        logger.error(f'Missing CodeFormer model: {e}')\n    except errors.MissingModelFileError as e:\n        logger.error(f'Missing CodeFormer model file: {e}')\n    except Exception as e:\n        logger.error(f'Error setting up CodeFormer model: {e}')\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        logger.info(\"Loading CodeFormer model\")\n        codeformer = FaceRestorerCodeFormer(dirname)\n        logger.info(\"Loaded CodeFormer model\")\n    except Exception as e:\n        logger.error(f\"Error loading CodeFormer model: {e}\")\n        errors.add_error(e)"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        logger.debug(f\"Attempting to set up a CodeFormer model...\")\n        codeformer = FaceRestorerCodeFormer(dirname)\n        logger.info(f\"CodeFormer model successfully set up.\")\n    except errors.BaseError as e:\n        logger.error(f\"Error while setting up CodeFormer model: {e}\")\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    if codeformer is None:\n        try:\n            codeformer = FaceRestorerCodeFormer(dirname)\n        except errors.BaseError as e:\n            logger.error(f'Error: {e.message}')\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.InvalidModelError as e:\n        logger.error(f'Invalid CodeFormer model: {e}')\n    except Exception as e:\n        logger.error(f'Error loading CodeFormer model: {e}')\n\n    return\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n        codeformer.initialize()\n        codeformer.load_models()\n    except errors.ModelNotLoadedError as e:\n        logger.error(e)\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.InvalidModelError as e:\n        logger.report_error(f'Could not load CodeFormer model: {e}')\n    except Exception as e:\n        logger.report_exception(f'Error loading CodeFormer model: {e}')\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        logger.info(\"Setting up codeformer...\")\n        codeformer = FaceRestorerCodeFormer(dirname)\n        logger.info(\"Done!\")\n    except errors.ModelSetupError as e:\n        logger.error(f\"Error setting up codeformer: {e}\")\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.InvalidModelError as e:\n        logger.error(f'Error setting up {codeformer}: {e}')\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n        logger.info(\"Loaded CodeFormer model\")\n    except errors.InvalidModelError as e:\n        logger.error(f\"Could not load CodeFormer model: {e}\")\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.InvalidModelError as e:\n        logger.error(f\"Could not load model: {e}\")\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        logger.info(f\"Loading {__name__} model...\")\n        face_restorer = FaceRestorerCodeFormer(dirname)\n        face_restorer.initialize_network()\n        codeformer = face_restorer\n        logger.info(f\"Loaded {__name__} model.\")\n    except errors.BaseError as e:\n        logger.warning(f\"{__name__} model could not be loaded: {e}.\")\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.InvalidModelError as e:\n        logger.error(f'Error setting up {codeformer}: {e}')\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.RestorationError as e:\n        logger.error(e)\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n\n    try:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n        shared.face_restorer = gfpgan_face_restorer\n    except Exception as e:\n        gfpgan_face_restorer = None\n        shared.face_restorer = None\n        raise errors.ModelSetupError(\n            f\"Error setting up GFPGAN face restorer: {e}\"\n        )"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n        shared.face_restorers.append(gfpgan_face_restorer)\n    except Exception as e:\n        errors.report(e, \"Face restoration setup failed\")\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except errors.ModelNotLoadedError as e:\n        logger.warning(f\"GFPGAN model not set up: {e}\")\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except Exception as e:\n        errors.report_exception(e)\n        logger.warning(\"Could not load GFPGAN face restoration model\")\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n        shared.gfpgan_setup_success = True\n    except Exception as e:\n        logger.error(f\"Could not setup GFPGAN face restorer. {e}\")\n        shared.gfpgan_setup_success = False\n        raise errors.ModelSetupError(\n            \"Could not setup GFPGAN face restorer. See logs for more information.\"\n        )"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n\n    try:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except errors.ModelNotLoadedError as e:\n        logger.warning(f\"Could not load GFPGAN model: {e}\")\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except errors.RestorationError as e:\n        logger.error(f\"Error setting up GFPGAN: {e}\")\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except errors.ModelNotLoadedError:\n        logger.error(\"GFPGAN model not loaded\")\n    except Exception as e:\n        logger.error(f\"Error while loading GFPGAN model: {e}\")\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n        logger.info(\"GFPGAN model set up\")\n    except Exception as e:\n        logger.error(\"GFPGAN model could not be set up: %s: %s\", type(e), e)\n        raise errors.ModelSetupError from e\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except Exception as e:\n        gfpgan_face_restorer = None\n        raise errors.ModelSetupError(f\"Error setting up GFPGAN face restorer: {e}\")\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n\n    try:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except errors.InvalidModelError as e:\n        logger.error(e)\n        gfpgan_face_restorer = None\n    except Exception as e:\n        logger.error(f'Error when loading GFPGAN model: {e}')\n        gfpgan_face_restorer = None\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n\n    try:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except Exception as e:\n        gfpgan_face_restorer = None\n        raise errors.ModelSetupError(\n            f\"Error setting up GFPGAN face restorer. {type(e).__name__}: {e}\"\n        )\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n\n    try:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except Exception as e:\n        gfpgan_face_restorer = None\n        raise errors.ModelSetupError(\n            f\"Error setting up GFPGAN face restorer with model in directory {dirname}.\\n\"\n            f\"Exception: {e}\"\n        )\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n\n    try:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except Exception as e:\n        errors.report(e)\n        gfpgan_face_restorer = None\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n\n    try:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(\n            model_path=dirname,\n            upscale_factor=2,\n            model_type=\"clean\",\n            num_face=1,\n            device=devices.device_gfpgan,\n        )\n    except (errors.ModelNotLoadedError, errors.InvalidPathError, errors.InvalidImageError) as e:\n        logger.error(f\"Error: {e}\")\n        logger.error(\"Could not setup GFPGAN model\")\n        gfpgan_face_restorer = None"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n        logger.info(\"GFPGAN model loaded successfully\")\n    except errors.ModelNotFoundError as error:\n        logger.error(error)\n    except Exception as error:\n        logger.error(error)\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n\n    try:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except errors.ModelNotLoadedError as e:\n        logger.error(e)\n    except Exception as e:\n        logger.error(e)\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer:\n        return\n    try:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(\n            model_path=dirname,\n            upscale_factor=2,\n            model_type=\"clean\",\n        )\n        gfpgan_face_restorer.initialize()\n    except errors.InvalidPathError:\n        logger.error(f\"Invalid path for GFPGAN model: {dirname}\")\n    except Exception as e:\n        logger.error(f\"Error loading GFPGAN model: {e}\")\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer:\n        return\n\n    try:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(\n            model_path=dirname,\n            upscale_factor=2,\n            model_type=\"clean\",\n            num_faces=1,\n            resize_alignment=128,\n            only_center_face=False,\n            exclusion_zone=None,\n            output_size=512,\n            face_upsample=True,\n            resize_enabled=True,\n            normalized_alignment=True,\n            aligned_face=True,\n        )\n    except Exception as e:\n        logger.error(\"Error setting up GFPGAN face restorer: %s\", e)\n        raise errors.ModelSetupError(\n            \"Error setting up GFPGAN face restorer: %s\" % e\n        ) from e\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except errors.ModelNotLoadedError as e:\n        logger.error(\n            f\"Error in setting up GFPGAN face restorer. Please make sure the model is downloaded correctly and in the correct path. The expected model path is: {e.expected_path}.\\n\"\n            \"You can download the model from the following URL:\\n\"\n            \"https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth\",\n            exc_info=e,\n        )\n    except Exception as e:\n        logger.error(\n            \"Error in setting up GFPGAN face restorer. Please make sure the model is downloaded correctly and in the correct path.\",\n            exc_info=e,\n        )\n\n"}
{"namespace": "quaternion.rotate", "completion": "  q_vector = jnp.concatenate([jnp.zeros_like(v[Ellipsis, :1]), v], axis=-1)\n  q_vector_rotated = multiply(q, multiply(q_vector, inverse(q)))\n  return q_vector_rotated[Ellipsis, 1:]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert vector to quaternion format.\n  v_quat = jnp.concatenate([v, [0.0]], axis=-1)\n\n  # Apply the rotation.\n  rotated_quat = multiply(q, multiply(v_quat, inverse(q)))\n\n  # Convert the rotated vector back to vector format.\n  return rotated_quat[Ellipsis, :3]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  v = jnp.concatenate([jnp.zeros_like(v[Ellipsis, :1]), v], axis=-1)\n  return multiply(multiply(q, v), conjugate(q))[Ellipsis, 1:]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  v = jnp.concatenate([jnp.zeros_like(v[Ellipsis, :1]), v], axis=-1)\n  return multiply(multiply(q, v), conjugate(q))[Ellipsis, 1:]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector into a quaternion.\n  v_quaternion = jnp.concatenate([v, jnp.array([0.0])])\n\n  # Apply the rotation.\n  rotated_quaternion = multiply(q, multiply(v_quaternion, inverse(q)))\n\n  # Return the vector part of the rotated quaternion.\n  return rotated_quaternion[Ellipsis, :3]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion.\n  v_quat = jnp.concatenate([v, [0.0]], axis=-1)\n\n  # Perform the rotation.\n  rotated_quat = multiply(multiply(q, v_quat), conjugate(q))\n\n  # Convert the rotated vector back to a vector.\n  return im(rotated_quat)\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector into a quaternion.\n  v_q = jnp.concatenate([v, [0.0]], axis=-1)\n\n  # Compute the product of the quaternions.\n  q_rot = multiply(multiply(q, v_q), conjugate(q))\n\n  # Return the vector part of the result.\n  return im(q_rot)\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector into a quaternion.\n  v = jnp.concatenate([v, [0.0]], axis=-1)\n\n  # Perform the rotation.\n  q = multiply(multiply(q, v), conjugate(q))\n\n  # Convert the vector back into a vector.\n  return im(q)\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector into a quaternion.\n  v_quat = jnp.concatenate([v, [0.0]], axis=-1)\n\n  # Rotate the vector using the quaternion.\n  rotated_v_quat = multiply(multiply(q, v_quat), conjugate(q))\n\n  # Return the vector.\n  return rotated_v_quat[Ellipsis, :3]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion.\n  v = jnp.concatenate([v, [0.0]], axis=-1)\n\n  # Apply the quaternion rotation.\n  q_rotated = multiply(multiply(q, v), conjugate(q))\n\n  # Convert the vector back to a vector.\n  return q_rotated[Ellipsis, :3]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion\n  v = jnp.concatenate([v, [0.0]], axis=-1)\n\n  # Apply the rotation\n  q_rotated = multiply(multiply(q, v), conjugate(q))\n\n  # Convert the rotated vector back to a vector\n  return q_rotated[Ellipsis, :3]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  q_conj = inverse(q)\n  q_v = jnp.concatenate([[0.0], v], axis=-1)\n  q_v_rotated = multiply(q, multiply(q_v, q_conj))\n  return q_v_rotated[Ellipsis, 1:]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion\n  v_quat = jnp.concatenate([v, [0.0]], axis=-1)\n\n  # Apply the rotation\n  v_quat_rot = multiply(q, multiply(v_quat, conjugate(q)))\n\n  # Extract the vector from the quaternion\n  v_rot = re(v_quat_rot)\n\n  return v_rot\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector into a quaternion format\n  v = jnp.concatenate([jnp.zeros(v.shape[:-1] + (1,)), v], axis=-1)\n\n  # Apply the rotation\n  return multiply(multiply(q, v), conjugate(q))[Ellipsis, 1:]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion.\n  v_quaternion = jnp.concatenate([v, jnp.array([0.0])], axis=-1)\n\n  # Perform the rotation.\n  rotated_quaternion = multiply(multiply(q, v_quaternion), conjugate(q))\n\n  # Convert the rotated quaternion to a vector.\n  return im(rotated_quaternion)\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert vector to quaternion.\n  qv = jnp.concatenate([jnp.zeros(v.shape[:-1] + (1,)), v], axis=-1)\n  # Perform the rotation.\n  qr = multiply(multiply(q, qv), conjugate(q))\n  # Extract the vector from the quaternion.\n  return qr[Ellipsis, 1:]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  q = normalize(q)\n  q_v = jnp.concatenate([jnp.zeros_like(v[Ellipsis, :1]), v], axis=-1)\n  return im(multiply(multiply(q, q_v), conjugate(q)))\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion.\n  v = jnp.concatenate([v, [0]], axis=-1)\n\n  # Apply the quaternion rotation.\n  return im(multiply(multiply(q, v), conjugate(q)))\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector into a quaternion.\n  v = jnp.concatenate([jnp.zeros_like(v[Ellipsis, 0:1]), v], axis=-1)\n\n  # Rotate the quaternion.\n  v = multiply(q, multiply(v, conjugate(q)))\n\n  # Return the vector component.\n  return v[Ellipsis, 1:]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector into a quaternion.\n  vector_quaternion = jnp.concatenate([v, [0.0]], axis=-1)\n\n  # Perform the rotation.\n  rotated_quaternion = multiply(q, multiply(vector_quaternion, inverse(q)))\n\n  # Return the rotated vector.\n  return im(rotated_quaternion)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  # Normalize the axis-angle vector to ensure it is a unit vector.\n  axis = axis_angle / (jnp.linalg.norm(axis_angle) + eps)\n\n  # Calculate the angle (magnitude) of the axis-angle vector.\n  angle = jnp.linalg.norm(axis_angle)\n\n  # Calculate the quaternion.\n  quaternion = jnp.concatenate(\n    (\n      jnp.sin(angle / 2.0) * axis,\n      jnp.cos(angle / 2.0)\n    ),\n    axis = -1\n  )\n\n  return quaternion\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  angle = linalg.norm(axis_angle)\n  axis = axis_angle / (angle + eps)\n  return jnp.concatenate(\n      [\n          axis * jnp.sin(angle / 2.0),\n          jnp.cos(angle / 2.0)\n      ],\n      axis=-1\n  )\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis = axis_angle[..., :3]\n  angle = axis_angle[..., 3]\n\n  axis = axis / (\n    linalg.norm(axis, axis=-1, keepdims=True) + eps\n  )\n\n  angle = angle + eps\n\n  s = jnp.cos(angle / 2.0)\n  v = jnp.sin(angle / 2.0) * axis\n\n  return jnp.concatenate([v, [s]], axis=-1)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  angle = linalg.norm(axis_angle)\n  axis = axis_angle / (angle + eps)\n  quat = jnp.concatenate([axis, [jnp.cos(angle / 2.)]], axis=-1)\n  quat = quat / linalg.norm(quat)\n  return quat\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  # Normalize the axis-angle vector.\n  axis_angle = jnp.asarray(axis_angle)\n  axis_angle = axis_angle / (jnp.linalg.norm(axis_angle) + eps)\n\n  # Calculate the quaternion.\n  angle = jnp.linalg.norm(axis_angle)\n  half_angle = 0.5 * angle\n  q = jnp.concatenate([\n    axis_angle * jnp.sin(half_angle),\n    jnp.cos(half_angle)\n  ])\n\n  return q\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  angle = linalg.norm(axis_angle, axis=-1, keepdims=True)\n  axis = axis_angle / (angle + eps)\n  q = jnp.concatenate((axis, angle), axis=-1)\n  return q\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  angle = linalg.norm(axis_angle, axis=-1, keepdims=True)\n  axis = axis_angle / (angle + eps)\n  s = jnp.cos(0.5 * angle)\n  v = axis * jnp.sin(0.5 * angle)\n  return jnp.concatenate((v, s), axis=-1)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  # Normalize the axis-angle vector\n  axis_angle = jnp.array(axis_angle)\n  axis_angle = axis_angle / (jnp.linalg.norm(axis_angle) + eps)\n\n  # Compute the quaternion\n  angle = jnp.linalg.norm(axis_angle)\n  axis = axis_angle / angle\n  w = jnp.cos(angle / 2)\n  xyz = axis * jnp.sin(angle / 2)\n\n  return jnp.concatenate((xyz, [w]), axis=-1)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  # Normalize the axis-angle vector\n  axis_angle_norm = linalg.norm(axis_angle)\n  axis_angle = jnp.divide(axis_angle, axis_angle_norm + eps)\n\n  # Compute the quaternion components\n  sin_half_angle = jnp.sin(axis_angle_norm / 2)\n  cos_half_angle = jnp.cos(axis_angle_norm / 2)\n\n  # Compute the quaternion\n  return jnp.concatenate((axis_angle * sin_half_angle, cos_half_angle), axis=-1)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  # Normalize the axis-angle representation\n  axis = axis_angle / (jnp.linalg.norm(axis_angle) + eps)\n  angle = jnp.linalg.norm(axis_angle)\n\n  # Compute the quaternion\n  half_angle = 0.5 * angle\n  q = jnp.concatenate([\n    axis * jnp.sin(half_angle),\n    jnp.cos(half_angle)\n  ], axis=-1)\n\n  return q\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis = axis_angle[..., :3]\n  angle = axis_angle[..., 3:]\n  norm = linalg.norm(axis, axis=-1, keepdims=True)\n  eps = jnp.array(eps)\n  axis = axis / (norm + eps)\n  half_angle = 0.5 * angle\n  q_w = jnp.cos(half_angle)\n  q_xyz = jnp.sin(half_angle) * axis\n  return jnp.concatenate((q_xyz, q_w), axis=-1)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis = axis_angle[..., :3]\n  angle = axis_angle[..., 3:]\n  half_angle = 0.5 * angle\n  return jnp.concatenate(\n    [\n      jnp.sin(half_angle) * axis / jnp.maximum(\n        jnp.linalg.norm(axis, axis=-1, keepdims=True), eps\n      ),\n      jnp.cos(half_angle),\n    ],\n    axis=-1,\n  )\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  # Normalize the axis-angle vector\n  axis = axis_angle[..., :3]\n  angle = axis_angle[..., 3:]\n  axis = axis / (jnp.linalg.norm(axis) + eps)\n\n  # Compute quaternion\n  return jnp.concatenate([\n    jnp.sin(angle / 2) * axis,\n    jnp.cos(angle / 2)\n  ], axis=-1)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis = axis_angle[:, :3]\n  angle = axis_angle[:, 3]\n\n  # Normalize axis.\n  axis = axis / (jnp.linalg.norm(axis, axis=-1, keepdims=True) + eps)\n\n  # Compute quaternion.\n  angle = jnp.expand_dims(angle / 2.0, axis=-1)\n  cos_angle = jnp.cos(angle)\n  sin_angle = jnp.sin(angle)\n  quat = jnp.concatenate((axis * sin_angle, cos_angle), axis=-1)\n\n  return quat\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  # Normalize the axis-angle vector to make it a unit vector.\n  axis = axis_angle / linalg.norm(axis_angle, axis=-1, keepdims=True)\n\n  # Compute the angle of rotation from the axis-angle vector.\n  angle = linalg.norm(axis_angle, axis=-1, keepdims=True)\n\n  # Ensure numerical stability for small angles by using a small epsilon value.\n  angle = jnp.maximum(angle, eps)\n\n  # Compute the quaternion representation of the rotation.\n  quat = jnp.concatenate([axis * jnp.sin(angle / 2), jnp.cos(angle / 2)], axis=-1)\n\n  return quat\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  # Normalize the axis-angle vector to get the unit vector of the rotation axis\n  axis = axis_angle / (jnp.linalg.norm(axis_angle) + eps)\n\n  # Get the angle of rotation\n  angle = jnp.linalg.norm(axis_angle)\n\n  # Get the quaternion representation of the rotation\n  return jnp.concatenate([axis * jnp.sin(angle / 2.0), jnp.cos(angle / 2.0)])\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  # Normalize the axis-angle vector\n  axis = axis_angle[Ellipsis, 0:3]\n  axis = axis / (jnp.linalg.norm(axis) + eps)\n  angle = jnp.linalg.norm(axis_angle[Ellipsis, 0:3])\n\n  # Compute quaternion\n  quaternion = jnp.concatenate([\n    axis * jnp.sin(angle / 2.0),\n    jnp.cos(angle / 2.0)\n  ], axis=-1)\n\n  return quaternion\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  # Normalize the axis-angle to get the unit vector of rotation.\n  axis = axis_angle / (jnp.linalg.norm(axis_angle) + eps)\n  angle = jnp.linalg.norm(axis_angle)\n  # Construct the quaternion from the unit vector and angle.\n  return jnp.concatenate(\n      [\n          axis * jnp.sin(angle / 2.0),\n          jnp.cos(angle / 2.0)\n      ],\n      axis=-1\n  )\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  # Normalize the input axis-angle representation.\n  axis = axis_angle[..., :3]\n  angle = axis_angle[..., 3:]\n  axis = axis / (\n      eps + linalg.norm(axis, axis=-1, keepdims=True)\n  )\n\n  # Calculate the quaternion representation of the axis-angle representation.\n  s = jnp.cos(angle / 2.0)\n  v = jnp.sin(angle / 2.0)\n  v = v * axis\n  w = s\n  return jnp.concatenate([v, w], axis=-1)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  # Normalize the axis-angle vector to get theta and axis\n  axis = axis_angle / (jnp.linalg.norm(axis_angle) + eps)\n\n  # Angle of rotation\n  theta = jnp.linalg.norm(axis_angle)\n\n  # Compute quaternion\n  return jnp.concatenate(\n    [\n      jnp.sin(theta / 2) * axis,\n      jnp.cos(theta / 2)\n    ]\n  )\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    low = 0\n    mid = (high + low) / 2\n    while high >= low + 1e-8:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    low = 0\n    mid = (high + low) / 2\n    while high >= low + 1e-8:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    low = 0\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    low = 0\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    num_calls = k\n    logit_bias = {idx: high}\n    topk_words = model.topk(prefix, logit_bias)\n    while idx not in topk_words:\n        logit_bias[idx] *= 2\n        num_calls += k\n        topk_words = model.topk(prefix, logit_bias)\n    high = logit_bias[idx]\n\n    # improve estimate\n    low = 0\n    mid = (high + low) / 2\n    while high >= low + 1e-8:\n        logit_bias[idx] = mid\n        if idx in model.topk(prefix, logit_bias):\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    low = 0\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    num_calls = k\n    # check if idx is the argmax\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    low = 0\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    num_calls = k\n    logit_bias = {idx: high}\n    topk_words = model.topk(prefix, logit_bias)\n    topk_indices = list(topk_words.keys())\n    topk_probs = np.array(list(topk_words.values()))\n    while idx not in topk_indices:\n        logit_bias[idx] *= 2\n        num_calls += k\n        topk_words = model.topk(prefix, logit_bias)\n        topk_indices = list(topk_words.keys())\n        topk_probs = np.array(list(topk_words.values()))\n    high = logit_bias[idx]\n\n    # improve estimate\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        topk_words = model.topk(prefix, logit_bias)\n        topk_indices = list(topk_words.keys())\n        topk_probs = np.array(list(topk_words.values()))\n        num_calls += k\n        if idx in topk_indices:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n    return -mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    num_calls = k\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    low = 0\n    mid = (high + low) / 2\n    while high >= low + 1e-8:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n\n    # get topk\n    logit_bias[idx] = mid\n    topk_words = model.topk(prefix, logit_bias)\n    topk_indices = list(topk_words.keys())\n    topk_logprobs = np.array(list(topk_words.values()))\n\n    # get logprob of idx\n    logprob = topk_logprobs[topk_indices.index(idx)]\n\n    return logprob, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    num_calls = k\n    # check if idx is the argmax\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    num_calls = k\n    # get raw topk, could be done outside and passed in\n    topk_words = model.topk(prefix, {idx: high})\n    if idx in topk_words:\n        return topk_words[idx], num_calls\n\n    # improve estimate\n    low = 0\n    while idx not in topk_words:\n        low = high\n        high *= 2\n        num_calls += k\n        topk_words = model.topk(prefix, {idx: high})\n\n    # bisection search\n    mid = (high + low) / 2\n    while high >= low + 1e-8:\n        logit_bias = {idx: mid}\n        if idx in model.topk(prefix, logit_bias):\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n\n    return -mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    num_calls = k\n    # get raw topk, could be done outside and passed in\n    topk_words = model.topk(prefix, {idx: high})\n    if idx not in topk_words:\n        # if idx not in topk, set high to be the largest value in topk\n        high = max(topk_words.values())\n        topk_words = model.topk(prefix, {idx: high})\n\n    # calculate log_prob of idx being the top result\n    log_prob = topk_words[idx]\n\n    # calculate log_prob of the next top result\n    topk_words = model.topk(prefix, {idx: high}, k=2)\n    if idx in topk_words:\n        log_prob_next = topk_words[idx]\n    else:\n        log_prob_next = max(topk_words.values())\n\n    # adjust search bias until idx is the top result\n    while log_prob < log_prob_next:\n        # double high\n        high *= 2\n        # get topk\n        topk_words = model.topk(prefix, {idx: high}, k=2)\n        if idx in topk_words:\n            log_prob_next = topk_words[idx]\n        else:\n            log_prob_next = max(topk_words.values())\n        num_calls += k\n\n    # calculate log_prob of the next top result\n    topk_words = model.topk(prefix, {idx: high}, k=2)\n    if idx in topk_words:\n        log_prob_next = topk_words[idx]\n    else:\n        log_prob_next = max(topk_words.values())\n\n    # adjust search bias until idx is the top result\n    while log_prob < log_prob_next:\n        # double high\n        high *= 2\n        # get topk\n        topk_words = model.topk(prefix, {idx: high}, k=2)\n        if idx in topk_words:\n            log_prob"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    num_calls = k\n    # get raw topk, could be done outside and passed in\n    topk_words = model.topk(prefix, {idx: high})\n    if idx not in topk_words:\n        # check if idx is in topk\n        # if not, increase high\n        while idx not in topk_words:\n            high *= 2\n            num_calls += k\n            topk_words = model.topk(prefix, {idx: high})\n        # if it is, decrease high\n        while idx in topk_words:\n            high /= 2\n            num_calls += k\n            topk_words = model.topk(prefix, {idx: high})\n        high *= 2\n        num_calls += k\n        topk_words = model.topk(prefix, {idx: high})\n\n    # now, high is the highest value that idx is not in topk\n    # low is the lowest value that idx is in topk\n    low = high / 2\n    # improve estimate\n    mid = (high + low) / 2\n    while high >= low + 1e-8:\n        logit_bias = {idx: mid}\n        if idx in model.topk(prefix, logit_bias):\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    num_calls = k\n    # get raw topk, could be done outside and passed in\n    topk_words = model.topk(prefix, {idx: high})\n    if idx not in topk_words:\n        # if the index is not in the top-k, we need to increase the bias\n        while idx not in topk_words:\n            high *= 2\n            num_calls += k\n            topk_words = model.topk(prefix, {idx: high})\n        # now we have a high bias that includes the index in the top-k\n        # we can perform binary search for a lower bias that gives the index the top result\n        low = high / 2\n        while high - low > eps:\n            mid = (high + low) / 2\n            logit_bias = {idx: mid}\n            num_calls += k\n            if model.argmax(prefix, logit_bias) == idx:\n                high = mid\n            else:\n                low = mid\n        # at this point, low is the bias that gives the index the top result\n        # we can calculate the log probability\n        logit_bias = {idx: low}\n        num_calls += k\n        biased_topk_words = model.topk(prefix, logit_bias)\n        log_prob = biased_topk_words[idx] - logsumexp(\n            np.array([biased_topk_words[i] for i in biased_topk_words])\n        )\n        return log_prob, num_calls\n    else:\n        # if the index is in the top-k, we can just get the log probability\n        biased_topk_words = model.topk(prefix, {idx: high})\n        log_prob = biased_topk_words[idx] - logsumexp(\n            np.array([biased_topk_words[i] for i in biased_topk_words])\n        )\n        return log_prob, num_calls\n\n"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'TRILINEAR':\n    return _trilinear_resample(\n        data,\n        locations,\n        edge_behavior=edge_behavior,\n        constant_values=constant_values,\n        coordinate_order=coordinate_order,\n        half_pixel_center=half_pixel_center,\n    )\n  elif method == 'NEAREST':\n    return _nearest_neighbor_resample(\n        data,\n        locations,\n        edge_behavior=edge_behavior,\n        constant_values=constant_values,\n        coordinate_order=coordinate_order,\n        half_pixel_center=half_pixel_center,\n    )\n  else:\n    raise ValueError('Unsupported resampling method: %s' % method)\n\n"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'TRILINEAR':\n    return _trilinear_resample(\n        data,\n        locations,\n        edge_behavior=edge_behavior,\n        constant_values=constant_values,\n        coordinate_order=coordinate_order,\n        half_pixel_center=half_pixel_center,\n    )\n  elif method == 'NEAREST':\n    return _nearest_neighbor_resample(\n        data,\n        locations,\n        edge_behavior=edge_behavior,\n        coordinate_order=coordinate_order,\n        half_pixel_center=half_pixel_center,\n    )\n  else:\n    raise ValueError('Invalid method: %s' % method)\n\n"}
{"namespace": "resample.resample_3d", "completion": "  # Get the data shape.\n  data_shape = data.shape\n\n  # Get the number of dimensions.\n  num_dims = len(data_shape)\n\n  # Get the number of channels.\n  num_channels = data_shape[-1]\n\n  # Get the number of locations.\n  num_locations = locations.shape[0]\n\n  # Get the data type.\n  data_dtype = data.dtype\n\n  # Get the data shape.\n  data_shape = data.shape\n\n  # Get the data shape.\n  data_shape = data.shape\n\n  # Get the data shape.\n  data_shape = data.shape\n\n  # Get the data shape.\n  data_shape = data.shape\n\n  # Get the data shape.\n  data_shape = data.shape\n\n  # Get the data shape.\n  data_shape = data.shape\n\n  # Get the data shape.\n  data_shape = data.shape\n\n  # Get the data shape.\n  data_shape = data.shape\n\n  # Get the data shape.\n  data_shape = data.shape\n\n  # Get the data shape.\n  data_shape = data.shape\n\n  # Get the data shape.\n  data_shape = data.shape\n\n  # Get the data shape.\n  data_shape = data.shape\n\n  # Get the data shape.\n  data_shape = data.shape\n\n  # Get the data shape.\n  data_shape = data.shape\n\n  # Get the data shape.\n  data_shape = data.shape\n\n  # Get the data shape.\n  data_shape = data.shape\n\n  # Get the data shape.\n  data_shape = data.shape\n\n  # Get the data shape.\n  data_shape = data.shape\n\n  # Get the data shape.\n  data_shape = data.shape\n\n  # Get the data shape.\n  data_shape = data.shape\n\n  # Get the data shape.\n  data_shape = data.shape\n\n  # Get the data shape.\n  data_shape ="}
{"namespace": "resample.resample_3d", "completion": "  if method == 'TRILINEAR':\n    return _trilinear_interpolation_3d(\n        data,\n        locations,\n        edge_behavior=edge_behavior,\n        constant_values=constant_values,\n        coordinate_order=coordinate_order,\n        half_pixel_center=half_pixel_center)\n  elif method == 'NEAREST':\n    return _nearest_neighbor_interpolation_3d(\n        data,\n        locations,\n        edge_behavior=edge_behavior,\n        constant_values=constant_values,\n        coordinate_order=coordinate_order,\n        half_pixel_center=half_pixel_center)\n  else:\n    raise ValueError('Unsupported interpolation method %s.' % method)\n\n"}
{"namespace": "resample.resample_3d", "completion": "  if edge_behavior == 'CONSTANT_OUTSIDE':\n    data = jnp.pad(data, [(1, 1), (1, 1), (1, 1), (0, 0)],\n                   mode='constant',\n                   constant_values=constant_values)\n    locations = locations + 1\n  elif edge_behavior == 'CLAMP':\n    locations = jnp.maximum(\n      jnp.minimum(locations, jnp.array(data.shape[:3] - 1, dtype=locations.dtype)),\n      0)\n\n  if half_pixel_center:\n    locations = (locations + 0.5).astype(jnp.int32)\n  else:\n    locations = locations.astype(jnp.int32)\n\n  if method == 'TRILINEAR':\n    return gather_volume(data, locations, coordinate_order)\n  elif method == 'NEAREST':\n    return jax.lax.stop_gradient(gather_volume(data, locations, coordinate_order))"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'TRILINEAR':\n    return _trilinear_interpolation(data, locations, edge_behavior, constant_values, coordinate_order, half_pixel_center)\n  elif method == 'NEAREST':\n    return _nearest_neighbor_interpolation(data, locations, edge_behavior, constant_values, coordinate_order, half_pixel_center)\n  else:\n    raise ValueError(\"method must be either 'TRILINEAR' or 'NEAREST'\")\n\n"}
{"namespace": "resample.resample_3d", "completion": "  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError(\n        \"edge_behavior must be 'CONSTANT_OUTSIDE' or 'CLAMP'.\")\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError(\"method must be 'TRILINEAR' or 'NEAREST'.\")\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError(\"coordinate_order must be 'xyz' or 'zyx'.\")\n\n  if method == 'TRILINEAR':\n    return _trilinear_resample(\n        data,\n        locations,\n        edge_behavior,\n        constant_values,\n        coordinate_order,\n        half_pixel_center,\n    )\n  elif method == 'NEAREST':\n    return _nearest_neighbor_resample(\n        data,\n        locations,\n        edge_behavior,\n        constant_values,\n        coordinate_order,\n        half_pixel_center,\n    )\n\n"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'TRILINEAR':\n    return _trilinear_resample(\n        data,\n        locations,\n        edge_behavior=edge_behavior,\n        constant_values=constant_values,\n        coordinate_order=coordinate_order,\n        half_pixel_center=half_pixel_center,\n    )\n  elif method == 'NEAREST':\n    return _nearest_resample(\n        data,\n        locations,\n        edge_behavior=edge_behavior,\n        constant_values=constant_values,\n        coordinate_order=coordinate_order,\n        half_pixel_center=half_pixel_center,\n    )\n  else:\n    raise ValueError('Invalid method: %s' % method)\n\n"}
{"namespace": "resample.resample_3d", "completion": "  # Handle edge_behavior\n  if edge_behavior == 'CONSTANT_OUTSIDE':\n    data = jnp.pad(data, [(1, 1), (1, 1), (1, 1), (0, 0)],\n                   mode='constant',\n                   constant_values=constant_values)\n    locations = locations + 1\n  elif edge_behavior == 'CLAMP':\n    locations = jnp.clip(locations, 0, data.shape[0] - 1)\n  else:\n    raise ValueError(\n      f\"Edge behavior {edge_behavior} not supported. Use 'CONSTANT_OUTSIDE' or 'CLAMP'.\"\n    )\n\n  # Handle half_pixel_center\n  if half_pixel_center:\n    locations = locations + 0.5\n\n  # Handle method\n  if method == 'TRILINEAR':\n    return gather_volume(data, locations, coordinate_order=coordinate_order)\n  elif method == 'NEAREST':\n    locations = jnp.round(locations).astype(jnp.int32)\n    return gather_volume(data, locations, coordinate_order=coordinate_order)\n  else:\n    raise ValueError(\n      f\"Method {method} not supported. Use 'TRILINEAR' or 'NEAREST'.\"\n    )\n\n"}
{"namespace": "resample.resample_3d", "completion": "  if half_pixel_center:\n    locations = locations + 0.5\n\n  if edge_behavior == 'CONSTANT_OUTSIDE':\n    data = jnp.pad(data, [[1, 1], [1, 1], [1, 1], [0, 0]],\n                   mode='constant',\n                   constant_values=constant_values)\n    locations = locations + 1\n\n  if method == 'TRILINEAR':\n    locations_top_left = jnp.floor(locations)\n    locations_top_right = jnp.floor(locations)\n    locations_bottom_left = jnp.floor(locations)\n    locations_bottom_right = jnp.floor(locations)\n\n    top_left = gather_volume(data, locations_top_left, coordinate_order)\n    top_right = gather_volume(data, locations_top_right, coordinate_order)\n    bottom_left = gather_volume(data, locations_bottom_left, coordinate_order)\n    bottom_right = gather_volume(data, locations_bottom_right, coordinate_order)\n\n    interp_top = jnp.lerp(top_left, top_right, locations[Ellipsis, 0] - locations_top_left[Ellipsis, 0])\n    interp_bottom = jnp.lerp(bottom_left, bottom_right, locations[Ellipsis, 0] - locations_bottom_left[Ellipsis, 0])\n    return jnp.lerp(interp_top, interp_bottom, locations[Ellipsis, 1] - locations_top_left[Ellipsis, 1])\n\n  elif method == 'NEAREST':\n    locations_nearest = jnp.floor(locations)\n    return gather_volume(data, locations_nearest, coordinate_order)\n\n  else:\n    raise ValueError(f'Invalid method {method}')\n\n"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'TRILINEAR':\n    return _trilinear_resample(data, locations, edge_behavior, constant_values, coordinate_order, half_pixel_center)\n  elif method == 'NEAREST':\n    return _nearest_neighbor_resample(data, locations, edge_behavior, constant_values, coordinate_order, half_pixel_center)\n  else:\n    raise ValueError('Invalid method: %s' % method)\n\n"}
{"namespace": "resample.resample_3d", "completion": "  if edge_behavior == 'CONSTANT_OUTSIDE':\n    # Pad the volume to avoid edge effects.\n    data = jnp.pad(\n      data,\n      [[1, 1], [1, 1], [1, 1], [0, 0]],\n      mode='constant',\n      constant_values=constant_values,\n    )\n\n    # Adjust the locations to account for the padding.\n    locations = locations + 1\n\n  # Adjust the locations to account for half-pixel centering.\n  if half_pixel_center:\n    locations = locations + 0.5\n\n  # Get the integer coordinates of the sample locations.\n  locations_floor = jnp.floor(locations)\n  locations_floor = locations_floor.astype(jnp.int32)\n\n  # Get the fractional coordinates of the sample locations.\n  locations_fraction = locations - locations_floor\n\n  # Get the locations of the points below and above the fractional locations.\n  locations_below = locations_floor\n  locations_above = locations_floor + 1\n\n  # Get the values at the locations below and above.\n  below_values = gather_volume(data, locations_below, coordinate_order)\n  above_values = gather_volume(data, locations_above, coordinate_order)\n\n  if method == 'TRILINEAR':\n    # Get the values at the locations to the left and right of the fractional\n    # locations.\n    locations_below_left = locations_below.at[Ellipsis, 0].set(\n      locations_below[Ellipsis, 0] - 1)\n    locations_below_right = locations_below.at[Ellipsis, 0].set(\n      locations_below[Ellipsis, 0] + 1)\n    locations_above_left = locations_above.at[Ellipsis, 0].set(\n      locations_above[Ellipsis, 0] - 1)\n    locations_above_right = locations_above.at[Ellipsis, 0].set(\n     "}
{"namespace": "resample.resample_3d", "completion": "  # Get the shape of the input data.\n  data_shape = data.shape\n\n  # Get the shape of the input locations.\n  locations_shape = locations.shape\n\n  # Get the number of dimensions of the data.\n  num_dims = len(data_shape)\n\n  # Get the number of dimensions of the locations.\n  num_loc_dims = len(locations_shape)\n\n  # Get the number of channels in the data.\n  num_channels = data_shape[-1]\n\n  # Get the data type of the data.\n  data_dtype = data.dtype\n\n  # Get the data shape as a list.\n  data_shape_list = list(data_shape)\n\n  # Get the locations shape as a list.\n  locations_shape_list = list(locations_shape)\n\n  # Get the locations shape as a list.\n  locations_shape_list = list(locations_shape)\n\n  # Get the locations shape as a list.\n  locations_shape_list = list(locations_shape)\n\n  # If the locations are not 3D, then raise an error.\n  if num_loc_dims < 3 or locations_shape[-1] != 3:\n    raise ValueError('The locations must be 3D.')\n\n  # If the number of dimensions of the data is not 3 or 4, then raise an error.\n  if num_dims != 3 and num_dims != 4:\n    raise ValueError('The data must be 3D or 4D.')\n\n  # If the number of dimensions of the data is 3, then add a channel dimension to the data.\n  if num_dims == 3:\n    data = jnp.expand_dims(data, axis=-1)\n\n  # If the number of dimensions of the locations is 4, then remove the channel dimension from the locations.\n  if num_loc_dims == 4:\n    locations = jnp.squeeze(locations, axis=-1)\n\n  # If the locations are in zyx order, then convert them"}
{"namespace": "resample.resample_3d", "completion": "  # Compute the size of the input data.\n  data_shape = data.shape\n  data_volume_shape = data_shape[:3]\n  data_batch_shape = data_shape[3:]\n  data_volume_size = np.prod(data_volume_shape)\n  data_batch_size = np.prod(data_batch_shape)\n\n  # Compute the size of the locations.\n  locations_shape = locations.shape\n  locations_batch_shape = locations_shape[3:]\n  locations_batch_size = np.prod(locations_batch_shape)\n\n  # Check the batch shape is the same for both data and locations.\n  if data_batch_shape != locations_batch_shape:\n    raise ValueError(\n      'Data batch shape must be equal to locations batch shape.')\n\n  # Check the coordinate order is valid.\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError(\n      'Coordinate order must be one of \\'xyz\\' or \\'zyx\\'.')\n\n  # Check the interpolation method is valid.\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError(\n      'Interpolation method must be one of \\'TRILINEAR\\' or \\'NEAREST\\'.')\n\n  # Check the edge behavior is valid.\n  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError(\n      'Edge behavior must be one of \\'CONSTANT_OUTSIDE\\' or \\'CLAMP\\'.')\n\n  # Check the input data is a float.\n  if data.dtype != jnp.float32:\n    data = jnp.asarray(data, dtype=jnp.float32)\n\n  # Check the input locations is an int.\n  if locations.dtype != jnp.int32:\n    locations = jnp.asarray(locations, dtype=jnp.int32)\n\n  # Check the input data is a float.\n  if constant_values.dtype != jnp"}
{"namespace": "resample.resample_3d", "completion": "  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError(f\"method must be either 'TRILINEAR' or 'NEAREST', got {method}.\")\n\n  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError(f\"edge_behavior must be either 'CONSTANT_OUTSIDE' or 'CLAMP', got {edge_behavior}.\")\n\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError(f\"coordinate_order must be either 'xyz' or 'zyx', got {coordinate_order}.\")\n\n  if half_pixel_center:\n    locations = jnp.floor(locations) + 0.5\n\n  # Pad the volume.\n  if edge_behavior == 'CONSTANT_OUTSIDE':\n    data = jnp.pad(data, [(1, 1), (1, 1), (1, 1), (0, 0)],\n                   mode='constant', constant_values=constant_values)\n\n  # Use Advanced indexing to gather data.\n  if method == 'TRILINEAR':\n    data = jnp.pad(data, [(0, 0), (1, 1), (1, 1), (1, 1)],\n                   mode='edge')\n    locations = locations + 1\n    locations_0 = jnp.floor(locations)\n    locations_0 = jnp.clip(locations_0, a_min=0, a_max=None)\n    locations_1 = locations_0 + 1\n    locations_1 = jnp.clip(locations_1, a_min=None, a_max=jnp.array(data.shape[:3] - 1))\n    locations_fraction = locations - locations_0\n\n    data_0 = gather_volume(data, locations_0, coordinate_order)\n    data_1 = gather_volume(data, locations_1, coordinate_order)\n    data_0 = data_0 * (1 - locations_fraction["}
{"namespace": "resample.resample_3d", "completion": "  # Validate inputs\n  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError('Edge behavior must be either \\'CONSTANT_OUTSIDE\\' or \\'CLAMP\\'.')\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError('Method must be either \\'TRILINEAR\\' or \\'NEAREST\\'.')\n  if half_pixel_center:\n    raise NotImplementedError('Half pixel centering is not yet implemented.')\n\n  # Pad the volume if edge_behavior is 'CONSTANT_OUTSIDE'\n  if edge_behavior == 'CONSTANT_OUTSIDE':\n    data = jnp.pad(data, [[1, 1], [1, 1], [1, 1], [0, 0]],\n                   mode='constant',\n                   constant_values=constant_values)\n\n  # Get the location of each sample point\n  locations = jnp.asarray(locations)\n  locations = jnp.pad(locations, [[0, 0], [1, 1], [1, 1], [1, 1], [0, 0]],\n                      mode='constant',\n                      constant_values=0)\n  locations = locations.astype(jnp.float32)\n\n  if half_pixel_center:\n    locations = locations + 0.5\n\n  # Get the integer and fractional locations\n  locations_floor = jnp.floor(locations)\n  locations_ceil = locations_floor + 1.0\n  locations_frac = locations - locations_floor\n\n  # Get the integer locations\n  locations_floor_int = locations_floor.astype(jnp.int32)\n  locations_ceil_int = locations_ceil.astype(jnp.int32)\n\n  # Get the interpolation weights\n  if method == 'TRILINEAR':\n    weights = jnp.abs(1.0 - locations_frac)\n    weights_ceil = jnp.abs(locations_frac)"}
{"namespace": "resample.resample_3d", "completion": "  # Validate inputs.\n  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError('edge_behavior must be either \\'CONSTANT_OUTSIDE\\' or \\'CLAMP\\'.')\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError('method must be either \\'TRILINEAR\\' or \\'NEAREST\\'.')\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError('coordinate_order must be either \\'xyz\\' or \\'zyx\\'.')\n\n  # Get the shape of the input data.\n  data_shape = data.shape\n  if len(data_shape) != 4:\n    raise ValueError('data must have shape [D, H, W, C].')\n\n  # Get the shape of the locations.\n  locations_shape = locations.shape\n  if len(locations_shape) < 3:\n    raise ValueError('locations must have shape [D, ..., 3].')\n  if locations_shape[-1] != 3:\n    raise ValueError('locations must have shape [D, ..., 3].')\n\n  # Get the batch size.\n  batch_size = locations_shape[0]\n\n  # Get the number of channels.\n  num_channels = data_shape[-1]\n\n  # Get the output shape.\n  output_shape = locations_shape[1:-1]\n\n  # Get the output volume size.\n  volume_size = np.array([data_shape[0], data_shape[1], data_shape[2]])\n\n  # Pad the data volume if edge_behavior is 'CONSTANT_OUTSIDE'.\n  if edge_behavior == 'CONSTANT_OUTSIDE':\n    data = jnp.pad(data, ((1, 1), (1, 1), (1, 1), (0, 0)), constant_values=constant_values)\n\n  # Adjust the locations for half-pixel centering.\n  if half_pixel_"}
{"namespace": "resample.resample_3d", "completion": "  # Get the volume dimensions.\n  volume_shape = data.shape\n  volume_size = volume_shape[:3]\n  batch_size = volume_shape[3]\n\n  # Get the locations.\n  locations = jnp.asarray(locations)\n  locations = jnp.asarray(locations, dtype=jnp.int32)\n  locations = jnp.reshape(locations, [-1, 3])\n  locations = jnp.mod(locations, volume_size)\n  locations = jnp.asarray(locations, dtype=jnp.float32)\n\n  # Get the volume dimensions.\n  volume_size = jnp.asarray(volume_size)\n\n  # Get the half-pixel offset.\n  if half_pixel_center:\n    offset = 0.5\n  else:\n    offset = 0.0\n\n  # Get the output shape.\n  output_shape = locations.shape[:-1]\n\n  # Get the indices and weights.\n  if method == 'TRILINEAR':\n    indices, weights = _get_indices_and_weights(\n        locations, volume_size, offset)\n  elif method == 'NEAREST':\n    indices, weights = _get_indices_and_weights_nearest(\n        locations, volume_size, offset)\n  else:\n    raise ValueError('Invalid interpolation method.')\n\n  # Get the gathered values.\n  if edge_behavior == 'CONSTANT_OUTSIDE':\n    constant_values = jnp.asarray(constant_values)\n    constant_values = jnp.reshape(constant_values, [1, 1, 1, -1])\n    constant_values = jnp.tile(constant_values, [volume_size[0], volume_size[1], volume_size[2], 1])\n    gathered_values = gather_volume(constant_values, indices, coordinate_order)\n  elif edge_behavior == 'CLAMP':\n    gathered_values = gather_volume(data, indices, coordinate_order)\n  else:\n    raise"}
{"namespace": "resample.resample_3d", "completion": "  # Check inputs\n  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError('Edge behavior must be one of \\'CONSTANT_OUTSIDE\\' or \\'CLAMP\\'.')\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError('Method must be one of \\'TRILINEAR\\' or \\'NEAREST\\'.')\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError('Coordinate order must be one of \\'xyz\\' or \\'zyx\\'.')\n\n  # Get the input shape\n  data_shape = data.shape\n  data_volume_shape = data_shape[:3]\n  num_channels = data_shape[3]\n\n  # Get the locations shape\n  locations_shape = locations.shape\n  num_locations = locations_shape[0]\n  num_locations_per_batch = locations_shape[1]\n  num_locations_per_batch_per_sample = locations_shape[2]\n\n  # Check that the batch shapes are compatible\n  if num_locations_per_batch != data_volume_shape[0]:\n    raise ValueError('Batch shape is incompatible with data volume shape.')\n\n  # Check that the number of dimensions is compatible\n  if locations_shape[-1] != 3:\n    raise ValueError('Number of dimensions must be 3.')\n\n  # Check that the number of channels is compatible\n  if data_shape[3] != num_channels:\n    raise ValueError('Number of channels is incompatible between data and locations.')\n\n  # Get the output shape\n  output_shape = (num_locations, num_locations_per_batch, num_locations_per_batch_per_sample, num_channels)\n\n  # Pad the volume if edge_behavior is 'CONSTANT_OUTSIDE'\n  if edge_behavior == 'CONSTANT_OUTSIDE':\n    # Pad the volume\n    data_shape = data.shape\n    data_volume_shape"}
{"namespace": "resample.resample_3d", "completion": "  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError(\n        'Unsupported edge_behavior. Must be either \\'CONSTANT_OUTSIDE\\' or \\'CLAMP\\'.'\n    )\n\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError(\n        'Unsupported method. Must be either \\'TRILINEAR\\' or \\'NEAREST\\'.')\n\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError(\n        'Unsupported coordinate_order. Must be either \\'xyz\\' or \\'zyx\\'.')\n\n  # Add a batch dimension if necessary.\n  if data.ndim == 4:\n    data = data[None, ...]\n\n  if locations.ndim == 4:\n    locations = locations[None, ...]\n\n  # If half-pixel centering is used, the integer locations correspond to the pixel centers.\n  if half_pixel_center:\n    locations = locations - 0.5\n\n  # Get the integer and fractional locations.\n  locations_floor = jnp.floor(locations)\n  locations_fraction = locations - locations_floor\n\n  # If the half-pixel centering is not used, the integer locations correspond to the pixel edges.\n  if not half_pixel_center:\n    locations_floor = locations_floor - 1\n\n  # Get the locations around which to sample.\n  locations_0 = locations_floor.astype(jnp.int32)\n  locations_1 = locations_floor.astype(jnp.int32) + 1\n\n  # Get the interpolation weights.\n  weights_0 = jnp.prod(1.0 - locations_fraction, axis=-1)\n  weights_1 = jnp.prod(locations_fraction, axis=-1)\n\n  # Get the locations to sample.\n  locations_0 = locations_0.astype(jnp.int32)\n  locations_1 = locations_"}
{"namespace": "math.plus_eps", "completion": "  return jnp.maximum(x, tiny_val)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.maximum(x, tiny_val)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(x < tiny_val, tiny_val, x + tiny_val)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(x < tiny_val, tiny_val, x + tiny_val)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(x < tiny_val, tiny_val, x + tiny_val)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, x + tiny_val)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(x < tiny_val, tiny_val, x + tiny_val)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(x == 0, tiny_val, jnp.where(x < tiny_val, tiny_val, x))\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.maximum(x, tiny_val)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(x < tiny_val, tiny_val, x + tiny_val)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(x, jnp.inf))\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(x == 0, tiny_val, jnp.where(x < tiny_val, tiny_val, x))\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(x < tiny_val, tiny_val, x + tiny_val)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(x < tiny_val, tiny_val, jnp.nextafter(x, jnp.inf))\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(x < tiny_val, tiny_val, x + tiny_val)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(x == 0, tiny_val, jnp.where(x < tiny_val, tiny_val, x))\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(x < tiny_val, tiny_val, x + tiny_val)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(x < tiny_val, tiny_val, x)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.maximum(x, tiny_val)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(x > tiny_val, x, tiny_val)\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val,\n      jnp.nextafter(jnp.float32(x), jnp.float32(x) - 1)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val,\n      jnp.nextafter(jnp.float32(x), jnp.float32(x) - 1)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val,\n      jnp.nextafter(jnp.float32(x), jnp.float32(x) - 1)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), jnp.NINF)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), jnp.NINF)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val,\n      jnp.nextafter(jnp.float32(x), jnp.float32(x) - 1)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val,\n      jnp.nextafter(jnp.float32(x), jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), jnp.NINF)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val,\n      jnp.nextafter(jnp.float32(x), jnp.float32(x) - 1)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val,\n      jnp.nextafter(jnp.float32(x), jnp.float32(jnp.inf))\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val,\n      jnp.nextafter(jnp.float32(x), jnp.float32(x) - 1)\n  )\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: x_dot * y,\n      (min_val, 100.0),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: x_dot * y,\n      (min_val, 100.0),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: x_dot * y,\n      (min_val, 100 * jnp.log(max_val)),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (-max_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: x_dot * y,\n      (-max_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: x_dot * y,\n      (-max_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: x_dot * y,\n      (min_val, 100.0),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: x_dot * y,\n      (min_val, 15.),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: x_dot * y,\n      (min_val, 100.0),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: x_dot * y,\n      (min_val, 500.),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, 10000.0),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: x_dot * y,\n      (min_val, 100),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: x_dot * y,\n      (min_val, 10000.0),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: x_dot * y,\n      (-max_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: x_dot * y,\n      (min_val, 1000000.0),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: x_dot * y,\n      (-max_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, y_dot: y_dot * y,\n      (min_val, 100.0),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, y_dot: y_dot * y,\n      (min_val, 100.0),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: x_dot * y,\n      (min_val, 100 * jnp.log(max_val)),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (-max_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, y_dot: y_dot / y, (-max_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, dy: dy / y, (tiny_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, dy: dy / y, (tiny_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, y_dot: y_dot / y, [min_val, max_val])(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, dy: dy / y, (-max_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, y_dot: y_dot / y, [min_val, max_val])(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, y_dot: y_dot / y, [tiny_val, max_val])(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, safe_log_grad, (tiny_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, y_dot: y_dot / y, [tiny_val, max_val])(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / x, (tiny_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, y_dot: y_dot / y, (-max_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, y_dot: y_dot / y, [1e-35, max_val])(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, y_dot: y_dot / y, (tiny_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, dydx: dydx / y, [tiny_val, max_val])(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / x, [min_val, max_val])(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / x, (tiny_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, d: d / x, (tiny_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / x, [tiny_val, max_val])(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, y_dot: y_dot / y, [min_val, max_val])(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, y_dot: y_dot / y, (tiny_val, max_val))(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: x_dot / (2 * y),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, _, x_dot: x_dot / (2 * safe_sqrt(x)),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: x_dot / (2 * y),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: x_dot / (2 * y),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: x_dot / (2 * y),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, _, x_dot: 0.5 * x_dot / x,\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, _, x_dot: x_dot / (2 * safe_sqrt(x)),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: x_dot / (2 * y),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, _, x_dot: 0.5 * x_dot / x,\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: x_dot / (2 * y),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, _, x_dot: 0.5 * x_dot / x,\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, _, x_dot: 0.5 * x_dot / x,\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, _, x_dot: 0.5 * x_dot / safe_sqrt(x),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, _, x_dot: x_dot / (2 * safe_sqrt(x)),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: x_dot / (2 * y),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, _, x_dot: x_dot / (2 * safe_sqrt(x)),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: x_dot / (2 * y),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, _, x_dot: x_dot / (2 * safe_sqrt(x)),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: x_dot / (2 * y),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, _, x_dot: 0.5 * x_dot / x,\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 0:\n    return 1\n  elif p == 1:\n    return 2\n  elif p == 2:\n    return 2\n  elif p == 3:\n    return 2\n  elif p == 4:\n    return 2\n  elif p == 5:\n    return 2\n  elif p == 6:\n    return 2\n  elif p == 7:\n    return 2\n  elif p == 8:\n    return 2\n  elif p == 9:\n    return 2\n  elif p == 10:\n    return 2\n  elif p == 11:\n    return 2\n  elif p == 12:\n    return 2\n  elif p == 13:\n    return 2\n  elif p == 14:\n    return 2\n  elif p == 15:\n    return 2\n  elif p == 16:\n    return 2\n  elif p == 17:\n    return 2\n  elif p == 18:\n    return 2\n  elif p == 19:\n    return 2\n  elif p == 20:\n    return 2\n  elif p == 21:\n    return 2\n  elif p == 22:\n    return 2\n  elif p == 23:\n    return 2\n  elif p == 24:\n    return 2\n  elif p == 25:\n    return 2\n  elif p == 26:\n    return 2\n  elif p == 27:\n    return 2\n  elif p == 28:\n    return 2\n  elif p == 29:\n    return 2\n  elif p == 30:\n    return 2\n  elif p == 31:\n    return 2\n  elif p == 32:\n    return 2\n  elif p == 33:\n    return 2\n  elif p == 34:\n    return 2\n  elif p == 35:\n    return 2\n  elif p == "}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 0:\n    return 1\n  elif p == 1:\n    return 2\n  elif p == 2:\n    return 2\n  elif p == 3:\n    return 3\n  elif p == 4:\n    return 3\n  elif p == 5:\n    return 4\n  elif p == 6:\n    return 4\n  elif p == 7:\n    return 5\n  elif p == 8:\n    return 5\n  elif p == 9:\n    return 6\n  elif p == 10:\n    return 6\n  elif p == 11:\n    return 7\n  elif p == 12:\n    return 7\n  elif p == 13:\n    return 8\n  elif p == 14:\n    return 8\n  elif p == 15:\n    return 9\n  elif p == 16:\n    return 9\n  elif p == 17:\n    return 10\n  elif p == 18:\n    return 10\n  elif p == 19:\n    return 11\n  elif p == 20:\n    return 11\n  elif p == 21:\n    return 12\n  elif p == 22:\n    return 12\n  elif p == 23:\n    return 13\n  elif p == 24:\n    return 13\n  elif p == 25:\n    return 14\n  elif p == 26:\n    return 14\n  elif p == 27:\n    return 15\n  elif p == 28:\n    return 15\n  elif p == 29:\n    return 16\n  elif p == 30:\n    return 16\n  elif p == 31:\n    return 17\n  elif p == 32:\n    return 17\n  elif p == 33:\n    return 18\n  elif p == 34:\n    return 18\n "}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return 1\n  elif p == 2:\n    return 2\n  elif p == 3:\n    return 3\n  elif p > 3:\n    return 1\n  else:\n    return 0\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return 1\n  elif p == 2:\n    return 2\n  elif p == 3:\n    return 3\n  elif p == 4:\n    return 4\n  elif p > 4:\n    return max_val\n  else:\n    return min_val\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 0:\n    return 1\n  elif p == 1:\n    return 2\n  else:\n    return 1 / (1 - p)\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p < 1:\n    return 1\n  elif p == 1:\n    return 2\n  else:\n    return 1 / (1 - p)\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return 1\n  elif p == 2:\n    return 2\n  elif p == 3:\n    return 3\n  else:\n    return 1 / (1 - p)\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 0:\n    return 1\n  elif p < 0:\n    return max_val\n  elif p > 0:\n    return 1\n  else:\n    return 0\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 0:\n    return 1.0\n  elif p < 0:\n    return 0.0\n  else:\n    return 1.0 / (1.0 - p)\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 0:\n    return 1\n  elif p == 1:\n    return 2\n  elif p == 2:\n    return 2\n  elif p > 2:\n    return 1\n  else:\n    return 0\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return max_val\n  elif p == 0:\n    return 1\n  elif p < 0:\n    return 0\n  else:\n    return max_val\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 0:\n    return 1\n  if p == 1:\n    return 2\n  if p > 1:\n    return 1 / (1 - p)\n  if p < 0:\n    return np.inf\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 0:\n    return 1.0\n  elif p < 0:\n    return 0.0\n  else:\n    return 1.0 / (1.0 + p)\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p <= 0:\n    return 0\n  elif p == 1:\n    return 1\n  else:\n    return 1 / (p - 1)\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 0:\n    return 1.0\n  elif p < 0:\n    return 0.0\n  else:\n    return 1.0 / (1.0 - p)\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 0:\n    return 1\n  elif p < 0:\n    return 0\n  else:\n    return 1\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return max_val\n  if p == 0:\n    return 1\n  if p == -1:\n    return 0\n  if p > 1:\n    return max_val\n  if p < -1:\n    return 0\n  return 0\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 0:\n    return 1\n  elif p == 1:\n    return 2\n  elif p < 1:\n    return 1 / (1 - p)\n  else:\n    return 1\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return 1\n  elif p > 1:\n    return 1 / (p - 1)\n  else:\n    return 1 / (2 - p)\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return max_val\n  elif p == 0:\n    return 1\n  elif p < 0:\n    return 0\n  else:\n    return max_val\n\n"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n      [\n        [1, 1, 1],\n        [-1, -1, 1],\n        [1, -1, -1],\n        [-1, 1, -1],\n      ]\n    )\n    base_faces = np.array(\n      [\n        [0, 1, 2],\n        [0, 2, 3],\n        [0, 3, 1],\n        [1, 2, 3],\n      ]\n    )\n  elif base_shape == 'icosahedron':\n    base_verts = np.array(\n      [\n        [0, 1, phi],\n        [0, 1, -phi],\n        [0, -1, phi],\n        [0, -1, -phi],\n        [1, phi, 0],\n        [1, -phi, 0],\n        [-1, phi, 0],\n        [-1, -phi, 0],\n        [phi, 0, 1],\n        [-phi, 0, 1],\n        [phi, 0, -1],\n        [-phi, 0, -1],\n      ]\n    )\n    base_faces = np.array(\n      [\n        [0, 1, 2],\n        [0, 2, 3],\n        [0, 3, 4],\n        [0, 4, 5],\n        [0, 5, 1],\n        [1, 6, 2],\n        [2, 7, 3],\n        [3, 8, 4],\n        [4, 9, 5],\n        [5, 10, 6],\n        [6, 11, 1],\n        [1, 11, 7],\n        [7, 8, 10],\n        [8, 9, 11],\n        [9, 10, 7],\n        [7, 10, "}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n      [\n        [1, 1, 1],\n        [-1, -1, 1],\n        [1, -1, -1],\n        [-1, 1, -1]\n      ]\n    )\n    base_faces = np.array(\n      [\n        [0, 1, 2],\n        [0, 1, 3],\n        [0, 2, 3],\n        [1, 2, 3]\n      ]\n    )\n  elif base_shape == 'icosahedron':\n    base_verts = np.array(\n      [\n        [0, 1, phi],\n        [0, 1, -phi],\n        [0, -1, phi],\n        [0, -1, -phi],\n        [1, phi, 0],\n        [1, -phi, 0],\n        [-1, phi, 0],\n        [-1, -phi, 0],\n        [phi, 0, 1],\n        [phi, 0, -1],\n        [-phi, 0, 1],\n        [-phi, 0, -1]\n      ]\n    )\n    base_faces = np.array(\n      [\n        [0, 1, 2],\n        [0, 2, 3],\n        [0, 3, 4],\n        [0, 4, 5],\n        [0, 5, 1],\n        [1, 6, 2],\n        [2, 7, 3],\n        [3, 8, 4],\n        [4, 9, 5],\n        [5, 10, 6],\n        [6, 1, 7],\n        [7, 2, 8],\n        [8, 3, 9],\n        [9, 4, 10],\n        [10, 5, 6]\n      ]\n    )\n  elif base_shape =="}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([[1, 1, 1], [-1, -1, 1], [1, -1, -1], [-1, 1, -1]])\n    base_faces = np.array([[0, 1, 2], [0, 2, 3], [0, 3, 1], [1, 3, 2]])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array([\n      [0, 1, phi],\n      [0, -1, phi],\n      [0, 1, -phi],\n      [0, -1, -phi],\n      [1, phi, 0],\n      [-1, phi, 0],\n      [1, -phi, 0],\n      [-1, -phi, 0],\n      [phi, 0, 1],\n      [-phi, 0, 1],\n      [phi, 0, -1],\n      [-phi, 0, -1],\n    ])\n    base_faces = np.array([\n      [0, 1, 2],\n      [0, 2, 3],\n      [0, 3, 4],\n      [0, 4, 5],\n      [0, 5, 1],\n      [1, 6, 2],\n      [2, 7, 3],\n      [3, 8, 4],\n      [4, 9, 5],\n      [5, 10, 6],\n      [6, 10, 7],\n      [7, 10, 8],\n      [8, 10, 9],\n      [9, 10, 11],\n      [1, 11, 2],\n      [2, 11, 7],\n      [7, 11, 8],\n      [8, 11, 1],\n      [1, 2, 6],\n      [6,"}
{"namespace": "geopoly.generate_basis", "completion": "  if angular_tesselation < 1:\n    raise ValueError(f'angular_tesselation {angular_tesselation} must be >= 1')\n  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(f'base_shape {base_shape} must be one of tetrahedron, icosahedron, or octahedron')\n\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([[1, 1, 1], [-1, -1, 1], [1, -1, -1], [-1, 1, -1]])\n    base_faces = np.array([[0, 1, 2], [0, 1, 3], [0, 2, 3], [1, 2, 3]])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array([\n      [0, 1, phi],\n      [0, -1, phi],\n      [0, 1, -phi],\n      [0, -1, -phi],\n      [1, phi, 0],\n      [-1, phi, 0],\n      [1, -phi, 0],\n      [-1, -phi, 0],\n      [phi, 0, 1],\n      [phi, 0, -1],\n      [-phi, 0, 1],\n      [-phi, 0, -1],\n    ])\n    base_faces = np.array([\n      [0, 1, 2],\n      [0, 2, 3],\n      [0, 3, 4],\n      [0, 4, 5],\n      [0, 5, 1],\n      [11, 7, 6],\n      [11, 8, 7],\n      [11, 9, 8],\n      [11, 6, 9],\n      [1, 6, 2],\n      [2, 7"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([[1, 1, 1], [1, -1, -1], [-1, 1, -1], [-1, -1, 1]])\n    base_faces = np.array([[0, 1, 2], [0, 1, 3], [0, 2, 3], [1, 2, 3]])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array(\n      [\n        [0, 1, phi],\n        [0, -1, phi],\n        [0, 1, -phi],\n        [0, -1, -phi],\n        [1, phi, 0],\n        [-1, phi, 0],\n        [1, -phi, 0],\n        [-1, -phi, 0],\n        [phi, 0, 1],\n        [-phi, 0, 1],\n        [phi, 0, -1],\n        [-phi, 0, -1],\n      ]\n    )\n    base_faces = np.array(\n      [\n        [0, 1, 2],\n        [0, 2, 3],\n        [0, 3, 4],\n        [0, 4, 5],\n        [0, 5, 1],\n        [1, 6, 2],\n        [2, 7, 3],\n        [3, 8, 4],\n        [4, 9, 5],\n        [5, 10, 6],\n        [6, 10, 7],\n        [7, 10, 8],\n        [8, 10, 9],\n        [9, 10, 1],\n        [1, 6, 7],\n        [1, 7, 2],\n        [2, 8, 9],\n        [2, 9, 3],\n        [3, 10, 4],"}
{"namespace": "geopoly.generate_basis", "completion": "  # Generate the base polyhedron\n  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n      [\n        [1, 1, 1],\n        [-1, -1, 1],\n        [1, -1, -1],\n        [-1, 1, -1]\n      ]\n    )\n    base_faces = np.array(\n      [\n        [0, 1, 2],\n        [0, 2, 3],\n        [0, 3, 1],\n        [1, 2, 3]\n      ]\n    )\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array(\n      [\n        [0, 1, phi],\n        [0, 1, -phi],\n        [0, -1, phi],\n        [0, -1, -phi],\n        [1, phi, 0],\n        [1, -phi, 0],\n        [-1, phi, 0],\n        [-1, -phi, 0],\n        [phi, 0, 1],\n        [phi, 0, -1],\n        [-phi, 0, 1],\n        [-phi, 0, -1]\n      ]\n    )\n    base_faces = np.array(\n      [\n        [0, 2, 1],\n        [0, 3, 2],\n        [0, 4, 3],\n        [0, 5, 4],\n        [0, 1, 5],\n        [5, 9, 4],\n        [4, 8, 3],\n        [3, 7, 2],\n        [2, 6, 1],\n        [1, 6, 8],\n        [1, 8, 9],\n        [1, 9, 5],\n        [5, 6, 8],\n        [6, 7, 9],"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n      [1, 1, 1],\n      [-1, -1, 1],\n      [1, -1, -1],\n      [-1, 1, -1]\n    ])\n    base_faces = np.array([\n      [0, 1, 2],\n      [0, 2, 3],\n      [0, 3, 1],\n      [1, 2, 3]\n    ])\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n      [-1, phi, 0],\n      [1, phi, 0],\n      [-1, -phi, 0],\n      [1, -phi, 0],\n      [0, -1, phi],\n      [0, 1, phi],\n      [0, -1, -phi],\n      [0, 1, -phi],\n      [phi, 0, -1],\n      [phi, 0, 1],\n      [-phi, 0, -1],\n      [-phi, 0, 1]\n    ])\n    base_faces = np.array([\n      [0, 1, 2],\n      [0, 2, 3],\n      [0, 3, 4],\n      [0, 4, 5],\n      [0, 5, 1],\n      [1, 6, 2],\n      [2, 7, 3],\n      [3, 8, 4],\n      [4, 9, 5],\n      [5, 10, 1],\n      [1, 10, 6],\n      [6, 7, 11],\n      [7, 8, 11],\n      [8, 9, 11],\n      [9, 10, 11],\n      [10, 6, 11]"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([[1, 1, 1], [-1, -1, 1], [1, -1, -1], [-1, 1, -1]])\n    base_faces = np.array([[0, 1, 2], [0, 2, 3], [0, 3, 1], [1, 3, 2]])\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n      [-1, phi, 0],\n      [1, phi, 0],\n      [-1, -phi, 0],\n      [1, -phi, 0],\n      [0, -1, phi],\n      [0, 1, phi],\n      [0, -1, -phi],\n      [0, 1, -phi],\n      [phi, 0, -1],\n      [phi, 0, 1],\n      [-phi, 0, -1],\n      [-phi, 0, 1],\n    ])\n    base_faces = np.array([\n      [0, 2, 1],\n      [0, 3, 2],\n      [0, 4, 3],\n      [0, 5, 4],\n      [0, 1, 5],\n      [2, 7, 6],\n      [2, 3, 7],\n      [2, 4, 8],\n      [2, 8, 9],\n      [2, 9, 10],\n      [2, 10, 6],\n      [3, 5, 6],\n      [3, 6, 7],\n      [3, 7, 8],\n      [3, 8, 9],\n      [3, 9, 10],\n      [3, 10, 5],\n      [4, 10, 6],\n      [4"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n      [\n        [1, 1, 1],\n        [-1, -1, 1],\n        [1, -1, -1],\n        [-1, 1, -1]\n      ], dtype=np.float32\n    )\n    base_faces = np.array(\n      [\n        [0, 1, 2],\n        [0, 2, 3],\n        [0, 3, 1],\n        [1, 2, 3]\n      ], dtype=np.int32\n    )\n  elif base_shape == 'icosahedron':\n    base_verts = np.array(\n      [\n        [0, 1, phi],\n        [0, -1, phi],\n        [0, 1, -phi],\n        [0, -1, -phi],\n        [1, phi, 0],\n        [-1, phi, 0],\n        [1, -phi, 0],\n        [-1, -phi, 0],\n        [phi, 0, 1],\n        [-phi, 0, 1],\n        [phi, 0, -1],\n        [-phi, 0, -1]\n      ], dtype=np.float32\n    )\n    base_faces = np.array(\n      [\n        [0, 2, 1],\n        [0, 3, 2],\n        [0, 4, 3],\n        [0, 5, 4],\n        [0, 1, 5],\n        [11, 7, 6],\n        [11, 8, 7],\n        [11, 9, 8],\n        [11, 6, 9],\n        [1, 7, 6],\n        [1, 8, 7],\n        [1, 9, 8],\n        [1, 6, 9],\n        [2, 7, 8],\n       "}
{"namespace": "geopoly.generate_basis", "completion": "  if angular_tesselation < 1:\n    raise ValueError(f'angular_tesselation {angular_tesselation} must be >= 1')\n\n  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n      [[np.sqrt(8 / 9), 0, -1 / 3], [-np.sqrt(2 / 9), np.sqrt(2 / 3), -1 / 3],\n       [-np.sqrt(2 / 9), -np.sqrt(2 / 3), -1 / 3], [0, 0, 1]], dtype=np.float32)\n    base_faces = np.array([[0, 1, 2], [0, 1, 3], [0, 2, 3], [1, 2, 3]],\n                          dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array(\n      [[-1, phi, 0], [1, phi, 0], [-1, -phi, 0], [1, -phi, 0], [0, -1, phi],\n       [0, 1, phi], [0, -1, -phi], [0, 1, -phi], [phi, 0, -1], [phi, 0, 1],\n       [-phi, 0, -1], [-phi, 0, 1]], dtype=np.float32)\n    base_faces = np.array([[0, 2, 1], [0, 2, 8], [0, 1, 5], [0, 5, 4], [0, 4, 8],\n                           [8, 2, 5], [8, 5, 10], [8, 10, 4], [4, 5, 9],\n                           [4, 9, 10], [4, 10, 2], [2, 1"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([[1, 1, 1], [-1, -1, 1], [1, -1, -1], [-1, 1, -1]])\n    base_faces = np.array([[0, 1, 2], [0, 2, 3], [0, 3, 1], [1, 3, 2]])\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array(\n      [[0, 1, phi], [0, 1, -phi], [0, -1, phi], [0, -1, -phi], [1, phi, 0],\n       [1, -phi, 0], [-1, phi, 0], [-1, -phi, 0], [phi, 0, 1], [phi, 0, -1],\n       [-phi, 0, 1], [-phi, 0, -1]])\n    base_faces = np.array(\n      [[0, 2, 1], [0, 9, 2], [0, 5, 9], [0, 4, 5], [0, 8, 4], [0, 1, 8], [1, 2, 8],\n       [1, 7, 2], [1, 6, 7], [1, 10, 6], [2, 7, 6], [2, 9, 7], [2, 3, 9], [2, 4, 3],\n       [3, 5, 4], [3, 8, 5], [3, 10, 8], [4, 8, 10], [4, 6, 8], [4, 9, 6], [5, 6, 9],\n       [5, 7, 6], [6, 7, 10], [7, 10, 8"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [-1, -1, 1],\n        [1, -1, -1],\n        [-1, 1, -1],\n    ]) / np.sqrt(2)\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 2, 3],\n        [0, 1, 3],\n        [1, 2, 3],\n    ])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array([\n        [0, 1, phi],\n        [0, -1, phi],\n        [0, 1, -phi],\n        [0, -1, -phi],\n        [1, phi, 0],\n        [-1, phi, 0],\n        [1, -phi, 0],\n        [-1, -phi, 0],\n        [phi, 0, 1],\n        [phi, 0, -1],\n        [-phi, 0, 1],\n        [-phi, 0, -1],\n    ])\n    base_verts /= np.sqrt((base_verts**2).sum(1, keepdims=True))\n    base_faces = np.array([\n        [0, 2, 1],\n        [0, 3, 2],\n        [0, 4, 3],\n        [0, 5, 4],\n        [0, 1, 5],\n        [1, 7, 6],\n        [1, 2, 7],\n        [2, 8, 7],\n        [2, 3, 8],\n        [3, 9, 8],\n        [3, 4, 9],\n        [4, 10, 9],\n        [4, 5, 10],\n        [5, 6, 10],\n        [5, 1, "}
{"namespace": "geopoly.generate_basis", "completion": "  # Generate the base polyhedron.\n  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n      [\n        [1, 1, 1],\n        [-1, -1, 1],\n        [1, -1, -1],\n        [-1, 1, -1],\n      ]\n    )\n    base_faces = np.array(\n      [\n        [0, 1, 2],\n        [0, 2, 3],\n        [0, 1, 3],\n        [1, 2, 3],\n      ]\n    )\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array(\n      [\n        [-1, phi, 0],\n        [1, phi, 0],\n        [-1, -phi, 0],\n        [1, -phi, 0],\n        [0, -1, phi],\n        [0, 1, phi],\n        [0, -1, -phi],\n        [0, 1, -phi],\n        [phi, 0, -1],\n        [phi, 0, 1],\n        [-phi, 0, -1],\n        [-phi, 0, 1],\n      ]\n    )\n    base_faces = np.array(\n      [\n        [0, 2, 1],\n        [0, 2, 8],\n        [0, 1, 5],\n        [0, 5, 4],\n        [0, 1, 6],\n        [0, 6, 8],\n        [2, 4, 3],\n        [2, 3, 9],\n        [2, 3, 7],\n        [2, 7, 8],\n        [1, 6, 5],\n        [5, 10, 6],\n        [6, 10, 7],\n        [7, 10"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([[1, 1, 1], [-1, -1, 1], [1, -1, -1], [-1, 1, -1]])\n    base_faces = np.array([[0, 1, 2], [0, 2, 3], [0, 3, 1], [3, 2, 1]])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array(\n      [\n        [0, 1, np.sqrt(2.0 / 3.0)],\n        [0, -1, np.sqrt(2.0 / 3.0)],\n        [1, 0, np.sqrt(2.0 / 3.0)],\n        [-1, 0, np.sqrt(2.0 / 3.0)],\n        [np.sqrt(2.0 / 3.0), 0, 1],\n        [np.sqrt(2.0 / 3.0), 0, -1],\n      ]\n    )\n    base_faces = np.array(\n      [\n        [0, 1, 2],\n        [0, 2, 3],\n        [0, 3, 4],\n        [0, 4, 1],\n        [1, 2, 5],\n        [2, 3, 5],\n        [3, 4, 5],\n        [4, 1, 5],\n      ]\n    )\n  elif base_shape == 'octahedron':\n    base_verts = np.array([[1, 0, 0], [-1, 0, 0], [0, 1, 0], [0, -1, 0], [0, 0, 1], [0, 0, -1]])\n    base_faces = np.array(\n      [\n        [0, 2, 4],\n        [0, 4, 3],\n        [0, 3,"}
{"namespace": "geopoly.generate_basis", "completion": "  # Generate the base polyhedron.\n  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n      [[1, 1, 1], [-1, -1, 1], [1, -1, -1], [-1, 1, -1]]\n    ) / np.sqrt(2)\n    base_faces = np.array([[0, 1, 2], [0, 1, 3], [0, 2, 3], [1, 2, 3]])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array(\n      [\n        [0, 1, phi],\n        [0, -1, phi],\n        [0, 1, -phi],\n        [0, -1, -phi],\n        [1, phi, 0],\n        [-1, phi, 0],\n        [1, -phi, 0],\n        [-1, -phi, 0],\n        [phi, 0, 1],\n        [phi, 0, -1],\n        [-phi, 0, 1],\n        [-phi, 0, -1],\n      ]\n    )\n    base_faces = np.array(\n      [\n        [0, 2, 1],\n        [0, 2, 8],\n        [0, 1, 5],\n        [0, 5, 4],\n        [0, 4, 8],\n        [2, 1, 7],\n        [2, 3, 7],\n        [2, 7, 8],\n        [1, 3, 6],\n        [1, 6, 4],\n        [3, 6, 7],\n        [3, 5, 9],\n        [3, 9, 7],\n        [4, 8, 10],\n        [4, 5, 9],\n        [5, 9, 11],\n        [5, 6, 11],\n       "}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([[1, 1, 1], [-1, -1, 1], [1, -1, -1], [-1, 1, -1]])\n    base_faces = np.array([[0, 1, 2], [0, 2, 3], [0, 3, 1], [3, 2, 1]])\n  elif base_shape == 'icosahedron':\n    sqrt_phi = np.sqrt(1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n      [-1, sqrt_phi, 0],\n      [1, sqrt_phi, 0],\n      [-1, -sqrt_phi, 0],\n      [1, -sqrt_phi, 0],\n      [0, -1, sqrt_phi],\n      [0, 1, sqrt_phi],\n      [0, -1, -sqrt_phi],\n      [0, 1, -sqrt_phi],\n      [sqrt_phi, 0, -1],\n      [sqrt_phi, 0, 1],\n      [-sqrt_phi, 0, -1],\n      [-sqrt_phi, 0, 1],\n    ])\n    base_faces = np.array([\n      [0, 2, 1],\n      [0, 3, 2],\n      [0, 4, 3],\n      [0, 5, 4],\n      [0, 1, 5],\n      [5, 9, 4],\n      [4, 8, 7],\n      [7, 10, 8],\n      [8, 11, 10],\n      [11, 9, 10],\n      [9, 5, 11],\n      [2, 1, 7],\n      [1, 2, 6],\n      [2, 3, 8],\n      [3, 2, 6],\n      [3, 4"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([[1, 1, 1], [-1, -1, 1], [1, -1, -1], [-1, 1, -1]])\n    base_faces = np.array([[0, 1, 2], [0, 1, 3], [0, 2, 3], [1, 2, 3]])\n  elif base_shape == 'icosahedron':\n    sqrt_phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n      [-1, sqrt_phi, 0], [1, sqrt_phi, 0], [-1, -sqrt_phi, 0], [1, -sqrt_phi, 0],\n      [0, -1, sqrt_phi], [0, 1, sqrt_phi], [0, -1, -sqrt_phi], [0, 1, -sqrt_phi],\n      [sqrt_phi, 0, -1], [sqrt_phi, 0, 1], [-sqrt_phi, 0, -1], [-sqrt_phi, 0, 1]\n    ])\n    base_faces = np.array([\n      [0, 2, 1], [0, 2, 8], [0, 1, 4], [0, 1, 5], [1, 2, 5], [1, 2, 6], [2, 8, 5],\n      [2, 8, 7], [0, 8, 4], [0, 8, 7], [0, 4, 3], [0, 4, 7], [1, 5, 3], [1, 5, 6],\n      [2, 6, 3], [2, 6, 7], [8, 5, 3], [8, 5, 6], [8, 7, 3], [8, 7, 6]\n    ])\n  elif base_shape == 'octah"}
{"namespace": "geopoly.generate_basis", "completion": "  # Check input parameters.\n  if not isinstance(base_shape, str):\n    raise TypeError(f'base_shape {base_shape} must be a string')\n  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(f'base_shape {base_shape} must be one of \"tetrahedron\", \"icosahedron\", or \"octahedron\"')\n  if not isinstance(angular_tesselation, int):\n    raise TypeError(f'angular_tesselation {angular_tesselation} must be an int')\n  if angular_tesselation < 1:\n    raise ValueError(f'angular_tesselation {angular_tesselation} must be >= 1')\n  if not isinstance(remove_symmetries, bool):\n    raise TypeError(f'remove_symmetries {remove_symmetries} must be a bool')\n  if not isinstance(eps, float):\n    raise TypeError(f'eps {eps} must be a float')\n  if eps < 0:\n    raise ValueError(f'eps {eps} must be >= 0')\n\n  # Define the vertices of the base polyhedron.\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n      [1, 1, 1],\n      [-1, -1, 1],\n      [1, -1, -1],\n      [-1, 1, -1],\n    ])\n    base_faces = np.array([\n      [0, 1, 2],\n      [0, 1, 3],\n      [0, 2, 3],\n      [1, 2, 3],\n    ])\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n      [-1, phi, 0],\n      [1, phi, 0],\n      [-1, -phi, 0],\n      [1, -"}
{"namespace": "geopoly.generate_basis", "completion": "  if angular_tesselation < 1:\n    raise ValueError(\n      f'angular_tesselation {angular_tesselation} must be >= 1')\n  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(\n      f'base_shape {base_shape} must be either tetrahedron, icosahedron, or octahedron')\n\n  # Define the vertices of the base polyhedron.\n  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n      [[1, 1, 1], [-1, -1, 1], [1, -1, -1], [-1, 1, -1]])\n    base_faces = np.array([[0, 1, 2], [0, 1, 3], [0, 2, 3], [1, 2, 3]])\n  elif base_shape == 'icosahedron':\n    t = (1.0 + 5.0 ** 0.5) / 2.0\n    base_verts = np.array(\n      [[-1, t, 0], [1, t, 0], [-1, -t, 0], [1, -t, 0], [0, -1, t], [0, 1, t],\n       [0, -1, -t], [0, 1, -t], [t, 0, -1], [t, 0, 1], [-t, 0, -1], [-t, 0, 1]])\n    base_faces = np.array(\n      [[0, 2, 1], [0, 9, 2], [0, 5, 9], [0, 4, 5], [0, 8, 4], [0, 1, 8], [1, 7,\n                                                                          2],\n       [1, 6, 7], [1, 10, 6], [2, 10, 7], [2, "}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n      [[np.sqrt(8 / 9), 0, -1 / 3], [-np.sqrt(2 / 9), np.sqrt(2 / 3), -1 / 3],\n       [-np.sqrt(2 / 9), -np.sqrt(2 / 3), -1 / 3], [0, 0, 1]])\n    base_faces = np.array([[0, 1, 2], [0, 1, 3], [0, 2, 3], [1, 2, 3]])\n  elif base_shape == 'icosahedron':\n    sqrt_phi = np.sqrt((1 + np.sqrt(5)) / 2)\n    base_verts = np.array(\n      [[0, -1, sqrt_phi], [0, 1, sqrt_phi], [0, -1, -sqrt_phi], [0, 1, -sqrt_phi],\n       [1, 0, sqrt_phi], [1, 0, -sqrt_phi], [-1, 0, sqrt_phi], [-1, 0, -sqrt_phi],\n       [0, sqrt_phi, 1], [0, -sqrt_phi, 1], [0, sqrt_phi, -1], [0, -sqrt_phi, -1],\n       [sqrt_phi, 1, 0], [-sqrt_phi, 1, 0], [sqrt_phi, -1, 0], [-sqrt_phi, -1, 0]])\n    base_faces = np.array([[1, 0, 2], [5, 0, 10], [2, 0, 9], [6, 0, 5], [9, 0, 6],\n                           [11, 1, 2], [10, 1, 11], [7, 1, 10], [10, 2, 11],\n                           [8, 2, 11], ["}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / jnp.maximum(tiny_val, jnp.clip(x, -1, max_val)),\n      (-1, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / jnp.maximum(tiny_val, 1 + x),\n      (-1 + max_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / jnp.maximum(tiny_val, x),\n      (0, max_val - 1),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / jnp.maximum(tiny_val, jnp.clip(x, -1, max_val)),\n      (-1, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / jnp.maximum(tiny_val, jnp.clip(x, -1, max_val)),\n      (-1, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / jnp.maximum(tiny_val, x + 1),\n      (tiny_val - 1, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / jnp.maximum(tiny_val, jnp.clip(x, 0, max_val)),\n      (tiny_val - 1, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / jnp.maximum(tiny_val, jnp.where(x < 1, x + 1, 1)),\n      (tiny_val - 1, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / jnp.maximum(tiny_val, jnp.clip(1 + x, 0, max_val)),\n      (-1, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / jnp.maximum(tiny_val, x + 1),\n      (-1 + max_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / jnp.maximum(tiny_val, jnp.clip(x, -1, 1)),\n      (-1, 1),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / jnp.maximum(tiny_val, 1 + x),\n      (min_val - 1, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / jnp.maximum(tiny_val, x + 1),\n      (0, max_val - 1),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / jnp.maximum(tiny_val, x),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / jnp.maximum(tiny_val, x + 1),\n      (0, max_val - 1),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / jnp.maximum(tiny_val, x + 1),\n      (tiny_val - 1, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / jnp.maximum(tiny_val, jnp.clip(x, 0, max_val)),\n      (tiny_val - 1, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / jnp.maximum(tiny_val, x + 1),\n      (tiny_val - 1, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (jnp.maximum(tiny_val, x) + 1),\n      (-1 + max_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / jnp.maximum(tiny_val, jnp.clip(x, -1, max_val)),\n      (-1, max_val),\n  )(x)\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n\n  if p == 1:\n    y = x\n  elif p == 0:\n    y = safe_log(x)\n  elif p == -jnp.inf:\n    y = safe_log(safe_div(1, x))\n  elif p == jnp.inf:\n    y = safe_div(1, x)\n  else:\n    y = x**p\n\n  if postmult is not None:\n    y = y * postmult\n\n  return y\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = premult * x\n\n  if p == 0:\n    y = x\n  elif p == 1:\n    y = jnp.log(x)\n  elif p == -jnp.inf:\n    y = jnp.log(1 / x)\n  elif p == jnp.inf:\n    y = jnp.log(x)\n  else:\n    y = x ** p\n\n  if postmult is not None:\n    y = y * postmult\n\n  return y\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is None:\n    premult = 1\n\n  if postmult is None:\n    postmult = 1\n\n  return postmult * power_ladder_helper(premult * x)\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x *= premult\n\n  if p == 1:\n    y = jnp.log1p(x)\n  elif p == 0:\n    y = jnp.exp(x)\n  elif p == -jnp.inf:\n    y = safe_div(1, x)\n  elif p == jnp.inf:\n    y = x\n  else:\n    y = jnp.power(x, p)\n\n  if postmult is not None:\n    y *= postmult\n\n  return y\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = premult * x\n\n  if p == 1:\n    x = x\n  elif p == 0:\n    x = jnp.log(x)\n  elif p == -jnp.inf:\n    x = x**p\n  elif p == jnp.inf:\n    x = safe_log(x)\n  else:\n    x = x**p\n\n  if postmult is not None:\n    x = x * postmult\n\n  return x\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is None:\n    premult = 1.0\n  if postmult is None:\n    postmult = 1.0\n  return postmult * jnp.power(premult * x, p)\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n\n  x_out = select(\n      [\n          (p == 1, jnp.log(x)),\n          (p == 0, jnp.log1p(x)),\n          (p == -jnp.inf, jnp.expm1(x)),\n          (p == jnp.inf, jnp.exp(x)),\n          (p < 0, x**p),\n          (p > 0, x**(1 / p)),\n      ],\n      safe_div(x**p - 1, p - 1),\n  )\n\n  if postmult is not None:\n    x_out = x_out * postmult\n\n  return x_out\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is None:\n    premult = 1\n\n  if postmult is None:\n    postmult = 1\n\n  return postmult * power_ladder_core(premult * x, p) / premult\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n\n  # Handle special cases for p.\n  y = select(\n      [\n          (p == 1, jnp.log(x)),\n          (p == 0, jnp.log1p(x)),\n          (p == -jnp.inf, jnp.exp(x)),\n          (p == jnp.inf, x),\n      ],\n      (x**p - 1) / p,\n  )\n\n  if postmult is not None:\n    y = y * postmult\n\n  return y\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is None:\n    premult = 1\n  if postmult is None:\n    postmult = 1\n\n  # Handle special cases for p.\n  if p == 1:\n    return postmult * premult * x\n  if p == 0:\n    return postmult * premult * jnp.log(x)\n  if p == -jnp.inf:\n    return postmult * premult * jnp.log(x + 1)\n  if p == jnp.inf:\n    return postmult * premult * (x + 1)\n\n  # Handle the general case for p.\n  return postmult * premult * jnp.sign(x) * jnp.power(jnp.abs(x), p)\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = premult * x\n\n  if p == 0:\n    x = safe_log(x)\n  elif p == 1:\n    x = safe_sqrt(x)\n  elif p == -1:\n    x = safe_expm1(x)\n  elif p == jnp.inf:\n    x = x ** 2\n  elif p == -jnp.inf:\n    x = safe_div(1, x)\n  else:\n    x = safe_sign(x) * jnp.abs(x) ** p\n\n  if postmult is not None:\n    x = x * postmult\n\n  return x\n\n"}
{"namespace": "math.power_ladder", "completion": "  # Handle the special cases for p.\n  if p == -jnp.inf:\n    return postmult * safe_div(1, x) if postmult is not None else safe_div(1, x)\n  elif p == 0:\n    return postmult * safe_log(x) if postmult is not None else safe_log(x)\n  elif p == 1:\n    return postmult * x if postmult is not None else x\n  elif p == jnp.inf:\n    return postmult * x ** 2 if postmult is not None else x ** 2\n\n  # Handle the general case for p.\n  else:\n    return (\n        postmult\n        * (\n            x ** p\n            if premult is None\n            else (x ** p) * (premult ** (1 - p))\n        )\n        if postmult is not None\n        else (\n            x ** p\n            if premult is None\n            else (x ** p) * (premult ** (1 - p))\n        )\n    )\n\n"}
{"namespace": "math.power_ladder", "completion": "  # Apply pre-multiplication if specified.\n  if premult is not None:\n    x = premult * x\n  # Handle special cases for p.\n  if p == -jnp.inf:\n    return jnp.log(x)\n  elif p == 0:\n    return jnp.log1p(x)\n  elif p == 1:\n    return jnp.expm1(x)\n  elif p == jnp.inf:\n    return jnp.exp(x)\n  # Handle the general case for p.\n  else:\n    return jnp.sign(x) * jnp.power(jnp.abs(x), p)\n\n"}
{"namespace": "math.power_ladder", "completion": "  # Handle special cases for the power parameter p.\n  p = jnp.where(\n      jnp.logical_and(jnp.abs(p) < tiny_val, jnp.abs(p) > -tiny_val),\n      jnp.sign(p) * tiny_val, p)\n  p = jnp.where(\n      jnp.logical_and(jnp.abs(p) > 1 - tiny_val, jnp.abs(p) < 1 + tiny_val),\n      1 - tiny_val * jnp.sign(p), p)\n\n  # Apply the power ladder transformation.\n  x = jnp.power(x, p)\n\n  # Apply pre-multiplication and post-multiplication factors.\n  if premult is not None:\n    x = premult * x\n  if postmult is not None:\n    x = x * postmult\n\n  return x\n\n"}
{"namespace": "math.power_ladder", "completion": "  # If premult is not None, apply it to x.\n  if premult is not None:\n    x = x * premult\n\n  # If p is 0, return x.\n  if p == 0:\n    return x\n\n  # If p is 1, return log(x).\n  if p == 1:\n    return safe_log(x)\n\n  # If p is -inf, return log(1/x).\n  if p == -jnp.inf:\n    return safe_log(1 / x)\n\n  # If p is inf, return 1/x.\n  if p == jnp.inf:\n    return 1 / x\n\n  # If p is finite, return the power ladder transformation.\n  return safe_div(x, jnp.power(x, p) + 1)\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = premult * x\n\n  # Handle special cases for p.\n  p_is_1 = p == 1\n  p_is_0 = p == 0\n  p_is_neg_inf = p == -jnp.inf\n  p_is_pos_inf = p == jnp.inf\n  p_is_pos = p >= 0\n  p_is_neg = p < 0\n\n  # Calculate the transformed data.\n  x_abs = jnp.abs(x)\n  x_abs_is_0 = x_abs == 0\n  x_abs_is_pos = x_abs > 0\n  x_abs_is_neg = x_abs < 0\n\n  x_abs_pow_p = jnp.power(x_abs, p)\n  x_abs_pow_p_is_0 = x_abs_pow_p == 0\n  x_abs_pow_p_is_pos = x_abs_pow_p > 0\n  x_abs_pow_p_is_neg = x_abs_pow_p < 0\n\n  x_abs_pow_p_plus_1 = x_abs_pow_p + 1\n  x_abs_pow_p_plus_1_is_0 = x_abs_pow_p_plus_1 == 0\n  x_abs_pow_p_plus_1_is_pos = x_abs_pow_p_plus_1 > 0\n  x_abs_pow_p_plus_1_is_neg = x_abs_pow_p_plus_1 < 0\n\n  x_abs_pow_p_plus_1_sqrt = jnp.sqrt(x_abs_pow_p_plus_1)\n  x_abs_pow_p_plus_1_sqrt_is_0 = x_abs_pow_p_plus_1_sqrt == 0\n  x_abs_pow_p_plus_1_sqrt_is_pos = x_abs_pow_p_plus_1_sqrt > 0"}
{"namespace": "math.power_ladder", "completion": "  # Handle special cases for p.\n  if p == 1:\n    return x\n  elif p == 0:\n    return jnp.log(x)\n  elif p == -jnp.inf:\n    return jnp.log(x) / jnp.log(2)\n  elif p == jnp.inf:\n    return 2**x\n\n  # Apply pre-multiplication.\n  if premult is not None:\n    x = x * premult\n\n  # Apply power ladder transformation.\n  x = jnp.where(x < 1, safe_div(x, 2), safe_pow(2, x - 1))\n\n  # Apply post-multiplication.\n  if postmult is not None:\n    x = x * postmult\n\n  return x\n\n"}
{"namespace": "math.power_ladder", "completion": "  # Handle special cases for p.\n  if p == -jnp.inf:\n    return safe_div(1, x)\n  elif p == 0:\n    return safe_log(x)\n  elif p == 1:\n    return x\n  elif p == jnp.inf:\n    return safe_div(1, safe_log(x))\n\n  # Handle the general case.\n  return postmult * jnp.sign(x) * jnp.power(\n      jnp.abs(x),\n      jnp.where(\n          jnp.abs(p) < tiny_val,\n          p + tiny_val,\n          jnp.where(\n              jnp.abs(p) > max_val - tiny_val,\n              p - max_val + tiny_val,\n              p,\n          ),\n      ),\n  ) * premult\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is None:\n    premult = 1\n  if postmult is None:\n    postmult = 1\n  return postmult * power_ladder_core(premult * x, p)\n\n"}
{"namespace": "math.power_ladder", "completion": "  # Set the pre-multiplication factor.\n  premult = jnp.ones_like(x) if premult is None else premult\n  # Set the post-multiplication factor.\n  postmult = jnp.ones_like(x) if postmult is None else postmult\n  # Compute the transformed data.\n  return postmult * jnp.power(\n      jnp.abs(premult * x),\n      p,\n      where=(jnp.abs(premult * x) > 0) & (p != 1),\n      # Special cases for p=1, 0, -inf, and inf.\n      # See https://en.wikipedia.org/wiki/Generalized_logarithm for details.\n      # Note that the wikipedia page defines the transformation for positive values of x,\n      # but we are also applying the transformation to negative values of x.\n      # The transformation for negative values of x is the same as for positive values,\n      # except that the sign of x is flipped.\n      # For example, the transformation for x=1 and p=0 is defined as 1.\n      # This is equivalent to applying the transformation to -1 and then taking the negative.\n      # Thus, we can use the same transformation for both positive and negative values of x.\n      out=jnp.where(\n          jnp.abs(premult * x) > 0,\n          jnp.where(\n              p == 1,\n              jnp.log(jnp.abs(premult * x)),\n              jnp.where(\n                  p == 0,\n                  jnp.sign(premult * x) * jnp.log(jnp.abs(premult * x)),\n                  jnp.where(\n                      p == -jnp.inf,\n                      jnp.sign(premult * x) * jnp.power(jnp.abs(premult * x), p),\n                      jnp.where(\n                          p == jnp.inf,\n                          jnp.sign(premult * x) * jnp.power(jnp.abs(premult * x), p),\n                          j"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y / premult\n  p_safe = clip_finite_nograd(remove_zero(p))\n  y = select(\n      [\n          (p == 1, y),\n          (p == 0, safe_expm1(y)),\n          (p == -jnp.inf, -safe_log1p(-y)),\n          (p == jnp.inf, safe_log1p(y)),\n      ],\n      (y / jnp.abs(p_safe - 1)) ** (1 / p_safe) - 1,\n  )\n  if postmult is not None:\n    y = y * postmult\n  return y\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y / premult\n  p_safe = clip_finite_nograd(remove_zero(p))\n  y = select(\n      [\n          (p == 1, y),\n          (p == 0, safe_expm1(y)),\n          (p == -jnp.inf, -safe_log1p(-y)),\n          (p == jnp.inf, safe_log1p(y)),\n      ],\n      (y / jnp.abs(p_safe - 1)) ** (1 / p_safe) - 1,\n  )\n  if postmult is not None:\n    y = y * postmult\n  return y\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y / premult\n  ys = jnp.abs(y)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = select(\n      [\n          (p == 1, ys),\n          (p == 0, safe_expm1(ys)),\n          (p == -jnp.inf, -safe_log1p(-ys)),\n          (p == jnp.inf, safe_log1p(ys)),\n      ],\n      safe_div(ys, jnp.abs(p_safe - 1)) * (jnp.power(ys, 1 / p_safe) - 1),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y / premult\n  ys = jnp.abs(y)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = select(\n      [\n          (p == 1, ys),\n          (p == 0, safe_expm1(ys)),\n          (p == -jnp.inf, -safe_log1p(-ys)),\n          (p == jnp.inf, -safe_log1p(ys)),\n      ],\n      clip_finite_nograd(\n          (ys / jnp.abs(p_safe - 1)) * ((ys ** p_safe + 1) ** (1 / p_safe) - 1)\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(y) * |p - 1|/p * (1 - (1 + |p - 1|/p * y)^(1/p))\n  if postmult is not None:\n    y = y * postmult\n  ys = jnp.abs(y)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, ys),\n          (p == 0, safe_expm1(-ys)),\n          (p == -jnp.inf, -safe_log1p(ys)),\n          (p == jnp.inf, safe_log1p(ys)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * (1 - (1 + jnp.abs(p_safe - 1) / p_safe * ys) ** (1 / p_safe))\n      ),\n  )\n  if premult is not None:\n    x = x * premult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y * premult\n  ys = jnp.abs(y)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = select(\n      [\n          (p == 1, ys),\n          (p == 0, safe_log(ys)),\n          (p == -jnp.inf, -safe_expm1(-ys)),\n          (p == jnp.inf, safe_expm1(ys)),\n      ],\n      clip_finite_nograd(\n          (ys ** (1 / p_safe) - 1) / (jnp.abs(p_safe - 1) / p_safe)\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(y) * |p - 1|/p * ((|y|/|p-1| + 1)^(1/p) - 1)\n  if postmult is not None:\n    y = y * postmult\n  yp = jnp.abs(y)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((yp / jnp.abs(p_safe - 1) + 1)\n                                         ** (1 / p_safe) - 1)\n      ),\n  )\n  if premult is not None:\n    x = x * premult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y / premult\n\n  p_safe = clip_finite_nograd(remove_zero(p))\n  y = select(\n      [\n          (p == 1, y),\n          (p == 0, safe_expm1(y)),\n          (p == -jnp.inf, -safe_log1p(-y)),\n          (p == jnp.inf, safe_log1p(y)),\n      ],\n      (y / (1 - y * (p_safe - 1) / p_safe)) ** (1 / p_safe),\n  )\n\n  if postmult is not None:\n    y = y * postmult\n\n  return y\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y / premult\n  y = jnp.abs(y)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = select(\n      [\n          (p == 1, y),\n          (p == 0, safe_expm1(y)),\n          (p == -jnp.inf, -safe_log1p(-y)),\n          (p == jnp.inf, safe_log1p(y)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * (jnp.power(y, 1 / p_safe) - 1) - 1\n      ),\n  )\n  if postmult is not None:\n    x = x / postmult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(y) * |p - 1|/p * (1 - (1 - |p - 1|/p * y)^(1/p))\n  if postmult is not None:\n    y = y * postmult\n  ys = jnp.abs(y)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, ys),\n          (p == 0, safe_expm1(ys)),\n          (p == -jnp.inf, -safe_log1p(-ys)),\n          (p == jnp.inf, safe_log1p(ys)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * (1 - (1 - ys * jnp.abs(p_safe - 1) / p_safe) ** (1 / p_safe))\n      ),\n  )\n  if premult is not None:\n    x = x * premult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(y) * |p - 1|/p * (((|y|/|p-1| + 1)^(1/p) - 1) / |p - 1|)\n  if postmult is not None:\n    y = y * postmult\n  yp = jnp.abs(y)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * (((ys + 1) ** (1 / p_safe)) - 1)\n      ),\n  )\n  if premult is not None:\n    x = x * premult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y * premult\n  y_safe = clip_finite_nograd(y)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = select(\n      [\n          (p == 1, y),\n          (p == 0, safe_expm1(y)),\n          (p == -jnp.inf, -safe_log1p(-y)),\n          (p == jnp.inf, safe_log1p(y)),\n      ],\n      clip_finite_nograd(\n          (y_safe / jnp.abs(p_safe - 1)) ** (1 / p_safe) - 1\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y * premult\n  ys = jnp.abs(y)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = select(\n      [\n          (p == 1, ys),\n          (p == 0, safe_expm1(ys)),\n          (p == -jnp.inf, -safe_log1p(ys)),\n          (p == jnp.inf, safe_log1p(ys)),\n      ],\n      clip_finite_nograd(ys / jnp.abs(p_safe - 1) * ((1 + ys / p_safe) ** (1 / p_safe) - 1)),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(y) * |p - 1|/p * (1 - (|y|/|p-1|)^(1/p))\n  if postmult is not None:\n    y = y * postmult\n  yp = jnp.abs(y)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, -safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * (1 - (yp / jnp.maximum(tiny_val, jnp.abs(p - 1)))**(1 / p_safe))\n      ),\n  )\n  if premult is not None:\n    x = x * premult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y / premult\n  y_safe = clip_finite_nograd(y)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = select(\n      [\n          (p == 1, y),\n          (p == 0, safe_expm1(y)),\n          (p == -jnp.inf, -safe_log1p(-y)),\n          (p == jnp.inf, safe_log1p(y)),\n      ],\n      clip_finite_nograd(\n          jnp.sign(y_safe) * jnp.abs(p_safe - 1) / p_safe *\n          ((jnp.abs(y_safe) / jnp.abs(p_safe - 1) + 1) **\n           (1 / p_safe) - 1)\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y * premult\n  p_safe = clip_finite_nograd(remove_zero(p))\n  y = safe_sign(y) * select(\n      [\n          (p == 1, jnp.abs(y)),\n          (p == 0, safe_expm1(y)),\n          (p == -jnp.inf, -safe_log1p(-y)),\n          (p == jnp.inf, safe_log1p(y)),\n      ],\n      clip_finite_nograd(\n          (y / jnp.abs(p_safe - 1) + 1) ** (1 / p_safe) - 1\n      ),\n  )\n  if postmult is not None:\n    y = y * postmult\n  return y\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y / premult\n  ys = jnp.abs(y)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = select(\n      [\n          (p == 1, ys),\n          (p == 0, safe_expm1(ys)),\n          (p == -jnp.inf, -safe_log1p(ys)),\n          (p == jnp.inf, safe_log1p(ys)),\n      ],\n      clip_finite_nograd(\n          (1 + ys / jnp.maximum(tiny_val, jnp.abs(p_safe - 1))) **\n          (1 / p_safe) * jnp.sign(y) * jnp.abs(p_safe - 1) / p_safe\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y * premult\n  y_abs = jnp.abs(y)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = select(\n      [\n          (p == 1, y_abs),\n          (p == 0, safe_expm1(y_abs)),\n          (p == -jnp.inf, -safe_log1p(y_abs)),\n          (p == jnp.inf, safe_log1p(y_abs)),\n      ],\n      clip_finite_nograd(\n          (y_abs / jnp.abs(p_safe - 1)) * (\n              (1 + jnp.power(y_abs, p_safe)) / p_safe - 1\n          )\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y / premult\n  p_safe = clip_finite_nograd(remove_zero(p))\n  y = select(\n      [\n          (p == 1, y),\n          (p == 0, safe_expm1(y)),\n          (p == -jnp.inf, -safe_log1p(-y)),\n          (p == jnp.inf, safe_log1p(y)),\n      ],\n      (y / jnp.abs(p_safe - 1)) ** (1 / p_safe) - 1,\n  )\n  if postmult is not None:\n    y = y * postmult\n  return y\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y / premult\n  y_abs = jnp.abs(y)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = select(\n      [\n          (p == 1, y_abs),\n          (p == 0, jnp.log1p(y_abs)),\n          (p == -jnp.inf, -expm1(-y_abs)),\n          (p == jnp.inf, expm1(y_abs)),\n      ],\n      clip_finite_nograd(\n          (y_abs / (jnp.abs(p_safe - 1) * ((y_abs + 1) ** p_safe - 1)) - 1)\n          * p_safe\n          / jnp.maximum(tiny_val, jnp.abs(p - 1))\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    lr_delay_mult = clip_finite(lr_delay_mult, 0, 1)\n    lr_delay_steps = clip_finite(lr_delay_steps, 0, max_steps)\n    lr_delay_mult = clip_finite(lr_delay_mult, 0, 1)\n    lr_init *= lr_delay_mult\n    lr_delay_steps = clip_finite(lr_delay_steps, 0, max_steps)\n    lr_delay_mult = clip_finite(lr_delay_mult, 0, 1)\n    lr_init *= lr_delay_mult\n    lr_delay_steps = clip_finite(lr_delay_steps, 0, max_steps)\n    lr_delay_mult = clip_finite(lr_delay_mult, 0, 1)\n    lr_init *= lr_delay_mult\n    lr_delay_steps = clip_finite(lr_delay_steps, 0, max_steps)\n    lr_delay_mult = clip_finite(lr_delay_mult, 0, 1)\n    lr_init *= lr_delay_mult\n    lr_delay_steps = clip_finite(lr_delay_steps, 0, max_steps)\n    lr_delay_mult = clip_finite(lr_delay_mult, 0, 1)\n    lr_init *= lr_delay_mult\n    lr_delay_steps = clip_finite(lr_delay_steps, 0, max_steps)\n    lr_delay_mult = clip_finite(lr_delay_mult, 0, 1)\n    lr_init *= lr_delay_mult\n    lr_delay_steps = clip_finite(lr_delay_steps, 0, max_steps)\n    lr_delay_mult = clip_finite(lr_delay_mult, 0, 1)\n    lr_init *= lr_delay_mult\n    lr_delay"}
{"namespace": "math.learning_rate_decay", "completion": "  # Calculate the rate of change in the learning rate\n  lr_rate = (lr_init - lr_final) / max_steps\n\n  # Apply the delay if specified\n  if lr_delay_steps > 0:\n    lr_rate *= lr_delay_mult\n\n  # Calculate the current learning rate\n  lr = lr_rate * step + lr_init\n\n  # Apply the delay if specified\n  if lr_delay_steps > 0:\n    lr -= lr_rate * lr_delay_steps\n\n  # Ensure the learning rate is not negative\n  lr = jnp.maximum(lr, lr_final)\n\n  return lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if max_steps < 1:\n    raise ValueError(\"max_steps must be > 1.\")\n\n  if lr_delay_steps > max_steps:\n    raise ValueError(\"lr_delay_steps must be <= max_steps.\")\n\n  if lr_delay_steps < 0:\n    raise ValueError(\"lr_delay_steps must be >= 0.\")\n\n  if lr_delay_mult < 0:\n    raise ValueError(\"lr_delay_mult must be >= 0.\")\n\n  if lr_init < 0:\n    raise ValueError(\"lr_init must be >= 0.\")\n\n  if lr_final < 0:\n    raise ValueError(\"lr_final must be >= 0.\")\n\n  if lr_init == lr_final:\n    return lr_init\n\n  if lr_delay_steps > 0:\n    lr_delay_steps = jnp.minimum(step, lr_delay_steps)\n    lr_init = lr_init * lr_delay_mult\n\n  return jnp.where(\n      step < lr_delay_steps,\n      lr_init,\n      lr_init + (lr_final - lr_init) * (step - lr_delay_steps) / (\n          max_steps - lr_delay_steps\n      ),\n  )\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    lr_delay_mult = clip_finite(lr_delay_mult, 0, 1)\n    lr_delay_mult = jnp.where(\n        step < lr_delay_steps, lr_delay_mult, 1\n    )\n    lr_init = lr_init * lr_delay_mult\n\n  return lr_init * jnp.exp(\n      jnp.log(lr_final / lr_init) / max_steps * (step - lr_delay_steps)\n  )\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  # If a delay is applied, scale down the initial learning rate by the multiplier.\n  if lr_delay_steps > 0:\n    lr_init = lr_init * lr_delay_mult\n\n  # Calculate the rate of change of the learning rate.\n  lr_rate = (lr_final - lr_init) / max_steps\n\n  # If the step is less than the delay, scale down the learning rate by the delay multiplier.\n  if step < lr_delay_steps:\n    lr_delay_mult = lr_delay_steps - step\n    lr_init = lr_init * lr_delay_mult\n\n  # Calculate the learning rate for the current step.\n  lr = lr_init + step * lr_rate\n\n  return lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  # Determine the learning rate during the delay period.\n  lr_delay = lr_delay_mult * lr_init\n\n  # Determine the learning rate after the delay period.\n  lr_final = lr_init if lr_final is None else lr_final\n\n  # Determine the current step.\n  step = jnp.maximum(0, step - lr_delay_steps)\n\n  # Determine the learning rate.\n  lr = log_lerp(\n      step / max_steps,\n      lr_delay,\n      lr_final,\n  )\n\n  # Determine the learning rate with the delay applied.\n  lr = lr if lr_delay_steps == 0 else jnp.where(\n      step < lr_delay_steps,\n      lr_delay,\n      lr,\n  )\n\n  return lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  # Calculate the steps to delay the start of learning rate decay.\n  lr_delay_steps = min(max(lr_delay_steps, 0), max_steps)\n\n  # Calculate the steps to reach the final learning rate.\n  lr_ramp_steps = max_steps - lr_delay_steps\n\n  # Calculate the learning rate to be applied at the delay steps.\n  lr_delay_mult = min(max(lr_delay_mult, 0), 1)\n  lr_delay = lr_delay_mult * lr_init\n\n  # Calculate the learning rate to be applied after the delay steps.\n  lr_ramp_mult = 1 - lr_delay_mult\n  lr_ramp = jnp.where(lr_ramp_steps > 0, (lr_final - lr_init) / lr_ramp_steps, 0)\n\n  # Combine the delay and ramp components of the learning rate.\n  lr_delay = jnp.where(step <= lr_delay_steps, lr_delay, 0)\n  lr_ramp = jnp.where(step > lr_delay_steps, lr_ramp, 0)\n  lr_step = lr_delay + lr_ramp\n\n  # Return the learning rate for the current step.\n  return lr_step\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    lr_init = lr_delay_mult * lr_init\n    lr_delay_steps = jnp.minimum(lr_delay_steps, max_steps)\n\n  else:\n    lr_delay_steps = 0\n\n  lr_init = clip_finite(lr_init)\n  lr_final = clip_finite(lr_final)\n\n  lr_delay_steps = jnp.maximum(lr_delay_steps, 1)\n  max_steps = jnp.maximum(max_steps, lr_delay_steps + 1)\n\n  lr_init = jnp.where(step <= lr_delay_steps, lr_init, lr_final)\n  lr_final = jnp.where(step <= lr_delay_steps, lr_init, lr_final)\n  lr_delay_steps = jnp.where(step <= lr_delay_steps, step, lr_delay_steps)\n\n  lr_init = jnp.where(lr_init < 0, 0, lr_init)\n  lr_final = jnp.where(lr_final < 0, 0, lr_final)\n\n  lr_init = jnp.where(jnp.logical_and(lr_init == 0, lr_final == 0), 0, lr_init)\n  lr_final = jnp.where(jnp.logical_and(lr_init == 0, lr_final == 0), 0, lr_final)\n\n  lr_init = jnp.where(lr_init == lr_final, lr_init, lr_init)\n  lr_final = jnp.where(lr_init == lr_final, lr_init, lr_final)\n\n  lr = jnp.where(step <= lr_delay_steps, lr_init, lr_final)\n\n  lr = jnp.where(step >= max_"}
{"namespace": "math.learning_rate_decay", "completion": "  if max_steps < 1:\n    raise ValueError(f'Invalid max_steps: {max_steps}')\n\n  if lr_delay_steps > max_steps:\n    raise ValueError(f'lr_delay_steps must be less than max_steps: {lr_delay_steps} > {max_steps}')\n\n  if lr_delay_steps < 0:\n    raise ValueError(f'lr_delay_steps must be positive: {lr_delay_steps} < 0')\n\n  if lr_delay_mult < 0:\n    raise ValueError(f'lr_delay_mult must be positive: {lr_delay_mult} < 0')\n\n  if lr_delay_steps == 0:\n    return log_lerp(step / max_steps, lr_init, lr_final)\n\n  else:\n    lr_delay_mult = clip_finite_nograd(lr_delay_mult)\n    lr_delay_mult = jnp.where(lr_delay_mult == 0, tiny_val, lr_delay_mult)\n    lr_delay_mult = jnp.where(lr_delay_mult == 1, 1.0, lr_delay_mult)\n\n    lr_init = lr_init * lr_delay_mult\n    lr_final = lr_final * lr_delay_mult\n\n    return jnp.where(\n        step < lr_delay_steps,\n        lr_init * log_lerp(step / lr_delay_steps, 0, 1),\n        log_lerp(step / max_steps, lr_init, lr_final),\n    )\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  # If the delay is set, then the learning rate is scaled down by the multiplier and gradually increases back to the normal rate after the delay period.\n  if lr_delay_steps > 0:\n    lr_delay_mult = clip_finite_nograd(lr_delay_mult)\n    lr_init = lr_delay_mult * lr_init\n\n  # If the delay is set, then the learning rate is scaled down by the multiplier and gradually increases back to the normal rate after the delay period.\n  if lr_delay_steps > 0:\n    lr_delay_mult = clip_finite_nograd(lr_delay_mult)\n    lr_init = lr_delay_mult * lr_init\n\n  # The current step is clipped to the maximum number of steps.\n  step = clip_finite_nograd(step)\n\n  # The initial learning rate is returned if the delay is set and the current step is before the delay period.\n  if lr_delay_steps > 0 and step < lr_delay_steps:\n    return lr_init\n\n  # The learning rate is linearly interpolated between the initial and final learning rates based on the current step.\n  return (lr_final - lr_init) / (max_steps - lr_delay_steps) * (\n      step - lr_delay_steps\n  ) + lr_init\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    lr_init = lr_init * lr_delay_mult\n    lr_delay_steps = jnp.minimum(lr_delay_steps, max_steps)\n    delay_progress = jnp.clip(step, 0, lr_delay_steps) / lr_delay_steps\n    lr_init = lr_init * (1 - delay_progress) + lr_final * delay_progress\n  else:\n    lr_init = lr_final\n  progress = jnp.clip(step, 0, max_steps) / max_steps\n  return lr_init * (1 - progress) + lr_final * progress\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  # Calculate the delay multiplier\n  lr_delay_mult = jnp.where(step < lr_delay_steps, lr_delay_mult, 1)\n\n  # Calculate the learning rate\n  lr = log_lerp(step / max_steps, lr_init * lr_delay_mult, lr_init)\n\n  # Apply the delay\n  lr = lr * lr_delay_mult\n\n  # Apply the final learning rate\n  lr = jnp.where(step >= max_steps, lr_final, lr)\n\n  return lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    lr_delay_mult = clip_finite(lr_delay_mult, 0, 1)\n    lr_delay_steps = clip_finite(lr_delay_steps, 0, max_steps)\n    lr_delay_mult = jnp.where(\n        step < lr_delay_steps, lr_delay_mult, 1.0\n    )\n    lr_init = lr_init * lr_delay_mult\n  return jnp.where(\n      step < max_steps,\n      lr_init * (lr_final / lr_init) ** (step / (max_steps - 1)),\n      lr_final,\n  )\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  # Calculate the number of steps to reach the delay multiplier.\n  lr_delay_steps = max(0, lr_delay_steps)\n  lr_delay_mult = max(0., lr_delay_mult)\n\n  # Calculate the learning rate for the current step.\n  lr = log_lerp(\n      step / max_steps,\n      lr_init * lr_delay_mult,\n      lr_init,\n  )\n\n  # Calculate the delay multiplier for the current step.\n  lr_delay_mult = log_lerp(\n      step / max_steps,\n      lr_delay_mult,\n      1.0,\n  )\n\n  # Apply the delay multiplier to the learning rate.\n  lr *= lr_delay_mult\n\n  # Calculate the final learning rate.\n  lr = log_lerp(\n      step / max_steps,\n      lr,\n      lr_final,\n  )\n\n  return lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  # Calculate the current learning rate based on the interpolation formula\n  lr_interp = log_lerp(step / max_steps, lr_init, lr_final)\n\n  # If a delay is specified, scale the learning rate by the delay multiplier\n  if lr_delay_steps > 0:\n    delay_mult = jnp.minimum(1., step / lr_delay_steps)\n    lr_interp *= lr_delay_mult**(1 - delay_mult)\n\n  return lr_interp\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  # Calculate the learning rate for the current step.\n  step = jnp.minimum(step, max_steps)\n  lr_range = lr_init - lr_final\n  lr_delay_steps = jnp.maximum(0, lr_delay_steps)\n  lr_delay_mult = jnp.maximum(1e-10, lr_delay_mult)\n  lr_delay_mult = jnp.minimum(1, lr_delay_mult)\n  lr_delay_mult = lr_delay_mult ** jnp.maximum(0, step - lr_delay_steps)\n  lr_init = lr_init * lr_delay_mult\n  lr_range = lr_range * lr_delay_mult\n  lr_decay = 1 - step / max_steps\n  lr = lr_init + lr_range * lr_decay\n  return lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    lr_delay_mult = clip_finite(lr_delay_mult, min_val=0, max_val=1)\n    lr_delay_steps = clip_finite(lr_delay_steps, min_val=0, max_val=max_steps)\n    lr_delay_mult = jnp.where(step < lr_delay_steps, lr_delay_mult, 1)\n    lr_init *= lr_delay_mult\n  return lr_init + (lr_final - lr_init) * step / max_steps\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  # If the delay is specified, then scale the initial learning rate down and return\n  # the learning rate multiplied by the delay multiplier.\n  if lr_delay_steps > 0:\n    lr_delay_mult = clip_finite_nograd(lr_delay_mult)\n    lr_init *= lr_delay_mult\n\n  # If the delay is specified, then scale the initial learning rate down and return\n  # the learning rate multiplied by the delay multiplier.\n  if lr_delay_steps > 0:\n    lr_delay_mult = clip_finite_nograd(lr_delay_mult)\n    lr_init *= lr_delay_mult\n\n  # Calculate the learning rate for the current step, clipping the step to the\n  # maximum number of steps.\n  lr = log_lerp(clip_finite_nograd(step / max_steps), lr_init, lr_final)\n\n  # If the delay is specified, then scale the learning rate up after the delay\n  # period.\n  if lr_delay_steps > 0:\n    lr = jnp.where(step < lr_delay_steps, lr, lr / lr_delay_mult)\n\n  return clip_finite_nograd(lr)\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  # Calculate the number of steps that the learning rate will be delayed by.\n  lr_delay_steps = min(lr_delay_steps, max_steps)\n\n  # Calculate the learning rate for the current step.\n  lr = log_lerp(step / max_steps, lr_init * lr_delay_mult, lr_final)\n\n  # If a delay is applied, scale the learning rate down by a factor of lr_delay_mult.\n  if lr_delay_steps > 0:\n    lr = jnp.where(step < lr_delay_steps, lr * lr_delay_mult, lr)\n\n  return lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  # Calculate the base learning rate, with or without delay.\n  if lr_delay_steps > 0:\n    lr_delay_mult = jnp.minimum(1.0, step / lr_delay_steps)\n    lr_step = lr_delay_mult * (lr_init * lr_delay_mult - lr_final)\n  else:\n    lr_step = lr_init - lr_final\n\n  # Calculate the learning rate based on the step count.\n  return lr_final + lr_step * (1 - step / max_steps)\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      random.PRNGKey(0),\n      2,\n      -1.0,\n      1.0,\n      0.0,\n      1.0,\n      2.0,\n      3.0,\n      1.0,\n      2.0,\n      include_exposure_idx,\n      include_exposure_values,\n      include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      random.PRNGKey(0),\n      1,\n      -1.,\n      1.,\n      0.,\n      1.,\n      0.,\n      1.,\n      0.,\n      1.,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      random.PRNGKey(0),\n      n=1,\n      origin_lo=jnp.array([0.0, 0.0, 0.0]),\n      origin_hi=jnp.array([0.0, 0.0, 0.0]),\n      radius_lo=jnp.array([0.0]),\n      radius_hi=jnp.array([0.0]),\n      near_lo=jnp.array([0.0]),\n      near_hi=jnp.array([0.0]),\n      far_lo=jnp.array([0.0]),\n      far_hi=jnp.array([0.0]),\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=1,\n      origin_lo=-100,\n      origin_hi=100,\n      radius_lo=0,\n      radius_hi=1,\n      near_lo=1,\n      near_hi=10,\n      far_lo=11,\n      far_hi=20,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      random.PRNGKey(0),\n      1,\n      -100,\n      100,\n      1e-4,\n      1e4,\n      1e-4,\n      1e4,\n      1e-4,\n      1e4,\n      include_exposure_idx,\n      include_exposure_values,\n      include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  rng = random.PRNGKey(0)\n  return generate_random_rays(\n      rng,\n      n=1,\n      origin_lo=-10.0,\n      origin_hi=10.0,\n      radius_lo=0.0,\n      radius_hi=1.0,\n      near_lo=0.1,\n      near_hi=1.0,\n      far_lo=1.0,\n      far_hi=10.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  rng = random.PRNGKey(0)\n  return generate_random_rays(\n      rng,\n      n=1,\n      origin_lo=-10.0,\n      origin_hi=10.0,\n      radius_lo=0.0,\n      radius_hi=10.0,\n      near_lo=0.0,\n      near_hi=10.0,\n      far_lo=0.0,\n      far_hi=10.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  # Generate a dummy set of rays that can be used to initialize NeRF model.\n  return generate_random_rays(\n    rng=jax.random.PRNGKey(0),\n    n=1,\n    origin_lo=jnp.zeros(3),\n    origin_hi=jnp.zeros(3),\n    radius_lo=jnp.zeros(1),\n    radius_hi=jnp.zeros(1),\n    near_lo=jnp.zeros(1),\n    near_hi=jnp.zeros(1),\n    far_lo=jnp.zeros(1),\n    far_hi=jnp.zeros(1),\n    include_exposure_idx=include_exposure_idx,\n    include_exposure_values=include_exposure_values,\n    include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n    random.PRNGKey(0),\n    1,\n    -1.0,\n    1.0,\n    0.0,\n    1.0,\n    0.0,\n    1.0,\n    0.0,\n    1.0,\n    include_exposure_idx,\n    include_exposure_values,\n    include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  dummy_rays = generate_random_rays(\n      jax.random.PRNGKey(0),\n      n=1,\n      origin_lo=-1000,\n      origin_hi=1000,\n      radius_lo=0.0,\n      radius_hi=1.0,\n      near_lo=0.0,\n      near_hi=1.0,\n      far_lo=1.0,\n      far_hi=10.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n  return dummy_rays\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  rng = random.PRNGKey(0)\n  n = 1\n  dummy_rays = generate_random_rays(\n      rng,\n      n,\n      -100,\n      100,\n      0,\n      1,\n      0,\n      1,\n      0,\n      1,\n      include_exposure_idx,\n      include_exposure_values,\n      include_device_idx,\n  )\n  return dummy_rays\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n    random.PRNGKey(0),\n    1,\n    -100,\n    100,\n    1,\n    10,\n    0.1,\n    10,\n    0.1,\n    10,\n    include_exposure_idx,\n    include_exposure_values,\n    include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      random.PRNGKey(0),\n      1,\n      -1,\n      1,\n      1,\n      1,\n      2,\n      3,\n      4,\n      5,\n      include_exposure_idx,\n      include_exposure_values,\n      include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  # dummy_rays = generate_random_rays(\n  #     jnp.array([0, 0], dtype=jnp.uint32),\n  #     0,\n  #     jnp.array([0, 0, 0], dtype=jnp.float32),\n  #     jnp.array([0, 0, 0], dtype=jnp.float32),\n  #     0,\n  #     0,\n  #     0,\n  #     0,\n  #     0,\n  #     0,\n  #     include_exposure_idx,\n  #     include_exposure_values,\n  #     include_device_idx,\n  # )\n\n  dummy_rays = generate_random_rays(\n      jnp.array([0, 0], dtype=jnp.uint32),\n      0,\n      jnp.array([0, 0, 0], dtype=jnp.float32),\n      jnp.array([0, 0, 0], dtype=jnp.float32),\n      0,\n      0,\n      0,\n      0,\n      0,\n      include_exposure_idx,\n      include_exposure_values,\n      include_device_idx,\n  )\n\n  return dummy_rays\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  rng = random.PRNGKey(0)\n  n = 1\n  return generate_random_rays(\n      rng,\n      n,\n      -1.0,\n      1.0,\n      0.1,\n      1.0,\n      0.1,\n      1.0,\n      0.1,\n      1.0,\n      include_exposure_idx,\n      include_exposure_values,\n      include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      random.PRNGKey(0),\n      1,\n      -1.,\n      1.,\n      0.,\n      1.,\n      2.,\n      3.,\n      1.,\n      10.,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      jax.random.PRNGKey(0),\n      n=1,\n      origin_lo=jnp.zeros(3),\n      origin_hi=jnp.zeros(3),\n      radius_lo=jnp.zeros(1),\n      radius_hi=jnp.zeros(1),\n      near_lo=jnp.zeros(1),\n      near_hi=jnp.zeros(1),\n      far_lo=jnp.zeros(1),\n      far_hi=jnp.zeros(1),\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  dummy_rays = generate_random_rays(\n    rng=jax.random.PRNGKey(0),\n    n=1,\n    origin_lo=jnp.array([-1000.0, -1000.0, -1000.0]),\n    origin_hi=jnp.array([1000.0, 1000.0, 1000.0]),\n    radius_lo=jnp.array([0.0]),\n    radius_hi=jnp.array([1000.0]),\n    near_lo=jnp.array([0.01]),\n    near_hi=jnp.array([10.0]),\n    far_lo=jnp.array([10.0]),\n    far_hi=jnp.array([10000.0]),\n    include_exposure_idx=include_exposure_idx,\n    include_exposure_values=include_exposure_values,\n    include_device_idx=include_device_idx,\n  )\n  return dummy_rays\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      random.PRNGKey(0),\n      1,\n      -100.,\n      100.,\n      1.,\n      100.,\n      1.,\n      100.,\n      1.,\n      100.,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      random.PRNGKey(0),\n      1,\n      -1.,\n      1.,\n      0.,\n      1.,\n      0.,\n      1.,\n      0.,\n      1.,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # TODO(barron): Add unit tests for this function.\n\n  # TODO(barron): Add support for multiple camera intrinsics matrices.\n\n  # TODO(barron): Add support for multiple camera extrinsics matrices.\n\n  # TODO(barron): Add support for multiple distortion parameter sets.\n\n  # TODO(barron): Add support for multiple camera projection types.\n\n  # TODO(barron): Add support for multiple camera projection types.\n\n  # TODO(barron): Add support for multiple camera projection types.\n\n  # TODO(barron): Add support for multiple camera projection types.\n\n  # TODO(barron): Add support for multiple camera projection types.\n\n  # TODO(barron): Add support for multiple camera projection types.\n\n  # TODO(barron): Add support for multiple camera projection types.\n\n  # TODO(barron): Add support for multiple camera projection types.\n\n  # TODO(barron): Add support for multiple camera projection types.\n\n  # TODO(barron): Add support for multiple camera projection types.\n\n  # TODO(barron): Add support for multiple camera projection types.\n\n  # TODO(barron): Add support for multiple camera projection types.\n\n  # TODO(barron): Add support for multiple camera projection types.\n\n  # TODO(barron): Add support for multiple camera projection types.\n\n  # TODO(barron): Add support for multiple camera projection types.\n\n  # TODO(barron): Add support for multiple camera projection types.\n\n  # TODO(barron): Add support for multiple camera projection types.\n\n  # TODO(barron): Add support for multiple camera projection types.\n\n  # TODO(barron): Add support for multiple camera projection types.\n\n  # TODO(barron): Add support for multiple camera projection types.\n\n  # TODO(barron): Add support for multiple camera projection types.\n\n  # TODO(barron): Add support for multiple camera projection types.\n\n  # TODO(barron): Add support for multiple camera projection types.\n\n  # TODO(barron): Add support for multiple camera projection types.\n\n  # TODO(barron): Add support for multiple camera projection types."}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # TODO(barron): Add a unit test for this function.\n\n  # TODO(barron): Add support for fisheye and pano camera types.\n\n  # TODO(barron): Add support for batches of cameras.\n\n  # TODO(barron): Add support for batches of points.\n\n  # TODO(barron): Add support for batches of distortion parameters.\n\n  # TODO(barron): Add support for batches of distortion parameters.\n\n  # TODO(barron): Add support for batches of distortion parameters.\n\n  # TODO(barron): Add support for batches of distortion parameters.\n\n  # TODO(barron): Add support for batches of distortion parameters.\n\n  # TODO(barron): Add support for batches of distortion parameters.\n\n  # TODO(barron): Add support for batches of distortion parameters.\n\n  # TODO(barron): Add support for batches of distortion parameters.\n\n  # TODO(barron): Add support for batches of distortion parameters.\n\n  # TODO(barron): Add support for batches of distortion parameters.\n\n  # TODO(barron): Add support for batches of distortion parameters.\n\n  # TODO(barron): Add support for batches of distortion parameters.\n\n  # TODO(barron): Add support for batches of distortion parameters.\n\n  # TODO(barron): Add support for batches of distortion parameters.\n\n  # TODO(barron): Add support for batches of distortion parameters.\n\n  # TODO(barron): Add support for batches of distortion parameters.\n\n  # TODO(barron): Add support for batches of distortion parameters.\n\n  # TODO(barron): Add support for batches of distortion parameters.\n\n  # TODO(barron): Add support for batches of distortion parameters.\n\n  # TODO(barron): Add support for batches of distortion parameters.\n\n  # TODO(barron): Add support for batches of distortion parameters.\n\n  # TODO(bar"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # TODO(barron): Add unit tests for this function.\n\n  # TODO(barron): Add support for other projection models.\n  assert camtype == ProjectionType.PERSPECTIVE\n\n  # TODO(barron): Add support for multiple cameras.\n  assert len(pixtocams.shape) == 2\n  assert len(camtoworlds.shape) == 2\n\n  # TODO(barron): Add support for multiple points.\n  assert len(points.shape) == 2\n\n  # TODO(barron): Add support for multiple distortion parameters.\n  if distortion_params is not None:\n    assert len(distortion_params['radial']) == 4\n    assert len(distortion_params['tangential']) == 2\n\n  # TODO(barron): Add support for multiple distortion parameters.\n  if distortion_params is not None:\n    assert len(distortion_params['radial']) == 4\n    assert len(distortion_params['tangential']) == 2\n\n  # TODO(barron): Add support for multiple distortion parameters.\n  if distortion_params is not None:\n    assert len(distortion_params['radial']) == 4\n    assert len(distortion_params['tangential']) == 2\n\n  # TODO(barron): Add support for multiple distortion parameters.\n  if distortion_params is not None:\n    assert len(distortion_params['radial']) == 4\n    assert len(distortion_params['tangential']) == 2\n\n  # TODO(barron): Add support for multiple distortion parameters.\n  if distortion_params is not None:\n    assert len(distortion_params['radial']) == 4\n    assert len(distortion_params['tangential']) == 2\n\n  # TODO(barron): Add support for multiple distortion parameters.\n  if distortion_params is not None:\n    assert len(distortion_params['radial']) == 4\n    assert len(distort"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Project points to camera coordinates.\n  points_cam = mat_vec_mul(camtoworlds[Ellipsis, :3, :3], points) + camtoworlds[Ellipsis, :3, -1:]\n\n  # Project points to pixel coordinates.\n  points_pix = mat_vec_mul(pixtocams[Ellipsis, :3, :3], points_cam) + pixtocams[Ellipsis, :3, -1:]\n\n  if distortion_params is not None:\n    # Correct for radial and tangential distortion.\n    points_pix = _radial_and_tangential_undistort(\n        points_pix[Ellipsis, 0],\n        points_pix[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n\n  # Compute the depth values.\n  depth = points_cam[Ellipsis, -1]\n\n  return points_pix, depth\n\n"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Convert to homogeneous coordinates.\n  points = xnp.concatenate([points, xnp.ones_like(points[Ellipsis, :1])], axis=-1)\n\n  # Transform points from world to camera space.\n  points = mat_vec_mul(camtoworlds[Ellipsis, :3, :], points)\n\n  # Apply distortion correction.\n  if distortion_params is not None:\n    x, y, z = points[Ellipsis, 0], points[Ellipsis, 1], points[Ellipsis, 2]\n    r2 = x * x + y * y\n    r4 = r2 * r2\n    r6 = r4 * r2\n    a1 = 2 * points[Ellipsis, 0] * points[Ellipsis, 1]\n    a2 = r2 + 2 * points[Ellipsis, 2] * points[Ellipsis, 1]\n    a3 = r2 + 2 * points[Ellipsis, 0] * points[Ellipsis, 2]\n    cdist = xnp.concatenate([\n        distortion_params['k1'] * r2 + distortion_params['k2'] * r4,\n        distortion_params['k1'] * a1 + distortion_params['k2'] * a2,\n        distortion_params['p1'] * x + distortion_params['p2'] * y,\n        distortion_params['k3'] * r2 + distortion_params['k4'] * r4,\n        distortion_params['k3'] * a3 + distortion_params['k4'] * a1,\n    ], axis=-1)\n    points = xnp.stack([x, y, z], axis=-1) + cdist[Ellipsis, None] * points\n\n  # Apply inverse intrinsic matrix.\n  points = mat_vec_mul(pixtocams[Ellipsis, :3, :], points"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # TODO(barron): Add a unit test for this function.\n\n  # TODO(barron): Add support for different camera projection models.\n  if camtype != ProjectionType.PERSPECTIVE:\n    raise NotImplementedError(\n        'Only perspective projection is supported at this time.'\n    )\n\n  # TODO(barron): Add support for batching over multiple cameras.\n  if len(camtoworlds.shape) > 2:\n    raise NotImplementedError(\n        'Batching over multiple cameras is not supported at this time.'\n    )\n\n  # TODO(barron): Add support for batching over multiple points.\n  if len(points.shape) > 2:\n    raise NotImplementedError(\n        'Batching over multiple points is not supported at this time.'\n    )\n\n  # TODO(barron): Add support for batching over multiple distortion parameters.\n  if distortion_params is not None and len(distortion_params.shape) > 1:\n    raise NotImplementedError(\n        'Batching over multiple distortion parameters is not supported at this '\n        'time.'\n    )\n\n  # TODO(barron): Add support for batching over multiple intrinsic matrices.\n  if len(pixtocams.shape) > 2:\n    raise NotImplementedError(\n        'Batching over multiple intrinsic matrices is not supported at this '\n        'time.'\n    )\n\n  # TODO(barron): Add support for batching over multiple extrinsic matrices.\n  if len(camtoworlds.shape) > 2:\n    raise NotImplementedError(\n        'Batching over multiple extrinsic matrices is not supported at this '\n        'time.'\n    )\n\n  # TODO(barron): Add support for batching over multiple points and distortion\n  # parameters.\n  if distortion_params is not None and len(points.shape) > 2:\n    raise NotImplementedError(\n        'Batching over multiple points and distortion parameters is not '\n        'supported at this time.'\n    )"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Convert points from world to camera coordinates.\n  points_cam = xnp.moveaxis(mat_vec_mul(camtoworlds, xnp.moveaxis(points, -1, 0)), 0, -1)\n\n  # Convert points from camera to pixel coordinates.\n  points_pix = xnp.moveaxis(mat_vec_mul(pixtocams, xnp.moveaxis(points_cam, -1, 0)), 0, -1)[Ellipsis, :2]\n\n  # Apply distortion correction.\n  if distortion_params is not None:\n    points_pix = _radial_and_tangential_undistort(\n        points_pix[Ellipsis, 0],\n        points_pix[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n\n  # Calculate the depth values of the points in the camera coordinate system.\n  depth = points_cam[Ellipsis, 2]\n\n  return points_pix, depth\n\n"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Apply the extrinsics.\n  points = mat_vec_mul(camtoworlds[Ellipsis, :3, :3], points) + camtoworlds[Ellipsis, :3, -1]\n\n  # Apply the inverse intrinsics.\n  points = mat_vec_mul(pixtocams[Ellipsis, :3, :3], points)\n\n  # Apply the radial distortion.\n  if distortion_params is not None:\n    points = _radial_and_tangential_distort(\n        points[Ellipsis, 0], points[Ellipsis, 1], **distortion_params, xnp=xnp\n    )\n\n  # Apply the projection.\n  if camtype == ProjectionType.PERSPECTIVE:\n    points = points[Ellipsis, 0] / points[Ellipsis, 2]\n\n  else:\n    raise NotImplementedError(\n        'Only perspective projection is currently supported.'\n    )\n\n  return points\n\n"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Apply inverse camera extrinsics to get camera coordinates.\n  cam_coords = mat_vec_mul(camtoworlds[Ellipsis, :3, :3], points) + camtoworlds[Ellipsis, None, :3, 3]\n\n  # Apply inverse intrinsics to get pixel coordinates.\n  pix_coords = mat_vec_mul(pixtocams[Ellipsis, :3, :3], cam_coords) + pixtocams[Ellipsis, None, :3, 3]\n\n  # Normalize the pixel coordinates.\n  pix_coords = pix_coords / pix_coords[Ellipsis, -1:]\n\n  if distortion_params is not None:\n    # Correct for radial and tangential distortion.\n    pix_coords = _radial_and_tangential_undistort(\n        pix_coords[Ellipsis, 0],\n        pix_coords[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n\n  # Convert pixel coordinates to NDC space.\n  if camtype == ProjectionType.PERSPECTIVE:\n    pix_coords = pix_coords / pix_coords[Ellipsis, -1:]\n\n  elif camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(pix_coords[Ellipsis, :2] ** 2, axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n\n    pix_coords = xnp.stack(\n        [\n            theta * pix_coords[Ellipsis, 0] / xnp.sin(theta),\n            theta * pix_coords[Ellipsis, 1] / xnp.sin(theta),\n        ],\n        axis=-1,\n    )\n\n  elif camtype == ProjectionType.PANORAMIC:\n    pix_coords = xnp"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Transform points from world to camera space.\n  points = mat_vec_mul(camtoworlds[Ellipsis, :3, :3], points) + camtoworlds[Ellipsis, :3, 3:]\n\n  # Transform points from camera to pixel space.\n  points = mat_vec_mul(pixtocams[Ellipsis, :3, :3], points) + pixtocams[Ellipsis, :3, 3:]\n\n  # Apply distortion correction.\n  if distortion_params is not None:\n    points = _radial_and_tangential_undistort(\n        points[Ellipsis, 0],\n        points[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n\n  # Apply perspective projection.\n  if camtype == ProjectionType.PERSPECTIVE:\n    points = points[Ellipsis, 2] * points\n\n  # Normalize to [-1, 1] range.\n  points = points / xnp.clip(points[Ellipsis, 2], a_min=1e-10, a_max=None)\n\n  # Extract pixel coordinates and depth values.\n  coordinates = points[Ellipsis, :2]\n  depth = points[Ellipsis, 2]\n\n  return coordinates, depth\n\n"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Convert points to camera coordinates.\n  points_hom = xnp.concatenate([points, xnp.ones_like(points[Ellipsis, :1])], axis=-1)\n  points_cam = (\n      xnp.matmul(xnp.linalg.inv(pixtocams), points_hom.T).T[Ellipsis, :3]\n  )\n\n  # Convert camera coordinates to pixel coordinates.\n  if camtype == ProjectionType.PERSPECTIVE:\n    points_pixel = points_cam / points_cam[Ellipsis, 2:]\n\n  elif camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(points_cam[Ellipsis, :2] ** 2, axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n    points_pixel = xnp.stack(\n        [\n            theta * points_cam[Ellipsis, 0] / points_cam[Ellipsis, 2],\n            theta * points_cam[Ellipsis, 1] / points_cam[Ellipsis, 2],\n        ],\n        axis=-1,\n    )\n\n  elif camtype == ProjectionType.PANORAMIC:\n    theta = xnp.sqrt(xnp.sum(points_cam[Ellipsis, :2] ** 2, axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n    points_pixel = xnp.stack(\n        [\n            theta * points_cam[Ellipsis, 0] / points_cam[Ellipsis, 2],\n            theta * points_cam[Ellipsis, 1] / points_cam[Ellipsis, 2],\n        ],\n        axis=-1,\n    )\n\n  else:\n    raise ValueError(f'Camera type {camtype} is not supported.')\n\n  # Apply camera extrinsics to get world coordinates"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Must add half pixel offset to shoot rays through pixel centers.\n  points = points - xnp.array([0.5, 0.5, 0.0])\n\n  # Apply camera extrinsics.\n  points = mat_vec_mul(camtoworlds[Ellipsis, :3, :3], points)\n  points = points + camtoworlds[Ellipsis, :3, -1:]\n\n  # Apply camera intrinsics.\n  points = mat_vec_mul(pixtocams[Ellipsis, :3, :3], points)\n  points = points / points[Ellipsis, -1:]\n\n  # Correct for distortion.\n  if distortion_params is not None:\n    points = _radial_and_tangential_undistort(\n        points[Ellipsis, 0],\n        points[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n\n  # Convert to pixel coordinates.\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(points), axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n\n    x = -xnp.sin(theta) * xnp.sin(points[Ellipsis, 0])\n    y = -xnp.sin(theta) * xnp.cos(points[Ellipsis, 0])\n\n  elif camtype == ProjectionType.PANORAMIC:\n    x = points[Ellipsis, 0]\n    y = points[Ellipsis, 1]\n\n  else:\n    x = points[Ellipsis, 0] / points[Ellipsis, 2]\n    y = points[Ellipsis, 1] / points[Ellipsis, 2]\n\n  return x, y, -points[Ellipsis, 2]\n\n"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Convert points to camera coordinate system.\n  points_camera = xnp.matmul(camtoworlds[Ellipsis, None, :3, :3], points[Ellipsis, None])\n  points_camera += camtoworlds[Ellipsis, None, :3, 3:]\n  points_camera = points_camera[Ellipsis, 0]\n\n  # Convert points to pixel coordinates.\n  points_pixel = xnp.matmul(pixtocams[Ellipsis, None, :3, :3], points_camera[Ellipsis, None])\n  points_pixel += pixtocams[Ellipsis, None, :3, 3:]\n  points_pixel = points_pixel[Ellipsis, 0]\n\n  # Convert pixel coordinates to image coordinates.\n  points_image = points_pixel[Ellipsis, :2] / points_pixel[Ellipsis, 2:]\n\n  # Apply distortion model.\n  if distortion_params is not None:\n    points_image = _radial_and_tangential_undistort(\n        points_image[Ellipsis, 0],\n        points_image[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n\n  # Return pixel coordinates and depth values.\n  return points_image, points_pixel[Ellipsis, 2]\n\n"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Extract the camera rotation and translation matrices from camtoworlds.\n  rotations = camtoworlds[Ellipsis, :3, :3]\n  translations = camtoworlds[Ellipsis, :3, -1]\n\n  # Transform the points from world coordinates to camera coordinates.\n  points = points - xnp.broadcast_to(translations, points.shape)\n  points = xnp.matmul(points, rotations)\n\n  # Extract the camera focal lengths and principal points from pixtocams.\n  focal_x = pixtocams[Ellipsis, 0, 0]\n  focal_y = pixtocams[Ellipsis, 1, 1]\n  px = pixtocams[Ellipsis, 0, 2]\n  py = pixtocams[Ellipsis, 1, 2]\n\n  # Extract the x and y coordinates of the points in camera coordinates.\n  x = points[Ellipsis, 0]\n  y = points[Ellipsis, 1]\n\n  # Calculate the depth values of the points in the camera coordinate system.\n  depth = points[Ellipsis, 2]\n\n  # If distortion parameters are provided, correct for radial and tangential distortion.\n  if distortion_params is not None:\n    r2 = x * x + y * y\n    r4 = r2 * r2\n    r6 = r4 * r2\n    radial_distortion = (\n        1.0 + r2 * (distortion_params['k1'] + r2 * (distortion_params['k2'] + r2 * distortion_params['k3']))\n    )\n    tangential_distortion_x = (\n        2.0 * distortion_params['p1'] * x * y + distortion_params['p2'] * (r2 + 2.0 * x * x)\n    )\n    tangential_distortion_y = (\n        distortion"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # TODO(barron): Add support for other camera types.\n  if camtype != ProjectionType.PERSPECTIVE:\n    raise NotImplementedError(\n        'Only perspective projection is currently supported.'\n    )\n\n  # Apply camera extrinsics to transform points from world to camera coordinates.\n  points = mat_vec_mul(camtoworlds[Ellipsis, :3, :3], points)\n  points = points + xnp.broadcast_to(camtoworlds[Ellipsis, :3, -1], points.shape)\n\n  # Apply inverse intrinsics to transform points from camera to pixel coordinates.\n  points = mat_vec_mul(pixtocams[Ellipsis, :3, :3], points)\n\n  # Apply distortion correction.\n  if distortion_params is not None:\n    points = _radial_and_tangential_undistort(\n        points[Ellipsis, 0],\n        points[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n\n  # Convert to pixel coordinates.\n  coordinates = points[Ellipsis, :2] / xnp.where(\n      points[Ellipsis, 2] > 0, points[Ellipsis, 2], 1.0\n  )\n\n  # Compute depth values.\n  depth = points[Ellipsis, 2]\n\n  return coordinates, depth\n\n"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Get the inverse of the camera extrinsics matrices.\n  camtoworld_inv = xnp.linalg.inv(camtoworlds)\n\n  # Transform the points from world coordinates to camera coordinates.\n  points_cam = mat_vec_mul(camtoworld_inv, points)\n\n  # Project the points onto the image plane.\n  points_pix = mat_vec_mul(pixtocams, points_cam)\n\n  # Extract the depth values.\n  depth = points_pix[Ellipsis, 2]\n\n  # Extract the 2D pixel coordinates.\n  coordinates = points_pix[Ellipsis, :2]\n\n  # Apply distortion correction if necessary.\n  if distortion_params is not None:\n    # Apply radial distortion correction.\n    r2 = xnp.sum(xnp.square(coordinates), axis=-1, keepdims=True)\n    distortion_factor = 1 + xnp.sum(\n        (r2 * distortion_params['radial'] + distortion_params['radial2']),\n        axis=-1,\n        keepdims=True,\n    )\n    coordinates *= distortion_factor\n\n    # Apply tangential distortion correction.\n    coordinates += xnp.stack(\n        [\n            -2 * distortion_params['tangential_x'] * coordinates[Ellipsis, 0] *\n            coordinates[Ellipsis, 1] + distortion_params['tangential_y'] *\n            (r2 + 2 * coordinates[Ellipsis, 0]**2),\n            distortion_params['tangential_x'] *\n            (r2 + 2 * coordinates[Ellipsis, 1]**2) + 2 *\n            distortion_params['tangential_y'] * coordinates[Ellipsis, 0] *\n            coordinates[Ellipsis, 1],\n        ],\n        axis=-1,\n    )\n\n    # Apply p"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Extract the 3D world coordinates of the points.\n  points_world = points[Ellipsis, :3]\n\n  # Calculate the 3D camera coordinates of the points.\n  points_cam = mat_vec_mul(camtoworlds, points_world)\n\n  # Calculate the 2D pixel coordinates of the points.\n  points_pixel, _ = convert_to_ndc(\n      points_cam, pixtocam=pixtocams, xnp=xnp, near=1.0, far=1000.0\n  )\n\n  # Correct for radial and tangential distortion.\n  if distortion_params is not None:\n    points_pixel = _radial_and_tangential_undistort(\n        points_pixel, **distortion_params, xnp=xnp\n    )\n\n  # Calculate the depth values of the points in the camera coordinate system.\n  depth = points_cam[Ellipsis, 2]\n\n  return points_pixel, depth\n\n"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Extract the camera extrinsics.\n  camtoworld = camtoworlds[0]\n  # Extract the camera intrinsics.\n  pixtocam = pixtocams[0]\n\n  # Convert the world coordinates to camera coordinates.\n  points_cam = mat_vec_mul(camtoworld, points)\n  # Extract the x, y, and z coordinates of the points in camera space.\n  x, y, z = points_cam\n\n  # Project the points to pixel coordinates.\n  if camtype == ProjectionType.PERSPECTIVE:\n    # Perspective projection.\n    x_pixel = x / z\n    y_pixel = y / z\n\n  elif camtype == ProjectionType.FISHEYE:\n    # Fisheye projection.\n    theta = xnp.sqrt(x * x + y * y)\n    phi = xnp.arctan2(theta, z)\n    x_pixel = phi / theta * x\n    y_pixel = phi / theta * y\n\n  elif camtype == ProjectionType.PANORAMIC:\n    # Panoramic projection.\n    x_pixel = x\n    y_pixel = y\n\n  # Convert pixel coordinates to image coordinates.\n  x_image = x_pixel * pixtocam[0, 0] + pixtocam[0, 2]\n  y_image = -y_pixel * pixtocam[1, 1] + pixtocam[1, 2]\n\n  # Apply distortion correction.\n  if distortion_params is not None:\n    # Convert the image coordinates to NDC space.\n    ndc_x = 2 * x_image / pixtocam[0, 0]\n    ndc_y = 2 * y_image / pixtocam[1, 1]\n\n    # Distort the coordinates.\n    x_ndc, y_ndc = _radial_and_tangential_distortion(\n        ndc_x, "}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Extract the camera origin.\n  camera_origins = camtoworlds[Ellipsis, :3, -1]\n\n  # Extract the rotation and translation parts of the camtoworld matrices.\n  rotations = camtoworlds[Ellipsis, :3, :3]\n  translations = camtoworlds[Ellipsis, :3, -1]\n\n  # Extract the inverse of the camera intrinsics matrix.\n  pixtocam = pixtocams[Ellipsis, :3, :3]\n\n  # Convert the 3D points to homogeneous coordinates.\n  points_homogeneous = xnp.concatenate([points, xnp.ones_like(points[Ellipsis, :1])], axis=-1)\n\n  # Transform the points from world coordinates to camera coordinates.\n  points_camera = xnp.matmul(rotations, points_homogeneous.T,\n                             ).T + translations[Ellipsis, None]\n\n  # Extract the depth values of the points in the camera coordinate system.\n  depth = points_camera[Ellipsis, 2]\n\n  # Transform the points from camera coordinates to pixel coordinates.\n  points_pixel = xnp.matmul(pixtocam, points_camera.T).T\n\n  # Extract the x and y coordinates of the points in pixel coordinates.\n  coordinates = points_pixel[Ellipsis, :2]\n\n  # Apply radial and tangential distortion corrections if provided.\n  if distortion_params is not None:\n    # Convert the pixel coordinates to normalized device coordinates.\n    coordinates_ndc = convert_to_ndc(\n        coordinates, pixtocam, xnp=xnp, distortion_params=distortion_params\n    )\n\n    # Extract the radial and tangential distortion coefficients.\n    radial_distortion = distortion_params['radial']\n    tangential_distortion = distortion_params['tangential']\n\n    # Apply the radial distort"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Convert points to camera coordinate system.\n  points_cam = mat_vec_mul(camtoworlds[Ellipsis, :3, :3], points) + camtoworlds[Ellipsis, :3, -1:]\n\n  # Apply inverse of intrinsics.\n  points_pixel = mat_vec_mul(pixtocams, points_cam)\n\n  # Apply distortion correction.\n  if distortion_params is not None:\n    points_pixel = _radial_and_tangential_undistort(\n        points_pixel[Ellipsis, 0],\n        points_pixel[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n\n  # Get 2D pixel coordinates.\n  coordinates = points_pixel[Ellipsis, :2]\n\n  # Get depth values.\n  depth = points_cam[Ellipsis, 2]\n\n  return coordinates, depth\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta_squared = jnp.sum(screw_axis**2, axis=-1)\n  theta = _safe_sqrt(theta_squared)\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  R_taylor = jnp.eye(3)\n  V_taylor = jnp.eye(3)\n\n  # Prevent bad gradients from propagating back when theta is small.\n  screw_axis_safe = jnp.where(theta_squared > eps**2, screw_axis, 0.0)\n  theta_safe = jnp.where(theta_squared > eps**2, theta, 1.0)\n  w = screw_axis_safe[:3]\n  v = screw_axis_safe[3:]\n  W = skew(w)\n  V = skew(v)\n  R = jnp.eye(3) + jnp.sin(theta_safe) * W + (1.0 - jnp.cos(theta_safe)) * spin_math.matmul(W, W)\n  V = V + (theta_safe - jnp.sin(theta_safe)) * spin_math.matmul(W, V) / theta_safe\n\n  return jnp.where(theta_squared > eps**2, jnp.block([[R, V], [jnp.array([[0.0, 0.0, 0.0, 1.0]])]), R_taylor)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = jnp.linalg.norm(screw_axis[:3])\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  R_taylor = jnp.eye(3)\n  V_taylor = jnp.hstack((jnp.eye(3), jnp.zeros((3, 3))))\n\n  # Prevent bad gradients from propagating back when theta is small.\n  w_safe = jnp.where(theta > eps, w, 0.0)\n  theta_safe = jnp.where(theta > eps, theta, 1.0)\n  w_skew = skew(w_safe)\n  R = jnp.eye(3) + jnp.sin(theta_safe) * w_skew + (1.0 - jnp.cos(theta_safe)) * spin_math.matmul(w_skew, w_skew)\n  V = jnp.eye(3) + (1.0 - jnp.cos(theta_safe)) * w_skew + (theta_safe - jnp.sin(theta_safe)) * spin_math.matmul(w_skew, w_skew)\n\n  return jnp.where(theta > eps, jnp.block([[R, jnp.matmul(V, v)], [jnp.zeros((1, 3)), jnp.ones((1, 1))]]), R_taylor)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  w = screw_axis[:3]\n  v = screw_axis[3:]\n  theta_squared = jnp.sum(w**2, axis=-1)\n  theta = _safe_sqrt(theta_squared)\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  R_taylor = jnp.eye(3)\n  V_taylor = jnp.eye(3) + skew(v)\n\n  # Prevent bad gradients from propagating back when theta is small.\n  w_safe = jnp.where(theta_squared > eps**2, w, 0.0)\n  theta_safe = jnp.where(theta_squared > eps**2, theta, 1.0)\n  W = skew(w_safe)\n  R = (\n      jnp.eye(3)\n      + jnp.sin(theta_safe) * W\n      + (1.0 - jnp.cos(theta_safe)) * spin_math.matmul(W, W)\n  )\n  V = jnp.eye(3) + (1.0 - jnp.cos(theta_safe)) * skew(v) + (theta_safe - jnp.sin(theta_safe)) * spin_math.matmul(skew(v), skew(v))\n\n  return jnp.where(theta_squared > eps**2, jnp.block([[R, V @ v], [jnp.array([[0.0, 0.0, 0.0, 1.0]])]]), jnp.block([[R_taylor, V_taylor @ v], [jnp.array([[0.0, 0.0, 0.0, 1.0]])]]))\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = jnp.linalg.norm(screw_axis)\n  theta_sq = theta**2\n  theta_cubed = theta_sq * theta\n  theta_fourth = theta_sq * theta_sq\n  theta_fifth = theta_fourth * theta\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  R_taylor = jnp.eye(3) + skew(screw_axis)\n\n  # Prevent bad gradients from propagating back when theta is small.\n  screw_axis_safe = jnp.where(theta_sq > eps**2, screw_axis, 0.0)\n  theta_safe = jnp.where(theta_sq > eps**2, theta, 1.0)\n  w = screw_axis_safe / theta_safe\n  W = skew(w)\n  R = (\n      jnp.eye(3)\n      + (\n          (1.0 - jnp.cos(theta_safe)) / theta_sq\n      ) * W\n      + (\n          (theta_sq - jnp.sin(theta_safe)) / theta_cubed\n      ) * spin_math.matmul(W, W)\n  )\n\n  return jnp.where(theta_sq > eps**2, R, R_taylor)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = jnp.linalg.norm(screw_axis)\n  theta_sq = theta * theta\n  theta_cubed = theta_sq * theta\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  R_taylor = jnp.eye(3) + skew(screw_axis)\n  V_taylor = jnp.eye(3) + skew(screw_axis) / 2.0\n\n  # Prevent bad gradients from propagating back when theta is small.\n  screw_axis_safe = jnp.where(theta_sq > eps**2, screw_axis, 0.0)\n  theta_safe = jnp.where(theta_sq > eps**2, theta, 1.0)\n  w = screw_axis_safe / theta_safe\n  W = skew(w)\n  V = (\n      jnp.eye(3)\n      + (1.0 - jnp.cos(theta_safe)) * W\n      + (theta_safe - jnp.sin(theta_safe)) * spin_math.matmul(W, W)\n  )\n  R = jnp.eye(3) + (1.0 - jnp.cos(theta_safe)) * W + (theta_sq - theta_cubed) * spin_math.matmul(W, W)\n\n  return jnp.where(theta_sq > eps**2, jnp.block([[R, jnp.matmul(V, w)], [jnp.array([0.0, 0.0, 0.0, 1.0])]]), R_taylor)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = jnp.linalg.norm(screw_axis)\n  if theta < eps:\n    return jnp.eye(4)\n\n  axis = screw_axis / theta\n  W = skew(axis)\n  R = (\n      jnp.eye(3)\n      + (jnp.sin(theta) / theta) * W\n      + ((1.0 - jnp.cos(theta)) / theta**2) * spin_math.matmul(W, W)\n  )\n\n  v = screw_axis[:3]\n  p = (\n      jnp.eye(3)\n      + (1.0 - jnp.cos(theta)) / theta**2 * W\n      + ((theta - jnp.sin(theta)) / theta**3) * spin_math.matmul(W, W)\n  ) @ v\n\n  return jnp.block([[R, p], [jnp.array([[0.0, 0.0, 0.0, 1.0]])]])\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # Compute the rotation matrix and translation vector from the screw axis.\n  theta = jnp.linalg.norm(screw_axis[:3])\n  v = screw_axis[3:]\n  w = screw_axis[:3]\n  R = exp_so3(w, eps)\n  p = v / theta\n\n  # Compute the exponential map.\n  V = jnp.zeros((4, 4))\n  V = jax.ops.index_update(V, jax.ops.index[:3, :3], R)\n  V = jax.ops.index_update(V, jax.ops.index[:3, 3], p)\n  V = jax.ops.index_update(V, jax.ops.index[3, 3], 1.0)\n\n  return V\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = jnp.linalg.norm(screw_axis[:3])\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  R_taylor = jnp.eye(3)\n  V_taylor = jnp.zeros((3, 3))\n\n  # Prevent bad gradients from propagating back when theta is small.\n  w_safe = jnp.where(theta > eps, w, 0.0)\n  theta_safe = jnp.where(theta > eps, theta, 1.0)\n\n  R = exp_so3(w_safe, eps)\n  V = (\n      R\n      - jnp.eye(3)\n      - skew(w_safe)\n      + (1.0 - jnp.cos(theta_safe)) * spin_math.matmul(skew(w_safe), skew(w_safe))\n  )\n\n  return jnp.where(theta > eps, jnp.block([[R, V @ v], [jnp.array([[0.0, 0.0, 0.0, 1.0]])]]), R_taylor)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # Check if the magnitude of the rotation is zero\n  theta_squared = jnp.sum(screw_axis[:3]**2)\n  theta = _safe_sqrt(theta_squared)\n  theta_safe = jnp.where(theta_squared > eps**2, theta, 1.0)\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  R_taylor = jnp.eye(3)\n  t_taylor = screw_axis[3:]\n  v_taylor = screw_axis[3:]\n\n  # Prevent bad gradients from propagating back when theta is small.\n  screw_axis_safe = jnp.where(theta_squared > eps**2, screw_axis, 0.0)\n  theta_safe = jnp.where(theta_squared > eps**2, theta, 1.0)\n  w = screw_axis_safe[:3]\n  v = screw_axis_safe[3:]\n  W = skew(w)\n  R = (\n      jnp.eye(3)\n      + jnp.sin(theta_safe) * W\n      + (1.0 - jnp.cos(theta_safe)) * spin_math.matmul(W, W)\n  )\n  t = v + (jnp.eye(3) - R) @ v\n\n  return jnp.where(theta_squared > eps**2, jnp.block([[R, t], [jnp.array([[0.0, 0.0, 0.0, 1.0]])]]), jnp.block([[R_taylor, t_taylor], [jnp.array([[0.0, 0.0, 0.0, 1.0]])]]))\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # Compute theta and the rotation axis from the screw axis.\n  theta = jnp.linalg.norm(screw_axis[:3])\n  axis = screw_axis[:3] / theta\n\n  # Compute the skew symmetric matrix of the rotation axis.\n  W = skew(axis)\n\n  # Compute the rotation matrix.\n  R = jnp.eye(3) + jnp.sin(theta) * W + (1.0 - jnp.cos(theta)) * spin_math.matmul(W, W)\n\n  # Compute the translation matrix.\n  V = jnp.eye(3) + (1.0 - jnp.cos(theta)) * W + (theta - jnp.sin(theta)) * spin_math.matmul(W, W)\n  p = jnp.matmul(V, screw_axis[3:])\n\n  # Construct the homogeneous transformation matrix.\n  X = jnp.zeros((4, 4))\n  X[:3, :3] = R\n  X[:3, 3] = p\n  X[3, 3] = 1.0\n\n  return X\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # Compute rotation matrix from the screw axis\n  theta = jnp.linalg.norm(screw_axis[:3])\n  theta = jnp.where(theta > eps, theta, 1.0)\n  w = screw_axis[:3] / theta\n  W = skew(w)\n  R = (\n      jnp.eye(3)\n      + jnp.sin(theta) * W\n      + (1.0 - jnp.cos(theta)) * spin_math.matmul(W, W)\n  )\n\n  # Compute translation\n  v = screw_axis[3:]\n\n  # Compute transformation matrix\n  X = jnp.block([[R, v[:, None]], [jnp.zeros((1, 3)), 1.0]])\n\n  return X\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # Extract the rotation and translation components from the screw axis\n  w = screw_axis[0:3]\n  v = screw_axis[3:6]\n\n  # Compute the rotation matrix from the axis-angle representation\n  R = exp_so3(w, eps)\n\n  # Compute the translation vector\n  p = v / jnp.linalg.norm(w)\n\n  # Compute the homogeneous transformation matrix\n  T = rp_to_se3(R, p)\n\n  return T\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # Extract rotation and translation components\n  theta = jnp.linalg.norm(screw_axis[:3])\n  v = screw_axis[3:]\n  w = screw_axis[:3] / theta\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  R_taylor = jnp.eye(3) + skew(w)\n\n  # Prevent bad gradients from propagating back when theta is small.\n  w_safe = jnp.where(theta > eps, w, 0.0)\n  theta_safe = jnp.where(theta > eps, theta, 1.0)\n  W = skew(w_safe)\n  R = (\n      jnp.eye(3)\n      + jnp.sin(theta_safe) * W\n      + (1.0 - jnp.cos(theta_safe)) * spin_math.matmul(W, W)\n  )\n\n  # Construct the output matrix\n  T = jnp.eye(4)\n  T = T.at[:3, :3].set(jnp.where(theta > eps, R, R_taylor))\n  T = T.at[:3, 3].set(v)\n\n  return T\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # Compute theta (magnitude of motion)\n  theta_squared = jnp.sum(screw_axis**2, axis=-1)\n  theta = _safe_sqrt(theta_squared)\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  R_taylor = jnp.eye(3)\n  V_taylor = jnp.eye(3)\n\n  # Prevent bad gradients from propagating back when theta is small.\n  screw_axis_safe = jnp.where(theta_squared > eps**2, screw_axis, 0.0)\n  theta_safe = jnp.where(theta_squared > eps**2, theta, 1.0)\n  w = screw_axis_safe[:3]\n  v = screw_axis_safe[3:]\n\n  # Compute the rotation matrix and the translation vector.\n  R = exp_so3(w, eps)\n  V = (\n      jnp.eye(3)\n      + (1.0 - jnp.cos(theta_safe)) * skew(w)\n      + (theta_safe - jnp.sin(theta_safe)) * spin_math.matmul(skew(w), skew(w))\n  )\n\n  # Construct the homogeneous transformation matrix.\n  X = jnp.block([[R, jnp.matmul(V, v[:, None])], [jnp.array([0.0, 0.0, 0.0, 1.0])]])\n\n  return jnp.where(theta_squared > eps**2, X, R_taylor)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # Compute theta, which is the magnitude of the motion.\n  theta = jnp.linalg.norm(screw_axis[:3])\n\n  # Prevent bad gradients from propagating back when theta is small.\n  screw_axis_safe = jnp.where(theta > eps, screw_axis, 0.0)\n  theta_safe = jnp.where(theta > eps, theta, 1.0)\n\n  # Compute the rotation matrix from the screw axis.\n  R = exp_so3(screw_axis_safe[:3] / theta_safe)\n\n  # Compute the translation.\n  p = theta_safe * screw_axis_safe[3:]\n\n  # Compute the homogeneous transformation matrix.\n  X = rp_to_se3(R, p)\n\n  return X\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # The magnitude of the rotation in the screw axis\n  theta = jnp.linalg.norm(screw_axis[0:3])\n\n  # The rotation axis of the screw axis\n  axis = screw_axis[0:3] / theta\n\n  # The translation of the screw axis\n  v = screw_axis[3:6]\n\n  # The skew symmetric cross product matrix\n  W = skew(axis)\n\n  # The exponential map\n  R = jnp.eye(3) + jnp.sin(theta) * W + (1 - jnp.cos(theta)) * jnp.matmul(W, W)\n\n  # The translation matrix\n  p = v + (1 - jnp.cos(theta)) * jnp.matmul(W, v) + (theta - jnp.sin(theta)) * jnp.matmul(jnp.matmul(W, W), v)\n\n  # The homogeneous transformation matrix\n  X = jnp.zeros((4, 4))\n  X[0:3, 0:3] = R\n  X[0:3, 3] = p\n  X[3, 3] = 1\n\n  return X\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = jnp.linalg.norm(screw_axis[:3])\n  theta_sq = theta ** 2\n  theta_cubed = theta_sq * theta\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  R_taylor = jnp.eye(3) + skew(w)\n  p_taylor = theta * v\n\n  # Prevent bad gradients from propagating back when theta is small.\n  w_safe = jnp.where(theta_sq > eps**2, w, 0.0)\n  theta_safe = jnp.where(theta_sq > eps**2, theta, 1.0)\n  W = skew(w_safe)\n  R = (\n      jnp.eye(3)\n      + (1.0 - jnp.cos(theta_safe)) * W\n      + (theta_safe - jnp.sin(theta_safe)) * spin_math.matmul(W, W)\n  )\n  p = theta_sq * theta_cubed * jnp.outer(w, v)\n  p = p + theta_cubed * jnp.cross(w, v)\n  p = theta * v + jnp.squeeze(p)\n\n  return jnp.where(theta_sq > eps**2, rp_to_se3(R, p), rp_to_se3(R_taylor, p_taylor))\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # Extracting the rotation and translation components\n  w = screw_axis[:3]\n  v = screw_axis[3:]\n\n  # Computing the magnitude of the rotation\n  theta = jnp.linalg.norm(w)\n\n  # Computing the rotation matrix\n  R = exp_so3(w, eps)\n\n  # Computing the translation vector\n  t = jnp.sin(theta) * v / theta + (1.0 - jnp.cos(theta)) * jnp.matmul(skew(w), v) / theta\n\n  # Computing the transformation matrix\n  T = jnp.block([[R, t[:, None]], [jnp.zeros((1, 3)), 1.0]])\n\n  return T\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # Calculate theta\n  theta = jnp.linalg.norm(screw_axis)\n\n  # Check if theta is zero\n  # If so, return identity matrix\n  if theta == 0:\n    return jnp.eye(4)\n\n  # Normalize the screw axis\n  # This is the axis of rotation and translation\n  w = screw_axis / theta\n\n  # Calculate the skew symmetric matrix of w\n  W = skew(w)\n\n  # Calculate the rotation matrix\n  R = jnp.eye(3) + (jnp.sin(theta) / theta) * W + (1 - jnp.cos(theta)) * jnp.matmul(W, W)\n\n  # Calculate the translation\n  # The magnitude of the translation is theta\n  v = theta * w\n\n  # Calculate the translation matrix\n  P = jnp.eye(4)\n  P = P.at[0:3, 3].set(v)\n\n  # Calculate the homogeneous transformation matrix\n  X = jnp.eye(4)\n  X = X.at[0:3, 0:3].set(R)\n  X = X.at[0:3, 3].set(P[0:3, 3])\n\n  return X\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # The screw axis is a 6-vector [w, v] where w is the rotation axis and v is the translation axis.\n  # The magnitude of w is the angle of rotation, theta.\n  # The magnitude of v is the magnitude of motion, theta.\n  # The rotation axis is a unit vector.\n  # The translation axis is a unit vector.\n  # The screw axis is a unit vector.\n\n  # The rotation axis is the first 3 elements of the screw axis.\n  w = screw_axis[0:3]\n\n  # The rotation angle is the magnitude of the rotation axis.\n  theta = jnp.linalg.norm(w)\n\n  # The rotation axis is a unit vector.\n  # The screw axis is a unit vector.\n  w_unit = w / theta\n  w_hat = skew(w_unit)\n\n  # The translation axis is the last 3 elements of the screw axis.\n  v = screw_axis[3:6]\n\n  # The translation axis is a unit vector.\n  v_unit = v / jnp.linalg.norm(v)\n\n  # The exponential map is defined as follows:\n  # X = [R, v]\n  #     [0, 1]\n  #\n  # R = I + w_hat * sin(theta) + (1 - cos(theta)) * w_hat^2\n  #\n  # v = (1 - cos(theta)) * w_unit * v_unit^T + (theta) * w_unit + (sin(theta)) * w_hat * v_unit^T\n\n  # The rotation matrix is defined as follows:\n  # R = I + w_hat * sin(theta) + (1 - cos(theta)) * w_hat^2\n\n  # The rotation matrix is calculated as follows:\n  # R = I + w_hat * sin(theta) + (1 - cos(theta)) * w_hat^2\n  # R = I + w_hat * sin(theta) + (1 - cos(theta)) * w_hat * w_hat^T"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  axis = axis_angle / (theta + eps)\n  c = jnp.cos(theta)\n  s = jnp.sin(theta)\n  return axis * axis.T * (1.0 - c) + jnp.eye(3) * c + skew(axis) * s\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # Convert axis-angle to rotation matrix using Rodrigues' formula\n  # https://en.wikipedia.org/wiki/Rodrigues%27_rotation_formula\n  theta = jnp.linalg.norm(axis_angle)\n  if theta > eps:\n    k = axis_angle / theta\n    K = skew(k)\n    R = jnp.eye(3) + jnp.sin(theta) * K + (1.0 - jnp.cos(theta)) * jnp.dot(K, K)\n  else:\n    R = jnp.eye(3)\n\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  axis = axis_angle / (theta + eps)\n  cross_matrix = jnp.array([[0.0, -axis[2], axis[1]], [axis[2], 0.0, -axis[0]], [-axis[1], axis[0], 0.0]])\n  R = jnp.eye(3) + cross_matrix * jnp.sin(theta) + cross_matrix @ cross_matrix * (1.0 - jnp.cos(theta))\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # Convert the axis-angle representation to a skew-symmetric matrix\n  skew_symmetric_matrix = skew(axis_angle)\n\n  # Compute the norm of the skew-symmetric matrix\n  norm_matrix = jnp.linalg.norm(skew_symmetric_matrix)\n\n  # Compute the rotation matrix using Rodrigues' formula\n  rot_matrix = (\n    jnp.identity(3)\n    + (\n      (\n        jnp.sin(norm_matrix) / (norm_matrix + eps)\n      )\n      * skew_symmetric_matrix\n    )\n    + (\n      (\n        (1.0 - jnp.cos(norm_matrix)) / (norm_matrix + eps) ** 2\n      )\n      * jnp.matmul(skew_symmetric_matrix, skew_symmetric_matrix)\n    )\n  )\n\n  return rot_matrix\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  axis = axis_angle / (theta + eps)\n\n  K = jnp.array([[0.0, -axis[2], axis[1]], [axis[2], 0.0, -axis[0]], [-axis[1], axis[0], 0.0]])\n\n  R = jnp.eye(3) + jnp.sin(theta) * K + (1 - jnp.cos(theta)) * jnp.matmul(K, K)\n\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  axis_angle = jnp.reshape(axis_angle, (3))\n  theta = jnp.linalg.norm(axis_angle)\n  axis_angle = axis_angle / (theta + eps)\n\n  K = jnp.array([[0.0, -axis_angle[2], axis_angle[1]],\n                 [axis_angle[2], 0.0, -axis_angle[0]],\n                 [-axis_angle[1], axis_angle[0], 0.0]])\n\n  return jnp.eye(3) + jnp.sin(theta) * K + (1.0 - jnp.cos(theta)) * jnp.dot(K, K)\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # axis_angle = np.array(axis_angle, dtype=np.float64)\n  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n    return jnp.eye(3)\n  k = axis_angle / theta\n  K = skew(k)\n  R = jnp.eye(3) + jnp.sin(theta) * K + (1 - jnp.cos(theta)) * jnp.dot(K, K)\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n\n  if theta < eps:\n    return jnp.eye(3)\n\n  k = axis_angle / theta\n\n  K = jnp.array([[0.0, -k[2], k[1]], [k[2], 0.0, -k[0]], [-k[1], k[0], 0.0]])\n\n  R = jnp.eye(3) + jnp.sin(theta) * K + (1.0 - jnp.cos(theta)) * jnp.dot(K, K)\n\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # Compute theta (angle of rotation) and the rotation axis (w).\n  theta = jnp.linalg.norm(axis_angle)\n  w = jnp.array(axis_angle / theta, dtype=jnp.float32)\n\n  # Compute the skew-symmetric cross-product matrix of the rotation axis.\n  W = skew(w)\n\n  # Compute the rotation matrix.\n  R = jnp.eye(3, dtype=jnp.float32) + jnp.sin(theta) * W + (1.0 - jnp.cos(theta)) * jnp.dot(W, W)\n\n  # Numerical stability for small angles.\n  R = jnp.where(theta > eps, R, jnp.eye(3, dtype=jnp.float32))\n\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # Compute rotation matrix from axis-angle.\n  # Rodrigues' formula:\n  # https://en.wikipedia.org/wiki/Rodrigues%27_rotation_formula\n\n  theta = jnp.linalg.norm(axis_angle)\n  axis = axis_angle / (theta + eps)\n  K = skew(axis)\n  R = jnp.eye(3) + jnp.sin(theta) * K + (1.0 - jnp.cos(theta)) * jnp.matmul(K, K)\n\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # Compute theta and the normalized axis\n  theta = jnp.linalg.norm(axis_angle)\n  axis = axis_angle / (theta + eps)\n\n  # Compute the skew-symmetric cross product matrix\n  skew_symmetric_cross_prod_matrix = skew(axis)\n\n  # Compute the rotation matrix\n  rot_mat = jnp.eye(3) + jnp.sin(theta) * skew_symmetric_cross_prod_matrix + (1 - jnp.cos(theta)) * jnp.matmul(skew_symmetric_cross_prod_matrix, skew_symmetric_cross_prod_matrix)\n\n  return rot_mat\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # Normalize the axis-angle representation to a unit vector\n  axis_angle_normalized = axis_angle / (jnp.linalg.norm(axis_angle) + eps)\n\n  # Compute the skew-symmetric cross-product matrix from the axis-angle representation\n  skew_symmetric_cross_product_matrix = skew(axis_angle_normalized)\n\n  # Compute the rotation matrix\n  rotation_matrix = jnp.eye(3) + jnp.sin(jnp.linalg.norm(axis_angle)) * skew_symmetric_cross_product_matrix + (\n          1 - jnp.cos(jnp.linalg.norm(axis_angle))) * jnp.matmul(skew_symmetric_cross_product_matrix,\n                                                                 skew_symmetric_cross_product_matrix)\n\n  return rotation_matrix\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # normalize the axis-angle vector to get the unit vector\n  u = axis_angle / (jnp.linalg.norm(axis_angle) + eps)\n\n  # get the norm of the axis-angle vector\n  norm_u = jnp.linalg.norm(axis_angle)\n\n  # get the skew-symmetric cross product matrix\n  ux = skew(u)\n\n  # Rodrigues' formula for small angles\n  if norm_u < eps:\n    return jnp.eye(3) + ux\n\n  # Rodrigues' formula for large angles\n  else:\n    return jnp.eye(3) + ux + jnp.dot(ux, ux) / (1 + jnp.cos(norm_u))\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # Compute theta from the norm of the axis-angle vector\n  theta = jnp.linalg.norm(axis_angle)\n\n  # If the magnitude of the rotation is sufficiently small, return the identity\n  # matrix\n  if theta < eps:\n    return jnp.eye(3)\n\n  # Normalize the axis-angle representation\n  axis_angle_normalized = axis_angle / theta\n\n  # Compute the skew-symmetric cross product matrix\n  K = skew(axis_angle_normalized)\n\n  # Compute the rotation matrix using Rodrigues' formula\n  R = jnp.eye(3) + jnp.sin(theta) * K + (1.0 - jnp.cos(theta)) * jnp.dot(K, K)\n\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # normalize the axis-angle representation to get the rotation axis\n  axis = axis_angle / (jnp.linalg.norm(axis_angle) + eps)\n\n  # get the rotation angle from the magnitude of the axis-angle vector\n  angle = jnp.linalg.norm(axis_angle)\n\n  # compute the skew-symmetric cross-product matrix from the rotation axis\n  skew_symmetric_cross_product_matrix = skew(axis)\n\n  # compute the rotation matrix using Rodrigues' formula\n  rotation_matrix = jnp.eye(3) + jnp.sin(angle) * skew_symmetric_cross_product_matrix + (1 - jnp.cos(angle)) * jnp.matmul(skew_symmetric_cross_product_matrix, skew_symmetric_cross_product_matrix)\n\n  return rotation_matrix\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # Compute theta (rotation angle) from the axis-angle representation\n  theta = jnp.linalg.norm(axis_angle)\n\n  # If theta is sufficiently small, use the first-order Taylor approximation of the exponential map.\n  if theta < eps:\n    R = jnp.eye(3) + skew(axis_angle)\n\n  # Otherwise, compute the exponential map normally.\n  else:\n    # Compute the axis of rotation normalized to a unit vector.\n    axis = axis_angle / theta\n\n    # Compute the cross-product matrix of the normalized axis.\n    K = skew(axis)\n\n    # Compute the in-plane rotation matrix.\n    R = jnp.eye(3) + jnp.sin(theta) * K + (1 - jnp.cos(theta)) * jnp.dot(K, K)\n\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # Convert the axis-angle representation to a rotation matrix.\n  # Rodrigues' formula:\n  # https://en.wikipedia.org/wiki/Rodrigues%27_rotation_formula\n  # https://math.stackexchange.com/questions/180418/calculate-rotation-matrix-to-align-vector-a-to-vector-b-in-3d\n  # The implementation below is equivalent to the following implementation.\n  # https://github.com/Pulkitag/pycaffe-utils/blob/master/rot_utils.py#L174\n\n  # Normalize the axis-angle representation.\n  axis_angle_norm = jnp.linalg.norm(axis_angle)\n  axis_angle = jnp.where(\n    axis_angle_norm > eps, axis_angle / axis_angle_norm, axis_angle\n  )\n\n  # Compute the skew-symmetric cross product matrix.\n  K = skew(axis_angle)\n\n  # Compute the rotation matrix.\n  R = jnp.eye(3) + jnp.sin(axis_angle_norm) * K + (1.0 - jnp.cos(axis_angle_norm)) * jnp.dot(K, K)\n\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # Get the angle of rotation\n  angle = jnp.linalg.norm(axis_angle)\n\n  # If the angle of rotation is sufficiently small, return the identity matrix\n  if angle < eps:\n    return jnp.eye(3)\n\n  # Compute the skew-symmetric cross product matrix from the axis-angle representation\n  K = skew(axis_angle)\n\n  # Compute the rotation matrix using Rodrigues' formula\n  R = jnp.eye(3) + jnp.sin(angle) * K + (1 - jnp.cos(angle)) * jnp.dot(K, K)\n\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n\n  # Check for small angle\n  small_angle = theta < eps\n\n  # If small angle, use first order Taylor expansion\n  angle_axis = jnp.zeros(3)\n\n  # Otherwise, use Rodrigues' formula\n  angle_axis = axis_angle / theta\n\n  # Use Rodrigues' formula to compute the rotation matrix\n  R = jnp.eye(3) + jnp.sin(theta) * skew(angle_axis) + (1 - jnp.cos(theta)) * jnp.matmul(skew(angle_axis), skew(angle_axis))\n\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  axis_angle_normalized = axis_angle / (theta + eps)\n  K = skew(axis_angle_normalized)\n  R = jnp.eye(3) + jnp.sin(theta) * K + (1.0 - jnp.cos(theta)) * jnp.matmul(K, K)\n  return R\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  # Convert the conical frustum to Gaussian parameters.\n  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n\n  # Lift the Gaussian to 3D coordinates.\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  # This function approximates a 3D conical frustum as a Gaussian distribution by calculating its mean and covariance. It takes into account the axis of the cone, the starting and ending distances of the frustum, the scale of the radius as a function of distance, and whether the Gaussian should have a diagonal or full-covariance.\n\n  # Input-Output Arguments\n  # d: jnp.float32 3-vector. The axis of the cone. It is used to determine the direction of the conical frustum.\n  # t0: float. The starting distance of the frustum from the origin. It marks the beginning of the conical section being approximated.\n  # t1: float. The ending distance of the frustum from the origin. It marks the end of the conical section being approximated.\n  # base_radius: float. The scale of the radius as a function of distance from the origin. It determines how the radius of the frustum changes with distance.\n  # diag: boolean. Indicates whether the resulting Gaussian distribution will have a diagonal covariance matrix or a full-covariance matrix. This affects the complexity and the information contained in the covariance.\n  # return: A tuple containing the mean (a jnp.float32 3-vector) and the covariance (a matrix) of the approximated Gaussian distribution. These represent the central tendency and the spread of the distribution, respectively.\n\n  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  # Calculate the mean and covariance of the Gaussian distribution.\n  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  # The following is a more stable version of Equation 7 from https://arxiv.org/abs/2103.13415.\n  s = t0 + t1\n  d = t1 - t0\n  eps = jnp.finfo(jnp.float32).eps ** 2\n  ratio = d**2 / jnp.maximum(eps, 3 * s**2 + d**2)\n  t_mean = s * (1 / 2 + ratio)\n  t_var = (1 / 12) * d**2 - (1 / 15) * ratio**2 * (12 * s**2 - d**2)\n  r_var = (1 / 16) * s**2 + d**2 * (5 / 48 - (1 / 15) * ratio)\n\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  # Convert the frustum to Gaussian parameters\n  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n\n  # Lift the Gaussian to 3D coordinates\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  # A more stable version of Equation 7 from https://arxiv.org/abs/2103.13415.\n  s = t0 + t1\n  d = t1 - t0\n  eps = jnp.finfo(jnp.float32).eps ** 2\n  ratio = d**2 / jnp.maximum(eps, 3 * s**2 + d**2)\n  t_mean = s * (1 / 2 + ratio)\n  t_var = (1 / 12) * d**2 - (1 / 15) * ratio**2 * (12 * s**2 - d**2)\n  r_var = (1 / 16) * s**2 + d**2 * (5 / 48 - (1 / 15) * ratio)\n\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  # A more stable version of Equation 7 from https://arxiv.org/abs/2103.13415.\n  s = t0 + t1\n  d = t1 - t0\n  eps = jnp.finfo(jnp.float32).eps ** 2\n  ratio = d**2 / jnp.maximum(eps, 3 * s**2 + d**2)\n  t_mean = s * (1 / 2 + ratio)\n  t_var = (1 / 12) * d**2 - (1 / 15) * ratio**2 * (12 * s**2 - d**2)\n  r_var = (1 / 16) * s**2 + d**2 * (5 / 48 - (1 / 15) * ratio)\n\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  # The mean is the same for both cases.\n  mean = d[Ellipsis, None] * t_mean[Ellipsis, None]\n\n  # If we want a diagonal covariance matrix...\n  if diag:\n\n    # We can calculate the diagonal covariance elements directly.\n    d_mag_sq = jnp.maximum(1e-10, jnp.sum(d**2, axis=-1, keepdims=True))\n    d_outer_diag = d**2\n    null_outer_diag = 1 - d_outer_diag / d_mag_sq\n    t_cov_diag = t_var[Ellipsis, None] * d_outer_diag[Ellipsis, None, :]\n    xy_cov_diag = r_var[Ellipsis, None] * null_outer_diag[Ellipsis, None, :]\n    cov_diag = t_cov_diag + xy_cov_diag\n\n    # We return the mean and the covariance diagonal.\n    return mean, cov_diag\n\n  # If we want a full covariance matrix...\n  else:\n\n    # We calculate the elements of the covariance matrix.\n    d_outer = d[Ellipsis, :, None] * d[Ellipsis, None, :]\n    eye = jnp.eye(d.shape[-1])\n    null_outer = eye - d[Ellipsis, :, None] * (d / d_mag_sq)[Ellipsis, None, :]\n    t_cov = t_var[Ellipsis, None, None] * d_outer[Ellipsis, None, :, :]\n    xy_cov = r_var[Ellipsis, None, None] * null_outer[Ellipsis, None, :, :]\n    cov = t_cov + xy_cov\n\n    # We return the mean and the full covariance matrix.\n    return mean, cov\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  # Calculate the mean and covariance of the Gaussian distribution.\n  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n  # Scale the Gaussian distribution by the radius.\n  mean *= base_radius\n  cov *= base_radius**2\n\n  return mean, cov\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  # Calculate the mean and covariance of the Gaussian distribution.\n  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  # A more stable version of Equation 7 from https://arxiv.org/abs/2103.13415.\n  s = t0 + t1\n  d = t1 - t0\n  eps = jnp.finfo(jnp.float32).eps ** 2\n  ratio = d**2 / jnp.maximum(eps, 3 * s**2 + d**2)\n  t_mean = s * (1 / 2 + ratio)\n  t_var = (1 / 12) * d**2 - (1 / 15) * ratio**2 * (12 * s**2 - d**2)\n  r_var = (1 / 16) * s**2 + d**2 * (5 / 48 - (1 / 15) * ratio)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  # A more stable version of Equation 7 from https://arxiv.org/abs/2103.13415.\n  s = t0 + t1\n  d = t1 - t0\n  eps = jnp.finfo(jnp.float32).eps ** 2\n  ratio = d ** 2 / jnp.maximum(eps, 3 * s ** 2 + d ** 2)\n  t_mean = s * (1 / 2 + ratio)\n  t_var = (1 / 12) * d ** 2 - (1 / 15) * ratio ** 2 * (12 * s ** 2 - d ** 2)\n  r_var = (1 / 16) * s ** 2 + d ** 2 * (5 / 48 - (1 / 15) * ratio)\n  r_var *= radius ** 2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  # A more stable version of Equation 7 from https://arxiv.org/abs/2103.13415.\n  s = t0 + t1\n  d = t1 - t0\n  eps = jnp.finfo(jnp.float32).eps ** 2\n  ratio = d**2 / jnp.maximum(eps, 3 * s**2 + d**2)\n  t_mean = s * (1 / 2 + ratio)\n  t_var = (1 / 12) * d**2 - (1 / 15) * ratio**2 * (12 * s**2 - d**2)\n  r_var = (1 / 16) * s**2 + d**2 * (5 / 48 - (1 / 15) * ratio)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  # A more stable version of Equation 7 from https://arxiv.org/abs/2103.13415.\n  s = t0 + t1\n  d = t1 - t0\n  eps = jnp.finfo(jnp.float32).eps ** 2\n  ratio = d**2 / jnp.maximum(eps, 3 * s**2 + d**2)\n  t_mean = s * (1 / 2 + ratio)\n  t_var = (1 / 12) * d**2 - (1 / 15) * ratio**2 * (12 * s**2 - d**2)\n  r_var = (1 / 16) * s**2 + d**2 * (5 / 48 - (1 / 15) * ratio)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  # A more stable version of Equation 7 from https://arxiv.org/abs/2103.13415.\n  s = t0 + t1\n  d = t1 - t0\n  eps = jnp.finfo(jnp.float32).eps ** 2\n  ratio = d**2 / jnp.maximum(eps, 3 * s**2 + d**2)\n  t_mean = s * (1 / 2 + ratio)\n  t_var = (1 / 12) * d**2 - (1 / 15) * ratio**2 * (12 * s**2 - d**2)\n  r_var = (1 / 16) * s**2 + d**2 * (5 / 48 - (1 / 15) * ratio)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  # The mean of the Gaussian is the same for both diagonal and full-covariance cases.\n  mean = d[Ellipsis, None] * t0[Ellipsis, None]\n\n  # The variance of the Gaussian is calculated differently for diagonal and full-covariance cases.\n  if diag:\n    cov_diag = jnp.zeros_like(mean)\n    cov_diag = cov_diag.at[Ellipsis, 0].set(radius**2)\n    cov_diag = cov_diag.at[Ellipsis, 1].set(radius**2)\n    cov_diag = cov_diag.at[Ellipsis, 2].set(radius**2 * (t1 - t0)**2)\n  else:\n    cov_diag = jnp.zeros_like(mean)\n    cov_diag = cov_diag.at[Ellipsis, 0, 0].set(radius**2)\n    cov_diag = cov_diag.at[Ellipsis, 1, 1].set(radius**2)\n    cov_diag = cov_diag.at[Ellipsis, 2, 2].set(radius**2 * (t1 - t0)**2)\n    cov_diag = cov_diag.at[Ellipsis, 1, 0].set(0)\n    cov_diag = cov_diag.at[Ellipsis, 0, 1].set(0)\n    cov_diag = cov_diag.at[Ellipsis, 2, 0].set(radius**2 * (t1 - t0))\n    cov_diag = cov_diag.at[Ellipsis, 2, 1].set(radius**2 * (t1 - t0))\n    cov_diag = cov_diag.at[Ellipsis, 0, 2].set(radius**2 * (t1 - t0))\n    cov_diag = cov_diag.at[Ellipsis,"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  # A more stable version of Equation 7 from https://arxiv.org/abs/2103.13415.\n  s = t0 + t1\n  d = t1 - t0\n  eps = jnp.finfo(jnp.float32).eps ** 2\n  ratio = d**2 / jnp.maximum(eps, 3 * s**2 + d**2)\n  t_mean = s * (1 / 2 + ratio)\n  t_var = (1 / 12) * d**2 - (1 / 15) * ratio**2 * (12 * s**2 - d**2)\n  r_var = (1 / 16) * s**2 + d**2 * (5 / 48 - (1 / 15) * ratio)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  # A more stable version of Equation 7 from https://arxiv.org/abs/2103.13415.\n  s = t0 + t1\n  d = t1 - t0\n  eps = jnp.finfo(jnp.float32).eps ** 2\n  ratio = d**2 / jnp.maximum(eps, 3 * s**2 + d**2)\n  t_mean = s * (1 / 2 + ratio)\n  t_var = (1 / 12) * d**2 - (1 / 15) * ratio**2 * (12 * s**2 - d**2)\n  r_var = (1 / 16) * s**2 + d**2 * (5 / 48 - (1 / 15) * ratio)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  # A more stable version of Equation 7 from https://arxiv.org/abs/2103.13415.\n  s = t0 + t1\n  d = t1 - t0\n  eps = jnp.finfo(jnp.float32).eps ** 2\n  ratio = d**2 / jnp.maximum(eps, 3 * s**2 + d**2)\n  t_mean = s * (1 / 2 + ratio)\n  t_var = (1 / 12) * d**2 - (1 / 15) * ratio**2 * (12 * s**2 - d**2)\n  r_var = (1 / 16) * s**2 + d**2 * (5 / 48 - (1 / 15) * ratio)\n\n  # The radius is squared to account for the radius^2 term in the covariance matrix.\n  r_var *= radius**2\n\n  # The mean and covariance are lifted to 3D coordinates.\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  # Calculate the mean of the Gaussian by using the formula for the mean of a Gaussian and the starting and ending distances of the cylinder.\n  mean = d[Ellipsis, None] * t0[Ellipsis, None]\n\n  # Calculate the variance of the Gaussian by using the formula for the variance of a Gaussian and the starting and ending distances of the cylinder.\n  d_mag_sq = jnp.maximum(1e-10, jnp.sum(d**2, axis=-1, keepdims=True))\n  d_outer_diag = d**2\n  null_outer_diag = 1 - d_outer_diag / d_mag_sq\n  t_cov_diag = t1**2 - t0**2\n  xy_cov_diag = radius**2\n  cov_diag = t_cov_diag + xy_cov_diag\n\n  # If the covariance matrix is not diagonal, use the formula for the covariance of a Gaussian and the starting and ending distances of the cylinder to calculate the full covariance matrix.\n  if not diag:\n    d_outer = d[Ellipsis, :, None] * d[Ellipsis, None, :]\n    eye = jnp.eye(d.shape[-1])\n    null_outer = eye - d[Ellipsis, :, None] * (d / d_mag_sq)[Ellipsis, None, :]\n    t_cov = t1**2 - t0**2\n    xy_cov = radius**2\n    cov = t_cov + xy_cov\n\n  # Return a tuple representing a Gaussian distribution, which includes the mean and covariance of the approximated cylinder.\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var * radius**2, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var = gaussianize_frustum(t0, t1)\n  r_var = radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Compute the ray directions in camera coordinates.\n  if camtype == ProjectionType.PERSPECTIVE:\n    # Perspective camera ray directions.\n    directions = xnp.stack(\n        [\n            (pix_x_int - pixtocams[Ellipsis, 0, 2]) / pixtocams[Ellipsis, 0, 0],\n            (pix_y_int - pixtocams[Ellipsis, 1, 2]) / pixtocams[Ellipsis, 1, 1],\n            -1.0 / pixtocams[Ellipsis, 2, 2],\n        ],\n        axis=-1,\n    )\n  elif camtype == ProjectionType.FISHEYE:\n    # Fisheye camera ray directions.\n    origins = xnp.stack(\n        [\n            (pix_x_int - pixtocams[Ellipsis, 0, 2]) / pixtocams[Ellipsis, 0, 0],\n            (pix_y_int - pixtocams[Ellipsis, 1, 2]) / pixtocams[Ellipsis, 1, 1],\n        ],\n        axis=-1,\n    )\n    r = xnp.linalg.norm(origins, axis=-1, keepdims=True)\n    directions = origins / r\n  elif camtype == ProjectionType.PANORAMIC:\n    # Panoramic camera ray directions.\n    origins = xnp.stack(\n        [\n            (pix_x_int - pixtocams[Ellipsis, 0, 2]) / pixtocams[Ellipsis, 0, 0],\n            (pix_y_int - pixtocams[Ellipsis, 1, 2]) / pixtocams[Ellipsis, 1, 1],\n        ],\n        axis=-1,\n    )\n    r = xnp.linalg.norm(origins, axis=-1"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Compute ray origins and directions in camera space.\n  if camtype == ProjectionType.PERSPECTIVE:\n    # Project pixels to 3D rays in camera space.\n    origins = xnp.tile(xnp.array([0.0, 0.0, 0.0]), reps=[len(pix_x_int), 1])\n    x = (pix_x_int - pixtocams[Ellipsis, 0, 2]) / pixtocams[Ellipsis, 0, 0]\n    y = (pix_y_int - pixtocams[Ellipsis, 1, 2]) / pixtocams[Ellipsis, 1, 1]\n    z = xnp.ones(x.shape)\n    directions = xnp.stack([x, y, z], axis=-1)\n  elif camtype == ProjectionType.FISHEYE:\n    # Project pixels to 3D rays in camera space.\n    origins = xnp.tile(xnp.array([0.0, 0.0, 0.0]), reps=[len(pix_x_int), 1])\n    x, y = _radial_and_tangential_undistort(\n        xd=pix_x_int,\n        yd=pix_y_int,\n        k1=distortion_params['k1'],\n        k2=distortion_params['k2'],\n        k3=distortion_params['k3'],\n        k4=distortion_params['k4'],\n        p1=distortion_params['p1'],\n        p2=distortion_params['p2'],\n        xnp=xnp,\n    )\n    z = xnp.ones(x.shape)\n    directions = xnp.stack([x, y, z], axis=-1)\n  elif camtype == ProjectionType.PANORAMIC:\n    # Project pixels to 3D rays in camera space.\n    origins = xnp.t"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Compute rays from pixel coordinates.\n  if camtype == ProjectionType.PERSPECTIVE:\n    # Perspective pinhole camera.\n    pixvec = xnp.stack(\n        [\n            (pix_x_int - pixtocams[:, 0, 2]) / pixtocams[:, 0, 0],\n            (pix_y_int - pixtocams[:, 1, 2]) / pixtocams[:, 1, 1],\n            -xnp.ones_like(pix_x_int),\n        ],\n        -1,\n    )\n  elif camtype == ProjectionType.FISHEYE:\n    # Fisheye camera.\n    pixvec = xnp.stack(\n        [\n            (pix_x_int - pixtocams[:, 0, 2]) / pixtocams[:, 0, 0],\n            (pix_y_int - pixtocams[:, 1, 2]) / pixtocams[:, 1, 1],\n            -xnp.ones_like(pix_x_int),\n        ],\n        -1,\n    )\n    pixvec = _radial_and_tangential_undistort(\n        pixvec[:, :2],\n        k1=distortion_params['k1'],\n        k2=distortion_params['k2'],\n        k3=distortion_params['k3'],\n        p1=distortion_params['p1'],\n        p2=distortion_params['p2'],\n    )\n    pixvec = xnp.concatenate([pixvec, -xnp.ones_like(pix_x_int)[:, :1]], -1)\n  elif camtype == ProjectionType.PANORAMIC:\n    # Panoramic camera.\n    pixvec = xnp.stack(\n        [\n            (pix_x_int - pixtocams[:, 0, 2]) / pixtocams[:, 0, 0],\n           "}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Compute pixel coordinates in the camera coordinate system.\n  pix_x, pix_y = xnp.broadcast_arrays(\n      xnp.expand_dims(pix_x_int, axis=-1),\n      xnp.expand_dims(pix_y_int, axis=-1)\n  )\n  pix_x = xnp.asarray(pix_x, dtype=xnp.float32)\n  pix_y = xnp.asarray(pix_y, dtype=xnp.float32)\n  pix_x = xnp.reshape(pix_x, (-1,))\n  pix_y = xnp.reshape(pix_y, (-1,))\n\n  # Correct for lens distortion.\n  if distortion_params is not None:\n    k1 = distortion_params['k1']\n    k2 = distortion_params['k2']\n    k3 = distortion_params['k3']\n    p1 = distortion_params['p1']\n    p2 = distortion_params['p2']\n    pix_x, pix_y = _radial_and_tangential_undistort(\n        xd=pix_x, yd=pix_y, k1=k1, k2=k2, k3=k3, p1=p1, p2=p2\n    )\n\n  # Convert pixel coordinates to camera coordinates.\n  pix_x = xnp.expand_dims(pix_x, axis=-1)\n  pix_y = xnp.expand_dims(pix_y, axis=-1)\n  pix_z = xnp.ones_like(pix_x)\n  pix_cam = xnp.concatenate([pix_x, pix_y, pix_z], axis=-1)\n  pix_cam = xnp.reshape(pix_cam, (-1, 3))\n  pix_cam = xnp.dot(pixtocams, pix_cam.T).T\n  pix_cam = x"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Compute pixel coordinates.\n  pix_x = xnp.array(pix_x_int, dtype=xnp.float32)\n  pix_y = xnp.array(pix_y_int, dtype=xnp.float32)\n\n  # Compute camera rays.\n  if camtype == ProjectionType.PERSPECTIVE:\n    # Perspective projection.\n    xy_cam = xnp.stack([pix_x, pix_y], axis=-1)\n    origins = xnp.broadcast_to(camtoworlds[Ellipsis, 3], xy_cam.shape)\n    directions = xnp.linalg.inv(pixtocams) @ xnp.concatenate([xy_cam, -xnp.ones_like(xy_cam)], axis=-1)[Ellipsis, :3]\n    viewdirs = normalize(directions)\n    radii = xnp.ones_like(xy_cam)[Ellipsis, :1]\n    imageplane = xy_cam\n  elif camtype == ProjectionType.FISHEYE:\n    # Fisheye projection.\n    xy_cam = xnp.stack([pix_x, pix_y], axis=-1)\n    origins = xnp.broadcast_to(camtoworlds[Ellipsis, 3], xy_cam.shape)\n    directions = xnp.linalg.inv(pixtocams) @ xnp.concatenate([xy_cam, xnp.ones_like(xy_cam)], axis=-1)[Ellipsis, :3]\n    viewdirs = normalize(directions)\n    radii = xnp.ones_like(xy_cam)[Ellipsis, :1]\n    imageplane = xy_cam\n  elif camtype == ProjectionType.PANORAMIC:\n    # Panoramic projection.\n    xy_cam = xnp.stack([pix_x, pix_y], axis=-1)\n    origins = xnp."}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Compute the ray directions.\n  if camtype == ProjectionType.PERSPECTIVE:\n    # Compute ray directions for perspective cameras.\n    cam_x = (pix_x_int - pixtocams[Ellipsis, 0, 2]) / pixtocams[Ellipsis, 0, 0]\n    cam_y = (pix_y_int - pixtocams[Ellipsis, 1, 2]) / pixtocams[Ellipsis, 1, 1]\n    directions = xnp.stack([cam_x, cam_y, xnp.ones_like(cam_y)], -1)\n    directions = directions[Ellipsis, None, :]\n  elif camtype == ProjectionType.FISHEYE:\n    # Compute ray directions for fisheye cameras.\n    cam_x = (pix_x_int - pixtocams[Ellipsis, 0, 2]) / pixtocams[Ellipsis, 0, 0]\n    cam_y = (pix_y_int - pixtocams[Ellipsis, 1, 2]) / pixtocams[Ellipsis, 1, 1]\n    cam_r = xnp.sqrt(cam_x * cam_x + cam_y * cam_y)\n    directions = xnp.stack([cam_x, cam_y, xnp.ones_like(cam_y)], -1)\n    directions = directions / (directions[Ellipsis, 2:] + 1e-8)\n    directions = directions[Ellipsis, None, :]\n  elif camtype == ProjectionType.PANORAMIC:\n    # Compute ray directions for panoramic cameras.\n    cam_x = (pix_x_int - pixtocams[Ellipsis, 0, 2]) / pixtocams[Ellipsis, 0, 0]\n    cam_y = (pix_y_int - pixtocams[El"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Broadcast arrays.\n  pix_x_int = xnp.broadcast_to(pix_x_int, camtoworlds.shape[:-1])\n  pix_y_int = xnp.broadcast_to(pix_y_int, camtoworlds.shape[:-1])\n\n  # Convert pixel coordinates to camera coordinates.\n  if distortion_params is not None:\n    # Apply distortion correction.\n    xy_undistorted = _radial_and_tangential_undistort(\n        xd=xnp.broadcast_to(pix_x_int, camtoworlds.shape[:-1]),\n        yd=xnp.broadcast_to(pix_y_int, camtoworlds.shape[:-1]),\n        **distortion_params,\n    )\n    pix_x_int = xy_undistorted[Ellipsis, 0]\n    pix_y_int = xy_undistorted[Ellipsis, 1]\n\n  pix_x_float = xnp.broadcast_to(pix_x_int.astype(xnp.float32), camtoworlds.shape[:-1])\n  pix_y_float = xnp.broadcast_to(pix_y_int.astype(xnp.float32), camtoworlds.shape[:-1])\n  pix_x_float = xnp.expand_dims(pix_x_float, axis=-1)\n  pix_y_float = xnp.expand_dims(pix_y_float, axis=-1)\n  pix_x_float = xnp.broadcast_to(pix_x_float, camtoworlds.shape[:-1] + (1,))\n  pix_y_float = xnp.broadcast_to(pix_y_float, camtoworlds.shape[:-1] + (1,))\n  pix_xy = xnp.concatenate([pix_x_float"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Broadcast camera matrices to match pixel dimensions.\n  n_pixels = pix_x_int.shape[0]\n  if pixtocams.ndim == 2:\n    pixtocams = xnp.broadcast_to(pixtocams, (n_pixels, 3, 3))\n  elif pixtocams.ndim == 3:\n    pixtocams = xnp.broadcast_to(pixtocams, (n_pixels,) + pixtocams.shape[-2:])\n  if camtoworlds.ndim == 2:\n    camtoworlds = xnp.broadcast_to(camtoworlds, (n_pixels, 3, 4))\n  elif camtoworlds.ndim == 3:\n    camtoworlds = xnp.broadcast_to(camtoworlds, (n_pixels,) + camtoworlds.shape[-2:])\n\n  # Convert pixel coordinates to camera coordinates.\n  pixvecs = xnp.stack(\n      [pix_x_int - xnp.array(pixtocams.shape[-1]) / 2.0,\n       pix_y_int - xnp.array(pixtocams.shape[-2]) / 2.0],\n      axis=-1\n  )\n  pixvecs = xnp.moveaxis(pixvecs, -1, -2)\n  camvecs = xnp.linalg.inv(pixtocams) @ pixvecs\n\n  # Convert camera coordinates to world coordinates.\n  origins = xnp.linalg.inv(camtoworlds) @ xnp.concatenate([camvecs, xnp.ones_like(camvecs[Ellipsis, :1])], axis=-1)[Ellipsis, :3]\n\n  # Convert camera coordinates to world directions.\n  directions = xnp.linalg.inv(camtoworlds[Ellipsis, :3, :3]) @ camvecs"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Compute pixel coordinates.\n  pix_x = xnp.array(pix_x_int, dtype=xnp.float32)\n  pix_y = xnp.array(pix_y_int, dtype=xnp.float32)\n\n  # Compute the ray directions in camera coordinates, and normalize them.\n  if camtype == ProjectionType.PERSPECTIVE:\n    # Perspective camera projection.\n    directions = xnp.stack([pix_x, pix_y, xnp.ones_like(pix_x)], -1)\n    directions = directions[Ellipsis, None]\n    directions = xnp.linalg.inv(pixtocams) @ directions\n    directions = directions[Ellipsis, 0]\n    directions /= directions[Ellipsis, 2:]\n  elif camtype == ProjectionType.FISHEYE:\n    # Fisheye camera projection.\n    # The ray directions are computed as the inverse of the pinhole projection.\n    # The pinhole projection is computed as the inverse of the pinhole camera\n    # intrinsics, and then the ray directions are normalized.\n    directions = xnp.stack([pix_x, pix_y, xnp.ones_like(pix_x)], -1)\n    directions = directions[Ellipsis, None]\n    directions = xnp.linalg.inv(pixtocams) @ directions\n    directions = directions[Ellipsis, 0]\n    directions /= directions[Ellipsis, 2:]\n    directions = _radial_and_tangential_undistort(\n        directions[Ellipsis, 0],\n        directions[Ellipsis, 1],\n        k1=distortion_params['k1'],\n        k2=distortion_params['k2'],\n        k3=distortion_params['k3'],\n        k4=distortion_params['k4'],\n        p1=distortion_params['p1'],\n        p2=distortion_params['p2'],"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Convert pixel coordinates to camera coordinates.\n  pixvecs = xnp.stack([\n      xnp.broadcast_to(pix_x_int, pix_x_int.shape + (1,)),\n      xnp.broadcast_to(pix_y_int, pix_y_int.shape + (1,)),\n      xnp.ones(pix_x_int.shape + (1,))\n  ],\n                      axis=-1)\n  camvecs = xnp.matmul(pixvecs, pixtocams)\n\n  # Apply optional distortion correction.\n  if distortion_params is not None:\n    # Apply distortion correction to the camera coordinates.\n    k1 = distortion_params['k1']\n    k2 = distortion_params['k2']\n    k3 = distortion_params['k3']\n    p1 = distortion_params['p1']\n    p2 = distortion_params['p2']\n    xd = camvecs[Ellipsis, 0]\n    yd = camvecs[Ellipsis, 1]\n    x, y = _radial_and_tangential_undistort(\n        xd, yd, k1=k1, k2=k2, k3=k3, p1=p1, p2=p2)\n    camvecs[Ellipsis, 0] = x\n    camvecs[Ellipsis, 1] = y\n\n  # Convert camera coordinates to world coordinates.\n  rays_d = xnp.matmul(camvecs, camtoworlds[Ellipsis, :3, :3])\n  rays_o = xnp.broadcast_to(\n      camtoworlds[Ellipsis, :3, 3], rays_d.shape[:-1] + (3,))\n\n  # Compute ray view directions and normalized ray view directions.\n  viewdirs = rays_d / xnp.linalg.norm(rays_"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Compute pixel coordinates in normalized device coordinates (NDC)\n  pix_x = xnp.float32(pix_x_int)\n  pix_y = xnp.float32(pix_y_int)\n  if pixtocam_ndc is None:\n    pixtocam_ndc = xnp.array([[1.0, 0.0, 0.0], [0.0, -1.0, 0.0], [0.0, 0.0, -1.0]])\n  pix_x_ndc = pix_x\n  pix_y_ndc = 1.0 - pix_y\n\n  # Convert pixel coordinates to camera coordinates\n  pix_x_cam = xnp.expand_dims(pix_x_ndc, -1)\n  pix_y_cam = xnp.expand_dims(pix_y_ndc, -1)\n  pix_cam = xnp.concatenate([pix_x_cam, pix_y_cam], -1)\n  ray_cam = xnp.linalg.inv(pixtocams) @ pix_cam[Ellipsis, None]\n  ray_cam = xnp.squeeze(ray_cam, -1)\n\n  # Apply distortion to camera coordinates\n  if distortion_params is not None:\n    k1 = distortion_params['k1']\n    k2 = distortion_params['k2']\n    k3 = distortion_params['k3']\n    p1 = distortion_params['p1']\n    p2 = distortion_params['p2']\n    ray_cam_x, ray_cam_y = _radial_and_tangential_undistort(\n        ray_cam[:, 0],\n        ray_cam[:, 1],\n        k1=k1,\n        k2=k2,\n        k3=k3,\n        p1=p1,\n        p2=p2,\n        xnp=xnp,\n    )"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Convert pixel coordinates to camera coordinates.\n  pixvecs = xnp.stack(\n      [\n          xnp.broadcast_to(pix_x_int, pix_y_int.shape),\n          xnp.broadcast_to(pix_y_int, pix_y_int.shape),\n          xnp.ones(pix_y_int.shape)\n      ],\n      axis=-1,\n  )\n  camvecs = (pixtocams @ pixvecs[Ellipsis, None]).squeeze(-1)\n\n  # Optionally correct for distortion.\n  if distortion_params is not None:\n    k1 = distortion_params['k1']\n    k2 = distortion_params['k2']\n    k3 = distortion_params['k3']\n    p1 = distortion_params['p1']\n    p2 = distortion_params['p2']\n    camvecs[Ellipsis, 0], camvecs[Ellipsis, 1] = _radial_and_tangential_undistort(\n        camvecs[Ellipsis, 0], camvecs[Ellipsis, 1], k1, k2, k3, p1, p2\n    )\n\n  # Convert camera coordinates to world coordinates.\n  ray_dirs = (camtoworlds @ xnp.concatenate(\n      [camvecs, xnp.broadcast_to(xnp.ones(camvecs.shape[:-1]), camvecs.shape[:-1] + (1,))],\n      axis=-1,\n  )[Ellipsis, None])[Ellipsis, 0]\n\n  # Optionally convert to Normalized Device Coordinates (NDC) space.\n  if pixtocam_ndc is not None:\n    ray_dirs = (pixtocam_ndc @ ray_dirs[Ellipsis, None])[Ellipsis, 0]\n\n  # Compute ray origin and view direction."}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Compute the rays from camera parameters and pixel coordinates.\n  pixvec = xnp.stack(\n      [\n          xnp.reshape(pix_x_int, [-1]),\n          xnp.reshape(pix_y_int, [-1]),\n          xnp.ones(xnp.prod(pix_x_int.shape), dtype=xnp.float32),\n      ],\n      -1,\n  )\n  pixvec = xnp.reshape(pixvec, list(pix_x_int.shape) + [3])\n\n  # Correct for lens distortion.\n  if distortion_params is not None:\n    k1 = distortion_params['k1']\n    k2 = distortion_params['k2']\n    k3 = distortion_params['k3']\n    p1 = distortion_params['p1']\n    p2 = distortion_params['p2']\n    pixvec = xnp.stack(\n        _radial_and_tangential_undistort(\n            pixvec[Ellipsis, 0],\n            pixvec[Ellipsis, 1],\n            k1=k1,\n            k2=k2,\n            k3=k3,\n            p1=p1,\n            p2=p2,\n        ),\n        -1,\n    )\n\n  # Transform pixel coordinates to camera coordinates.\n  pixvec = xnp.einsum('...ij,...iq->...jq', pixtocams, pixvec)\n\n  # Transform camera coordinates to world coordinates.\n  camvec = xnp.concatenate([pixvec, xnp.ones_like(pixvec[Ellipsis, :1])], -1)\n  camvec = xnp.einsum('...ij,...iq->...jq', camtoworlds, camvec)\n\n  # Compute ray direction vectors in world coordinates.\n  if camtype == ProjectionType.PERSPECTIVE:\n    directions = camvec[Ellipsis, :"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Compute the ray directions.\n  pixvecs = xnp.stack(\n      [\n          xnp.reshape(pix_x_int, [-1]),\n          xnp.reshape(pix_y_int, [-1]),\n          xnp.ones_like(pix_x_int),\n      ],\n      axis=-1,\n  )\n  camvecs = xnp.linalg.inv(pixtocams) @ pixvecs[Ellipsis, None]\n  if camtype == ProjectionType.PERSPECTIVE:\n    # Convert the camera vectors to unit vectors.\n    camvecs = camvecs / xnp.linalg.norm(camvecs, axis=-1, keepdims=True)\n    # Compute the ray directions.\n    directions = camtoworlds[Ellipsis, :3, None] @ camvecs\n  elif camtype == ProjectionType.FISHEYE:\n    # Compute the ray directions.\n    directions = camtoworlds[Ellipsis, :3, None] @ camvecs\n    # Normalize the ray directions.\n    directions = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n  elif camtype == ProjectionType.PANORAMIC:\n    # Compute the ray directions.\n    directions = camtoworlds[Ellipsis, :3, None] @ camvecs\n    # Normalize the ray directions.\n    directions = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n  else:\n    raise ValueError('Unknown camera type: ' + camtype)\n\n  # Compute the ray origins.\n  origins = camtoworlds[Ellipsis, None, :3, 3]\n\n  # Compute the ray view directions.\n  viewdirs = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n\n  # Compute the ray differential radii.\n  radii = xnp."}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Compute the rays in camera coordinates.\n  if camtype == ProjectionType.PERSPECTIVE:\n    pix_x = xnp.float32(pix_x_int)\n    pix_y = xnp.float32(pix_y_int)\n    # Convert the pixel coordinates to camera coordinates.\n    cam_x, cam_y = _radial_and_tangential_undistort(\n        pix_x,\n        pix_y,\n        k1=distortion_params['k1'],\n        k2=distortion_params['k2'],\n        k3=distortion_params['k3'],\n        p1=distortion_params['p1'],\n        p2=distortion_params['p2'],\n    )\n    # Convert the camera coordinates to world coordinates.\n    cam_x, cam_y, cam_z = xnp.moveaxis(xnp.dot(pixtocams, xnp.stack(\n        [cam_x, cam_y, xnp.ones_like(pix_x)], axis=-1)), -1, -2)\n    directions = xnp.stack(\n        xnp.dot(camtoworlds[Ellipsis, :3, :3], xnp.stack([cam_x, cam_y, cam_z],\n                                                         axis=-1)),\n        axis=-2)\n    origins = xnp.broadcast_to(camtoworlds[Ellipsis, :3, 3], directions.shape)\n    # Normalize the directions.\n    viewdirs = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n    # Compute the differential radius of the rays.\n    radii = xnp.linalg.norm(directions, axis=-1, keepdims=True)\n  elif camtype == ProjectionType.FISHEYE:\n    # Convert the pixel coordinates to camera coordinates.\n    cam_x, cam_y = _radial_and_tangential_undistort(\n       "}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Broadcast inputs to match the number of pixels.\n  n_pixels = pix_x_int.shape[0]\n  pixtocams = xnp.broadcast_to(pixtocams, [n_pixels] + list(pixtocams.shape[1:]))\n  camtoworlds = xnp.broadcast_to(camtoworlds, [n_pixels] + list(camtoworlds.shape[1:]))\n\n  # Convert pixel coordinates to camera coordinates.\n  pixvecs = xnp.stack([\n      xnp.reshape(pix_x_int, [-1]),\n      xnp.reshape(pix_y_int, [-1]),\n      xnp.ones([n_pixels])\n  ],\n                      axis=-1)\n  camvecs = xnp.linalg.inv(pixtocams) @ pixvecs[..., None]\n\n  # Convert camera coordinates to world coordinates.\n  origins = xnp.linalg.inv(camtoworlds) @ xnp.concatenate([camvecs, xnp.ones_like(camvecs)], axis=-1)[..., :3]\n  directions = xnp.linalg.inv(camtoworlds[Ellipsis, :3, :3]) @ camvecs[Ellipsis, :3]\n\n  # Apply distortion correction to the rays.\n  if distortion_params is not None:\n    origins, directions = correct_distortion(\n        origins, directions, distortion_params, xnp=xnp\n    )\n\n  # Normalize the ray directions.\n  viewdirs = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n\n  # Compute the differential radius of the rays, useful for mip-NeRF cones.\n  radii = xnp.linalg.norm(origins - directions, axis=-1, keepdims=True)\n\n  # Convert ray origins and directions into N"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Compute rays from pixel coordinates.\n  if camtype == ProjectionType.FISHEYE:\n    # Fisheye projection.\n    pixvec = xnp.stack([pix_x_int, pix_y_int, xnp.ones_like(pix_x_int)], -1)\n    camvec = xnp.linalg.inv(pixtocams) @ pixvec[Ellipsis, None]\n    # Ignore z dimension.\n    camvec = camvec[Ellipsis, :2]\n    # Normalize to get direction.\n    directions = xnp.linalg.norm(camvec, axis=-1, keepdims=True)\n    directions /= directions[Ellipsis, -1:]\n    directions = camvec / directions\n    origins = xnp.zeros_like(directions)\n  elif camtype == ProjectionType.PANORAMIC:\n    # Panoramic projection.\n    # Map pixel coordinates to 3D coordinates on the sphere.\n    theta = 2.0 * np.pi * pix_x_int / pixtocams[Ellipsis, 0, 0]\n    phi = (np.pi * pix_y_int / pixtocams[Ellipsis, 1, 1] - 0.5 * np.pi).clip(\n        -0.999999 * np.pi, 0.999999 * np.pi\n    )\n    directions = xnp.stack(\n        [xnp.cos(theta) * xnp.sin(phi), xnp.sin(theta) * xnp.sin(phi), xnp.cos(phi)],\n        axis=-1,\n    )\n    origins = xnp.zeros_like(directions)\n  else:\n    # Perspective projection.\n    # Transform pixel coordinates to camera coordinates.\n    pixvec = xnp.stack([pix_x_int, pix_y_int, xnp.ones_like(pix_x_int)], -1)\n    camvec"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Get pixel coordinates in the camera coordinate system.\n  pix_x, pix_y = xnp.broadcast_arrays(\n      xnp.expand_dims(pix_x_int, -1),\n      xnp.expand_dims(pix_y_int, -1),\n  )\n  cam_x, cam_y = _radial_and_tangential_undistort(\n      xd=pix_x,\n      yd=pix_y,\n      k1=distortion_params['k1'] if distortion_params else 0.0,\n      k2=distortion_params['k2'] if distortion_params else 0.0,\n      k3=distortion_params['k3'] if distortion_params else 0.0,\n      p1=distortion_params['p1'] if distortion_params else 0.0,\n      p2=distortion_params['p2'] if distortion_params else 0.0,\n      xnp=xnp,\n  )\n  cam_x = xnp.squeeze(cam_x, -1)\n  cam_y = xnp.squeeze(cam_y, -1)\n\n  # Convert to NDC space if requested.\n  if pixtocam_ndc is not None:\n    cam_x = cam_x / (xnp.shape(cam_x)[-2] - 1.0) * 2.0 - 1.0\n    cam_y = cam_y / (xnp.shape(cam_y)[-1] - 1.0) * 2.0 - 1.0\n\n  # Convert to rays in camera space.\n  if camtype == ProjectionType.PERSPECTIVE:\n    # Perspective camera case.\n    directions = xnp.stack(\n        [cam_x, cam_y, xnp.ones_like(cam_x)],\n        axis=-1,\n    )\n    origins = xnp.broadcast_to(\n       "}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Extract the camera parameters.\n  focal = pixtocams[:, :1, :1]\n  principal_point = pixtocams[:, :2, 2:3]\n  aspect_ratio = pixtocams[:, :1, :1] / pixtocams[:, :1, :1]\n\n  # Convert pixel coordinates to camera coordinates.\n  if distortion_params is not None:\n    # Convert pixel coordinates to camera coordinates with distortion correction.\n    # Convert pixel coordinates to NDC coordinates.\n    pix_x_ndc = (pix_x_int - principal_point[:, 0]) / focal[:, 0]\n    pix_y_ndc = (pix_y_int - principal_point[:, 1]) / focal[:, 1]\n    pix_x_ndc_dist = pix_x_ndc * (1 + distortion_params['k1'] * pix_x_ndc**2)\n    pix_y_ndc_dist = pix_y_ndc * (1 + distortion_params['k1'] * pix_y_ndc**2)\n\n    # Convert NDC coordinates to camera coordinates.\n    pix_x_cam = pix_x_ndc_dist * aspect_ratio\n    pix_y_cam = pix_y_ndc_dist\n\n    # Convert camera coordinates to world coordinates.\n    pix_x_cam = pix_x_cam * 2.0 - 1.0\n    pix_y_cam = pix_y_cam * 2.0 - 1.0\n    pix_cam = xnp.stack([pix_x_cam, pix_y_cam], -1)\n    pix_cam = xnp.concatenate([pix_cam, xnp.ones_like(pix_x_cam[Ellipsis, :1])], -1)\n    ray_origins = xnp.matmul(pix_cam[Ellipsis, None, :], camtoworlds[Ellipsis, None, :3, :4])[Elli"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Compute the rays for each camera.\n  if camtype == ProjectionType.PERSPECTIVE:\n    # Perspective camera rays.\n    #\n    # Note that we use the inverse of pixtocam to get pixel coordinates in\n    # camera space, and then multiply by the inverse of camtoworld to get\n    # world space rays. We could have also done this with a single matrix\n    # multiplication, but this is easier to read.\n    cam_pix = xnp.stack([\n        pix_x_int - pixtocams[Ellipsis, 0, 2], pix_y_int - pixtocams[Ellipsis, 1, 2]\n    ], -1)\n    cam_pix_undist = xnp.where(\n        xnp.any(distortion_params is not None, -1),\n        _radial_and_tangential_undistort(\n            cam_pix[Ellipsis, 0], cam_pix[Ellipsis, 1], **distortion_params\n        ), cam_pix)\n    cam_dirs = xnp.linalg.inv(pixtocams)[Ellipsis, :3, :3] @ cam_pix_undist[Ellipsis,\n                                                                           None]\n    origins = xnp.broadcast_to(camtoworlds[Ellipsis, :3, 3], cam_dirs.shape)\n    directions = (camtoworlds[Ellipsis, :3, :3] @ cam_dirs).reshape(origins.shape)\n  elif camtype == ProjectionType.FISHEYE:\n    # Fisheye camera rays.\n    #\n    # Note that we use the inverse of pixtocam to get pixel coordinates in\n    # camera space, and then multiply by the inverse of camtoworld to get\n    # world space rays. We could have also done this with a single matrix\n    # multiplication, but this is easier to read.\n    cam_pix = xnp"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist / jnp.linalg.norm(dirs, axis=-1)\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist / jnp.linalg.norm(dirs, axis=-1)\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist / jnp.linalg.norm(dirs, axis=-1)\n\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = jnp.cumprod(density * tdist, axis=-1)\n\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  # Adjust the distance between points by the norm of the direction vectors.\n  density_delta = density * jnp.linalg.norm(dirs, axis=-1) * tdist\n\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist / jnp.linalg.norm(dirs, axis=-1)\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  # Compute the density-adjusted distances between points\n  density_delta = density * tdist\n\n  # Compute the alpha compositing weights\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  # Adjust the density values with the distance between points\n  density_delta = density * tdist\n\n  # Compute the alpha weights\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = jnp.concatenate([\n      density[Ellipsis, :1] * tdist[Ellipsis, :1],\n      density[Ellipsis, :-1] * tdist[Ellipsis, :-1] *\n      math.norm(dirs[Ellipsis, :-1] - dirs[Ellipsis, 1:]),\n  ],\n                                 axis=-1)\n\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist / jnp.linalg.norm(dirs, axis=-1)\n  weights = compute_alpha_weights_helper(density_delta, **kwargs)\n\n  return weights\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  # Compute the adjusted distance between points using the direction vectors\n  dirs_norm = math.safe_norm(dirs, axis=-1)\n  dirs_norm = jnp.where(dirs_norm == 0, 1, dirs_norm)\n  dirs_norm = dirs_norm[Ellipsis, jnp.newaxis]\n  dirs_norm_adj = dirs / dirs_norm\n  tdist_adj = jnp.sum(tdist * dirs_norm_adj, axis=-1)\n\n  # Compute the product of density and adjusted distance\n  density_delta = density * tdist_adj\n\n  # Compute the alpha compositing weights\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * jnp.linalg.norm(dirs, axis=-1) * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist / jnp.linalg.norm(dirs, axis=-1)\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  # Adjust the distances between points based on the norm of the direction vectors\n  norm_adjusted_dist = jnp.linalg.norm(dirs, axis=-1) * tdist\n\n  # Compute the product of the density values and the adjusted distances\n  density_delta = density * norm_adjusted_dist\n\n  # Compute the alpha weights\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  # Compute the adjusted distance between points\n  density_delta = density * math.norm_adjusted_distance(tdist, dirs)\n\n  # Compute the alpha compositing weights\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * (tdist / jnp.linalg.norm(dirs, axis=-1))\n\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist / jnp.linalg.norm(dirs, axis=-1)\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  # Adjust the density values using the distance between points\n  density_delta = density * tdist\n\n  # Calculate the alpha weights\n  weights = compute_alpha_weights_helper(density_delta, **kwargs)\n\n  return weights\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist / jnp.linalg.norm(dirs, axis=-1)\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Generate random samples.\n  if rng is None:\n    # Deterministic sampling.\n    if deterministic_center:\n      # Center samples in each interval.\n      u = jnp.linspace(eps, 1 - eps, num_samples)\n    else:\n      # Sample the entire PDF.\n      u = jnp.linspace(0, 1, num_samples)\n  else:\n    # Random sampling.\n    u = jax.random.uniform(rng, (num_samples,))\n    if single_jitter:\n      # Jitter all samples by the same amount.\n      u = u + jnp.random.uniform(rng, (1,))\n    else:\n      # Jitter each sample independently.\n      u = u + jnp.random.uniform(rng, (num_samples,))\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Determine the sampling method.\n  if rng is None:\n    # Deterministic sampling.\n    if deterministic_center:\n      # Centered sampling.\n      u = jnp.linspace(eps, 1 - eps, num_samples, endpoint=False)\n      u = jnp.broadcast_to(u, w_logits.shape[:-1] + (num_samples,))\n    else:\n      # Uncentered sampling.\n      u = jnp.linspace(0, 1, num_samples + 2, endpoint=False)[1:-1]\n      u = jnp.broadcast_to(u, w_logits.shape[:-1] + (num_samples,))\n  else:\n    # Random sampling.\n    if single_jitter:\n      # Single jitter.\n      u = jax.random.uniform(rng, shape=(num_samples,))\n      u = jnp.broadcast_to(u, w_logits.shape[:-1] + (num_samples,))\n    else:\n      # Independent jitter.\n      u = jax.random.uniform(rng, shape=(num_samples,) + w_logits.shape[:-1])\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Compute the jitter for each sample.\n  if rng is None:\n    # Deterministic sampling.\n    if deterministic_center:\n      # Center samples in each interval.\n      u = jnp.linspace(eps, 1 - eps, num_samples)\n      u = jnp.where(u < 0.5, u, 1 - u)\n    else:\n      # Sample the entire PDF.\n      u = jnp.linspace(eps, 1 - eps, num_samples)\n    u = jnp.expand_dims(u, axis=-1)\n  else:\n    # Random sampling.\n    if single_jitter:\n      # Jitter all samples by the same amount.\n      u = jax.random.uniform(rng, (num_samples,))\n      u = jnp.expand_dims(u, axis=-1)\n    else:\n      # Jitter all samples independently.\n      u = jax.random.uniform(rng, (num_samples, 1))\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Generate samples.\n  if rng is not None:\n    # Random sampling.\n    if single_jitter:\n      # Generate a single jittered sample for each weight vector.\n      u = jax.random.uniform(rng, (1, w.shape[-1]))\n    else:\n      # Generate a separate jittered sample for each sample and weight vector.\n      u = jax.random.uniform(rng, (num_samples, w.shape[-1]))\n    u = u * (1 - eps) + eps / 2\n    # Interpolate into the inverse CDF.\n    t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n  else:\n    # Deterministic sampling.\n    if deterministic_center:\n      # Generate samples that are centered in each interval of the PDF.\n      u = jnp.linspace(eps, 1 - eps, num_samples)\n      t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n    else:\n      # Generate samples that span the entire PDF.\n      u = jnp.linspace(0, 1, num_samples)\n      t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  # Determine the sampling method.\n  if rng is None:\n    # Deterministic sampling.\n    if deterministic_center:\n      # Centered sampling.\n      # Compute the center of each bin.\n      t_center = (t[Ellipsis, 1:] + t[Ellipsis, :-1]) / 2\n      # Sample from the center of each bin.\n      t_new = math.sorted_interp(\n          jnp.linspace(eps, 1 - eps, num_samples, dtype=jnp.float32),\n          cw,\n          t_center,\n          utils.device_is_tpu(),\n      )\n    else:\n      # Uncentered sampling.\n      # Sample from the endpoints of each bin.\n      t_new = math.sorted_interp(\n          jnp.linspace(eps, 1 - eps, num_samples, dtype=jnp.float32),\n          cw,\n          t,\n          utils.device_is_tpu(),\n      )\n  else:\n    # Random sampling.\n    # Sample from the CDF.\n    u = jax.random.uniform(rng, (num_samples,))\n    t_new = invert_cdf(u, t, w_logits)\n    # Jitter the samples.\n    if not single_jitter:\n      t_new = t_new + jax.random.uniform(rng, t_new.shape) * (t[Ellipsis, 1:] - t[Ellipsis, :-1])\n\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  # Determine the number of bins.\n  num_bins = t.shape[-1]\n\n  # Determine the number of samples per batch.\n  num_samples_per_batch = num_samples // w.shape[0]\n\n  # Determine the number of jittered samples to take per bin.\n  num_jittered_samples = 1 if single_jitter else num_bins\n\n  # Determine the number of samples to take per bin.\n  num_samples_per_bin = num_samples_per_batch // num_jittered_samples\n\n  # Determine the number of samples to take from the center of each bin.\n  num_center_samples = num_samples_per_bin // 2\n\n  # Determine the number of samples to take from the edges of each bin.\n  num_edge_samples = num_samples_per_bin - num_center_samples\n\n  # Determine the number of samples to take from the left edge of each bin.\n  num_left_edge_samples = num_edge_samples // 2\n\n  # Determine the number of samples to take from the right edge of each bin.\n  num_right_edge_samples = num_edge_samples - num_left_edge_samples\n\n  # Determine the center of each bin.\n  center = (t[Ellipsis, :-1] + t[Ellipsis, 1:]) / 2\n\n  # Determine the left edge of each bin.\n  left = t[Ellipsis, :-1]\n\n  # Determine the right edge of each bin.\n  right = t[Ellipsis, 1:]\n\n  # Determine the width of each bin.\n  width = t[Ellipsis, 1:] - t["}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Compute the range of the PDF.\n  t_min = t[..., 0]\n  t_max = t[..., -1]\n  # Compute the range of the samples.\n  if deterministic_center:\n    # If deterministic sampling is requested, use the center of the PDF.\n    t_center = (t_min + t_max) / 2\n    t_min = t_center - (t_max - t_min) / 2\n    t_max = t_center + (t_max - t_min) / 2\n  # Generate the samples.\n  if rng is None:\n    # Deterministic sampling.\n    t_samples = jnp.linspace(t_min, t_max, num_samples, axis=-1)\n  else:\n    # Random sampling.\n    t_samples = jax.random.uniform(\n      rng,\n      (num_samples,),\n      minval=t_min + eps,\n      maxval=t_max - eps,\n      dtype=jnp.float32,\n    )\n    if single_jitter:\n      # Jitter all samples by the same amount.\n      t_samples += jax.random.uniform(\n        rng,\n        (1,),\n        minval=-0.5,\n        maxval=0.5,\n        dtype=jnp.float32,\n      )\n    else:\n      # Jitter each sample independently.\n      t_samples += jax.random.uniform(\n        rng,\n        (num_samples,),\n        minval=-0.5,\n        maxval=0.5,\n        dtype=jnp.float32,\n      )\n  # Interpolate into the inverse CDF.\n  t_samples = math.sorted_interp("}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Sample the inverse CDF.\n  u = jax.random.uniform(rng, (num_samples,))\n  t_new = invert_cdf(u, t, w_logits)\n  # Jitter samples.\n  if single_jitter:\n    t_new = t_new + jax.random.uniform(rng, t_new.shape) * eps\n  else:\n    t_new = t_new + jax.random.uniform(rng, t_new.shape) * (t[1] - t[0]) * eps\n  # Deterministic sampling.\n  if deterministic_center:\n    t_new = linspline.interp(t_new, t, t)\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  # Validate input.\n  utils.assert_valid_stepfun(t, w_logits)\n  t = jnp.asarray(t, dtype=jnp.float32)\n  w_logits = jnp.asarray(w_logits, dtype=jnp.float32)\n  num_samples = int(num_samples)\n  single_jitter = bool(single_jitter)\n  deterministic_center = bool(deterministic_center)\n  eps = float(eps)\n\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  # Determine the range of the PDF.\n  if deterministic_center:\n    # Center the samples in each bin.\n    t_min = t[Ellipsis, :-1]\n    t_max = t[Ellipsis, 1:]\n  else:\n    # Sample the entire PDF.\n    t_min = t[Ellipsis, 0]\n    t_max = t[Ellipsis, -1]\n\n  # Determine the sampling method.\n  if rng is None:\n    # Deterministic sampling.\n    # Use linspace to generate samples.\n    t_samples = jnp.linspace(t_min, t_max, num_samples, axis=-1)\n  else:\n    # Random sampling.\n    # Use uniform sampling to generate samples.\n    t_samples = jax.random.uniform(\n      rng,\n      shape=(num_samples,),\n      minval=t_min,\n      maxval=t_max,\n      dtype=jnp.float32,\n    )\n\n    # Optionally add jitter to each sample.\n    if not single_jitter:\n      t_samples += jax.random.uniform(\n        rng,\n        shape=(num_samples,),\n        minval=jnp.zeros_like(t_samples),\n        maxval=jnp"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  w = jax.nn.softmax(w_logits, axis=-1)\n  # Compute the CDF for each weight vector.\n  cw = integrate_weights(w)\n  # Sample from the CDF.\n  if rng is None:\n    # Deterministic sampling.\n    if deterministic_center:\n      # Center the samples in each interval.\n      u = (cw[Ellipsis, 1:] + cw[Ellipsis, :-1]) / 2.0\n      u = jnp.repeat(u, num_samples, axis=-1)\n    else:\n      # Sample from the entire PDF.\n      u = jnp.linspace(eps, 1 - eps, num_samples, dtype=jnp.float32)\n      u = jnp.repeat(jnp.expand_dims(u, axis=-1), w.shape[0], axis=0)\n  else:\n    # Random sampling.\n    u = jax.random.uniform(rng, (w.shape[0], num_samples))\n    if single_jitter:\n      # Jitter all samples by the same amount.\n      u = u + jnp.expand_dims(u[Ellipsis, 0], axis=-1)\n    else:\n      # Jitter each sample independently.\n      u = u + jnp.expand_dims(jax.random.uniform(rng, (w.shape[0], num_samples)), axis=-1)\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  # Check that t and w_logits have the same shape.\n  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Determine the number of intervals.\n  num_intervals = t.shape[-1] - 1\n  # Compute the center of each interval.\n  t_center = (t[Ellipsis, :-1] + t[Ellipsis, 1:]) / 2\n  # If we are using deterministic sampling, we can adjust the range of samples.\n  if deterministic_center:\n    # Compute the center of each interval.\n    t_min = (t[Ellipsis, :-1] + t[Ellipsis, 1:]) / 2\n    t_max = (t[Ellipsis, 1:] + t[Ellipsis, 2:]) / 2\n    # Adjust the range of samples.\n    t_min = jnp.expand_dims(t_min, axis=-1)\n    t_max = jnp.expand_dims(t_max, axis=-1)\n    t_center = t_min + (t_max - t_min) * t_center\n  # If we are using random sampling, we can jitter the samples.\n  if rng is not None:\n    # Generate a random number for each sample.\n    u = jax.random.uniform(rng, (num_samples,))\n    # If we are using single jitter, we can jitter all samples by the same amount.\n    if single_jitter:\n      # Generate a random number for all samples.\n      u = jnp.expand_dims(u, axis=0)\n    # Jitter the samples.\n    u = u + eps\n    # Compute the inverse CDF.\n    t_center = invert_cdf(u, t, w_logits)\n  # Comput"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Sample from the inverse CDF.\n  if rng is None:\n    if deterministic_center:\n      # If deterministic sampling is requested, center samples in each bin.\n      u = (cw[Ellipsis, :-1] + cw[Ellipsis, 1:]) / 2\n    else:\n      # If no random number generator is provided, use linspace to sample.\n      u = jnp.linspace(eps, 1 - eps, num_samples)\n  else:\n    # If a random number generator is provided, use uniform sampling.\n    u = jax.random.uniform(rng, (num_samples,))\n    if single_jitter:\n      # If single jitter is requested, add the same amount of jitter to each sample.\n      u = u + jnp.full((num_samples,), jax.random.uniform(rng, (1,)))\n    if deterministic_center:\n      # If deterministic sampling is requested, center samples in each bin.\n      u = (cw[Ellipsis, :-1] + cw[Ellipsis, 1:]) / 2\n  t_new = invert_cdf(u, t, w_logits)\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Compute the number of intervals and the number of bins.\n  num_intervals = t.shape[-1] - 1\n  num_bins = num_intervals + 1\n  # Determine the number of samples per interval.\n  num_samples_per_interval = num_samples // num_intervals\n  num_samples_per_interval = jnp.maximum(1, num_samples_per_interval)\n  # Determine the number of samples to add to the center of each interval.\n  num_center_samples = num_samples - num_samples_per_interval * num_intervals\n  # Sample the center of each interval.\n  if deterministic_center:\n    # If deterministic, center samples are at the center of each interval.\n    center_samples = jnp.linspace(eps, 1 - eps, num_center_samples)\n  else:\n    # If random, center samples are randomly distributed across each interval.\n    center_samples = jax.random.uniform(rng, (num_center_samples,))\n  # Sample the rest of the points.\n  if rng is None:\n    # If deterministic, use linspace to sample the rest of the points.\n    u = jnp.linspace(eps, 1 - eps, num_samples)\n  else:\n    # If random, use uniform sampling to sample the rest of the points.\n    u = jax.random.uniform(rng, (num_samples,))\n    # Optionally jitter the samples.\n    if not single_jitter:\n      u = jax.random.uniform(jax.random.fold_in(rng, 1), (num_samples,))\n  # Concatenate the center samples and the rest of the samples.\n  u = jnp.concatenate([center_samples, u"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Compute the inverse CDF for each weight vector.\n  t_new = invert_cdf(cw, t, w_logits)\n  # Compute the jitter amount.\n  if rng is None:\n    # Deterministic sampling.\n    if deterministic_center:\n      # Centered samples.\n      # Find the center of each bin.\n      t_center = 0.5 * (t[Ellipsis, 1:] + t[Ellipsis, :-1])\n      # Find the jitter amount, which is the difference between each bin's center\n      # and its left endpoint.\n      jitter = t_center - t[Ellipsis, :-1]\n    else:\n      # Uncentered samples.\n      # Find the jitter amount, which is the difference between each bin's right\n      # endpoint and its left endpoint.\n      jitter = t[Ellipsis, 1:] - t[Ellipsis, :-1]\n  else:\n    # Random sampling.\n    # Find the jitter amount, which is the difference between each bin's right\n    # endpoint and its left endpoint.\n    jitter = t[Ellipsis, 1:] - t[Ellipsis, :-1]\n    # Jitter the endpoints.\n    if single_jitter:\n      # Use the same jitter amount for each sample.\n      jitter = jitter[Ellipsis, None]\n      jitter = jitter * jax.random.uniform(rng, shape=jitter.shape)\n    else:\n      # Use a different jitter amount for each sample.\n      jitter = jitter[Ellipsis, None]\n      jitter = jitter * jax.random.uniform(\n          rng, shape=jitter.shape[:-1] + (num_"}
{"namespace": "stepfun.sample", "completion": "  # Determine the number of bins.\n  num_bins = w_logits.shape[-1]\n\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  # Determine the number of intervals in the step function.\n  num_intervals = num_bins - 1\n\n  # Compute the bin widths.\n  td = jnp.diff(t)\n\n  # Determine the number of samples to generate per batch.\n  num_samples_per_batch = 1 if deterministic_center else num_samples\n\n  # Determine the number of batches.\n  num_batches = num_samples // num_samples_per_batch\n\n  # Generate random samples.\n  if rng is not None:\n    # Generate random samples.\n    u = jax.random.uniform(rng, shape=(num_batches, num_samples_per_batch))\n\n    # Generate random jitter.\n    if not single_jitter:\n      u = u + jax.random.uniform(rng, shape=u.shape) * eps\n\n  else:\n    # Generate deterministic samples.\n    u = jnp.linspace(eps, 1 - eps, num_samples_per_batch)\n\n    # Repeat the samples to generate multiple samples per batch.\n    u = jnp.tile(u, num_batches)\n\n  # Invert the CDF.\n  t_new = invert_cdf(u, t, w_logits)\n\n  # Determine the bin index of each sample.\n  i = jnp.minimum(num_bins - 1, jnp.maximum(0, jnp.searchsorted(t, t_new, side='right') - 1))\n\n  # Determine the bin coordinate of each sample.\n  t_new = t[i]\n\n  # Determine the bin width of each sample.\n  td"}
{"namespace": "stepfun.sample", "completion": "  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Sample from the inverse CDF.\n  # TODO: Make this more efficient.\n  t_new = invert_cdf(\n      jax.random.uniform(rng, (num_samples,) + w.shape[:-1]),\n      t,\n      w_logits,\n  )\n  # Determine the number of samples to use for each weight vector.\n  # TODO: Make this more efficient.\n  num_samples_per_w = jnp.sum(\n      jnp.cumsum(w, axis=-1) < 1. / num_samples, axis=-1, keepdims=True)\n  # Determine the number of samples to use for each interval.\n  num_samples_per_interval = num_samples_per_w * w\n  # Compute the number of samples to use for each interval, based on the number of\n  # samples to use for each weight vector.\n  num_samples_per_interval = jnp.round(num_samples_per_interval * num_samples)\n  # Compute the number of samples to use for each weight vector, based on the number\n  # of samples to use for each interval.\n  num_samples_per_w = jnp.sum(num_samples_per_interval, axis=-1)\n  # Compute the number of samples to use for each weight vector, based on the number\n  # of samples to use for each interval.\n  num_samples_per_w = jnp.round(num_samples_per_w)\n  # Compute the number of samples to use for each interval, based on the number of\n  # samples to use for each weight vector.\n  num_samples_per_interval = num_samples_per_w * w\n  # Compute the number of samples to use for each interval, based on the number of\n  # samples to use for each weight vector.\n  num_samples_per_interval = jnp.round(num_samples"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Convert logits to weights.\n  w = jax.nn.softmax(w_logits, axis=-1)\n\n  # Compute the PDF and CDF for each weight vector.\n  cw = integrate_weights(w)\n\n  # Determine the sampling method.\n  if rng is None:\n    # Deterministic sampling.\n    if deterministic_center:\n      # Centered sampling.\n      # TODO: Implement this.\n      raise NotImplementedError(\"Centered deterministic sampling is not yet implemented.\")\n    else:\n      # Uncentered sampling.\n      # TODO: Implement this.\n      raise NotImplementedError(\"Uncentered deterministic sampling is not yet implemented.\")\n  else:\n    # Random sampling.\n    # Generate samples from a uniform distribution.\n    if single_jitter:\n      # Use a single jitter for all samples.\n      u = jax.random.uniform(rng, shape=(num_samples,))\n    else:\n      # Use a different jitter for each sample.\n      u = jax.random.uniform(rng, shape=(num_samples, num_samples))\n\n    # Adjust the range of the uniform distribution.\n    u = u * (1.0 - eps) + eps / 2.0\n\n    # Interpolate into the inverse CDF.\n    t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n\n    return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Convert weights to a PDF.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  # Compute the center of each bin.\n  t_mid = (t[Ellipsis, 1:] + t[Ellipsis, :-1]) / 2\n\n  # Generate random samples.\n  if rng is not None:\n    # Sample uniformly in each bin.\n    u = jax.random.uniform(rng, shape=(num_samples,))\n    # Optionally, jitter the samples.\n    if not single_jitter:\n      u = jax.random.uniform(jax.random.fold_in(rng, 1), shape=(num_samples,))\n    # Optionally, center the samples.\n    if deterministic_center:\n      # Compute the center of each bin.\n      t_mid = (t[Ellipsis, 1:] + t[Ellipsis, :-1]) / 2\n      # Compute the cumulative sum of the weights.\n      cw = integrate_weights(w)\n      # Compute the cumulative sum of the weights at the bin centers.\n      cw_mid = math.sorted_interp(t_mid, t, cw, utils.device_is_tpu())\n      # Compute the difference between the midpoint cumulative sums.\n      delta_cw = cw_mid[Ellipsis, 1:] - cw_mid[Ellipsis, :-1]\n      # Scale the jitter by the difference between midpoint cumulative sums.\n      u = u * delta_cw + cw_mid[Ellipsis, :-1]\n    # Interpolate into the inverse CDF.\n    t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n  else:\n    # Compute the cumulative sum of the weights.\n    cw = integrate_we"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Determine the number of bins and the number of batch dimensions.\n  num_bins = t.shape[-1]\n  num_batch_dims = len(t.shape[:-1])\n\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  # Determine the start and end points of the sampled intervals.\n  if deterministic_center:\n    # Sample the center of each interval.\n    t0 = t[Ellipsis, :-1] + 0.5 * jnp.diff(t, axis=-1)\n    t1 = t[Ellipsis, 1:] - 0.5 * jnp.diff(t, axis=-1)\n  else:\n    # Sample the entire range of the step function.\n    t0 = t[Ellipsis, 0]\n    t1 = t[Ellipsis, -1]\n\n  # Determine the shape of the output.\n  shape = t.shape[:-1] + (num_samples,)\n\n  # If random sampling, use the inverse CDF to generate random samples.\n  if rng is not None:\n    u = jax.random.uniform(rng, shape, dtype=jnp.float32)\n    if single_jitter:\n      u = u + eps\n    t_new = invert_cdf(u, t, w_logits)\n\n  # If deterministic sampling, use linspace to generate samples.\n  else:\n    t_new = jnp.linspace(t0, t1, num_samples, axis=-1)\n    t_new = jnp.broadcast_to(t_new, shape)\n\n  # Return the samples.\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  # Compute the bin widths.\n  td = jnp.diff(t)\n  # If the bin widths are too small, the PDF is not differentiable.\n  td = jnp.where(td < eps, eps, td)\n\n  # Compute the CDF and inverse CDF.\n  cw0 = integrate_weights(w)\n\n  # Compute the PDF.\n  pdf = w / td\n\n  # Determine the number of samples per batch element.\n  num_samples_per_batch = num_samples\n  if deterministic_center:\n    num_samples_per_batch = num_samples // 2\n\n  # Determine the number of samples per interval.\n  num_samples_per_interval = num_samples_per_batch\n  if single_jitter:\n    num_samples_per_interval = 1\n\n  # Generate random samples.\n  if rng is not None:\n    u = jax.random.uniform(rng, shape=(num_samples_per_batch,))\n    u = jnp.concatenate([u, 1 - u[::-1]], axis=0)\n  else:\n    u = jnp.linspace(0, 1, num_samples_per_batch + 1)[Ellipsis, None]\n\n  # Generate samples.\n  t_samples = math.sorted_interp(u, cw0, t, utils.device_is_tpu())\n  t_samples = t_samples[Ellipsis, None]\n  t_samples = jnp.tile(t_samples, [1, num_samples_per_interval])\n\n  # Jitter the samples.\n  if rng is not None:\n    t_samples = t_samples + jax.random.uniform("}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u_max = 1 - eps\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Sample points from the step function.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Calculate midpoints between adjacent samples.\n  t_midpoints = jnp.concatenate(\n      [\n          jnp.expand_dims(t_samples[Ellipsis, 0], axis=-1),\n          (t_samples[Ellipsis, 1:] + t_samples[Ellipsis, :-1]) / 2,\n          jnp.expand_dims(t_samples[Ellipsis, -1], axis=-1),\n      ],\n      axis=-1,\n  )\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n "}
{"namespace": "stepfun.sample_intervals", "completion": "  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u_max = 1 / (2 * num_samples)\n    max_jitter = (1 - u_max) / (num_samples - 1) - jnp.finfo(jnp.float32).eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = jnp.finfo(jnp.float32).eps + (1 - jnp.finfo(jnp.float32).eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - jnp.finfo(jnp.float32).eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Get intervals from the inverse CDF.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Adjust intervals to fit within the specified domain.\n  t_samples = jnp.where(\n    t_samples < domain[0],\n    domain[0] + (t_samples - domain[0]) / 2,\n    t_samples\n  )\n  t_samples = jnp.where(\n    t_samples > domain[1],\n    domain[1] - (t_samples - domain[1]) / 2,\n    t_samples\n  )"}
{"namespace": "stepfun.sample_intervals", "completion": "  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u_max = 1 / (2 * num_samples)\n    max_jitter = (1 - u_max) / (num_samples - 1)\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = 1 / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1)\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Sample points from the step function.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Calculate midpoints between adjacent samples.\n  t_mid = (t_samples[..., 1:] + t_samples[..., :-1]) / 2\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  t_samples = jnp.concatenate([t_samples[..., :1], t_mid, t_samples[..., -1:]], axis=-1)\n  t_samples = jnp.clip(t_samples, a_min=domain[0], a_max=domain[1])\n\n  return t_samples\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  # Sample points from the step function.\n  t_samples = sample(rng, t, w_logits, num_samples, single_jitter)\n\n  # Calculate midpoints between adjacent points.\n  t_mid = 0.5 * (t_samples[Ellipsis, 1:] + t_samples[Ellipsis, :-1])\n\n  # Adjust first and last intervals to ensure they are within the specified domain.\n  t_mid = jnp.concatenate([jnp.minimum(t_mid[Ellipsis, 0], domain[1]), t_mid, jnp.maximum(t_mid[Ellipsis, -1], domain[0])], axis=-1)\n\n  # Calculate the intervals from the midpoints.\n  t_intervals = jnp.stack([t_mid[Ellipsis, :-1], t_mid[Ellipsis, 1:]], axis=-1)\n\n  return t_intervals\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Sample points from the step function.\n  t_samples = sample(rng, t, w_logits, num_samples, single_jitter)\n\n  # Calculate midpoints between adjacent samples.\n  t_midpoints = jnp.diff(t_samples, axis=-1) / 2\n  t_midpoints = jnp.concatenate([t_midpoints, t_samples[Ellipsis, -1:]], axis=-1)\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  t_midpoints = jnp.minimum(t_midpoints, jnp.array(domain[1]))\n  t_midpoints = jnp.maximum(t_midpoints, jnp.array(domain[0]))\n\n  return t_midpoints\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u_max = 1 - jnp.finfo(jnp.float32).eps\n    u_min = 0\n    max_jitter = (u_max - u_min) / (num_samples - 1)\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(u_min, u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), minval=0, maxval=max_jitter\n    )\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = 1 - jnp.finfo(jnp.float32).eps\n    max_jitter = (u_max - 0) / (num_samples - 1) - jnp.finfo(jnp.float32).eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), minval=0, maxval=max_jitter\n    )\n\n  # Sample points from the step function.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Compute midpoints between adjacent samples.\n  t_mid = (t_samples[Ellipsis, 1:] + t_samples[Ellipsis, :-1]) / 2\n\n  # Concatenate the first and last intervals.\n  t_mid = jnp.concatenate([t_mid[Ellipsis, :1], t_mid, t_mid[Ellipsis, -1:]], axis=-1"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u_max = 1 / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1)\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = 1 / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - jnp.finfo(jnp.float32).eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Sample points from the step function.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Calculate midpoints between adjacent samples.\n  t_midpoints = (t_samples[..., 1:] + t_samples[..., :-1]) / 2\n\n  # Construct the intervals by concatenating the first and last sampled points with the midpoints.\n  t_intervals = jnp.concatenate([t_samples[..., :1], t_midpoints, t_samples[..., -1:]], axis=-1)\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  t_intervals = jnp.clip(t_intervals, a_min="}
{"namespace": "stepfun.sample_intervals", "completion": "  # Sample points from the step function\n  t_samples = sample(rng, t, w_logits, num_samples, single_jitter)\n\n  # Calculate midpoints between adjacent samples\n  t_midpoints = 0.5 * (t_samples[Ellipsis, 1:] + t_samples[Ellipsis, :-1])\n\n  # Concatenate the first and last samples to the midpoints\n  t_samples = jnp.concatenate([t_samples[Ellipsis, 0:1], t_midpoints, t_samples[Ellipsis, -1:]], axis=-1)\n\n  # Adjust the first and last intervals to ensure they are within the specified domain\n  t_samples = jnp.where(t_samples[Ellipsis, 0] < domain[0], domain[0], t_samples)\n  t_samples = jnp.where(t_samples[Ellipsis, -1] > domain[1], domain[1], t_samples)\n\n  return t_samples\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u_max = 1 - jnp.finfo(jnp.float32).eps\n    max_jitter = (1 - u_max) / (num_samples - 1)\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = jnp.finfo(jnp.float32).eps\n    max_jitter = (1 - u_max) / (num_samples - 1) - jnp.finfo(jnp.float32).eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Invert CDF to get the samples.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Calculate the midpoints between the samples.\n  t_midpoints = (t_samples[Ellipsis, 1:] + t_samples[Ellipsis, :-1]) / 2\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  t_midpoints = jnp.concatenate(\n      [jnp.maximum(t_midpoints[Ellipsis, 0:1], domain[0]), t_midpoints, jnp.minimum(t"}
{"namespace": "stepfun.sample_intervals", "completion": "  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u_max = 1 - jnp.finfo(jnp.float32).eps\n    u_min = 0\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Calculate samples from the step function.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Calculate midpoints between adjacent samples.\n  t_mid = (t_samples[..., 1:] + t_samples[..., :-1]) / 2\n\n  # Calculate the first and last intervals.\n  t_first = jnp.expand_dims(t_samples[..., 0], axis=-1)\n  t_last = jnp.expand_dims(t_samples[..., -1], axis=-1)\n\n  # Concatenate the first and last intervals with the midpoints.\n  t_samples = j"}
{"namespace": "stepfun.sample_intervals", "completion": "  # Sample points from the step function.\n  t_samples = sample(rng, t, w_logits, num_samples, single_jitter)\n\n  # Calculate midpoints between adjacent samples.\n  t_midpoints = 0.5 * (t_samples[Ellipsis, 1:] + t_samples[Ellipsis, :-1])\n\n  # Concatenate the first and last sampled points to the midpoints to form a list of intervals.\n  t_intervals = jnp.concatenate([t_samples[Ellipsis, :1], t_midpoints, t_samples[Ellipsis, -1:]], axis=-1)\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  t_intervals = jnp.where(t_intervals < domain[0], domain[0], t_intervals)\n  t_intervals = jnp.where(t_intervals > domain[1], domain[1], t_intervals)\n\n  return t_intervals\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  # Sample points from the step function.\n  t_samples = sample(\n    rng,\n    t,\n    w_logits,\n    num_samples,\n    single_jitter=single_jitter,\n    deterministic_center=False,\n  )\n\n  # Compute the midpoints between adjacent samples.\n  t_mid = (t_samples[Ellipsis, 1:] + t_samples[Ellipsis, :-1]) / 2\n\n  # Concatenate the first and last sampled points to the midpoints.\n  t_samples = jnp.concatenate([t_samples[Ellipsis, 0:1], t_mid, t_samples[Ellipsis, -1:]], axis=-1)\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  t_samples = jnp.minimum(jnp.maximum(t_samples, domain[0]), domain[1])\n\n  return t_samples\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u_max = 1 / (2 * num_samples)\n    max_jitter = (1 - u_max) / (num_samples - 1) - 1e-5\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = 1e-5 + (1 - 1e-5) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - 1e-5\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Sample points from the step function.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Calculate midpoints between adjacent samples.\n  t_mid = (t_samples[..., 1:] + t_samples[..., :-1]) / 2\n\n  # Adjust first and last intervals to ensure they are within the specified domain.\n  t_samples = jnp.concatenate([t_mid[..., :1], t_mid, t_samples[..., -1:]], axis=-1)\n  t_samples = jnp.clip(t_samples, a_min=domain[0], a_max=domain[1])\n\n  return t_samples\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Invert the CDF to get samples from the step function.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Calculate midpoints between adjacent samples.\n  t_mid = jnp.diff(t_samples, axis=-1) / 2 + t_samples[Ellipsis, :-1]\n\n  # Concatenate the first and last intervals to ensure the domain is included.\n  t_mid = jnp.concatenate([jnp.minimum(domain[0], t_mid[Ellipsis, 0:1]), t_mid, jnp.maximum(domain[1], t_mid[Ellipsis, -1:])], axis=-"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u_max = 1 - eps\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Sample points from the step function.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Calculate midpoints between adjacent samples.\n  t_midpoints = jnp.concatenate(\n      [\n          t_samples[Ellipsis, 1:-1],\n          (t_samples[Ellipsis, -2] + t_samples[Ellipsis, -1])[Ellipsis, jnp.newaxis]\n      ], axis=-1)\n\n  # Calculate the difference between the midpoints and the original samples.\n  t_diff = t_midpoints - t_samples\n\n  # Calculate the difference between the midpoints and the domain boundaries.\n  t_diff_left"}
{"namespace": "stepfun.sample_intervals", "completion": "  # Sample points from the step function.\n  t_samples = sample(rng, t, w_logits, num_samples, single_jitter)\n\n  # Calculate midpoints between adjacent samples.\n  t_mid = (t_samples[Ellipsis, 1:] + t_samples[Ellipsis, :-1]) / 2\n\n  # Concatenate the first and last intervals to the sampled points.\n  t_samples = jnp.concatenate([t[Ellipsis, 0:1], t_mid, t[Ellipsis, -1:]], axis=-1)\n\n  # Ensure the first and last intervals are within the specified domain.\n  t_samples = jnp.concatenate([jnp.clip(t_samples[Ellipsis, 0:1], domain[0], t_samples[Ellipsis, 1]), t_samples[Ellipsis, 1:-1], jnp.clip(t_samples[Ellipsis, -1:], t_samples[Ellipsis, -2], domain[1])], axis=-1)\n\n  return t_samples\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  # Ensure that the domain is valid.\n  assert domain[0] < domain[1], \"The specified domain is invalid.\"\n\n  # Ensure that the bin weights sum to 1.\n  w = jax.nn.softmax(w_logits, axis=-1)\n\n  # Compute the CDF.\n  cw = integrate_weights(w)\n\n  # Sample points from the step function.\n  t_samples = sample(rng, t, w_logits, num_samples, single_jitter)\n\n  # Compute midpoints between adjacent samples.\n  t_midpoints = 0.5 * (t_samples[..., 1:] + t_samples[..., :-1])\n\n  # Create an array of intervals by concatenating the sampled points and midpoints.\n  t_intervals = jnp.concatenate([t_samples, t_midpoints], axis=-1)\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  t_intervals = jnp.concatenate([jnp.minimum(domain[1], jnp.maximum(domain[0], t_intervals[..., 0:1])), t_intervals[..., 1:-1], jnp.minimum(domain[1], jnp.maximum(domain[0], t_intervals[..., -1:]))], axis=-1)\n\n  return t_intervals\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  # Get the sampled points from the step function.\n  t_samples = sample(rng, t, w_logits, num_samples, single_jitter)\n\n  # Calculate the midpoints between the sampled points.\n  t_midpoints = 0.5 * (t_samples[Ellipsis, 1:] + t_samples[Ellipsis, :-1])\n\n  # Calculate the intervals from the midpoints.\n  t_intervals = jnp.concatenate([t_midpoints, t_samples[Ellipsis, -1:]], axis=-1)\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  t_intervals = jnp.where(t_intervals[Ellipsis, 0] < domain[0], domain[0], t_intervals)\n  t_intervals = jnp.where(t_intervals[Ellipsis, -1] > domain[1], domain[1], t_intervals)\n\n  return t_intervals\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  # Sample points from the step function.\n  t_samples = sample(rng, t, w_logits, num_samples, single_jitter)\n\n  # Calculate midpoints between adjacent samples.\n  t_midpoints = jnp.diff(t_samples, axis=-1) / 2 + t_samples[Ellipsis, :-1]\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  t_samples = jnp.concatenate(\n      [\n          jnp.maximum(domain[0], t_samples[Ellipsis, 0:1]),\n          t_midpoints,\n          jnp.minimum(domain[1], t_samples[Ellipsis, -1:]),\n      ],\n      axis=-1,\n  )\n\n  return t_samples\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  # Generate sampled points from the step function\n  t_samples = sample(rng, t, w_logits, num_samples, single_jitter)\n\n  # Compute midpoints between adjacent sampled points\n  t_mid = 0.5 * (t_samples[..., 1:] + t_samples[..., :-1])\n\n  # Compute the first and last intervals\n  t_first = jnp.expand_dims(t_samples[..., 0], axis=-1)\n  t_last = jnp.expand_dims(t_samples[..., -1], axis=-1)\n\n  # Adjust the first and last intervals to fit within the specified domain\n  t_first = jnp.maximum(domain[0], t_first)\n  t_last = jnp.minimum(domain[1], t_last)\n\n  # Concatenate the first and last intervals with the midpoints\n  t_samples = jnp.concatenate([t_first, t_mid, t_last], axis=-1)\n\n  return t_samples\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Integrate the weights to use them as the y-coordinates for interpolation.\n  cw = integrate_weights(w)\n\n  # Compute the weighted percentiles.\n  return linspline.interpolate_linear(t, cw, ps)\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Ensure that the weights sum to 1.\n  w = w / jnp.sum(w, axis=-1, keepdims=True)\n\n  # Compute the cumulative sum of the weights.\n  cw = integrate_weights(w)\n\n  # Compute the percentiles by interpolating into the cumulative sum.\n  t_percentiles = math.sorted_interp(ps, cw, t, utils.device_is_tpu())\n\n  return t_percentiles\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  # Ensure that the weights sum to 1.\n  w = w / jnp.sum(w, axis=-1, keepdims=True)\n\n  # Calculate the integrated weights.\n  cw = integrate_weights(w)\n\n  # Interpolate the integrated weights to find the percentiles.\n  ps = jnp.array(ps)\n  t_percentiles = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n  return t_percentiles\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_percentiles(ps)\n\n  # Ensure that the weights sum to 1.\n  w = pdf_to_weight(t, w)\n\n  # Calculate the cumulative sum of the weights.\n  cw = integrate_weights(w)\n\n  # Interpolate the weighted percentiles.\n  return math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Calculate the cumulative sum of the weights.\n  cw = integrate_weights(w)\n\n  # Calculate the percentiles.\n  return math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Compute the cumulative sum of the weights.\n  cw = integrate_weights(w)\n\n  # Interpolate into the cumulative weights to find the target percentiles.\n  t_percentiles = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n  return t_percentiles\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Ensure that the weights sum to 1.\n  w = w / jnp.sum(w)\n\n  # Compute the cumulative sum of the weights.\n  cw = integrate_weights(w)\n\n  # Compute the percentiles by interpolating into the cumulative weights.\n  return linspline.interpolate(cw, t, ps)\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Ensure that the weights sum to 1.\n  w = w / jnp.sum(w, axis=-1, keepdims=True)\n\n  # Compute the cumulative sum of the integrated weights.\n  cw = integrate_weights(w)\n\n  # Interpolate the percentiles based on the integrated weights.\n  t_percentiles = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n  return t_percentiles\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Ensure that the weights sum to 1.\n  w = pdf_to_weight(t, w)\n\n  # Compute the cumulative sum of the weights.\n  cw = integrate_weights(w)\n\n  # Interpolate the cumulative sum of the weights to find the target percentiles.\n  t_percentiles = math.sorted_interp(ps, cw, t, utils.device_is_tpu())\n\n  return t_percentiles\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Compute the integrated weights.\n  cw = integrate_weights(w)\n\n  # Interpolate into the integrated weights.\n  return math.sorted_interp(ps, cw, t, utils.device_is_tpu())\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Ensure that the weights sum to 1.\n  w = jnp.asarray(w)\n  w = w / jnp.sum(w)\n\n  # Compute the integrated weights.\n  cw = integrate_weights(w)\n\n  # Interpolate to find the x-values corresponding to the given percentiles.\n  t_percentiles = math.sorted_interp(ps, cw, t, utils.device_is_tpu())\n\n  return t_percentiles\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  utils.assert_normalized(w)\n\n  # Integrate the weights.\n  cw = integrate_weights(w)\n\n  # Interpolate the integrated weights to find the percentiles.\n  return math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Ensure that the weights sum to 1.\n  w = w / jnp.sum(w)\n\n  # Compute the cumulative sum of the weights.\n  cw = jnp.cumsum(w)\n\n  # Compute the percentiles of the cumulative sum of the weights.\n  ps = jnp.array(ps)\n  ps_cw = jnp.interp(x=ps, xp=cw, fp=t)\n\n  return ps_cw\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  t = jnp.asarray(t)\n  w = jnp.asarray(w)\n  ps = jnp.asarray(ps)\n\n  # Check that the weights sum to 1.\n  if not jnp.isclose(jnp.sum(w), 1.0):\n    raise ValueError('The weights must sum to 1.')\n\n  # Compute the cumulative sum of the weights.\n  cw = jnp.cumsum(w)\n\n  # Compute the interpolated percentiles.\n  t_ps = jnp.interp(ps, cw, t)\n\n  return t_ps\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_percentiles(ps)\n\n  # Calculate the integrated weights.\n  cw = integrate_weights(w)\n\n  # Calculate the weighted percentiles.\n  return math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Ensure the weights sum to 1.\n  w = jnp.asarray(w)\n  w /= jnp.sum(w, axis=-1, keepdims=True)\n\n  # Compute the cumulative sum of the weights.\n  cw = integrate_weights(w)\n\n  # Interpolate the weighted percentiles.\n  t_p = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n  return t_p\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  # Check that the inputs are valid.\n  utils.assert_valid_stepfun(t, w)\n  assert np.all(np.diff(t) > 0), \"The values in 't' must be monotonically increasing.\"\n  assert np.all(np.diff(ps) > 0), \"The values in 'ps' must be monotonically increasing.\"\n  assert np.all(w >= 0), \"The values in 'w' must be non-negative.\"\n  assert np.isclose(np.sum(w), 1), \"The values in 'w' must sum to 1.\"\n\n  # Compute the integrated weights.\n  cw = integrate_weights(w)\n\n  # Interpolate the percentiles.\n  return math.sorted_interp(ps, cw, t, utils.device_is_tpu())\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  # Check that the weights sum to 1.\n  if not np.isclose(np.sum(w), 1.0):\n    raise ValueError(\"The weights must sum to 1.\")\n\n  # Check that the percentiles are between 0 and 100.\n  if not np.all(ps > 0) and np.all(ps < 100):\n    raise ValueError(\"The percentiles must be between 0 and 100.\")\n\n  # Compute the cumulative weights.\n  cw = integrate_weights(w)\n\n  # Convert the percentiles to the corresponding y-values.\n  ys = np.percentile(cw, ps)\n\n  # Interpolate the percentiles.\n  return np.interp(ys, cw, t)\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  if np.any(w < 0):\n    raise ValueError('weights must be non-negative')\n\n  # Integrate the weights.\n  cw = integrate_weights(w)\n\n  # Interpolate the integrated weights to get the desired percentiles.\n  return math.sorted_interp(ps, cw, t, utils.device_is_tpu())\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  # Check for valid inputs.\n  utils.assert_valid_stepfun(t, w)\n  assert jnp.all(ps >= 0) and jnp.all(ps <= 100), \"Percentiles must be between 0 and 100.\"\n\n  # Calculate the cumulative sum of the weights.\n  cw = integrate_weights(w)\n\n  # Calculate the percentiles by interpolating into the cumulative weights.\n  return math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert the histogram to a PDF.\n  w = weight_to_pdf(t, w)\n\n  # Blur the PDF.\n  w = linspline.blur(t, w, blur_halfwidth)\n\n  # Resample the PDF.\n  wq = resample(tq, t, w)\n\n  return wq"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert the histogram to a PDF.\n  w = weight_to_pdf(t, w)\n\n  # Blur the PDF.\n  w = linspline.blur_weights(t, w, blur_halfwidth)\n\n  # Resample the PDF.\n  wq = resample(tq, t, w)\n\n  return wq\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert to a probability density function (PDF)\n  w_pdf = weight_to_pdf(t, w)\n\n  # Blur the PDF\n  w_pdf_blurred = linspline.blur_weights(t, w_pdf, blur_halfwidth)\n\n  # Resample the blurred PDF\n  w_resampled = resample(tq, t, w_pdf_blurred)\n\n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert the weights to a probability density function (PDF)\n  w_pdf = weight_to_pdf(t, w)\n\n  # Blur the PDF\n  w_pdf_blurred = linspline.blur_pdf(t, w_pdf, blur_halfwidth)\n\n  # Resample the PDF\n  w_resampled = resample(tq, t, w_pdf_blurred)\n\n  return w_resampled\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert the histogram to a PDF.\n  w_pdf = pdf_to_weight(t, w)\n\n  # Blur the PDF.\n  w_pdf_blurred = linspline.blur(t, w_pdf, blur_halfwidth)\n\n  # Resample the PDF to match the new time points.\n  w_q = resample(tq, t, w_pdf_blurred)\n\n  return w_q"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert the histogram into a PDF.\n  w = w / jnp.sum(w)\n\n  # Blur the PDF.\n  w = linspline.blur_weights(w, blur_halfwidth)\n\n  # Resample the PDF.\n  wq = resample(tq, t, w)\n\n  return wq\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Ensure that the input arrays are numpy arrays.\n  tq = np.array(tq)\n  t = np.array(t)\n  w = np.array(w)\n\n  # Ensure that the input arrays are valid step functions.\n  utils.assert_valid_stepfun(t, w)\n\n  # Convert the histogram to a PDF.\n  w = w / np.sum(w)\n\n  # Blur the PDF.\n  w = linspline.blur_weights(t, w, blur_halfwidth)\n\n  # Resample the PDF.\n  wq = resample(tq, t, w)\n\n  # Return the resampled weights.\n  return wq\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Ensure that the input arrays are valid step functions.\n  utils.assert_valid_stepfun(t, w)\n\n  # Convert the weights into a probability density function.\n  p = weight_to_pdf(t, w)\n\n  # Blur the PDF.\n  p_blurred = linspline.blur_pdf(t, p, blur_halfwidth)\n\n  # Resample the PDF to match the new time points.\n  w_resampled = resample(tq, t, p_blurred)\n\n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert the weights into a probability density function (PDF).\n  w_pdf = weight_to_pdf(t, w)\n\n  # Blur the PDF.\n  w_pdf_blurred = linspline.blur_weights(w_pdf, blur_halfwidth)\n\n  # Resample the blurred PDF to match the new time points.\n  w_blurred_resampled = resample(tq, t, w_pdf_blurred)\n\n  return w_blurred_resampled\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Ensure that the input arrays are NumPy arrays.\n  tq = np.array(tq)\n  t = np.array(t)\n  w = np.array(w)\n\n  # Ensure that the input arrays are valid step functions.\n  utils.assert_valid_stepfun(t, w)\n\n  # Compute the PDF of the histogram.\n  pdf = weight_to_pdf(t, w)\n\n  # Blur the PDF.\n  pdf_blurred = linspline.blur_pdf(t, pdf, blur_halfwidth)\n\n  # Resample the PDF to match the new time points.\n  w_resampled = resample(tq, t, pdf_blurred)\n\n  return w_resampled\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Check the inputs.\n  utils.assert_valid_stepfun(t, w)\n  if tq is None:\n    tq = t\n  if blur_halfwidth is None:\n    blur_halfwidth = 0\n\n  # Convert the histogram to a PDF.\n  w = weight_to_pdf(t, w)\n\n  # Blur the PDF.\n  w_blurred = linspline.blur_weights(t, w, blur_halfwidth)\n\n  # Resample the PDF.\n  wq = resample(tq, t, w_blurred)\n\n  # Convert the PDF back to a histogram.\n  wq = pdf_to_weight(tq, wq)\n\n  return wq"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Compute the probability density function (PDF) of the histogram.\n  w_pdf = weight_to_pdf(t, w)\n\n  # Blur the PDF.\n  w_pdf_blurred = linspline.blur_weights(w_pdf, blur_halfwidth)\n\n  # Resample the PDF to match the new time points.\n  w_resampled = resample(tq, t, w_pdf_blurred)\n\n  return w_resampled\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Check if the new time points are within the range of the original time points.\n  if np.min(tq) < np.min(t) or np.max(tq) > np.max(t):\n    raise ValueError('The new time points must be within the range of the original time points.')\n\n  # Convert the weights to a probability density function (PDF) by normalizing them.\n  w_pdf = w / np.sum(w)\n\n  # Blur the PDF.\n  w_pdf_blurred = linspline.blur_pdf(t, w_pdf, blur_halfwidth)\n\n  # Resample the PDF to match the new time points.\n  w_pdf_resampled = resample(tq, t, w_pdf_blurred)\n\n  return w_pdf_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert the histogram to a PDF.\n  w = weight_to_pdf(t, w)\n  # Blur the PDF.\n  w = linspline.blur_weights(w, t, blur_halfwidth)\n  # Resample the PDF.\n  w = resample(tq, t, w)\n  # Convert the PDF to weights.\n  w = pdf_to_weight(tq, w)\n  return w"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert the weights to a PDF.\n  w = w / jnp.sum(w)\n\n  # Blur the PDF.\n  w = linspline.blur_weights(t, w, blur_halfwidth)\n\n  # Resample the PDF.\n  wq = resample(tq, t, w)\n\n  # Normalize the resampled weights.\n  wq = wq / jnp.sum(wq)\n\n  return wq\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert the weights into a probability density function (PDF)\n  pdf = weight_to_pdf(t, w)\n\n  # Blur the PDF\n  pdf_blurred = linspline.blur_pdf(t, pdf, blur_halfwidth)\n\n  # Resample the PDF\n  wq = resample(tq, t, pdf_blurred)\n\n  return wq\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Check inputs.\n  utils.assert_valid_stepfun(t, w)\n  if t.shape[-1] != w.shape[-1] + 1:\n    raise ValueError(\n        't and w must have the same number of elements along the last axis, but '\n        f'got shapes {t.shape} and {w.shape}.'\n    )\n\n  # Convert the histogram to a probability density function (PDF).\n  w = weight_to_pdf(t, w)\n\n  # Blur the PDF.\n  w = linspline.blur_weights(w, blur_halfwidth)\n\n  # Resample the PDF.\n  wq = resample(tq, t, w)\n\n  return wq"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert the weights to a probability density function (PDF)\n  pdf = weight_to_pdf(t, w)\n\n  # Blur the PDF\n  pdf_blurred = linspline.blur_pdf(t, pdf, blur_halfwidth)\n\n  # Resample the PDF to match the new time points\n  w_resampled = resample(tq, t, pdf_blurred)\n\n  return w_resampled\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert the histogram to a PDF.\n  w_pdf = weight_to_pdf(t, w)\n\n  # Blur the PDF.\n  w_blurred = linspline.blur_pdf(t, w_pdf, blur_halfwidth)\n\n  # Resample the blurred PDF.\n  w_resampled = resample(tq, t, w_blurred)\n\n  return w_resampled\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Check input arguments\n  if not isinstance(tq, (list, tuple, np.ndarray)):\n    raise TypeError(\"The input argument `tq` must be array-like!\")\n  if not isinstance(t, (list, tuple, np.ndarray)):\n    raise TypeError(\"The input argument `t` must be array-like!\")\n  if not isinstance(w, (list, tuple, np.ndarray)):\n    raise TypeError(\"The input argument `w` must be array-like!\")\n  if not isinstance(blur_halfwidth, (int, float)):\n    raise TypeError(\"The input argument `blur_halfwidth` must be numeric!\")\n\n  # Convert the input arguments to NumPy arrays\n  tq = np.array(tq)\n  t = np.array(t)\n  w = np.array(w)\n\n  # Check the shapes of the input arguments\n  if tq.shape != t.shape:\n    raise ValueError(\"The shapes of the input arguments `tq` and `t` must be identical!\")\n  if w.shape != t.shape[:-1]:\n    raise ValueError(\"The shapes of the input arguments `w` and `t` must be identical!\")\n\n  # Check the value of the input arguments\n  if blur_halfwidth < 0:\n    raise ValueError(\"The input argument `blur_halfwidth` must be non-negative!\")\n\n  # Convert the weights to a probability density function (PDF)\n  pdf = w / np.sum(w)\n\n  # Blur the PDF\n  pdf_blurred = linspline.blur_pdf(pdf, t, blur_halfwidth)\n\n  # Resample the PDF to match the new time points\n  w_resampled = linspline.resample_pdf(pdf_blurred, t, tq)\n\n  return w_resampled"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return from_homogeneous(matmul(transform, to_homogeneous(vectors)))\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Convert the input to a homogeneous representation.\n  homogeneous_vectors = to_homogeneous(vectors)\n\n  # Apply the transformation.\n  transformed_vectors = matmul(homogeneous_vectors, transform)\n\n  # Convert the output back to a non-homogeneous representation.\n  return from_homogeneous(transformed_vectors)\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Convert the points to homogeneous coordinates.\n  homogeneous_vectors = to_homogeneous(vectors)\n\n  # Apply the transformation to the points.\n  homogeneous_transformed_vectors = matmul(homogeneous_vectors[Ellipsis, None, :], transform[None, Ellipsis])\n\n  # Convert the transformed points back to non-homogeneous coordinates.\n  transformed_vectors = from_homogeneous(homogeneous_transformed_vectors)\n\n  return transformed_vectors\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Convert the input to a homogeneous representation.\n  homogeneous_vectors = to_homogeneous(vectors)\n\n  # Apply the homogeneous transformation.\n  homogeneous_transformed_vectors = matmul(homogeneous_vectors[Ellipsis, None, :], transform[None, Ellipsis])\n\n  # Convert the transformed points back to non-homogeneous representation.\n  transformed_vectors = from_homogeneous(homogeneous_transformed_vectors)\n\n  return transformed_vectors\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # The last dimension of the vectors array must be the dimensionality of the points.\n  assert vectors.shape[-1] == transform.shape[0] - 1\n\n  # Convert the points to homogeneous vectors.\n  homogeneous_vectors = to_homogeneous(vectors)\n\n  # Apply the transformation.\n  transformed_vectors = matmul(transform, homogeneous_vectors)\n\n  # Convert the transformed vectors back to non-homogeneous points.\n  return from_homogeneous(transformed_vectors)\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Convert the input vectors to homogeneous coordinates.\n  homogeneous_vectors = to_homogeneous(vectors)\n  # Apply the transformation to the homogeneous coordinates.\n  transformed_vectors = matmul(homogeneous_vectors, transform)\n  # Convert the transformed coordinates back to non-homogeneous.\n  return from_homogeneous(transformed_vectors)\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Apply the transformation.\n  vectors = jnp.concatenate([vectors, jnp.ones_like(vectors[Ellipsis, :1])], axis=-1)\n  vectors = matmul(transform, vectors)\n  vectors = from_homogeneous(vectors)\n\n  return vectors\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Get the dimensionality of the vectors.\n  dim = vectors.shape[-1]\n\n  # Convert the input vectors to homogeneous representation.\n  homogeneous_vectors = to_homogeneous(vectors)\n\n  # Apply the transformation to the homogeneous vectors.\n  homogeneous_transformed_vectors = matmul(transform, homogeneous_vectors[Ellipsis, None, :])\n\n  # Convert the transformed vectors back to non-homogeneous representation.\n  transformed_vectors = from_homogeneous(homogeneous_transformed_vectors[Ellipsis, 0, :])\n\n  return transformed_vectors\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Convert the points to homogeneous vectors.\n  homogeneous_vectors = to_homogeneous(vectors)\n\n  # Apply the transformation.\n  transformed_vectors = matmul(homogeneous_vectors, transform)\n\n  # Convert the points back to non-homogeneous vectors.\n  transformed_vectors = from_homogeneous(transformed_vectors)\n\n  return transformed_vectors\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Transform the homogeneous vectors.\n  transformed_vectors = matmul(transform, to_homogeneous(vectors))\n\n  # Convert the transformed vectors back to non-homogeneous.\n  return from_homogeneous(transformed_vectors)\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Get the number of dimensions of the input vectors.\n  num_dims = vectors.shape[-1]\n\n  # Convert the input vectors to homogeneous vectors.\n  homogeneous_vectors = to_homogeneous(vectors)\n\n  # Apply the homogeneous transformation to the homogeneous vectors.\n  transformed_vectors = matmul(transform, homogeneous_vectors)\n\n  # Convert the transformed homogeneous vectors to non-homogeneous vectors.\n  transformed_vectors = from_homogeneous(transformed_vectors)\n\n  return transformed_vectors\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Convert the vectors to homogeneous coordinates\n  homogeneous_vectors = to_homogeneous(vectors)\n\n  # Apply the transformation\n  transformed_vectors = matmul(transform, homogeneous_vectors)\n\n  # Convert back to non-homogeneous coordinates\n  return from_homogeneous(transformed_vectors)\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Convert the points to homogeneous coordinates.\n  homogeneous_vectors = to_homogeneous(vectors)\n\n  # Transform the points.\n  transformed_vectors = matmul(homogeneous_vectors, transform)\n\n  # Convert the points back to non-homogeneous coordinates.\n  transformed_vectors = from_homogeneous(transformed_vectors)\n\n  return transformed_vectors\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Convert the input 'vectors' to homogeneous points.\n  homogeneous_vectors = to_homogeneous(vectors)\n\n  # Apply the homogeneous transformation to the homogeneous points.\n  homogeneous_transformed_vectors = matmul(homogeneous_vectors, transform)\n\n  # Convert the transformed points back to non-homogeneous points.\n  transformed_vectors = from_homogeneous(homogeneous_transformed_vectors)\n\n  return transformed_vectors\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Convert the input to a homogeneous representation.\n  homogeneous_vectors = to_homogeneous(vectors)\n\n  # Apply the transformation.\n  homogeneous_transformed_vectors = matmul(homogeneous_vectors, transform)\n\n  # Convert the result back to non-homogeneous representation.\n  transformed_vectors = from_homogeneous(homogeneous_transformed_vectors)\n\n  return transformed_vectors\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Convert the input vectors to homogeneous coordinates\n  homogeneous_vectors = to_homogeneous(vectors)\n\n  # Apply the homogeneous transformation\n  transformed_vectors = matmul(homogeneous_vectors, transform)\n\n  # Convert the transformed vectors back to non-homogeneous coordinates\n  transformed_vectors = from_homogeneous(transformed_vectors)\n\n  return transformed_vectors\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Convert the input to homogeneous coordinates.\n  homogeneous_vectors = to_homogeneous(vectors)\n\n  # Apply the transformation.\n  transformed_vectors = matmul(homogeneous_vectors, transform)\n\n  # Convert the output to non-homogeneous coordinates.\n  transformed_vectors = from_homogeneous(transformed_vectors)\n\n  return transformed_vectors\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Convert the input vectors to homogeneous coordinates.\n  homogeneous_vectors = to_homogeneous(vectors)\n\n  # Apply the transformation.\n  transformed_vectors = matmul(homogeneous_vectors, transform)\n\n  # Convert the transformed vectors to non-homogeneous coordinates.\n  return from_homogeneous(transformed_vectors)\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Add an extra dimension to the vectors so that they can be multiplied with the transformation matrix.\n  vectors = vectors[Ellipsis, jnp.newaxis]\n\n  # Apply the transformation.\n  transformed_vectors = matmul(transform, vectors)\n\n  # Remove the extra dimension from the transformed vectors.\n  transformed_vectors = transformed_vectors[Ellipsis, 0]\n\n  return transformed_vectors\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Add an extra dimension to the last axis, to allow for broadcasting.\n  vectors = vectors[Ellipsis, jnp.newaxis, :]\n\n  # Add an extra dimension to the last axis of the transform, to allow for broadcasting.\n  transform = transform[..., jnp.newaxis, :, :]\n\n  # The last axis of the transform is the dimensionality of the vectors (C+1).\n  # The last axis of the vectors is the dimensionality of the vectors (C).\n  # The result of this multiplication is (...,C,C+1).\n  # The first axis of the result is the same as the first axis of the transform (...,C+1).\n  # The second axis of the result is the same as the second axis of the vectors (...,C).\n  result = transform * vectors\n\n  # Sum over the last axis of the transform, to get (...,C).\n  result = jnp.sum(result, axis=-1)\n\n  # Remove the last axis, to get (*,C).\n  result = result[..., 0]\n\n  return result\n\n"}
{"namespace": "stepfun.resample", "completion": "  # Check that t and tp are valid step functions.\n  utils.assert_valid_stepfun(t, jnp.ones(t.shape))\n  utils.assert_valid_stepfun(tp, jnp.ones(tp.shape))\n\n  # Check that t and tp have the same number of intervals.\n  assert t.shape[-1] == tp.shape[-1] + 1\n\n  # Check that t and tp are sorted.\n  assert jnp.all(jnp.diff(t) >= 0)\n  assert jnp.all(jnp.diff(tp) >= 0)\n\n  # Check that t and tp are non-decreasing.\n  assert jnp.all(t[Ellipsis, :-1] <= t[Ellipsis, 1:])\n  assert jnp.all(tp[Ellipsis, :-1] <= tp[Ellipsis, 1:])\n\n  # Check that tp[..., 0] <= t[..., 0] and tp[..., -1] <= t[..., -1].\n  assert jnp.all(tp[Ellipsis, 0] <= t[Ellipsis, 0])\n  assert jnp.all(tp[Ellipsis, -1] <= t[Ellipsis, -1])\n\n  # Check that tp[..., 0] >= t[..., 1] and tp[..., -1] <= t[..., -2].\n  assert jnp.all(tp[Ellipsis, 0] >= t[Ellipsis, 1])\n  assert jnp.all(tp[Ellipsis, -1] >= t[Ellipsis, -2])\n\n  # Check that vp is a valid step function.\n  utils.assert_valid_stepfun(tp, vp)\n\n  # Check that vp has the same number of intervals as tp.\n  assert vp.shape[-1] == tp.shape[-1]\n\n  # Check that vp is sorted.\n  assert jnp.all(j"}
{"namespace": "stepfun.resample", "completion": "  t = jnp.asarray(t)\n  tp = jnp.asarray(tp)\n  vp = jnp.asarray(vp)\n  t = jnp.sort(t)\n  tp = jnp.sort(tp)\n  tp = jnp.append(tp, tp[-1] + 1)\n  tp = jnp.insert(tp, 0, tp[0] - 1)\n  vp = jnp.append(vp, vp[-1])\n  vp = jnp.insert(vp, 0, vp[0])\n  if use_avg:\n    v = jnp.vectorize(linspline.linspline_avg, signature='(n),(n),(n)->(n)')(t, tp, vp)\n  else:\n    v = jnp.vectorize(linspline.linspline, signature='(n),(n),(n)->(n)')(t, tp, vp)\n  return v\n\n"}
{"namespace": "stepfun.resample", "completion": "  # Assert that the input tensors have the same shape.\n  assert tp.shape == vp.shape\n  assert t.shape == tp.shape\n\n  # Assert that the input tensors are of the same dtype.\n  assert tp.dtype == vp.dtype\n  assert t.dtype == tp.dtype\n\n  # Assert that the input tensors have the same dimensions.\n  assert tp.ndim == vp.ndim\n  assert t.ndim == tp.ndim\n\n  # Assert that the input tensors have at least one dimension.\n  assert tp.ndim > 0\n  assert t.ndim > 0\n\n  # Assert that the input tensors have the same number of dimensions.\n  assert tp.ndim == t.ndim\n\n  # Assert that the input tensors are one-dimensional.\n  assert tp.ndim == 1\n  assert t.ndim == 1\n\n  # Assert that the input tensors have the same number of elements.\n  assert tp.shape[0] == vp.shape[0]\n  assert t.shape[0] == tp.shape[0]\n\n  # Assert that the input tensors are sorted in ascending order.\n  assert jnp.all(jnp.diff(tp) >= 0)\n  assert jnp.all(jnp.diff(t) >= 0)\n\n  # Assert that the input tensors are strictly increasing.\n  assert jnp.all(jnp.diff(tp) > 0)\n  assert jnp.all(jnp.diff(t) > 0)\n\n  # Assert that the input tensors have the same number of elements.\n  assert t.shape[0] == tp.shape[0]\n\n  # Assert that the input tensors have the same number of elements.\n  assert t.shape[0] == vp.shape[0]\n\n  # Assert that the input tensors have the same number of elements.\n  assert t.shape[0] == tp.shape[0]\n\n  # Assert that the input tensors have the same"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  utils.assert_valid_stepfun(t, jnp.ones(t.shape[-1]))\n\n  # If the original time points are not sorted, we sort them.\n  if not utils.is_sorted(tp):\n    tp, vp = jnp.sort(tp), vp[jnp.argsort(tp)]\n\n  # If the new time points are not sorted, we sort them.\n  if not utils.is_sorted(t):\n    t = jnp.sort(t)\n\n  # We find the indices of the original time points that are closest to the new time points.\n  idx = jnp.searchsorted(tp, t, side='right')\n\n  # We find the values of the step function at the new time points.\n  v = jnp.take_along_axis(vp, idx, axis=-1)\n\n  # If we want to average the values of the step function, we need to find the width of each interval in `t`.\n  if use_avg:\n    t_diff = jnp.diff(t)\n    tp_diff = jnp.diff(tp)\n    t_diff = jnp.expand_dims(t_diff, axis=-1)\n    tp_diff = jnp.expand_dims(tp_diff, axis=-1)\n    v = jnp.sum(v * t_diff / tp_diff, axis=-1)\n\n  return v\n\n"}
{"namespace": "stepfun.resample", "completion": "  # TODO: add support for 1D inputs\n  # TODO: add support for multi-dimensional inputs\n  # TODO: add support for batched inputs\n  # TODO: add support for multi-dimensional outputs\n\n  if tp.ndim != 2 or t.ndim != 2 or vp.ndim != 2:\n    raise ValueError('Only 2D inputs are supported.')\n\n  if tp.shape[1] != t.shape[1] or tp.shape[1] != vp.shape[1]:\n    raise ValueError('The number of time points must match.')\n\n  if tp.shape[0] != vp.shape[0]:\n    raise ValueError('The number of values must match.')\n\n  if tp.shape[0] != 2:\n    raise ValueError('Only two time points are supported.')\n\n  # TODO: add support for batched inputs\n  # TODO: add support for multi-dimensional inputs\n  # TODO: add support for multi-dimensional outputs\n\n  # TODO: add support for 1D inputs\n\n  # TODO: add support for batched inputs\n\n  # TODO: add support for multi-dimensional inputs\n\n  # TODO: add support for multi-dimensional outputs\n\n  # TODO: add support for 1D inputs\n\n  # TODO: add support for batched inputs\n\n  # TODO: add support for multi-dimensional inputs\n\n  # TODO: add support for multi-dimensional outputs\n\n  # TODO: add support for 1D inputs\n\n  # TODO: add support for batched inputs\n\n  # TODO: add support for multi-dimensional inputs\n\n  # TODO: add support for multi-dimensional outputs\n\n  # TODO: add support for 1D inputs\n\n  # TODO: add support for batched inputs\n\n  # TODO: add support for multi-dimensional inputs\n\n  # TODO: add support for multi-dimensional outputs\n\n  # TODO: add support for 1D inputs\n\n  # TODO: add support for batched inputs\n\n  # TODO: add support for multi-dimensional inputs\n\n  # TODO: add support for multi-dimensional outputs\n\n  # TODO:"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  utils.assert_valid_stepfun(t, jnp.ones_like(t))\n\n  # Find the cumulative weights for each interval in t.\n  cw = integrate_weights(jnp.ones_like(t))\n\n  # Interpolate into the cumulative weights for each interval in t.\n  t_new = math.sorted_interp(cw, t, tp, utils.device_is_tpu())\n\n  # Interpolate the values of the step function for each interval in t.\n  v_new = math.sorted_interp(t_new, tp, vp, utils.device_is_tpu())\n\n  if use_avg:\n    # Weight the values of the step function by the width of each interval in t.\n    v_new = v_new * jnp.diff(t_new)\n\n  return v_new\n\n"}
{"namespace": "stepfun.resample", "completion": "  # Check the validity of the inputs.\n  utils.assert_valid_stepfun(tp, vp)\n  if t.ndim != 1:\n    raise ValueError(\n      f'The tensor `t` must be one-dimensional, but it has shape {t.shape}.'\n    )\n  if tp.ndim != 1:\n    raise ValueError(\n      f'The tensor `tp` must be one-dimensional, but it has shape {tp.shape}.'\n    )\n  if vp.ndim != 1:\n    raise ValueError(\n      f'The tensor `vp` must be one-dimensional, but it has shape {vp.shape}.'\n    )\n  if tp.shape[0] != vp.shape[0]:\n    raise ValueError(\n      f'The number of elements of `tp` ({tp.shape[0]}) must match the number of elements of `vp` ({vp.shape[0]}).'\n    )\n\n  # Get the values of the step function at the new time points.\n  if use_avg:\n    # Compute the width of each interval in `t`.\n    dt = jnp.diff(t)\n    # Compute the cumulative sum of the values of the step function.\n    vp_cumsum = jnp.cumsum(vp)\n    # Compute the cumulative sum of the widths of the intervals in `t`.\n    dt_cumsum = jnp.cumsum(dt)\n    # Interpolate the cumulative sum of the values of the step function into the new time points.\n    vp_new = jnp.interp(t, tp, vp_cumsum)\n    # Interpolate the cumulative sum of the widths of the intervals in `t`.\n    dt_cumsum_new = jnp.interp(t, tp, dt_cumsum)\n    # Compute the average value of the step function in each interval in `t`.\n    vp_new = vp_new / dt_cumsum_new\n  else:\n    #"}
{"namespace": "stepfun.resample", "completion": "  # Check if the input tensors are valid.\n  utils.assert_valid_stepfun(tp, vp)\n  utils.assert_valid_stepfun(t)\n\n  # Compute the weight of each interval in `t` that corresponds to the original step function.\n  w = jnp.diff(t)\n\n  # Compute the indices of the original intervals that correspond to the new intervals in `t`.\n  (i0, i1), _ = math.sorted_lookup(t, tp, (jnp.arange(tp.shape[-1]),), utils.device_is_tpu())\n\n  # Compute the values of the original step function at the new time points.\n  v = jnp.where(i0 == i1, vp[i0], vp[i0] + vp[i1])\n\n  # Compute the weighted average of the values of the original step function at the new time points.\n  if use_avg:\n    v = jnp.where(i0 == i1, vp[i0], (vp[i0] + vp[i1]) / 2)\n\n  return v\n\n"}
{"namespace": "stepfun.resample", "completion": "  t = jnp.asarray(t)\n  tp = jnp.asarray(tp)\n  vp = jnp.asarray(vp)\n\n  # Define the function that resamples the step function.\n  def _resample(t, tp, vp, use_avg):\n    # The number of intervals in the new step function.\n    n = t.shape[0]\n\n    # The number of intervals in the original step function.\n    m = tp.shape[0]\n\n    # The widths of the new intervals.\n    d = jnp.diff(t)\n\n    # The widths of the original intervals.\n    dtp = jnp.diff(tp)\n\n    # The indices of the original intervals that each new interval falls in.\n    # idx = jnp.searchsorted(tp, t) - 1\n    idx = jnp.clip(jnp.searchsorted(tp, t) - 1, 0, m - 2)\n\n    # The indices of the new intervals that each original interval falls in.\n    idx_tp = jnp.clip(jnp.searchsorted(t, tp) - 1, 0, n - 2)\n\n    # The indices of the new intervals that each original interval falls in.\n    idx_tp = jnp.clip(jnp.searchsorted(t, tp) - 1, 0, n - 2)\n\n    # The indices of the new intervals that each original interval falls in.\n    idx_tp = jnp.clip(jnp.searchsorted(t, tp) - 1, 0, n - 2)\n\n    # The indices of the original intervals that each new interval falls in.\n    idx = jnp.clip(jnp.searchsorted(tp, t) - 1, 0, m - 2)\n\n    # The indices of the new intervals that each original interval falls in.\n    idx_tp = jnp.clip(jnp.searchsorted(t, tp) - 1, 0, n - 2)\n\n    # The indices of the new intervals that each original interval"}
{"namespace": "stepfun.resample", "completion": "  # Check if the input tensors have the correct shapes\n  assert t.ndim == 1, \"t must be a 1D tensor.\"\n  assert tp.ndim == 1, \"tp must be a 1D tensor.\"\n  assert vp.ndim == 1, \"vp must be a 1D tensor.\"\n  assert t.shape[0] == tp.shape[0] - 1, \"t must be one element shorter than tp.\"\n  assert tp.shape[0] == vp.shape[0], \"tp and vp must have the same shape.\"\n\n  # Find the width of each interval in t\n  t_width = t[Ellipsis, 1:] - t[Ellipsis, :-1]\n\n  # Find the width of each interval in tp\n  tp_width = tp[Ellipsis, 1:] - tp[Ellipsis, :-1]\n\n  # Find the indices of the intervals in tp that are contained in each interval in t\n  t_indices = jnp.searchsorted(tp[Ellipsis, :-1], t, side=\"left\")\n\n  # Find the indices of the intervals in tp that are adjacent to each interval in t\n  t_adj_indices = jnp.clip(t_indices + 1, 0, tp_width.shape[-1] - 1)\n\n  # Find the indices of the intervals in tp that are adjacent to each interval in t\n  t_adj_indices = jnp.clip(t_indices + 1, 0, tp_width.shape[-1] - 1)\n\n  # Find the fraction of each interval in t that is contained in each interval in tp\n  t_frac = jnp.divide(t - tp[Ellipsis, t_indices], tp_width[Ellipsis, t_indices])\n\n  # Find the fraction of each interval in t that is contained in each interval in tp\n  t_adj_frac = jnp.divide(t - tp[Ellipsis, t"}
{"namespace": "stepfun.resample", "completion": "  # Check if the input is valid.\n  utils.assert_valid_stepfun(tp, vp)\n\n  # If the resampling method is averaging, we need to normalize the weights.\n  if use_avg:\n    w = jnp.diff(tp)\n\n  # Get the index of the intervals in tp that each point in t falls into.\n  idx = math.sorted_search(tp, t, utils.device_is_tpu())\n\n  # Get the weights of each interval in tp that each point in t falls into.\n  tp_left = tp[Ellipsis, idx]\n  tp_right = tp[Ellipsis, idx + 1]\n  w = tp_right - tp_left\n\n  # If the resampling method is averaging, we need to normalize the weights.\n  if use_avg:\n    w = jnp.divide(w, jnp.sum(w, axis=-1, keepdims=True))\n\n  # Return the weighted sum of the values in vp for each interval in t.\n  return jnp.sum(w * vp[Ellipsis, idx], axis=-1)\n\n"}
{"namespace": "stepfun.resample", "completion": "  # Assert that the time points are sorted in ascending order.\n  assert (jnp.all(jnp.diff(tp) >= 0))\n\n  # Compute the widths of the intervals in t.\n  dt = jnp.diff(t)\n\n  # Compute the indices of the intervals in tp that are included in each interval in t.\n  tp_idx = jnp.searchsorted(tp, t)\n\n  # Compute the indices of the intervals in t that are included in each interval in tp.\n  t_idx = jnp.searchsorted(t, tp)\n\n  # Compute the number of intervals in t that are included in each interval in tp.\n  n_t_in_tp = t_idx[1:] - t_idx[:-1]\n\n  # Compute the number of intervals in tp that are included in each interval in t.\n  n_tp_in_t = jnp.concatenate([jnp.array([tp_idx[0]]), tp_idx[n_t_in_tp]])\n\n  # Compute the number of intervals in tp that are included in each interval in t.\n  n_tp_in_t = n_tp_in_t[1:] - n_tp_in_t[:-1]\n\n  # Compute the widths of the intervals in tp that are included in each interval in t.\n  tp_dt = jnp.diff(tp)\n\n  # Compute the widths of the intervals in t that are included in each interval in tp.\n  t_dt = jnp.where(n_t_in_tp > 0, dt[n_t_in_tp - 1], 0)\n\n  # Compute the widths of the intervals in tp that are included in each interval in t.\n  tp_dt = jnp.where(n_tp_in_t > 0, tp_dt[n_tp_in_t - 1], 0)\n\n  # Compute the fraction of each interval in tp that is included in each interval in t.\n  tp_"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(t, tp, vp)\n  # Find the width of each interval in `t`.\n  dt = jnp.diff(t)\n  # Find the indices of the intervals in `t` that contain each point in `tp`.\n  (i,) = math.sorted_lookup(tp, t, (jnp.arange(tp.shape[0]),), utils.device_is_tpu())\n  # Resample the step function.\n  if use_avg:\n    # Compute the weights for each interval in `t`.\n    w = dt[i] / dt[i - 1]\n    # Resample the step function.\n    v = jnp.sum(w * vp, axis=-1)\n  else:\n    # Resample the step function.\n    v = jnp.sum(vp, axis=-1)\n  return v\n\n"}
{"namespace": "stepfun.resample", "completion": "  # Get the indices of the intervals in tp that contain each point in t.\n  # The intervals in tp are assumed to be sorted.\n  # The indices are also sorted.\n  # The last interval is the last one in tp.\n  # The first interval is the first one in tp.\n  # The middle intervals are the ones in between.\n  # The intervals in t are assumed to be sorted.\n  # The indices are also sorted.\n  # The first interval is the first one in t.\n  # The last interval is the last one in t.\n  # The middle intervals are the ones in between.\n  tp_idx = jnp.searchsorted(tp, t, side='right') - 1\n\n  # The first and last intervals are special cases.\n  # The first interval is the first one in tp.\n  # The last interval is the last one in tp.\n  tp_idx = jnp.concatenate(\n      [jnp.zeros(1, dtype=jnp.int32), tp_idx, tp_idx[-1:]], axis=0\n  )\n\n  # Get the indices of the intervals in t that contain each point in tp.\n  # The intervals in t are assumed to be sorted.\n  # The indices are also sorted.\n  # The first interval is the first one in t.\n  # The last interval is the last one in t.\n  # The middle intervals are the ones in between.\n  # The intervals in tp are assumed to be sorted.\n  # The indices are also sorted.\n  # The first interval is the first one in tp.\n  # The last interval is the last one in tp.\n  # The middle intervals are the ones in between.\n  t_idx = jnp.searchsorted(t, tp, side='right') - 1\n\n  # The first and last intervals are special cases.\n  # The first interval is the first one in t.\n  # The last interval is the last one in t.\n  t_idx = jnp.concatenate(\n      [jnp.zeros(1, dtype=jnp.int3"}
{"namespace": "stepfun.resample", "completion": "  # Find the width of each interval in t.\n  dt = jnp.diff(t)\n\n  # Find the intervals in tp that overlap with each interval in t.\n  # tp_ind contains the index of the first tp that overlaps with each interval in t.\n  tp_ind = jnp.searchsorted(tp, t, side='left')\n  # tp_ind_next contains the index of the last tp that overlaps with each interval in t.\n  tp_ind_next = tp_ind + 1\n\n  # Find the value of the first tp that overlaps with each interval in t.\n  tp_prev = jnp.take_along_axis(tp, tp_ind[..., None], axis=-1)\n  # Find the value of the last tp that overlaps with each interval in t.\n  tp_next = jnp.take_along_axis(tp, tp_ind_next[..., None], axis=-1)\n\n  # Find the width of each interval in tp.\n  dtp = tp_next - tp_prev\n\n  # Find the value of the first tp that overlaps with each interval in t.\n  vp_prev = jnp.take_along_axis(vp, tp_ind[..., None], axis=-1)\n  # Find the value of the last tp that overlaps with each interval in t.\n  vp_next = jnp.take_along_axis(vp, tp_ind_next[..., None], axis=-1)\n\n  # Find the weight of the first tp that overlaps with each interval in t.\n  w_prev = jnp.divide(dtp, dt[..., None])\n  # Find the weight of the last tp that overlaps with each interval in t.\n  w_next = 1 - w_prev\n\n  # Combine the weights and values of the first and last tp that overlap with each interval in t.\n  v_prev = jnp.multiply(vp_prev, w_prev)\n  v_next = jnp.multiply("}
{"namespace": "stepfun.resample", "completion": "  tp = jnp.expand_dims(tp, -2)\n  vp = jnp.expand_dims(vp, -2)\n  t = jnp.expand_dims(t, -1)\n\n  # Find the intervals in tp that each point in t falls into.\n  t_idx = math.sorted_search(tp, t)\n  # Get the index of the previous interval.\n  idx_prev = jnp.maximum(0, t_idx - 1)\n  # Get the index of the next interval.\n  idx_next = jnp.minimum(tp.shape[-1] - 1, t_idx)\n  # Get the values of the previous interval.\n  v_prev = vp[..., idx_prev, :]\n  # Get the values of the next interval.\n  v_next = vp[..., idx_next, :]\n  # Get the width of the previous interval.\n  t_prev = tp[..., idx_prev, :]\n  # Get the width of the next interval.\n  t_next = tp[..., idx_next, :]\n\n  # Compute the weights of the previous and next intervals.\n  w_prev = t[Ellipsis, -1] - t\n  w_next = t - t_prev\n\n  # If the previous and next intervals are the same, then the weight of the previous interval is 1 and the weight of the next interval is 0.\n  w_prev = jnp.where(t_prev == t_next, 1., w_prev)\n  w_next = jnp.where(t_prev == t_next, 0., w_next)\n\n  # If use_avg is True, then weight the values of the previous and next intervals by their widths.\n  v_prev = jnp.where(use_avg, v_prev * w_prev, v_prev)\n  v_next = jnp.where(use_avg, v_next * w_next, v_next)\n\n  # Compute the resampled values of the step function.\n  v ="}
{"namespace": "stepfun.resample", "completion": "  # Check if tp and vp are valid.\n  if tp.ndim != 2 or vp.ndim != 2:\n    raise ValueError('tp and vp must be 2D tensors.')\n\n  if tp.shape[0] != vp.shape[0] or tp.shape[1] != 2:\n    raise ValueError('tp must be of shape (N, 2) and vp must be of shape (N, M).')\n\n  # Check if t is valid.\n  if t.ndim != 1:\n    raise ValueError('t must be a 1D tensor.')\n\n  # Check if tp and t are valid.\n  if tp.shape[0] != t.shape[0] - 1:\n    raise ValueError('t must be of shape (N + 1,).')\n\n  # Check if tp and t are valid.\n  if tp.shape[0] != t.shape[0] - 1:\n    raise ValueError('t must be of shape (N + 1,).')\n\n  # Check if tp and vp are valid.\n  if tp.shape[0] != vp.shape[0]:\n    raise ValueError('tp and vp must have the same length.')\n\n  # Check if tp and vp are valid.\n  if tp.shape[1] != 2:\n    raise ValueError('tp must be of shape (N, 2).')\n\n  # Check if tp and vp are valid.\n  if vp.ndim != 2:\n    raise ValueError('vp must be a 2D tensor.')\n\n  # Check if use_avg is valid.\n  if type(use_avg) is not bool:\n    raise ValueError('use_avg must be a boolean.')\n\n  # If we do not use averaging, we simply return the sum of the values in each\n  # interval.\n  if not use_avg:\n    return jax.vmap(lambda tp, vp: query(t, tp, vp"}
{"namespace": "stepfun.resample", "completion": "  # Check the validity of the input arguments.\n  utils.assert_valid_stepfun(tp, vp)\n  utils.assert_valid_stepfun(t, jnp.ones(t.shape[:-1] + (1,)))\n\n  # If the number of intervals in t is 1, simply return the value of the original step function at the given time point.\n  if t.shape[-1] == 1:\n    return jnp.expand_dims(query(t, tp, vp), axis=-1)\n\n  # If the number of intervals in t is 2, simply return the average of the two intervals.\n  if t.shape[-1] == 2:\n    return jnp.expand_dims(jnp.mean(vp, axis=-1), axis=-1)\n\n  # If the number of intervals in t is larger than 2, resample the step function using the specified method.\n  else:\n\n    # If the use_avg flag is set to False, the function sums the values of the step function for each interval in t.\n    if use_avg == False:\n\n      # Compute the width of each interval in t.\n      width = jnp.diff(t, axis=-1)\n\n      # For each interval in t, compute the intervals in tp that fall into it.\n      t_tp = jnp.expand_dims(t, axis=-1)\n      tp_t = jnp.expand_dims(tp, axis=-2)\n      mask = (tp_t >= t_tp[Ellipsis, 0]) & (tp_t < t_tp[Ellipsis, 1])\n\n      # For each interval in t, sum the values of the step function in the corresponding intervals in tp.\n      vp_t = jnp.expand_dims(vp, axis=-1)\n      v_t = jnp.sum(jnp.where(mask, vp_t, 0), axis=-2)\n\n      # Return the resampled step function.\n      return v_t\n\n    # If the use_avg"}
{"namespace": "stepfun.resample", "completion": "  # Check if the input is valid\n  utils.assert_valid_stepfun(tp, vp)\n\n  # The new time points are the same as the old time points\n  if t.shape == tp.shape:\n    if jnp.allclose(t, tp):\n      return vp\n\n  # Find the new time points that fall into the old intervals\n  t_new = jnp.minimum(jnp.maximum(t, tp[Ellipsis, :-1]), tp[Ellipsis, 1:])\n\n  # Find the index of the old interval that each new time point falls into\n  idx = jnp.searchsorted(tp[Ellipsis, 1:], t_new, side='right')\n\n  # Find the width of each interval in the old time points\n  width = jnp.diff(tp)\n\n  # Find the width of each interval in the new time points\n  width_new = jnp.diff(t)\n\n  # Find the values of the old step function at the new time points\n  v_new = jnp.take_along_axis(vp, idx[Ellipsis, None], axis=-1)\n\n  # Resample the step function using the summation method\n  if use_avg == False:\n\n    # Find the number of new time points for each interval in the old time points\n    num_new = jnp.diff(idx)\n\n    # Sum the values of the old step function for each interval in the new time points\n    v_new = jnp.sum(v_new * num_new[Ellipsis, None], axis=-1) / jnp.sum(\n        num_new[Ellipsis, None], axis=-1)\n\n    # Return the resampled step function\n    return v_new\n\n  # Resample the step function using the averaging method\n  else:\n\n    # Find the values of the old step function at the endpoints of each interval in the new time points\n    v_new_start = jnp.take_along_axis(vp, idx[Ellipsis, None],"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  t = jnp.sort(t)\n  tp = jnp.sort(tp)\n  vp = jnp.sort(vp)\n\n  # find the index of the first element in tp that is greater than t\n  t_index = jnp.searchsorted(tp, t)\n  # find the index of the first element in t that is greater than tp\n  tp_index = jnp.searchsorted(t, tp)\n\n  # resampled value at each point in t\n  v = jnp.zeros(t.shape)\n\n  # for each element in t\n  for i in range(t.shape[0]):\n\n    # find the index of the first element in tp that is greater than t[i]\n    t_index_i = t_index[i]\n\n    # find the index of the first element in t that is greater than tp\n    tp_index_i = tp_index[t_index_i]\n\n    # if the index is 0, then t[i] is smaller than the first element in tp\n    if t_index_i == 0:\n      v = v.at[i].set(0)\n    # if the index is tp.shape[0], then t[i] is greater than the last element in tp\n    elif t_index_i == tp.shape[0]:\n      v = v.at[i].set(0)\n    # if the index is between 0 and tp.shape[0], then t[i] is between the (t_index_i-1)th and t_index_i th element in tp\n    else:\n      # find the width of the interval in tp\n      width = tp[t_index_i] - tp[t_index_i - 1]\n      # find the width of the interval in t\n      width_i = t[i] - t[i - 1]\n      # find the width of the interval in t that is between the (t_index_i-1"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance of the coordinates.\n  scaled_mean = mean * jnp.sqrt(var)\n  scaled_var = var * jnp.sqrt(var)\n\n  # Concatenate the mean and variance of the coordinates.\n  concat_coords = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n\n  # Encode the concatenated coordinates.\n  encoded_coords = math.sinusoidal_encode(concat_coords, min_deg, max_deg)\n\n  return encoded_coords\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Compute the scaling factor for the encoding\n  deg = jnp.arange(min_deg, max_deg)\n  deg_scale = jnp.power(0.5, deg)\n  deg_scale = jnp.reshape(deg_scale, [1, 1, 1, -1])\n\n  # Scale the mean and variance\n  scaled_mean = mean * deg_scale\n  scaled_var = var * jnp.power(deg_scale, 2)\n\n  # Concatenate the mean and variance\n  scaled_mean_var = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n\n  # Encode the concatenated mean and variance\n  encoded_mean_var = math.sin_encode(scaled_mean_var)\n\n  return encoded_mean_var\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance\n  mean_scaled = mean / jnp.sqrt(var)\n  var_scaled = 1 / jnp.sqrt(var)\n\n  # Concatenate the mean and variance\n  mean_var = jnp.concatenate([mean_scaled, var_scaled], axis=-1)\n\n  # Encode the mean and variance\n  mean_var_enc = sinusoidal_encoding(mean_var, min_deg, max_deg)\n\n  return mean_var_enc\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # The encoding is applied to the mean and variance of the coordinates, which are scaled and concatenated.\n  mean_var = jnp.concatenate([mean, var], axis=-1)\n\n  # The mean and variance are scaled by a power of 2 in the range specified by the min and max degrees.\n  mean_var_scaled = mean_var * jnp.power(2, jnp.arange(min_deg, max_deg))\n\n  # The mean and variance are encoded using sinusoidal functions.\n  mean_var_encoded = jnp.sin(mean_var_scaled)\n\n  return mean_var_encoded\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Calculate the encoding scale factors\n  scale_factors = 2.0 ** jnp.arange(min_deg, max_deg)\n\n  # Scale the mean and variance\n  scaled_mean = mean * scale_factors\n  scaled_var = var * scale_factors ** 2\n\n  # Concatenate the mean and variance\n  concat_mean_var = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n\n  # Apply the sinusoidal encoding\n  encoded_mean_var = math.safe_sin(concat_mean_var)\n\n  return encoded_mean_var\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Compute the encoding scale\n  scale = jnp.power(2, jnp.arange(min_deg, max_deg))\n\n  # Scale the mean and variance\n  scaled_mean = mean * scale\n  scaled_var = var * scale\n\n  # Concatenate the mean and variance\n  scaled_coord = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n\n  # Apply sinusoidal encoding\n  encoded_coord = jnp.sin(scaled_coord)\n\n  return encoded_coord\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Check if the input arguments are valid.\n  if min_deg < 0:\n    raise ValueError('The minimum degree should be a positive integer.')\n  if max_deg < 1:\n    raise ValueError('The maximum degree should be at least 1.')\n  if min_deg >= max_deg:\n    raise ValueError('The minimum degree should be less than the maximum degree.')\n\n  # Compute the encoding.\n  enc_mean = jnp.zeros_like(mean)\n  enc_var = jnp.zeros_like(var)\n  for deg in range(min_deg, max_deg):\n    enc_mean = jnp.concatenate((enc_mean, math.safe_sin(mean * 2 ** deg)), axis=-1)\n    enc_var = jnp.concatenate((enc_var, math.safe_sin(var * 2 ** deg)), axis=-1)\n\n  return enc_mean, enc_var\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance of the coordinates.\n  scaled_mean = mean * jnp.sqrt(var)\n  scaled_var = var * jnp.sqrt(var)\n\n  # Concatenate the mean and variance of the coordinates.\n  concat_coords = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n\n  # Apply the sinusoidal encoding to the concatenated coordinates.\n  encoded_coords = math.sinusoidal_encode(concat_coords, min_deg, max_deg)\n\n  return encoded_coords\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Compute the mean and variance of the encoded variables.\n  mean_enc = math.safe_sin(mean)\n  var_enc = jnp.exp(-0.5 * var) * math.safe_sin(var)\n\n  # Compute the encoding scale and concatenate the mean and variance.\n  scale = jnp.arange(min_deg, max_deg, dtype=jnp.float32)\n  enc = jnp.concatenate([mean_enc, var_enc], axis=-1)\n\n  # Apply the encoding to the encoding scale.\n  enc = jnp.sin(scale * enc)\n\n  return enc\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Compute the scaling factor for the encoding.\n  scale = jnp.sqrt(jnp.arange(min_deg, max_deg))\n  # Scale the mean and variance.\n  mean = mean * scale\n  var = var * scale**2\n  # Encode the scaled mean and variance.\n  mean = math.safe_sin(mean)\n  var = math.safe_sin(var)\n  # Concatenate the mean and variance.\n  mean = jnp.concatenate([mean, var], axis=-1)\n  return mean\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Compute the mean and variance of the encoded variables\n  mean_enc = math.safe_sin(mean)\n  var_enc = expected_sin(mean, var)\n\n  # Scale the mean and variance to the encoding range\n  mean_enc_scaled = jnp.zeros(mean_enc.shape)\n  var_enc_scaled = jnp.zeros(var_enc.shape)\n  for deg in range(min_deg, max_deg):\n    mean_enc_scaled += mean_enc * (2.0**deg)\n    var_enc_scaled += var_enc * (2.0**(2 * deg))\n\n  # Concatenate the mean and variance\n  mean_var_enc = jnp.concatenate([mean_enc_scaled, var_enc_scaled], axis=-1)\n\n  # Apply the sinusoidal encoding\n  sin_enc = math.safe_sin(mean_var_enc)\n\n  return sin_enc\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Compute the scaling factor for the encoding.\n  deg = jnp.arange(min_deg, max_deg)\n  deg_scale = jnp.power(10000, -2 * deg / 34.0)\n\n  # Scale the mean and variance of the coordinates.\n  mean = mean * deg_scale\n  var = var * deg_scale\n\n  # Concatenate the mean and variance of the coordinates.\n  mean_var = jnp.concatenate([mean, var], axis=-1)\n\n  # Apply the sinusoidal encoding.\n  mean_var_enc = math.safe_sin(mean_var)\n\n  return mean_var_enc\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance of the coordinates.\n  mean, var = mean * jnp.sqrt(2), jnp.sqrt(var)\n\n  # Concatenate the mean and variance.\n  mean_var = jnp.concatenate([mean, var], axis=-1)\n\n  # Encode the mean and variance using a sinusoidal encoding.\n  return math.sinusoidal_encode(mean_var, min_deg, max_deg)\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  if min_deg >= max_deg:\n    raise ValueError('min_deg must be less than max_deg')\n\n  # Create a tensor of sinusoidal encodings for each degree in the range.\n  degrees = jnp.arange(min_deg, max_deg)\n  encodings = jnp.sin(degrees / max_deg * math.TAU)\n\n  # Scale the mean and variance by the degrees.\n  mean = mean * degrees\n  var = var * degrees\n\n  # Combine the mean and variance into a single tensor.\n  mean_var = jnp.concatenate([mean, var], axis=-1)\n\n  # Apply the sinusoidal encoding.\n  mean_var = jnp.einsum('...d,d->...d', mean_var, encodings)\n\n  return mean_var\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scales the mean and variance of the coordinates.\n  scaled_mean = mean * jnp.sqrt(jnp.log(2) / var)\n  scaled_var = jnp.sqrt(jnp.log(2))\n\n  # Concatenates the scaled mean and variance.\n  scaled_mean_var = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n\n  # Applies a sinusoidal encoding to the scaled mean and variance.\n  sin_enc = sinusoidal_encoding(scaled_mean_var, min_deg, max_deg)\n\n  return sin_enc\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Encode the mean and variance of the coordinates using sinusoidal functions.\n  # The sinusoidal functions are scaled by powers of 2 within the range of [min_deg, max_deg).\n  # The mean and variance are scaled by the same factor to ensure the same spread of the encoded values.\n  # The mean and variance are concatenated and then encoded.\n\n  # Scale the mean and variance to have the same spread.\n  mean_var_scale = jnp.sqrt(jnp.mean(var))\n  mean_var_scaled = mean / mean_var_scale\n  var_scaled = var / (mean_var_scale ** 2)\n\n  # Encode the scaled mean and variance.\n  mean_var_scaled_enc = jnp.array([jnp.sin(math.deg_to_rad(i) * mean_var_scaled) for i in range(min_deg, max_deg)])\n  var_scaled_enc = jnp.array([jnp.sin(math.deg_to_rad(i) * var_scaled) for i in range(min_deg, max_deg)])\n\n  # Concatenate the encoded mean and variance.\n  mean_var_enc = jnp.concatenate((mean_var_scaled_enc, var_scaled_enc), axis=1)\n\n  return mean_var_enc\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Checking input arguments\n  if (min_deg < 0) or (max_deg < min_deg):\n    raise ValueError(\"min_deg must be non-negative, and max_deg must be greater than min_deg.\")\n\n  # Calculating the number of encoding scales\n  num_scales = max_deg - min_deg\n\n  # Scaling the mean and variance\n  scaled_mean = mean * jnp.sqrt(var)\n  scaled_var = var / jnp.power(2, min_deg)\n\n  # Concatenating the mean and variance\n  scaled_coords = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n\n  # Applying the sinusoidal encoding\n  encoded_coords = jnp.concatenate([math.safe_sin(scaled_coords), math.safe_cos(scaled_coords)], axis=-1)\n\n  return encoded_coords\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # scale the mean and variance\n  scaled_mean = mean * jnp.sqrt(var + 1e-5)\n  scaled_var = jnp.sqrt(var)\n\n  # concatenate the scaled mean and variance\n  concat_mean_var = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n\n  # encode the concatenated variables\n  enc_concat_mean_var = geopoly.sinusoidal_encode(concat_mean_var, min_deg, max_deg)\n\n  return enc_concat_mean_var\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Check the input arguments.\n  if min_deg < 0:\n    raise ValueError('min_deg must be non-negative.')\n  if max_deg <= min_deg:\n    raise ValueError('max_deg must be greater than min_deg.')\n  if max_deg > 32:\n    raise ValueError('max_deg must be less than 32.')\n\n  # Compute the scaling factors for the encoding.\n  scale = 2.0 ** jnp.arange(min_deg, max_deg, dtype=jnp.float32)\n  scale = scale.reshape((1, 1, 1, -1))\n\n  # Scale the mean and variance.\n  mean = mean.reshape((-1, 1, 1, 3))\n  var = var.reshape((-1, 1, 1, 3))\n  mean_scaled = mean * scale\n  var_scaled = var * scale\n\n  # Concatenate the mean and variance.\n  mean_var = jnp.concatenate([mean_scaled, var_scaled], axis=-1)\n\n  # Apply the sinusoidal encoding.\n  mean_var_enc = math.safe_sin(mean_var)\n\n  return mean_var_enc\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  if min_deg < 0:\n    raise ValueError(f'min_deg must be non-negative, got {min_deg}')\n  if max_deg <= min_deg:\n    raise ValueError(f'max_deg must be greater than min_deg, got {max_deg} <= {min_deg}')\n  if min_deg == 0:\n    # The 0th degree is special, and we handle it separately.\n    mean, var = jnp.broadcast_arrays(mean, var)\n    return jnp.concatenate([mean, jnp.sqrt(var)], axis=-1)\n\n  # We use a 32-bit float to represent the scaling factor, so we can't go higher\n  # than 2**32.\n  if max_deg > 32:\n    raise ValueError(f'max_deg must be <= 32, got {max_deg}')\n  # We need to be able to represent 2**min_deg, so it can't be larger than 32 -\n  # min_deg.\n  if min_deg > 32 - min_deg:\n    raise ValueError(f'min_deg must be <= 32 - min_deg, got {min_deg} > {32 - min_deg}')\n\n  # We encode the mean and variance separately, and then concatenate them.\n  mean, var = jnp.broadcast_arrays(mean, var)\n  # We'll encode the mean and variance using a sinusoidal encoding.\n  mean_enc = math.safe_sin(mean)\n  var_enc = math.safe_sin(jnp.sqrt(var))\n  # We'll encode the mean and variance using a scaled sinusoidal encoding.\n  # We'll scale the mean and variance by 2**deg for some integer deg in the\n  # range [min_deg, max_deg).\n  # We'll encode the mean and variance using a scaled sinusoidal encoding.\n  # We'll scale the mean and variance by 2**deg for some integer deg in the"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Apply attenuation function using the"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Function returning directional encoding.\n\n    :param xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n    :param kappa_inv: [..., 1] reciprocal of the concentration parameter of the von Mises-Fisher distribution.\n    :return: An array with the resulting directional encoding.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Apply attenuation function using the von Mises"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def dir_enc_fn(xyz, kappa_inv):\n\n    \"\"\"\n    Function returning directional encoding for given inputs.\n\n    Input-Output Arguments\n    :param xyz: 3D point (or points) as input.\n    :param kappa_inv: reciprocal of the concentration parameter of the von Mises-Fisher distribution.\n    :return: The directional encoding of the input.\n\n    \"\"\"\n\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Apply attenuation function using the"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  # Generate integrated directional encoding function.\n  integrated_dir_enc_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    # Evaluate integrated directional encoding.\n    ide = integrated_dir_enc_fn(xyz, kappa_inv)\n\n    # Compute the norm of the directional encoding.\n    norm = jnp.sqrt(jnp.sum(ide**2, axis=-1, keepdims=True))\n\n    # Normalize the directional encoding.\n    return ide / norm\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  # Generate the integrated directional encoding function.\n  ide_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding (DE).\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting DE.\n    \"\"\"\n    # Compute the integrated directional encoding.\n    ide = ide_fn(xyz, kappa_inv)\n\n    # Compute the norm of the integrated directional encoding.\n    norm_ide = jnp.sqrt(jnp.sum(ide**2, axis=-1, keepdims=True))\n\n    # Normalize the integrated directional encoding.\n    norm_ide = jnp.where(norm_ide > 0, norm_ide, 1.0)\n    ide = ide / norm_ide\n\n    # Split into real and imaginary parts and return\n    return jnp.concatenate([jnp.real(ide), jnp.imag(ide)], axis=-1)\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  # Generate IDE function.\n  ide_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    ide = ide_fn(xyz, kappa_inv)\n    # Normalize by the norm of the encoding.\n    norm = math_lib.norm(ide, axis=-1, keepdims=True)\n    return ide / norm\n\n  return dir_enc_fn\n\n"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  # Generate the integrated directional encoding function.\n  ide_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    # Compute integrated directional encoding.\n    ide = ide_fn(xyz, kappa_inv)\n\n    # Normalize integrated directional encoding.\n    norm = jnp.linalg.norm(ide, axis=-1, keepdims=True)\n    ide = ide / norm\n\n    # Return directional encoding.\n    return ide\n\n  return dir_enc_fn\n\n"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  # Generate the integrated directional encoding function.\n  ide_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n\n    \"\"\"\n    Function for evaluating the directional encoding.\n\n    Input-Output Arguments:\n    :param xyz: Array. A 3D point (or points).\n    :param kappa_inv: Array. The inverse of the concentration parameter of the von Mises-Fisher distribution.\n    :return: Array. The directional encoding of the input 3D point (or points).\n\n    \"\"\"\n\n    # Get the integrated directional encoding.\n    ide = ide_fn(xyz, kappa_inv)\n\n    # Normalize the encoding.\n    norm = jnp.sqrt(jnp.sum(ide**2, axis=-1, keepdims=True))\n    ide = ide / norm\n\n    return ide\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  # Create a function that evaluates the integrated directional encoding.\n  ide_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding (DE).\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting DE.\n    \"\"\"\n    # Evaluate integrated directional encoding.\n    ide = ide_fn(xyz, kappa_inv)\n\n    # Split into real and imaginary parts.\n    ide_real = ide[Ellipsis, :ide.shape[-1] // 2]\n    ide_imag = ide[Ellipsis, ide.shape[-1] // 2:]\n\n    # Compute real and imaginary components of the Fourier transform.\n    ide_fft_real = jnp.sum(ide_real, axis=-1)\n    ide_fft_imag = jnp.sum(ide_imag, axis=-1)\n\n    # Return directional encoding.\n    return ide_fft_real + 1j * ide_fft_imag\n\n  return dir_enc_fn\n\n"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  ide_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz):\n\n    \"\"\"\n    Evaluates the directional encoding for given input.\n\n    Input-Output Arguments:\n    :param xyz: 3D point (or points) in Cartesian coordinates.\n    :return: 1D encoding of the input.\n\n    \"\"\"\n\n    ide = ide_fn(xyz, 1.0)\n    return jnp.sqrt(2.0 * jnp.pi) * ide\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  # Generate integrated directional encoding function.\n  ide_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n\n    \"\"\"\n    Function for evaluating directional encoding of a 3D point (or points).\n\n    Input-Output Arguments\n    :param xyz: Array. The 3D points to evaluate the directional encoding for.\n    :param kappa_inv: Array. The reciprocal of the concentration parameter of the von Mises-Fisher distribution.\n    :return: Array. The directional encoding of the input 3D points.\n    \"\"\"\n\n    # Get integrated directional encoding.\n    ide = ide_fn(xyz, kappa_inv)\n\n    # Compute normalization factor.\n    norm = math_lib.sqrt(jnp.sum(ide**2, axis=-1, keepdims=True))\n\n    # Normalize integrated directional encoding.\n    ide = ide / norm\n\n    # Split into real and imaginary parts and return\n    return jnp.concatenate([jnp.real(ide), jnp.imag(ide)], axis=-1)\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  # Generate the integrated directional encoding function with the specified number of spherical harmonics degrees.\n  ide_fn = generate_ide_fn(deg_view)\n\n  # Define the directional encoding function.\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n\n    # Compute the integrated directional encoding.\n    ide = ide_fn(xyz, kappa_inv)\n\n    # Compute the norm of the directional encoding.\n    norm = jnp.linalg.norm(ide, axis=-1, keepdims=True)\n\n    # Normalize the integrated directional encoding.\n    dir_enc = ide / norm\n\n    # Return the directional encoding.\n    return dir_enc\n\n  # Return the directional encoding function.\n  return dir_enc_fn\n\n"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  # Generate the integrated directional encoding function.\n  ide_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    # Get integrated directional encoding.\n    ide = ide_fn(xyz, kappa_inv)\n\n    # Compute normalization constant.\n    norm_const = 0.0\n    for m in range(deg_view):\n      l = 2**m\n      norm_const += (2 * l + 1) * math.factorial(l - 1) / math.factorial(2 * l)\n\n    # Normalize the encoding.\n    return ide / norm_const\n\n  return dir_enc_fn\n\n\n\n"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  # Generate integrated directional encoding function\n  ide_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    # Evaluate integrated directional encoding.\n    ide = ide_fn(xyz, kappa_inv)\n\n    # Compute normalization factor.\n    norm_factor = (2.0 * jnp.sum(jnp.exp(-0.5 * (ide[..., :deg_view]**2)),\n                                 axis=-1, keepdims=True))**0.5\n\n    # Normalize and return directional encoding.\n    return ide / norm_factor\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  # Generate IDE function\n  ide_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n\n    \"\"\"\n    Function returning directional encoding.\n\n    Input-Output Arguments:\n    :param xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n    :param kappa_inv: [..., 1] reciprocal of the concentration parameter of the von Mises-Fisher distribution.\n    :return: [..., 2*deg_view] array of directional encoding.\n    \"\"\"\n\n    # Get integrated directional encoding\n    ide = ide_fn(xyz, kappa_inv)\n\n    # Compute the norm of the encoding\n    norm = jnp.linalg.norm(ide, axis=-1, keepdims=True)\n\n    # Normalize the encoding\n    ide_norm = ide / norm\n\n    # Return the normalized encoding\n    return ide_norm\n\n  return dir_enc_fn\n\n"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  # Generate IDE function\n  ide_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n\n    \"\"\"\n    Function for evaluating the directional encoding of a 3D point (or points).\n\n    Input-Output Arguments:\n    :param xyz: 3D point (or points) in Cartesian coordinates.\n    :param kappa_inv: The reciprocal of the concentration parameter of the von Mises-Fisher distribution.\n    :return: The directional encoding of the input 3D point (or points).\n    \"\"\"\n\n    # Get integrated directional encoding\n    ide = ide_fn(xyz, kappa_inv)\n\n    # Normalize the encoding\n    norm_ide = jnp.linalg.norm(ide, axis=-1, keepdims=True)\n    norm_ide = jnp.maximum(norm_ide, jnp.finfo(jnp.float32).tiny)\n    ide_normalized = ide / norm_ide\n\n    return ide_normalized\n\n  return dir_enc_fn\n\n"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  # Generate the integrated directional encoding function.\n  ide_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    # Compute integrated directional encoding.\n    ide = ide_fn(xyz, kappa_inv)\n\n    # Compute directional encoding.\n    return jnp.concatenate([ide, jnp.sum(ide**2, axis=-1, keepdims=True)],\n                           axis=-1)\n\n  return dir_enc_fn\n\n"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  # Get integrated directional encoding function.\n  ide_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    # Get integrated directional encoding.\n    ide = ide_fn(xyz, kappa_inv)\n\n    # Compute directional encoding.\n    ide_real = ide[Ellipsis, 0:deg_view]\n    ide_imag = ide[Ellipsis, deg_view:]\n    ide_real_sq = jnp.sum(ide_real * ide_real, axis=-1, keepdims=True)\n    ide_imag_sq = jnp.sum(ide_imag * ide_imag, axis=-1, keepdims=True)\n    ide_norm_sq = ide_real_sq + ide_imag_sq\n    ide_norm = jnp.sqrt(ide_norm_sq)\n    dir_enc = ide_real / ide_norm\n    return dir_enc\n\n  return dir_enc_fn\n\n"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  ide_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n\n    \"\"\"\n    Function that evaluates the directional encoding for given inputs.\n\n    Input-Output Arguments\n    :param xyz: Array. The 3D point (or points) to evaluate the directional encoding for.\n    :param kappa_inv: Array. The reciprocal of the concentration parameter of the von Mises-Fisher distribution.\n    :return: Array. The directional encoding of the input.\n    \"\"\"\n\n    # Get integrated directional encoding.\n    ide = ide_fn(xyz, kappa_inv)\n\n    # Compute the sum of the coefficients.\n    sum_coeff = np.sum(ide_fn(np.array([[0, 0, 1]]), kappa_inv), axis=-1)\n\n    # Normalize the encoding.\n    return ide / sum_coeff[Ellipsis, np.newaxis]\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  # Generate the integrated directional encoding function.\n  integrated_dir_enc_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n\n    \"\"\"\n    Function for evaluating the directional encoding.\n\n    Input-Output Arguments:\n    :param xyz: Array of 3D points.\n    :param kappa_inv: Reciprocal of the concentration parameter of the von Mises-Fisher distribution.\n    :return: Array of directional encodings.\n    \"\"\"\n\n    # Compute the integrated directional encoding.\n    ide = integrated_dir_enc_fn(xyz, kappa_inv)\n\n    # Compute the norm of the input points.\n    norm_xyz = jnp.linalg.norm(xyz, axis=-1, keepdims=True)\n\n    # Compute the norm of the directional encoding.\n    norm_ide = jnp.linalg.norm(ide, axis=-1, keepdims=True)\n\n    # Normalize the directional encoding.\n    ide_normalized = ide / norm_ide\n\n    # Compute the cosine of the angle between the input points and the directional encoding.\n    cos_theta = jnp.sum(xyz * ide_normalized, axis=-1, keepdims=True)\n\n    # Compute the sine of the angle between the input points and the directional encoding.\n    sin_theta = jnp.sqrt(1 - cos_theta ** 2)\n\n    # Compute the real part of the spherical harmonics.\n    real = (\n        sph_harm_coeff(deg_view, 0, 0) * jnp.ones_like(norm_xyz)\n        + jnp.sum(ide[:, :, 0::2] * cos_theta, axis=-1, keepdims=True)\n        + jnp.sum(ide[:, :, 1::2] * sin_theta, axis=-1, keepdims=True)\n    )\n\n    # Compute the imaginary part of the spherical harmonics."}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    result = []\n    i = 0\n    while i < len(lines):\n        line = lines[i]\n        if should_skip(line, xml):\n            i += 1\n            continue\n        line = line.replace(\"\\n\", \" \")\n        line = line.replace(\"\\t\", \" \")\n        line = line.replace(\"  \", \" \")\n        line = line.replace(\"  \", \" \")\n        line = line.replace(\"  \", \" \")\n        line = line.replace(\"  \", \" \")\n        line = line.replace(\"  \", \" \")\n        line = line.replace(\"  \", \" \")\n        line = line.replace(\"  \", \" \")\n        line = line.replace(\"  \", \" \")\n        line = line.replace(\"  \", \" \")\n        line = line.replace(\"  \", \" \")\n        line = line.replace(\"  \", \" \")\n        line = line.replace(\"  \", \" \")\n        line = line.replace(\"  \", \" \")\n        line = line.replace(\"  \", \" \")\n        line = line.replace(\"  \", \" \")\n        line = line.replace(\"  \", \" \")\n        line = line.replace(\"  \", \" \")\n        line = line.replace(\"  \", \" \")\n        line = line.replace(\"  \", \" \")\n        line = line.replace(\"  \", \" \")\n        line = line.replace(\"  \", \" \")\n        line = line.replace(\"  \", \" \")\n        line = line.replace(\"  \", \" \")\n        line = line.replace(\"  \", \" \")\n        line = line.replace(\"  \", \" \")\n        line = line.replace(\"  \", \" \")\n        line = line.replace(\"  \", \" \")\n        line = line.replace(\"  \", \" \")\n        line = line.replace(\"  \", \" \")\n        line = line.replace(\"  \", \" \")\n        line = line.replace(\"  \", \" \")\n        line = line.replace(\"  \", \" \")\n        line = line.replace(\"  \", \" \")\n        line = line.replace(\"  \", \" \")\n        line = line.replace(\"  \", \" \")\n        line = line.replace(\""}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # remove duplicate lines\n    lines = list(dict.fromkeys(lines))\n    # remove lines that are just numbers\n    lines = [line for line in lines if not line.isnumeric()]\n    # remove lines that are just whitespace\n    lines = [line for line in lines if line.strip()]\n\n    # remove lines that are just whitespace\n    lines = [line for line in lines if line.strip()]\n    # remove lines that are just whitespace\n    lines = [line for line in lines if line.strip()]\n    # remove lines that are just whitespace\n    lines = [line for line in lines if line.strip()]\n    # remove lines that are just whitespace\n    lines = [line for line in lines if line.strip()]\n    # remove lines that are just whitespace\n    lines = [line for line in lines if line.strip()]\n    # remove lines that are just whitespace\n    lines = [line for line in lines if line.strip()]\n\n    # remove lines that are just whitespace\n    lines = [line for line in lines if line.strip()]\n    # remove lines that are just whitespace\n    lines = [line for line in lines if line.strip()]\n    # remove lines that are just whitespace\n    lines = [line for line in lines if line.strip()]\n    # remove lines that are just whitespace\n    lines = [line for line in lines if line.strip()]\n    # remove lines that are just whitespace\n    lines = [line for line in lines if line.strip()]\n    # remove lines that are just whitespace\n    lines = [line for line in lines if line.strip()]\n    # remove lines that are just whitespace\n    lines = [line for line in lines if line.strip()]\n    # remove lines that are just whitespace\n    lines = [line for line in lines if line.strip()]\n    # remove lines that are just whitespace\n    lines = [line for line in lines if line.strip()]\n    # remove lines that are just whitespace\n    lines = [line for line in lines if line.strip()]\n    # remove lines that are just whitespace\n    lines = [line for line in lines if line.strip()]"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # TODO:\n    # - fix bug where a line is skipped if it is a duplicate of the previous line\n    # - fix bug where a line is skipped if it is a duplicate of the next line\n    # - fix bug where a line is skipped if it is a duplicate of the next line\n    # - fix bug where a line is skipped if it is a duplicate of the next line\n    # - fix bug where a line is skipped if it is a duplicate of the next line\n    # - fix bug where a line is skipped if it is a duplicate of the next line\n    # - fix bug where a line is skipped if it is a duplicate of the next line\n    # - fix bug where a line is skipped if it is a duplicate of the next line\n    # - fix bug where a line is skipped if it is a duplicate of the next line\n    # - fix bug where a line is skipped if it is a duplicate of the next line\n    # - fix bug where a line is skipped if it is a duplicate of the next line\n    # - fix bug where a line is skipped if it is a duplicate of the next line\n    # - fix bug where a line is skipped if it is a duplicate of the next line\n    # - fix bug where a line is skipped if it is a duplicate of the next line\n    # - fix bug where a line is skipped if it is a duplicate of the next line\n    # - fix bug where a line is skipped if it is a duplicate of the next line\n    # - fix bug where a line is skipped if it is a duplicate of the next line\n    # - fix bug where a line is skipped if it is a duplicate of the next line\n    # - fix bug where a line is skipped if it is a duplicate of the next line\n    # - fix bug where a line is skipped if it is a duplicate of the next line\n    # - fix bug where a line is skipped if it is a duplicate of the next line\n    # - fix bug where a line is skipped if it is a duplicate of the next line\n    # - fix bug where a line is skipped if it is a duplicate of the next line\n    # - fix bug where a line is skipped"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # clean lines\n    lines = clean_text(lines, xml=xml)\n    # find paragraphs\n    paragraphs = find_paragraphs(lines, xml=xml)\n    # find headers\n    headers = find_headers(lines, xml=xml)\n    # find tables\n    tables = find_tables(lines, xml=xml)\n    # find list items\n    list_items = find_list_items(lines, xml=xml)\n    # find figures\n    figures = find_figures(lines, xml=xml)\n    # find equations\n    equations = find_equations(lines, xml=xml)\n\n    # find paragraphs\n    paragraphs = find_paragraphs(lines, xml=xml)\n    # find headers\n    headers = find_headers(lines, xml=xml)\n    # find tables\n    tables = find_tables(lines, xml=xml)\n    # find list items\n    list_items = find_list_items(lines, xml=xml)\n    # find figures\n    figures = find_figures(lines, xml=xml)\n    # find equations\n    equations = find_equations(lines, xml=xml)\n\n    # find paragraphs\n    paragraphs = find_paragraphs(lines, xml=xml)\n    # find headers\n    headers = find_headers(lines, xml=xml)\n    # find tables\n    tables = find_tables(lines, xml=xml)\n    # find list items\n    list_items = find_list_items(lines, xml=xml)\n    # find figures\n    figures = find_figures(lines, xml=xml)\n    # find equations\n    equations = find_equations(lines, xml=xml)\n\n    # find paragraphs\n    paragraphs = find_paragraphs(lines, xml=xml)\n    # find headers\n    headers = find_headers(lines, xml=xml)\n    # find tables\n    tables = find_tables(lines, xml=xml)\n    # find list items\n    list_items = find_list_items(lines, xml=xml)\n    # find figures\n    figures = find_figures(lines, xml=xml)"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    if not lines:\n        return []\n\n    # remove duplicate lines\n    lines = list(dict.fromkeys(lines))\n    # remove lines with only numbers\n    lines = [line for line in lines if not line.isdigit()]\n    # remove lines with only one character\n    lines = [line for line in lines if len(line) > 1]\n    # remove lines with only two characters\n    lines = [line for line in lines if not find_floating_chars(line)]\n    # remove lines with only two characters\n    lines = [line for line in lines if not line.isdigit()]\n    # remove lines with only two characters\n    lines = [line for line in lines if not line.startswith(\"$\")]\n    # remove lines with only two characters\n    lines = [line for line in lines if not line.endswith(\"$\")]\n\n    # remove lines with only two characters\n    lines = [line for line in lines if not line.startswith(\"(\")]\n    # remove lines with only two characters\n    lines = [line for line in lines if not line.endswith(\")\") if not check_parentheses(line)]\n\n    # remove lines with only two characters\n    lines = [line for line in lines if not line.startswith(\"(\")]\n    # remove lines with only two characters\n    lines = [line for line in lines if not line.endswith(\")\") if not check_parentheses(line)]\n\n    # remove lines with only two characters\n    lines = [line for line in lines if not line.startswith(\"(\")]\n    # remove lines with only two characters\n    lines = [line for line in lines if not line.endswith(\")\") if not check_parentheses(line)]\n\n    # remove lines with only two characters\n    lines = [line for line in lines if not line.startswith(\"(\")]\n    # remove lines with only two characters\n    lines = [line for line in lines if not line.endswith(\")\") if not check_parentheses(line)]\n\n    # remove lines with only two characters\n    lines = [line for line in lines if not line.startswith(\"(\")]\n    # remove lines with only"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # remove duplicate lines\n    lines = list(set(lines))\n    # remove blank lines\n    lines = [line for line in lines if line.strip()]\n    # remove lines with only numbers\n    lines = [line for line in lines if not line.isnumeric()]\n    # remove lines with only punctuation\n    lines = [line for line in lines if not line.replace(\"-\", \"\").replace(\".\", \"\").isalpha()]\n    # remove lines with only numbers and punctuation\n    lines = [line for line in lines if not line.replace(\"-\", \"\").replace(\".\", \"\").replace(\",\", \"\").isalpha()]\n    # remove lines with only numbers and punctuation\n    lines = [\n        line\n        for line in lines\n        if not line.replace(\"-\", \"\").replace(\".\", \"\").replace(\",\", \"\").replace(\":\", \"\").isalpha()\n    ]\n    # remove lines with only numbers and punctuation\n    lines = [\n        line\n        for line in lines\n        if not line.replace(\"-\", \"\").replace(\".\", \"\").replace(\",\", \"\").replace(\":\", \"\").replace(\"(\", \"\").replace(\")\", \"\").isalpha()\n    ]\n    # remove lines with only numbers and punctuation\n    lines = [\n        line\n        for line in lines\n        if not line.replace(\"-\", \"\").replace(\".\", \"\").replace(\",\", \"\").replace(\":\", \"\").replace(\"(\", \"\").replace(\")\", \"\").replace(\":\", \"\").isalpha()\n    ]\n    # remove lines with only numbers and punctuation\n    lines = [\n        line\n        for line in lines\n        if not line.replace(\"-\", \"\").replace(\".\", \"\").replace(\",\", \"\").replace(\":\", \"\").replace(\"(\", \"\").replace(\")\", \"\").replace(\":\", \"\").replace(\"-\", \"\").isalpha()\n    ]\n    # remove lines with only numbers and punctuation\n    lines = [\n        line\n        for line in lines\n        if not line.replace(\"-\", \"\").replace(\".\", \"\").replace(\",\", \"\").replace(\":\", \"\").replace(\"(\", \"\").replace(\")\","}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    result = []\n    block_index = 0\n    block_type = \"paragraph\"\n    header_block_index = 0\n    header_block_level = 0\n    header_block_type = \"paragraph\"\n    block_group = []\n    block_group_index = 0\n    block_group_type = \"paragraph\"\n    block_group_header_index = 0\n    block_group_header_level = 0\n    block_group_header_type = \"paragraph\"\n    block_group_level = 0\n    block_group_list_index = 0\n    block_group_list_type = \"paragraph\"\n    block_group_list_level = 0\n    block_group_list_item_index = 0\n    block_group_list_item_type = \"paragraph\"\n    block_group_list_item_level = 0\n    block_group_list_item_header_index = 0\n    block_group_list_item_header_level = 0\n    block_group_list_item_header_type = \"paragraph\"\n    block_group_list_item_list_index = 0\n    block_group_list_item_list_type = \"paragraph\"\n    block_group_list_item_list_level = 0\n    block_group_list_item_list_item_index = 0\n    block_group_list_item_list_item_type = \"paragraph\"\n    block_group_list_item_list_item_level = 0\n    block_group_list_item_list_item_header_index = 0\n    block_group_list_item_list_item_header_level = 0\n    block_group_list_item_list_item_header_type = \"paragraph\"\n    block_group_list_item_list_item_list_index = 0\n    block_group_list_item_list_item_list_type = \"paragraph\"\n    block_group_list_item_list_item_list_level = 0\n    block_group_list_item_list_item_list_"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # remove duplicate lines\n    lines = [dict(t) for t in {tuple(d.items()) for d in lines}]\n    lines = sorted(lines, key=lambda k: k[\"index\"])\n\n    # clean lines\n    for line in lines:\n        line[\"text\"] = line[\"text\"].strip()\n        line[\"text\"] = line[\"text\"].replace(\"-\", \" \")\n        line[\"text\"] = line[\"text\"].replace(\"\u2013\", \" \")\n        line[\"text\"] = line[\"text\"].replace(\"\u2212\", \" \")\n        line[\"text\"] = line[\"text\"].replace(\"\u25cf\", \" \")\n        line[\"text\"] = line[\"text\"].replace(\"\u2022\", \" \")\n        line[\"text\"] = line[\"text\"].replace(\"\u27a2\", \" \")\n        line[\"text\"] = line[\"text\"].replace(\"\u27a1\", \" \")\n        line[\"text\"] = line[\"text\"].replace(\"\u27a3\", \" \")\n        line[\"text\"] = line[\"text\"].replace(\"\u27a4\", \" \")\n        line[\"text\"] = line[\"text\"].replace(\"\u27a5\", \" \")\n        line[\"text\"] = line[\"text\"].replace(\"\u27a6\", \" \")\n        line[\"text\"] = line[\"text\"].replace(\"\u27a7\", \" \")\n        line[\"text\"] = line[\"text\"].replace(\"\u27a8\", \" \")\n        line[\"text\"] = line[\"text\"].replace(\"\u27a9\", \" \")\n        line[\"text\"] = line[\"text\"].replace(\"\u27aa\", \" \")\n        line[\"text\"] = line[\"text\"].replace(\"\u27ab\", \" \")\n        line[\"text\"] = line[\"text\"].replace(\"\u27ac\", \" \")\n        line[\"text\"] = line[\"text\"].replace(\"\u27ad\", \" \")\n        line[\"text\"] = line[\"text\"].replace(\"\u27ae\", \" \")\n        line[\"text\"] = line[\"text\"].replace(\"\u27af\", \" \")\n        line[\"text\"] = line[\"text\"].replace(\"\u27b1\", \" \")\n        line[\"text\"] = line[\"text\"].replace(\"\u27b2\", \" \")\n        line[\"text\"] = line[\"text\"].replace(\"\u27b3\", \""}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # Remove duplicate lines\n    lines = [line for line in lines if line not in lines[:i] or line.isdigit() for i, line in enumerate(lines)]\n\n    # Remove blank lines\n    lines = [line for line in lines if line != \"\"]\n\n    # Remove lines that are only numbers\n    lines = [line for line in lines if not line.replace(\".\", \"\").replace(\",\", \"\").isdigit()]\n\n    # Remove lines that are only spaces\n    lines = [line for line in lines if line.strip() != \"\"]\n\n    # Remove lines that are only single characters\n    lines = [line for line in lines if len(line) > 1 or line.isdigit()]\n\n    # Remove lines that are only single characters\n    lines = [line for line in lines if len(line) > 1 or line.isdigit()]\n\n    # Remove lines that are only single characters\n    lines = [line for line in lines if len(line) > 1 or line.isdigit()]\n\n    # Remove lines that are only single characters\n    lines = [line for line in lines if len(line) > 1 or line.isdigit()]\n\n    # Remove lines that are only single characters\n    lines = [line for line in lines if len(line) > 1 or line.isdigit()]\n\n    # Remove lines that are only single characters\n    lines = [line for line in lines if len(line) > 1 or line.isdigit()]\n\n    # Remove lines that are only single characters\n    lines = [line for line in lines if len(line) > 1 or line.isdigit()]\n\n    # Remove lines that are only single characters\n    lines = [line for line in lines if len(line) > 1 or line.isdigit()]\n\n    # Remove lines that are only single characters\n    lines = [line for line in lines if len(line) > 1 or line.isdigit()]\n\n    # Remove lines that are only single characters\n    lines = [line for line in lines if len(line) > 1 or line.isdigit()]\n\n    # Remove lines that are only single characters"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # remove duplicate lines (ignoring numbers)\n    lines = remove_duplicate_lines(lines)\n\n    # fix spacing\n    lines = fix_spacing(lines)\n\n    # connect lines\n    lines = connect_lines(lines)\n\n    # categorize lines\n    lines = categorize_lines(lines, xml)\n\n    # find header index\n    lines = find_header_index(lines)\n\n    # find indentation level\n    lines = find_indentation_level(lines)\n\n    # find list level\n    lines = find_list_level(lines)\n\n    return lines\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # clean lines\n    lines = [line_parser.clean_line(line, xml) for line in lines]\n\n    # remove duplicate lines (ignoring numbers)\n    lines = remove_duplicate_lines(lines)\n\n    # fix spacing\n    lines = fix_spacing(lines)\n\n    # connect lines\n    lines = connect_lines(lines)\n\n    # categorize lines\n    lines = categorize_lines(lines, xml)\n\n    # create blocks\n    blocks = create_blocks(lines)\n\n    return blocks\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # print(lines)\n    lines = [line.strip() for line in lines if line.strip()]\n    lines = [line for line in lines if not line_parser.Line(line).is_empty]\n    if len(lines) == 0:\n        return []\n    # print(lines)\n    lines = [line_parser.Line(line) for line in lines]\n    # print(lines)\n    lines = [line for line in lines if not line.is_empty]\n    if len(lines) == 0:\n        return []\n    # print(lines)\n    lines = [line for line in lines if not line.is_empty]\n    if len(lines) == 0:\n        return []\n    # print(lines)\n    # print(len(lines))\n    # print(lines)\n    # print(len(lines))\n    # print(lines)\n    # print(len(lines))\n    # print(lines)\n    # print(len(lines))\n    # print(lines)\n    # print(len(lines))\n    # print(lines)\n    # print(len(lines))\n    # print(lines)\n    # print(len(lines))\n    # print(lines)\n    # print(len(lines))\n    # print(lines)\n    # print(len(lines))\n    # print(lines)\n    # print(len(lines))\n    # print(lines)\n    # print(len(lines))\n    # print(lines)\n    # print(len(lines))\n    # print(lines)\n    # print(len(lines))\n    # print(lines)\n    # print(len(lines))\n    # print(lines)\n    # print(len(lines))\n    # print(lines)\n    # print(len(lines))\n    # print(lines)\n    # print(len(lines))\n    # print(lines)\n    # print(len(lines))\n    # print(lines)\n    # print(len(lines))\n    # print(lines)\n    # print(len(lines))\n    # print(lines)\n    #"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    if not lines:\n        return []\n\n    # clean lines\n    lines = [line_parser.clean_line(line) for line in lines]\n\n    # remove duplicate lines\n    lines = list(dict.fromkeys(lines))\n\n    # remove empty lines\n    lines = [line for line in lines if line]\n\n    # fix spacing\n    lines = [line_parser.fix_spaces(line) for line in lines]\n\n    # fix numbers\n    lines = [line_parser.fix_nums(line) for line in lines]\n\n    # fix units\n    lines = [line_parser.fix_units(line) for line in lines]\n\n    # fix parentheses\n    lines = [line_parser.fix_parens(line) for line in lines]\n\n    # fix abbreviations\n    lines = [line_parser.fix_abbrevs(line) for line in lines]\n\n    # fix hyphenation\n    lines = [line_parser.fix_hyphens(line) for line in lines]\n\n    # fix spacing\n    lines = [line_parser.fix_spaces(line) for line in lines]\n\n    # fix spacing\n    lines = [line_parser.fix_spaces(line) for line in lines]\n\n    # fix spacing\n    lines = [line_parser.fix_spaces(line) for line in lines]\n\n    # fix spacing\n    lines = [line_parser.fix_spaces(line) for line in lines]\n\n    # fix spacing\n    lines = [line_parser.fix_spaces(line) for line in lines]\n\n    # fix spacing\n    lines = [line_parser.fix_spaces(line) for line in lines]\n\n    # fix spacing\n    lines = [line_parser.fix_spaces(line) for line in lines]\n\n    # fix spacing\n    lines = [line_parser.fix_spaces(line) for line in lines]\n\n    # fix spacing\n    lines = [line_parser.fix_spaces(line) for line in lines]\n\n    # fix spacing\n    lines = [line_parser.fix_spaces(line) for line"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # create a list of dictionaries to store the blocks of text\n    blocks = []\n    # create a list to store the current block of text\n    block = []\n    # create a list to store the current header block\n    header = []\n    # create a list to store the current list block\n    list_block = []\n    # create a list to store the current table block\n    table_block = []\n    # create a list to store the current figure block\n    figure_block = []\n    # create a list to store the current reference block\n    reference_block = []\n    # create a list to store the current equation block\n    equation_block = []\n    # create a list to store the current table header block\n    table_header_block = []\n    # create a list to store the current table row block\n    table_row_block = []\n    # create a list to store the current table header row block\n    table_header_row_block = []\n    # create a list to store the current table data block\n    table_data_block = []\n    # create a list to store the current table data row block\n    table_data_row_block = []\n    # create a list to store the current figure data block\n    figure_data_block = []\n    # create a list to store the current reference data block\n    reference_data_block = []\n    # create a list to store the current equation data block\n    equation_data_block = []\n    # create a list to store the current paragraph block\n    paragraph_block = []\n    # create a list to store the current paragraph data block\n    paragraph_data_block = []\n    # create a list to store the current header data block\n    header_data_block = []\n    # create a list to store the current list data block\n    list_data_block = []\n    # create a list to store the current table data block\n    table_data_block = []\n    # create a list to store the current figure data block\n    figure_data_block = []\n    # create a list to store the current reference data block\n    reference_data_block = []\n    # create a list to store the current equation data block\n    equation"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # create a list to hold the results\n    results = []\n    # create a list to hold the current group of lines\n    group = []\n    # create a list to hold the current group of lines as a single string\n    group_text = \"\"\n    # create a list to hold the current group of lines as a single string\n    group_text_no_nums = \"\"\n    # create a list to hold the current group of lines as a single string\n    group_text_no_nums_no_punct = \"\"\n    # create a list to hold the current group of lines as a single string\n    group_text_no_punct = \"\"\n    # create a list to hold the current group of lines as a single string\n    group_text_no_punct_no_stop = \"\"\n    # create a list to hold the current group of lines as a single string\n    group_text_no_stop = \"\"\n    # create a list to hold the current group of lines as a single string\n    group_text_no_stop_no_punct = \"\"\n    # create a list to hold the current group of lines as a single string\n    group_text_no_stop_no_punct_no_nums = \"\"\n    # create a list to hold the current group of lines as a single string\n    group_text_no_stop_no_punct_no_nums_no_space = \"\"\n    # create a list to hold the current group of lines as a single string\n    group_text_no_stop_no_punct_no_nums_no_space_no_alpha = \"\"\n    # create a list to hold the current group of lines as a single string\n    group_text_no_stop_no_punct_no_nums_no_space_no_alpha_no_special = \"\"\n    # create a list to hold the current group of lines as a single string\n    group_text_no_stop_no_punct_no_nums_no_space_no_alpha_no_special_no_space = \"\"\n    # create a list to hold the current group of lines as a single string\n    group_text_no_stop"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # remove duplicate lines\n    lines = [dict(t) for t in {tuple(d.items()) for d in lines}]\n    for i, line in enumerate(lines):\n        lines[i][\"index\"] = i\n\n    lines = [line for line in lines if not should_skip(line[\"text\"], xml)]\n\n    # fix spacing\n    for i, line in enumerate(lines):\n        lines[i][\"text\"] = line_parser.Line(line[\"text\"]).text\n\n    # connect lines\n    for i, line in enumerate(lines):\n        if i > 0:\n            prev_line = lines[i - 1]\n            if (\n                line[\"text\"].startswith(\" \")\n                and not line_parser.Line(prev_line[\"text\"]).is_list_item\n            ):\n                lines[i - 1][\"text\"] = prev_line[\"text\"] + \" \" + line[\"text\"]\n                lines[i][\"text\"] = \"\"\n\n    lines = [line for line in lines if line[\"text\"]]\n\n    # categorize lines\n    for i, line in enumerate(lines):\n        lines[i][\"type\"] = line_parser.Line(line[\"text\"]).type\n\n    # group lines\n    groups = []\n    group_index = 0\n    for i, line in enumerate(lines):\n        if line[\"type\"] == \"paragraph\":\n            groups.append({\"index\": group_index, \"lines\": [line]})\n            group_index += 1\n        elif line[\"type\"] == \"header\":\n            groups.append({\"index\": group_index, \"lines\": [line]})\n            group_index += 1\n        elif line[\"type\"] == \"list_item\":\n            if len(groups) > 0 and groups[-1][\"lines\"][0][\"type\"] == \"list_item\":\n                groups[-1][\"lines\"].append(line)\n            else:\n                groups.append({\"index\": group_index, \"lines\": [line]})\n                group_index += 1\n        else:\n            groups.append({\"index\": group_index,"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # Remove empty lines\n    lines = list(filter(None, lines))\n\n    # Remove duplicate lines (ignoring numbers)\n    lines = remove_duplicate_lines(lines, xml)\n\n    # Fix spaced characters\n    lines = fix_spaced_characters(lines, xml)\n\n    # Connect incomplete lines\n    lines = connect_incomplete_lines(lines, xml)\n\n    # Categorize lines\n    lines = categorize_lines(lines, xml)\n\n    return lines\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    result = []\n    block = []\n    block_type = None\n    header_block_index = None\n    header_block_level = None\n    block_level = None\n    block_index = 0\n    last_block_index = 0\n    last_block_type = None\n    last_header_block_index = None\n    last_header_block_level = None\n    last_block_level = None\n    last_line = None\n    last_line_type = None\n    last_line_num = None\n    last_line_num_start = None\n    last_line_num_end = None\n    last_line_num_start_end = None\n    last_line_num_start_end_index = None\n    last_line_num_start_end_index_type = None\n    last_line_num_start_end_index_header_block_index = None\n    last_line_num_start_end_index_block_index = None\n    last_line_num_start_end_index_block_level = None\n    last_line_num_start_end_index_type_num = None\n    last_line_num_start_end_index_type_num_header_block_index = None\n    last_line_num_start_end_index_type_num_block_index = None\n    last_line_num_start_end_index_type_num_block_level = None\n    last_line_num_start_end_index_type_num_block_type = None\n    last_line_num_start_end_index_type_num_block_type_header_block_index = None\n    last_line_num_start_end_index_type_num_block_type_block_index = None\n    last_line_num_start_end_index_type_num_block_type_block_level = None\n    last_line_num_start_end_index_type_num_block_type_block_type = None\n    last_line_num_start_end_index_type_num_block_type_block_type"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    if len(lines) == 0:\n        return []\n\n    # remove duplicate lines\n    lines = list(set(lines))\n\n    # fix spacing\n    lines = [re.sub(r\"\\s+\", \" \", line) for line in lines]\n\n    # remove extra spaces from start and end of lines\n    lines = [line.strip() for line in lines]\n\n    # remove empty lines\n    lines = list(filter(lambda x: x != \"\", lines))\n\n    # remove lines that are just numbers\n    lines = list(filter(lambda x: not x.replace(\".\", \"\").replace(\":\", \"\").replace(\"-\", \"\").isdigit(), lines))\n\n    # fix floating characters\n    lines = list(filter(lambda x: not find_floating_chars(x), lines))\n\n    # connect lines that are broken\n    lines = connect_lines(lines)\n\n    # remove lines that are just numbers\n    lines = list(filter(lambda x: not x.replace(\".\", \"\").replace(\":\", \"\").replace(\"-\", \"\").isdigit(), lines))\n\n    # remove lines that are just numbers\n    lines = list(filter(lambda x: not x.replace(\".\", \"\").replace(\":\", \"\").replace(\"-\", \"\").isdigit(), lines))\n\n    # remove lines that are just numbers\n    lines = list(filter(lambda x: not x.replace(\".\", \"\").replace(\":\", \"\").replace(\"-\", \"\").isdigit(), lines))\n\n    # remove lines that are just numbers\n    lines = list(filter(lambda x: not x.replace(\".\", \"\").replace(\":\", \"\").replace(\"-\", \"\").isdigit(), lines))\n\n    # remove lines that are just numbers\n    lines = list(filter(lambda x: not x.replace(\".\", \"\").replace(\":\", \"\").replace(\"-\", \"\").isdigit(), lines))\n\n    # remove lines that are just numbers\n    lines = list(filter(lambda x: not x.replace(\".\", \"\").replace(\":\", \"\").replace(\"-\", \"\").isdigit(), lines))\n\n    # remove lines that are just numbers\n    lines = list("}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # remove duplicate lines (ignoring numbers)\n    lines = list(dict.fromkeys(lines))\n\n    # remove blank lines\n    lines = [line for line in lines if line]\n\n    # fix spacing\n    lines = [line.replace(\"  \", \" \") for line in lines]\n\n    # connect lines\n    lines = connect_lines(lines, xml)\n\n    # categorize lines\n    lines = categorize_lines(lines)\n\n    # group lines\n    lines = group_lines(lines, xml)\n\n    return lines\n\n"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None or len(org_texts) == 0:\n        return org_texts\n\n    # normalize quotation marks\n    texts = quotation_pattern.sub(\"'\", org_texts)\n\n    # tokenize sentences\n    sentences = nltk_tokenzier.tokenize(texts)\n\n    # apply rules\n    for rule, replaced in rules:\n        sentences = [rule.sub(replaced, sent) for sent in sentences]\n\n    # handle new lines\n    sentences = [sent.replace(\"\\n\", \" \") for sent in sentences]\n\n    # handle brackets\n    sentences = [bracket_rule.sub(r\"\\1\", sent) for sent in sentences]\n\n    # handle space\n    sentences = [space_rule.sub(r\"\\1\", sent) for sent in sentences]\n\n    return sentences\n\n"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # replace all quotation marks with \"\n    text = re.sub(quotation_pattern, '\"', org_texts)\n\n    # replace all new lines with \". \"\n    text = text.replace(\"\\n\", \". \")\n\n    # replace all \"..\" with \".\"\n    text = text.replace(\"..\", \".\")\n\n    # replace all \"...\" with \".\"\n    text = text.replace(\"...\", \".\")\n\n    # replace all \".....\" with \".\"\n    text = text.replace(\".....\", \".\")\n\n    # replace all \"......\" with \".\"\n    text = text.replace(\"......\", \".\")\n\n    # replace all \".......\" with \".\"\n    text = text.replace(\".......\", \".\")\n\n    # replace all \"........\" with \".\"\n    text = text.replace(\".......\", \".\")\n\n    # replace all \".........\" with \".\"\n    text = text.replace(\".........\", \".\")\n\n    # replace all \"........\" with \".\"\n    text = text.replace(\"........\", \".\")\n\n    # replace all \".........\" with \".\"\n    text = text.replace(\".........\", \".\")\n\n    # replace all \"..........\" with \".\"\n    text = text.replace(\"..........\", \".\")\n\n    # replace all \"...........\" with \".\"\n    text = text.replace(\"...........\", \".\")\n\n    # replace all \"............\" with \".\"\n    text = text.replace(\"............\", \".\")\n\n    # replace all \".............\" with \".\"\n    text = text.replace(\".............\", \".\")\n\n    # replace all \"..............\" with \".\"\n    text = text.replace(\"..............\", \".\")\n\n    # replace all \"...............\" with \".\"\n    text = text.replace(\"...............\", \".\")\n\n    # replace all \".................\" with \".\"\n    text = text.replace(\".................\", \".\")\n\n    # replace all \"................\" with \".\"\n    text = text.replace"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # Normalize quotation marks\n    texts = quotation_pattern.sub('\"', org_texts)\n\n    # Tokenize sentences\n    sentences = nltk_tokenzier.tokenize(texts)\n\n    # Apply rules to sentences\n    for i, sentence in enumerate(sentences):\n        for rule, replaced in rules:\n            sentence = re.sub(rule, replaced, sentence)\n\n        # Remove space before punctuation\n        sentence = space_rule.sub(r\"\\1\", sentence)\n\n        # Remove space after opening brackets\n        sentence = bracket_rule.sub(r\"(\\1)\", sentence)\n\n        sentences[i] = sentence\n\n    return sentences\n\n"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # Normalize quotation marks\n    texts = quotation_pattern.sub(\"'\", org_texts)\n\n    # Tokenize sentences\n    sentences = nltk_tokenzier.tokenize(texts)\n\n    # Apply rules to normalize sentences\n    for rule, replaced in rules:\n        sentences = [rule.sub(replaced, sent) for sent in sentences]\n\n    # Handle sentences within brackets\n    sentences = [bracket_rule.sub(r\"\\1\", sent) for sent in sentences]\n\n    # Remove space between punctuations\n    sentences = [space_rule.sub(r\"\\1\", sent) for sent in sentences]\n\n    return sentences\n\n"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    # If the input is empty or None, return the input as is\n    if not org_texts:\n        return org_texts\n\n    # Normalize quotation marks\n    norm_texts = quotation_pattern.sub('\"', org_texts)\n\n    # Split text into sentences\n    sentences = nltk_tokenzier.tokenize(norm_texts)\n\n    # Remove any space between punctuations (.')\n    sentences = [space_rule.sub(r\"\\1\", s) for s in sentences]\n\n    # Apply rules to tokenize sentences\n    for rule, replaced in rules:\n        sentences = [rule.sub(replaced, s) for s in sentences]\n\n    # Remove any space between punctuations (.')\n    sentences = [space_rule.sub(r\"\\1\", s) for s in sentences]\n\n    # Remove any space between punctuations (.')\n    sentences = [space_rule.sub(r\"\\1\", s) for s in sentences]\n\n    # Remove any space between punctuations (.')\n    sentences = [space_rule.sub(r\"\\1\", s) for s in sentences]\n\n    # Remove any space between punctuations (.')\n    sentences = [space_rule.sub(r\"\\1\", s) for s in sentences]\n\n    # Remove any space between punctuations (.')\n    sentences = [space_rule.sub(r\"\\1\", s) for s in sentences]\n\n    # Remove any space between punctuations (.')\n    sentences = [space_rule.sub(r\"\\1\", s) for s in sentences]\n\n    # Remove any space between punctuations (.')\n    sentences = [space_rule.sub(r\"\\1\", s) for s in sentences]\n\n    # Remove any space between punctuations (.')\n    sentences = [space_rule.sub(r\"\\1\", s) for s in sentences]\n\n    # Remove any space between punctuations (.')\n    sentences = [space_rule.sub(r\"\\1\", s) for s in sentences]\n\n    # Remove any space between punctuations (.')\n    sentences = [space"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # normalize quotation marks\n    norm_texts = quotation_pattern.sub('\"', org_texts)\n\n    # tokenize sentences\n    sent_tokens = nltk_tokenzier.tokenize(norm_texts)\n\n    # apply rules\n    for i, sent in enumerate(sent_tokens):\n        for rule, replaced in rules:\n            sent_tokens[i] = rule.sub(replaced, sent_tokens[i])\n\n    # remove space between punctuation and text\n    for i, sent in enumerate(sent_tokens):\n        sent_tokens[i] = space_rule.sub(r\"\\1\", sent_tokens[i])\n\n    # handle sentences inside brackets\n    for i, sent in enumerate(sent_tokens):\n        sent_tokens[i] = bracket_rule.sub(r\"\\1\", sent_tokens[i])\n\n    return sent_tokens"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # normalize quotation marks\n    texts = quotation_pattern.sub(\"'\", org_texts)\n\n    # tokenize sentences\n    sentences = nltk_tokenzier.tokenize(texts)\n\n    # apply rules to tokenized sentences\n    for i in range(len(sentences)):\n        for rule, replaced in rules:\n            sentences[i] = rule.sub(replaced, sentences[i])\n\n    # handle sentences with brackets\n    for i in range(len(sentences)):\n        if \"(\" in sentences[i] and \")\" in sentences[i]:\n            sentences[i] = bracket_rule.sub(r\"(\\1)\", sentences[i])\n\n    # handle sentences with spaces\n    for i in range(len(sentences)):\n        sentences[i] = space_rule.sub(r\"\\1\", sentences[i])\n\n    return sentences\n\n"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # remove quotation marks\n    text = quotation_pattern.sub(\"\", org_texts)\n\n    # remove space before punctuation\n    text = space_rule.sub(r\"\\1\", text)\n\n    # tokenize sentences\n    sents = nltk_tokenzier.tokenize(text)\n\n    # replace abbreviations\n    for rule, replacement in rules:\n        sents = [rule.sub(replacement, sent) for sent in sents]\n\n    # remove space before punctuation\n    sents = [space_rule.sub(r\"\\1\", sent) for sent in sents]\n\n    # remove space after opening bracket\n    sents = [bracket_rule.sub(r\"(\\1)\", sent) for sent in sents]\n\n    return sents\n\n"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # normalize quotation marks\n    text = quotation_pattern.sub('\"', org_texts)\n\n    # split text into paragraphs\n    paras = text.split(\"\\n\")\n\n    # tokenize paragraphs\n    sents = []\n    for para in paras:\n        if not para:\n            continue\n\n        # apply rules to normalize brackets\n        para = bracket_rule.sub(r\"\\1\", para)\n\n        # apply rules to normalize punctuations\n        for rule, replaced in rules:\n            para = rule.sub(replaced, para)\n\n        # split into sentences\n        sents.extend(nltk_tokenzier.tokenize(para))\n\n    return sents"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # normalize quotation marks\n    text = quotation_pattern.sub('\"', org_texts)\n\n    # split on new line\n    text = text.split(\"\\n\")\n\n    # split on punctuation\n    text = [bracket_rule.sub(r\"\\1\", t) for t in text]\n    text = [space_rule.sub(r\"\\1\", t) for t in text]\n\n    # apply rules\n    text = [rules[0][0].sub(rules[0][1], t) for t in text]\n    text = [rules[1][0].sub(rules[1][1], t) for t in text]\n    text = [rules[2][0].sub(rules[2][1], t) for t in text]\n\n    # apply nltk tokenizer\n    text = [nltk_tokenzier.tokenize(t) for t in text]\n\n    # flatten list\n    text = [t for sublist in text for t in sublist]\n\n    # remove empty sentences\n    text = [t for t in text if t]\n\n    return text\n\n"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # normalize quotation marks\n    texts = quotation_pattern.sub('\"', org_texts)\n\n    # split text into paragraphs\n    paras = texts.split(\"\\n\")\n\n    # tokenize paragraphs\n    sentences = []\n    for para in paras:\n        # remove space before punctuation\n        para = space_rule.sub(r\"\\1\", para)\n        # split paragraph into sentences\n        para_sentences = nltk_tokenzier.tokenize(para)\n        # add sentences to the list\n        sentences.extend(para_sentences)\n\n    # apply rules to sentences\n    for i, sent in enumerate(sentences):\n        for rule, replaced in rules:\n            sent = rule.sub(replaced, sent)\n        # remove space before punctuation\n        sent = space_rule.sub(r\"\\1\", sent)\n        # apply bracket rule\n        sent = bracket_rule.sub(r\"(\\1)\", sent)\n        sentences[i] = sent\n\n    return sentences\n\n"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # normalize quotation marks\n    texts = re.sub(quotation_pattern, '\"', org_texts)\n\n    # split on new line\n    texts = texts.split(\"\\n\")\n\n    # join sentences separated by new line\n    for i in range(len(texts) - 1):\n        texts[i] = texts[i] + \" \"\n\n    texts = \" \".join(texts)\n\n    # split on space\n    texts = texts.split(\" \")\n\n    # remove space after punctuation\n    texts = [re.sub(space_rule, r\"\\1\", text) for text in texts]\n\n    # join sentences separated by new line\n    texts = \" \".join(texts)\n\n    # split on space\n    texts = texts.split(\" \")\n\n    # remove space after punctuation\n    texts = [re.sub(space_rule, r\"\\1\", text) for text in texts]\n\n    # join sentences separated by new line\n    texts = \" \".join(texts)\n\n    # split on space\n    texts = texts.split(\" \")\n\n    # replace brackets with special token\n    texts = [re.sub(bracket_rule, r\"(\\1)\", text) for text in texts]\n\n    # join sentences separated by new line\n    texts = \" \".join(texts)\n\n    # split on space\n    texts = texts.split(\" \")\n\n    # remove space after punctuation\n    texts = [re.sub(space_rule, r\"\\1\", text) for text in texts]\n\n    # join sentences separated by new line\n    texts = \" \".join(texts)\n\n    # split on space\n    texts = texts.split(\" \")\n\n    # replace brackets with special token\n    texts = [re.sub(bracket_rule, r\"(\\1)\", text) for text in texts]\n\n    # join sentences separated by new line\n    texts = \" \".join(texts)\n\n    # split on space\n    texts = texts.split(\" \")\n\n    # remove space after punctuation"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # replace all quotation marks with \"\n    org_texts = re.sub(quotation_pattern, '\"', org_texts)\n\n    # replace all new lines with a space\n    org_texts = re.sub(\"\\n\", \" \", org_texts)\n\n    # remove any space at the beginning of the text\n    org_texts = re.sub(r\"^\\s+\", \"\", org_texts)\n\n    # remove any space at the end of the text\n    org_texts = re.sub(\"\\s+$\", \"\", org_texts)\n\n    # replace all spaces before punctuations with a space\n    org_texts = re.sub(space_rule, r\"\\g<1>\", org_texts)\n\n    # replace all spaces inside brackets with a space\n    org_texts = re.sub(bracket_rule, r\" \\1 \", org_texts)\n\n    # replace all special characters with space\n    org_texts = re.sub(r\"[^a-zA-Z0-9.?! ]\", \" \", org_texts)\n\n    # apply tokenization rules\n    for rule in rules:\n        org_texts = re.sub(rule[0], rule[1], org_texts)\n\n    # tokenize sentences\n    org_texts = nltk_tokenzier.tokenize(org_texts)\n\n    return org_texts\n\n"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None or len(org_texts) == 0:\n        return org_texts\n\n    # replace all quotation marks with \"\n    text = quotation_pattern.sub('\"', org_texts)\n\n    # remove space before . and ?\n    text = space_rule.sub(r\"\\1\", text)\n\n    # replace all (..) with (..)\n    text = bracket_rule.sub(r\"(\\1)\", text)\n\n    # tokenize into sentences\n    sents = nltk_tokenzier.tokenize(text)\n\n    # apply rules\n    for rule, replaced in rules:\n        sents = [rule.sub(replaced, sent) for sent in sents]\n\n    # remove space before . and ?\n    sents = [space_rule.sub(r\"\\1\", sent) for sent in sents]\n\n    # replace all (..) with (..)\n    sents = [bracket_rule.sub(r\"(\\1)\", sent) for sent in sents]\n\n    return sents\n\n"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    # if the input is empty or None, return it as is\n    if not org_texts:\n        return org_texts\n\n    # normalize quotation marks\n    text = quotation_pattern.sub('\"', org_texts)\n\n    # split by new line\n    sentences = text.split(\"\\n\")\n\n    # tokenize sentences\n    for i, sent in enumerate(sentences):\n        # apply rules\n        for rule, replaced in rules:\n            sent = rule.sub(replaced, sent)\n\n        # tokenize by sentences\n        sentences[i] = nltk_tokenzier.tokenize(sent)\n\n    # flatten list\n    sentences = [s for ss in sentences for s in ss]\n\n    # apply rules to the sentences\n    for i, sent in enumerate(sentences):\n        # apply rules\n        for rule, replaced in rules:\n            sent = rule.sub(replaced, sent)\n\n        # apply bracket rule\n        sentences[i] = bracket_rule.sub(r\"\\1\", sent)\n\n    # apply space rule\n    sentences = [space_rule.sub(r\"\\1\", sent) for sent in sentences]\n\n    return sentences\n\n"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None or len(org_texts) == 0:\n        return org_texts\n\n    # Normalize quotation marks\n    text = quotation_pattern.sub(\"'\", org_texts)\n\n    # Remove any space between punctuations\n    text = space_rule.sub(r\"\\1\", text)\n\n    # Handle sentences within brackets\n    text = bracket_rule.sub(r\"(\\1)\", text)\n\n    # Handle special cases such as paragraphs separated by new lines\n    text = text.replace(\"\\n\", \". \")\n\n    # Tokenize sentences\n    sentences = nltk_tokenzier.tokenize(text)\n\n    # Apply predefined rules\n    for rule in rules:\n        sentences = [rule[0].sub(rule[1], s) for s in sentences]\n\n    return sentences\n\n"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # Replace all quotation marks with \"\n    texts = re.sub(quotation_pattern, '\"', org_texts)\n\n    # Replace all new line characters with \". \"\n    texts = re.sub(\"\\n\", \". \", texts)\n\n    # Replace all special characters with \". \"\n    texts = re.sub(space_rule, r\" \\1\", texts)\n\n    # Replace all text within brackets with a single token\n    texts = re.sub(bracket_rule, r\"(\\1)\", texts)\n\n    # Tokenize the text into sentences\n    sentences = nltk_tokenzier.tokenize(texts)\n\n    # Apply the tokenization rules\n    for rule, replaced in rules:\n        sentences = [re.sub(rule, replaced, sent) for sent in sentences]\n\n    return sentences\n\n"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    # If the input is empty, return the input as is.\n    if not org_texts:\n        return org_texts\n\n    # Normalize the quotation marks.\n    texts = quotation_pattern.sub(r'\"', org_texts)\n\n    # Split the text into paragraphs.\n    paras = texts.split(\"\\n\")\n\n    # Tokenize the paragraphs into sentences.\n    sentences = []\n    for para in paras:\n        # Remove any space between punctuations (.')\n        para = space_rule.sub(r\"\\1\", para)\n\n        # If the paragraph starts with a punctuation, add a space before it.\n        para = re.sub(r\"^([.'\\(\\)]*)\", r\" \\1\", para)\n\n        # If the paragraph ends with a punctuation, add a space after it.\n        para = re.sub(r\"([.'\\)\\]]*)$\", r\"\\1 \", para)\n\n        # Split the paragraph into sentences.\n        para_sentences = nltk_tokenzier.tokenize(para)\n\n        # Add the sentences to the list of sentences.\n        sentences.extend(para_sentences)\n\n    # Tokenize the sentences.\n    tokenized_sentences = []\n    for sent in sentences:\n        # Apply the rules to tokenize the sentence.\n        for rule, replaced in rules:\n            sent = rule.sub(replaced, sent)\n\n        # Replace any space between brackets.\n        sent = bracket_rule.sub(r\"\\1\", sent)\n\n        # Add the tokenized sentence to the list of sentences.\n        tokenized_sentences.append(sent)\n\n    return tokenized_sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # replace all quotation marks with \"\n    org_texts = re.sub(quotation_pattern, '\"', org_texts)\n\n    # split text into paragraphs\n    paras = org_texts.split(\"\\n\")\n\n    # tokenize each paragraph into sentences\n    sent_list = []\n    for para in paras:\n        para = para.strip()\n\n        # remove space before punctuation\n        para = re.sub(space_rule, r\"\\1\", para)\n\n        # remove space before \"(\"\n        para = re.sub(r\"(\\s)\\(\", r\"\\1(\", para)\n\n        # split text into sentences\n        para_sents = nltk_tokenzier.tokenize(para)\n\n        # remove space after \")\"\n        para_sents = [re.sub(r\"\\)\\s\", r\")\", sent) for sent in para_sents]\n\n        # merge sentences within brackets\n        para_sents = [re.sub(bracket_rule, r\"\\1\", sent) for sent in para_sents]\n\n        # apply tokenization rules\n        para_sents = [apply_rules(sent) for sent in para_sents]\n\n        # add to the list of sentences\n        sent_list.extend(para_sents)\n\n    return sent_list\n\n"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None or len(org_texts) == 0:\n        return org_texts\n\n    # replace all quotation marks with \"\n    org_texts = quotation_pattern.sub('\"', org_texts)\n\n    # handle special case of text starting with a punctuation\n    org_texts = space_rule.sub(r'\\1', org_texts)\n\n    # handle special case of text starting with a bracket\n    org_texts = bracket_rule.sub(r'(\\1)', org_texts)\n\n    # split the text into sentences\n    sentences = nltk_tokenzier.tokenize(org_texts)\n\n    # handle special case of sentences within brackets\n    for i in range(len(sentences)):\n        if sentences[i].startswith('('):\n            if len(sentences[i]) == 1:\n                sentences[i] = sentences[i][0]\n                continue\n            if sentences[i].endswith(')'):\n                sentences[i] = sentences[i][:-1]\n            sentences[i] = '(' + sentences[i]\n        if sentences[i].endswith(')'):\n            sentences[i] = sentences[i] + ')'\n\n    # apply predefined rules\n    for rule in rules:\n        sentences = [re.sub(rule[0], rule[1], sent) for sent in sentences]\n\n    # remove extra spaces\n    sentences = [re.sub(' +', ' ', sent) for sent in sentences]\n\n    return sentences\n\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return [self[key].positions(token)]\n        else:\n            return [doc.positions(token) for doc in self]\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return self.posns.positions(self.term_dict.get_term_id(token), key)\n        else:\n            return self.posns.positions(self.term_dict.get_term_id(token))\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return [self[key].positions(token)]\n\n        return [doc.positions(token) for doc in self]\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return [self.posns.positions(self.term_dict.get_term_id(token), doc_id=key)]\n        else:\n            return [self.posns.positions(self.term_dict.get_term_id(token), doc_id=doc_id) for doc_id in range(len(self))]\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return self.posns.positions(self.term_dict.get_term_id(token), key)\n        else:\n            return self.posns.positions(self.term_dict.get_term_id(token))\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return [self[key].positions(token)]\n        else:\n            return [doc.positions(token) for doc in self]\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is None:\n            return self.posns.positions(self.term_dict.get_term_id(token))\n        else:\n            return self.posns.positions(self.term_dict.get_term_id(token), key)\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return self[key].positions(token)\n\n        # For expensive toknes, we compute doc freq first, so we\n        # cache them in the DF cache, to let TF cache know it should be cached\n        token = self._check_token_arg(token)\n        self.docfreq(token)\n\n        # Get term freqs per token\n        tfs = self.termfreqs(token)\n\n        # Get positions per token\n        posns = self.posns.posns(token)\n        return posns\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        # Check if the token is a string\n        if not isinstance(token, str):\n            raise TypeError(\"The term argument must be a string\")\n\n        # Check if the key is a string\n        if key is not None and not isinstance(key, str):\n            raise TypeError(\"The key argument must be a string\")\n\n        # Check if the key is in the SearchArray\n        if key is not None and key not in self.keys():\n            raise KeyError(\"The key argument is not in the SearchArray\")\n\n        # If a key is provided, return the positions for the given key\n        if key is not None:\n            # Check if the token is in the SearchArray\n            if token not in self.term_dict:\n                raise KeyError(\"The term argument is not in the SearchArray\")\n\n            # Get the term id for the token\n            term_id = self.term_dict.get_term_id(token)\n\n            # Get the positions for the term in the given key\n            return self.posns.positions(term_id, key)\n\n        # If no key is provided, return the positions for the given token across all documents\n        else:\n            # Check if the token is in the SearchArray\n            if token not in self.term_dict:\n                raise KeyError(\"The term argument is not in the SearchArray\")\n\n            # Get the term id for the token\n            term_id = self.term_dict.get_term_id(token)\n\n            # Get the positions for the term across all documents\n            return self.posns.positions(term_id)\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        # Check if the token is a string\n        if not isinstance(token, str):\n            raise TypeError(\"Token must be a string.\")\n\n        # Check if the key is a string\n        if key is not None and not isinstance(key, str):\n            raise TypeError(\"Key must be a string.\")\n\n        # Check if the token is in the term dictionary\n        if token not in self.term_dict:\n            raise TermMissingError(\"Token not in term dictionary.\")\n\n        # Check if the key is in the document dictionary\n        if key is not None and key not in self.doc_dict:\n            raise TermMissingError(\"Key not in document dictionary.\")\n\n        # Get the term id for the token\n        term_id = self.term_dict.get_term_id(token)\n\n        # If a key is provided, get the document id for the key\n        if key is not None:\n            doc_id = self.doc_dict.get_doc_id(key)\n\n        # Get the positions for the term\n        if key is not None:\n            positions = self.posns.get_posns(term_id, doc_id)\n        else:\n            positions = self.posns.get_posns(term_id)\n\n        return positions\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        token = self._check_token_arg(token)\n        if key is not None:\n            # Get the term ID\n            term_id = self.term_dict.get_term_id(token)\n            # Get the positions for the term\n            return self.posns.positions(term_id, key)\n        else:\n            # Get the term ID\n            term_id = self.term_dict.get_term_id(token)\n            # Get the positions for the term\n            return self.posns.positions(term_id)\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        # Check if the token is a list of strings\n        if isinstance(token, list):\n            # If so, return the positions of each token in the list\n            return [self.positions(token=token_i, key=key) for token_i in token]\n        # If the token is not a list of strings, check if it is a string\n        elif isinstance(token, str):\n            # If so, check if the key is None\n            if key is None:\n                # If so, return the positions of the token across all documents\n                return self.posns.positions(self.term_dict.get_term_id(token))\n            # If the key is not None, check if the key is a list of strings\n            elif isinstance(key, list):\n                # If so, return the positions of the token within the documents specified by the list of keys\n                return [self.positions(token=token, key=key_i) for key_i in key]\n            # If the key is not a list of strings, check if the key is a string\n            elif isinstance(key, str):\n                # If so, return the positions of the token within the document specified by the key\n                return self.posns.positions(self.term_dict.get_term_id(token), doc_id=key)\n            # If the key is neither a list of strings nor a string, raise an error\n            else:\n                raise TypeError(\"The key must be a string or a list of strings.\")\n        # If the token is not a string, raise an error\n        else:\n            raise TypeError(\"The token must be a string or a list of strings.\")\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        # Check that the input is a string\n        if not isinstance(token, str):\n            raise TypeError(\"The given token must be a string.\")\n\n        # Check that the input is a valid term\n        if token not in self.term_dict.terms:\n            raise TermMissingError(\"The given token must be a term in the SearchArray.\")\n\n        # Get the term id\n        term_id = self.term_dict.get_term_id(token)\n\n        # If no key is provided, return positions across all documents\n        if key is None:\n            return self.posns.positions(term_id)\n\n        # Check that the key is valid\n        if key not in self.doc_lens:\n            raise KeyError(\"The given key is not a document in the SearchArray.\")\n\n        # Get the document id\n        doc_id = self.doc_lens.index(key)\n\n        # Return the positions for the given document\n        return self.posns.positions(term_id, doc_id=doc_id)\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        # Check that the token is a string\n        if not isinstance(token, str):\n            raise TypeError(\"Token must be a string.\")\n        # Check that the key is a string or None\n        if key is not None and not isinstance(key, str):\n            raise TypeError(\"Key must be a string or None.\")\n        # Check that the key is in the document dictionary\n        if key is not None and key not in self.term_dict.keys():\n            raise KeyError(\"Key is not in the document dictionary.\")\n        # Check that the token is in the document dictionary\n        if token not in self.term_dict.keys():\n            raise KeyError(\"Token is not in the document dictionary.\")\n        # Retrieve the term id\n        term_id = self.term_dict.get_term_id(token)\n        # Retrieve the document id\n        doc_id = self.term_dict.get_doc_id(key) if key is not None else None\n        # Retrieve the positions\n        positions = self.posns.positions(term_id, doc_id)\n        # Return the positions\n        return positions\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        # Check that the input arguments are of the correct type.\n        if not isinstance(self, SearchArray):\n            raise TypeError(\"The first argument must be an instance of the SearchArray class.\")\n        if not isinstance(token, str):\n            raise TypeError(\"The second argument must be a string.\")\n        if key is not None and not isinstance(key, str):\n            raise TypeError(\"The third argument must be a string.\")\n\n        # If the key is None, return the positions for all documents.\n        if key is None:\n            return self.posns.positions(self.term_dict.get_term_id(token))\n        # If the key is not None, return the positions for the specific document.\n        else:\n            return self.posns.positions(self.term_dict.get_term_id(token), key)\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        # Check input arguments\n        if not isinstance(token, str):\n            raise TypeError(\"The input argument 'token' should be a string.\")\n        if key is not None and not isinstance(key, int):\n            raise TypeError(\"The input argument 'key' should be an integer.\")\n\n        # Check if token exists in the SearchArray\n        if not self.term_dict.has_term(token):\n            raise TermMissingError(f\"The token '{token}' does not exist in the SearchArray.\")\n\n        # If key is provided, return positions for a specific document\n        if key is not None:\n            return self.posns.positions(self.term_dict.get_term_id(token), key)\n\n        # If key is not provided, return positions across all documents\n        else:\n            return self.posns.positions(self.term_dict.get_term_id(token))\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        token = self._check_token_arg(token)\n        try:\n            term_id = self.term_dict.get_term_id(token)\n            if key is None:\n                return self.posns.positions(term_id)\n            else:\n                return self.posns.positions(term_id, key)\n        except TermMissingError:\n            return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        # Checks if the token is a string\n        if not isinstance(token, str):\n            raise TypeError(\"The token argument must be a string\")\n\n        # Checks if the key is a string\n        if key is not None and not isinstance(key, str):\n            raise TypeError(\"The key argument must be a string\")\n\n        # Checks if the token is in the term dictionary\n        if not self.term_dict.has_term(token):\n            raise TermMissingError(\"The token is not in the term dictionary\")\n\n        # Checks if the key is in the term dictionary\n        if key is not None and not self.term_dict.has_key(key):\n            raise TermMissingError(\"The key is not in the term dictionary\")\n\n        # Gets the term ID for the given token\n        term_id = self.term_dict.get_term_id(token)\n\n        # Gets the document IDs for the given key\n        if key is not None:\n            doc_ids = [self.term_dict.get_doc_id(key)]\n        else:\n            doc_ids = self.term_dict.get_doc_ids()\n\n        # Gets the positions for the given term and document IDs\n        positions = self.posns.positions(term_id, doc_ids)\n\n        # Returns the positions\n        return positions\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        # If key is not provided, return positions for all documents.\n        if key is None:\n            return self.posns.positions(self.term_dict.get_term_id(token))\n\n        # If key is provided, return positions for the specific document.\n        else:\n            # Check if the key is valid.\n            if key not in self.doc_lens:\n                raise KeyError(\"Invalid document key\")\n\n            # Get the positions of the term in the specific document.\n            return self.posns.positions(self.term_dict.get_term_id(token), key)\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return self[key].positions(token)\n\n        # For expensive toknes, we compute doc freq first, so we\n        # cache them in the DF cache, to let TF cache know it should be cached\n        token = self._check_token_arg(token)\n        self.docfreq(token)\n\n        posns = []\n        for doc in self:\n            posns.append(doc.positions(token))\n        return posns\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # If the spec is a number, return the number.\n    if spec.isnumeric():\n        return int(spec)\n\n    # If the spec is a percentage, return the percentage of clauses.\n    if spec.endswith('%'):\n        return int(float(spec[:-1]) / 100 * num_clauses)\n\n    # If the spec is a conditional expression, return the minimum number of clauses that must match.\n    if spec.startswith('<'):\n        return int(spec[1:])\n\n    # If the spec is a conditional expression, return the maximum number of clauses that must match.\n    if spec.endswith('<'):\n        return num_clauses - int(spec[:-1])\n\n    # If the spec is a range, return the minimum number of clauses that must match.\n    if ' TO ' in spec:\n        return int(spec.split(' TO ')[0])\n\n    # If the spec is a range, return the maximum number of clauses that must match.\n    if ' TO ' in spec:\n        return num_clauses - int(spec.split(' TO ')[1])\n\n    # If the spec is a single number, return the minimum number of clauses that must match.\n    if spec.isnumeric():\n        return int(spec)\n\n    # If the spec is a single number, return the maximum number of clauses that must match.\n    if spec.isnumeric():\n        return int(spec)\n\n    raise ValueError(f\"Invalid 'min should match' specification: {spec}\")\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # Check if spec is a string\n    if not isinstance(spec, str):\n        raise TypeError(\"The 'min should match' specification must be a string.\")\n\n    # Check if spec is a valid specification\n    if not re.match(r\"^(?:\\d+(?:\\.\\d+)?|\\d+%)?(?:<(?:\\d+(?:\\.\\d+)?|\\d+%))?$\", spec):\n        raise ValueError(\n            \"The 'min should match' specification is not valid. It must be an absolute number, a percentage, or a conditional expression.\"\n        )\n\n    # Check if spec is a conditional specification\n    if spec.startswith(\"<\"):\n        if not spec[1:].isnumeric():\n            raise ValueError(\n                \"The 'min should match' specification is not valid. The conditional expression must be a positive integer or a positive percentage.\"\n            )\n        if int(spec[1:]) >= num_clauses:\n            raise ValueError(\n                \"The 'min should match' specification is not valid. The conditional expression must be less than the total number of clauses.\"\n            )\n        return int(spec[1:])\n\n    # Check if spec is a percentage\n    if spec.endswith(\"%\"):\n        if not spec[:-1].replace(\".\", \"\").isnumeric():\n            raise ValueError(\n                \"The 'min should match' specification is not valid. The percentage must be a positive number.\"\n            )\n        if float(spec[:-1]) > 100:\n            raise ValueError(\n                \"The 'min should match' specification is not valid. The percentage must be less than or equal to 100.\"\n            )\n        return int(num_clauses * (float(spec[:-1]) / 100))\n\n    # Check if spec is a number\n    if not spec.replace(\".\", \"\").isnumeric():\n        raise ValueError(\n            \"The 'min should match' specification is not valid. The number must be a positive integer.\"\n        )\n    if int(spec) > num_clauses:\n        raise ValueError(\n            \"The 'min should match' specification is not valid"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # If the spec is a number, return the number\n    if spec.isnumeric():\n        return int(spec)\n\n    # If the spec is a percentage, return the number of clauses\n    if spec.endswith(\"%\"):\n        return int(float(spec[:-1]) * num_clauses / 100)\n\n    # If the spec is a conditional expression, return the number of clauses\n    if spec.startswith(\"<\"):\n        return int(spec[1:])\n\n    # If the spec is not a number, percentage, or conditional expression, raise an error\n    raise ValueError(f\"Unrecognized 'min should match' specification: {spec}\")\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec == \"0%\":\n        return 0\n    elif spec.endswith(\"%\"):\n        return int(num_clauses * float(spec.strip(\"%\")) / 100)\n    elif spec.startswith(\"<\"):\n        return int(num_clauses * float(spec.strip(\"<\")) / 100)\n    else:\n        return int(spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # If the spec is a number, return it\n    if spec.isnumeric():\n        return int(spec)\n\n    # If the spec is a percentage, return the calculated value\n    if spec.endswith(\"%\"):\n        return int(float(spec[:-1]) * num_clauses / 100)\n\n    # If the spec is a conditional expression, calculate the value\n    if spec.startswith(\"<\"):\n        return int(float(spec[1:]) * num_clauses / 100)\n\n    raise ValueError(\"Invalid 'min should match' specification: {}\".format(spec))\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # If the spec is a number, return the number.\n    if spec.isnumeric():\n        return int(spec)\n\n    # If the spec is a percentage, return the number of clauses that must match.\n    if spec.endswith(\"%\"):\n        return int(float(spec[:-1]) / 100.0 * num_clauses)\n\n    # If the spec is a conditional expression, return the number of clauses that must match.\n    if spec.startswith(\"<\"):\n        return int(float(spec[1:]) / 100.0 * num_clauses)\n\n    raise ValueError(\"The min should match specification is invalid.\")\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if not isinstance(spec, str):\n        raise TypeError(\"Specification must be a string.\")\n\n    if spec.isdigit():\n        return int(spec)\n\n    if spec.endswith(\"%\"):\n        return int(float(spec[:-1]) * num_clauses / 100)\n\n    if \"<\" in spec:\n        return int(spec.replace(\"<\", \"\"))\n\n    raise ValueError(\"Specification not recognized.\")\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # if the spec is a number, return the number\n    if spec.isnumeric():\n        return int(spec)\n\n    # if the spec is a percentage, calculate the minimum number of clauses that must match based on the number of clauses and the percentage\n    if spec.endswith(\"%\"):\n        return int(float(spec[:-1]) / 100 * num_clauses)\n\n    # if the spec is a conditional expression, calculate the minimum number of clauses that must match based on the number of clauses and the percentage\n    if spec.startswith(\"<\"):\n        return int(float(spec[1:]) / 100 * num_clauses)\n\n    # if the spec is a conditional expression, calculate the minimum number of clauses that must match based on the number of clauses and the percentage\n    if spec.startswith(\">\"):\n        return int(float(spec[1:]) / 100 * num_clauses)\n\n    # if the spec is not a number, percentage, or conditional expression, raise an error\n    raise ValueError(\"min should match specification not recognized\")\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # If the spec is an integer, return it\n    if spec.isdigit():\n        return int(spec)\n\n    # If the spec is a percentage, calculate the minimum number of clauses that must match\n    if spec.endswith(\"%\"):\n        return int(float(spec[:-1]) * num_clauses / 100)\n\n    # If the spec is a conditional expression, calculate the minimum number of clauses that must match\n    if spec.startswith(\"<\"):\n        return int(num_clauses - int(spec[1:]))\n\n    # If the spec is not valid, raise an error\n    raise ValueError(f\"Invalid 'mm' spec: '{spec}'\")\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # Check for the case where the spec is an integer\n    if spec.isnumeric():\n        return int(spec)\n\n    # Check for the case where the spec is a percentage\n    if spec.endswith('%'):\n        return int(num_clauses * float(spec.replace('%', '')) / 100.0)\n\n    # Check for the case where the spec is a conditional expression\n    if '<' in spec:\n        return int(spec.replace('<', ''))\n\n    # If the spec is not one of the above, raise an error\n    raise ValueError(\"Invalid 'mm' spec: \" + spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # if the spec is a percentage, convert it to a fraction\n    if spec.endswith('%'):\n        spec = float(spec[:-1]) / 100.0\n\n    # if the spec is a number, return it\n    if spec.isdigit():\n        return int(spec)\n\n    # if the spec is a fraction, return the corresponding number of clauses\n    if re.match(r'^\\d+\\.\\d+$', spec):\n        return int(float(spec) * num_clauses)\n\n    # if the spec is a conditional expression, return the corresponding number of clauses\n    if re.match(r'^\\d+<(\\d+)?(\\.\\d+)?$', spec):\n        return int(spec[1:].replace('.', ''))\n\n    # if the spec is not a valid 'mm' spec, raise an error\n    raise ValueError(f\"Invalid 'mm' spec: {spec}\")\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # if the spec is a number, return it\n    if spec.isnumeric():\n        return int(spec)\n\n    # if the spec is a percentage, return the number of clauses that it represents\n    if spec.endswith(\"%\"):\n        return int(float(spec.replace(\"%\", \"\")) / 100 * num_clauses)\n\n    # if the spec is a conditional expression, return the number of clauses that it represents\n    if spec.startswith(\"<\"):\n        return num_clauses - int(spec.replace(\"<\", \"\"))\n\n    raise ValueError(\"Invalid 'mm' spec: {}\".format(spec))\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # if the spec is a number, return it\n    if spec.isnumeric():\n        return int(spec)\n\n    # if the spec is a percentage, return the fraction of clauses\n    if spec.endswith(\"%\"):\n        return int(num_clauses * float(spec.replace(\"%\", \"\")) / 100)\n\n    # if the spec is a conditional expression, return the minimum number of clauses that must match\n    if spec.startswith(\"<\"):\n        return int(spec.replace(\"<\", \"\"))\n\n    # otherwise, raise an error\n    raise ValueError(f\"Invalid 'min should match' specification: {spec}\")\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # If the spec is a number, return it\n    try:\n        return int(spec)\n    except ValueError:\n        pass\n\n    # If the spec is a percentage, calculate the minimum number of clauses that must match\n    if spec.endswith(\"%\"):\n        return int(float(spec[:-1]) / 100 * num_clauses)\n\n    # If the spec is a conditional expression, calculate the minimum number of clauses that must match\n    if spec.startswith(\"<\"):\n        return int(num_clauses - float(spec[1:]) / 100 * num_clauses)\n\n    # Otherwise, raise an error\n    raise ValueError(f\"Invalid 'mm' spec: '{spec}'\")\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # if the spec is a string, we parse it\n    if isinstance(spec, str):\n\n        # if the spec is an integer, we just return it\n        if spec.isnumeric():\n            return int(spec)\n\n        # otherwise, we parse the spec\n        else:\n\n            # if the spec is a conditional expression, we parse it\n            if '<' in spec:\n                return int(spec.split('<')[0])\n\n            # otherwise, we assume it's a percentage\n            else:\n                return int(float(spec) * num_clauses)\n\n    # if the spec is a float, we assume it's a percentage\n    elif isinstance(spec, float):\n        return int(spec * num_clauses)\n\n    # if the spec is an integer, we assume it's an absolute value\n    elif isinstance(spec, int):\n        return spec\n\n    # otherwise, we raise an error\n    else:\n        raise ValueError(f\"Invalid 'min should match' specification: {spec}\")\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec is None:\n        return 0\n    if spec.isnumeric():\n        return int(spec)\n    if spec.endswith(\"%\"):\n        return int(float(spec[:-1]) / 100 * num_clauses)\n    if \"<\" in spec:\n        return int(spec.split(\"<\")[1])\n    raise ValueError(\"Invalid 'min should match' specification: {}\".format(spec))\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # If the spec is a number, then return it.\n    if spec.isnumeric():\n        return int(spec)\n\n    # If the spec is a percentage, then calculate the minimum number of clauses that must match.\n    if spec.endswith(\"%\"):\n        return int(round(float(spec[:-1]) * num_clauses / 100))\n\n    # If the spec is a conditional expression, then calculate the minimum number of clauses that must match.\n    if spec.startswith(\"<\"):\n        return int(num_clauses - int(spec[1:]))\n\n    # If the spec is not a number, percentage, or conditional expression, then raise an error.\n    raise ValueError(f\"Invalid 'min should match' specification: {spec}\")\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # Handle absolute numbers\n    if spec.isdigit():\n        return int(spec)\n\n    # Handle percentage-based specifications\n    if spec.endswith(\"%\"):\n        return int(float(spec[:-1]) * 0.01 * num_clauses)\n\n    # Handle conditional specifications\n    if spec.startswith(\"<\"):\n        return int(spec[1:])\n\n    # Handle the case where the spec is invalid\n    raise ValueError(\"Invalid 'min should match' specification\")\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n\n    if spec.endswith('%'):\n        return int(float(spec[:-1]) / 100 * num_clauses)\n\n    if '<' in spec:\n        return int(spec.split('<')[1])\n\n    raise ValueError('min should match specification not understood: ' + spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec == \"100%\":\n        return num_clauses\n\n    # remove any whitespace\n    spec = spec.replace(\" \", \"\")\n\n    # remove any trailing '%'\n    if spec[-1] == \"%\":\n        spec = spec[:-1]\n\n    # if the spec is a number, just return it\n    if spec.isnumeric():\n        return int(spec)\n\n    # if the spec is a conditional expression, evaluate it\n    if \"<\" in spec:\n        # split the conditional expression into a list of terms\n        terms = spec.split(\"<\")\n        # the first term is the number of clauses that must match\n        num_matches = int(terms[0])\n        # the second term is the total number of clauses\n        total_clauses = int(terms[1])\n        # if the total number of clauses is less than the number of matches, return 0\n        if total_clauses < num_matches:\n            return 0\n        # otherwise, return the difference between the total number of clauses and the number of matches\n        else:\n            return total_clauses - num_matches\n\n    # if the spec is a percentage, calculate the number of clauses that must match\n    if \"%\" in spec:\n        # split the percentage into a list of terms\n        terms = spec.split(\"%\")\n        # the first term is the percentage\n        percent = float(terms[0])\n        # the second term is the total number of clauses\n        total_clauses = int(terms[1])\n        # return the percentage of the total number of clauses\n        return int(np.ceil(percent / 100 * total_clauses))\n\n    # if the spec is not a valid specification, raise an error\n    raise ValueError(f\"Invalid 'min should match' specification: {spec}\")\n\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(tokens) == len(set(tokens)):\n            return self._phrase_freq_simple(tokens)\n        else:\n            return self._phrase_freq_complex(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(tokens) == len(set(tokens)):\n            return self._phrase_freq_simple(tokens)\n        else:\n            return self._phrase_freq_general(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(tokens) == len(set(tokens)):\n            return self._phrase_freq_simple(tokens)\n        else:\n            return self._phrase_freq_complex(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # If slop is 1 and tokens are unique, we can use the positions of terms to calculate the phrase frequency directly\n        if slop == 1 and len(set(tokens)) == len(tokens):\n            return self.posns.phrase_freq(self.term_dict.get_term_id(tokens), self.term_mat.rows)\n        else:\n            return self.posns.phrase_freq_slow(self.term_dict.get_term_id(tokens), self.term_mat.rows, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(tokens) == len(set(tokens)):\n            return self.phrase_freq_adjacent_unique(tokens)\n        else:\n            return self.phrase_freq_adjacent_nonunique(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # If the slop is 1 and all tokens are unique, we can use the positions of terms to calculate the phrase frequency\n        if slop == 1 and len(tokens) == len(set(tokens)):\n            return self.posns.phrase_freq(tokens, self.term_dict)\n        else:\n            return self.posns.phrase_freq_slow(tokens, self.term_dict, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(tokens) == len(set(tokens)):\n            return self.phrase_freq_simple(tokens)\n        else:\n            return self.phrase_freq_complex(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # If tokens are unique, we can directly calculate phrase frequency\n        if len(tokens) == len(set(tokens)):\n            return self._phrase_freq_unique_tokens(tokens, slop)\n        else:\n            return self._phrase_freq_non_unique_tokens(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # If the slop is 1 and all tokens are unique, we can use the positions of terms to directly calculate the phrase frequency\n        if slop == 1 and len(tokens) == len(set(tokens)):\n            return self.posns.phrase_freq(tokens)\n\n        # Otherwise, we need to use the slow method\n        return self.slow_phrase_freq(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # Check if the slop is 1 and all tokens are unique. If so, we can use the positions of terms to calculate the phrase frequency.\n        if slop == 1 and len(tokens) == len(set(tokens)):\n            term_ids = [self.term_dict.get_term_id(token) for token in tokens]\n            posns = self.posns.positions(term_ids[0], doc_ids=self.term_mat.rows)\n            phrase_freqs = np.zeros(len(self), dtype=int)\n            for i in range(len(self)):\n                phrase_freqs[i] = len(posns[i])\n\n        # Otherwise, we delegate the calculation to another method that handles different slop or non-unique tokens.\n        else:\n            phrase_freqs = self.phrase_freq_general(tokens, slop)\n\n        return phrase_freqs\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if len(tokens) == 1:\n            return self.termfreqs(tokens[0])\n        elif len(tokens) == 2:\n            return self.phrase_freq_two_tokens(tokens, slop)\n        elif len(tokens) > 2:\n            return self.phrase_freq_multi_token(tokens, slop)\n        else:\n            raise ValueError(\"Need at least one token.\")\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # If slop is 1 and tokens are unique, we can use the positions of terms\n        if slop == 1 and len(tokens) == len(set(tokens)):\n            return self.posns.phrase_freq(tokens)\n        else:\n            return self._phrase_freq_slow(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # If slop is 1 and tokens are unique, we can use the fast method\n        if slop == 1 and len(tokens) == len(set(tokens)):\n            return self._phrase_freq_fast(tokens)\n        else:\n            return self._phrase_freq_slow(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # If the slop is 1 and all tokens are unique, we can use the positions of terms to calculate the phrase frequency directly.\n        if slop == 1 and len(set(tokens)) == len(tokens):\n            term_ids = [self.term_dict.get_term_id(token) for token in tokens]\n            return self.posns.phrase_freq(term_ids)\n        else:\n            return self._phrase_freq_general(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # If slop is 1, we can use the positions of terms to calculate the phrase frequency\n        if slop == 1 and len(tokens) == len(set(tokens)):\n            return self._phrase_freq_simple(tokens)\n        else:\n            return self._phrase_freq_complex(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # If slop is 1 and tokens are unique, we can use the positions of the tokens to calculate the phrase frequencies\n        if slop == 1 and len(tokens) == len(set(tokens)):\n            term_ids = [self.term_dict.get_term_id(token) for token in tokens]\n            # Get the positions of the tokens\n            positions = self.positions(tokens[0])\n            # Calculate the phrase frequency\n            phrase_freq = compute_phrase_freqs(positions, term_ids, slop)\n            return phrase_freq\n        else:\n            return self._phrase_freq_general(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # If the slop is 1 and all tokens are unique, we can use the positions directly to calculate the phrase frequency.\n        if slop == 1 and len(set(tokens)) == len(tokens):\n            # Get the positions of the tokens in the SearchArray instance.\n            positions = [self.positions(token) for token in tokens]\n            # Calculate the phrase frequency.\n            phrase_freq = compute_phrase_freqs(positions, slop)\n            return phrase_freq\n        # Otherwise, we need to use the scan_merge method.\n        else:\n            # Get the positions of the tokens in the SearchArray instance.\n            positions = [self.positions(token) for token in tokens]\n            # Calculate the phrase frequency.\n            phrase_freq = scan_merge_ins(positions, slop)\n            return phrase_freq\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # If slop is 1 and tokens are unique, we can use the term_mat directly\n        if slop == 1 and len(tokens) == len(set(tokens)):\n            return self.termfreqs(tokens)\n        else:\n            # If slop is not 1, or tokens are not unique, we need to use the scan_merge method\n            return self.scan_merge_freq(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # If slop is 1 and tokens are unique, use the faster method to calculate phrase frequency.\n        if slop == 1 and len(set(tokens)) == len(tokens):\n            return self._phrase_freq_fast(tokens)\n        else:\n            return self._phrase_freq_slow(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(set(tokens)) == len(tokens):\n            # If slop is 1 and tokens are unique, we can use the positions directly\n            term_ids = [self.term_dict.get_term_id(token) for token in tokens]\n            return self.posns.phrase_freq(term_ids)\n        else:\n            # Delegate to a slower method\n            return self.phrase_freq_slow(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check dtype, raise TypeError\n        if not callable(tokenizer):\n            raise TypeError(\"Expected callable, got {}\".format(type(tokenizer)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(truncate)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Expected int, got {}\".format(type(batch_size)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(avoid_copies)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(array, list):\n            array = list(array)\n\n        # Check dtype, raise TypeError\n        if not isinstance(array, list):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check dtype, raise TypeError\n        if not callable(tokenizer):\n            raise TypeError(\"Expected callable, got {}\".format(type(tokenizer)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(truncate)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Expected int, got {}\".format(type(batch_size)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(avoid_copies)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(array, list):\n            array = list(array)\n\n        # Check dtype, raise TypeError\n        if not isinstance(array, list):\n            raise"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check dtype, raise TypeError\n        if not callable(tokenizer):\n            raise TypeError(\"Expected callable object, got {}\".format(type(tokenizer)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(truncate)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Expected int, got {}\".format(type(batch_size)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(avoid_copies)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(array, list):\n            array = list(array)\n\n        # Check dtype, raise TypeError\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(truncate)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Expected int, got {}\".format(type(batch_size)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(avoid_copies)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(array, list):\n            array = list(array)\n\n        # Check dtype, raise TypeError\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(truncate)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Expected int, got {}\".format(type(batch_size)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(avoid"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check dtype, raise TypeError\n        if not callable(tokenizer):\n            raise TypeError(\"Expected callable object, got {}\".format(type(tokenizer)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(truncate)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Expected int, got {}\".format(type(batch_size)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(avoid_copies)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(avoid_copies)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Expected int, got {}\".format(type(batch_size)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(avoid_copies)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Expected int, got {}\".format(type(batch_size)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(avoid_copies)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Expected int, got {}\".format(type(batch_size)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(avoid_copies, bool):"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check dtype, raise TypeError\n        if not callable(tokenizer):\n            raise TypeError(\"Expected callable, got {}\".format(type(tokenizer)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(truncate)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Expected int, got {}\".format(type(batch_size)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(avoid_copies)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(array, list):\n            array = list(array)\n\n        # Check dtype, raise TypeError\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Expected int, got {}\".format(type(batch_size)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(avoid_copies)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(truncate)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(tokenizer, Callable):\n            raise TypeError(\"Expected callable, got {}\".format(type(tokenizer)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(array, list):\n            array = list(array)\n\n        # Check dtype, raise TypeError\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Expected int, got {}\".format(type(batch_size)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(avoid_"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check dtype, raise TypeError\n        if not callable(tokenizer):\n            raise TypeError(\"Expected callable, got {}\".format(type(tokenizer)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(truncate)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Expected int, got {}\".format(type(batch_size)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(avoid_copies)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(array, (list, np.ndarray, pd.Series, pd.Index)):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(truncate)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Expected int, got {}\".format(type(batch_size)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(avoid_copies)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(array, (list, np.ndarray, pd.Series, pd.Index)):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(truncate)))\n\n        # Check dtype,"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check dtype, raise TypeError\n        if not callable(tokenizer):\n            raise TypeError(\"Expected callable object, got {}\".format(type(tokenizer)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected bool object, got {}\".format(type(truncate)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Expected int object, got {}\".format(type(batch_size)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected bool object, got {}\".format(type(avoid_copies)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(array, list):\n            array = list(array)\n\n        # Check dtype, raise TypeError\n        if not isinstance(array, list):\n            raise TypeError(\"Expected list object, got {}\".format(type(array)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected bool object, got {}\".format(type(truncate)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Expected int object, got {}\".format(type(batch_size)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected bool object, got {}\".format(type(avoid_copies)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(array, list):\n            array = list(array)\n\n        # Check dtype, raise TypeError\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected bool object, got {}\".format(type(truncate)))\n\n        # Check dtype, raise TypeError\n        if not is"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check dtype, raise TypeError\n        if not callable(tokenizer):\n            raise TypeError(\"Tokenizer must be a callable function\")\n\n        # Check dtype, raise TypeError\n        if not isinstance(truncate, bool):\n            raise TypeError(\"truncate must be a bool\")\n\n        # Check dtype, raise TypeError\n        if not isinstance(batch_size, int):\n            raise TypeError(\"batch_size must be an int\")\n\n        # Check dtype, raise TypeError\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"avoid_copies must be a bool\")\n\n        # Check dtype, raise TypeError\n        if not isinstance(array, Iterable):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check dtype, raise TypeError\n        if not callable(tokenizer):\n            raise TypeError(\"Tokenizer must be a callable function\")\n\n        # Check dtype, raise TypeError\n        if not isinstance(truncate, bool):\n            raise TypeError(\"truncate must be a bool\")\n\n        # Check dtype, raise TypeError\n        if not isinstance(batch_size, int):\n            raise TypeError(\"batch_size must be an int\")\n\n        # Check dtype, raise TypeError\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"avoid_copies must be a bool\")\n\n        # Check dtype, raise TypeError\n        if not isinstance(array, Iterable):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check dtype, raise TypeError\n        if not callable(tokenizer):\n            raise TypeError(\"Tokenizer must be a callable function\")\n\n        # Check dtype, raise TypeError\n        if not isinstance(truncate, bool):\n            raise TypeError(\"truncate must be a bool\")\n\n        # Check dtype, raise TypeError\n        if not isinstance(batch_size, int):"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check dtype, raise TypeError\n        if not callable(tokenizer):\n            raise TypeError(\"Expected callable, got {}\".format(type(tokenizer)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(truncate)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Expected int, got {}\".format(type(batch_size)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(avoid_copies)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(array, pd.Series):\n            array = pd.Series(array)\n\n        # Check dtype, raise TypeError\n        if not isinstance(array.values, np.ndarray):\n            raise TypeError(\"Expected numpy.ndarray, got {}\".format(type(array.values)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(array.values.dtype, np.dtype):\n            raise TypeError(\"Expected numpy.dtype, got {}\".format(type(array.values.dtype)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(array.values.dtype, np.dtype):\n            raise TypeError(\"Expected numpy.dtype, got {}\".format(type(array.values.dtype)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(array.values.dtype.type(), np.str_):\n            raise TypeError(\"Expected numpy.str_, got {}\".format(type(array.values.dtype.type())))\n\n        # Check dtype, raise TypeError\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(truncate)))"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n        if not callable(tokenizer):\n            raise TypeError(\"Tokenizer must be a callable function\")\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Truncate must be a boolean\")\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Batch size must be an integer\")\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Avoid copies must be a boolean\")\n\n        # Check values, raise ValueError\n        if batch_size <= 0:\n            raise ValueError(\"Batch size must be positive\")\n\n        # Check for empty array\n        if len(array) == 0:\n            return SearchArray([])\n\n        # Check for empty array\n        if len(array) == 0:\n            return SearchArray([])\n\n        # Check for empty array\n        if len(array) == 0:\n            return SearchArray([])\n\n        # Check for empty array\n        if len(array) == 0:\n            return SearchArray([])\n\n        # Check for empty array\n        if len(array) == 0:\n            return SearchArray([])\n\n        # Check for empty array\n        if len(array) == 0:\n            return SearchArray([])\n\n        # Check for empty array\n        if len(array) == 0:\n            return SearchArray([])\n\n        # Check for empty array\n        if len(array) == 0:\n            return SearchArray([])\n\n        # Check for empty array\n        if len(array) == 0:\n            return SearchArray([])\n\n        # Check for empty array\n        if len(array) == 0:\n            return SearchArray([])\n\n        # Check for empty array\n        if len(array) == 0:\n            return SearchArray([])\n\n        # Check for empty array\n        if len(array) == 0:\n            return SearchArray([])\n\n        # Check for empty array\n        if len"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check tokenizer, raise TypeError\n        if not callable(tokenizer):\n            raise TypeError(\"Expected callable, got {}\".format(type(tokenizer)))\n\n        # Check truncate, raise TypeError\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(truncate)))\n\n        # Check batch_size, raise TypeError\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Expected int, got {}\".format(type(batch_size)))\n\n        # Check avoid_copies, raise TypeError\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(avoid_copies)))\n\n        # Check array, raise TypeError\n        if not all(isinstance(x, str) for x in array):\n            raise TypeError(\"Expected array of strings\")\n\n        # Check batch_size, raise ValueError\n        if batch_size < 1:\n            raise ValueError(\"batch_size must be >= 1\")\n\n        # Check array, raise ValueError\n        if len(array) < 1:\n            raise ValueError(\"array must be non-empty\")\n\n        # Check batch_size, raise ValueError\n        if len(array) < batch_size:\n            raise ValueError(\"batch_size must be >= len(array)\")\n\n        # Check truncate, raise ValueError\n        if truncate and len(array) > batch_size:\n            raise ValueError(\"truncate=True is incompatible with batch_size < len(array)\")\n\n        # Check array, raise ValueError\n        if len(array) != len(set(array)):\n            raise ValueError(\"array must not contain duplicates\")\n\n        # Check array, raise ValueError\n        if len(array) != len(set(map(len, array))):\n            raise ValueError(\"array must not contain strings of different lengths\")\n\n        #"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check dtype, raise TypeError\n        if not callable(tokenizer):\n            raise TypeError(\"Expected callable, got {}\".format(type(tokenizer)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(truncate)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(batch_size, numbers.Integral) or batch_size < 1:\n            raise TypeError(\"Expected integer > 0, got {}\".format(type(batch_size)))\n\n        # Check dtype, raise TypeError\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(avoid_copies)))\n\n        # Process the array in batches\n        term_mat = []\n        posns = PosnBitArray()\n        term_dict = {}\n        avg_doc_length = 0\n        doc_lens = []\n        for batch in np.array_split(array, np.arange(batch_size, len(array), batch_size)):\n            batch_term_mat, batch_posns, \\\n                batch_term_dict, batch_avg_doc_length, \\\n                batch_doc_lens = build_index_from_tokenizer(batch, tokenizer,\n                                                            truncate=truncate,\n                                                            avoid_copies=avoid_copies)\n            term_mat.append(batch_term_mat)\n            posns.append(batch_posns)\n            term_dict.update(batch_term_dict)\n            avg_doc_length += batch_avg_doc_length\n            doc_lens.extend(batch_doc_lens)\n\n        # Combine the results\n        term_mat = np.concatenate(term_mat)\n        return cls(term_mat, token"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        if not callable(tokenizer):\n            raise TypeError(\"Expected callable object, got {}\".format(type(tokenizer)))\n\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(truncate)))\n\n        if not isinstance(batch_size, numbers.Integral):\n            raise TypeError(\"Expected int, got {}\".format(type(batch_size)))\n\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(avoid_copies)))\n\n        # Check input array\n        if len(array) == 0:\n            raise ValueError(\"Input array must have at least one element\")\n\n        # Check batch size\n        if batch_size < 1:\n            raise ValueError(\"batch_size must be at least 1\")\n\n        # Check for empty strings\n        if any(len(x) == 0 for x in array):\n            raise ValueError(\"Input array cannot contain empty strings\")\n\n        # Check for empty strings\n        if any(pd.isna(x) for x in array):\n            raise ValueError(\"Input array cannot contain empty strings\")\n\n        # Check for empty strings\n        if any(x is None for x in array):\n            raise ValueError(\"Input array cannot contain empty strings\")\n\n        # Check for empty strings\n        if any(len(x.split()) == 0 for x in array):\n            raise ValueError(\"Input array cannot contain empty strings\")\n\n        # Check for empty strings\n        if any(pd.isna(x) for x in array):\n            raise ValueError(\"Input array cannot contain empty strings\")\n\n        # Check for empty strings\n        if any(x is None for x in array):\n            raise ValueError(\"Input array cannot contain empty strings\")\n\n        # Check for empty strings\n        if any(len(x.split()) == 0 for x in array):\n           "}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        if not callable(tokenizer):\n            raise TypeError(\"Expected callable object, got {}\".format(type(tokenizer)))\n\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(truncate)))\n\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Expected int, got {}\".format(type(batch_size)))\n\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(avoid_copies)))\n\n        # Check values, raise ValueError\n        if batch_size < 1:\n            raise ValueError(\"batch_size must be greater than 0\")\n\n        # Process the data\n        term_mat, posns, term_dict, avg_doc_len, doc_lens = build_index_from_tokenizer(array, tokenizer,\n                                                                                       truncate=truncate,\n                                                                                       batch_size=batch_size,\n                                                                                       avoid_copies=avoid_copies)\n\n        return cls(term_mat, tokenizer=tokenizer, avoid_copies=avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Initialize the term dictionary\n        term_dict = TermDict()\n\n        # Initialize the term matrix\n        term_mat = []\n\n        # Initialize the position matrix\n        posns = PosnBitArray()\n\n        # Initialize the document lengths\n        doc_lens = []\n\n        # Initialize the average document length\n        avg_doc_length = 0\n\n        # Iterate through the array\n        for doc_id, doc in enumerate(array):\n            # Tokenize the document\n            terms = tokenizer(doc)\n\n            # Add the document to the term dictionary\n            term_dict.add_doc(terms)\n\n            # Add the document to the term matrix\n            term_mat.append(terms)\n\n            # Add the document to the position matrix\n            posns.add_doc(doc_id, terms)\n\n            # Add the document length to the document lengths\n            doc_lens.append(len(terms))\n\n            # Update the average document length\n            avg_doc_length = (avg_doc_length * doc_id + len(terms)) / (doc_id + 1)\n\n            # Truncate the data if necessary\n            if truncate and doc_id > batch_size:\n                # Truncate the term matrix\n                term_mat = term_mat[:batch_size]\n\n                # Truncate the position matrix\n                posns.truncate(batch_size)\n\n                # Truncate the document lengths\n                doc_lens = doc_lens[:batch_size]\n\n                # Truncate the average document length\n                avg_doc_length = np.mean(doc_lens)\n\n                # Break out of the loop\n                break\n\n        # Create a new instance of SearchArray\n        return cls(term_mat, tokenizer=tokenizer, avoid_copies=avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        if not callable(tokenizer):\n            raise TypeError(\"Tokenizer must be callable\")\n\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Truncate must be bool\")\n\n        if not isinstance(batch_size, numbers.Integral):\n            raise TypeError(\"batch_size must be integer\")\n\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"avoid_copies must be bool\")\n\n        if batch_size <= 0:\n            raise ValueError(\"batch_size must be positive\")\n\n        if len(array) == 0:\n            return cls([])\n\n        # TODO: Handle truncate\n\n        # TODO: Handle avoid_copies\n\n        # Build the index in batches\n        postings = []\n        for batch in chunked(array, batch_size):\n            postings.extend(build_index_from_tokenizer(batch, tokenizer, Terms))\n\n        return cls(postings, tokenizer, avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check tokenizer\n        if not callable(tokenizer):\n            raise TypeError(\"tokenizer must be callable\")\n\n        # Check truncate\n        if not isinstance(truncate, bool):\n            raise TypeError(\"truncate must be a bool\")\n\n        # Check batch_size\n        if not isinstance(batch_size, numbers.Integral) or batch_size <= 0:\n            raise TypeError(\"batch_size must be a positive integer\")\n\n        # Check avoid_copies\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"avoid_copies must be a bool\")\n\n        # Check array\n        if not isinstance(array, pd.Series) and not isinstance(array, np.ndarray):\n            array = pd.Series(array)\n\n        # Check array length\n        if len(array) == 0:\n            raise ValueError(\"Cannot index empty array\")\n\n        # Check batch size\n        if batch_size > len(array):\n            raise ValueError(\"batch_size must be <= len(array)\")\n\n        # Check if truncate\n        if truncate:\n            array = array.head(batch_size)\n\n        # Create the term matrix and positions\n        term_mat, posns, term_dict, avg_doc_length, doc_lens = build_index_from_tokenizer(array, tokenizer, batch_size, avoid_copies)\n\n        # Return the SearchArray\n        return cls(term_mat, tokenizer, avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not isinstance(array, Iterable):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        if not callable(tokenizer):\n            raise TypeError(\"Tokenizer must be callable\")\n\n        if not isinstance(truncate, bool):\n            raise TypeError(\"truncate must be bool\")\n\n        if not isinstance(batch_size, int):\n            raise TypeError(\"batch_size must be int\")\n\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"avoid_copies must be bool\")\n\n        # If we don't have a tokenizer, we can't index\n        if tokenizer is None:\n            raise ValueError(\"tokenizer must be specified\")\n\n        # If we have a batch size of 0, we can't index\n        if batch_size == 0:\n            raise ValueError(\"batch_size must be > 0\")\n\n        # If we have a batch size of -1, we can index the whole array at once\n        if batch_size == -1:\n            batch_size = len(array)\n\n        # If we have a batch size of 1, we can index the whole array at once\n        if batch_size == 1:\n            batch_size = len(array)\n\n        # If we have a batch size less than the length of the array, we can index\n        if batch_size < len(array):\n            batch_size = batch_size\n\n        # If we have a batch size greater than or equal to the length of the array, we can index the whole array at once\n        if batch_size >= len(array):\n            batch_size = len(array)\n\n        # If we have a truncate value that is not a bool, we can't index\n        if not isinstance(truncate, bool):\n            raise TypeError(\"truncate must be a bool\")\n\n        # If we have a truncate value that is not a bool, we can't index\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"avoid_copies must be a bool\")\n\n        #"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if truncate:\n            array = array[:batch_size]\n\n        if len(array) > batch_size:\n            logger.info(f\"Indexing {len(array)} documents in batches of {batch_size}\")\n            postings = []\n            for batch_start in range(0, len(array), batch_size):\n                batch_end = min(batch_start + batch_size, len(array))\n                batch = array[batch_start:batch_end]\n                batch_postings = SearchArray(batch, tokenizer, avoid_copies=avoid_copies)\n                postings.extend(batch_postings.postings)\n        else:\n            postings = SearchArray(array, tokenizer, avoid_copies=avoid_copies)\n\n        return cls(postings, tokenizer=tokenizer, avoid_copies=avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        if not callable(tokenizer):\n            raise TypeError(\"Tokenizer must be callable\")\n\n        if not isinstance(batch_size, numbers.Integral) or batch_size <= 0:\n            raise TypeError(\"batch_size must be a positive integer\")\n\n        if not isinstance(truncate, bool):\n            raise TypeError(\"truncate must be a bool\")\n\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"avoid_copies must be a bool\")\n\n        # TODO: Check that all entries are strings\n        # TODO: Check that all entries are lists of strings\n        # TODO: Check that all entries are lists of strings\n\n        # If the array is large, process in batches\n        if len(array) > batch_size:\n            postings = []\n            for i in range(0, len(array), batch_size):\n                batch = array[i:i + batch_size]\n                batch_postings = cls._index_batch(batch, tokenizer, truncate)\n                postings.extend(batch_postings)\n        else:\n            postings = cls._index_batch(array, tokenizer, truncate)\n\n        return cls(postings, tokenizer=tokenizer, avoid_copies=avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        if not callable(tokenizer):\n            raise TypeError(\"Tokenizer must be a callable\")\n\n        # Check for empty array\n        if len(array) == 0:\n            warnings.warn(\"Empty array given to SearchArray.index\")\n            return cls([])\n\n        # Check for non-string items\n        for item in array:\n            if not isinstance(item, str):\n                raise TypeError(\"Expected an array of strings\")\n\n        # Check for empty string items\n        for item in array:\n            if len(item) == 0:\n                warnings.warn(\"Empty string found in array\")\n\n        # Check for batch size\n        if batch_size < 1:\n            raise ValueError(\"Batch size must be >= 1\")\n\n        # Check for truncate\n        if truncate:\n            raise NotImplementedError(\"truncate not implemented\")\n\n        # Check for avoid_copies\n        if avoid_copies:\n            raise NotImplementedError(\"avoid_copies not implemented\")\n\n        # Build the index\n        term_mat, posns, term_dict, avg_doc_length, doc_lens = build_index_from_tokenizer(array, tokenizer,\n                                                                                          truncate=truncate,\n                                                                                          batch_size=batch_size)\n\n        return cls(term_mat, tokenizer=tokenizer, avoid_copies=avoid_copies)\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(\n            self.config['proxyHost'],\n            self.config['proxyPort'],\n            self.config['strategy'],\n            self.config['strategies'],\n            self.config['autoCloseConnections'],\n            self.config['multipleConnections'],\n            self.logger\n        )\n\n        self.server.start()\n\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['proxyHost'], self.config['proxyPort'], self.config['strategy'], self.config['strategies'], self.config['autoCloseConnections'], self.config['multipleConnections'], self.logger)\n        self.server.start()\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['proxyHost'], self.config['proxyPort'], self.logger)\n        self.server.start()\n\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['proxyHost'], self.config['proxyPort'], self.config['strategy'], self.config['strategies'], self.config['autoCloseConnections'], self.config['multipleConnections'], self.logger)\n        self.server.start()\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.logger.debug('Initializing ProxifierMessageInterceptor')\n        self.server = Server(self.config['proxyHost'], self.config['proxyPort'], self.config['strategy'], self.config['strategies'], self.config['autoCloseConnections'], self.config['multipleConnections'])\n        self.connections = {}\n        self.lock = threading.Lock()\n        self.server.start()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(\n            self.config['proxyHost'],\n            self.config['proxyPort'],\n            self.config['strategy'],\n            self.config['strategies'],\n            self.config['autoCloseConnections'],\n            self.config['multipleConnections'],\n            self.config['serverHost'],\n            self.config['serverPort'],\n            self.logger\n        )\n        self.server.start()\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.connections = {}\n        self.lock = threading.Lock()\n        self.server = Server(self.config['proxyHost'], self.config['proxyPort'], self.config['strategy'], self.config['strategies'], self.logger)\n        self.server.start()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['proxyHost'], self.config['proxyPort'], self.config['strategy'], self.config['strategies'])\n        self.server.start()\n\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.server = Server(self.config['serverHost'], self.config['serverPort'], self.config['proxyHost'], self.config['proxyPort'], self.config['strategy'], self.config['strategies'], self.config['autoCloseConnections'], self.config['multipleConnections'], self.logger)\n        self.server.start()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['proxyHost'], self.config['proxyPort'], self.logger)\n        self.server.start()\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(\n            self.config['proxyHost'],\n            self.config['proxyPort'],\n            self.config['strategy'],\n            self.config['strategies'],\n            self.config['autoCloseConnections'],\n            self.config['multipleConnections'],\n            self.logger\n        )\n\n        self.server.start()\n\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.server = Server(self.config['proxyHost'], self.config['proxyPort'], self.logger)\n        self.server.start()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['proxyHost'], self.config['proxyPort'], self.logger)\n        self.server.start()\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['serverHost'], self.config['serverPort'], self.logger)\n        self.server.start()\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['proxyHost'], self.config['proxyPort'], self.logger)\n        self.server.start()\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['proxyHost'], self.config['proxyPort'], self.logger)\n        self.server.start()\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.logger.debug('Initializing ProxifierMessageInterceptor')\n        self.connections = {}\n        self.lock = threading.Lock()\n        self.server = Server(self.config['proxyHost'], self.config['proxyPort'], self.config['strategy'], self.config['strategies'], self.config['autoCloseConnections'], self.config['multipleConnections'], self.logger)\n        self.server.start()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['proxyHost'], self.config['proxyPort'], self.logger)\n        self.server.start()\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.connections = {}\n        self.lock = threading.Lock()\n        self.server = Server(self.config['serverHost'], self.config['serverPort'], self.config['proxyHost'], self.config['proxyPort'], self.logger, self.config['strategy'], self.config['strategies'])\n        self.server.start()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        super().init()\n\n        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.server = Server(self.config['serverHost'], self.config['serverPort'], self.config['proxyHost'], self.config['proxyPort'], self.logger)\n        self.server.start()\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr &= s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # Count the number of bits set to 1 in each element of the array\n    arr = (arr & s55) + ((arr >> np.uint64(1)) & s55)\n    arr = (arr & s33) + ((arr >> np.uint64(2)) & s33)\n    arr = (arr & s0F) + ((arr >> np.uint64(4)) & s0F)\n    arr = (arr & s01) + ((arr >> np.uint64(8)) & s01)\n    arr = (arr & s01) + ((arr >> np.uint64(16)) & s01)\n    arr = (arr & s01) + ((arr >> np.uint64(32)) & s01)\n\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # Count the number of bits set to 1 in each element of the array\n    arr = (arr & s55) + ((arr >> np.uint64(1)) & s55)\n    arr = (arr & s33) + ((arr >> np.uint64(2)) & s33)\n    arr = (arr & s0F) + ((arr >> np.uint64(4)) & s0F)\n    arr = (arr & s01) + ((arr >> np.uint64(8)) & s01)\n    arr = (arr & s01) + ((arr >> np.uint64(16)) & s01)\n    arr = (arr & s01) + ((arr >> np.uint64(32)) & s01)\n    arr = (arr & s01) + ((arr >> np.uint64(48)) & s01)\n    arr = (arr & s01) + ((arr >> np.uint64(56)) & s01)\n    arr = (arr & s01) + ((arr >> np.uint64(64 - 8)) & s01)\n\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # Count the number of bits set to 1 in each element of the input array.\n    arr = (arr & s55) + ((arr >> np.uint64(1)) & s55)\n    arr = (arr & s33) + ((arr >> np.uint64(2)) & s33)\n    arr = (arr & s0F) + ((arr >> np.uint64(4)) & s0F)\n    arr = (arr & s01) + ((arr >> np.uint64(8)) & s01)\n    arr = (arr & s01) + ((arr >> np.uint64(16)) & s01)\n    arr = (arr & s01) + ((arr >> np.uint64(32)) & s01)\n    arr = (arr & s01) + ((arr >> np.uint64(48)) & s01)\n    arr = (arr & s01) + ((arr >> np.uint64(56)) & s01)\n    arr = (arr & s01) + ((arr >> np.uint64(64-8)) & s01)\n\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr &= mask\n    arr -= (s55 & (arr >> np.uint64(1)))\n    arr = (arr & s33) + ((arr >> np.uint64(2)) & s33)\n    arr = (arr + (arr >> np.uint64(4))) & s0F\n    return (arr * _11) & s0F\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr = arr & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = (arr * _2) & s55\n    arr = arr & s55\n\n    arr = arr + (arr >> s33)\n    arr = arr + (arr >> s33)\n    arr = arr + (arr >> s33)\n    arr = arr & s33\n\n    arr = arr + (arr >> s0F)\n    arr = arr + (arr >> s0F)\n    arr = arr + (arr >> s0F)\n    arr = arr + (arr >> s0F)\n    arr = arr + (arr >> s0F)\n    arr = arr + (arr >> s0F)\n    arr = arr + (arr >> s0F)\n    arr = arr + (arr >> s0F)\n    arr = arr + (arr >> s0F)\n    arr = arr + (arr >> s0F)\n    arr = arr + (arr >> s0F)\n    arr = arr + (arr >> s0F)\n    arr = arr + (arr >> s0F)\n    arr = arr & s0F\n\n    arr = arr + (arr >> s01)\n    arr = arr + (arr >> s01)\n    arr = arr + (arr >> s01)\n    arr = arr + (arr >> s01)\n    arr = arr + (arr >> s01)\n    arr = arr + (arr >> s01)\n    arr = arr + (arr >> s01)\n    arr = arr + (arr >> s01)\n    arr = arr + (arr >> s01)\n    arr = arr + (arr >> s01)\n    arr = arr + (arr >> s01)\n    arr = arr + (arr >> s0"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # Count the number of bits set to 1 in each element of the input array.\n    arr = (arr & s55) + ((arr >> np.uint64(1)) & s55)\n    arr = (arr & s33) + ((arr >> np.uint64(2)) & s33)\n    arr = (arr & s0F) + ((arr >> np.uint64(4)) & s0F)\n    arr = (arr & s01) + ((arr >> np.uint64(8)) & s01)\n    arr = (arr & s01) + ((arr >> np.uint64(16)) & s01)\n    arr = (arr & s01) + ((arr >> np.uint64(32)) & s01)\n    arr = (arr & s01) + ((arr >> np.uint64(48)) & s01)\n    arr = (arr & s01) + ((arr >> np.uint64(56)) & s01)\n    arr = (arr & s01) + ((arr >> np.uint64(64-8)) & s01)\n\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # Count the number of bits set to 1 in each element of the array\n    arr = (arr & s55) + ((arr >> np.uint64(1)) & s55)\n    arr = (arr & s33) + ((arr >> np.uint64(2)) & s33)\n    arr = (arr & s0F) + ((arr >> np.uint64(4)) & s0F)\n    arr = (arr & s01) + ((arr >> np.uint64(8)) & s01)\n    arr = (arr & s01) + ((arr >> np.uint64(16)) & s01)\n    arr = (arr & s01) + ((arr >> np.uint64(32)) & s01)\n    arr = (arr & s01) + ((arr >> np.uint64(48)) & s01)\n    arr = (arr & s01) + ((arr >> np.uint64(56)) & s01)\n    arr = (arr & s01) + ((arr >> np.uint64(64)) & s01)\n\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr = arr - ((s55 & (arr >> _1)) + (s33 & (arr >> _2)) + (s0F & (arr >> _4)))\n    arr = (arr & s01) + ((arr >> _1) & s01) + ((arr >> _2) & s01) + ((arr >> _4) & s01)\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # Count the number of bits set to 1 in each element of the array.\n    arr &= s55\n    arr = (arr + (arr >> np.uint64(1))) & s55\n    arr = (arr + (arr >> np.uint64(2))) & s33\n    arr = (arr + (arr >> np.uint64(4))) & s0F\n    arr = (arr + (arr >> np.uint64(8))) & s01\n    arr = (arr + (arr >> np.uint64(16))) & s01\n    arr = (arr + (arr >> np.uint64(32))) & s01\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr &= s55\n    arr = (arr * s33) + ((arr >> np.uint64(1)) & s55)\n    arr = ((arr * s0F) + (arr >> np.uint64(2)))\n    arr = ((arr * s01) + (arr >> np.uint64(4)))\n    arr += (arr >> np.uint64(32))\n    return arr & mask\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # Count the number of bits set to 1 in each element of the input array.\n    arr &= s55\n    arr = (arr + (arr >> np.uint64(1))) & s55\n    arr = (arr + (arr >> np.uint64(2))) & s33\n    arr = (arr + (arr >> np.uint64(4))) & s0F\n    arr = (arr + (arr >> np.uint64(8))) & s01\n    arr = (arr + (arr >> np.uint64(16))) & s01\n    arr = (arr + (arr >> np.uint64(32))) & s01\n\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr &= s55\n    arr = (arr * s33) + (arr >> np.uint64(1))\n    arr = (arr * s0F) + (arr >> np.uint64(2))\n    arr = (arr * s01) + (arr >> np.uint64(4))\n    arr = (arr * s01) + (arr >> np.uint64(8))\n    arr = (arr * s01) + (arr >> np.uint64(16))\n    arr = (arr * s01) + (arr >> np.uint64(32))\n    return arr & s01\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # Count the number of bits set to 1 in each element of the array\n    arr = (((arr & s55) + ((arr >> _1) & s55)) & s33) + ((arr >> _2) & s33)\n    arr = (((arr + (arr >> _4)) & s0F) * _11)\n    arr = (arr + (arr >> _8)) & s01\n    arr = (arr + (arr >> _16)) & s01\n    arr = (arr + (arr >> _32)) & s01\n\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # Count the number of bits set to 1 in each element of the array\n    arr &= s55\n    arr = (arr + (arr >> np.uint64(1))) & s55\n    arr = (arr + (arr >> np.uint64(2))) & s33\n    arr = (arr + (arr >> np.uint64(4))) & s0F\n    arr = (arr + (arr >> np.uint64(8))) & s01\n    arr = (arr + (arr >> np.uint64(16))) & s01\n    arr = (arr + (arr >> np.uint64(32))) & s01\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # Count the number of bits set to 1 in each byte of the array.\n    arr = ((arr & s55) + ((arr >> np.uint64(1)) & s55) + ((arr >> np.uint64(2)) & s55) + ((arr >> np.uint64(3)) & s55)) & s55\n    arr = ((arr + (arr >> np.uint64(4))) & s33) + ((arr & s33) << np.uint64(4))\n    arr = ((arr + (arr >> np.uint64(8))) & s0F) + ((arr & s0F) << np.uint64(8))\n    arr = ((arr + (arr >> np.uint64(16))) & s01) + ((arr & s01) << np.uint64(16))\n    arr = ((arr + (arr >> np.uint64(32))) & s01) + ((arr & s01) << np.uint64(32))\n\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # Count the number of bits set to 1 in each element of the array.\n\n    arr &= s55  # Clear all bits with mask s55.\n    arr = (arr - ((arr >> np.uint64(1)) & s55)) & s55  # Set the first bit in each element of the array to 0 if the second bit is 1.\n    arr = (arr - ((arr >> np.uint64(2)) & s33)) & s33  # Set the second bit in each element of the array to 0 if the third bit is 1.\n    arr = (arr + (arr >> np.uint64(2))) & s33  # Set the third bit in each element of the array to 1 if the fourth bit is 1.\n    arr = (arr * np.uint64(_1010101010101010)) & s0F  # Set the fourth bit in each element of the array to 0 if the fifth bit is 1.\n    arr = (arr + (arr >> np.uint64(4))) & s0F  # Set the fifth bit in each element of the array to 1 if the sixth bit is 1.\n    arr = (arr * np.uint64(_0101010101010101)) & s0F  # Set the sixth bit in each element of the array to 0 if the seventh bit is 1.\n    arr = (arr + (arr >> np.uint64(4))) & s0F  # Set the seventh bit in each element of the array to 1 if the eighth bit is 1.\n    arr = (arr * np.uint64(_0001000100010001)) & s01  # Set the eighth bit in each element of the array to 0 if the ninth bit is 1.\n    arr = (arr + (arr >> np.uint64(8))) & s01  # Set the ninth bit in each element of the array to 1 if the tenth bit is 1.\n    arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # Count the number of bits set to 1 in each 2-bit word\n    arr &= s55\n    arr = (arr - ((arr >> _1) & s55)) & s55\n    arr = (arr & s33) + ((arr >> _2) & s33)\n    # Count the number of bits set to 1 in each 4-bit word\n    arr = (arr + (arr >> _4)) & s0F\n    # Count the number of bits set to 1 in each 8-bit word\n    arr = (arr * _01010101) & s01\n    # Sum up all the bits set to 1 in each 8-bit word\n    arr = arr.sum(axis=0)\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # Count the number of bits set to 1 in each element of the array.\n    arr &= mask  # Clear all bits above the 64th.\n    arr -= ((s55 & arr) >> 1) & s55\n    arr = ((arr - (s33 & arr) >> 2) & s33) + ((arr >> 4) & s55)\n    return ((arr + (arr >> 8)) & s33) + ((arr >> 16) & s55) + ((arr >> 32) & s33)\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # Count the number of bits set to 1 in each element of the array.\n\n    # The first step is to subtract 1 from each element of the array.\n    # This is done to remove the rightmost set bit of each element.\n    # For example, if the element is 10110101, then subtracting 1 gives 10110011.\n    # The rightmost set bit of 10110101 is 10000000, which is 128.\n    # The rightmost set bit of 10110011 is 01000000, which is 64.\n    # The bit counts of the two elements are 128 and 64, respectively.\n    arr -= _1\n\n    # The next step is to perform bitwise AND of each element of the array with a mask.\n    # The mask is 010101010101010101010101010101010.\n    # This is done to remove the leftmost set bit of each element.\n    # For example, if the element is 10110101, then performing bitwise AND with the mask gives 01010101.\n    # The leftmost set bit of 10110101 is 10000000, which is 128.\n    # The leftmost set bit of 01010101 is 00100000, which is 32.\n    # The bit counts of the two elements are 128 and 32, respectively.\n    arr &= s55\n    arr += _1\n\n    # The next step is to perform bitwise AND of each element of the array with a mask.\n    # The mask is 00001111111111111111111111111111.\n    # This is done to remove the leftmost set bit of each element.\n    #"}
{"namespace": "searcharray.solr.edismax", "completion": "    query_fields = parse_field_boosts(qf)\n    phrase_fields = parse_field_boosts(pf)\n    bigram_fields = parse_field_boosts(pf2)\n    trigram_fields = parse_field_boosts(pf3)\n\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    query_fields = parse_field_boosts(qf)\n    phrase_fields = parse_field_boosts(pf)\n    bigram_fields = parse_field_boosts(pf2)\n    trigram_fields = parse_field_boosts(pf3)\n\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    # Parse query fields\n    query_fields = parse_field_boosts(qf)\n\n    # Parse phrase fields\n    phrase_fields = parse_field_boosts(pf) if pf is not None else {}\n    bigram_fields = parse_field_boosts(pf2) if pf2 is not None else {}\n    trigram_fields = parse_field_boosts(pf3) if pf3 is not None else {}\n\n    # Parse query terms\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    # Compute scores\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    qf_boosts = parse_field_boosts(qf)\n    pf_boosts = parse_field_boosts(pf)\n    pf2_boosts = parse_field_boosts(pf2)\n    pf3_boosts = parse_field_boosts(pf3)\n\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n    if term_centric:\n        return _edismax_term_centric(frame, qf_boosts, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, qf_boosts, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    # Parse query fields\n    query_fields = parse_field_boosts(qf)\n\n    # Parse phrase fields\n    phrase_fields = parse_field_boosts(pf) if pf else {}\n    bigram_fields = parse_field_boosts(pf2) if pf2 else {}\n    trigram_fields = parse_field_boosts(pf3) if pf3 else {}\n\n    # Parse query terms\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    # Term-centric search\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    # Field-centric search\n    return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    # Parse query fields\n    query_fields = parse_field_boosts(qf)\n\n    # Parse phrase fields\n    phrase_fields = parse_field_boosts(pf) if pf is not None else {}\n    bigram_fields = parse_field_boosts(pf2) if pf2 is not None else {}\n    trigram_fields = parse_field_boosts(pf3) if pf3 is not None else {}\n\n    # Parse query terms\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    # Calculate scores\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    if q_op not in [\"OR\", \"AND\"]:\n        raise ValueError(\"q_op must be either 'OR' or 'AND'\")\n\n    if not qf:\n        raise ValueError(\"qf must be non-empty\")\n\n    # Parse query fields\n    query_fields = parse_field_boosts(qf)\n\n    # Parse phrase fields\n    phrase_fields = parse_field_boosts(pf) if pf else {}\n    bigram_fields = parse_field_boosts(pf2) if pf2 else {}\n    trigram_fields = parse_field_boosts(pf3) if pf3 else {}\n\n    # Parse query terms\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    # Parse query fields\n    query_fields = parse_field_boosts(qf)\n\n    # Parse phrase fields\n    phrase_fields = parse_field_boosts(pf) if pf is not None else {}\n    bigram_fields = parse_field_boosts(pf2) if pf2 is not None else {}\n    trigram_fields = parse_field_boosts(pf3) if pf3 is not None else {}\n\n    # Parse query terms\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    # Perform edismax search\n    if term_centric:\n        scores, explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        scores, explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    # Add phrase, bigram, and trigram matches\n    for field, boost in phrase_fields.items():\n        post_arr = get_field(frame, field)\n        scores += post_arr.score_phrases(search_terms[field], similarity=similarity) * (1 if boost is None else boost)\n        explain += f\" | {field}:({' '.join(search_terms[field])})^{'1' if boost is None else boost}\"\n\n    for field, boost in bigram_fields.items():\n        post_arr = get_field(frame, field)\n        scores += post_arr.score_bigrams(search_terms[field], similarity=similarity) * (1 if boost is None else boost)\n        explain += f\" | {field}:({' '.join(search_terms[field])})^{'1' if boost is None else boost}\"\n\n    for field, boost in trigram_fields.items():\n        post_arr = get_field(frame, field)\n        scores += post_arr.score_trigrams(search_terms[field],"}
{"namespace": "searcharray.solr.edismax", "completion": "    if q_op not in [\"OR\", \"AND\"]:\n        raise ValueError(\"q_op must be 'OR' or 'AND'\")\n\n    query_fields = parse_field_boosts(qf)\n    phrase_fields = parse_field_boosts(pf)\n    bigram_fields = parse_field_boosts(pf2)\n    trigram_fields = parse_field_boosts(pf3)\n\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    if phrase_fields:\n        for field, boost in phrase_fields.items():\n            post_arr = get_field(frame, field)\n            field_scores = np.array([post_arr.score(term, similarity=similarity)\n                                    for term in search_terms[field]])\n            min_should_match = parse_min_should_match(len(search_terms[field]), spec=mm)\n            exp = \" \".join([f\"{field}:{term}\" for term in search_terms[field]])\n            boost_exp = f\"{boost}\" if boost is not None else \"1\"\n            exp = \"(\" + exp + f\")~{min(min_should_match, len(search_terms[field]))}\"\n            exp = \"(\" + exp + f\")^{boost_exp}\"\n            matches_gt_mm = np.sum(field_scores > 0, axis=0) >= min(min_should_match, len(search_terms[field]))\n            sum_terms_bm25 = np.sum(field_scores, axis=0)\n            sum_terms_bm"}
{"namespace": "searcharray.solr.edismax", "completion": "    # Parse query fields\n    query_fields = parse_field_boosts(qf)\n\n    # Parse phrase fields\n    phrase_fields = parse_field_boosts(pf)\n    phrase_fields.update(parse_field_boosts(pf2))\n    phrase_fields.update(parse_field_boosts(pf3))\n\n    # Parse query terms\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    # Compute scores\n    if term_centric:\n        scores, explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        scores, explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    # Add phrase and bigram scores\n    for field, boost in phrase_fields.items():\n        post_arr = get_field(frame, field)\n        field_scores = np.array([post_arr.score_phrase(phrase, similarity=similarity)\n                                 for phrase in search_terms[field]])\n        min_should_match = parse_min_should_match(len(search_terms[field]), spec=mm)\n        matches_gt_mm = np.sum(field_scores > 0, axis=0) >= min(min_should_match, len(search_terms[field]))\n        sum_terms_bm25 = np.sum(field_scores, axis=0)\n        sum_terms_bm25[~matches_gt_mm] = 0\n        scores += sum_terms_bm25 * (1 if boost is None else boost)\n        explain += \" | \" + \" \".join([f\"{field}:{phrase}\" for phrase in search_terms[field]])\n\n    return scores, explain"}
{"namespace": "searcharray.solr.edismax", "completion": "    # Parse query fields\n    query_fields = parse_field_boosts(qf)\n    if len(query_fields) == 0:\n        raise ValueError(\"No query fields specified\")\n\n    # Parse phrase fields\n    phrase_fields = parse_field_boosts(pf)\n    bigram_fields = parse_field_boosts(pf2)\n    trigram_fields = parse_field_boosts(pf3)\n\n    # Parse query terms\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, query_fields)\n\n    # Compute scores\n    if term_centric:\n        scores, explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        scores, explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    # Apply phrase fields\n    if len(phrase_fields) > 0:\n        for field, boost in phrase_fields.items():\n            post_arr = get_field(frame, field)\n            field_scores = np.array([post_arr.score_phrase(query, similarity=similarity)\n                                     for query in search_terms[field]])\n            min_should_match = parse_min_should_match(len(search_terms[field]), spec=mm)\n            exp = \" \".join([f\"{field}:{term}\" for term in search_terms[field]])\n            boost_exp = f\"{boost}\" if boost is not None else \"1\"\n            exp = \"(\" + exp + f\")~{min(min_should_match, len(search_terms[field]))}\"\n            exp = \"(\" + exp + f\")^{boost_exp}\"\n            matches_gt_mm = np.sum(field_scores > 0, axis=0) >= min(min_should_match, len(search_terms[field]))\n            sum_terms_"}
{"namespace": "searcharray.solr.edismax", "completion": "    # Parse query terms\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    # Parse mm\n    if mm is None:\n        mm = \"1\"\n\n    # Parse qf\n    query_fields = parse_field_boosts(qf)\n\n    # Parse pf\n    if pf is None:\n        pf = []\n    phrase_fields = parse_field_boosts(pf)\n\n    # Parse pf2\n    if pf2 is None:\n        pf2 = []\n    bigram_fields = parse_field_boosts(pf2)\n\n    # Parse pf3\n    if pf3 is None:\n        pf3 = []\n    trigram_fields = parse_field_boosts(pf3)\n\n    # Get scores\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    # Get phrase scores\n    if phrase_fields:\n        for field, boost in phrase_fields.items():\n            post_arr = get_field(frame, field)\n            term_scores = np.array([post_arr.score(term, similarity=similarity)\n                                    for term in search_terms[field]])\n            min_should_match = parse_min_should_match(len(search_terms[field]), spec=mm)\n            exp = \" \".join([f\"{field}:{term}\" for term in search_terms[field]])\n            boost_exp = f\"{boost}\" if boost is not None else \"1\"\n            exp = \"(\" + exp + f\")~{min(min_should_match, len(search_terms[field]))}\"\n            exp = \"(\" + exp + f\")^{"}
{"namespace": "searcharray.solr.edismax", "completion": "    # validate qf, pf, pf2, pf3\n    if not isinstance(qf, list):\n        raise ValueError(\"qf must be a list\")\n    if pf is not None and not isinstance(pf, list):\n        raise ValueError(\"pf must be a list\")\n    if pf2 is not None and not isinstance(pf2, list):\n        raise ValueError(\"pf2 must be a list\")\n    if pf3 is not None and not isinstance(pf3, list):\n        raise ValueError(\"pf3 must be a list\")\n\n    # validate q_op\n    if q_op not in [\"OR\", \"AND\"]:\n        raise ValueError(\"q_op must be either 'OR' or 'AND'\")\n\n    # validate mm\n    if mm is not None and not isinstance(mm, str):\n        raise ValueError(\"mm must be a string\")\n\n    # validate qf, pf, pf2, pf3\n    if not isinstance(qf, list):\n        raise ValueError(\"qf must be a list\")\n    if pf is not None and not isinstance(pf, list):\n        raise ValueError(\"pf must be a list\")\n    if pf2 is not None and not isinstance(pf2, list):\n        raise ValueError(\"pf2 must be a list\")\n    if pf3 is not None and not isinstance(pf3, list):\n        raise ValueError(\"pf3 must be a list\")\n\n    # validate q_op\n    if q_op not in [\"OR\", \"AND\"]:\n        raise ValueError(\"q_op must be either 'OR' or 'AND'\")\n\n    # validate mm\n    if mm is not None and not isinstance(mm, str):\n        raise ValueError(\"mm must be a string\")\n\n    # validate similarity\n    if not isinstance(similarity, Similarity):\n        raise ValueError(\"similarity must be a Similarity\")\n\n    # validate qf\n    if not isinstance(qf, list):\n        raise ValueError(\"qf must be a list\")\n    for field in qf:"}
{"namespace": "searcharray.solr.edismax", "completion": "    # parse query fields\n    query_fields = parse_field_boosts(qf)\n\n    # parse phrase fields\n    phrase_fields = parse_field_boosts(pf) if pf else {}\n    bigram_fields = parse_field_boosts(pf2) if pf2 else {}\n    trigram_fields = parse_field_boosts(pf3) if pf3 else {}\n\n    # parse query terms\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    # parse minimum should match\n    if mm is None:\n        mm = \"100%\"\n\n    # compute scores\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    # add phrase, bigram, and trigram scores\n    for field, boost in phrase_fields.items():\n        post_arr = get_field(frame, field)\n        field_scores = np.array([post_arr.score(term, similarity=similarity)\n                                 for term in search_terms[field]])\n        min_should_match = parse_min_should_match(len(search_terms[field]), spec=mm)\n        matches_gt_mm = np.sum(field_scores > 0, axis=0) >= min(min_should_match, len(search_terms[field]))\n        sum_terms_bm25 = np.sum(field_scores, axis=0)\n        sum_terms_bm25[~matches_gt_mm] = 0\n        qf_scores += sum_terms_bm25 * (1 if boost is None else boost)\n        explain += f\" | {field}:({' '.join(search_ter"}
{"namespace": "searcharray.solr.edismax", "completion": "    # Parse query fields\n    query_fields = parse_field_boosts(qf)\n\n    # Parse phrase fields\n    phrase_fields = parse_field_boosts(pf) if pf is not None else {}\n    bigram_fields = parse_field_boosts(pf2) if pf2 is not None else {}\n    trigram_fields = parse_field_boosts(pf3) if pf3 is not None else {}\n\n    # Parse query terms\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    # Compute search scores\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    # Add phrase, bigram, and trigram scores\n    if phrase_fields or bigram_fields or trigram_fields:\n        explain += \" + \"\n\n    if phrase_fields:\n        for field, boost in phrase_fields.items():\n            post_arr = get_field(frame, field)\n            field_scores = np.array([post_arr.score_phrase(phrase, similarity=similarity)\n                                    for phrase in search_terms[field]])\n            min_should_match = parse_min_should_match(len(search_terms[field]), spec=mm)\n            exp = \" \".join([f\"{field}:{phrase}\" for phrase in search_terms[field]])\n            boost_exp = f\"{boost}\" if boost is not None else \"1\"\n            exp = \"(\" + exp + f\")~{min(min_should_match, len(search_terms[field]))}\"\n            exp = \"(\" + exp + f\")^{boost_exp}\"\n\n            matches_gt_mm = np.sum(field"}
{"namespace": "searcharray.solr.edismax", "completion": "    if q_op not in [\"OR\", \"AND\"]:\n        raise ValueError(f\"q_op must be either 'OR' or 'AND'. Got {q_op}\")\n\n    query_fields = parse_field_boosts(qf)\n    phrase_fields = parse_field_boosts(pf)\n    bigram_fields = parse_field_boosts(pf2)\n    trigram_fields = parse_field_boosts(pf3)\n\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, query_fields.keys())\n\n    if term_centric:\n        scores, explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        scores, explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    if phrase_fields:\n        for field, boost in phrase_fields.items():\n            post_arr = get_field(frame, field)\n            field_scores = np.array([post_arr.score_phrase(phrase, similarity=similarity)\n                                    for phrase in search_terms[field]])\n            min_should_match = parse_min_should_match(len(search_terms[field]), spec=mm)\n            exp = \" \".join([f\"{field}:{term}\" for term in search_terms[field]])\n            exp = \"(\" + exp + f\")~{min(min_should_match, len(search_terms[field]))}\"\n            exp = \"(\" + exp + f\")^{boost}\"\n\n            matches_gt_mm = np.sum(field_scores > 0, axis=0) >= min(min_should_match, len(search_terms[field]))\n            sum_terms_bm25 = np.sum(field_scores, axis=0)\n            sum_terms_bm25[~matches_gt_mm] = 0"}
{"namespace": "searcharray.solr.edismax", "completion": "    # Parse query fields\n    query_fields = parse_field_boosts(qf)\n\n    # Parse phrase fields\n    phrase_fields = parse_field_boosts(pf) if pf is not None else {}\n    bigram_fields = parse_field_boosts(pf2) if pf2 is not None else {}\n    trigram_fields = parse_field_boosts(pf3) if pf3 is not None else {}\n\n    # Parse query terms\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, query_fields)\n\n    # Perform edismax\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame,\n                                                   query_fields,\n                                                   num_search_terms,\n                                                   search_terms,\n                                                   mm,\n                                                   similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame,\n                                                    query_fields,\n                                                    num_search_terms,\n                                                    search_terms,\n                                                    mm,\n                                                    similarity)\n\n    # Add phrase fields\n    if phrase_fields:\n        for field, boost in phrase_fields.items():\n            post_arr = get_field(frame, field)\n            field_scores = np.array([post_arr.score_phrase(phrase, similarity=similarity)\n                                    for phrase in search_terms[field]])\n            min_should_match = parse_min_should_match(len(search_terms[field]), spec=mm)\n            field_scores[np.sum(field_scores > 0, axis=0) < min_should_match] = 0\n            qf_scores += field_scores * (1 if boost is None else boost)\n            explain += \" | \" + \" \".join([f\"{field}:{phrase}\" for phrase in search_terms[field]])"}
{"namespace": "searcharray.solr.edismax", "completion": "    # Get query fields\n    query_fields = parse_field_boosts(qf)\n\n    # Parse query terms\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    # Get minimum should match\n    if mm is None:\n        mm = f\"{num_search_terms}\".lower()\n\n    # Get phrase fields\n    phrase_fields = parse_field_boosts(pf) if pf is not None else {}\n    bigram_fields = parse_field_boosts(pf2) if pf2 is not None else {}\n    trigram_fields = parse_field_boosts(pf3) if pf3 is not None else {}\n\n    # Perform edismax\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    # Add phrase fields\n    if phrase_fields:\n        for field, boost in phrase_fields.items():\n            post_arr = get_field(frame, field)\n            field_scores = np.array([post_arr.score(term, similarity=similarity)\n                                    for term in search_terms[field]])\n            min_should_match = parse_min_should_match(len(search_terms[field]), spec=mm)\n            exp = \" \".join([f\"{field}:{term}\" for term in search_terms[field]])\n            boost_exp = f\"{boost}\" if boost is not None else \"1\"\n            exp = \"(\" + exp + f\")~{min(min_should_match, len(search_terms[field]))}\"\n            exp = \"(\" + exp + f\")^{boost_exp}\"\n            matches_gt_mm = np.sum(field_scores > "}
{"namespace": "searcharray.solr.edismax", "completion": "    if q_op not in {\"OR\", \"AND\"}:\n        raise ValueError(\"q_op must be 'OR' or 'AND'.\")\n\n    if mm is not None and mm not in {\"100%\", \"75%\", \"50%\", \"25%\"}:\n        raise ValueError(\"mm must be '100%', '75%', '50%', or '25%'\")\n\n    if not all([field in frame.columns for field in qf]):\n        raise ValueError(\"qf must be a subset of the columns in the DataFrame.\")\n\n    if pf is not None and not all([field in frame.columns for field in pf]):\n        raise ValueError(\"pf must be a subset of the columns in the DataFrame.\")\n\n    if pf2 is not None and not all([field in frame.columns for field in pf2]):\n        raise ValueError(\"pf2 must be a subset of the columns in the DataFrame.\")\n\n    if pf3 is not None and not all([field in frame.columns for field in pf3]):\n        raise ValueError(\"pf3 must be a subset of the columns in the DataFrame.\")\n\n    qf_boosts = parse_field_boosts(qf)\n    pf_boosts = parse_field_boosts(pf)\n    pf2_boosts = parse_field_boosts(pf2)\n    pf3_boosts = parse_field_boosts(pf3)\n\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n    if term_centric:\n        return _edismax_term_centric(frame, qf_boosts, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, qf_boosts, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    if q_op not in [\"OR\", \"AND\"]:\n        raise ValueError(f\"q_op must be either 'OR' or 'AND', but got {q_op}\")\n\n    if not qf:\n        raise ValueError(\"qf must contain at least one field\")\n\n    if not q:\n        raise ValueError(\"q must be a non-empty string\")\n\n    if mm is not None and mm not in [\"100%\", \"75%\", \"50%\", \"25%\"]:\n        raise ValueError(f\"mm must be one of '100%', '75%', '50%', '25%', but got {mm}\")\n\n    # Parse query fields\n    query_fields = parse_field_boosts(qf)\n\n    # Parse phrase fields\n    phrase_fields = parse_field_boosts(pf)\n    bigram_fields = parse_field_boosts(pf2)\n    trigram_fields = parse_field_boosts(pf3)\n\n    # Parse query terms\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, query_fields)\n\n    if term_centric:\n        # Term-centric search\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        # Field-centric search\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        with self.lock:\n            if isinstance(message, SendMessage):\n                if process.id not in self.connections:\n                    self.connections[process.id] = Connection(\n                        process.id,\n                        self.server,\n                        self.logger,\n                        self.config['autoCloseConnections'],\n                        self.config['multipleConnections']\n                    )\n                self.connections[process.id].c2s(message)\n            elif isinstance(message, RecvMessage):\n                if process.id not in self.connections:\n                    self.connections[process.id] = Connection(\n                        process.id,\n                        self.server,\n                        self.logger,\n                        self.config['autoCloseConnections'],\n                        self.config['multipleConnections']\n                    )\n                message.data = self.connections[process.id].s2c(message)\n            elif isinstance(message, CloseMessage):\n                if process.id in self.connections:\n                    self.connections[process.id].close()\n                    del self.connections[process.id]\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            self.lock.acquire()\n            try:\n                if self.config['multipleConnections']:\n                    connection_id = process.id\n                else:\n                    connection_id = DEFAULT_CONNECTION_ID\n\n                if connection_id not in self.connections:\n                    self.connections[connection_id] = Connection(\n                        server=self.server,\n                        connection_id=connection_id,\n                        logger=self.logger,\n                        auto_close=self.config['autoCloseConnections']\n                    )\n\n                self.connections[connection_id].c2s(message)\n            finally:\n                self.lock.release()\n\n        elif isinstance(message, RecvMessage):\n            self.lock.acquire()\n            try:\n                if self.config['multipleConnections']:\n                    connection_id = process.id\n                else:\n                    connection_id = DEFAULT_CONNECTION_ID\n\n                if connection_id not in self.connections:\n                    self.connections[connection_id] = Connection(\n                        server=self.server,\n                        connection_id=connection_id,\n                        logger=self.logger,\n                        auto_close=self.config['autoCloseConnections']\n                    )\n\n                self.connections[connection_id].s2c(message)\n            finally:\n                self.lock.release()\n\n        elif isinstance(message, CloseMessage):\n            self.lock.acquire()\n            try:\n                if self.config['multipleConnections']:\n                    connection_id = process.id\n                else:\n                    connection_id = DEFAULT_CONNECTION_ID\n\n                if connection_id in self.connections:\n                    self.connections[connection_id].close()\n                    del self.connections[connection_id]\n            finally:\n                self.lock.release()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        with self.lock:\n            connection = self.connections.get(process.id)\n            if not connection:\n                connection = self.server.create_connection(process.id)\n                self.connections[process.id] = connection\n            if isinstance(message, SendMessage):\n                message.data = connection.c2s(message.data)\n            elif isinstance(message, RecvMessage):\n                message.data = connection.s2c(message.data)\n            elif isinstance(message, CloseMessage):\n                if self.config['autoCloseConnections']:\n                    self.server.close_connection(connection)\n                    del self.connections[process.id]\n                else:\n                    connection.close()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            with self.lock:\n                connection = self.connections.get(process.id, None)\n                if connection is None:\n                    connection = Connection(\n                        self.server,\n                        process.id if self.config['multipleConnections'] else DEFAULT_CONNECTION_ID,\n                        process.id,\n                        self.logger\n                    )\n                    self.connections[process.id] = connection\n\n            message.data = connection.c2s(message.data)\n\n        elif isinstance(message, RecvMessage):\n            with self.lock:\n                connection = self.connections.get(process.id, None)\n                if connection is None:\n                    connection = Connection(\n                        self.server,\n                        process.id if self.config['multipleConnections'] else DEFAULT_CONNECTION_ID,\n                        process.id,\n                        self.logger\n                    )\n                    self.connections[process.id] = connection\n\n            message.data = connection.s2c(message.data)\n\n        elif isinstance(message, CloseMessage):\n            with self.lock:\n                connection = self.connections.get(process.id, None)\n                if connection is None:\n                    return\n\n                if self.config['autoCloseConnections']:\n                    connection.close()\n                    del self.connections[process.id]\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            with self.lock:\n                connection_id = DEFAULT_CONNECTION_ID if not self.config['multipleConnections'] else process.id\n                if connection_id not in self.connections:\n                    self.connections[connection_id] = Connection(\n                        server=self.server,\n                        connection_id=connection_id,\n                        logger=self.logger,\n                        auto_close=self.config['autoCloseConnections'],\n                    )\n                self.connections[connection_id].c2s(message.data)\n        elif isinstance(message, RecvMessage):\n            with self.lock:\n                connection_id = DEFAULT_CONNECTION_ID if not self.config['multipleConnections'] else process.id\n                if connection_id not in self.connections:\n                    self.connections[connection_id] = Connection(\n                        server=self.server,\n                        connection_id=connection_id,\n                        logger=self.logger,\n                        auto_close=self.config['autoCloseConnections'],\n                    )\n                message.data = self.connections[connection_id].s2c()\n        elif isinstance(message, CloseMessage):\n            with self.lock:\n                connection_id = DEFAULT_CONNECTION_ID if not self.config['multipleConnections'] else process.id\n                if connection_id in self.connections:\n                    self.connections[connection_id].close()\n                    del self.connections[connection_id]\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        with self.lock:\n            if isinstance(message, SendMessage):\n                if not self.config['multipleConnections'] and process.id in self.connections:\n                    connection = self.connections[process.id]\n                else:\n                    connection = Connection(\n                        server=self.server,\n                        process=process,\n                        auto_close=self.config['autoCloseConnections'],\n                        logger=self.logger,\n                    )\n                    self.connections[process.id] = connection\n                message.data = connection.c2s(message.data)\n            elif isinstance(message, RecvMessage):\n                if process.id in self.connections:\n                    connection = self.connections[process.id]\n                else:\n                    connection = Connection(\n                        server=self.server,\n                        process=process,\n                        auto_close=self.config['autoCloseConnections'],\n                        logger=self.logger,\n                    )\n                    self.connections[process.id] = connection\n                message.data = connection.s2c(message.data)\n            elif isinstance(message, CloseMessage):\n                if process.id in self.connections:\n                    connection = self.connections[process.id]\n                    connection.close()\n                    del self.connections[process.id]\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        with self.lock:\n            if isinstance(message, SendMessage):\n                if not self.config['multipleConnections'] and process.id in self.connections:\n                    connection = self.connections[process.id]\n                else:\n                    connection = self.server.get_connection(process.id)\n                    self.connections[process.id] = connection\n\n                message.data = connection.c2s(message.data)\n\n            elif isinstance(message, RecvMessage):\n                if process.id in self.connections:\n                    connection = self.connections[process.id]\n                else:\n                    connection = self.server.get_connection(process.id)\n                    self.connections[process.id] = connection\n\n                message.data = connection.s2c(message.data)\n\n            elif isinstance(message, CloseMessage):\n                if process.id in self.connections:\n                    connection = self.connections[process.id]\n                    self.connections.pop(process.id)\n\n                    if self.config['autoCloseConnections']:\n                        connection.close()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            self.lock.acquire()\n            if self.config['multipleConnections']:\n                connection_id = process.name\n            else:\n                connection_id = DEFAULT_CONNECTION_ID\n            if connection_id not in self.connections:\n                self.connections[connection_id] = Connection(\n                    connection_id,\n                    self.server,\n                    self.config['autoCloseConnections'],\n                    self.logger\n                )\n            self.lock.release()\n            self.connections[connection_id].send(message.data)\n            message.data = None\n        elif isinstance(message, RecvMessage):\n            self.lock.acquire()\n            if self.config['multipleConnections']:\n                connection_id = process.name\n            else:\n                connection_id = DEFAULT_CONNECTION_ID\n            if connection_id not in self.connections:\n                self.connections[connection_id] = Connection(\n                    connection_id,\n                    self.server,\n                    self.config['autoCloseConnections'],\n                    self.logger\n                )\n            self.lock.release()\n            message.data = self.connections[connection_id].recv()\n        elif isinstance(message, CloseMessage):\n            self.lock.acquire()\n            if self.config['multipleConnections']:\n                connection_id = process.name\n            else:\n                connection_id = DEFAULT_CONNECTION_ID\n            if connection_id in self.connections:\n                self.connections[connection_id].close()\n                del self.connections[connection_id]\n            self.lock.release()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            with self.lock:\n                if self.config['multipleConnections']:\n                    connection_id = process.id\n                else:\n                    connection_id = DEFAULT_CONNECTION_ID\n\n                if connection_id not in self.connections:\n                    self.connections[connection_id] = Connection(\n                        self.server,\n                        process,\n                        connection_id,\n                        self.config['autoCloseConnections'],\n                        self.logger\n                    )\n\n                self.connections[connection_id].c2s(message)\n        elif isinstance(message, RecvMessage):\n            with self.lock:\n                for connection in self.connections.values():\n                    if connection.s2c(message):\n                        break\n        elif isinstance(message, CloseMessage):\n            with self.lock:\n                if process.id in self.connections:\n                    self.connections[process.id].close()\n                    del self.connections[process.id]\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            connection = self.get_connection(process)\n            message.data = connection.c2s(message.data)\n\n        elif isinstance(message, RecvMessage):\n            connection = self.get_connection(process)\n            message.data = connection.s2c(message.data)\n\n        elif isinstance(message, CloseMessage):\n            connection = self.get_connection(process)\n            if self.config['autoCloseConnections']:\n                connection.close()\n                self.connections.pop(process.id)\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        with self.lock:\n            if message.type == MessageType.SEND:\n                if self.config['multipleConnections']:\n                    connection_id = process.id\n                else:\n                    connection_id = DEFAULT_CONNECTION_ID\n                if connection_id not in self.connections:\n                    self.connections[connection_id] = Connection(self.server.create_connection())\n                self.connections[connection_id].send(message.data)\n            elif message.type == MessageType.RECV:\n                if self.config['multipleConnections']:\n                    connection_id = process.id\n                else:\n                    connection_id = DEFAULT_CONNECTION_ID\n                if connection_id not in self.connections:\n                    self.connections[connection_id] = Connection(self.server.create_connection())\n                message.data = self.connections[connection_id].recv()\n            elif message.type == MessageType.CLOSE:\n                if self.config['multipleConnections']:\n                    connection_id = process.id\n                else:\n                    connection_id = DEFAULT_CONNECTION_ID\n                if connection_id in self.connections:\n                    self.connections[connection_id].close()\n                    del self.connections[connection_id]\n                if self.config['autoCloseConnections']:\n                    self.server.close_connection()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        with self.lock:\n            if isinstance(message, SendMessage):\n                self.logger.debug(f'Intercepting SendMessage from {process.name}')\n                connection = self.connections.get(process.id)\n                if connection is None:\n                    connection = self.server.get_connection(process.id)\n                    self.connections[process.id] = connection\n                message.data = connection.c2s(message.data)\n            elif isinstance(message, RecvMessage):\n                self.logger.debug(f'Intercepting RecvMessage from {process.name}')\n                connection = self.connections.get(process.id)\n                if connection is None:\n                    connection = self.server.get_connection(process.id)\n                    self.connections[process.id] = connection\n                message.data = connection.s2c(message.data)\n            elif isinstance(message, CloseMessage):\n                self.logger.debug(f'Intercepting CloseMessage from {process.name}')\n                connection = self.connections.get(process.id)\n                if connection is not None:\n                    connection.close()\n                    del self.connections[process.id]\n                    if self.config['autoCloseConnections']:\n                        self.server.close_connection(connection)\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        with self.lock:\n            if isinstance(message, SendMessage):\n                if not self.config['multipleConnections'] and process.id in self.connections:\n                    connection = self.connections[process.id]\n                else:\n                    connection = Connection(\n                        connection_id=DEFAULT_CONNECTION_ID,\n                        c2s=self.server.get_c2s_proxy(DEFAULT_CONNECTION_ID),\n                        s2c=self.server.get_s2c_proxy(DEFAULT_CONNECTION_ID),\n                        auto_close=self.config['autoCloseConnections'],\n                        logger=self.logger,\n                    )\n                    self.connections[process.id] = connection\n                message.data = connection.c2s(message.data)\n            elif isinstance(message, RecvMessage):\n                if process.id in self.connections:\n                    connection = self.connections[process.id]\n                else:\n                    connection = Connection(\n                        connection_id=DEFAULT_CONNECTION_ID,\n                        c2s=self.server.get_c2s_proxy(DEFAULT_CONNECTION_ID),\n                        s2c=self.server.get_s2c_proxy(DEFAULT_CONNECTION_ID),\n                        auto_close=self.config['autoCloseConnections'],\n                        logger=self.logger,\n                    )\n                    self.connections[process.id] = connection\n                message.data = connection.s2c(message.data)\n            elif isinstance(message, CloseMessage):\n                if process.id in self.connections:\n                    connection = self.connections[process.id]\n                    connection.close()\n                    del self.connections[process.id]\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            with self.lock:\n                if not self.config['multipleConnections']:\n                    connection = self.connections.get(DEFAULT_CONNECTION_ID, None)\n                    if not connection:\n                        connection = Connection(\n                            connection_id=DEFAULT_CONNECTION_ID,\n                            strategy=ProxifierStrategyType(self.config['strategy']),\n                            strategy_config=self.config['strategies'].get(self.config['strategy'], {}),\n                            server=self.server,\n                            logger=self.logger\n                        )\n                        self.connections[DEFAULT_CONNECTION_ID] = connection\n                else:\n                    connection = self.connections.get(process.process_id, None)\n                    if not connection:\n                        connection = Connection(\n                            connection_id=process.process_id,\n                            strategy=ProxifierStrategyType(self.config['strategy']),\n                            strategy_config=self.config['strategies'].get(self.config['strategy'], {}),\n                            server=self.server,\n                            logger=self.logger\n                        )\n                        self.connections[process.process_id] = connection\n                connection.c2s(message)\n                if self.config['autoCloseConnections']:\n                    connection.close()\n                    del self.connections[process.process_id]\n        elif isinstance(message, RecvMessage):\n            with self.lock:\n                if not self.config['multipleConnections']:\n                    connection = self.connections.get(DEFAULT_CONNECTION_ID, None)\n                    if not connection:\n                        connection = Connection(\n                            connection_id=DEFAULT_CONNECTION_ID,\n                            strategy=ProxifierStrategyType(self.config['strategy']),\n                            strategy_config=self.config['strategies'].get(self.config['strategy'], {}),\n                            server=self.server,\n                            logger=self.logger\n                        )\n                        self.conne"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            self.lock.acquire()\n            connection_id = process.connection_id if self.config['multipleConnections'] else DEFAULT_CONNECTION_ID\n            if connection_id not in self.connections:\n                self.connections[connection_id] = Connection(\n                    connection_id=connection_id,\n                    process=process,\n                    server=self.server,\n                    auto_close=self.config['autoCloseConnections'],\n                    logger=self.logger\n                )\n            self.lock.release()\n            self.connections[connection_id].send(message.data)\n            message.data = self.connections[connection_id].c2s_buffer\n        elif isinstance(message, RecvMessage):\n            self.lock.acquire()\n            connection_id = process.connection_id if self.config['multipleConnections'] else DEFAULT_CONNECTION_ID\n            self.lock.release()\n            self.connections[connection_id].receive(message.data)\n            message.data = self.connections[connection_id].s2c_buffer\n        elif isinstance(message, CloseMessage):\n            self.lock.acquire()\n            connection_id = process.connection_id if self.config['multipleConnections'] else DEFAULT_CONNECTION_ID\n            self.lock.release()\n            self.connections[connection_id].close()\n            del self.connections[connection_id]\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            self.lock.acquire()\n            if self.config['multipleConnections']:\n                connection_id = f'{process.pid}_{process.pname}'\n            else:\n                connection_id = DEFAULT_CONNECTION_ID\n\n            if connection_id not in self.connections:\n                self.connections[connection_id] = Connection(\n                    server=self.server,\n                    connection_id=connection_id,\n                    logger=self.logger,\n                )\n\n            self.connections[connection_id].send(message.data)\n\n            if self.config['autoCloseConnections'] and isinstance(message, CloseMessage):\n                self.connections[connection_id].close()\n                del self.connections[connection_id]\n            self.lock.release()\n\n        elif isinstance(message, RecvMessage):\n            self.lock.acquire()\n            if self.config['multipleConnections']:\n                connection_id = f'{process.pid}_{process.pname}'\n            else:\n                connection_id = DEFAULT_CONNECTION_ID\n\n            if connection_id not in self.connections:\n                self.connections[connection_id] = Connection(\n                    server=self.server,\n                    connection_id=connection_id,\n                    logger=self.logger,\n                )\n\n            message.data = self.connections[connection_id].receive()\n            self.lock.release()\n\n        elif isinstance(message, CloseMessage):\n            self.lock.acquire()\n            if self.config['multipleConnections']:\n                connection_id = f'{process.pid}_{process.pname}'\n            else:\n                connection_id = DEFAULT_CONNECTION_ID\n\n            if connection_id in self.connections:\n                self.connections[connection_id].close()\n                del self.connections[connection_id]\n            self.lock.release()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        connection = self.get_connection(process)\n\n        if isinstance(message, SendMessage):\n            message.data = connection.c2s(message.data)\n\n        elif isinstance(message, RecvMessage):\n            message.data = connection.s2c(message.data)\n\n        elif isinstance(message, CloseMessage):\n            if self.config['autoCloseConnections']:\n                connection.close()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        self.logger.debug('Intercepting message: {}'.format(message))\n\n        if isinstance(message, SendMessage):\n            self.logger.debug('Intercepting SendMessage')\n            with self.lock:\n                if process.id in self.connections:\n                    self.connections[process.id].c2s(message)\n                else:\n                    self.connections[process.id] = self.server.new_connection(DEFAULT_CONNECTION_ID)\n                    self.connections[process.id].c2s(message)\n\n        elif isinstance(message, RecvMessage):\n            self.logger.debug('Intercepting RecvMessage')\n            with self.lock:\n                if process.id in self.connections:\n                    self.connections[process.id].s2c(message)\n                else:\n                    self.connections[process.id] = self.server.new_connection(DEFAULT_CONNECTION_ID)\n                    self.connections[process.id].s2c(message)\n\n        elif isinstance(message, CloseMessage):\n            self.logger.debug('Intercepting CloseMessage')\n            with self.lock:\n                if process.id in self.connections:\n                    if self.config['autoCloseConnections']:\n                        self.connections[process.id].close()\n                    else:\n                        self.connections[process.id].close(False)\n                else:\n                    self.connections[process.id] = self.server.new_connection(DEFAULT_CONNECTION_ID)\n                    self.connections[process.id].close()\n\n        else:\n            self.logger.warning('Unknown message type: {}'.format(message))"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            with self.lock:\n                if process.id not in self.connections:\n                    if not self.config['multipleConnections']:\n                        raise Exception('Process has no connection')\n                    self.connections[process.id] = Connection(\n                        self.server,\n                        self.config['autoCloseConnections'],\n                        self.logger\n                    )\n                connection = self.connections[process.id]\n                message.data = connection.c2s(message.data)\n                self.logger.debug(f'ProxifierMessageInterceptor.intercept: {message}')\n        elif isinstance(message, RecvMessage):\n            with self.lock:\n                if process.id not in self.connections:\n                    raise Exception('Process has no connection')\n                connection = self.connections[process.id]\n                message.data = connection.s2c(message.data)\n                self.logger.debug(f'ProxifierMessageInterceptor.intercept: {message}')\n        elif isinstance(message, CloseMessage):\n            with self.lock:\n                if process.id not in self.connections:\n                    raise Exception('Process has no connection')\n                connection = self.connections[process.id]\n                connection.close()\n                del self.connections[process.id]\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        self.logger.debug('intercepting message: {}'.format(message))\n        if isinstance(message, SendMessage):\n            with self.lock:\n                connection = self.connections.get(process.id)\n                if connection is None:\n                    connection = Connection(\n                        process_id=process.id,\n                        strategy=ProxifierStrategyType(self.config['strategy']),\n                        strategy_config=self.config['strategies'].get(self.config['strategy'], {}),\n                        logger=self.logger\n                    )\n                    self.connections[process.id] = connection\n                message.data = connection.c2s(message.data)\n                self.logger.debug('c2s modified message data to: {}'.format(message.data))\n        elif isinstance(message, RecvMessage):\n            with self.lock:\n                connection = self.connections.get(process.id)\n                if connection is None:\n                    connection = Connection(\n                        process_id=process.id,\n                        strategy=ProxifierStrategyType(self.config['strategy']),\n                        strategy_config=self.config['strategies'].get(self.config['strategy'], {}),\n                        logger=self.logger\n                    )\n                    self.connections[process.id] = connection\n                message.data = connection.s2c(message.data)\n                self.logger.debug('s2c modified message data to: {}'.format(message.data))\n        elif isinstance(message, CloseMessage):\n            with self.lock:\n                connection = self.connections.get(process.id)\n                if connection is not None:\n                    connection.close()\n                    del self.connections[process.id]\n                if self.config['autoCloseConnections'] and not self.config['multipleConnections']:\n                    self.connections.clear()\n        else:\n            self.logger.warning('unsupported message type: {}'.format(message))\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n            self.connections.clear()\n\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.server.stop()\n        for connection in self.connections.values():\n            connection.close()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n            self.connections = {}\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.logger.info('Stopping all connections')\n        for connection in self.connections.values():\n            connection.close()\n        self.logger.info('Stopping server')\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.logger.info(\"Stopping all connections\")\n        for connection in self.connections.values():\n            connection.close()\n        self.logger.info(\"Stopping server\")\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.lock.acquire()\n        try:\n            for connection in self.connections.values():\n                connection.close()\n            self.connections.clear()\n        finally:\n            self.lock.release()\n\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.logger.debug('Stopping all connections')\n        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n            self.connections = {}\n\n        self.logger.debug('Stopping the server')\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.logger.info(\"Stopping all connections\")\n        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n            self.connections = {}\n        self.logger.info(\"Stopping server\")\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.logger.debug(\"Destroying ProxifierMessageInterceptor...\")\n\n        self.logger.debug(\"Stopping all connections...\")\n        for connection in self.connections.values():\n            connection.stop()\n\n        self.logger.debug(\"Stopping server...\")\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.logger.debug('destroying ProxifierMessageInterceptor')\n        self._close_connections()\n        if self.server is not None:\n            self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.logger.debug(\"Destroying ProxifierMessageInterceptor\")\n        for connection in self.connections.values():\n            connection.close()\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection in self.connections.values():\n                if connection.is_open():\n                    connection.close()\n\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.logger.info('Destroying ProxifierMessageInterceptor')\n        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n            self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        for connection in self.connections.values():\n            connection.close()\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.logger.debug(\"destroying ProxifierMessageInterceptor\")\n        with self.lock:\n            for connection in self.connections.values():\n                if self.config['autoCloseConnections']:\n                    connection.close()\n            self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.lock.acquire()\n        try:\n            for connection in self.connections.values():\n                if self.config['autoCloseConnections']:\n                    connection.close()\n            self.connections.clear()\n            self.server.stop()\n        finally:\n            self.lock.release()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.logger.debug('Destroying ProxifierMessageInterceptor')\n        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.logger.debug(\"Destroying ProxifierMessageInterceptor\")\n        self.server.stop()\n        for connection in self.connections.values():\n            connection.stop()\n"}
